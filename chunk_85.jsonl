{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nintegrate the object over the left - hand side of the domain.", "response": "def integrate(self):\n        \"\"\"\n        Return the object representing the primitive of self over the domain. The\n        output starts at zero on the left-hand side of the domain.\n        \"\"\"\n        coeffs = self.coefficients()\n        a,b = self.domain()\n        int_coeffs = 0.5*(b-a)*poly.chebyshev.chebint(coeffs)\n        antiderivative = self.from_coeff(int_coeffs, domain=self.domain())\n        return antiderivative - antiderivative(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new instance of the class with the n - th derivative.", "response": "def differentiate(self, n=1):\n        \"\"\"\n        n-th derivative, default 1.\n        \"\"\"\n        ak = self.coefficients()\n        a_, b_ = self.domain()\n        for _ in range(n):\n            ak = self.differentiator(ak)\n        return self.from_coeff((2./(b_-a_))**n*ak, domain=self.domain())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef roots(self):\n        if self.size() == 1:\n            return np.array([])\n\n        elif self.size() <= 100:\n            ak = self.coefficients()\n            v = np.zeros_like(ak[:-1])\n            v[1] = 0.5\n            C1 = linalg.toeplitz(v)\n            C2 = np.zeros_like(C1)\n            C1[0,1] = 1.\n            C2[-1,:] = ak[:-1]\n            C = C1 - .5/ak[-1] * C2\n            eigenvalues = linalg.eigvals(C)\n            roots = [eig.real for eig in eigenvalues\n                    if np.allclose(eig.imag,0,atol=1e-10)\n                        and np.abs(eig.real) <=1]\n            scaled_roots = self._ui_to_ab(np.array(roots))\n            return scaled_roots\n        else:\n            # divide at a close-to-zero split-point\n            split_point = self._ui_to_ab(0.0123456789)\n            return np.concatenate(\n                (self.restrict([self._domain[0],split_point]).roots(),\n                 self.restrict([split_point,self._domain[1]]).roots())\n            )", "response": "This method returns a list of roots of the current ChallengeEntry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the interpolation points of the Chebyshev table.", "response": "def interpolation_points(self, N):\n        \"\"\"\n        N Chebyshev points in [-1, 1], boundaries included\n        \"\"\"\n        if N == 1:\n            return np.array([0.])\n        return np.cos(np.arange(N)*np.pi/(N-1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsample a function on N Chebyshev points.", "response": "def sample_function(self, f, N):\n        \"\"\"\n        Sample a function on N+1 Chebyshev points.\n        \"\"\"\n        x = self.interpolation_points(N+1)\n        return f(x)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef polyfit(self, sampled):\n        asampled = np.asarray(sampled)\n        if len(asampled) == 1:\n            return asampled\n        evened = even_data(asampled)\n        coeffs = dct(evened)\n        return coeffs", "response": "Compute Chebyshev coefficients for values located on Chebyshev points."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the interpolation values at Chebyshev points.", "response": "def polyval(self, chebcoeff):\n        \"\"\"\n        Compute the interpolation values at Chebyshev points.\n        chebcoeff: Chebyshev coefficients\n        \"\"\"\n        N = len(chebcoeff)\n        if N == 1:\n            return chebcoeff\n\n        data = even_data(chebcoeff)/2\n        data[0] *= 2\n        data[N-1] *= 2\n\n        fftdata = 2*(N-1)*fftpack.ifft(data, axis=0)\n        complex_values = fftdata[:N]\n        # convert to real if input was real\n        if np.isrealobj(chebcoeff):\n            values = np.real(complex_values)\n        else:\n            values = complex_values\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interpolator(self, x, values):\n        # hacking the barycentric interpolator by computing the weights in advance\n        p = Bary([0.])\n        N = len(values)\n        weights = np.ones(N)\n        weights[0] = .5\n        weights[1::2] = -1\n        weights[-1] *= .5\n        p.wi = weights\n        p.xi = x\n        p.set_yi(values)\n        return p", "response": "Returns a polynomial with vector coefficients which interpolates the values at the Chebyshev points x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndifferentiates a set of Chebyshev polynomial expansion coefficients Originally from http://www.scientificpython.net/pyblog/chebyshev-differentiation + (lots of) bug fixing + pythonisation", "response": "def differentiator(self, A):\n        \"\"\"Differentiate a set of Chebyshev polynomial expansion\n           coefficients\n           Originally from http://www.scientificpython.net/pyblog/chebyshev-differentiation\n            + (lots of) bug fixing + pythonisation\n           \"\"\"\n        m = len(A)\n        SA = (A.T* 2*np.arange(m)).T\n        DA = np.zeros_like(A)\n        if m == 1: # constant\n            return np.zeros_like(A[0:1])\n        if m == 2: # linear\n            return A[1:2,]\n        DA[m-3:m-1,] = SA[m-2:m,]\n        for j in range(m//2 - 1):\n            k = m-3-2*j\n            DA[k] = SA[k+1] + DA[k+2]\n            DA[k-1] = SA[k] + DA[k+1]\n        DA[0] = (SA[1] + DA[2])*0.5\n        return DA"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Morsi_Alexander(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = \\left\\{ \\begin{array}{ll}\n        \\frac{24}{Re} & \\mbox{if $Re < 0.1$}\\\\\n        \\frac{22.73}{Re}+\\frac{0.0903}{Re^2} + 3.69 & \\mbox{if $0.1 < Re < 1$}\\\\\n        \\frac{29.1667}{Re}-\\frac{3.8889}{Re^2} + 1.2220 & \\mbox{if $1 < Re < 10$}\\\\\n        \\frac{46.5}{Re}-\\frac{116.67}{Re^2} + 0.6167 & \\mbox{if $10 < Re < 100$}\\\\\n        \\frac{98.33}{Re}-\\frac{2778}{Re^2} + 0.3644 & \\mbox{if $100 < Re < 1000$}\\\\\n        \\frac{148.62}{Re}-\\frac{4.75\\times10^4}{Re^2} + 0.3570 & \\mbox{if $1000 < Re < 5000$}\\\\\n        \\frac{-490.5460}{Re}+\\frac{57.87\\times10^4}{Re^2} + 0.46 & \\mbox{if $5000 < Re < 10000$}\\\\\n        \\frac{-1662.5}{Re}+\\frac{5.4167\\times10^6}{Re^2} + 0.5191 & \\mbox{if $10000 < Re < 50000$}\\end{array} \\right.\n\n    Parameters\n    ----------\n    Re : float\n        Particle Reynolds number of the sphere using the surrounding fluid\n        density and viscosity, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 2E5.\n    Original was reviewed, and confirmed to contain the cited equations.\n\n    Examples\n    --------\n    >>> Morsi_Alexander(200)\n    0.7866\n\n    References\n    ----------\n    .. [1] Morsi, S. A., and A. J. Alexander. \"An Investigation of Particle\n       Trajectories in Two-Phase Flow Systems.\" Journal of Fluid Mechanics\n       55, no. 02 (September 1972): 193-208. doi:10.1017/S0022112072001806.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    if Re < 0.1:\n        return 24./Re\n    elif Re < 1:\n        return 22.73/Re + 0.0903/Re**2 + 3.69\n    elif Re < 10:\n        return 29.1667/Re - 3.8889/Re**2 + 1.222\n    elif Re < 100:\n        return 46.5/Re - 116.67/Re**2 + 0.6167\n    elif Re < 1000:\n        return 98.33/Re - 2778./Re**2 + 0.3644\n    elif Re < 5000:\n        return 148.62/Re - 4.75E4/Re**2 + 0.357\n    elif Re < 10000:\n        return -490.546/Re + 57.87E4/Re**2 + 0.46\n    else:\n        return -1662.5/Re + 5.4167E6/Re**2 + 0.5191", "response": "Alexander method for the Morsi - Alexander system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Clift(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = \\left\\{ \\begin{array}{ll}\n        \\frac{24}{Re} + \\frac{3}{16} & \\mbox{if $Re < 0.01$}\\\\\n        \\frac{24}{Re}(1 + 0.1315Re^{0.82 - 0.05\\log Re}) & \\mbox{if $0.01 < Re < 20$}\\\\\n        \\frac{24}{Re}(1 + 0.1935Re^{0.6305}) & \\mbox{if $20 < Re < 260$}\\\\\n        10^{[1.6435 - 1.1242\\log Re + 0.1558[\\log Re]^2} & \\mbox{if $260 < Re < 1500$}\\\\\n        10^{[-2.4571 + 2.5558\\log Re - 0.9295[\\log Re]^2 + 0.1049[\\log Re]^3} & \\mbox{if $1500 < Re < 12000$}\\\\\n        10^{[-1.9181 + 0.6370\\log Re - 0.0636[\\log Re]^2} & \\mbox{if $12000 < Re < 44000$}\\\\\n        10^{[-4.3390 + 1.5809\\log Re - 0.1546[\\log Re]^2} & \\mbox{if $44000 < Re < 338000$}\\\\\n        9.78 - 5.3\\log Re & \\mbox{if $338000 < Re < 400000$}\\\\\n        0.19\\log Re - 0.49 & \\mbox{if $400000 < Re < 1000000$}\\end{array} \\right.\n\n    Parameters\n    ----------\n    Re : float\n        Particle Reynolds number of the sphere using the surrounding fluid\n        density and viscosity, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is Re <= 1E6.\n\n    Examples\n    --------\n    >>> Clift(200)\n    0.7756342422322543\n\n    References\n    ----------\n    .. [1] R. Clift, J.R. Grace, M.E. Weber, Bubbles, Drops, and Particles,\n       Academic, New York, 1978.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    if Re < 0.01:\n        return 24./Re + 3/16.\n    elif Re < 20:\n        return 24./Re*(1 + 0.1315*Re**(0.82 - 0.05*log10(Re)))\n    elif Re < 260:\n        return 24./Re*(1 + 0.1935*Re**(0.6305))\n    elif Re < 1500:\n        return 10**(1.6435 - 1.1242*log10(Re) + 0.1558*(log10(Re))**2)\n    elif Re < 12000:\n        return 10**(-2.4571 + 2.5558*log10(Re) - 0.9295*(log10(Re))**2 + 0.1049*log10(Re)**3)\n    elif Re < 44000:\n        return 10**(-1.9181 + 0.6370*log10(Re) - 0.0636*(log10(Re))**2)\n    elif Re < 338000:\n        return 10**(-4.3390 + 1.5809*log10(Re) - 0.1546*(log10(Re))**2)\n    elif Re < 400000:\n        return 29.78 - 5.3*log10(Re)\n    else:\n        return 0.19*log10(Re) - 0.49", "response": "Calculates the drag coefficient of a smooth sphere using the method in\n    [ 1 ] _ as described in [ 2 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Ceylan(Re):\n    r'''Calculates drag coefficient of a smooth sphere using the method in\n    [1]_ as described in [2]_.\n\n    .. math::\n        C_D = 1 - 0.5\\exp(0.182) + 10.11Re^{-2/3}\\exp(0.952Re^{-1/4})\n        - 0.03859Re^{-4/3}\\exp(1.30Re^{-1/2})\n        + 0.037\\times10^{-4}Re\\exp(-0.125\\times10^{-4}Re)\n        -0.116\\times10^{-10}Re^2\\exp(-0.444\\times10^{-5}Re)\n\n    Parameters\n    ----------\n    Re : float\n        Particle Reynolds number of the sphere using the surrounding fluid\n        density and viscosity, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n\n    Notes\n    -----\n    Range is 0.1 < Re <= 1E6\n    Original article reviewed.\n\n    Examples\n    --------\n    >>> Ceylan(200.)\n    0.7816735980280175\n\n    References\n    ----------\n    .. [1] Ceylan, Kadim, Ay\u015fe Altunba\u015f, and Gudret Kelbaliyev. \"A New Model\n       for Estimation of Drag Force in the Flow of Newtonian Fluids around\n       Rigid or Deformable Particles.\" Powder Technology 119, no. 2-3\n       (September 24, 2001): 250-56. doi:10.1016/S0032-5910(01)00261-3.\n    .. [2] Barati, Reza, Seyed Ali Akbar Salehi Neyshabouri, and Goodarz\n       Ahmadi. \"Development of Empirical Models with High Accuracy for\n       Estimation of Drag Coefficient of Flow around a Smooth Sphere: An\n       Evolutionary Approach.\" Powder Technology 257 (May 2014): 11-19.\n       doi:10.1016/j.powtec.2014.02.045.\n    '''\n    Cd = (1 - 0.5*exp(0.182) + 10.11*Re**(-2/3.)*exp(0.952*Re**-0.25)\n    - 0.03859*Re**(-4/3.)*exp(1.30*Re**-0.5) + 0.037E-4*Re*exp(-0.125E-4*Re)\n    - 0.116E-10*Re**2*exp(-0.444E-5*Re))\n    return Cd", "response": "A function that calculates the drag coefficient of a smooth sphere."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef drag_sphere(Re, Method=None, AvailableMethods=False):\n    r'''This function handles calculation of drag coefficient on spheres.\n    Twenty methods are available, all requiring only the Reynolds number of the\n    sphere. Most methods are valid from Re=0 to Re=200,000. A correlation will\n    be automatically selected if none is specified. The full list of correlations\n    valid for a given Reynolds number can be obtained with the `AvailableMethods`\n    flag.\n\n    If no correlation is selected, the following rules are used:\n\n        * If Re < 0.01, use Stoke's solution.\n        * If 0.01 <= Re < 0.1, linearly combine 'Barati' with Stokes's solution\n          such that at Re = 0.1 the solution is 'Barati', and at Re = 0.01 the\n          solution is 'Stokes'.\n        * If 0.1 <= Re <= ~212963, use the 'Barati' solution.\n        * If ~212963 < Re <= 1E6, use the 'Barati_high' solution.\n        * For Re > 1E6, raises an exception; no valid results have been found.\n\n    Examples\n    --------\n    >>> drag_sphere(200)\n    0.7682237950389874\n\n    Parameters\n    ----------\n    Re : float\n        Particle Reynolds number of the sphere using the surrounding fluid\n        density and viscosity, [-]\n\n    Returns\n    -------\n    Cd : float\n        Drag coefficient [-]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate `Cd` with the given `Re`\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        A string of the function name to use, as in the dictionary\n        drag_sphere_correlations\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate `Cd` with the given `Re`\n    '''\n    def list_methods():\n        methods = []\n        for key, (func, Re_min, Re_max) in drag_sphere_correlations.items():\n            if (Re_min is None or Re > Re_min) and (Re_max is None or Re < Re_max):\n                methods.append(key)\n        return methods\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        if Re > 0.1:\n            # Smooth transition point between the two models\n            if Re <= 212963.26847812787:\n                return Barati(Re)\n            elif Re <= 1E6:\n                return Barati_high(Re)\n            else:\n                raise ValueError('No models implement a solution for Re > 1E6')\n        elif Re >= 0.01:\n            # Re from 0.01 to 0.1\n            ratio = (Re - 0.01)/(0.1 - 0.01)\n            # Ensure a smooth transition by linearly switching to Stokes' law\n            return ratio*Barati(Re) + (1-ratio)*Stokes(Re)\n        else:\n            return Stokes(Re)\n\n    if Method in drag_sphere_correlations:\n        return drag_sphere_correlations[Method][0](Re)\n    else:\n        raise Exception('Failure in in function')", "response": "r This function calculates the drag coefficient on a given Reynolds number of a sphere."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef integrate_drag_sphere(D, rhop, rho, mu, t, V=0, Method=None,\n                          distance=False):\n    r'''Integrates the velocity and distance traveled by a particle moving\n    at a speed which will converge to its terminal velocity.\n\n    Performs an integration of the following expression for acceleration:\n\n    .. math::\n        a = \\frac{g(\\rho_p-\\rho_f)}{\\rho_p} - \\frac{3C_D \\rho_f u^2}{4D \\rho_p}\n\n    Parameters\n    ----------\n    D : float\n        Diameter of the sphere, [m]\n    rhop : float\n        Particle density, [kg/m^3]\n    rho : float\n        Density of the surrounding fluid, [kg/m^3]\n    mu : float\n        Viscosity of the surrounding fluid [Pa*s]\n    t : float\n        Time to integrate the particle to, [s]\n    V : float\n        Initial velocity of the particle, [m/s]\n    Method : string, optional\n        A string of the function name to use, as in the dictionary\n        drag_sphere_correlations\n    distance : bool, optional\n        Whether or not to calculate the distance traveled and return it as\n        well\n\n    Returns\n    -------\n    v : float\n        Velocity of falling sphere after time `t` [m/s]\n    x : float, returned only if `distance` == True\n        Distance traveled by the falling sphere in time `t`, [m]\n\n    Notes\n    -----\n    This can be relatively slow as drag correlations can be complex.\n    \n    There are analytical solutions available for the Stokes law regime (Re < \n    0.3). They were obtained from Wolfram Alpha. [1]_ was not used in the\n    derivation, but also describes the derivation fully.\n    \n    .. math::\n        V(t) = \\frac{\\exp(-at) (V_0 a + b(\\exp(at) - 1))}{a}\n        \n    .. math::\n        x(t) = \\frac{\\exp(-a t)\\left[V_0 a(\\exp(a t) - 1) + b\\exp(a t)(a t-1) \n        + b\\right]}{a^2}\n    \n    .. math::\n        a = \\frac{18\\mu_f}{D^2\\rho_p}\n    \n    .. math::\n        b = \\frac{g(\\rho_p-\\rho_f)}{\\rho_p}\n        \n    The analytical solution will automatically be used if the initial and \n    terminal velocity is show the particle's behavior to be laminar. Note\n    that this behavior requires that the terminal velocity of the particle be\n    solved for - this adds slight (1%) overhead for the cases where particles \n    are not laminar.\n\n    Examples\n    --------\n    >>> integrate_drag_sphere(D=0.001, rhop=2200., rho=1.2, mu=1.78E-5, t=0.5,\n    ... V=30, distance=True) \n    (9.686465044053476, 7.8294546436299175)\n    \n    References\n    ----------\n    .. [1] Timmerman, Peter, and Jacobus P. van der Weele. \"On the Rise and \n       Fall of a Ball with Linear or Quadratic Drag.\" American Journal of \n       Physics 67, no. 6 (June 1999): 538-46. https://doi.org/10.1119/1.19320.\n    '''\n    laminar_initial = Reynolds(V=V, rho=rho, D=D, mu=mu) < 0.01\n    v_laminar_end_assumed = v_terminal(D=D, rhop=rhop, rho=rho, mu=mu, Method=Method)\n    laminar_end = Reynolds(V=v_laminar_end_assumed, rho=rho, D=D, mu=mu) < 0.01\n    if Method == 'Stokes' or (laminar_initial and laminar_end and Method is None):\n        try:\n            t1 = 18.0*mu/(D*D*rhop)\n            t2 = g*(rhop-rho)/rhop\n            V_end = exp(-t1*t)*(t1*V + t2*(exp(t1*t) - 1.0))/t1\n            x_end = exp(-t1*t)*(V*t1*(exp(t1*t) - 1.0) + t2*exp(t1*t)*(t1*t - 1.0) + t2)/(t1*t1)\n            if distance:\n                return V_end, x_end\n            else:\n                return V_end\n        except OverflowError:\n            # It is only necessary to integrate to terminal velocity\n            t_to_terminal = time_v_terminal_Stokes(D, rhop, rho, mu, V0=V, tol=1e-9)\n            if t_to_terminal > t:\n                raise Exception('Should never happen')\n            V_end, x_end = integrate_drag_sphere(D=D, rhop=rhop, rho=rho, mu=mu, t=t_to_terminal, V=V, Method='Stokes', distance=True)\n            # terminal velocity has been reached - V does not change, but x does\n            # No reason to believe this isn't working even though it isn't\n            # matching the ode solver\n            if distance:\n                return V_end, x_end + V_end*(t - t_to_terminal)\n            else:\n                return V_end\n            \n            # This is a serious problem for small diameters\n            # It would be possible to step slowly, using smaller increments\n            # of time to avlid overflows. However, this unfortunately quickly\n            # gets much, exponentially, slower than just using odeint because\n            # for example solving 10000 seconds might require steps of .0001\n            # seconds at a diameter of 1e-7 meters.\n#            x = 0.0\n#            subdivisions = 10\n#            dt = t/subdivisions\n#            for i in range(subdivisions):\n#                V, dx = integrate_drag_sphere(D=D, rhop=rhop, rho=rho, mu=mu,\n#                                              t=dt, V=V, distance=True,\n#                                              Method=Method)\n#                x += dx\n#            if distance:\n#                return V, x\n#            else:\n#                return V\n    \n    Re_ish = rho*D/mu\n    c1 = g*(rhop-rho)/rhop\n    c2 = -0.75*rho/(D*rhop)\n\n    def dv_dt(V, t):\n        if V == 0:\n            # 64/Re goes to infinity, but gets multiplied by 0 squared.\n            t2 = 0.0\n        else:\n#            t2 = c2*V*V*Stokes(Re_ish*V)\n            t2 = c2*V*V*drag_sphere(Re_ish*V, Method=Method)\n        return c1 + t2\n\n    # Number of intervals for the solution to be solved for; the integrator\n    # doesn't care what we give it, but a large number of intervals are needed\n    # For an accurate integration of the particle's distance traveled\n    pts = 1000 if distance else 2\n    ts = np.linspace(0, t, pts)\n    \n    # Delayed import of necessaray functions\n    from scipy.integrate import odeint, cumtrapz\n\n    # Perform the integration\n    Vs = odeint(dv_dt, [V], ts)\n    #\n    V_end = float(Vs[-1])\n    if distance:\n        # Calculate the distance traveled\n        x = float(cumtrapz(np.ravel(Vs), ts)[-1])\n        return V_end, x\n    else:\n        return V_end", "response": "r Integrates the velocity and distance traveled by a particle moving\n    at a speed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef entrance_distance(Di, t=None, l=None, method='Rennels'):\n    r'''Returns the loss coefficient for a sharp entrance to a pipe at a distance\n    from the wall of a reservoir. This calculation has five methods available;\n    all but 'Idelchik' require the pipe to be at least `Di/2` into the\n    reservoir.\n\n    The most conservative formulation is that of Rennels; with Miller being\n    almost identical until `t/Di` reaches 0.05, when it continues settling to\n    K = 0.53 compared to K = 0.57 for 'Rennels'. 'Idelchik' is offset lower\n    by about 0.03 and settles to 0.50. The 'Harris' method is a straight\n    interpolation from experimental results with smoothing, and it is the \n    lowest at all points. The 'Crane' [6]_ method returns 0.78 for all cases.\n    \n    The Rennels [1]_ formula is:\n\n    .. math::\n        K = 1.12 - 22\\frac{t}{d} + 216\\left(\\frac{t}{d}\\right)^2 +\n        80\\left(\\frac{t}{d}\\right)^3\n\n    .. figure:: fittings/sharp_edged_entrace_extended_mount.png\n       :scale: 30 %\n       :alt: sharp edged entrace, extended mount; after [1]_\n        \n    Parameters\n    ----------\n    Di : float\n        Inside diameter of pipe, [m]\n    t : float, optional\n        Thickness of pipe wall, used in all but 'Crane' method, [m]\n    l : float, optional\n        The distance the pipe extends into the reservoir; used only in the\n        'Idelchik' method, defaults to `Di`, [m]\n    method : str, optional\n        One of 'Rennels', 'Miller', 'Idelchik', 'Harris', 'Crane', [-]\n        \n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    This type of inlet is also known as a Borda's mouthpiece.\n    It is not of practical interest according to [1]_.\n    \n    The 'Idelchik' [3]_ data is recommended in [5]_; it also provides rounded\n    values for the 'Harris. method.\n    \n    .. plot:: plots/entrance_distance.py\n    \n    Examples\n    --------\n    >>> entrance_distance(Di=0.1, t=0.0005)\n    1.0154100000000001\n    >>> entrance_distance(Di=0.1, t=0.0005, method='Idelchik')\n    0.9249999999999999\n    >>> entrance_distance(Di=0.1, t=0.0005, l=.02, method='Idelchik')\n    0.8474999999999999\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    .. [3] Idel\u2019chik, I. E. Handbook of Hydraulic Resistance: Coefficients of \n       Local Resistance and of Friction (Spravochnik Po Gidravlicheskim \n       Soprotivleniyam, Koeffitsienty Mestnykh Soprotivlenii i Soprotivleniya\n       Treniya). National technical information Service, 1966.\n    .. [4] Harris, Charles William. The Influence of Pipe Thickness on \n       Re-Entrant Intake Losses. Vol. 48. University of Washington, 1928.\n    .. [5] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.: \n       Van Nostrand Reinhold Co., 1984.\n    .. [6] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if method is None:\n        method = 'Rennels'\n    if method == 'Rennels':\n        t_Di = t/Di\n        if t_Di > 0.05:\n            t_Di = 0.05\n        return 1.12 + t_Di*(t_Di*(80.0*t_Di + 216.0) - 22.0)\n    elif method == 'Miller':\n        t_Di = t/Di\n        if t_Di > 0.3:\n            t_Di = 0.3\n        return horner(entrance_distance_Miller_coeffs, 20.0/3.0*(t_Di - 0.15))\n    elif method == 'Idelchik':\n        if l is None:\n            l = Di\n        t_Di = min(t/Di, 1.0)\n        l_Di = min(l/Di, 10.0)\n        K = float(entrance_distance_Idelchik_obj(l_Di, t_Di))\n        if K < 0.0:\n            K = 0.0\n        return K\n    elif method == 'Harris':\n        ratio = min(t/Di, 0.289145) # max value for interpolation - extrapolation looks bad\n        K = float(entrance_distance_Harris_obj(ratio))\n        return K\n    elif method == 'Crane':\n        return 0.78\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(entrance_distance_methods))", "response": "r Returns the loss coefficient for a sharp entrance to a pipe at a given distance t and l."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef entrance_angled(angle, method='Idelchik'):\n    r'''Returns loss coefficient for a sharp, angled entrance to a pipe\n    flush with the wall of a reservoir. First published in [2]_, it has been\n    recommended in [3]_ as well as in [1]_.\n\n    .. math::\n        K = 0.57 + 0.30\\cos(\\theta) + 0.20\\cos(\\theta)^2\n\n    .. figure:: fittings/entrance_mounted_at_an_angle.png\n       :scale: 30 %\n       :alt: entrace mounted at an angle; after [1]_\n\n    Parameters\n    ----------\n    angle : float\n        Angle of inclination (90\u00b0 = straight, 0\u00b0 = parallel to pipe wall),\n        [degrees]\n    method : str, optional\n        The method to use; only 'Idelchik' is supported\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    Not reliable for angles under 20 degrees.\n    Loss coefficient is the same for an upward or downward angled inlet.\n\n    Examples\n    --------\n    >>> entrance_angled(30)\n    0.9798076211353315\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Idel\u2019chik, I. E. Handbook of Hydraulic Resistance: Coefficients of \n       Local Resistance and of Friction (Spravochnik Po Gidravlicheskim \n       Soprotivleniyam, Koeffitsienty Mestnykh Soprotivlenii i Soprotivleniya\n       Treniya). National technical information Service, 1966.\n    .. [3] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.: \n       Van Nostrand Reinhold Co., 1984.\n    '''\n    if method is None:\n         method = 'Idelchik'\n    if method == 'Idelchik':\n        cos_term = cos(radians(angle))\n        return 0.57 + cos_term*(0.2*cos_term + 0.3)\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(entrance_angled_methods))", "response": "r Returns an entrance that is at a given angle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef entrance_beveled(Di, l, angle, method='Rennels'):\n    r'''Returns loss coefficient for a beveled or chamfered entrance to a pipe\n    flush with the wall of a reservoir. This calculation has two methods\n    available.\n    \n    The 'Rennels' and 'Idelchik' methods have similar trends, but the 'Rennels'\n    formulation is centered around a straight loss coefficient of 0.57, so it\n    is normally at least 0.07 higher.\n    \n    The Rennels [1]_ formulas are:\n\n    .. math::\n        K = 0.0696\\left(1 - C_b\\frac{l}{d}\\right)\\lambda^2 + (\\lambda-1)^2\n\n    .. math::\n        \\lambda = 1 + 0.622\\left[1-1.5C_b\\left(\\frac{l}{d}\n        \\right)^{\\frac{1-(l/d)^{1/4}}{2}}\\right]\n\n    .. math::\n        C_b = \\left(1 - \\frac{\\theta}{90}\\right)\\left(\\frac{\\theta}{90}\n        \\right)^{\\frac{1}{1+l/d}}\n\n    .. figure:: fittings/flush_mounted_beveled_entrance.png\n       :scale: 30 %\n       :alt: Beveled entrace mounted straight; after [1]_\n\n    Parameters\n    ----------\n    Di : float\n        Inside diameter of pipe, [m]\n    l : float\n        Length of bevel measured parallel to the pipe length, [m]\n    angle : float\n        Angle of bevel with respect to the pipe length, [degrees]\n    method : str, optional\n        One of 'Rennels', or 'Idelchik', [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    A cheap way of getting a lower pressure drop.\n    Little credible data is available.\n    \n    The table of data in [2]_ uses the angle for both bevels, so it runs from 0\n    to 180 degrees; this function follows the convention in [1]_ which uses\n    only one angle, with the angle varying from 0 to 90 degrees.\n\n    .. plot:: plots/entrance_beveled.py\n\n    Examples\n    --------\n    >>> entrance_beveled(Di=0.1, l=0.003, angle=45)\n    0.45086864221916984\n    >>> entrance_beveled(Di=0.1, l=0.003, angle=45, method='Idelchik')\n    0.3995000000000001\n    \n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Idel\u2019chik, I. E. Handbook of Hydraulic Resistance: Coefficients of \n       Local Resistance and of Friction (Spravochnik Po Gidravlicheskim \n       Soprotivleniyam, Koeffitsienty Mestnykh Soprotivlenii i Soprotivleniya\n       Treniya). National technical information Service, 1966.\n    '''\n    if method is None:\n        method = 'Rennels'\n    if method == 'Rennels':\n        Cb = (1-angle/90.)*(angle/90.)**(1./(1 + l/Di ))\n        lbd = 1 + 0.622*(1 - 1.5*Cb*(l/Di)**((1 - (l/Di)**0.25)/2.))\n        return 0.0696*(1 - Cb*l/Di)*lbd**2 + (lbd - 1.)**2\n    elif method == 'Idelchik':\n        return float(entrance_beveled_Idelchik_obj(angle*2.0, l/Di))\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(entrance_beveled_methods))", "response": "r Returns the loss coefficient for a beveled entrance to a pipe."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Miller_bend_unimpeded_correction(Kb, Di, L_unimpeded):\n    '''Limitations as follows:\n    * Ratio not over 30\n    * If ratio under 0.01, tabulated values are used near the limits \n      (discontinuity in graph anyway)\n    * If ratio for a tried curve larger than max value, max value is used\n      instead of calculating it\n    * Kb limited to between 0.1 and 1.0\n    * When between two Kb curves, interpolate linearly after evaluating both\n      splines appropriately\n    '''\n    if Kb < 0.1:\n        Kb_C_o = 0.1\n    elif Kb > 1:\n        Kb_C_o = 1.0\n    else:\n        Kb_C_o = Kb\n\n    L_unimpeded_ratio = L_unimpeded/Di\n    if L_unimpeded_ratio > 30:\n        L_unimpeded_ratio = 30.0\n        \n    for i in range(len(bend_rounded_Miller_C_o_Kbs)):        \n        Kb_low, Kb_high = bend_rounded_Miller_C_o_Kbs[i], bend_rounded_Miller_C_o_Kbs[i+1]\n        if Kb_low <= Kb_C_o <= Kb_high:\n            if L_unimpeded_ratio >= bend_rounded_Miller_C_o_limits[i]:\n                Co_low = 1.0\n            elif L_unimpeded_ratio <= 0.01:\n                Co_low = bend_rounded_Miller_C_o_limit_0_01[i]\n            else:\n                Co_low = splev(L_unimpeded_ratio, tck_bend_rounded_Miller_C_os[i])\n            if L_unimpeded_ratio >= bend_rounded_Miller_C_o_limits[i+1]:\n                Co_high = 1.0\n            elif L_unimpeded_ratio <= 0.01:\n                Co_high = bend_rounded_Miller_C_o_limit_0_01[i+1]\n            else:\n                Co_high = splev(L_unimpeded_ratio, tck_bend_rounded_Miller_C_os[i+1])\n            C_o = Co_low + (Kb_C_o - Kb_low)*(Co_high - Co_low)/(Kb_high - Kb_low)\n            return C_o", "response": "Miller - Bend unimpeded correction for a single site."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bend_rounded_Crane(Di, angle, rc=None, bend_diameters=None):\n    r'''Calculates the loss coefficient for any rounded bend in a pipe\n    according to the Crane TP 410M [1]_ method. This method effectively uses\n    an interpolation from tabulated values in [1]_ for friction factor\n    multipliers vs. curvature radius.\n    \n    .. figure:: fittings/bend_rounded.png\n       :scale: 30 %\n       :alt: rounded bend; after [1]_\n\n    Parameters\n    ----------\n    Di : float\n        Inside diameter of pipe, [m]\n    angle : float\n        Angle of bend, [degrees]\n    rc : float, optional\n        Radius of curvature of the entrance, optional [m]\n    bend_diameters : float, optional (used if rc not provided)\n        Number of diameters of pipe making up the bend radius [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    The Crane method does match the trend of increased pressure drop as\n    roughness increases.\n\n    The points in [1]_ are extrapolated to other angles via a well-fitting\n    Chebyshev approximation, whose accuracy can be seen in the below plot.\n\n    .. plot:: plots/bend_rounded_Crane.py\n    \n    Examples\n    --------\n    >>> bend_rounded_Crane(Di=.4020, rc=.4*5, angle=30)\n    0.09321910015613409\n\n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if not rc:\n        if bend_diameters is None:\n            bend_diameters = 5.0\n        rc = Di*bend_diameters\n    fd = ft_Crane(Di)\n    \n    radius_ratio = rc/Di\n    if radius_ratio < 1.0:\n        radius_ratio = 1.0\n    elif radius_ratio > 20.0:\n        radius_ratio = 20.0\n    factor = horner(bend_rounded_Crane_coeffs, 0.105263157894736836*(radius_ratio - 10.5))\n    K = fd*factor\n    K = (angle/90.0 - 1.0)*(0.25*pi*fd*radius_ratio + 0.5*K) + K\n    return K", "response": "r Calculates the loss coefficient for any rounded bend in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bend_rounded(Di, angle, fd=None, rc=None, bend_diameters=5.0,\n                 Re=None, roughness=0.0, L_unimpeded=None, method='Rennels'):\n    r'''Returns loss coefficient for rounded bend in a pipe of diameter `Di`,\n    `angle`, with a specified either radius of curvature `rc` or curvature \n    defined by `bend_diameters`, Reynolds number `Re` and optionally pipe\n    roughness, unimpeded length downstrean, and with the specified method.\n    This calculation has five methods available.\n    \n    It is hard to describe one method as more conservative than another as\n    depending on the conditions, the relative results change significantly.\n    \n    The 'Miller' method is the most complicated and slowest method; the 'Ito'\n    method comprehensive as well and a source of original data, and the primary\n    basis for the 'Rennels' method. The 'Swamee' method is very simple and\n    generally does not match the other methods. The 'Crane' method may match \n    or not match other methods depending on the inputs.\n    \n    The Rennels [1]_ formula is:\n    \n    .. math::\n        K = f\\alpha\\frac{r}{d} + (0.10 + 2.4f)\\sin(\\alpha/2)\n        + \\frac{6.6f(\\sqrt{\\sin(\\alpha/2)}+\\sin(\\alpha/2))}\n        {(r/d)^{\\frac{4\\alpha}{\\pi}}}\n\n    The Swamee [5]_ formula is:\n        \n    .. math::\n        K = \\left[0.0733 + 0.923 \\left(\\frac{d}{rc}\\right)^{3.5} \\right]\n        \\theta^{0.5}\n        \n    .. figure:: fittings/bend_rounded.png\n       :scale: 30 %\n       :alt: rounded bend; after [1]_\n\n    Parameters\n    ----------\n    Di : float\n        Inside diameter of pipe, [m]\n    angle : float\n        Angle of bend, [degrees]\n    fd : float, optional\n        Darcy friction factor; used only in Rennels method; calculated if not\n        provided from Reynolds number, diameter, and roughness [-]\n    rc : float, optional\n        Radius of curvature of the entrance, optional [m]\n    bend_diameters : float, optional (used if rc not provided)\n        Number of diameters of pipe making up the bend radius [-]\n    Re : float, optional\n        Reynolds number of the pipe (used in Miller, Ito methods primarily, and\n        Rennels method if no friction factor given), [m]\n    roughness : float, optional\n        Roughness of bend wall (used in Miller, Ito methods primarily, and\n        Rennels method if no friction factor given), [m]   \n    L_unimpeded : float, optional\n        The length of unimpeded pipe without any fittings, instrumentation,\n        or flow disturbances downstream (assumed 20 diameters if not \n        specified); used only in Miller method, [m]\n    method : str, optional\n        One of 'Rennels', 'Miller', 'Crane', 'Ito', or 'Swamee', [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    When inputting bend diameters, note that manufacturers often specify\n    this as a multiplier of nominal diameter, which is different than actual\n    diameter. Those require that rc be specified.\n    \n    In the 'Rennels' method, `rc` is limited to 0.5 or above; which represents \n    a sharp, square, inner edge - and an outer bend radius of 1.0. Losses are \n    at a minimum when this value is large. Its first term represents surface \n    friction loss; the second, secondary flows; and the third, flow separation.\n    It encompasses the entire range of elbow and pipe bend configurations.\n    It was developed for bend angles between 0 and 180 degrees; and r/D\n    ratios above 0.5. Only smooth pipe data was used in its development.\n    Note the loss coefficient includes the surface friction of the pipe as if\n    it was straight.\n   \n    Examples\n    --------\n    >>> bend_rounded(Di=4.020, rc=4.0*5, angle=30, Re=1E5)\n    0.11519070808085191\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    .. [3] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    .. [4] Swamee, Prabhata K., and Ashok K. Sharma. Design of Water Supply \n       Pipe Networks. John Wiley & Sons, 2008.\n    .. [5] Ito\u0304, H.\"Pressure Losses in Smooth Pipe Bends.\" Journal of Fluids \n       Engineering 82, no. 1 (March 1, 1960): 131-40. doi:10.1115/1.3662501\n    .. [6] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.: \n       Van Nostrand Reinhold Co., 1984.\n    '''\n    if method is None:\n        method = 'Rennels'\n    if rc is None:\n        rc = Di*bend_diameters\n    if method == 'Rennels':\n        angle = radians(angle)\n        if fd is None:\n            if Re is None:\n                raise ValueError(\"The `Rennels` method requires either a \"\n                                 \"specified friction factor or `Re`\")\n            fd = Colebrook(Re=Re, eD=roughness/Di, tol=-1)\n        sin_term = sin(0.5*angle)\n        return (fd*angle*rc/Di + (0.10 + 2.4*fd)*sin_term\n        + 6.6*fd*(sin_term**0.5 + sin_term)/(rc/Di)**(4.*angle/pi))\n    elif method == 'Miller':\n        if Re is None:\n            raise ValueError('Miller method requires Reynolds number')\n        return bend_rounded_Miller(Di=Di, angle=angle, Re=Re, rc=rc, \n                                   bend_diameters=bend_diameters, \n                                   roughness=roughness, \n                                   L_unimpeded=L_unimpeded)\n    elif method == 'Crane':\n        return bend_rounded_Crane(Di=Di, angle=angle, rc=rc, \n                                  bend_diameters=bend_diameters)\n    elif method == 'Ito':\n        if Re is None:\n            raise ValueError(\"The `Iso` method requires`Re`\")\n        return bend_rounded_Ito(Di=Di, angle=angle, Re=Re, rc=rc, bend_diameters=bend_diameters, \n                     roughness=roughness)\n    elif method == 'Swamee':\n        return (0.0733 + 0.923*(Di/rc)**3.5)*radians(angle)**0.5\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(bend_rounded_methods))", "response": "r Returns a rounded bend in a pipe of diameter Di angle with a specified radius of curvature rc or Reynolds number Re."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bend_miter_Miller(Di, angle, Re, roughness=0.0, L_unimpeded=None):\n    r'''Calculates the loss coefficient for a single miter bend according to \n    Miller [1]_. This is a sophisticated model which uses corrections for\n    pipe roughness, the length of the pipe downstream before another \n    interruption, and a correction for Reynolds number. It interpolates several\n    times using several corrections graphs in [1]_.\n    \n    Parameters\n    ----------\n    Di : float\n        Inside diameter of pipe, [m]\n    angle : float\n        Angle of miter bend, [degrees]\n    Re : float\n        Reynolds number of the pipe (no specification if inlet or outlet\n        properties should be used), [m]\n    roughness : float, optional\n        Roughness of bend wall, [m]   \n    L_unimpeded : float, optional\n        The length of unimpeded pipe without any fittings, instrumentation,\n        or flow disturbances downstream (assumed 20 diameters if not \n        specified), [m]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----    \n    Note the loss coefficient includes the surface friction of the pipe as if\n    it was straight.\n   \n    Examples\n    --------\n    >>> bend_miter_Miller(Di=.6, angle=90, Re=2e6, roughness=2e-5, \n    ... L_unimpeded=30*.6)\n    1.1921574594947668\n    \n    References\n    ----------\n    .. [1] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    '''\n    if L_unimpeded is None:\n        L_unimpeded = 20.0*Di\n    if angle > 120:\n        angle = 120.0\n    \n    Kb = horner(bend_miter_Miller_coeffs, 1.0/60.0*(angle-60.0))\n    \n    C_o =  Miller_bend_unimpeded_correction(Kb=Kb, Di=Di, L_unimpeded=L_unimpeded)\n    C_roughness = Miller_bend_roughness_correction(Re=Re, Di=Di, \n                                                   roughness=roughness)\n    Re_C_Re = min(max(Re, 1E4), 1E8)\n    C_Re_1 = bend_rounded_Miller_C_Re(Re_C_Re, 1.0) if Re_C_Re < 207956.58904584477 else 1.0\n    C_Re = Kb/(Kb - 0.2*C_Re_1 + 0.2)\n    if C_Re > 2.2 or C_Re < 0:\n        C_Re = 2.2\n    return Kb*C_Re*C_roughness*C_o", "response": "r Calculates the loss coefficient for a single miter bend."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bend_miter(angle, Di=None, Re=None, roughness=0.0, L_unimpeded=None,\n               method='Rennels'):\n    r'''Returns loss coefficient for any single-joint miter bend in a pipe\n    of angle `angle`, diameter `Di`, Reynolds number `Re`, roughness\n    `roughness` unimpeded downstream length `L_unimpeded`, and using the \n    specified method. This calculation has four methods available.\n    The 'Rennels' method is based on a formula and extends to angles up to \n    150 degrees. The 'Crane' method extends only to 90 degrees; the 'Miller'\n    and 'Blevins' methods extend to 120 degrees.\n    \n    The Rennels [1]_ formula is:\n        \n    .. math::\n        K = 0.42\\sin(\\alpha/2) + 2.56\\sin^3(\\alpha/2)\n\n    The 'Crane', 'Miller', and 'Blevins' methods are all in part graph or \n    tabular based and do not have straightforward formulas.\n\n    .. figure:: fittings/bend_miter.png\n       :scale: 25 %\n       :alt: Miter bend, one joint only; after [1]_\n\n    Parameters\n    ----------\n    angle : float\n        Angle of bend, [degrees]\n    Di : float, optional\n        Inside diameter of pipe, [m]\n    Re : float, optional\n        Reynolds number of the pipe (no specification if inlet or outlet\n        properties should be used), [m]\n    roughness : float, optional\n        Roughness of bend wall, [m]   \n    L_unimpeded : float, optional\n        The length of unimpeded pipe without any fittings, instrumentation,\n        or flow disturbances downstream (assumed 20 diameters if not \n        specified), [m]\n    method : str, optional\n        The specified method to use; one of 'Rennels', 'Miller', 'Crane', \n        or 'Blevins', [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to either upstream or downstream \n        diameter, [-]\n\n    Notes\n    -----\n    This method is designed only for single-jointed miter bends. It is common\n    for miter bends to have two or three sections, to further reduce the loss\n    coefficient. Some methods exist in [2]_ for taking this into account. \n    Because the additional configurations reduce the pressure loss, it is\n    \"common practice\" to simply ignore their effect and accept the slight\n    overdesign.\n    \n    The following figure illustrates the different methods.\n\n    .. plot:: plots/bend_miter.py\n\n    Examples\n    --------\n    >>> bend_miter(150)\n    2.7128147734758103\n    >>> bend_miter(Di=.6, angle=45, Re=1e6, roughness=1e-5, L_unimpeded=20, \n    ... method='Miller')\n    0.2944060416245167\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    .. [3] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    .. [4] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.: \n       Van Nostrand Reinhold Co., 1984.\n    '''\n    if method is None:\n        method = 'Rennels'\n    if method == 'Rennels':\n        angle_rad = radians(angle)\n        sin_half_angle = sin(angle_rad*0.5)\n        return 0.42*sin_half_angle + 2.56*sin_half_angle*sin_half_angle*sin_half_angle\n    elif method == 'Crane':\n        factor = interp(angle, bend_miter_Crane_angles, bend_miter_Crane_fds)\n        return ft_Crane(Di)*factor\n    elif method == 'Miller':\n        return bend_miter_Miller(Di=Di, angle=angle, Re=Re, roughness=roughness, L_unimpeded=L_unimpeded)\n    elif method == 'Blevins':\n        # data from Idelchik, Miller, an earlier ASME publication\n        # For 90-120 degrees, a polynomial/spline would be better than a linear fit\n        K_base = interp(angle, bend_miter_Blevins_angles, bend_miter_Blevins_Ks)\n        return K_base*(2E5/Re)**0.2\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(bend_miter_methods))", "response": "r Returns loss coefficient for any single - joint miter bend in a pipe with the given angle Di Re roughness L_unimpeded."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contraction_sharp(Di1, Di2):\n    r'''Returns loss coefficient for any sharp edged pipe contraction\n    as shown in [1]_.\n\n    .. math::\n        K = 0.0696(1-\\beta^5)\\lambda^2 + (\\lambda-1)^2\n\n    .. math::\n        \\lambda = 1 + 0.622(1-0.215\\beta^2 -  0.785\\beta^5) \n\n    .. math::\n        \\beta = d_2/d_1\n\n    .. figure:: fittings/contraction_sharp.png\n       :scale: 40 %\n       :alt: Sharp contraction; after [1]_\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside diameter of original pipe, [m]\n    Di2 : float\n        Inside diameter of following pipe, [m]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient in terms of the following pipe [-]\n\n    Notes\n    -----\n    A value of 0.506 or simply 0.5 is often used.\n\n    Examples\n    --------\n    >>> contraction_sharp(Di1=1, Di2=0.4)\n    0.5301269161591805\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    '''\n    beta = Di2/Di1\n    lbd = 1 + 0.622*(1-0.215*beta**2 - 0.785*beta**5)\n    return 0.0696*(1-beta**5)*lbd**2 + (lbd-1)**2", "response": "r Returns loss coefficient for any sharp edged pipe contraction."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contraction_round(Di1, Di2, rc, method='Rennels'):\n    r'''Returns loss coefficient for any any round edged pipe contraction.\n    This calculation has three methods available. The 'Miller' [2]_ method is a \n    bivariate spline digitization of a graph; the 'Idelchik' [3]_ method is an\n    interpolation using a formula and a table of values.\n\n    The most conservative formulation is that of Rennels; with fairly similar.\n    The 'Idelchik' method is more conservative and less complex; it offers a\n    straight-line curve where the others curves are curved.\n    \n    The Rennels [1]_ formulas are:\n        \n    .. math::\n        K = 0.0696\\left(1 - 0.569\\frac{r}{d_2}\\right)\\left(1-\\sqrt{\\frac{r}\n        {d_2}}\\beta\\right)(1-\\beta^5)\\lambda^2 + (\\lambda-1)^2\n\n    .. math::\n        \\lambda = 1 + 0.622\\left(1 - 0.30\\sqrt{\\frac{r}{d_2}}\n        - 0.70\\frac{r}{d_2}\\right)^4 (1-0.215\\beta^2-0.785\\beta^5)\n\n    .. math::\n        \\beta = d_2/d_1\n\n    .. figure:: fittings/contraction_round.png\n       :scale: 30 %\n       :alt: Cirucular round contraction; after [1]_\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside diameter of original pipe, [m]\n    Di2 : float\n        Inside diameter of following pipe, [m]\n    rc : float\n        Radius of curvature of the contraction, [m]\n    method : str\n        The calculation method to use; one of 'Rennels', 'Miller', or \n        'Idelchik', [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient in terms of the following pipe [-]\n\n    Notes\n    -----\n    Rounding radius larger than 0.14Di2 prevents flow separation from the wall.\n    Further increase in rounding radius continues to reduce loss coefficient.\n    \n    .. plot:: plots/contraction_round.py\n\n    Examples\n    --------\n    >>> contraction_round(Di1=1, Di2=0.4, rc=0.04)\n    0.1783332490866574\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    .. [3] Idel\u2019chik, I. E. Handbook of Hydraulic Resistance: Coefficients of \n       Local Resistance and of Friction (Spravochnik Po Gidravlicheskim \n       Soprotivleniyam, Koeffitsienty Mestnykh Soprotivlenii i Soprotivleniya\n       Treniya). National technical information Service, 1966.\n    '''\n    beta = Di2/Di1\n    if method is None:\n        method = 'Rennels'\n    if method == 'Rennels':\n        lbd = 1.0 + 0.622*(1.0 - 0.30*(rc/Di2)**0.5 - 0.70*rc/Di2)**4*(1.0 - 0.215*beta**2 - 0.785*beta**5)\n        return 0.0696*(1.0 - 0.569*rc/Di2)*(1.0 - (rc/Di2)**0.5*beta)*(1.0 - beta**5)*lbd*lbd + (lbd - 1.0)**2\n    elif method == 'Miller':\n        return contraction_round_Miller(Di1=Di1, Di2=Di2, rc=rc)\n    elif method == 'Idelchik':\n        # Di2, ratio defined in terms over diameter\n        K0 = interp(rc/Di2, contraction_round_Idelchik_ratios, \n                    contraction_round_Idelchik_factors)\n        return K0*(1.0 - beta*beta)\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(contraction_round_methods))", "response": "r Calculates the loss coefficient for any round edged pipe contraction."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contraction_conical_Crane(Di1, Di2, l=None, angle=None):\n    r'''Returns loss coefficient for a conical pipe contraction\n    as shown in Crane TP 410M [1]_ between 0 and 180 degrees.\n\n    If :math:`\\theta < 45^{\\circ}`:\n        \n    .. math::\n        K_2 = {0.8 \\sin \\frac{\\theta}{2}(1 - \\beta^2)}\n\n    otherwise:\n        \n    .. math::\n        K_2 = {0.5\\sqrt{\\sin \\frac{\\theta}{2}} (1 - \\beta^2)}\n        \n    .. math::\n        \\beta = d_2/d_1\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside pipe diameter of the larger, upstream, pipe, [m]    \n    Di2 : float\n        Inside pipe diameter of the smaller, downstream, pipe, [m]    \n    l : float\n        Length of the contraction, optional [m]\n    angle : float\n        Angle of contraction, optional [degrees]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient in terms of the following (smaller) pipe [-]\n\n    Notes\n    -----\n    Cheap and has substantial impact on pressure drop. Note that the \n    nomenclature in [1]_ is somewhat different - the smaller pipe is called 1,\n    and the larger pipe is called 2; and so the beta ratio is reversed, and the\n    fourth power of beta used in their equation is not necessary.\n\n    Examples\n    --------\n    >>> contraction_conical_Crane(Di1=0.0779, Di2=0.0525, l=0)\n    0.2729017979998056\n\n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if l is None and angle is None:\n        raise Exception('One of `l` or `angle` must be specified')\n    beta = Di2/Di1\n    beta2 = beta*beta\n    if angle is not None:\n        angle = radians(angle)\n        #l = (Di1 - Di2)/(2.0*tan(0.5*angle)) # L is not needed in this calculation\n    elif l is not None:\n        try:\n            angle = 2.0*atan((Di1-Di2)/(2.0*l))\n        except ZeroDivisionError:\n            angle = pi\n    if angle < 0.25*pi:\n        # Formula 1\n        K2 = 0.8*sin(0.5*angle)*(1.0 - beta2)\n    else:\n        # Formula 2\n        K2 = 0.5*(sin(0.5*angle)**0.5*(1.0 - beta2))\n    return K2", "response": "r Returns a new contraction conical pipe for the given diameter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contraction_conical(Di1, Di2, fd=None, l=None, angle=None,\n                        Re=None, roughness=0.0, method='Rennels'):\n    r'''Returns the loss coefficient for any conical pipe contraction.\n    This calculation has five methods available. The 'Idelchik' [2]_ and \n    'Blevins' [3]_ methods use interpolation among tables of values; 'Miller' \n    uses a 2d spline representation of a graph; and the \n    'Rennels' [1]_, 'Crane' [4]_, and 'Swamee' [5]_ methods use formulas for\n    their calculations.\n    \n    The 'Rennels' [1]_ formulas are:\n\n    .. math::\n        K_2 = K_{fr,2} + K_{conv,2}\n        \n    .. math::\n        K_{fr,2} = \\frac{f_d}{1 - \\beta^4}{8\\sin(\\theta/2)}\n        \n    .. math::\n        K_{conv,2} = 0.0696[1+C_B(\\sin(\\alpha/2)-1)](1-\\beta^5)\\lambda^2 + (\\lambda-1)^2\n\n    .. math::\n        \\lambda = 1 + 0.622(\\alpha/180)^{0.8}(1-0.215\\beta^2-0.785\\beta^5)\n\n    .. math::\n        \\beta = d_2/d_1\n    \n    The 'Swamee' [5]_ formula is:\n    \n    .. math::\n        K = 0.315 \\theta^{1/3}\n\n    .. figure:: fittings/contraction_conical.png\n       :scale: 30 %\n       :alt: contraction conical; after [1]_\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside pipe diameter of the larger, upstream, pipe, [m]    \n    Di2 : float\n        Inside pipe diameter of the smaller, downstream, pipe, [m]    \n    fd : float, optional\n        Darcy friction factor; used only in the Rennels method and will be \n        calculated if not given, [-]\n    l : float, optional\n        Length of the contraction, optional [m]\n    angle : float, optional\n        Angle of contraction (180 = sharp, 0 = infinitely long contraction),\n        optional [degrees]\n    Re : float, optional\n        Reynolds number of the pipe (used in Rennels method only if no friction\n        factor given), [m]\n    roughness : float, optional\n        Roughness of bend wall (used in Rennel method if no friction factor \n        given), [m]   \n    method : str, optional\n        The method to use for the calculation; one of 'Rennels', 'Idelchik',\n        'Crane', 'Swamee' or 'Blevins', [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient in terms of the following pipe [-]\n\n    Notes\n    -----\n    Cheap and has substantial impact on pressure drop.\n    \n    The 'Idelchik' method includes two tabular interpolations; its friction\n    term is limited to angles between 2 and 20 degrees and area ratios 0.05 to\n    0.6, while its main term is limited to length over diameter ratios 0.025 to\n    0.6. This seems to give it high results for angles < 25 degrees.\n    \n    The 'Blevins' method is based on Idelchik data; it should not be used, \n    because its data jumps around and its data is limited to area ratios .1 to\n    0.83, and length over diameter ratios 0 to 0.6. The 'Miller' method jumps\n    around as well. Unlike most of Miller's method, there is no correction for \n    Reynolds number.\n\n    \n    There is quite a bit of variance in the predictions of the methods, as \n    demonstrated by the following figure.\n\n    .. plot:: plots/contraction_conical.py\n\n    Examples\n    --------\n    >>> contraction_conical(Di1=0.1, Di2=0.04, l=0.04, Re=1E6)\n    0.15639885880609544\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    .. [2] Idel\u2019chik, I. E. Handbook of Hydraulic Resistance: Coefficients of \n       Local Resistance and of Friction (Spravochnik Po Gidravlicheskim \n       Soprotivleniyam, Koeffitsienty Mestnykh Soprotivlenii i Soprotivleniya\n       Treniya). National technical information Service, 1966.\n    .. [3] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.: \n       Van Nostrand Reinhold Co., 1984.\n    .. [4] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    .. [5] Swamee, Prabhata K., and Ashok K. Sharma. Design of Water Supply \n       Pipe Networks. John Wiley & Sons, 2008.\n    .. [6] Miller, Donald S. Internal Flow Systems: Design and Performance\n       Prediction. Gulf Publishing Company, 1990.\n    '''\n    beta = Di2/Di1\n    if angle is not None:\n        angle_rad = radians(angle)\n        l = (Di1 - Di2)/(2.0*tan(0.5*angle_rad)) \n    elif l is not None:\n        try:\n            angle_rad = 2.0*atan((Di1-Di2)/(2.0*l))\n            angle = degrees(angle_rad)\n        except ZeroDivisionError:\n            angle_rad = pi\n            angle = 180.0\n    else:\n        raise Exception('Either l or angle is required')\n    if method is None:\n        method == 'Rennels'\n\n    if method == 'Rennels':\n        if fd is None:\n            if Re is None:\n                raise ValueError(\"The `Rennels` method requires either a \"\n                                 \"specified friction factor or `Re`\")\n            fd = Colebrook(Re=Re, eD=roughness/Di2, tol=-1)\n            \n        beta2 = beta*beta\n        beta4 = beta2*beta2\n        beta5 = beta4*beta\n        lbd = 1.0 + 0.622*(angle_rad/pi)**0.8*(1.0 - 0.215*beta2 - 0.785*beta5)\n        sin_half_angle = sin(0.5*angle_rad)\n        K_fr2 = fd*(1.0 - beta4)/(8.0*sin_half_angle)\n        K_conv2 = 0.0696*sin_half_angle*(1.0 - beta5)*lbd*lbd + (lbd - 1.0)**2\n        return K_fr2 + K_conv2\n    elif method == 'Crane':\n        return contraction_conical_Crane(Di1=Di1, Di2=Di2, l=l, angle=angle)\n    elif method == 'Swamee':\n        return 0.315*angle_rad**(1.0/3.0)\n    elif method == 'Idelchik':\n        # Diagram 3-6; already digitized for beveled entrance\n        K0 = float(entrance_beveled_Idelchik_obj(angle, l/Di2))\n        \n        # Angles 0 to 20, ratios 0.05 to 0.06\n        if angle > 20.0:\n            angle_fric = 20.0\n        elif angle < 2.0:\n            angle_fric = 2.0\n        else:\n            angle_fric = angle\n            \n        A_ratio = A_ratio_fric = Di2*Di2/(Di1*Di1)\n        if A_ratio_fric < 0.05:\n            A_ratio_fric = 0.05\n        elif A_ratio_fric > 0.6:\n            A_ratio_fric = 0.6\n            \n        K_fr = float(contraction_conical_frction_Idelchik_obj(angle_fric, A_ratio_fric))\n        return K0*(1.0 - A_ratio) + K_fr\n    elif method == 'Blevins':\n        A_ratio = Di1*Di1/(Di2*Di2)\n        if A_ratio < 1.2:\n            A_ratio = 1.2\n        elif A_ratio > 10.0:\n            A_ratio = 10.0\n        \n        l_ratio = l/Di2\n        if l_ratio > 0.6:\n            l_ratio= 0.6\n        return float(contraction_conical_Blevins_obj(l_ratio, A_ratio))\n    elif method == 'Miller':\n        A_ratio = Di1*Di1/(Di2*Di2)\n        if A_ratio > 4.0:\n            A_ratio = 4.0\n        elif A_ratio < 1.1:\n            A_ratio = 1.1\n        l_ratio = l/(Di2*0.5)\n        if l_ratio < 0.1:\n            l_ratio = 0.1\n        elif l_ratio > 10.0:\n            l_ratio = 10.0\n        # Turning on ofr off the limits - little difference in plot\n        return contraction_conical_Miller_obj(l_ratio, A_ratio)\n    else:\n        raise ValueError('Specified method not recognized; methods are %s'\n                         %(contraction_conical_methods))", "response": "r Returns the loss coefficient for any conical pipe contraction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contraction_beveled(Di1, Di2, l=None, angle=None):\n    r'''Returns loss coefficient for any sharp beveled pipe contraction\n    as shown in [1]_.\n\n    .. math::\n        K = 0.0696[1+C_B(\\sin(\\alpha/2)-1)](1-\\beta^5)\\lambda^2 + (\\lambda-1)^2\n\n    .. math::\n        \\lambda = 1 + 0.622\\left[1+C_B\\left(\\left(\\frac{\\alpha}{180}\n        \\right)^{0.8}-1\\right)\\right](1-0.215\\beta^2-0.785\\beta^5)\n\n    .. math::\n        C_B = \\frac{l}{d_2}\\frac{2\\beta\\tan(\\alpha/2)}{1-\\beta}\n\n    .. math::\n        \\beta = d_2/d_1\n\n    .. figure:: fittings/contraction_beveled.png\n       :scale: 30 %\n       :alt: contraction beveled; after [1]_\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside diameter of original pipe, [m]\n    Di2 : float\n        Inside diameter of following pipe, [m]\n    l : float\n        Length of the bevel along the pipe axis ,[m]\n    angle : float\n        Angle of bevel, [degrees]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient in terms of the following pipe [-]\n\n    Notes\n    -----\n\n    Examples\n    --------\n    >>> contraction_beveled(Di1=0.5, Di2=0.1, l=.7*.1, angle=120)\n    0.40946469413070485\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    '''\n    angle = radians(angle)\n    beta = Di2/Di1\n    CB = l/Di2*2.0*beta*tan(0.5*angle)/(1.0 - beta)\n    beta2 = beta*beta\n    beta5 = beta2*beta2*beta\n    lbd = 1.0 + 0.622*(1.0 + CB*((angle/pi)**0.8 - 1.0))*(1.0 - 0.215*beta2 - 0.785*beta5)\n    return 0.0696*(1.0 + CB*(sin(0.5*angle) - 1.0))*(1.0 - beta5)*lbd*lbd + (lbd-1.0)**2", "response": "r Return the loss coefficient for any sharp beveled pipe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef diffuser_conical_staged(Di1, Di2, DEs, ls, fd=None, method='Rennels'):\n    r'''Returns loss coefficient for any series of staged conical pipe expansions\n    as shown in [1]_. Five different formulas are used, depending on\n    the angle and the ratio of diameters. This function calls diffuser_conical.\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside diameter of original pipe (smaller), [m]\n    Di2 : float\n        Inside diameter of following pipe (larger), [m]\n    DEs : array\n        Diameters of intermediate sections, [m]\n    ls : array\n        Lengths of the various sections, [m]\n    fd : float\n        Darcy friction factor [-]\n    method : str\n        The method to use for the calculation; one of 'Rennels', 'Crane',\n        'Miller', 'Swamee', or 'Idelchik' [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    Only lengths of sections currently allowed. This could be changed\n    to understand angles also.\n\n    Formula doesn't make much sense, as observed by the example comparing\n    a series of conical sections. Use only for small numbers of segments of\n    highly differing angles.\n\n    Examples\n    --------\n    >>> diffuser_conical(Di1=1., Di2=10.,l=9, fd=0.01)\n    0.973137914861591\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    '''\n    K = 0\n    DEs.insert(0, Di1)\n    DEs.append(Di2)\n    for i in range(len(ls)):\n        K += diffuser_conical(Di1=float(DEs[i]), Di2=float(DEs[i+1]), l=float(ls[i]), fd=fd, method=method)\n    return K", "response": "r Returns loss coefficient for any series of staged conical pipe expansions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef diffuser_pipe_reducer(Di1, Di2, l, fd1, fd2=None):\n    r'''Returns loss coefficient for any pipe reducer pipe expansion\n    as shown in [1]. This is an approximate formula.\n\n    .. math::\n        K_f = f_1\\frac{0.20l}{d_1} + \\frac{f_1(1-\\beta)}{8\\sin(\\alpha/2)}\n        + f_2\\frac{0.20l}{d_2}\\beta^4\n\n    .. math::\n        \\alpha = 2\\tan^{-1}\\left(\\frac{d_1-d_2}{1.20l}\\right)\n\n    Parameters\n    ----------\n    Di1 : float\n        Inside diameter of original pipe (smaller), [m]\n    Di2 : float\n        Inside diameter of following pipe (larger), [m]\n    l : float\n        Length of the pipe reducer along the pipe axis, [m]\n    fd1 : float\n        Darcy friction factor at inlet diameter [-]\n    fd2 : float\n        Darcy friction factor at outlet diameter, optional [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    Industry lack of standardization prevents better formulas from being\n    developed. Add 15% if the reducer is eccentric.\n    Friction factor at outlet will be assumed the same as at inlet if not specified.\n\n    Doubt about the validity of this equation is raised.\n\n    Examples\n    --------\n    >>> diffuser_pipe_reducer(Di1=.5, Di2=.75, l=1.5, fd1=0.07)\n    0.06873244301714816\n\n    References\n    ----------\n    .. [1] Rennels, Donald C., and Hobart M. Hudson. Pipe Flow: A Practical\n       and Comprehensive Guide. 1st edition. Hoboken, N.J: Wiley, 2012.\n    '''\n    if fd2 is None:\n        fd2 = fd1\n    beta = Di1/Di2\n    angle = -2*atan((Di1-Di2)/1.20/l)\n    K = fd1*0.20*l/Di1 + fd1*(1-beta)/8./sin(angle/2) + fd2*0.20*l/Di2*beta**4\n    return K", "response": "r Returns loss coefficient for any pipe reducer pipe expansion\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Hooper2K(Di, Re, name=None, K1=None, Kinfty=None):\n    r'''Returns loss coefficient for any various fittings, depending\n    on the name input. Alternatively, the Hooper constants K1, Kinfty\n    may be provided and used instead. Source of data is [1]_.\n    Reviews of this model are favorable less favorable than the Darby method\n    but superior to the constant-K method.\n\n    .. math::\n        K = \\frac{K_1}{Re} + K_\\infty\\left(1 + \\frac{1\\text{ inch}}{D_{in}}\\right)\n\n    Note this model uses actual inside pipe diameter in inches.\n\n    Parameters\n    ----------\n    Di : float\n        Actual inside diameter of the pipe, [in]\n    Re : float\n        Reynolds number, [-]\n    name : str, optional\n        String from Hooper dict representing a fitting\n    K1 : float, optional\n        K1 parameter of Hooper model, optional [-]\n    Kinfty : float, optional\n        Kinfty parameter of Hooper model, optional [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient [-]\n\n    Notes\n    -----\n    Also described in Ludwig's Applied Process Design.\n    Relatively uncommon to see it used.\n    No actual example found.\n\n    Examples\n    --------\n    >>> Hooper2K(Di=2., Re=10000., name='Valve, Globe, Standard')\n    6.15\n    >>> Hooper2K(Di=2., Re=10000., K1=900, Kinfty=4)\n    6.09\n\n    References\n    ----------\n    .. [1] Hooper, W. B., \"The 2-K Method Predicts Head Losses in Pipe\n       Fittings,\" Chem. Eng., p. 97, Aug. 24 (1981).\n    .. [2] Hooper, William B. \"Calculate Head Loss Caused by Change in Pipe\n       Size.\" Chemical Engineering 95, no. 16 (November 7, 1988): 89.\n    .. [3] Kayode Coker. Ludwig's Applied Process Design for Chemical and\n       Petrochemical Plants. 4E. Amsterdam\u202f; Boston: Gulf Professional\n       Publishing, 2007.\n    '''\n    if name:\n        if name in Hooper:\n            d = Hooper[name]\n            K1, Kinfty = d['K1'], d['Kinfty']\n        else:\n            raise Exception('Name of fitting not in list')\n    elif K1 and Kinfty:\n        pass\n    else:\n        raise Exception('Name of fitting or constants are required')\n    return K1/Re + Kinfty*(1. + 1./Di)", "response": "r Returns loss coefficient for any various fittings depending on the name input."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef K_gate_valve_Crane(D1, D2, angle, fd=None):\n    r'''Returns loss coefficient for a gate valve of types wedge disc, double\n    disc, or plug type, as shown in [1]_.\n\n    If \u03b2 = 1 and \u03b8 = 0:\n        \n    .. math::\n        K = K_1 = K_2 = 8f_d\n        \n    If \u03b2 < 1 and \u03b8 <= 45\u00b0:\n        \n    .. math::\n        K_2 = \\frac{K + \\sin \\frac{\\theta}{2} \\left[0.8(1-\\beta^2) \n        + 2.6(1-\\beta^2)^2\\right]}{\\beta^4}\n            \n    If \u03b2 < 1 and \u03b8 > 45\u00b0:\n        \n    .. math::\n        K_2 = \\frac{K + 0.5\\sqrt{\\sin\\frac{\\theta}{2}}(1-\\beta^2) \n        + (1-\\beta^2)^2}{\\beta^4}\n        \n    Parameters\n    ----------\n    D1 : float\n        Diameter of the valve seat bore (must be smaller or equal to `D2`), [m]\n    D2 : float\n        Diameter of the pipe attached to the valve, [m]\n    angle : float\n        Angle formed by the reducer in the valve, [degrees]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!\n        [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions [2]_.\n    \n    Examples\n    --------\n    Example 7-4 in [1]_; a 150 by 100 mm class 600 steel gate valve, conically\n    tapered ports, length 550 mm, back of sear ring ~150 mm. The valve is \n    connected to 146 mm schedule 80 pipe. The angle can be calculated to be \n    13 degrees. The valve is specified to be operating in turbulent conditions.\n    \n    >>> K_gate_valve_Crane(D1=.1, D2=.146, angle=13.115)\n    1.1466029421844073\n    \n    The calculated result is lower than their value of 1.22; the difference is\n    due to Crane's generous intermediate rounding. A later, Imperial edition of\n    Crane rounds differently - and comes up with K=1.06.\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    .. [2] Harvey Wilson. \"Pressure Drop in Pipe Fittings and Valves | \n       Equivalent Length and Resistance Coefficient.\" Katmar Software. Accessed\n       July 28, 2017. http://www.katmarsoftware.com/articles/pipe-fitting-pressure-drop.htm.\n    '''\n    angle = radians(angle)\n    beta = D1/D2\n    if fd is None:\n        fd = ft_Crane(D2)\n    K1 = 8.0*fd # This does not refer to upstream loss per se\n    if beta == 1 or angle == 0:\n        return K1 # upstream and down\n    else:\n        beta2 = beta*beta\n        one_m_beta2 = 1.0 - beta2\n        if angle <= 0.7853981633974483:\n            K = (K1 + sin(0.5*angle)*(0.8*one_m_beta2 + 2.6*one_m_beta2*one_m_beta2))/(beta2*beta2)\n        else:\n            K = (K1 + 0.5*(sin(0.5*angle))**0.5*one_m_beta2 + one_m_beta2*one_m_beta2)/(beta2*beta2)\n    return K", "response": "r Returns loss coefficient for a gate valve in a fully developed turbulent Seat bore."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef K_globe_valve_Crane(D1, D2, fd=None):\n    r'''Returns the loss coefficient for all types of globe valve, (reduced \n    seat or throttled) as shown in [1]_.\n\n    If \u03b2 = 1:\n        \n    .. math::\n        K = K_1 = K_2 = 340 f_d\n        \n    Otherwise:\n    \n    .. math::\n        K_2 = \\frac{K + \\left[0.5(1-\\beta^2) + (1-\\beta^2)^2\\right]}{\\beta^4}\n        \n    Parameters\n    ----------\n    D1 : float\n        Diameter of the valve seat bore (must be smaller or equal to `D2`), [m]\n    D2 : float\n        Diameter of the pipe attached to the valve, [m]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_globe_valve_Crane(.01, .02)\n    135.9200548324305\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    beta = D1/D2\n    if fd is None:\n        fd = ft_Crane(D2)\n    K1 = 340.0*fd \n    if beta == 1:\n        return K1 # upstream and down\n    else:\n        return (K1 + beta*(0.5*(1-beta)**2 + (1-beta**2)**2))/beta**4", "response": "r Returns the loss coefficient for all types of globe valve and throttled."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the loss coefficient for a globe stop check valve.", "response": "def K_globe_stop_check_valve_Crane(D1, D2, fd=None, style=0):\n    r'''Returns the loss coefficient for a globe stop check valve as shown in \n    [1]_.\n        \n    If \u03b2 = 1:\n        \n    .. math::\n        K = K_1 = K_2 = N\\cdot f_d\n        \n    Otherwise:\n    \n    .. math::\n        K_2 = \\frac{K + \\left[0.5(1-\\beta^2) + (1-\\beta^2)^2\\right]}{\\beta^4}\n        \n    Style 0 is the standard form; style 1 is angled, with a restrition to force\n    the flow up through the valve; style 2 is also angled but with a smaller\n    restriction forcing the flow up. N is 400, 300, and 55 for those cases\n    respectively.\n    \n    Parameters\n    ----------\n    D1 : float\n        Diameter of the valve seat bore (must be smaller or equal to `D2`), [m]\n    D2 : float\n        Diameter of the pipe attached to the valve, [m]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n    style : int, optional\n        One of 0, 1, or 2; refers to three different types of angle valves\n        as shown in [1]_ [-]\n        \n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_globe_stop_check_valve_Crane(.1, .02, style=1)\n    4.5235076518969795\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if fd is None:\n        fd = ft_Crane(D2)\n    try:\n        K = globe_stop_check_valve_Crane_coeffs[style]*fd\n    except KeyError:\n        raise KeyError('Accepted valve styles are 0, 1, and 2 only')\n    beta = D1/D2\n    if beta == 1:\n        return K\n    else:\n        return (K + beta*(0.5*(1 - beta**2) + (1 - beta**2)**2))/beta**4"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the loss coefficient for a ball valve.", "response": "def K_ball_valve_Crane(D1, D2, angle, fd=None):\n    r'''Returns the loss coefficient for a ball valve as shown in [1]_.\n\n    If \u03b2 = 1:\n        \n    .. math::\n        K = K_1 = K_2 = 3f_d\n        \n    If \u03b2 < 1 and \u03b8 <= 45\u00b0:\n        \n    .. math::\n        K_2 = \\frac{K + \\sin \\frac{\\theta}{2} \\left[0.8(1-\\beta^2) \n        + 2.6(1-\\beta^2)^2\\right]} {\\beta^4}\n            \n    If \u03b2 < 1 and \u03b8 > 45\u00b0:\n        \n    .. math::\n        K_2 = \\frac{K + 0.5\\sqrt{\\sin\\frac{\\theta}{2}}(1-\\beta^2) \n        + (1-\\beta^2)^2}{\\beta^4}\n        \n    Parameters\n    ----------\n    D1 : float\n        Diameter of the valve seat bore (must be equal to or smaller than \n        `D2`), [m]\n    D2 : float\n        Diameter of the pipe attached to the valve, [m]\n    angle : float\n        Angle formed by the reducer in the valve, [degrees]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_ball_valve_Crane(.01, .02, 50)\n    14.051310974926592\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if fd is None:\n        fd = ft_Crane(D2)\n    beta = D1/D2\n    K1 = 3*fd\n    angle = radians(angle)\n    if beta == 1:\n        return K1\n    else:\n        if angle <= pi/4:\n            return (K1 + sin(angle/2)*(0.8*(1-beta**2) + 2.6*(1-beta**2)**2))/beta**4\n        else:\n            return (K1 + 0.5*(sin(angle/2))**0.5 * (1 - beta**2) + (1-beta**2)**2)/beta**4"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef K_diaphragm_valve_Crane(D=None, fd=None, style=0):\n    r'''Returns the loss coefficient for a diaphragm valve of either weir\n    (`style` = 0) or straight-through (`style` = 1) as shown in [1]_.\n        \n    .. math::\n        K = K_1 = K_2 = N\\cdot f_d\n        \n    For style 0 (weir), N = 149; for style 1 (straight through), N = 39.\n    \n    Parameters\n    ----------\n    D : float, optional\n        Diameter of the pipe section the valve in mounted in; the\n        same as the line size [m]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n    style : int, optional\n        Either 0 (weir type valve) or 1 (straight through weir valve) [-]\n        \n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_diaphragm_valve_Crane(D=.1, style=0)\n    2.4269804835982565\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if D is None and fd is None:\n        raise ValueError('Either `D` or `fd` must be specified')\n    if fd is None:\n        fd = ft_Crane(D)\n    try:\n        K = diaphragm_valve_Crane_coeffs[style]*fd\n    except KeyError:\n        raise KeyError('Accepted valve styles are 0 (weir) or 1 (straight through) only')\n    return K", "response": "r Returns the loss coefficient for a weir valve of a clean \n       ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef K_butterfly_valve_Crane(D, fd=None, style=0):\n    r'''Returns the loss coefficient for a butterfly valve as shown in\n    [1]_. Three different types are supported; Centric (`style` = 0),\n    double offset (`style` = 1), and triple offset (`style` = 2).\n        \n    .. math::\n        K = N\\cdot f_d\n        \n    N is obtained from the following table:\n        \n    +------------+---------+---------------+---------------+\n    | Size range | Centric | Double offset | Triple offset |\n    +============+=========+===============+===============+\n    | 2\" - 8\"    | 45      | 74            | 218           |\n    +------------+---------+---------------+---------------+\n    | 10\" - 14\"  | 35      | 52            | 96            |\n    +------------+---------+---------------+---------------+\n    | 16\" - 24\"  | 25      | 43            | 55            |\n    +------------+---------+---------------+---------------+\n        \n    The actual change of coefficients happen at <= 9\" and <= 15\".\n            \n    Parameters\n    ----------\n    D : float\n        Diameter of the pipe section the valve in mounted in; the\n        same as the line size [m]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n    style : int, optional\n        Either 0 (centric), 1 (double offset), or 2 (triple offset) [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_butterfly_valve_Crane(D=.1, style=2)\n    3.5508841974793284\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if fd is None:\n        fd = ft_Crane(D)\n    try:\n        c1, c2, c3 = butterfly_valve_Crane_coeffs[style]\n    except KeyError:\n        raise KeyError('Accepted valve styles are 0 (centric), 1 (double offset), or 2 (triple offset) only.')\n    if D <= 0.2286:\n        # 2-8 inches, split at 9 inch\n        return c1*fd\n    elif D <= 0.381:\n        # 10-14 inches, split at 15 inch\n        return c2*fd\n    else:\n        # 16-18 inches\n        return c3*fd", "response": "A function that returns the loss coefficient for a butterfly valve."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef K_plug_valve_Crane(D1, D2, angle, fd=None, style=0):\n    r'''Returns the loss coefficient for a plug valve or cock valve as shown in\n    [1]_.\n\n    If \u03b2 = 1:\n        \n    .. math::\n        K = K_1 = K_2 = Nf_d\n        \n    Otherwise:\n        \n    .. math::\n        K_2 = \\frac{K + 0.5\\sqrt{\\sin\\frac{\\theta}{2}}(1-\\beta^2) \n        + (1-\\beta^2)^2}{\\beta^4}\n        \n    Three types of plug valves are supported. For straight-through plug valves\n    (`style` = 0), N = 18. For 3-way, flow straight through (`style` = 1) \n    plug valves, N = 30. For 3-way, flow 90\u00b0 valves (`style` = 2) N = 90.\n        \n    Parameters\n    ----------\n    D1 : float\n        Diameter of the valve plug bore (must be equal to or smaller than \n        `D2`), [m]\n    D2 : float\n        Diameter of the pipe attached to the valve, [m]\n    angle : float\n        Angle formed by the reducer in the valve, [degrees]\n    fd : float, optional\n        Darcy friction factor calculated for the actual pipe flow in clean \n        steel (roughness = 0.0018 inch) in the fully developed turbulent \n        region; do not specify this to use the original Crane friction factor!,\n        [-]\n    style : int, optional\n        Either 0 (straight-through), 1 (3-way, flow straight-through), or 2 \n        (3-way, flow 90\u00b0) [-]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient with respect to the pipe inside diameter [-]\n\n    Notes\n    -----    \n    This method is not valid in the laminar regime and the pressure drop will\n    be underestimated in those conditions.\n\n    Examples\n    --------\n    >>> K_plug_valve_Crane(D1=.01, D2=.02, angle=50)\n    19.80513692341617\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    if fd is None:\n        fd = ft_Crane(D2)\n    beta = D1/D2\n    try:\n        K = plug_valve_Crane_coeffs[style]*fd\n    except KeyError:\n        raise KeyError('Accepted valve styles are 0 (straight-through), 1 (3-way, flow straight-through), or 2 (3-way, flow 90\u00b0)')\n    angle = radians(angle)\n    if beta == 1:\n        return K\n    else:\n        return (K + 0.5*(sin(angle/2))**0.5 * (1 - beta**2) + (1-beta**2)**2)/beta**4", "response": "Returns the loss coefficient for a plug valve or cock valve."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef v_lift_valve_Crane(rho, D1=None, D2=None, style='swing check angled'):\n    r'''Calculates the approximate minimum velocity required to lift the disk \n    or other controlling element of a check valve to a fully open, stable,\n    position according to the Crane method [1]_.\n    \n    .. math::        \n        v_{min} = N\\cdot \\text{m/s} \\cdot \\sqrt{\\frac{\\text{kg/m}^3}{\\rho}}\n    \n    .. math::\n        v_{min} = N\\beta^2 \\cdot \\text{m/s} \\cdot \\sqrt{\\frac{\\text{kg/m}^3}{\\rho}}\n        \n    See the notes for the definition of values of N and which check valves use \n    which formulas.\n\n    Parameters\n    ----------\n    rho : float\n        Density of the fluid [kg/m^3]\n    D1 : float, optional\n        Diameter of the valve bore (must be equal to or smaller than \n        `D2`), [m]\n    D2 : float, optional\n        Diameter of the pipe attached to the valve, [m]\n    style : str\n        The type of valve; one of ['swing check angled', 'swing check straight',\n        'swing check UL', 'lift check straight', 'lift check angled', \n        'tilting check 5\u00b0', 'tilting check 15\u00b0', 'stop check globe 1', \n        'stop check angle 1', 'stop check globe 2',  'stop check angle 2', \n        'stop check globe 3', 'stop check angle 3', 'foot valve poppet disc', \n        'foot valve hinged disc'], [-]\n\n    Returns\n    -------\n    v_min : float\n        Approximate minimum velocity required to keep the disc fully lifted,\n        preventing chattering and wear [m/s]\n\n    Notes\n    -----\n    This equation is not dimensionless.\n\n    +--------------------------+-----+------+\n    | Name/string              | N   | Full |\n    +==========================+=====+======+\n    | 'swing check angled'     | 45  | No   |\n    +--------------------------+-----+------+\n    | 'swing check straight'   | 75  | No   |\n    +--------------------------+-----+------+\n    | 'swing check UL'         | 120 | No   |\n    +--------------------------+-----+------+\n    | 'lift check straight'    | 50  | Yes  |\n    +--------------------------+-----+------+\n    | 'lift check angled'      | 170 | Yes  |\n    +--------------------------+-----+------+\n    | 'tilting check 5\u00b0'       | 100 | No   |\n    +--------------------------+-----+------+\n    | 'tilting check 15\u00b0'      | 40  | No   |\n    +--------------------------+-----+------+\n    | 'stop check globe 1'     | 70  | Yes  |\n    +--------------------------+-----+------+\n    | 'stop check angle 1'     | 95  | Yes  |\n    +--------------------------+-----+------+\n    | 'stop check globe 2'     | 75  | Yes  |\n    +--------------------------+-----+------+\n    | 'stop check angle 2'     | 75  | Yes  |\n    +--------------------------+-----+------+\n    | 'stop check globe 3'     | 170 | Yes  |\n    +--------------------------+-----+------+\n    | 'stop check angle 3'     | 170 | Yes  |\n    +--------------------------+-----+------+\n    | 'foot valve poppet disc' | 20  | No   |\n    +--------------------------+-----+------+\n    | 'foot valve hinged disc' | 45  | No   |\n    +--------------------------+-----+------+\n\n    Examples\n    --------\n    >>> v_lift_valve_Crane(rho=998.2, D1=0.0627, D2=0.0779, style='lift check straight')\n    1.0252301935349286\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    specific_volume = 1./rho\n    if D1 is not None and D2 is not None:\n        beta = D1/D2\n        beta2 = beta*beta\n    if style == 'swing check angled':\n        return 45.0*specific_volume**0.5\n    elif style == 'swing check straight':\n        return 75.0*specific_volume**0.5\n    elif style == 'swing check UL':\n        return 120.0*specific_volume**0.5\n    elif style == 'lift check straight':\n        return 50.0*beta2*specific_volume**0.5\n    elif style == 'lift check angled':\n        return 170.0*beta2*specific_volume**0.5\n    elif style == 'tilting check 5\u00b0':\n        return 100.0*specific_volume**0.5\n    elif style == 'tilting check 15\u00b0':\n        return 40.0*specific_volume**0.5\n    elif style == 'stop check globe 1':\n        return 70.0*beta2*specific_volume**0.5\n    elif style == 'stop check angle 1':\n        return 95.0*beta2*specific_volume**0.5\n    elif style in ('stop check globe 2', 'stop check angle 2'):\n        return 75.0*beta2*specific_volume**0.5\n    elif style in ('stop check globe 3', 'stop check angle 3'):\n        return 170.0*beta2*specific_volume**0.5\n    elif style == 'foot valve poppet disc':\n        return 20.0*specific_volume**0.5\n    elif style == 'foot valve hinged disc':\n        return 45.0*specific_volume**0.5", "response": "r Returns the approximate minimum velocity required to lift a disk \n    or other controlling element of a check valve to a fully open stable one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef K_run_diverging_Crane(D_run, D_branch, Q_run, Q_branch, angle=90):\n    r'''Returns the loss coefficient for the run of a converging tee or wye\n    according to the Crane method [1]_.\n    \n    .. math::\n        K_{run} = M \\left(\\frac{Q_{branch}}{Q_{comb}}\\right)^2\n            \n    .. math::\n        \\beta_{branch} = \\frac{D_{branch}}{D_{comb}}\n    \n    See the notes for the definition of M.\n\n    Parameters\n    ----------\n    D_run : float\n        Diameter of the straight-through inlet portion of the tee or wye [m]\n    D_branch : float\n        Diameter of the pipe attached at an angle to the straight-through, [m]\n    Q_run : float\n        Volumetric flow rate in the straight-through outlet of the tee or wye,\n        [m^3/s]\n    Q_branch : float\n        Volumetric flow rate in the pipe attached at an angle to the straight-\n        through, [m^3/s]\n    angle : float, optional\n        Angle the branch makes with the straight-through (tee=90, wye<90)\n        [degrees]\n\n    Returns\n    -------\n    K : float\n        Loss coefficient of run with respect to the velocity and inside \n        diameter of the combined flow inlet [-]\n\n    Notes\n    -----\n    M is calculated according to the following pseudocode:\n        \n    .. code-block:: python\n\n        if beta*beta <= 0.4:\n            M = 0.4\n        elif Q_branch/Q_comb <= 0.5:\n            M = 2*(2*Q_branch/Q_comb - 1)\n        else:\n            M = 0.3*(2*Q_branch/Q_comb - 1)\n\n    Examples\n    --------\n    Example 7-36 of [1]_. A DN150 schedule 80 wye has 1515 liters/minute of\n    water exiting the straight leg, and 950 liters/minute of water\n    exiting it through a 45\u00b0 branch. Calculate the loss coefficient in\n    the branch. The calculated value there is -0.06809.\n    \n    >>> K_run_diverging_Crane(0.146, 0.146, 0.02525, 0.01583, angle=45)\n    -0.06810067607153049\n    \n    References\n    ----------\n    .. [1] Crane Co. Flow of Fluids Through Valves, Fittings, and Pipe. Crane,\n       2009.\n    '''\n    beta = (D_branch/D_run)\n    beta2 = beta*beta\n    Q_comb = Q_run + Q_branch\n    Q_ratio = Q_branch/Q_comb\n    if beta2 <= 0.4:\n        M = 0.4\n    elif Q_ratio <= 0.5:\n        M = 2.*(2.*Q_ratio - 1.)\n    else:\n        M = 0.3*(2.*Q_ratio - 1.)\n    return M*Q_ratio*Q_ratio", "response": "r Returns the loss coefficient for a run of a converging tee or wye with respect to the flow rate in the given branch."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Schade(mp, rhop, dp, rhog, D):\n    r'''Calculates saltation velocity of the gas for pneumatic conveying,\n    according to [1]_ as described in [2]_, [3]_, [4]_, and [5]_.\n\n    .. math::\n        Fr_s = \\mu^{0.11}\\left(\\frac{D}{d_p}\\right)^{0.025}\\left(\\frac{\\rho_p}\n        {\\rho_f}\\right)^{0.34}\n\n    .. math::\n        Fr_s = \\frac{V_{salt}}{\\sqrt{gD}}\n\n    .. math::\n        \\mu = \\frac{m_p}{\\frac{\\pi}{4}D^2V \\rho_f}\n\n    Parameters\n    ----------\n    mp : float\n        Solid mass flow rate, [kg/s]\n    rhop : float\n        Particle density, [kg/m^3]\n    dp : float\n        Particle diameter, [m]\n    rhog : float\n        Gas density, [kg/m^3]\n    D : float\n        Diameter of pipe, [m]\n\n    Returns\n    -------\n    V : float\n        Saltation velocity of gas, [m/s]\n\n    Notes\n    -----\n    Model is rearranged to be explicit in terms of saltation velocity\n    internally.\n\n    Examples\n    --------\n    >>> Schade(mp=1., rhop=1000., dp=1E-3, rhog=1.2, D=0.1)\n    13.697415809497912\n\n    References\n    ----------\n    .. [1] Schade, B., Zum Ubergang Sprung-Strahnen-forderung bei der\n       Horizontalen Pneumatischen Feststoffordrung. Dissertation, University of\n       Karlsruche (1987)\n    .. [2] Rabinovich, Evgeny, and Haim Kalman. \"Threshold Velocities of\n       Particle-Fluid Flows in Horizontal Pipes and Ducts: Literature Review.\"\n       Reviews in Chemical Engineering 27, no. 5-6 (January 1, 2011).\n       doi:10.1515/REVCE.2011.011.\n    .. [3] Setia, G., S. S. Mallick, R. Pan, and P. W. Wypych. \"Modeling\n       Minimum Transport Boundary for Fluidized Dense-Phase Pneumatic Conveying\n       Systems.\" Powder Technology 277 (June 2015): 244-51.\n       doi:10.1016/j.powtec.2015.02.050.\n    .. [4] Bansal, A., S. S. Mallick, and P. W. Wypych. \"Investigating\n       Straight-Pipe Pneumatic Conveying Characteristics for Fluidized\n       Dense-Phase Pneumatic Conveying.\" Particulate Science and Technology\n       31, no. 4 (July 4, 2013): 348-56. doi:10.1080/02726351.2012.732677.\n    .. [5] Gomes, L. M., and A. L. Amarante Mesquita. \"On the Prediction of\n       Pickup and Saltation Velocities in Pneumatic Conveying.\" Brazilian\n       Journal of Chemical Engineering 31, no. 1 (March 2014): 35-46.\n       doi:10.1590/S0104-66322014000100005\n    '''\n    B = (D/dp)**0.025*(rhop/rhog)**0.34\n    A = (g*D)**0.5\n    C = mp/(rhog*pi/4*D**2)\n    return (C**0.11*B*A)**(1/1.11)", "response": "r Schade a base class for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Corripio_motor_efficiency(P):\n    r'''Estimates motor efficiency using the method in Corripio (1982)\n    as shown in [1]_ and originally in [2]_. Estimation only.\n\n    .. math::\n        \\eta_M = 0.8  + 0.0319\\ln(P_B) - 0.00182\\ln(P_B)^2\n\n    Parameters\n    ----------\n    P : float\n        Power, [W]\n\n    Returns\n    -------\n    efficiency : float\n        Motor efficiency, [-]\n\n    Notes\n    -----\n    Example 16.5 in [1]_.\n\n    Examples\n    --------\n    >>> Corripio_motor_efficiency(137*745.7)\n    0.9128920875679222\n\n    References\n    ----------\n    .. [1] Seider, Warren D., J. D. Seader, and Daniel R. Lewin. Product and\n       Process Design Principles: Synthesis, Analysis, and Evaluation.\n       2 edition. New York: Wiley, 2003.\n    .. [2] Corripio, A.B., K.S. Chrien, and L.B. Evans, \"Estimate Costs of\n       Centrifugal Pumps and Electric Motors,\" Chem. Eng., 89, 115-118,\n       February 22 (1982).\n    '''\n    P = P/745.69987\n    logP = log(P)\n    return 0.8 + 0.0319*logP - 0.00182*logP*logP", "response": "Estimate motor efficiency using the method in Corripio ( 1982 )."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef VFD_efficiency(P, load=1):\n    r'''Returns the efficiency of a Variable Frequency Drive according to [1]_.\n    These values are generic, and not standardized as minimum values.\n    Older VFDs often have much worse performance.\n\n    Parameters\n    ----------\n    P : float\n        Power, [W]\n    load : float, optional\n        Fraction of motor's rated electrical capacity being used\n\n    Returns\n    -------\n    efficiency : float\n        VFD efficiency, [-]\n\n    Notes\n    -----\n    The use of a VFD does change the characteristics of a pump curve's\n    efficiency, but this has yet to be quantified. The effect is small.\n    This value should be multiplied by the product of the pump and motor\n    efficiency to determine the overall efficiency.\n\n    Efficiency table is in units of hp, so a conversion is performed internally.\n    If load not specified, assumed 1 - where maximum efficiency occurs.\n    Table extends down to 3 hp and up to 400 hp; values outside these limits\n    are rounded to the nearest known value. Values between standardized sizes\n    are interpolated linearly. Load values extend down to 0.016.\n    \n    The table used is for Pulse Width Modulation (PWM) VFDs.\n\n    Examples\n    --------\n    >>> VFD_efficiency(10*hp)\n    0.96\n    >>> VFD_efficiency(100*hp, load=0.2)\n    0.92\n\n    References\n    ----------\n    .. [1] GoHz.com. Variable Frequency Drive Efficiency.\n       http://www.variablefrequencydrive.org/vfd-efficiency\n    '''\n    P = P/hp # convert to hp\n    if P < 3:\n        P = 3\n    elif P > 400:\n        P = 400\n    if load < 0.016:\n        load = 0.016\n    return round(bisplev(load, P, VFD_efficiency_tck), 4)", "response": "r Returns the efficiency of a Variable Frequency Drive according to [ 1 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_ideal(P, V, phase=3, PF=1):\n    r'''Returns the current drawn by a motor of power `P` operating at voltage\n    `V`, with line AC of phase `phase` and power factor `PF` according to [1]_.\n\n    Single-phase power:\n\n    .. math::\n        I = \\frac{P}{V \\cdot \\text{PF}}\n\n    3-phase power:\n\n    .. math::\n        I = \\frac{P}{V \\cdot \\text{PF} \\sqrt{3}}\n\n\n    Parameters\n    ----------\n    P : float\n        Power, [W]\n    V : float\n        Voltage, [V]\n    phase : int, optional\n        Line AC phase, either 1 or 3\n    PF : float, optional\n        Power factor of motor\n\n    Returns\n    -------\n    I : float\n        Power drawn by motor, [A]\n\n    Notes\n    -----\n    Does not include power used by the motor's fan, or startor, or internal\n    losses. These are all significant.\n\n    Examples\n    --------\n    >>> current_ideal(V=120, P=1E4, PF=1, phase=1)\n    83.33333333333333\n\n    References\n    ----------\n    .. [1] Electrical Construction, and Maintenance. \"Calculating Single- and\n       3-Phase Parameters.\" April 1, 2008.\n       http://ecmweb.com/basics/calculating-single-and-3-phase-parameters.\n    '''\n    if phase not in [1, 3]:\n        raise Exception('Only 1 and 3 phase power supported')\n    if phase == 3:\n        return P/(V*3**0.5*PF)\n    else:\n        return P/(V*PF)", "response": "r Returns the current drawn by a motor of power P operating at voltage V with line AC of phase PF."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the Sounders Brown Horizontal or Vertical K factor as used in determining maximum permissible gas velocity in a horizontal or vertical separator.", "response": "def K_separator_demister_York(P, horizontal=False):\n    r'''Calculates the Sounders Brown `K` factor as used in determining maximum \n    permissible gas velocity in a two-phase separator in either a horizontal or \n    vertical orientation, *with a demister*.\n    This function is a curve fit to [1]_ published in [2]_ and is widely used. \n    \n    For 1 < P < 15 psia:   \n    \n    .. math::\n        K = 0.1821 + 0.0029P + 0.0460\\ln P\n\n    For 15 <= P <= 40 psia:   \n    \n    .. math::\n        K = 0.35\n        \n    For P < 5500 psia:\n    \n    .. math::\n        K = 0.430 - 0.023\\ln P\n        \n    In the above equations, P is in units of psia.\n\n    Parameters\n    ----------\n    P : float\n        Pressure of separator, [Pa]\n    horizontal : bool, optional\n        Whether to use the vertical or horizontal value; horizontal is 1.25 \n        times higher, [-]\n\n    Returns\n    -------\n    K : float\n        Sounders Brown Horizontal or vertical `K` factor for two-phase\n        separator design with a demister, [m/s]\n\n    Notes\n    -----\n    If the input pressure is under 1 psia, 1 psia is used. If the\n    input pressure is over 5500 psia, 5500 psia is used.\n\n    Examples\n    --------\n    >>> K_separator_demister_York(975*psi)\n    0.08281536035331669\n\n    References\n    ----------\n    .. [2] Otto H. York Company, \"Mist Elimination in Gas Treatment Plants and \n       Refineries,\" Engineering, Parsippany, NJ.\n    .. [1] Svrcek, W. Y., and W. D. Monnery. \"Design Two-Phase Separators \n       within the Right Limits\" Chemical Engineering Progress, (October 1, \n       1993): 53-60.\n    '''\n    P = P/psi # Correlation in terms of psia\n    if P < 15:\n        if P < 1: \n            P = 1 # Prevent negative K values, but as a consequence be  \n            # optimistic for K values; limit is 0.185 ft/s but real values\n            # should probably be lower\n        K = 0.1821 + 0.0029*P + 0.0460*log(P)\n    elif P < 40:\n        K = 0.35\n    else:\n        if P > 5500:\n            P = 5500 # Do not allow for lower K values above 5500 psia, as\n            # the limit is stated to be 5500\n        K = 0.430 - 0.023*log(P)\n    K *= foot # Converts units of ft/s to m/s; the graph and all fits are in ft/s \n    if horizontal:\n        # Watkins recommends a factor of 1.25 for horizontal separators over \n        # vertical separators as well\n        K *= 1.25 \n    return K"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the flow rate across a V - notch fluid.", "response": "def Q_weir_V_Shen(h1, angle=90):\n    r'''Calculates the flow rate across a V-notch (triangular) weir from\n    the height of the liquid above the tip of the notch, and with the angle\n    of the notch. Most of these type of weir are 90 degrees. Model from [1]_\n    as reproduced in [2]_.\n\n    Flow rate is given by:\n\n    .. math::\n        Q = C \\tan\\left(\\frac{\\theta}{2}\\right)\\sqrt{g}(h_1 + k)^{2.5}\n\n    Parameters\n    ----------\n    h1 : float\n        Height of the fluid above the notch [m]\n    angle : float, optional\n        Angle of the notch [degrees]\n\n    Returns\n    -------\n    Q : float\n        Volumetric flow rate across the weir [m^3/s]\n\n    Notes\n    -----\n    angles = [20, 40, 60, 80, 100]\n    Cs = [0.59, 0.58, 0.575, 0.575, 0.58]\n    k = [0.0028, 0.0017, 0.0012, 0.001, 0.001]\n\n    The following limits apply to the use of this equation:\n\n    h1 >= 0.05 m\n    h2 > 0.45 m\n    h1/h2 <= 0.4 m\n    b > 0.9 m\n\n    .. math::\n        \\frac{h_1}{b}\\tan\\left(\\frac{\\theta}{2}\\right) < 2\n\n    Flows are lower than obtained by the curves at\n    http://www.lmnoeng.com/Weirs/vweir.php.\n\n    Examples\n    --------\n    >>> Q_weir_V_Shen(0.6, angle=45)\n    0.21071725775478228\n\n    References\n    ----------\n    .. [1] Shen, John. \"Discharge Characteristics of Triangular-Notch\n       Thin-Plate Weirs\u202f: Studies of Flow to Water over Weirs and Dams.\"\n       USGS Numbered Series. Water Supply Paper. U.S. Geological Survey\u202f:\n       U.S. G.P.O., 1981\n    .. [2] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.:\n       Van Nostrand Reinhold Co., 1984.\n    '''\n    C = interp(angle, angles_Shen, Cs_Shen)\n    k = interp(angle, angles_Shen, k_Shen)    \n    return C*tan(radians(angle)/2)*g**0.5*(h1 + k)**2.5"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Q_weir_rectangular_full_SIA(h1, h2, b):\n    r'''Calculates the flow rate across a full-channel rectangular weir from\n    the height of the liquid above the crest of the weir, the liquid depth\n    beneath it, and the width of the channel. Model from [1]_ as reproduced in\n    [2]_.\n\n    Flow rate is given by:\n\n    .. math::\n        Q = \\frac{2}{3}\\sqrt{2}\\left(0.615 + \\frac{0.000615}{h_1+0.0016}\\right)\n        b\\sqrt{g} h_1 +0.5\\left(\\frac{h_1}{h_1+h_2}\\right)^2b\\sqrt{g} h_1^{1.5}\n\n    Parameters\n    ----------\n    h1 : float\n        Height of the fluid above the crest of the weir [m]\n    h2 : float\n        Height of the fluid below the crest of the weir [m]\n    b : float\n        Width of the channel section [m]\n\n    Returns\n    -------\n    Q : float\n        Volumetric flow rate across the weir [m^3/s]\n\n    Notes\n    -----\n    The following limits apply to the use of this equation:\n\n    0.025 < h < 0.8 m\n    b > 0.3 m\n    h2 > 0.3 m\n    h1/h2 < 1\n\n    Examples\n    --------\n    Example compares terribly with the Ackers expression - probable error\n    in [2]_. DO NOT USE.\n\n    >>> Q_weir_rectangular_full_SIA(h1=0.3, h2=0.4, b=2)\n    1.1875825055400384\n\n    References\n    ----------\n    .. [1] Normen f\u00fcr Wassermessungen: bei Durchf\u00fchrung von Abnahmeversuchen an\n       Wasserkraftmaschinen. SIA, 1924.\n    .. [2] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.:\n       Van Nostrand Reinhold Co., 1984.\n    '''\n    Q = 2/3.*2**0.5*(0.615 + 0.000615/(h1 + 0.0016))*b*g**0.5*h1 \\\n    + 0.5*(h1/(h1+h2))**2*b*g**0.5*h1**1.5\n    return Q", "response": "r Returns the flow rate across a full - channel rectangular weir."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Q_weir_rectangular_full_Kindsvater_Carter(h1, h2, b):\n    r'''Calculates the flow rate across a full-channel rectangular weir from\n    the height of the liquid above the crest of the weir, the liquid depth\n    beneath it, and the width of the channel. Model from [1]_ as reproduced in\n    [2]_.\n\n    Flow rate is given by:\n\n    .. math::\n        Q = \\frac{2}{3}\\sqrt{2}\\left(0.602 + 0.0832\\frac{h_1}{h_2}\\right)\n        b\\sqrt{g} (h_1 +0.00125)^{1.5}\n\n    Parameters\n    ----------\n    h1 : float\n        Height of the fluid above the crest of the weir [m]\n    h2 : float\n        Height of the fluid below the crest of the weir [m]\n    b : float\n        Width of the channel section [m]\n\n    Returns\n    -------\n    Q : float\n        Volumetric flow rate across the weir [m^3/s]\n\n    Notes\n    -----\n    The following limits apply to the use of this equation:\n\n    h1 > 0.03 m\n    b > 0.15 m\n    h2 > 0.1 m\n    h1/h2 < 2\n\n    Examples\n    --------\n    >>> Q_weir_rectangular_full_Kindsvater_Carter(h1=0.3, h2=0.4, b=2)\n    0.641560300081563\n\n    References\n    ----------\n    .. [1] Kindsvater, Carl E., and Rolland W. Carter. \"Discharge\n       Characteristics of Rectangular Thin-Plate Weirs.\" Journal of the\n       Hydraulics Division 83, no. 6 (December 1957): 1-36.\n    .. [2] Blevins, Robert D. Applied Fluid Dynamics Handbook. New York, N.Y.:\n       Van Nostrand Reinhold Co., 1984.\n    '''\n    Q = 2/3.*2**0.5*(0.602 + 0.075*h1/h2)*(b - 0.001)*g**0.5*(h1 + 0.001)**1.5\n    return Q", "response": "r Returns the flow rate across a full - channel rectangular weir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying function to obtain a latitude and longitude from a location string such as Houston TX or Colombia.", "response": "def geocode(address):\n    '''Query function to obtain a latitude and longitude from a location\n    string such as `Houston, TX` or`Colombia`. This uses an online lookup,\n    currently wrapping the `geopy` library, and providing an on-disk cache\n    of queries.\n    \n    Parameters\n    ----------\n    address : str\n        Search string to retrieve the location, [-]\n        \n    Returns\n    -------\n    latitude : float\n        Latitude of address, [degrees]\n    longitude : float\n        Longitude of address, [degrees]\n        \n    Notes\n    -----\n    If a query has been retrieved before, this function will take under 1 ms;\n    it takes several seconds otherwise.\n    \n    Examples\n    --------\n    >>> geocode('Fredericton, NB')\n    (45.966425, -66.645813)\n    '''\n    loc_tuple = None\n    try:\n        cache = geopy_cache()\n        loc_tuple = cache.cached_address(address)\n    except:\n        # Handle bugs in the cache, i.e. if there is no space on disk to create\n        # the database, by ignoring them\n        pass\n    if loc_tuple is not None:\n        return loc_tuple\n    else:\n        geocoder = geopy_geolocator()\n        if geocoder is None:\n            return geopy_missing_msg\n        location = geocoder.geocode(address)\n        try:\n            cache.cache_address(address, location.latitude, location.longitude)\n        except:\n            pass\n        return (location.latitude, location.longitude)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef heating_degree_days(T, T_base=F2K(65), truncate=True):\n    r'''Calculates the heating degree days for a period of time.\n\n    .. math::\n        \\text{heating degree days} = max(T - T_{base}, 0)\n\n    Parameters\n    ----------\n    T : float\n        Measured temperature; sometimes an average over a length of time is used,\n        other times the average of the lowest and highest temperature in a \n        period are used, [K]\n    T_base : float, optional\n        Reference temperature for the degree day calculation, defaults\n        to 65 \u00b0F (18.33 \u00b0C, 291.483 K), the value most used in the US, [K]\n    truncate : bool\n        If truncate is True, no negative values will be returned; if negative, \n        the value is truncated to 0, [-]\n\n    Returns\n    -------\n    heating_degree_days : float\n        Degree above the base temperature multiplied by the length of time of\n        the measurement, normally days [day*K]\n\n    Notes\n    -----\n    Some common base temperatures are 18 \u00b0C (Canada), 15.5 \u00b0C (EU), \n    17 \u00b0C (Denmark, Finland), 12 \u00b0C Switzerland. The base temperature\n    should always be presented with the results.\n    \n    The time unit does not have to be days; it can be any time unit, and the\n    calculation behaves the same.\n\n    Examples\n    --------\n    >>> heating_degree_days(303.8)\n    12.31666666666672\n    \n    >>> heating_degree_days(273)\n    0.0\n    \n    >>> heating_degree_days(322, T_base=300)\n    22\n\n    References\n    ----------\n    .. [1] \"Heating Degree Day.\" Wikipedia, January 24, 2018. \n       https://en.wikipedia.org/w/index.php?title=Heating_degree_day&oldid=822187764.\n    '''\n    dd = T - T_base\n    if truncate and dd < 0.0:\n        dd = 0.0\n    return dd", "response": "Calculates the heating degree days for a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cooling_degree_days(T, T_base=283.15, truncate=True):\n    r'''Calculates the cooling degree days for a period of time.\n\n    .. math::\n        \\text{cooling degree days} = max(T_{base} - T, 0)\n\n    Parameters\n    ----------\n    T : float\n        Measured temperature; sometimes an average over a length of time is used,\n        other times the average of the lowest and highest temperature in a \n        period are used, [K]\n    T_base : float, optional\n        Reference temperature for the degree day calculation, defaults\n        to 10 \u00b0C, 283.15 K, a common value, [K]\n    truncate : bool\n        If truncate is True, no negative values will be returned; if negative, \n        the value is truncated to 0, [-]\n\n    Returns\n    -------\n    cooling_degree_days : float\n        Degree below the base temperature multiplied by the length of time of\n        the measurement, normally days [day*K]\n\n    Notes\n    -----\n    The base temperature should always be presented with the results.\n    \n    The time unit does not have to be days; it can be time unit, and the\n    calculation behaves the same.\n\n    Examples\n    --------\n    >>> cooling_degree_days(250)\n    33.14999999999998\n    \n    >>> cooling_degree_days(300)\n    0.0\n    \n    >>> cooling_degree_days(250, T_base=300)\n    50\n\n    References\n    ----------\n    .. [1] \"Heating Degree Day.\" Wikipedia, January 24, 2018. \n       https://en.wikipedia.org/w/index.php?title=Heating_degree_day&oldid=822187764.\n    '''\n    dd = T_base - T\n    if truncate and dd < 0.0:\n        dd = 0.0\n    return dd", "response": "r Returns the cooling degree days for a given time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_clean_isd_history(dest=os.path.join(folder, 'isd-history-cleaned.tsv'),\n                          url=\"ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv\"): # pragma: no cover\n    '''Basic method to update the isd-history file from the NOAA. This is \n    useful as new weather stations are updated all the time.\n    \n    This function requires pandas to run. If fluids is installed for the \n    superuser, this method must be called in an instance of Python running\n    as the superuser (administrator).\n    \n    Retrieving the file from ftp typically takes several seconds.\n    Pandas reads the file in ~30 ms and writes it in ~220 ms. Reading it with \n    the code below takes ~220 ms but is necessary to prevent a pandas \n    dependency.\n    \n    Parameters\n    ----------\n    dest : str, optional\n        The file to store the data retrieved; leave as the default argument\n        for it to be accessible by fluids.\n    url : str, optional\n        The location of the data file; this can be anywhere that can be read\n        by pandas, including a local file as would be useful in an offline\n        situation.\n    '''\n    import pandas as pd\n    df = pd.read_csv(url)\n    df.to_csv(dest, sep='\\t', index=False, header=False)", "response": "This method will read the isd - history file from the NOAA and store it in a TTY file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_station_year_text(WMO, WBAN, year):\n    '''Basic method to download data from the GSOD database, given a \n    station identifier and year. \n\n    Parameters\n    ----------\n    WMO : int or None\n         World Meteorological Organization (WMO) identifiers, [-]\n    WBAN : int or None\n        Weather Bureau Army Navy (WBAN) weather station identifier, [-]\n    year : int\n        Year data should be retrieved from, [year]\n        \n    Returns\n    -------\n    data : str\n        Downloaded data file\n    '''\n    if WMO is None:\n        WMO = 999999\n    if WBAN is None:\n        WBAN = 99999\n    station = str(int(WMO)) + '-' + str(int(WBAN)) \n    gsod_year_dir = os.path.join(data_dir, 'gsod', str(year))\n    path = os.path.join(gsod_year_dir, station + '.op')\n    if os.path.exists(path):\n        data = open(path).read()\n        if data and data != 'Exception':\n            return data\n        else:\n            raise Exception(data)\n        \n    toget = ('ftp://ftp.ncdc.noaa.gov/pub/data/gsod/' + str(year) + '/' \n             + station + '-' + str(year) +'.op.gz')\n    try:\n        data = urlopen(toget, timeout=5)\n    except Exception as e:\n        if not os.path.exists(gsod_year_dir):\n            os.makedirs(gsod_year_dir)\n        open(path, 'w').write('Exception')\n        raise Exception('Could not obtain desired data; check '\n                        'if the year has data published for the '\n                        'specified station and the station was specified '\n                        'in the correct form. The full error is %s' %(e))\n        \n    data = data.read()\n    data_thing = StringIO(data)\n\n    f = gzip.GzipFile(fileobj=data_thing, mode=\"r\")\n    year_station_data = f.read()\n    try: \n        year_station_data = year_station_data.decode('utf-8')\n    except:\n        pass\n    \n    # Cache the data for future use\n    if not os.path.exists(gsod_year_dir):\n        os.makedirs(gsod_year_dir)\n    open(path, 'w').write(year_station_data)\n    \n    \n    return year_station_data", "response": "Basic method to download data from the GSOD database given a weather station identifier and year."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dP_demister_dry_Setekleiv_Svendsen(S, voidage, vs, rho, mu, L=1):\n    r'''Calculates dry pressure drop across a demister, using the\n    correlation in [1]_. This model is for dry demisters with no holdup only.\n\n    .. math::\n        \\frac{\\Delta P \\epsilon^2}{\\rho_f v^2} = 10.29 - \\frac{565}\n        {69.6SL - (SL)^2 - 779} - \\frac{74.9}{160.9 - 4.85SL} + 45.33\\left(\n        \\frac{\\mu_f \\epsilon S^2 L}{\\rho_f v}\\right)^{0.75}\n\n    Parameters\n    ----------\n    S : float\n        Specific area of the demister, normally ~250-1000 [m^2/m^3]\n    voidage : float\n        Voidage of bed of the demister material, normally ~0.98 []\n    vs : float\n        Superficial velocity of fluid, Q/A [m/s]\n    rho : float\n        Density of fluid [kg/m^3]\n    mu : float\n        Viscosity of fluid [Pa*s]\n    L : float, optional\n        Length of the demister [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across a dry demister [Pa]\n\n    Notes\n    -----\n    Useful at startup and in modeling. Dry pressure drop is normally negligible\n    compared to wet pressure drop. Coefficients obtained by evolutionary\n    programming and may not fit data outside of the limits of the variables.\n\n    Examples\n    --------\n    >>> dP_demister_dry_Setekleiv_Svendsen(S=250, voidage=.983, vs=1.2, rho=10, mu=3E-5, L=1)\n    320.3280788941329\n\n    References\n    ----------\n    .. [1] Setekleiv, A. Eddie, and Hallvard F. Svendsen. \"Dry Pressure Drop in\n       Spiral Wound Wire Mesh Pads at Low and Elevated Pressures.\" Chemical\n       Engineering Research and Design 109 (May 2016): 141-149.\n       doi:10.1016/j.cherd.2016.01.019.\n    '''\n    term = 10.29 - 565./(69.6*S*L - (S*L)**2 - 779) - 74.9/(160.9 - 4.85*S*L)\n    right = term + 45.33*(mu*voidage*S**2*L/rho/vs)**0.75\n    return right*rho*vs**2/voidage**2", "response": "r Returns a new base class for a dry demister with the given voidage vs rho mu and L."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef voidage_experimental(m, rho, D, H):\n    r'''Calculates voidage of a bed or mesh given an experimental weight and\n    fixed density, diameter, and height, as shown in [1]_. The formula is also\n    self-evident.\n\n    .. math::\n        \\epsilon = 1 - \\frac{\\frac{m_{mesh}}{\\frac{\\pi}{4}d_{column}^2\n        L_{mesh}}}{\\rho_{material}}\n\n    Parameters\n    ----------\n    m : float\n        Mass of mesh or bed particles weighted, [kg]\n    rho : float\n        Density of solid particles or mesh [kg/m^3]\n    D : float\n        Diameter of the cylindrical bed [m]\n    H : float\n        Height of the demister or bed [m]\n\n    Returns\n    -------\n    voidage : float\n        Voidage of bed of the material []\n\n    Notes\n    -----\n    Should be trusted over manufacturer data.\n\n    Examples\n    --------\n    >>> voidage_experimental(m=126, rho=8000, D=1, H=1)\n    0.9799464771704212\n\n    References\n    ----------\n    .. [1] Hels\u00f8r, T., and H. Svendsen. \"Experimental Characterization of\n       Pressure Drop in Dry Demisters at Low and Elevated Pressures.\" Chemical\n       Engineering Research and Design 85, no. 3 (2007): 377-85.\n       doi:10.1205/cherd06048.\n    '''\n    return 1 - m/(pi/4*D**2*H)/rho", "response": "r Returns the voidage of a single modular cylindrical."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Stichlmair_dry(Vg, rhog, mug, voidage, specific_area, C1, C2, C3, H=1.):\n    r'''Calculates dry pressure drop across a packed column, using the\n    Stichlmair [1]_ correlation. Uses three regressed constants for each\n    type of packing, and voidage and specific area.\n\n    Pressure drop is given by:\n\n    .. math::\n        \\Delta P_{dry} = \\frac{3}{4} f_0 \\frac{1-\\epsilon}{\\epsilon^{4.65}}\n        \\rho_G \\frac{H}{d_p}V_g^2\n\n    .. math::\n        f_0 = \\frac{C_1}{Re_g} + \\frac{C_2}{Re_g^{0.5}} + C_3\n\n    .. math::\n        d_p = \\frac{6(1-\\epsilon)}{a}\n\n    Parameters\n    ----------\n    Vg : float\n        Superficial velocity of gas, Q/A [m/s]\n    rhog : float\n        Density of gas [kg/m^3]\n    mug : float\n        Viscosity of gas [Pa*s]\n    voidage : float\n        Voidage of bed of packing material []\n    specific_area : float\n        Specific area of the packing material [m^2/m^3]\n    C1 : float\n        Packing-specific constant []\n    C2 : float\n        Packing-specific constant []\n    C3 : float\n        Packing-specific constant []\n    H : float, optional\n        Height of packing [m]\n\n    Returns\n    -------\n    dP_dry : float\n        Pressure drop across dry packing [Pa]\n\n    Notes\n    -----\n    This model is used by most process simulation tools. If H is not provided,\n    it defaults to 1. If Z is not provided, it defaults to 1.\n\n    Examples\n    --------\n    >>> Stichlmair_dry(Vg=0.4, rhog=5., mug=5E-5, voidage=0.68,\n    ... specific_area=260., C1=32., C2=7, C3=1)\n    236.80904286559885\n\n    References\n    ----------\n    .. [1] Stichlmair, J., J. L. Bravo, and J. R. Fair. \"General Model for\n       Prediction of Pressure Drop and Capacity of Countercurrent Gas/liquid\n       Packed Columns.\" Gas Separation & Purification 3, no. 1 (March 1989):\n       19-28. doi:10.1016/0950-4214(89)80016-7.\n    '''\n    dp = 6*(1-voidage)/specific_area\n    Re = Vg*rhog*dp/mug\n    f0 = C1/Re + C2/Re**0.5 + C3\n    return 3/4.*f0*(1-voidage)/voidage**4.65*rhog*H/dp*Vg**2", "response": "r Calculates the dry pressure drop across a packed column."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Stichlmair_wet(Vg, Vl, rhog, rhol, mug, voidage, specific_area, C1, C2, C3, H=1):\n    r'''Calculates dry pressure drop across a packed column, using the\n    Stichlmair [1]_ correlation. Uses three regressed constants for each\n    type of packing, and voidage and specific area. This model is for irrigated\n    columns only.\n\n    Pressure drop is given by:\n\n    .. math::\n        \\frac{\\Delta P_{irr}}{H} = \\frac{\\Delta P_{dry}}{H}\\left(\\frac\n        {1-\\epsilon + h_T}{1-\\epsilon}\\right)^{(2+c)/3}\n        \\left(\\frac{\\epsilon}{\\epsilon-h_T}\\right)^{4.65}\n\n    .. math::\n        h_T = h_0\\left[1 + 20\\left(\\frac{\\Delta Pirr}{H\\rho_L g}\\right)^2\\right]\n\n    .. math::\n        Fr_L = \\frac{V_L^2 a}{g \\epsilon^{4.65}}\n\n    .. math::\n        h_0 = 0.555 Fr_L^{1/3}\n\n    .. math::\n        c = \\frac{-C_1/Re_g - C_2/(2Re_g^{0.5})}{f_0}\n\n    .. math::\n        \\Delta P_{dry} = \\frac{3}{4} f_0 \\frac{1-\\epsilon}{\\epsilon^{4.65}}\n        \\rho_G \\frac{H}{d_p}V_g^2\n\n    .. math::\n        f_0 = \\frac{C_1}{Re_g} + \\frac{C_2}{Re_g^{0.5}} + C_3\n\n    .. math::\n        d_p = \\frac{6(1-\\epsilon)}{a}\n\n    Parameters\n    ----------\n    Vg : float\n        Superficial velocity of gas, Q/A [m/s]\n    Vl : float\n        Superficial velocity of liquid, Q/A [m/s]\n    rhog : float\n        Density of gas [kg/m^3]\n    rhol : float\n        Density of liquid [kg/m^3]\n    mug : float\n        Viscosity of gas [Pa*s]\n    voidage : float\n        Voidage of bed of packing material []\n    specific_area : float\n        Specific area of the packing material [m^2/m^3]\n    C1 : float\n        Packing-specific constant []\n    C2 : float\n        Packing-specific constant []\n    C3 : float\n        Packing-specific constant []\n    H : float, optional\n        Height of packing [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across irrigated packing [Pa]\n\n    Notes\n    -----\n    This model is used by most process simulation tools. If H is not provided,\n    it defaults to 1. If Z is not provided, it defaults to 1.\n    A numerical solver is used and needed by this model. Its initial guess\n    is the dry pressure drop. Convergence problems may occur.\n    The model as described in [1]_ appears to have a typo, and could not match\n    the example. As described in [2]_, however, the model works.\n\n    Examples\n    --------\n    Example is from [1]_, matches.\n\n    >>> Stichlmair_wet(Vg=0.4, Vl = 5E-3, rhog=5., rhol=1200., mug=5E-5,\n    ... voidage=0.68, specific_area=260., C1=32., C2=7., C3=1.)\n    539.8768237253518\n\n    References\n    ----------\n    .. [1] Stichlmair, J., J. L. Bravo, and J. R. Fair. \"General Model for\n       Prediction of Pressure Drop and Capacity of Countercurrent Gas/liquid\n       Packed Columns.\" Gas Separation & Purification 3, no. 1 (March 1989):\n       19-28. doi:10.1016/0950-4214(89)80016-7.\n    .. [2] Piche, Simon R., Faical Larachi, and Bernard P. A. Grandjean.\n       \"Improving the Prediction of Irrigated Pressure Drop in Packed\n       Absorption Towers.\" The Canadian Journal of Chemical Engineering 79,\n       no. 4 (August 1, 2001): 584-94. doi:10.1002/cjce.5450790417.\n    '''\n    dp = 6.0*(1.0 - voidage)/specific_area\n    Re = Vg*rhog*dp/mug\n    f0 = C1/Re + C2/Re**0.5 + C3\n    dP_dry = 3/4.*f0*(1-voidage)/voidage**4.65*rhog*H/dp*Vg*Vg\n    c = (-C1/Re - C2/(2*Re**0.5))/f0\n    Frl = Vl**2*specific_area/(g*voidage**4.65)\n    h0 = 0.555*Frl**(1/3.)\n    def to_zero(dP_irr):\n        hT = h0*(1.0 + 20.0*(dP_irr/H/rhol/g)**2)\n        err = dP_dry/H*((1-voidage+hT)/(1.0 - voidage))**((2.0 + c)/3.)*(voidage/(voidage-hT))**4.65 -dP_irr/H\n        return err\n    return float(newton(to_zero, dP_dry))", "response": "r Calculates the stichlmair model for a given set of components."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Stichlmair_flood_f(inputs, Vl, rhog, rhol, mug, voidage, specific_area,\n                        C1, C2, C3, H):\n    '''Internal function which calculates the errors of the two Stichlmair\n    objective functions, and their jacobian.\n    '''\n    Vg, dP_irr = float(inputs[0]), float(inputs[1])\n    dp = 6.0*(1.0 - voidage)/specific_area\n    Re = Vg*rhog*dp/mug\n    f0 = C1/Re + C2/Re**0.5 + C3\n    dP_dry = 0.75*f0*(1.0 - voidage)/voidage**4.65*rhog*H/dp*Vg*Vg\n    c = (-C1/Re - 0.5*C2*Re**-0.5)/f0\n    Frl = Vl*Vl*specific_area/(g*voidage**4.65)\n    h0 = 0.555*Frl**(1/3.)\n    hT = h0*(1.0 + 20.0*(dP_irr/H/rhol/g)**2)\n    err1 = dP_dry/H*((1.0 - voidage + hT)/(1.0 - voidage))**((2.0 + c)/3.)*(voidage/(voidage-hT))**4.65 - dP_irr/H\n    term = (dP_irr/(rhol*g*H))**2\n    err2 = (1./term - 40.0*((2.0+c)/3.)*h0/(1.0 - voidage + h0*(1.0 + 20.0*term))\n    - 186.0*h0/(voidage - h0*(1.0 + 20.0*term)))\n    return err1, err2", "response": "Internal function which calculates the errors of the two Stichlmair\n    objective functions and their jacobian."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Stichlmair_flood_f_and_jac(inputs, Vl, rhog, rhol, mug, voidage, \n                                specific_area, C1, C2, C3, H):\n    '''Internal function which calculates the errors of the two Stichlmair\n    objective functions, and their jacobian.\n    \n    Derived using SymPy on the main flooding function.\n    '''\n    Vg, dP_irr = float(inputs[0]), float(inputs[1])\n    x0 = 1.0/H\n    x1 = Vg*Vg\n    x2 = voidage**(-4.65)\n    x3 = specific_area*x2\n    x4 = Vl*Vl*x3/g\n    x5 = x4**0.333333333333333\n    x6 = dP_irr*dP_irr\n    x7 = H*H\n    x8 = 1.0/x7\n    x9 = g*g\n    x10 = 1.0/x9\n    x11 = rhol*rhol\n    x12 = 1.0/x11\n    x13 = x5*(20.0*x10*x12*x6*x8 + 1.0)\n    x14 = 0.555*x13\n    x15 = (voidage/(voidage - x14))**4.65\n    x16 = 1.0/Vg\n    x17 = 1.0/rhog\n    x18 = voidage - 1.0\n    x19 = 1.0/x18\n    x20 = C1*mug*specific_area*x16*x17*x19\n    x21 = 2.44948974278318*C2\n    x22 = Vg*rhog/(mug*specific_area)\n    x23 = x21*(-x18*x22)**-0.5\n    x24 = 6.0*C3 - x20 + x23\n    x25 = 1.0 - voidage \n    x26 = x14 + x25\n    x27 = -x19*x26\n    x28 = 2.0*C1*mug*specific_area*x16*x17/x25 + x21*(x22*x25)**-0.5\n    x29 = 1.0/x24\n    x30 = x28*x29\n    x31 = x27**(-0.166666666666667*x30 + 0.666666666666667)\n    x32 = x11*x7*x9\n    x33 = 200.0*voidage\n    x34 = 111.0*x13\n    x35 = x33 - x34\n    x36 = 1.0/x35\n    x37 = -x33 + x34 + 200.0\n    x38 = 1.0/x37\n    x39 = 2.0*x20\n    x40 = -4.0*x20 + x23 + x29*(-x23 + x39)*(x23 - x39)\n    x41 = dP_irr*rhog*specific_area*x0*x1*x10*x12*x15*x2*x24*x31\n    x42 = dP_irr*x10*x12*x4**0.666666666666667*x8\n    \n    F1, F2, dF1_dVg, dF2_dVg, dF1_dP_irr, dF2_dP_irr = (\n            -dP_irr*x0 + 0.0208333333333333*rhog*specific_area*x1*x15*x2*x24*x31,\n             x32/x6 - 20646.0*x36*x5 - x38*x5*(2960.0 - 740.0*x28*x29),\n             0.00173611111111111*Vg*rhog*x15*x3*x31*(144.0*C3 - 12.0*x20 + 18.0*x23 + x40*log(x27)),\n             x0*(430.125*x36*x41*x5 - 15.4166666666667*x38*x41*x5*(x30 - 4.0) - 1.0),\n             -1.85*x16*x29*x40*x5/x26,\n             3285600.0*x42*(-x30 + 4.0)*x38*x38- 91668240.0*x42*x36*x36 - 2.0*x32/(dP_irr*x6))\n    \n    return [F1, F2], [[dF1_dVg, dF2_dVg], [dF1_dP_irr, dF2_dP_irr]]", "response": "Internal function which calculates the errors of the two Stichlmair\n    objective functions and their jacobian."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Stichlmair_flood(Vl, rhog, rhol, mug, voidage, specific_area, C1, C2, C3,\n                     H=1.0):\n    r'''Calculates gas rate for flooding of a packed column, using the\n    Stichlmair [1]_ correlation. Uses three regressed constants for each\n    type of packing, and voidage and specific area.\n\n    Pressure drop is given by:\n\n    .. math::\n        \\frac{\\Delta P_{irr}}{H} = \\frac{\\Delta P_{dry}}{H}\\left(\\frac\n        {1-\\epsilon + h_T}{1-\\epsilon}\\right)^{(2+c)/3}\n        \\left(\\frac{\\epsilon}{\\epsilon-h_T}\\right)^{4.65}\n\n    .. math::\n        h_T = h_0\\left[1 + 20\\left(\\frac{\\Delta Pirr}{H\\rho_L g}\\right)^2\\right]\n\n    .. math::\n        Fr_L = \\frac{V_L^2 a}{g \\epsilon^{4.65}}\n\n    .. math::\n        h_0 = 0.555 Fr_L^{1/3}\n\n    .. math::\n        c = \\frac{-C_1/Re_g - C_2/(2Re_g^{0.5})}{f_0}\n\n    .. math::\n        \\Delta P_{dry} = \\frac{3}{4} f_0 \\frac{1-\\epsilon}{\\epsilon^{4.65}}\n        \\rho_G \\frac{H}{d_p}V_g^2\n\n    .. math::\n        f_0 = \\frac{C_1}{Re_g} + \\frac{C_2}{Re_g^{0.5}} + C_3\n\n    .. math::\n        d_p = \\frac{6(1-\\epsilon)}{a}\n\n    Parameters\n    ----------\n    Vl : float\n        Superficial velocity of liquid, Q/A [m/s]\n    rhog : float\n        Density of gas [kg/m^3]\n    rhol : float\n        Density of liquid [kg/m^3]\n    mug : float\n        Viscosity of gas [Pa*s]\n    voidage : float\n        Voidage of bed of packing material []\n    specific_area : float\n        Specific area of the packing material [m^2/m^3]\n    C1 : float\n        Packing-specific constant []\n    C2 : float\n        Packing-specific constant []\n    C3 : float\n        Packing-specific constant []\n    H : float, optional\n        Height of packing [m]\n\n    Returns\n    -------\n    Vg : float\n        Superficial velocity of gas, Q/A [m/s]\n\n    Notes\n    -----\n    A numerical solver is used to solve this model.\n\n    Examples\n    --------\n    Example is from [1]_, matches.\n\n    >>> Stichlmair_flood(Vl = 5E-3, rhog=5., rhol=1200., mug=5E-5,\n    ... voidage=0.68, specific_area=260., C1=32., C2=7., C3=1.)\n    0.6394323542746928\n\n    References\n    ----------\n    .. [1] Stichlmair, J., J. L. Bravo, and J. R. Fair. \"General Model for\n       Prediction of Pressure Drop and Capacity of Countercurrent Gas/liquid\n       Packed Columns.\" Gas Separation & Purification 3, no. 1 (March 1989):\n       19-28. doi:10.1016/0950-4214(89)80016-7.\n    '''\n    guess =  [Vl*100., 1000.0]\n    return newton_system(_Stichlmair_flood_f_and_jac, x0=guess, jac=True,\n                         args=(Vl, rhog, rhol, mug, voidage, specific_area, C1, \n                         C2, C3, H), ytol=1e-11)[0][0]", "response": "r Calculates the gas rate for a packed column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Fahien_Schriver(dp, voidage, vs, rho, mu, L=1):\n    r'''Calculates pressure drop across a packed bed of spheres using a\n    correlation developed in [1]_, as shown in [2]_. Second most accurate\n    correlation overall in the review of [2]_.\n\n    .. math::\n        f_p = \\left(q\\frac{f_{1L}}{Re_{Erg}} + (1-q)\\left(f_2 + \\frac{f_{1T}}\n        {Re_{Erg}}\\right)\\right)\\frac{1-\\epsilon}{\\epsilon^3}\n\n    .. math::\n        q = \\exp\\left(-\\frac{\\epsilon^2(1-\\epsilon)}{12.6}Re_{Erg}\\right)\n\n    .. math::\n        f_{1L}=\\frac{136}{(1-\\epsilon)^{0.38}}\n\n    .. math::\n        f_{1T} = \\frac{29}{(1-\\epsilon)^{1.45}\\epsilon^2}\n\n    .. math::\n        f_2 = \\frac{1.87\\epsilon^{0.75}}{(1-\\epsilon)^{0.26}}\n\n    .. math::\n        f_p = \\frac{\\Delta P d_p}{\\rho v_s^2 L}\n\n    .. math::\n        Re_{Erg} = \\frac{\\rho v_s  d_p}{\\mu(1-\\epsilon)}\n\n    Parameters\n    ----------\n    dp : float\n        Particle diameter of spheres [m]\n    voidage : float\n        Void fraction of bed packing [-]\n    vs : float\n        Superficial velocity of the fluid (volumetric flow rate/cross-sectional \n        area)[m/s]\n    rho : float\n        Density of the fluid [kg/m^3]\n    mu : float\n        Viscosity of the fluid, [Pa*s]\n    L : float, optional\n        Length the fluid flows in the packed bed [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across the bed [Pa]\n\n    Notes\n    -----\n    No range of validity available.\n\n    Examples\n    --------\n    >>> Fahien_Schriver(dp=8E-4, voidage=0.4, vs=1E-3, rho=1E3, mu=1E-3)\n    1470.6175541844711\n\n    References\n    ----------\n    .. [1] R.W. Fahien, C.B. Schriver, Paper presented at the 1961 Denver\n       meeting of AIChE, in: R.W. Fahien, Fundamentals of Transport Phenomena,\n       McGraw-Hill, New York, 1983.\n    .. [2] Erdim, Esra, \u00d6mer Akgiray, and \u0130brahim Demir. \"A Revisit of Pressure\n       Drop-Flow Rate Correlations for Packed Beds of Spheres.\" Powder\n       Technology 283 (October 2015): 488-504. doi:10.1016/j.powtec.2015.06.017.\n    '''\n    Rem = dp*rho*vs/mu/(1-voidage)\n    q = exp(-voidage**2*(1-voidage)/12.6*Rem)\n    f1L = 136/(1-voidage)**0.38\n    f1T = 29/((1-voidage)**1.45*voidage**2)\n    f2 = 1.87*voidage**0.75/(1-voidage)**0.26\n    fp = (q*f1L/Rem + (1-q)*(f2 + f1T/Rem))*(1-voidage)/voidage**3\n    return fp*rho*vs**2*L/dp", "response": "r Fahien - Schriver for the given fluid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Idelchik(dp, voidage, vs, rho, mu, L=1):\n    r'''Calculates pressure drop across a packed bed of spheres as in [2]_,\n    originally in [1]_.\n\n    .. math::\n        \\frac{\\Delta P}{L\\rho v_s^2} d_p  = \\frac{0.765}{\\epsilon^{4.2}}\n        \\left(\\frac{30}{Re_l} + \\frac{3}{Re_l^{0.7}} + 0.3\\right)\n\n    .. math::\n        Re_l = (0.45/\\epsilon^{0.5})Re_{Erg}\n\n    .. math::\n        Re_{Erg} = \\frac{\\rho v_s  D_p}{\\mu(1-\\epsilon)}\n\n    Parameters\n    ----------\n    dp : float\n        Particle diameter of spheres [m]\n    voidage : float\n        Void fraction of bed packing [-]\n    vs : float\n        Superficial velocity of the fluid (volumetric flow rate/cross-sectional \n        area)[m/s]\n    rho : float\n        Density of the fluid [kg/m^3]\n    mu : float\n        Viscosity of the fluid, [Pa*s]\n    L : float, optional\n        Length the fluid flows in the packed bed [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across the bed [Pa]\n\n    Notes\n    -----\n    :math:`0.001 < Re_{Erg} <1000`\n    This equation is valid for void fractions between 0.3 and 0.8. Cited as\n    by Bernshtein.\n\n    Examples\n    --------\n    >>> Idelchik(dp=8E-4, voidage=0.4, vs=1E-3, rho=1E3, mu=1E-3)\n    1571.909125999067\n\n    References\n    ----------\n    .. [1] Idelchik, I. E. Flow Resistance: A Design Guide for Engineers.\n       Hemisphere Publishing Corporation, New York, 1989.\n    .. [2] Allen, K. G., T. W. von Backstrom, and D. G. Kroger. \"Packed Bed\n       Pressure Drop Dependence on Particle Shape, Size Distribution, Packing\n       Arrangement and Roughness.\" Powder Technology 246 (September 2013):\n       590-600. doi:10.1016/j.powtec.2013.06.022.\n    '''\n    Re = rho*vs*dp/mu/(1-voidage)\n    Re = (0.45/voidage**0.5)*Re\n    right = 0.765/voidage**4.2*(30./Re + 3./Re**0.7 + 0.3)\n    left = dp/L/rho/vs**2\n    return right/left", "response": "r Returns a base - level function that calculates the pressure drop across a packed bed of spheres."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Guo_Sun(dp, voidage, vs, rho, mu, Dt, L=1):\n    r'''Calculates pressure drop across a packed bed of spheres using a\n    correlation developed in [1]_. This is valid for highly-packed particles \n    at particle/tube diameter ratios between 2 and 3, where a ring packing \n    structure occurs. If a packing ratio is so low, it is important to use this\n    model because in some cases its predictions are as low as half those of \n    other models!\n\n    .. math::\n        f_v = 180 + \\left(9.5374\\frac{d_p}{D_t} - 2.8054\\right)Re_{Erg}^{0.97}\n        \n    .. math::\n        f_v = \\frac{\\Delta P d_p^2}{\\mu v_s L}\\frac{\\epsilon^3}{(1-\\epsilon)^2}\n\n    .. math::\n        Re_{Erg} = \\frac{\\rho v_s  d_p}{\\mu(1-\\epsilon)}\n\n    Parameters\n    ----------\n    dp : float\n        Particle diameter of spheres [m]\n    voidage : float\n        Void fraction of bed packing [-]\n    vs : float\n        Superficial velocity of the fluid (volumetric flow rate/cross-sectional \n        area)[m/s]\n    rho : float\n        Density of the fluid [kg/m^3]\n    mu : float\n        Viscosity of the fluid, [Pa*s]\n    Dt : float\n        Diameter of the tube, [m]\n    L : float, optional\n        Length the fluid flows in the packed bed [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across the bed [Pa]\n\n    Notes\n    -----\n    Developed with data in the range of:\n\n    .. math::\n        100 < Re_{m} <33000\\\\\n        2 < d_t/d_p < 3 1\\\\\n        0.476 < \\epsilon <0.492\n\n    Examples\n    --------\n    >>> Guo_Sun(dp=14.2E-3, voidage=0.492, vs=0.6, rho=1E3, mu=1E-3, Dt=40.9E-3)\n    42019.529911473706\n    \n    References\n    ----------\n    .. [1] Guo, Zehua, Zhongning Sun, Nan Zhang, Ming Ding, and Jiaqing Liu. \n       \"Pressure Drop in Slender Packed Beds with Novel Packing Arrangement.\" \n       Powder Technology 321 (November 2017): 286-92.\n       doi:10.1016/j.powtec.2017.08.024. \n    '''\n    #  2 < D/d < 3, particles in contact with the wall tend to form a highly ordered ring structure. \n    Rem = dp*rho*vs/mu/(1-voidage)\n    fv = 180 + (9.5374*dp/Dt - 2.8054)*Rem**0.97\n    return fv*(mu*vs*L/dp**2)*(1-voidage)**2/voidage**3", "response": "r Returns a base class for a new a\n    that is a highly - packed particle - packing paper."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dP_packed_bed(dp, voidage, vs, rho, mu, L=1, Dt=None, sphericity=None,\n                  Method=None, AvailableMethods=False):\n    r'''This function handles choosing which pressure drop in a packed bed\n    correlation is used. Automatically select which correlation\n    to use if none is provided. Returns None if insufficient information is\n    provided.\n\n    Preferred correlations are 'Erdim, Akgiray & Demir' when tube\n    diameter is not provided, and 'Harrison, Brunner & Hecker' when tube\n    diameter is provided. If you are using a particles in a narrow tube \n    between 2 and 3 particle diameters, expect higher than normal voidages \n    (0.4-0.5) and used the method 'Guo, Sun, Zhang, Ding & Liu'.\n\n    Examples\n    --------\n    >>> dP_packed_bed(dp=8E-4, voidage=0.4, vs=1E-3, rho=1E3, mu=1E-3)\n    1438.2826958844414\n    >>> dP_packed_bed(dp=8E-4, voidage=0.4, vs=1E-3, rho=1E3, mu=1E-3, Dt=0.01)\n    1255.1625662548427\n    >>> dP_packed_bed(dp=0.05, voidage=0.492, vs=0.1, rho=1E3, mu=1E-3, Dt=0.015, Method='Guo, Sun, Zhang, Ding & Liu')\n    18782.499710673364\n\n    Parameters\n    ----------\n    dp : float\n        Particle diameter of spheres [m]\n    voidage : float\n        Void fraction of bed packing [-]\n    vs : float\n        Superficial velocity of the fluid (volumetric flow rate/cross-sectional \n        area) [m/s]\n    rho : float\n        Density of the fluid [kg/m^3]\n    mu : float\n        Viscosity of the fluid, [Pa*s]\n    L : float, optional\n        Length the fluid flows in the packed bed [m]\n    Dt : float, optional\n        Diameter of the tube, [m]\n    sphericity : float, optional\n        Sphericity of the particles [-]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop across the bed [Pa]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate `dP` with the given inputs\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        A string of the function name to use, as in the dictionary\n        packed_beds_correlations\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate `dP` with the given inputs and return them as a list\n    '''\n    def list_methods():\n        methods = []\n        if all((dp, voidage, vs, rho, mu, L)):\n            for key, values in packed_beds_correlations.items():\n                if Dt or not values[1]:\n                    methods.append(key)\n        if 'Harrison, Brunner & Hecker' in methods:\n            methods.remove('Harrison, Brunner & Hecker')\n            methods.insert(0, 'Harrison, Brunner & Hecker')\n        elif 'Erdim, Akgiray & Demir' in methods:\n            methods.remove('Erdim, Akgiray & Demir')\n            methods.insert(0, 'Erdim, Akgiray & Demir')\n        return methods\n\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        Method = list_methods()[0]\n\n    if dp and sphericity:\n        dp = dp*sphericity\n    if Method in packed_beds_correlations:\n        if packed_beds_correlations[Method][1]:\n            return packed_beds_correlations[Method][0](dp=dp, voidage=voidage, vs=vs, rho=rho, mu=mu, L=L, Dt=Dt)\n        else:\n            return packed_beds_correlations[Method][0](dp=dp, voidage=voidage, vs=vs, rho=rho, mu=mu, L=L)\n    else:\n        raise Exception('Failure in in function')", "response": "r Returns a new packed bed containing the required information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef liquid_jet_pump_ancillary(rhop, rhos, Kp, Ks, d_nozzle=None, d_mixing=None, \n                              Qp=None, Qs=None, P1=None, P2=None):\n    r'''Calculates the remaining variable in a liquid jet pump when solving for\n    one if the inlet variables only and the rest of them are known. The\n    equation comes from conservation of energy and momentum in the mixing\n    chamber.\n    \n    The variable to be solved for must be one of `d_nozzle`, `d_mixing`,\n    `Qp`, `Qs`, `P1`, or `P2`.\n    \n    .. math::\n        P_1 - P_2 = \\frac{1}{2}\\rho_pV_n^2(1+K_p)\n        - \\frac{1}{2}\\rho_s V_3^2(1+K_s)\n        \n    Rearrange to express V3 in terms of Vn, and using the density ratio `C`,  \n    the expression becomes:\n        \n    .. math::\n        P_1 - P_2 = \\frac{1}{2}\\rho_p V_n^2\\left[(1+K_p) - C(1+K_s) \n        \\left(\\frac{MR}{1-R}\\right)^2\\right]\n\n    Using the primary nozzle area and flow rate:\n        \n    .. math::\n        P_1 - P_2 = \\frac{1}{2}\\rho_p \\left(\\frac{Q_p}{A_n}\\right)^2\n        \\left[(1+K_p) - C(1+K_s) \\left(\\frac{MR}{1-R}\\right)^2\\right]\n\n    For `P`, `P2`, `Qs`, and `Qp`, the equation can be rearranged explicitly \n    for them. For `d_mixing` and `d_nozzle`, a bounded solver is used searching\n    between 1E-9 m and 20 times the other diameter which was specified.\n\n    Parameters\n    ----------\n    rhop : float\n        The density of the primary (motive) fluid, [kg/m^3]\n    rhos : float\n        The density of the secondary fluid (drawn from the vacuum chamber),\n        [kg/m^3]\n    Kp : float\n        The primary nozzle loss coefficient, [-]\n    Ks : float\n        The secondary inlet loss coefficient, [-]\n    d_nozzle : float, optional\n        The inside diameter of the primary fluid's nozle, [m]\n    d_mixing : float, optional\n        The diameter of the mixing chamber, [m]\n    Qp : float, optional\n        The volumetric flow rate of the primary fluid, [m^3/s]\n    Qs : float, optional\n        The volumetric flow rate of the secondary fluid, [m^3/s]\n    P1 : float, optional\n        The pressure of the primary fluid entering its nozzle, [Pa]\n    P2 : float, optional\n        The pressure of the secondary fluid at the entry of the ejector, [Pa]\n        \n    Returns\n    -------\n    solution : float\n        The parameter not specified (one of `d_nozzle`, `d_mixing`,\n        `Qp`, `Qs`, `P1`, or `P2`), (units of `m`, `m`, `m^3/s`, `m^3/s`,\n        `Pa`, or `Pa` respectively)\n\n    Notes\n    -----\n    The following SymPy code was used to obtain the analytical formulas (\n    they are not shown here due to their length):\n    \n    >>> from sympy import *\n    >>> A_nozzle, A_mixing, Qs, Qp, P1, P2, rhos, rhop, Ks, Kp = symbols('A_nozzle, A_mixing, Qs, Qp, P1, P2, rhos, rhop, Ks, Kp')\n    >>> R = A_nozzle/A_mixing\n    >>> M = Qs/Qp\n    >>> C = rhos/rhop\n    >>> rhs = rhop/2*(Qp/A_nozzle)**2*((1+Kp) - C*(1 + Ks)*((M*R)/(1-R))**2 )\n    >>> new = Eq(P1 - P2,  rhs)\n    >>> #solve(new, Qp)\n    >>> #solve(new, Qs)\n    >>> #solve(new, P1)\n    >>> #solve(new, P2)\n\n    Examples\n    --------\n    Calculating primary fluid nozzle inlet pressure P1:\n    \n    >>> liquid_jet_pump_ancillary(rhop=998., rhos=1098., Ks=0.11, Kp=.04, \n    ... P2=133600, Qp=0.01, Qs=0.01, d_mixing=0.045, d_nozzle=0.02238)\n    426434.60314398084\n\n    References\n    ----------\n    .. [1] Ejectors and Jet Pumps. Design and Performance for Incompressible \n       Liquid Flow. 85032. ESDU International PLC, 1985.\n    '''\n    unknowns = sum(i is None for i in (d_nozzle, d_mixing, Qs, Qp, P1, P2))\n    if unknowns > 1:\n        raise Exception('Too many unknowns')\n    elif unknowns < 1:\n        raise Exception('Overspecified')\n    C = rhos/rhop\n    \n    if Qp is not None and Qs is not None:\n        M = Qs/Qp\n    if d_nozzle is not None:\n        A_nozzle = pi/4*d_nozzle*d_nozzle\n        if d_mixing is not None:\n            A_mixing = pi/4*d_mixing*d_mixing\n            R = A_nozzle/A_mixing\n            \n    if P1 is None:        \n        return rhop/2*(Qp/A_nozzle)**2*((1+Kp) - C*(1 + Ks)*((M*R)/(1-R))**2 ) + P2\n    elif P2 is None:\n        return -rhop/2*(Qp/A_nozzle)**2*((1+Kp) - C*(1 + Ks)*((M*R)/(1-R))**2 ) + P1\n    elif Qs is None:\n        try:\n            return ((-2*A_nozzle**2*P1 + 2*A_nozzle**2*P2 + Kp*Qp**2*rhop + Qp**2*rhop)/(C*rhop*(Ks + 1)))**0.5*(A_mixing - A_nozzle)/A_nozzle\n        except ValueError:\n            return -1j\n    elif Qp is None:\n        return A_nozzle*((2*A_mixing**2*P1 - 2*A_mixing**2*P2 - 4*A_mixing*A_nozzle*P1 + 4*A_mixing*A_nozzle*P2 + 2*A_nozzle**2*P1 - 2*A_nozzle**2*P2 + C*Ks*Qs**2*rhop + C*Qs**2*rhop)/(rhop*(Kp + 1)))**0.5/(A_mixing - A_nozzle)\n    elif d_nozzle is None:\n        def err(d_nozzle):\n            return P1 - liquid_jet_pump_ancillary(rhop=rhop, rhos=rhos, Kp=Kp, Ks=Ks, d_nozzle=d_nozzle, d_mixing=d_mixing, Qp=Qp, Qs=Qs, \n                              P1=None, P2=P2)\n        return brenth(err, 1E-9, d_mixing*20)\n    elif d_mixing is None:\n        def err(d_mixing):\n            return P1 - liquid_jet_pump_ancillary(rhop=rhop, rhos=rhos, Kp=Kp, Ks=Ks, d_nozzle=d_nozzle, d_mixing=d_mixing, Qp=Qp, Qs=Qs, \n                              P1=None, P2=P2)\n        try:\n            return brenth(err, 1E-9, d_nozzle*20)\n        except:\n            return newton(err, d_nozzle*2)", "response": "r Calculates the remaining variable in a liquid jet pump when solving for a liquid jet pump."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Beggs_Brill(m, x, rhol, rhog, mul, mug, sigma, P, D, angle, roughness=0.0,\n                L=1.0, g=g, acceleration=True):\n    r'''Calculates the two-phase pressure drop according to the Beggs-Brill\n    correlation ([1]_, [2]_, [3]_).\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Mass quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    sigma : float\n        Surface tension, [N/m]\n    P : float\n        Pressure of fluid (used only if `acceleration=True`), [Pa]\n    D : float\n        Diameter of pipe, [m]\n    angle : float\n        The angle of the pipe with respect to the horizontal, [degrees]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n    acceleration : bool\n        Whether or not to include the original acceleration component, [-]\n        \n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    The original acceleration formula is fairly primitive and normally\n    neglected. The model was developed assuming smooth pipe, so leaving\n    `roughness` to zero may be wise.\n    \n    Note this is a \"mechanistic\" pressure drop model - the gravitational \n    pressure drop cannot be separated from the frictional pressure drop.\n\n    Examples\n    --------\n    >>> Beggs_Brill(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... sigma=0.0487, P=1E7, D=0.05, angle=0, roughness=0, L=1)\n    686.9724506803472\n\n    References\n    ----------\n    .. [1] Beggs, D.H., and J.P. Brill. \"A Study of Two-Phase Flow in Inclined \n       Pipes.\" Journal of Petroleum Technology 25, no. 05 (May 1, 1973): \n       607-17. https://doi.org/10.2118/4007-PA.\n    .. [2] Brill, James P., and Howard Dale Beggs. Two-Phase Flow in Pipes,\n       1994.\n    .. [3] Shoham, Ovadia. Mechanistic Modeling of Gas-Liquid Two-Phase Flow in \n       Pipes. Pap/Cdr edition. Richardson, TX: Society of Petroleum Engineers,\n       2006.\n    '''\n    qg = x*m/rhog\n    ql = (1.0 - x)*m/rhol\n    \n    A = 0.25*pi*D*D\n    Vsg = qg/A\n    Vsl = ql/A\n    Vm = Vsg + Vsl\n    Fr = Vm*Vm/(g*D)\n    lambda_L = Vsl/Vm # no slip liquid holdup\n\n    L1 = 316.0*lambda_L**0.302\n    L2 = 0.0009252*lambda_L**-2.4684\n    L3 = 0.1*lambda_L**-1.4516\n    L4 = 0.5*lambda_L**-6.738\n    if (lambda_L < 0.01 and Fr < L1) or (lambda_L >= 0.01 and Fr < L2):\n        regime = 'segregated'\n    elif (lambda_L >= 0.01 and L2 <= Fr <= L3):\n        regime = 'transition'\n    elif (0.01 <= lambda_L < 0.4 and L3 < Fr <= L1) or (lambda_L >= 0.4 and L3 < Fr <= L4):\n        regime = 'intermittent'\n    elif (lambda_L < 0.4 and Fr >= L1) or (lambda_L >= 0.4 and Fr > L4):\n        regime = 'distributed'\n    else:\n        raise Exception('Outside regime ranges')\n\n    LV = Vsl*(rhol/(g*sigma))**0.25\n    angle = radians(angle)\n    \n    def holdup(regime):\n        a, b, c = Beggs_Brill_dat[regime]\n        HL0 = a*lambda_L**b*Fr**-c\n        if HL0 < lambda_L:\n            HL0 = lambda_L\n\n        if angle > 0.0: # uphill\n            # h used instead of g to avoid conflict with gravitational constant\n            if regime == 'segregated':\n                d, e, f, h = 0.011, -3.768, 3.539, -1.614\n            elif regime == 'intermittent':\n                d, e, f, h = 2.96, 0.305, -0.4473, 0.0978\n            elif regime == 'distributed':\n                # Dummy values for distributed - > psi = 1.\n                d, e, f, h = 2.96, 0.305, -0.4473, 0.0978\n        elif angle <= 0: # downhill\n            d, e, f, h = 4.70, -0.3692, 0.1244, -0.5056\n    \n        C = (1.0 - lambda_L)*log(d*lambda_L**e*LV**f*Fr**h)\n        if C < 0.0:\n            C = 0.0\n        \n        # Correction factor for inclination angle\n        Psi = 1.0 + C*(sin(1.8*angle) - 1.0/3.0*sin(1.8*angle)**3)\n        if (angle > 0 and regime == 'distributed') or angle == 0:\n            Psi = 1.0\n        Hl = HL0*Psi\n        return Hl\n    if regime != 'transition':\n        Hl = holdup(regime)\n    else:\n        A = (L3 - Fr)/(L3 - L2)\n        Hl = A*holdup('segregated') + (1.0 - A)*holdup('intermittent')\n\n    rhos = rhol*Hl + rhog*(1.0 - Hl)\n    mum = mul*lambda_L +  mug*(1.0 - lambda_L)\n    rhom = rhol*lambda_L +  rhog*(1.0 - lambda_L)\n    Rem = rhom*D/mum*Vm\n    fn = friction_factor(Re=Rem, eD=roughness/D)\n    x = lambda_L/(Hl*Hl)\n    \n    \n    if 1.0 < x < 1.2:\n        S = log(2.2*x - 1.2)\n    else:\n        logx = log(x)\n        # from horner(-0.0523 + 3.182*log(x) - 0.8725*log(x)**2 + 0.01853*log(x)**4, x)\n        S = logx/(logx*(logx*(0.01853*logx*logx - 0.8725) + 3.182) - 0.0523)\n    if S > 7.0:\n        S = 7.0  # Truncate S to avoid exp(S) overflowing\n    ftp = fn*exp(S)\n    dP_ele = g*sin(angle)*rhos*L\n    dP_fric = ftp*L/D*0.5*rhom*Vm*Vm\n    # rhos here is pretty clearly rhos according to Shoham\n    if not acceleration:\n        dP = dP_ele + dP_fric\n    else:\n        Ek = Vsg*Vm*rhos/P  # Confirmed this expression is dimensionless\n        dP = (dP_ele + dP_fric)/(1.0 - Ek)\n    return dP", "response": "r Calculates the two - phase pressure drop of a single modular system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Friedel(m, x, rhol, rhog, mul, mug, sigma, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Friedel correlation.\n\n    .. math::\n        \\Delta P_{friction} = \\Delta P_{lo} \\phi_{lo}^2\n\n    .. math::\n        \\phi_{lo}^2 = E + \\frac{3.24FH}{Fr^{0.0454} We^{0.035}}\n\n    .. math::\n        H = \\left(\\frac{\\rho_l}{\\rho_g}\\right)^{0.91}\\left(\\frac{\\mu_g}{\\mu_l}\n        \\right)^{0.19}\\left(1 - \\frac{\\mu_g}{\\mu_l}\\right)^{0.7}\n\n    .. math::\n        F = x^{0.78}(1 - x)^{0.224}\n\n    .. math::\n        E = (1-x)^2 + x^2\\left(\\frac{\\rho_l f_{d,go}}{\\rho_g f_{d,lo}}\\right)\n\n    .. math::\n        Fr = \\frac{G_{tp}^2}{gD\\rho_H^2}\n\n    .. math::\n        We = \\frac{G_{tp}^2 D}{\\sigma \\rho_H}\n\n    .. math::\n        \\rho_H = \\left(\\frac{x}{\\rho_g} + \\frac{1-x}{\\rho_l}\\right)^{-1}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    sigma : float\n        Surface tension, [N/m]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Applicable to vertical upflow and horizontal flow. Known to work poorly\n    when mul/mug > 1000. Gives mean errors on the order of 40%. Tested on data\n    with diameters as small as 4 mm.\n\n    The power of 0.0454 is given as 0.045 in [2]_, [3]_, [4]_, and [5]_; [6]_\n    and [2]_ give 0.0454 and [2]_ also gives a similar correlation said to be\n    presented in [1]_, so it is believed this 0.0454 was the original power.\n    [6]_ also gives an expression for friction factor claimed to be presented\n    in [1]_; it is not used here.\n\n    Examples\n    --------\n    Example 4 in [6]_:\n\n    >>> Friedel(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... sigma=0.0487, D=0.05, roughness=0, L=1)\n    738.6500525002245\n\n    References\n    ----------\n    .. [1] Friedel, L. \"Improved Friction Pressure Drop Correlations for\n       Horizontal and Vertical Two-Phase Pipe Flow.\" , in: Proceedings,\n       European Two Phase Flow Group Meeting, Ispra, Italy, 1979: 485-481.\n    .. [2] Whalley, P. B. Boiling, Condensation, and Gas-Liquid Flow. Oxford:\n       Oxford University Press, 1987.\n    .. [3] Triplett, K. A., S. M. Ghiaasiaan, S. I. Abdel-Khalik, A. LeMouel,\n       and B. N. McCord. \"Gas-liquid Two-Phase Flow in Microchannels: Part II:\n       Void Fraction and Pressure Drop.\u201d International Journal of Multiphase\n       Flow 25, no. 3 (April 1999): 395-410. doi:10.1016/S0301-9322(98)00055-X.\n    .. [4] Mekisso, Henock Mateos. \"Comparison of Frictional Pressure Drop\n       Correlations for Isothermal Two-Phase Horizontal Flow.\" Thesis, Oklahoma\n       State University, 2013. https://shareok.org/handle/11244/11109.\n    .. [5] Thome, John R. \"Engineering Data Book III.\" Wolverine Tube Inc\n       (2004). http://www.wlv.com/heat-transfer-databook/\n    .. [6] Ghiaasiaan, S. Mostafa. Two-Phase Flow, Boiling, and Condensation:\n        In Conventional and Miniature Systems. Cambridge University Press, 2007.\n    '''\n    # Liquid-only properties, for calculation of E, dP_lo\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n    fd_lo = friction_factor(Re=Re_lo, eD=roughness/D)\n    dP_lo = fd_lo*L/D*(0.5*rhol*v_lo**2)\n\n    # Gas-only properties, for calculation of E\n    v_go = m/rhog/(pi/4*D**2)\n    Re_go = Reynolds(V=v_go, rho=rhog, mu=mug, D=D)\n    fd_go = friction_factor(Re=Re_go, eD=roughness/D)\n\n    F = x**0.78*(1-x)**0.224\n    H = (rhol/rhog)**0.91*(mug/mul)**0.19*(1 - mug/mul)**0.7\n    E = (1-x)**2 + x**2*(rhol*fd_go/(rhog*fd_lo))\n\n    # Homogeneous properties, for Froude/Weber numbers\n    voidage_h = homogeneous(x, rhol, rhog)\n    rho_h = rhol*(1-voidage_h) + rhog*voidage_h\n    Q_h = m/rho_h\n    v_h = Q_h/(pi/4*D**2)\n\n    Fr = Froude(V=v_h, L=D, squared=True) # checked with (m/(pi/4*D**2))**2/g/D/rho_h**2\n    We = Weber(V=v_h, L=D, rho=rho_h, sigma=sigma) # checked with (m/(pi/4*D**2))**2*D/sigma/rho_h\n\n    phi_lo2 = E + 3.24*F*H/(Fr**0.0454*We**0.035)\n    return phi_lo2*dP_lo", "response": "r Calculates two - phase pressure drop with the Friedel correlation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Chisholm(m, x, rhol, rhog, mul, mug, D, roughness=0, L=1,\n             rough_correction=False):\n    r'''Calculates two-phase pressure drop with the Chisholm (1973) correlation\n    from [1]_, also in [2]_ and [3]_.\n\n    .. math::\n        \\frac{\\Delta P_{tp}}{\\Delta P_{lo}} = \\phi_{ch}^2\n\n    .. math::\n        \\phi_{ch}^2 = 1 + (\\Gamma^2 -1)\\left\\{B x^{(2-n)/2} (1-x)^{(2-n)/2}\n        + x^{2-n} \\right\\}\n\n    .. math::\n        \\Gamma ^2 = \\frac{\\left(\\frac{\\Delta P}{L}\\right)_{go}}{\\left(\\frac{\n        \\Delta P}{L}\\right)_{lo}}\n\n    For Gamma < 9.5:\n\n    .. math::\n        B = \\frac{55}{G_{tp}^{0.5}} \\text{ for } G_{tp} > 1900\n\n    .. math::\n        B = \\frac{2400}{G_{tp}} \\text{ for } 500 < G_{tp} < 1900\n\n    .. math::\n        B = 4.8 \\text{ for } G_{tp} < 500\n\n    For 9.5 < Gamma < 28:\n\n    .. math::\n        B = \\frac{520}{\\Gamma G_{tp}^{0.5}} \\text{ for } G_{tp} < 600\n\n    .. math::\n        B = \\frac{21}{\\Gamma} \\text{ for } G_{tp} > 600\n\n    For Gamma > 28:\n\n    .. math::\n        B = \\frac{15000}{\\Gamma^2 G_{tp}^{0.5}}\n\n    If `rough_correction` is True, the following correction to B is applied:\n\n    .. math::\n        \\frac{B_{rough}}{B_{smooth}} = \\left[0.5\\left\\{1+ \\left(\\frac{\\mu_g}\n        {\\mu_l}\\right)^2 + 10^{-600\\epsilon/D}\\right\\}\\right]^{\\frac{0.25-n}\n        {0.25}}\n\n    .. math::\n        n = \\frac{\\log \\frac{f_{d,lo}}{f_{d,go}}}{\\log \\frac{Re_{go}}{Re_{lo}}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n    rough_correction : bool, optional\n        Whether or not to use the roughness correction proposed in the 1968\n        version of the correlation\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Applicable for  0 < x < 1. n = 0.25, the exponent in the Blassius equation.\n    Originally developed for smooth pipes, a roughness correction is included\n    as well from the Chisholm's 1968 work [4]_. Neither [2]_ nor [3]_ have any\n    mention of the correction however.\n\n    Examples\n    --------\n    >>> Chisholm(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6,\n    ... mug=14E-6, D=0.05, roughness=0, L=1)\n    1084.1489922923738\n\n    References\n    ----------\n    .. [1] Chisholm, D. \"Pressure Gradients due to Friction during the Flow of\n       Evaporating Two-Phase Mixtures in Smooth Tubes and Channels.\"\n       International Journal of Heat and Mass Transfer 16, no. 2 (February\n       1973): 347-58. doi:10.1016/0017-9310(73)90063-X.\n    .. [2] Mekisso, Henock Mateos. \"Comparison of Frictional Pressure Drop\n       Correlations for Isothermal Two-Phase Horizontal Flow.\" Thesis, Oklahoma\n       State University, 2013. https://shareok.org/handle/11244/11109.\n    .. [3] Thome, John R. \"Engineering Data Book III.\" Wolverine Tube Inc\n       (2004). http://www.wlv.com/heat-transfer-databook/\n    .. [4] Chisholm, D. \"Research Note: Influence of Pipe Surface Roughness on\n       Friction Pressure Gradient during Two-Phase Flow.\" Journal of Mechanical\n       Engineering Science 20, no. 6 (December 1, 1978): 353-354.\n       doi:10.1243/JMES_JOUR_1978_020_061_02.\n    '''\n    G_tp = m/(pi/4*D**2)\n    n = 0.25 # Blasius friction factor exponent\n    # Liquid-only properties, for calculation of dP_lo\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n    fd_lo = friction_factor(Re=Re_lo, eD=roughness/D)\n    dP_lo = fd_lo*L/D*(0.5*rhol*v_lo**2)\n\n    # Gas-only properties, for calculation of dP_go\n    v_go = m/rhog/(pi/4*D**2)\n    Re_go = Reynolds(V=v_go, rho=rhog, mu=mug, D=D)\n    fd_go = friction_factor(Re=Re_go, eD=roughness/D)\n    dP_go = fd_go*L/D*(0.5*rhog*v_go**2)\n\n    Gamma = (dP_go/dP_lo)**0.5\n    if Gamma <= 9.5:\n        if G_tp <= 500:\n            B = 4.8\n        elif G_tp < 1900:\n            B = 2400./G_tp\n        else:\n            B = 55*G_tp**-0.5\n    elif Gamma <= 28:\n        if G_tp <= 600:\n            B = 520.*G_tp**-0.5/Gamma\n        else:\n            B = 21./Gamma\n    else:\n        B = 15000.*G_tp**-0.5/Gamma**2\n\n    if rough_correction:\n        n = log(fd_lo/fd_go)/log(Re_go/Re_lo)\n        B_ratio = (0.5*(1 + (mug/mul)**2 + 10**(-600*roughness/D)))**((0.25-n)/0.25)\n        B = B*B_ratio\n\n    phi2_ch = 1 + (Gamma**2-1)*(B*x**((2-n)/2.)*(1-x)**((2-n)/2.) + x**(2-n))\n    return phi2_ch*dP_lo", "response": "r Returns a correlation of two - phase pressure drop with Chisholm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Lombardi_Pedrocchi(m, x, rhol, rhog, sigma, D, L=1):\n    r'''Calculates two-phase pressure drop with the Lombardi-Pedrocchi (1972)\n    correlation from [1]_ as shown in [2]_ and [3]_.\n\n    .. math::\n        \\Delta P_{tp} = \\frac{0.83 G_{tp}^{1.4} \\sigma^{0.4} L}{D^{1.2}\n        \\rho_{h}^{0.866}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    sigma : float\n        Surface tension, [N/m]\n    D : float\n        Diameter of pipe, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    This is a purely empirical method. [3]_ presents a review of this and other\n    correlations. It did not perform best, but there were also correlations\n    worse than it.\n\n    Examples\n    --------\n    >>> Lombardi_Pedrocchi(m=0.6, x=0.1, rhol=915., rhog=2.67, sigma=0.045,\n    ... D=0.05, L=1)\n    1567.328374498781\n\n    References\n    ----------\n    .. [1] Lombardi, C., and E. Pedrocchi. \"Pressure Drop Correlation in Two-\n       Phase Flow.\" Energ. Nucl. (Milan) 19: No. 2, 91-99, January 1, 1972.\n    .. [2] Mekisso, Henock Mateos. \"Comparison of Frictional Pressure Drop\n       Correlations for Isothermal Two-Phase Horizontal Flow.\" Thesis, Oklahoma\n       State University, 2013. https://shareok.org/handle/11244/11109.\n    .. [3] Turgut, O\u011fuz Emrah, Mustafa Turhan \u00c7oban, and Mustafa Asker.\n       \"Comparison of Flow Boiling Pressure Drop Correlations for Smooth\n       Macrotubes.\" Heat Transfer Engineering 37, no. 6 (April 12, 2016):\n       487-506. doi:10.1080/01457632.2015.1060733.\n    '''\n    voidage_h = homogeneous(x, rhol, rhog)\n    rho_h = rhol*(1-voidage_h) + rhog*voidage_h\n    G_tp = m/(pi/4*D**2)\n    return 0.83*G_tp**1.4*sigma**0.4*L/(D**1.2*rho_h**0.866)", "response": "r Calculates two - phase pressure drop with the Lombardi - Pedrocchi."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Theissing(m, x, rhol, rhog, mul, mug, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Theissing (1980)\n    correlation as shown in [2]_ and [3]_.\n\n    .. math::\n        \\Delta P_{{tp}} = \\left[ {\\Delta P_{{lo}}^{{1/{n\\epsilon}}} \\left({1 -\n        x} \\right)^{{1/\\epsilon}} + \\Delta P_{{go}}^{{1/\n        {(n\\epsilon)}}} x^{{1/\\epsilon}}} \\right]^{n\\epsilon}\n\n    .. math::\n        \\epsilon = 3 - 2\\left({\\frac{{2\\sqrt {{{\\rho_{{l}}}/\n        {\\rho_{{g}}}}}}}{{1 + {{\\rho_{{l}}}/{\\rho_{{g}}}}}}}\n        \\right)^{{{0.7}/n}}\n\n    .. math::\n        n = \\frac{{n_1 + n_2 \\left({{{\\Delta P_{{g}}}/{\\Delta\n        P_{{l}}}}} \\right)^{0.1}}}{{1 + \\left({{{\\Delta P_{{g}}} /\n        {\\Delta P_{{l}}}}} \\right)^{0.1}}}\n\n    .. math::\n        n_1 = \\frac{{\\ln \\left({{{\\Delta P_{{l}}}/\n        {\\Delta P_{{lo}}}}} \\right)}}{{\\ln \\left({1 - x} \\right)}}\n\n    .. math::\n        n_2 = \\frac{\\ln \\left({\\Delta P_{{g}} / \\Delta P_{{go}}}\n        \\right)}{{\\ln x}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Applicable for 0 < x < 1. Notable, as it can be used for two-phase liquid-\n    liquid flow as well as liquid-gas flow.\n\n    Examples\n    --------\n    >>> Theissing(m=0.6, x=.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... D=0.05, roughness=0, L=1)\n    497.6156370699528\n\n    References\n    ----------\n    .. [1] Theissing, Peter. \"Eine Allgemeing\u00fcltige Methode Zur Berechnung Des\n       Reibungsdruckverlustes Der Mehrphasenstr\u00f6mung (A Generally Valid Method\n       for Calculating Frictional Pressure Drop on Multiphase Flow).\" Chemie\n       Ingenieur Technik 52, no. 4 (January 1, 1980): 344-345.\n       doi:10.1002/cite.330520414.\n    .. [2] Mekisso, Henock Mateos. \"Comparison of Frictional Pressure Drop\n       Correlations for Isothermal Two-Phase Horizontal Flow.\" Thesis, Oklahoma\n       State University, 2013. https://shareok.org/handle/11244/11109.\n    .. [3] Greco, A., and G. P. Vanoli. \"Experimental Two-Phase Pressure\n       Gradients during Evaporation of Pure and Mixed Refrigerants in a Smooth\n       Horizontal Tube. Comparison with Correlations.\" Heat and Mass Transfer\n       42, no. 8 (April 6, 2006): 709-725. doi:10.1007/s00231-005-0020-7.\n    '''\n    # Liquid-only flow\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n    fd_lo = friction_factor(Re=Re_lo, eD=roughness/D)\n    dP_lo = fd_lo*L/D*(0.5*rhol*v_lo**2)\n\n    # Gas-only flow\n    v_go = m/rhog/(pi/4*D**2)\n    Re_go = Reynolds(V=v_go, rho=rhog, mu=mug, D=D)\n    fd_go = friction_factor(Re=Re_go, eD=roughness/D)\n    dP_go = fd_go*L/D*(0.5*rhog*v_go**2)\n\n    # Handle x = 0, x=1:\n    if x == 0:\n        return dP_lo\n    elif x == 1:\n        return dP_go\n\n    # Actual Liquid flow\n    v_l = m*(1-x)/rhol/(pi/4*D**2)\n    Re_l = Reynolds(V=v_l, rho=rhol, mu=mul, D=D)\n    fd_l = friction_factor(Re=Re_l, eD=roughness/D)\n    dP_l = fd_l*L/D*(0.5*rhol*v_l**2)\n\n    # Actual gas flow\n    v_g = m*x/rhog/(pi/4*D**2)\n    Re_g = Reynolds(V=v_g, rho=rhog, mu=mug, D=D)\n    fd_g = friction_factor(Re=Re_g, eD=roughness/D)\n    dP_g = fd_g*L/D*(0.5*rhog*v_g**2)\n\n    # The model\n    n1 = log(dP_l/dP_lo)/log(1.-x)\n    n2 = log(dP_g/dP_go)/log(x)\n    n = (n1 + n2*(dP_g/dP_l)**0.1)/(1 + (dP_g/dP_l)**0.1)\n    epsilon = 3 - 2*(2*(rhol/rhog)**0.5/(1.+rhol/rhog))**(0.7/n)\n    dP = (dP_lo**(1./(n*epsilon))*(1-x)**(1./epsilon)\n          + dP_go**(1./(n*epsilon))*x**(1./epsilon))**(n*epsilon)\n    return dP", "response": "r Calculates two - phase pressure drop with the Theissing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Tran(m, x, rhol, rhog, mul, mug, sigma, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Tran (2000) correlation,\n    also shown in [2]_ and [3]_.\n\n    .. math::\n        \\Delta P = dP_{lo} \\phi_{lo}^2\n\n    .. math::\n        \\phi_{lo}^2 = 1 + (4.3\\Gamma^2-1)[\\text{Co} \\cdot x^{0.875}\n        (1-x)^{0.875}+x^{1.75}]\n\n    .. math::\n        \\Gamma ^2 = \\frac{\\left(\\frac{\\Delta P}{L}\\right)_{go}}{\\left(\\frac\n        {\\Delta P}{L}\\right)_{lo}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    sigma : float\n        Surface tension, [N/m]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Developed for boiling refrigerants in channels with hydraulic diameters of\n    2.4 mm to 2.92 mm.\n\n    Examples\n    --------\n    >>> Tran(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... sigma=0.0487, D=0.05, roughness=0, L=1)\n    423.2563312951232\n\n    References\n    ----------\n    .. [1] Tran, T. N, M. -C Chyu, M. W Wambsganss, and D. M France. \"Two-Phase\n       Pressure Drop of Refrigerants during Flow Boiling in Small Channels: An\n       Experimental Investigation and Correlation Development.\" International\n       Journal of Multiphase Flow 26, no. 11 (November 1, 2000): 1739-54.\n       doi:10.1016/S0301-9322(99)00119-6.\n    .. [2] Kim, Sung-Min, and Issam Mudawar. \"Universal Approach to Predicting\n       Two-Phase Frictional Pressure Drop for Adiabatic and Condensing Mini/\n       Micro-Channel Flows.\" International Journal of Heat and Mass Transfer\n       55, no. 11\u201312 (May 2012): 3246-61.\n       doi:10.1016/j.ijheatmasstransfer.2012.02.047.\n    .. [3] Choi, Kwang-Il, A. S. Pamitran, Chun-Young Oh, and Jong-Taek Oh.\n       \"Two-Phase Pressure Drop of R-410A in Horizontal Smooth Minichannels.\"\n       International Journal of Refrigeration 31, no. 1 (January 2008): 119-29.\n       doi:10.1016/j.ijrefrig.2007.06.006.\n    '''\n    # Liquid-only properties, for calculation of dP_lo\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n    fd_lo = friction_factor(Re=Re_lo, eD=roughness/D)\n    dP_lo = fd_lo*L/D*(0.5*rhol*v_lo**2)\n\n    # Gas-only properties, for calculation of dP_go\n    v_go = m/rhog/(pi/4*D**2)\n    Re_go = Reynolds(V=v_go, rho=rhog, mu=mug, D=D)\n    fd_go = friction_factor(Re=Re_go, eD=roughness/D)\n    dP_go = fd_go*L/D*(0.5*rhog*v_go**2)\n\n    Gamma2 = dP_go/dP_lo\n    Co = Confinement(D=D, rhol=rhol, rhog=rhog, sigma=sigma)\n    phi_lo2 = 1 + (4.3*Gamma2 -1)*(Co*x**0.875*(1-x)**0.875 + x**1.75)\n    return dP_lo*phi_lo2", "response": "r Returns a base - 2 - phase pressure drop with the Tran correlation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Bankoff(m, x, rhol, rhog, mul, mug, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Bankoff (1960) correlation,\n    as shown in [2]_, [3]_, and [4]_.\n\n    .. math::\n        \\Delta P_{tp} = \\phi_{l}^{7/4} \\Delta P_{l}\n\n    .. math::\n        \\phi_l = \\frac{1}{1-x}\\left[1 - \\gamma\\left(1 - \\frac{\\rho_g}{\\rho_l}\n        \\right)\\right]^{3/7}\\left[1 + x\\left(\\frac{\\rho_l}{\\rho_g} - 1\\right)\n        \\right]\n\n    .. math::\n        \\gamma = \\frac{0.71 + 2.35\\left(\\frac{\\rho_g}{\\rho_l}\\right)}\n        {1 + \\frac{1-x}{x} \\cdot \\frac{\\rho_g}{\\rho_l}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    This correlation is not actually shown in [1]_. Its origin is unknown.\n    The author recommends against using this.\n\n    Examples\n    --------\n    >>> Bankoff(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... D=0.05, roughness=0, L=1)\n    4746.059442453399\n\n    References\n    ----------\n    .. [1] Bankoff, S. G. \"A Variable Density Single-Fluid Model for Two-Phase\n       Flow With Particular Reference to Steam-Water Flow.\" Journal of Heat\n       Transfer 82, no. 4 (November 1, 1960): 265-72. doi:10.1115/1.3679930.\n    .. [2] Thome, John R. \"Engineering Data Book III.\" Wolverine Tube Inc\n       (2004). http://www.wlv.com/heat-transfer-databook/\n    .. [3] Moreno Quib\u00e9n, Jes\u00fas. \"Experimental and Analytical Study of Two-\n       Phase Pressure Drops during Evaporation in Horizontal Tubes,\" 2005.\n       doi:10.5075/epfl-thesis-3337.\n    .. [4] Mekisso, Henock Mateos. \"Comparison of Frictional Pressure Drop\n       Correlations for Isothermal Two-Phase Horizontal Flow.\" Thesis, Oklahoma\n       State University, 2013. https://shareok.org/handle/11244/11109.\n    '''\n    # Liquid-only properties, for calculation of dP_lo\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n    fd_lo = friction_factor(Re=Re_lo, eD=roughness/D)\n    dP_lo = fd_lo*L/D*(0.5*rhol*v_lo**2)\n\n    gamma = (0.71 + 2.35*rhog/rhol)/(1. + (1.-x)/x*rhog/rhol)\n    phi_Bf = 1./(1.-x)*(1 - gamma*(1 - rhog/rhol))**(3/7.)*(1. + x*(rhol/rhog -1.))\n    return dP_lo*phi_Bf**(7/4.)", "response": "r Calculates two - phase pressure drop of a single class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Wang_Chiang_Lu(m, x, rhol, rhog, mul, mug, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Wang, Chiang, and Lu (1997)\n    correlation given in [1]_ and reviewed in [2]_ and [3]_.\n\n    .. math::\n        \\Delta P = \\Delta P_{g} \\phi_g^2\n\n    .. math::\n        \\phi_g^2 = 1 + 9.397X^{0.62} + 0.564X^{2.45} \\text{ for } G >= 200 kg/m^2/s\n\n    .. math::\n        \\phi_g^2 = 1 + CX + X^2 \\text{ for lower mass fluxes}\n\n    .. math::\n        C = 0.000004566X^{0.128}Re_{lo}^{0.938}\\left(\\frac{\\rho_l}{\\rho_g}\n        \\right)^{-2.15}\\left(\\frac{\\mu_l}{\\mu_g}\\right)^{5.1}\n\n    .. math::\n        X^2 = \\frac{\\Delta P_l}{\\Delta P_g}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n\n    Examples\n    --------\n    >>> Wang_Chiang_Lu(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6,\n    ... mug=14E-6, D=0.05, roughness=0, L=1)\n    448.29981978639154\n\n    References\n    ----------\n    .. [1] Wang, Chi-Chuan, Ching-Shan Chiang, and Ding-Chong Lu. \"Visual\n       Observation of Two-Phase Flow Pattern of R-22, R-134a, and R-407C in a\n       6.5-Mm Smooth Tube.\" Experimental Thermal and Fluid Science 15, no. 4\n       (November 1, 1997): 395-405. doi:10.1016/S0894-1777(97)00007-1.\n    .. [2] Kim, Sung-Min, and Issam Mudawar. \"Universal Approach to Predicting\n       Two-Phase Frictional Pressure Drop for Adiabatic and Condensing Mini/\n       Micro-Channel Flows.\" International Journal of Heat and Mass Transfer\n       55, no. 11-12 (May 2012): 3246-61.\n       doi:10.1016/j.ijheatmasstransfer.2012.02.047.\n    .. [3] Xu, Yu, Xiande Fang, Xianghui Su, Zhanru Zhou, and Weiwei Chen.\n       \"Evaluation of Frictional Pressure Drop Correlations for Two-Phase Flow\n       in Pipes.\" Nuclear Engineering and Design, SI\u202f: CFD4NRS-3, 253 (December\n       2012): 86-97. doi:10.1016/j.nucengdes.2012.08.007.\n    '''\n    G_tp = m/(pi/4*D**2)\n\n    # Actual Liquid flow\n    v_l = m*(1-x)/rhol/(pi/4*D**2)\n    Re_l = Reynolds(V=v_l, rho=rhol, mu=mul, D=D)\n    fd_l = friction_factor(Re=Re_l, eD=roughness/D)\n    dP_l = fd_l*L/D*(0.5*rhol*v_l**2)\n\n    # Actual gas flow\n    v_g = m*x/rhog/(pi/4*D**2)\n    Re_g = Reynolds(V=v_g, rho=rhog, mu=mug, D=D)\n    fd_g = friction_factor(Re=Re_g, eD=roughness/D)\n    dP_g = fd_g*L/D*(0.5*rhog*v_g**2)\n\n    X = (dP_l/dP_g)**0.5\n\n    if G_tp >= 200:\n        phi_g2 = 1 + 9.397*X**0.62 + 0.564*X**2.45\n    else:\n        # Liquid-only flow; Re_lo is oddly needed\n        v_lo = m/rhol/(pi/4*D**2)\n        Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n        C = 0.000004566*X**0.128*Re_lo**0.938*(rhol/rhog)**-2.15*(mul/mug)**5.1\n        phi_g2 = 1 + C*X + X**2\n    return dP_g*phi_g2", "response": "r Calculates two - phase pressure drop with the Wang Chiang and Lu."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Hwang_Kim(m, x, rhol, rhog, mul, mug, sigma, D, roughness=0, L=1):\n    r'''Calculates two-phase pressure drop with the Hwang and Kim (2006)\n    correlation as in [1]_, also presented in [2]_ and [3]_.\n\n    .. math::\n        \\Delta P = \\Delta P_{l} \\phi_{l}^2\n\n    .. math::\n        C = 0.227 Re_{lo}^{0.452} X^{-0.32} Co^{-0.82}\n\n    .. math::\n        \\phi_l^2 = 1 + \\frac{C}{X} + \\frac{1}{X^2}\n\n    .. math::\n        X^2 = \\frac{\\Delta P_l}{\\Delta P_g}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    sigma : float\n        Surface tension, [N/m]\n    D : float\n        Diameter of pipe, [m]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Developed with data for microtubes of diameter 0.244 mm and 0.792 mm only.\n    Not likely to be suitable to larger diameters.\n\n    Examples\n    --------\n    >>> Hwang_Kim(m=0.0005, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... sigma=0.0487, D=0.003, roughness=0, L=1)\n    798.302774184557\n\n    References\n    ----------\n    .. [1] Hwang, Yun Wook, and Min Soo Kim. \"The Pressure Drop in Microtubes\n       and the Correlation Development.\"  International Journal of Heat and\n       Mass Transfer 49, no. 11-12 (June 2006): 1804-12.\n       doi:10.1016/j.ijheatmasstransfer.2005.10.040.\n    .. [2] Kim, Sung-Min, and Issam Mudawar. \"Universal Approach to Predicting\n       Two-Phase Frictional Pressure Drop for Adiabatic and Condensing Mini/\n       Micro-Channel Flows.\" International Journal of Heat and Mass Transfer\n       55, no. 11-12 (May 2012): 3246-61.\n       doi:10.1016/j.ijheatmasstransfer.2012.02.047.\n    .. [3] Xu, Yu, Xiande Fang, Xianghui Su, Zhanru Zhou, and Weiwei Chen.\n       \"Evaluation of Frictional Pressure Drop Correlations for Two-Phase Flow\n       in Pipes.\" Nuclear Engineering and Design, SI\u202f: CFD4NRS-3, 253 (December\n       2012): 86-97. doi:10.1016/j.nucengdes.2012.08.007.\n    '''\n    # Liquid-only flow\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n\n    # Actual Liquid flow\n    v_l = m*(1-x)/rhol/(pi/4*D**2)\n    Re_l = Reynolds(V=v_l, rho=rhol, mu=mul, D=D)\n    fd_l = friction_factor(Re=Re_l, eD=roughness/D)\n    dP_l = fd_l*L/D*(0.5*rhol*v_l**2)\n\n    # Actual gas flow\n    v_g = m*x/rhog/(pi/4*D**2)\n    Re_g = Reynolds(V=v_g, rho=rhog, mu=mug, D=D)\n    fd_g = friction_factor(Re=Re_g, eD=roughness/D)\n    dP_g = fd_g*L/D*(0.5*rhog*v_g**2)\n\n    # Actual model\n    X = (dP_l/dP_g)**0.5\n    Co = Confinement(D=D, rhol=rhol, rhog=rhog, sigma=sigma)\n    C = 0.227*Re_lo**0.452*X**-0.320*Co**-0.820\n    phi_l2 = 1 + C/X + 1./X**2\n    return dP_l*phi_l2", "response": "r Hwang and Kim is a wrapper for the Hwang_Kim function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Kim_Mudawar(m, x, rhol, rhog, mul, mug, sigma, D, L=1):\n    r'''Calculates two-phase pressure drop with the Kim and Mudawar (2012)\n    correlation as in [1]_, also presented in [2]_.\n\n    .. math::\n        \\Delta P = \\Delta P_{l} \\phi_{l}^2\n\n    .. math::\n        \\phi_l^2 = 1 + \\frac{C}{X} + \\frac{1}{X^2}\n\n    .. math::\n        X^2 = \\frac{\\Delta P_l}{\\Delta P_g}\n\n    For turbulent liquid, turbulent gas:\n\n    .. math::\n        C = 0.39Re_{lo}^{0.03} Su_{go}^{0.10}\\left(\\frac{\\rho_l}{\\rho_g}\n        \\right)^{0.35}\n\n    For turbulent liquid, laminar gas:\n\n    .. math::\n        C = 8.7\\times 10^{-4} Re_{lo}^{0.17} Su_{go}^{0.50}\\left(\\frac{\\rho_l}\n        {\\rho_g}\\right)^{0.14}\n\n    For laminar liquid, turbulent gas:\n\n    .. math::\n        C = 0.0015 Re_{lo}^{0.59} Su_{go}^{0.19}\\left(\\frac{\\rho_l}{\\rho_g}\n        \\right)^{0.36}\n\n    For laminar liquid, laminar gas:\n\n    .. math::\n        C = 3.5\\times 10^{-5} Re_{lo}^{0.44} Su_{go}^{0.50}\\left(\\frac{\\rho_l}\n        {\\rho_g}\\right)^{0.48}\n\n    This model has its own friction factor calculations, to be consistent with\n    its Reynolds number transition. As their model was regressed with these\n    equations, more error is obtained when using any other friction factor\n    calculation. The laminar equation 64/Re is used up to Re=2000, then the\n    Blasius equation with a coefficient of 0.316, and above Re = 20000,\n\n    .. math::\n        f_d = \\frac{0.184}{Re^{0.2}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    sigma : float\n        Surface tension, [N/m]\n    D : float\n        Diameter of pipe, [m]\n    L : float, optional\n        Length of pipe, [m]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    The critical Reynolds number in this model is 2000, with a Reynolds number\n    definition using actual liquid and gas flows. This model also requires\n    liquid-only Reynolds number to be calculated.\n\n    No attempt to incorporate roughness into the model was made in [1]_.\n\n    The model was developed with hydraulic diameter from 0.0695 to 6.22 mm,\n    mass velocities 4 to 8528 kg/m^2/s, flow qualities from 0 to 1, reduced\n    pressures from 0.0052 to 0.91, superficial liquid Reynolds numbers up to\n    79202, superficial gas Reynolds numbers up to 253810, liquid-only Reynolds\n    numbers up to 89798, 7115 data points from 36 sources and working fluids\n    air, CO2, N2, water, ethanol, R12, R22, R134a, R236ea, R245fa, R404A, R407C,\n    propane, methane, and ammonia.\n\n    Examples\n    --------\n    >>> Kim_Mudawar(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6, mug=14E-6,\n    ... sigma=0.0487, D=0.05, L=1)\n    840.4137796786074\n\n    References\n    ----------\n    .. [1] Kim, Sung-Min, and Issam Mudawar. \"Universal Approach to Predicting\n       Two-Phase Frictional Pressure Drop for Adiabatic and Condensing Mini/\n       Micro-Channel Flows.\" International Journal of Heat and Mass Transfer\n       55, no. 11-12 (May 2012): 3246-61.\n       doi:10.1016/j.ijheatmasstransfer.2012.02.047.\n    .. [2] Kim, Sung-Min, and Issam Mudawar. \"Review of Databases and\n       Predictive Methods for Pressure Drop in Adiabatic, Condensing and\n       Boiling Mini/Micro-Channel Flows.\" International Journal of Heat and\n       Mass Transfer 77 (October 2014): 74-97.\n       doi:10.1016/j.ijheatmasstransfer.2014.04.035.\n    '''\n    def friction_factor(Re):\n        if Re < 2000:\n            return 64./Re\n        elif Re < 20000:\n            return 0.316*Re**-0.25\n        else:\n            return 0.184*Re**-0.2\n\n    # Actual Liquid flow\n    v_l = m*(1-x)/rhol/(pi/4*D**2)\n    Re_l = Reynolds(V=v_l, rho=rhol, mu=mul, D=D)\n    fd_l = friction_factor(Re=Re_l)\n    dP_l = fd_l*L/D*(0.5*rhol*v_l**2)\n\n    # Actual gas flow\n    v_g = m*x/rhog/(pi/4*D**2)\n    Re_g = Reynolds(V=v_g, rho=rhog, mu=mug, D=D)\n    fd_g = friction_factor(Re=Re_g)\n    dP_g = fd_g*L/D*(0.5*rhog*v_g**2)\n\n    # Liquid-only flow\n    v_lo = m/rhol/(pi/4*D**2)\n    Re_lo = Reynolds(V=v_lo, rho=rhol, mu=mul, D=D)\n\n    Su = Suratman(L=D, rho=rhog, mu=mug, sigma=sigma)\n    X = (dP_l/dP_g)**0.5\n    Re_c = 2000 # Transition Reynolds number\n\n    if Re_l < Re_c and Re_g < Re_c:\n        C = 3.5E-5*Re_lo**0.44*Su**0.5*(rhol/rhog)**0.48\n    elif Re_l < Re_c and Re_g >= Re_c:\n        C = 0.0015*Re_lo**0.59*Su**0.19*(rhol/rhog)**0.36\n    elif Re_l >= Re_c and Re_g < Re_c:\n        C = 8.7E-4*Re_lo**0.17*Su**0.5*(rhol/rhog)**0.14\n    else: # Turbulent case\n        C = 0.39*Re_lo**0.03*Su**0.10*(rhol/rhog)**0.35\n\n    phi_l2 = 1 + C/X + 1./X**2\n    return dP_l*phi_l2", "response": "r A model that calculates two - phase pressure drop with the Kim and Mudawar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Lockhart_Martinelli(m, x, rhol, rhog, mul, mug, D, L=1, Re_c=2000):\n    r'''Calculates two-phase pressure drop with the Lockhart and Martinelli\n    (1949) correlation as presented in non-graphical form by Chisholm (1967).\n\n    .. math::\n        \\Delta P = \\Delta P_{l} \\phi_{l}^2\n\n    .. math::\n        \\phi_l^2 = 1 + \\frac{C}{X} + \\frac{1}{X^2}\n\n    .. math::\n        X^2 = \\frac{\\Delta P_l}{\\Delta P_g}\n\n    +---------+---------+--+\n    |Liquid   |Gas      |C |\n    +=========+=========+==+\n    |Turbulent|Turbulent|20|\n    +---------+---------+--+\n    |Laminar  |Turbulent|12|\n    +---------+---------+--+\n    |Turbulent|Laminar  |10|\n    +---------+---------+--+\n    |Laminar  |Laminar  |5 |\n    +---------+---------+--+\n\n    This model has its own friction factor calculations, to be consistent with\n    its Reynolds number transition and the procedure specified in the original\n    work. The equation 64/Re is used up to Re_c, and above it the Blasius\n    equation is used as follows:\n\n    .. math::\n        f_d = \\frac{0.184}{Re^{0.2}}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    L : float, optional\n        Length of pipe, [m]\n    Re_c : float, optional\n        Transition Reynolds number, used to decide which friction factor\n        equation to use and which C value to use from the table above.\n\n    Returns\n    -------\n    dP : float\n        Pressure drop of the two-phase flow, [Pa]\n\n    Notes\n    -----\n    Developed for horizontal flow. Very popular. Many implementations of this\n    model assume turbulent-turbulent flow.\n\n    The original model proposed that the transition Reynolds number was 1000\n    for laminar flow, and 2000 for turbulent flow; it proposed no model\n    for Re_l < 1000 and Re_g between 1000 and 2000 and also Re_g < 1000 and\n    Re_l between 1000 and 2000.\n\n    No correction is available in this model for rough pipe.\n\n    [3]_ examined the original data in [1]_ again, and fit more curves to the\n    data, separating them into different flow regimes. There were 229 datum\n    in the turbulent-turbulent regime, 9 in the turbulent-laminar regime, 339\n    in the laminar-turbulent regime, and 42 in the laminar-laminar regime.\n    Errors from [3]_'s curves were 13.4%, 3.5%, 14.3%, and 12.0% for the above\n    regimes, respectively. [2]_'s fits provide further error.\n\n    Examples\n    --------\n    >>> Lockhart_Martinelli(m=0.6, x=0.1, rhol=915., rhog=2.67, mul=180E-6,\n    ... mug=14E-6, D=0.05, L=1)\n    716.4695654888484\n\n    References\n    ----------\n    .. [1] Lockhart, R. W. & Martinelli, R. C. (1949), \"Proposed correlation of\n       data for isothermal two-phase, two-component flow in pipes\", Chemical\n       Engineering Progress 45 (1), 39-48.\n    .. [2] Chisholm, D.\"A Theoretical Basis for the Lockhart-Martinelli\n       Correlation for Two-Phase Flow.\" International Journal of Heat and Mass\n       Transfer 10, no. 12 (December 1967): 1767-78.\n       doi:10.1016/0017-9310(67)90047-6.\n    .. [3] Cui, Xiaozhou, and John J. J. Chen.\"A Re-Examination of the Data of\n       Lockhart-Martinelli.\" International Journal of Multiphase Flow 36, no.\n       10 (October 2010): 836-46. doi:10.1016/j.ijmultiphaseflow.2010.06.001.\n    .. [4] Kim, Sung-Min, and Issam Mudawar. \"Universal Approach to Predicting\n       Two-Phase Frictional Pressure Drop for Adiabatic and Condensing Mini/\n       Micro-Channel Flows.\" International Journal of Heat and Mass Transfer\n       55, no. 11-12 (May 2012): 3246-61.\n       doi:10.1016/j.ijheatmasstransfer.2012.02.047.\n    '''\n    def friction_factor(Re):\n        # As in the original model\n        if Re < Re_c:\n            return 64./Re\n        else:\n            return 0.184*Re**-0.2\n\n    v_l = m*(1-x)/rhol/(pi/4*D**2)\n    Re_l = Reynolds(V=v_l, rho=rhol, mu=mul, D=D)\n    v_g = m*x/rhog/(pi/4*D**2)\n    Re_g = Reynolds(V=v_g, rho=rhog, mu=mug, D=D)\n\n    if Re_l < Re_c and Re_g < Re_c:\n        C = 5.0\n    elif Re_l < Re_c and Re_g >= Re_c:\n        # Liquid laminar, gas turbulent\n        C = 12.0\n    elif Re_l >= Re_c and Re_g < Re_c:\n        # Liquid turbulent, gas laminar\n        C = 10.0\n    else: # Turbulent case\n        C = 20.0\n\n    fd_l = friction_factor(Re=Re_l)\n    dP_l = fd_l*L/D*(0.5*rhol*v_l**2)\n    fd_g = friction_factor(Re=Re_g)\n    dP_g = fd_g*L/D*(0.5*rhog*v_g**2)\n\n    X = (dP_l/dP_g)**0.5\n\n    phi_l2 = 1 + C/X + 1./X**2\n    return dP_l*phi_l2", "response": "rCalculates two - phase pressure drop with the Lockhart and Martinelli model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef two_phase_dP_acceleration(m, D, xi, xo, alpha_i, alpha_o, rho_li, rho_gi,  \n                              rho_lo=None, rho_go=None):\n    r'''This function handles calculation of two-phase liquid-gas pressure drop\n    due to acceleration for flow inside channels. This is a discrete \n    calculation for a segment with a known difference in quality (and ideally\n    known inlet and outlet pressures so density dependence can be included). \n    \n    .. math::\n        \\Delta P_{acc} = G^2\\left\\{\\left[\\frac{(1-x_o)^2}{\\rho_{l,o}\n        (1-\\alpha_o)} + \\frac{x_o^2}{\\rho_{g,o}\\alpha_o} \\right]\n        - \\left[\\frac{(1-x_i)^2}{\\rho_{l,i}(1-\\alpha_i)} \n        + \\frac{x_i^2}{\\rho_{g,i}\\alpha_i} \\right]\\right\\}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    D : float\n        Diameter of pipe, [m]\n    xi : float\n        Quality of fluid at inlet, [-]\n    xo : float\n        Quality of fluid at outlet, [-]\n    alpha_i : float\n        Void fraction at inlet (area of gas / total area of channel), [-]\n    alpha_o : float\n        Void fraction at outlet (area of gas / total area of channel), [-]\n    rho_li : float\n        Liquid phase density at inlet, [kg/m^3]\n    rho_gi : float\n        Gas phase density at inlet, [kg/m^3]\n    rho_lo : float, optional\n        Liquid phase density at outlet, [kg/m^3]\n    rho_go : float, optional\n        Gas phase density at outlet, [kg/m^3]\n\n    Returns\n    -------\n    dP : float\n        Acceleration component of pressure drop for two-phase flow, [Pa]\n        \n    Notes\n    -----\n    The use of different gas and liquid phase densities at the inlet and outlet\n    is optional; the outlet densities conditions will be assumed to be those of\n    the inlet if they are not specified.\n    \n    There is a continuous variant of this method which can be integrated over,\n    at the expense of a speed. The differential form of this is as follows \n    ([1]_, [3]_):\n        \n    .. math::\n        - \\left(\\frac{d P}{dz}\\right)_{acc} = G^2 \\frac{d}{dz} \\left[\\frac{\n        (1-x)^2}{\\rho_l(1-\\alpha)} + \\frac{x^2}{\\rho_g\\alpha}\\right]\n\n    Examples\n    --------\n    >>> two_phase_dP_acceleration(m=1, D=0.1, xi=0.372, xo=0.557, rho_li=827.1,\n    ... rho_gi=3.919, alpha_i=0.992, alpha_o=0.996)\n    706.8560377214725\n    \n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Awad, M. M., and Y. S. Muzychka. \"Effective Property Models for \n       Homogeneous Two-Phase Flows.\" Experimental Thermal and Fluid Science 33,\n       no. 1 (October 1, 2008): 106-13. \n       doi:10.1016/j.expthermflusci.2008.07.006.\n    .. [3] Kim, Sung-Min, and Issam Mudawar. \"Review of Databases and\n       Predictive Methods for Pressure Drop in Adiabatic, Condensing and\n       Boiling Mini/Micro-Channel Flows.\" International Journal of Heat and\n       Mass Transfer 77 (October 2014): 74-97.\n       doi:10.1016/j.ijheatmasstransfer.2014.04.035.\n    '''\n    G = 4*m/(pi*D*D)\n    if rho_lo is None:\n        rho_lo = rho_li\n    if rho_go is None:\n        rho_go = rho_gi\n    in_term = (1.-xi)**2/(rho_li*(1.-alpha_i)) + xi*xi/(rho_gi*alpha_i)\n    out_term = (1.-xo)**2/(rho_lo*(1.-alpha_o)) + xo*xo/(rho_go*alpha_o)\n    return G*G*(out_term - in_term)", "response": "r This function handles two - phase liquid - gas pressure drop calculation for a given flow rate xi xo alpha_i alpha_o rho_li rho_gi rho_go and rho_lo and rho_go."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef two_phase_dP_gravitational(angle, z, alpha_i, rho_li, rho_gi,  \n                               alpha_o=None, rho_lo=None, rho_go=None, g=g):\n    r'''This function handles calculation of two-phase liquid-gas pressure drop\n    due to gravitation for flow inside channels. This is a discrete \n    calculation for a segment with a known difference in elevation (and ideally\n    known inlet and outlet pressures so density dependence can be included). \n    \n    .. math::\n        - \\Delta P_{grav} =  g \\sin \\theta z \\left\\{\\frac{ [\\alpha_o\\rho_{g,o} \n        + (1-\\alpha_o)\\rho_{l,o}] + [\\alpha_i\\rho_{g,i} + (1-\\alpha_i)\\rho_{l,i}]}\n        {2}\\right\\}\n        \n    Parameters\n    ----------\n    angle : float\n        The angle of the pipe with respect to the horizontal, [degrees]\n    z : float\n        The total length of the pipe, [m]\n    alpha_i : float\n        Void fraction at inlet (area of gas / total area of channel), [-]\n    rho_li : float\n        Liquid phase density at inlet, [kg/m^3]\n    rho_gi : float\n        Gas phase density at inlet, [kg/m^3]\n    alpha_o : float, optional\n        Void fraction at outlet (area of gas / total area of channel), [-]\n    rho_lo : float, optional\n        Liquid phase density at outlet, [kg/m^3]\n    rho_go : float, optional\n        Gas phase density at outlet, [kg/m^3]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    dP : float\n        Gravitational component of pressure drop for two-phase flow, [Pa]\n        \n    Notes\n    -----\n    The use of different gas and liquid phase densities and void fraction \n    at the inlet and outlet is optional; the outlet densities and void fraction\n    will be assumed to be those of the inlet if they are not specified. This\n    does not add much accuracy.\n    \n    There is a continuous variant of this method which can be integrated over,\n    at the expense of a speed. The differential form of this is as follows \n    ([1]_, [2]_):\n        \n    .. math::\n        -\\left(\\frac{dP}{dz} \\right)_{grav} =  [\\alpha\\rho_g + (1-\\alpha)\n        \\rho_l]g \\sin \\theta\n        \n    Examples\n    --------\n    Example calculation, page 13-2 from [3]_:\n    \n    >>> two_phase_dP_gravitational(angle=90, z=2, alpha_i=0.9685, rho_li=1518., \n    ... rho_gi=2.6)\n    987.237416829999\n\n    The same calculation, but using average inlet and outlet conditions:\n    \n    >>> two_phase_dP_gravitational(angle=90, z=2, alpha_i=0.9685, rho_li=1518.,\n    ... rho_gi=2.6,  alpha_o=0.968, rho_lo=1517.9, rho_go=2.59)\n    994.5416058829999\n    \n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Kim, Sung-Min, and Issam Mudawar. \"Review of Databases and\n       Predictive Methods for Pressure Drop in Adiabatic, Condensing and\n       Boiling Mini/Micro-Channel Flows.\" International Journal of Heat and\n       Mass Transfer 77 (October 2014): 74-97.\n       doi:10.1016/j.ijheatmasstransfer.2014.04.035.\n    .. [3] Thome, John R. \"Engineering Data Book III.\" Wolverine Tube Inc\n       (2004). http://www.wlv.com/heat-transfer-databook/\n    '''\n    if rho_lo is None:\n        rho_lo = rho_li\n    if rho_go is None:\n        rho_go = rho_gi\n    if alpha_o is None:\n        alpha_o = alpha_i\n    angle = radians(angle)\n    in_term = alpha_i*rho_gi + (1. - alpha_i)*rho_li\n    out_term = alpha_o*rho_go + (1. - alpha_o)*rho_lo\n    return g*z*sin(angle)*(out_term + in_term)/2.", "response": "r Returns a discrete \n    that is a two - phase liquid - gas pressure drop for a flow inside channels."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclassifies the regime of a two - phase flow according to Taitel and Tukler and Dukler.", "response": "def Taitel_Dukler_regime(m, x, rhol, rhog, mul, mug,  D, angle, roughness=0, \n                         g=g, full_output=False):\n    r'''Classifies the regime of a two-phase flow according to Taitel and\n    Dukler (1976) ([1]_, [2]_).\n    \n    The flow regimes in this method are 'annular', 'bubbly', 'intermittent', \n    'stratified wavy', and 'stratified smooth'.\n    \n    The parameters used are 'X', 'T', 'F', and 'K'.\n    \n    .. math::\n        X = \\left[\\frac{(dP/dL)_{l,s,f}}{(dP/dL)_{g,s,f}}\\right]^{0.5}\n        \n    .. math::\n        T = \\left[\\frac{(dP/dL)_{l,s,f}}{(\\rho_l-\\rho_g)g\\cos\\theta}\\right]^{0.5}\n        \n    .. math::\n        F = \\sqrt{\\frac{\\rho_g}{(\\rho_l-\\rho_g)}} \\frac{v_{g,s}}{\\sqrt{D g \\cos\\theta}}\n        \n    .. math::\n        K = F\\left[\\frac{D v_{l,s}}{\\nu_l}  \\right]^{0.5} = F \\sqrt{Re_{l,s}}\n        \n    Note that 'l' refers to liquid, 'g' gas, 'f' friction-only, and 's' \n    superficial (i.e. if only the mass flow of that phase were flowing in the\n    pipe).\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate of fluid, [kg/s]\n    x : float\n        Mass quality of fluid, [-]\n    rhol : float\n        Liquid density, [kg/m^3]\n    rhog : float\n        Gas density, [kg/m^3]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    D : float\n        Diameter of pipe, [m]\n    angle : float\n        The angle of the pipe with respect to the horizontal, [degrees]\n    roughness : float, optional\n        Roughness of pipe for use in calculating friction factor, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n    full_output : bool, optional\n        When True, returns a dictionary with the values 'F', 'X', 'T', and 'K'\n        - the parameters used internally to determine where on the plot the\n        regime occurs, [-]\n    \n    Returns\n    -------\n    regime : str\n        One of 'annular', 'bubbly', 'intermittent', 'stratified wavy',\n        'stratified smooth', [-]\n\n    Notes\n    -----\n    The original friction factor used in this model is that of Blasius.\n\n    Examples\n    --------\n    >>> Taitel_Dukler_regime(m=0.6, x=0.112, rhol=915.12, rhog=2.67,\n    ... mul=180E-6, mug=14E-6, D=0.05, roughness=0, angle=0)\n    'annular'\n    \n    References\n    ----------\n    .. [1] Taitel, Yemada, and A. E. Dukler. \"A Model for Predicting Flow \n       Regime Transitions in Horizontal and near Horizontal Gas-Liquid Flow.\" \n       AIChE Journal 22, no. 1 (January 1, 1976): 47-55.\n       doi:10.1002/aic.690220105. \n    .. [2] Brill, James P., and Howard Dale Beggs. Two-Phase Flow in Pipes,\n       1994.\n    .. [3] Shoham, Ovadia. Mechanistic Modeling of Gas-Liquid Two-Phase Flow in \n       Pipes. Pap/Cdr edition. Richardson, TX: Society of Petroleum Engineers,\n       2006.\n    '''\n    angle = radians(angle)\n    A = 0.25*pi*D*D\n    # Liquid-superficial properties, for calculation of dP_ls, dP_ls\n    # Paper and Brill Beggs 1991 confirms not v_lo but v_sg\n    v_ls =  m*(1.0 - x)/(rhol*A)\n    Re_ls = Reynolds(V=v_ls, rho=rhol, mu=mul, D=D)\n    fd_ls = friction_factor(Re=Re_ls, eD=roughness/D)\n    dP_ls = fd_ls/D*(0.5*rhol*v_ls*v_ls)\n\n    # Gas-superficial properties, for calculation of dP_gs\n    v_gs = m*x/(rhog*A)\n    Re_gs = Reynolds(V=v_gs, rho=rhog, mu=mug, D=D)\n    fd_gs = friction_factor(Re=Re_gs, eD=roughness/D)\n    dP_gs = fd_gs/D*(0.5*rhog*v_gs*v_gs)\n    \n    X = (dP_ls/dP_gs)**0.5\n    \n    F = (rhog/(rhol-rhog))**0.5*v_gs*(D*g*cos(angle))**-0.5\n    \n    # Paper only uses kinematic viscosity\n    nul = mul/rhol\n\n    T = (dP_ls/((rhol-rhog)*g*cos(angle)))**0.5    \n    K = (rhog*v_gs*v_gs*v_ls/((rhol-rhog)*g*nul*cos(angle)))**0.5\n    \n    F_A_at_X = XA_interp_obj(X)\n    \n    X_B_transition = 1.7917 # Roughly\n    \n    if F >= F_A_at_X and X <= X_B_transition:\n        regime = 'annular'\n    elif F >= F_A_at_X:\n        T_D_at_X = XD_interp_obj(X)\n        if T >= T_D_at_X:\n            regime = 'bubbly'\n        else:\n            regime = 'intermittent'\n    else:\n        K_C_at_X = XC_interp_obj(X)\n        if K >= K_C_at_X:\n            regime = 'stratified wavy'\n        else:\n            regime = 'stratified smooth'\n            \n    if full_output:\n        res = {}\n        res['F'] = F\n        res['T'] = T\n        res['K'] = K\n        res['X'] = X\n\n    if full_output:\n        return regime, res\n    return regime"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Turner_Wallis(x, rhol, rhog, mul, mug):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_, as given in [2]_ and [3]_.\n\n    .. math::\n        \\alpha = \\left[1 + \\left(\\frac{1-x}{x}\\right)^{0.72}\\left(\\frac{\\rho_g}\n        {\\rho_l}\\right)^{0.4}\\left(\\frac{\\mu_l}{\\mu_g}\\right)^{0.08}\n        \\right]^{-1}\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ has not been reviewed. However, both [2]_ and [3]_ present it the\n    same way, if slightly differently rearranged.\n\n    Examples\n    --------\n    >>> Turner_Wallis(.4, 800, 2.5, 1E-3, 1E-5)\n    0.8384824581634625\n\n    References\n    ----------\n    .. [1] J.M. Turner, G.B. Wallis, The Separate-cylinders Model of Two-phase \n       Flow, NYO-3114-6, Thayer's School Eng., Dartmouth College, Hanover, New \n       Hampshire, USA, 1965.\n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Dalkilic, A. S., S. Laohalertdecha, and S. Wongwises. \"Effect of \n       Void Fraction Models on the Two-Phase Friction Factor of R134a during \n       Condensation in Vertical Downward Flow in a Smooth Tube.\" International \n       Communications in Heat and Mass Transfer 35, no. 8 (October 2008): \n       921-27. doi:10.1016/j.icheatmasstransfer.2008.04.001.\n    '''\n    return (1 + ((1-x)/x)**0.72 * (rhog/rhol)**0.4 * (mul/mug)**0.08)**-1", "response": "r This function calculates the void fraction in two - phase flow according to the model of Two - Phase Refrigerant Flow."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Tandon_Varma_Gupta(x, rhol, rhog, mul, mug, m, D):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ also given in [2]_, [3]_, and [4]_.\n\n    For 50 < Rel < 1125:\n    \n    .. math::\n        \\alpha = 1- 1.928Re_l^{-0.315}[F(X_{tt})]^{-1} + 0.9293Re_l^{-0.63}\n        [F(X_{tt})]^{-2}\n    \n    For Rel > 1125:\n    \n    .. math::\n        \\alpha = 1- 0.38 Re_l^{-0.088}[F(X_{tt})]^{-1} + 0.0361 Re_l^{-0.176}\n        [F(X_{tt})]^{-2}\n    \n    .. math::\n        F(X_{tt}) = 0.15[X_{tt}^{-1} + 2.85X_{tt}^{-0.476}]\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ does not specify how it defines the liquid Reynolds number. \n    [2]_ disagrees with [3]_ and [4]_; the later variant was selected, with:\n    \n    .. math::\n        Re_l = \\frac{G_{tp}D}{\\mu_l}\n    \n    The lower limit on Reynolds number is not enforced.\n        \n    Examples\n    --------\n    >>> Tandon_Varma_Gupta(.4, 800, 2.5, 1E-3, 1E-5, m=1, D=0.3)\n    0.9228265670341428\n\n    References\n    ----------\n    .. [1] Tandon, T. N., H. K. Varma, and C. P. Gupta. \"A Void Fraction Model \n       for Annular Two-Phase Flow.\" International Journal of Heat and Mass \n       Transfer 28, no. 1 (January 1, 1985): 191-198. \n       doi:10.1016/0017-9310(85)90021-3.\n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Dalkilic, A. S., S. Laohalertdecha, and S. Wongwises. \"Effect of \n       Void Fraction Models on the Two-Phase Friction Factor of R134a during \n       Condensation in Vertical Downward Flow in a Smooth Tube.\" International \n       Communications in Heat and Mass Transfer 35, no. 8 (October 2008): \n       921-27. doi:10.1016/j.icheatmasstransfer.2008.04.001.\n    .. [4] Woldesemayat, Melkamu A., and Afshin J. Ghajar. \"Comparison of Void \n       Fraction Correlations for Different Flow Patterns in Horizontal and \n       Upward Inclined Pipes.\" International Journal of Multiphase Flow 33, \n       no. 4 (April 2007): 347-370. doi:10.1016/j.ijmultiphaseflow.2006.09.004.\n    '''\n    G = m/(pi/4*D**2)\n    Rel = G*D/mul\n    Xtt = Lockhart_Martinelli_Xtt(x, rhol, rhog, mul, mug)\n    Fxtt = 0.15*(Xtt**-1 + 2.85*Xtt**-0.476)\n    if Rel < 1125:\n        alpha = 1 - 1.928*Rel**-0.315/Fxtt + 0.9293*Rel**-0.63/Fxtt**2\n    else:\n        alpha = 1 - 0.38*Rel**-0.088/Fxtt + 0.0361*Rel**-0.176/Fxtt**2\n    return alpha", "response": "r Returns a base of the two - phase flow according to the model of \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Harms(x, rhol, rhog, mul, mug, m, D):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ also given in [2]_ and [3]_.\n\n    .. math::\n        \\alpha = \\left[1 - 10.06Re_l^{-0.875}(1.74 + 0.104Re_l^{0.5})^2\n        \\left(1.376 + \\frac{7.242}{X_{tt}^{1.655}}\\right)^{-0.5}\\right]^2\n        \n    .. math::\n        Re_l = \\frac{G_{tp}(1-x)D}{\\mu_l}\n\n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ has been reviewed.\n        \n    Examples\n    --------\n    >>> Harms(.4, 800, 2.5, 1E-3, 1E-5, m=1, D=0.3)\n    0.9653289762907554\n\n    References\n    ----------\n    .. [1] Tandon, T. N., H. K. Varma, and C. P. Gupta. \"A Void Fraction Model \n       for Annular Two-Phase Flow.\" International Journal of Heat and Mass \n       Transfer 28, no. 1 (January 1, 1985): 191-198. \n       doi:10.1016/0017-9310(85)90021-3.\n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Dalkilic, A. S., S. Laohalertdecha, and S. Wongwises. \"Effect of \n       Void Fraction Models on the Two-Phase Friction Factor of R134a during \n       Condensation in Vertical Downward Flow in a Smooth Tube.\" International \n       Communications in Heat and Mass Transfer 35, no. 8 (October 2008): \n       921-27. doi:10.1016/j.icheatmasstransfer.2008.04.001.\n    '''\n    G = m/(pi/4*D**2)\n    Rel = G*D*(1-x)/mul\n    Xtt = Lockhart_Martinelli_Xtt(x, rhol, rhog, mul, mug)\n    return (1 - 10.06*Rel**-0.875*(1.74 + 0.104*Rel**0.5)**2\n            *(1.376 + 7.242/Xtt**1.655)**-0.5)", "response": "r Calculates void fraction in two - phase flow according to the model of \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Domanski_Didion(x, rhol, rhog, mul, mug):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ also given in [2]_ and [3]_.\n\n    if Xtt < 10:\n    \n    .. math::\n        \\alpha = (1 + X_{tt}^{0.8})^{-0.378}\n        \n    Otherwise:\n    \n    .. math::\n        \\alpha = 0.823- 0.157\\ln(X_{tt})\n    \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ has been reviewed. [2]_ gives an exponent of -0.38 instead of -0.378\n    as is in [1]_. [3]_ describes only the novel half of the correlation.\n    The portion for Xtt > 10 is novel; the other is said to be from their 31st \n    reference, Wallis.\n    \n    There is a discontinuity at Xtt = 10.\n        \n    Examples\n    --------\n    >>> Domanski_Didion(.4, 800, 2.5, 1E-3, 1E-5)\n    0.9355795597059169\n\n    References\n    ----------\n    .. [1] Domanski, Piotr, and David A. Didion. \"Computer Modeling of the \n       Vapor Compression Cycle with Constant Flow Area Expansion Device.\" \n       Report. UNT Digital Library, May 1983. \n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Dalkilic, A. S., S. Laohalertdecha, and S. Wongwises. \"Effect of \n       Void Fraction Models on the Two-Phase Friction Factor of R134a during \n       Condensation in Vertical Downward Flow in a Smooth Tube.\" International \n       Communications in Heat and Mass Transfer 35, no. 8 (October 2008): \n       921-27. doi:10.1016/j.icheatmasstransfer.2008.04.001.\n    '''\n    Xtt = Lockhart_Martinelli_Xtt(x, rhol, rhog, mul, mug)\n    if Xtt < 10:\n        return (1 + Xtt**0.8)**-0.378\n    else:\n        return 0.823 - 0.157*log(Xtt)", "response": "r This function calculates the void fraction in two - phase flow according to the model of the given liquid interval and gas."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Yashar(x, rhol, rhog, mul, mug, m, D, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ also given in [2]_ and [3]_.\n    \n    .. math::\n        \\alpha = \\left[1 + \\frac{1}{Ft} + X_{tt}\\right]^{-0.321}\n        \n    .. math::\n        Ft = \\left[\\frac{G_{tp}^2 x^3}{(1-x)\\rho_g^2gD}\\right]^{0.5}\n                \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ has been reviewed; both [2]_ and [3]_ give it correctly.\n        \n    Examples\n    --------\n    >>> Yashar(.4, 800, 2.5, 1E-3, 1E-5, m=1, D=0.3)\n    0.7934893185789146\n\n    References\n    ----------\n    .. [1] Yashar, D. A., M. J. Wilson, H. R. Kopke, D. M. Graham, J. C. Chato,\n       and T. A. Newell. \"An Investigation of Refrigerant Void Fraction in \n       Horizontal, Microfin Tubes.\" HVAC&R Research 7, no. 1 (January 1, 2001):\n       67-82. doi:10.1080/10789669.2001.10391430. \n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Dalkilic, A. S., S. Laohalertdecha, and S. Wongwises. \"Effect of \n       Void Fraction Models on the Two-Phase Friction Factor of R134a during \n       Condensation in Vertical Downward Flow in a Smooth Tube.\" International \n       Communications in Heat and Mass Transfer 35, no. 8 (October 2008): \n       921-27. doi:10.1016/j.icheatmasstransfer.2008.04.001.\n    '''\n    G = m/(pi/4*D**2)\n    Ft = (G**2*x**3/((1-x)*rhog**2*g*D))**0.5\n    Xtt = Lockhart_Martinelli_Xtt(x, rhol, rhog, mul, mug)\n    return (1 + 1./Ft + Xtt)**-0.321", "response": "r Yashar - function to calculate the void fraction of a single channel in two - phase flow according to the model of \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Kopte_Newell_Chato(x, rhol, rhog, mul, mug, m, D, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ also given in [2]_.\n    \n    .. math::\n        \\alpha = 1.045 - \\exp\\{-1 - 0.342\\ln(Ft) - 0.0268[\\ln(Ft)]^2 \n        + 0.00597[\\ln(Ft)]^3\\}\n        \n    .. math::\n        Ft = \\left[\\frac{G_{tp}^2 x^3}{(1-x)\\rho_g^2gD}\\right]^{0.5}\n        \n    .. math::\n        \\alpha = \\alpha_h \\text{ for } F_t \\le 0.044\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    [1]_ has been reviewed. If is recommended this expression not be used above\n    Ft values of 454.\n        \n    Examples\n    --------\n    >>> Kopte_Newell_Chato(.4, 800, 2.5, 1E-3, 1E-5, m=1, D=0.3)\n    0.6864466770087425\n\n    References\n    ----------\n    .. [1] Kopke, H. R. \"Experimental Investigation of Void Fraction During \n       Refrigerant Condensation in Horizontal Tubes.\" ACRC Technical Report \n       142. Air Conditioning and Refrigeration Center. College of Engineering. \n       University of Illinois at Urbana-Champaign., August 1998. \n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    '''\n    G = m/(pi/4*D**2)\n    Ft = (G**2*x**3/((1-x)*rhog**2*g*D))**0.5\n    if Ft < 0.044:\n        return homogeneous(x, rhol, rhog)\n    else:\n        return 1.045 - exp(-1 - 0.342*log(Ft) - 0.0268*log(Ft)**2 + 0.00597*log(Ft)**3)", "response": "r Returns a newell version of the given channel with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Nicklin_Wilkes_Davidson(x, rhol, rhog, m, D, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ as given in [2]_ and [3]_.\n    \n    .. math::\n        \\alpha = \\frac{x}{\\rho_g}\\left[C_0\\left(\\frac{x}{\\rho_g} + \\frac{1-x}\n        {\\rho_l}\\right) +\\frac{v_{gm}}{G} \\right]^{-1}\n        \n    .. math::\n        v_{gm} = 0.35\\sqrt{gD}\n\n    .. math::\n        C_0 = 1.2\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n        \n    Examples\n    --------\n    >>> Nicklin_Wilkes_Davidson(0.4, 800., 2.5, m=1, D=0.3)\n    0.6798826626721431\n\n    References\n    ----------\n    .. [1] D. Nicklin, J. Wilkes, J. Davidson, \"Two-phase flow in vertical \n       tubes\", Trans. Inst. Chem. Eng. 40 (1962) 61-68.\n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Woldesemayat, Melkamu A., and Afshin J. Ghajar. \"Comparison of Void \n       Fraction Correlations for Different Flow Patterns in Horizontal and \n       Upward Inclined Pipes.\" International Journal of Multiphase Flow 33, \n       no. 4 (April 2007): 347-370. doi:10.1016/j.ijmultiphaseflow.2006.09.004.\n    '''\n    G = m/(pi/4*D**2)\n    C0 = 1.2\n    vgm = 0.35*(g*D)**0.5\n    return x/rhog*(C0*(x/rhog + (1-x)/rhol) + vgm/G)**-1", "response": "r Nicklin Wilkes J. Davidson and J. Wilkes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Dix(x, rhol, rhog, sigma, m, D, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_ as given in [2]_ and [3]_.\n    \n    .. math::\n        \\alpha = \\frac{x}{\\rho_g}\\left[C_0\\left(\\frac{x}{\\rho_g} + \\frac{1-x}\n        {\\rho_l}\\right) +\\frac{v_{gm}}{G} \\right]^{-1}\n        \n    .. math::\n        v_{gm} = 2.9\\left(g\\sigma\\frac{\\rho_l-\\rho_g}{\\rho_l^2}\\right)^{0.25}\n\n    .. math::\n        C_0 = \\frac{v_{sg}}{v_m}\\left[1 + \\left(\\frac{v_{sl}}{v_{sg}}\\right)\n        ^{\\left(\\left(\\frac{\\rho_g}{\\rho_l}\\right)^{0.1}\\right)}\\right]\n\n    .. math::\n        v_{gs} = \\frac{mx}{\\rho_g \\frac{\\pi}{4}D^2}\n        \n    .. math::\n        v_{ls} = \\frac{m(1-x)}{\\rho_l \\frac{\\pi}{4}D^2}\n        \n    .. math::\n        v_m = v_{gs} + v_{ls}\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    sigma : float\n        Surface tension of liquid [N/m]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    Has formed the basis for several other correlations.\n        \n    Examples\n    --------\n    >>> Dix(0.4, 800., 2.5, sigma=0.02, m=1, D=0.3)\n    0.8268737961156514\n\n    References\n    ----------\n    .. [1] Gary Errol. Dix. \"Vapor Void Fractions for Forced Convection with \n       Subcooled Boiling at Low Flow Rates.\" Thesis. University of California, \n       Berkeley, 1971.\n    .. [2] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    .. [3] Woldesemayat, Melkamu A., and Afshin J. Ghajar. \"Comparison of Void \n       Fraction Correlations for Different Flow Patterns in Horizontal and \n       Upward Inclined Pipes.\" International Journal of Multiphase Flow 33, \n       no. 4 (April 2007): 347-370. doi:10.1016/j.ijmultiphaseflow.2006.09.004.\n    '''\n    vgs = m*x/(rhog*pi/4*D**2)\n    vls = m*(1-x)/(rhol*pi/4*D**2)\n    G = m/(pi/4*D**2)\n    C0 = vgs/(vls+vgs)*(1 + (vls/vgs)**((rhog/rhol)**0.1))\n    vgm = 2.9*(g*sigma*(rhol-rhog)/rhol**2)**0.25\n    return x/rhog*(C0*(x/rhog + (1-x)/rhol) + vgm/G)**-1", "response": "r Returns a single void fraction in two - phase flow according to the model of \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Xu_Fang_voidage(x, rhol, rhog, m, D, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model \n    developed in the review of [1]_.\n    \n    .. math::\n        \\alpha = \\left[1 + \\left(1 + 2Fr_{lo}^{-0.2}\\alpha_h^{3.5}\\right)\\left(\n        \\frac{1-x}{x}\\right)\\left(\\frac{\\rho_g}{\\rho_l}\\right)\\right]^{-1}\n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    Claims an AARD of 5.0%, and suitability for any flow regime,\n    mini and micro channels, adiabatic, evaporating, or condensing flow,\n    and for Frlo from 0.02 to 145, rhog/rhol from 0.004-0.153, and x from 0 to \n    1.\n        \n    Examples\n    --------\n    >>> Xu_Fang_voidage(0.4, 800., 2.5, m=1, D=0.3)\n    0.9414660089942093\n\n    References\n    ----------\n    .. [1] Xu, Yu, and Xiande Fang. \"Correlations of Void Fraction for Two-\n       Phase Refrigerant Flow in Pipes.\" Applied Thermal Engineering 64, no. \n       1-2 (March 2014): 242\u201351. doi:10.1016/j.applthermaleng.2013.12.032. \n    '''\n    G = m/(pi/4*D**2)\n    alpha_h = homogeneous(x, rhol, rhog)\n    Frlo = G**2/(g*D*rhol**2)\n    return (1 + (1 + 2*Frlo**-0.2*alpha_h**3.5)*((1-x)/x)*(rhog/rhol))**-1", "response": "r A function that calculates the void fraction of a single channel in two - phase flow according to the model \n    developed in the review of the model \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Woldesemayat_Ghajar(x, rhol, rhog, sigma, m, D, P, angle=0, g=g):\n    r'''Calculates void fraction in two-phase flow according to the model of \n    [1]_.\n    \n    .. math::\n        \\alpha = \\frac{v_{gs}}{v_{gs}\\left(1 + \\left(\\frac{v_{ls}}{v_{gs}}\n        \\right)^{\\left(\\frac{\\rho_g}{\\rho_l}\\right)^{0.1}}\\right)\n        + 2.9\\left[\\frac{gD\\sigma(1+\\cos\\theta)(\\rho_l-\\rho_g)}\n        {\\rho_l^2}\\right]^{0.25}(1.22 + 1.22\\sin\\theta)^{\\frac{P}{P_{atm}}}}\n        \n    .. math::\n        v_{gs} = \\frac{mx}{\\rho_g \\frac{\\pi}{4}D^2}\n        \n    .. math::\n        v_{ls} = \\frac{m(1-x)}{\\rho_l \\frac{\\pi}{4}D^2}\n        \n        \n    Parameters\n    ----------\n    x : float\n        Quality at the specific tube interval []\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    sigma : float\n        Surface tension of liquid [N/m]\n    m : float\n        Mass flow rate of both phases, [kg/s]\n    D : float\n        Diameter of the channel, [m]\n    P : float\n        Pressure of the fluid, [Pa]\n    angle : float\n        Angle of the channel with respect to the horizontal (vertical = 90), \n        [degrees]\n    g : float, optional\n        Acceleration due to gravity, [m/s^2]\n\n    Returns\n    -------\n    alpha : float\n        Void fraction (area of gas / total area of channel), [-]\n\n    Notes\n    -----\n    Strongly recommended.\n        \n    Examples\n    --------\n    >>> Woldesemayat_Ghajar(0.4, 800., 2.5, sigma=0.2, m=1, D=0.3, P=1E6, angle=45)\n    0.7640815513429202\n\n    References\n    ----------\n    .. [1] Woldesemayat, Melkamu A., and Afshin J. Ghajar. \"Comparison of Void \n       Fraction Correlations for Different Flow Patterns in Horizontal and \n       Upward Inclined Pipes.\" International Journal of Multiphase Flow 33, \n       no. 4 (April 2007): 347-370. doi:10.1016/j.ijmultiphaseflow.2006.09.004.\n    '''\n    vgs = m*x/(rhog*pi/4*D**2)\n    vls = m*(1-x)/(rhol*pi/4*D**2)\n    first = vgs*(1 + (vls/vgs)**((rhog/rhol)**0.1))\n    second = 2.9*((g*D*sigma*(1 + cos(radians(angle)))*(rhol-rhog))/rhol**2)**0.25\n    third = (1.22 + 1.22*sin(radians(angle)))**(101325./P)\n    return vgs/(first + second*third)", "response": "r Returns a single entry in the two - phase flow of a particular type of channel in a given liquid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Beattie_Whalley(x, mul, mug, rhol, rhog):\n    r'''Calculates a suggested definition for liquid-gas two-phase flow \n    viscosity in internal pipe flow according to the form in [1]_ and shown\n    in [2]_ and [3]_.\n        \n    .. math::\n        \\mu_m = \\mu_l(1-\\alpha_m)(1 + 2.5\\alpha_m) + \\mu_g\\alpha_m\n        \n    .. math::\n        \\alpha_m = \\frac{1}{1 + \\left(\\frac{1-x}{x}\\right)\\frac{\\rho_g}{\\rho_l}}\n        \\text{(homogeneous model)}\n\n    Parameters\n    ----------\n    x : float\n        Quality of the gas-liquid flow, [-]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n\n    Returns\n    -------\n    mu_lg : float\n        Liquid-gas viscosity (**a suggested definition, potentially useful\n        for empirical work only!**) [Pa*s]\n\n    Notes\n    -----\n    This model converges to the liquid or gas viscosity as the quality\n    approaches either limits.\n        \n    Examples\n    --------\n    >>> Beattie_Whalley(x=0.4, mul=1E-3, mug=1E-5, rhol=850, rhog=1.2)\n    1.7363806909512365e-05\n\n    References\n    ----------\n    .. [1] Beattie, D. R. H., and P. B. Whalley. \"A Simple Two-Phase Frictional\n       Pressure Drop Calculation Method.\" International Journal of Multiphase \n       Flow 8, no. 1 (February 1, 1982): 83-87. \n       doi:10.1016/0301-9322(82)90009-X. \n    .. [2] Awad, M. M., and Y. S. Muzychka. \"Effective Property Models for \n       Homogeneous Two-Phase Flows.\" Experimental Thermal and Fluid Science 33,\n       no. 1 (October 1, 2008): 106-13. \n    .. [3] Kim, Sung-Min, and Issam Mudawar. \"Review of Databases and\n       Predictive Methods for Pressure Drop in Adiabatic, Condensing and\n       Boiling Mini/Micro-Channel Flows.\" International Journal of Heat and\n       Mass Transfer 77 (October 2014): 74-97.\n       doi:10.1016/j.ijheatmasstransfer.2014.04.035.\n    '''\n    alpha = homogeneous(x, rhol, rhog)\n    return mul*(1. - alpha)*(1. + 2.5*alpha) + mug*alpha", "response": "r Calculates a suggested definition for a liquid - gas two - phase flow with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Lin_Kwok(x, mul, mug):\n    r'''Calculates a suggested definition for liquid-gas two-phase flow \n    viscosity in internal pipe flow according to the form in [1]_ and shown\n    in [2]_ and [3]_.\n        \n    .. math::\n        \\mu_m = \\frac{\\mu_l \\mu_g}{\\mu_g + x^{1.4}(\\mu_l - \\mu_g)}\n        \n    Parameters\n    ----------\n    x : float\n        Quality of the gas-liquid flow, [-]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n\n    Returns\n    -------\n    mu_lg : float\n        Liquid-gas viscosity (**a suggested definition, potentially useful\n        for empirical work only!**) [Pa*s]\n\n    Notes\n    -----\n    This model converges to the liquid or gas viscosity as the quality\n    approaches either limits.\n    \n    Examples\n    --------\n    >>> Lin_Kwok(x=0.4, mul=1E-3, mug=1E-5)\n    3.515119398126066e-05\n\n    References\n    ----------\n    .. [1] Lin, S., C. C. K. Kwok, R. -Y. Li, Z. -H. Chen, and Z. -Y. Chen. \n       \"Local Frictional Pressure Drop during Vaporization of R-12 through \n       Capillary Tubes.\" International Journal of Multiphase Flow 17, no. 1 \n       (January 1, 1991): 95-102. doi:10.1016/0301-9322(91)90072-B.\n    .. [2] Awad, M. M., and Y. S. Muzychka. \"Effective Property Models for \n       Homogeneous Two-Phase Flows.\" Experimental Thermal and Fluid Science 33,\n       no. 1 (October 1, 2008): 106-13. \n    '''\n    return mul*mug/(mug + x**1.4*(mul - mug))", "response": "r Returns a suggested definition for a liquid - gas two - phase flow."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Fourar_Bories(x, mul, mug, rhol, rhog):\n    r'''Calculates a suggested definition for liquid-gas two-phase flow \n    viscosity in internal pipe flow according to the form in [1]_ and shown\n    in [2]_ and [3]_.\n        \n    .. math::\n        \\mu_m = \\rho_m\\left(\\sqrt{x\\nu_g} + \\sqrt{(1-x)\\nu_l}\\right)^2\n        \n    Parameters\n    ----------\n    x : float\n        Quality of the gas-liquid flow, [-]\n    mul : float\n        Viscosity of liquid, [Pa*s]\n    mug : float\n        Viscosity of gas, [Pa*s]\n    rhol : float\n        Density of the liquid, [kg/m^3]\n    rhog : float\n        Density of the gas, [kg/m^3]\n\n    Returns\n    -------\n    mu_lg : float\n        Liquid-gas viscosity (**a suggested definition, potentially useful\n        for empirical work only!**) [Pa*s]\n\n    Notes\n    -----\n    This model converges to the liquid or gas viscosity as the quality\n    approaches either limits.\n    \n    This was first expressed in the equalivalent form as follows:\n        \n    .. math::\n        \\mu_m = \\rho_m\\left(x\\nu_g + (1-x)\\nu_l + 2\\sqrt{x(1-x)\\nu_g\\nu_l}\n        \\right)\n    \n    Examples\n    --------\n    >>> Fourar_Bories(x=0.4, mul=1E-3, mug=1E-5, rhol=850, rhog=1.2)\n    2.127617150298565e-05\n\n    References\n    ----------\n    .. [1] Fourar, M., and S. Bories. \"Experimental Study of Air-Water \n       Two-Phase Flow through a Fracture (Narrow Channel).\" International \n       Journal of Multiphase Flow 21, no. 4 (August 1, 1995): 621-37. \n       doi:10.1016/0301-9322(95)00005-I.\n    .. [2] Awad, M. M., and Y. S. Muzychka. \"Effective Property Models for \n       Homogeneous Two-Phase Flows.\" Experimental Thermal and Fluid Science 33,\n       no. 1 (October 1, 2008): 106-13. \n    .. [3] Aung, NZ, and T. Yuwono. \"Evaluation of Mixture Viscosity Models in \n       the Prediction of Two-Phase Flow Pressure Drops.\" ASEAN Journal on \n       Science and Technology for Development 29, no. 2 (2012). \n    '''\n    rhom = 1./(x/rhog + (1. - x)/rhol)\n    nul = mul/rhol # = nu_mu_converter(rho=rhol, mu=mul)\n    nug = mug/rhog # = nu_mu_converter(rho=rhog, mu=mug)\n    return rhom*((x*nug)**0.5 + ((1. - x)*nul)**0.5)**2", "response": "r Fourar Bories of a liquid - gas two - phase flow."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hwm93(Z, latitude=0, longitude=0, day=0, seconds=0, f107=150., \n          f107_avg=150., geomagnetic_disturbance_index=4):\n    r'''Horizontal Wind Model 1993, for calculating wind velocity in the\n    atmosphere as a function of time of year, longitude and latitude, solar \n    activity and earth's geomagnetic disturbance.\n    \n    The model is described across the publications [1]_, [2]_, and [3]_.\n    \n    Parameters\n    ----------\n    Z : float\n        Elevation, [m]\n    latitude : float, optional\n        Latitude, between -90 and 90 [degrees]\n    longitude : float, optional\n        Longitude, between -180 and 180 or 0 and 360, [degrees]\n    day : float, optional\n        Day of year, 0-366 [day]\n    seconds : float, optional\n        Seconds since start of day, in UT1 time; using UTC provides no loss in\n        accuracy [s]\n    f107 : float, optional\n        Daily average 10.7 cm solar flux measurement of the strength of solar  \n        emissions on the 100 MHz band centered on 2800 MHz, averaged hourly; in \n        sfu units, which are multiples of 10^-22 W/m^2/Hz; use 150 as a default \n        [W/m^2/Hz]\n    f107_avg : float, optional\n        81-day sfu average; centered on specified day if possible, otherwise\n        use the previous days [W/m^2/Hz]\n    geomagnetic_disturbance_index : float, optional\n        Average daily `Ap` or also known as planetary magnetic index.\n        \n    Returns\n    -------\n    v_north : float\n        Wind velocity, meridional (Northward) [m/s]\n    v_east : float\n        Wind velocity, zonal (Eastward) [m/s]\n\n    Examples\n    --------\n    >>> hwm93(5E5, 45, 50, 365)\n    (-73.00312042236328, 0.1485661268234253)\n    \n    Notes\n    -----\n    No full description has been published of this model; it has been defined by\n    its implementation only. It was written in FORTRAN, and is accessible\n    at ftp://hanna.ccmc.gsfc.nasa.gov/pub/modelweb/atmospheric/hwm93/.\n    \n    F2PY auto-compilation support is not yet currently supported.\n    To compile this file, run the following command in a shell after navigating\n    to $FLUIDSPATH/fluids/optional/. This should generate the file hwm93.so\n    in that directory.\n        \n    f2py -c hwm93.pyf hwm93.for --f77flags=\"-std=legacy\"\n    \n    If the module is not compiled, an import error will be raised.\n    \n    References\n    ----------\n    .. [1] Hedin, A. E., N. W. Spencer, and T. L. Killeen. \"Empirical Global \n       Model of Upper Thermosphere Winds Based on Atmosphere and Dynamics \n       Explorer Satellite Data.\" Journal of Geophysical Research: Space Physics\n       93, no. A9 (September 1, 1988): 9959-78. doi:10.1029/JA093iA09p09959.\n    .. [2] Hedin, A. E., M. A. Biondi, R. G. Burnside, G. Hernandez, R. M. \n       Johnson, T. L. Killeen, C. Mazaudier, et al. \"Revised Global Model of \n       Thermosphere Winds Using Satellite and Ground-Based Observations.\" \n       Journal of Geophysical Research: Space Physics 96, no. A5 (May 1, 1991):\n       7657-88. doi:10.1029/91JA00251.\n    .. [3] Hedin, A. E., E. L. Fleming, A. H. Manson, F. J. Schmidlin, S. K. \n       Avery, R. R. Clark, S. J. Franke, et al. \"Empirical Wind Model for the \n       Upper, Middle and Lower Atmosphere.\" Journal of Atmospheric and \n       Terrestrial Physics 58, no. 13 (September 1996): 1421-47. \n       doi:10.1016/0021-9169(95)00122-0.\n    '''\n    try:\n        from .optional.hwm93 import gws5\n    except: # pragma: no cover\n        raise ImportError(no_gfortran_error)\n    slt_hour = seconds/3600. + longitude/15.\n    ans = gws5(day, seconds, Z/1000., latitude, longitude, slt_hour, f107, \n               f107_avg, geomagnetic_disturbance_index)\n    return tuple(ans.tolist())", "response": "Horizontal Wind Model 1993 for calculating wind velocity in the solar articles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hwm14(Z, latitude=0, longitude=0, day=0, seconds=0, \n          geomagnetic_disturbance_index=4):\n    r'''Horizontal Wind Model 2014, for calculating wind velocity in the\n    atmosphere as a function of time of year, longitude and latitude, and \n    earth's geomagnetic disturbance. The model is described in [1]_.\n    \n    The model no longer accounts for solar flux.\n    \n    Parameters\n    ----------\n    Z : float\n        Elevation, [m]\n    latitude : float, optional\n        Latitude, between -90 and 90 [degrees]\n    longitude : float, optional\n        Longitude, between -180 and 180 or 0 and 360, [degrees]\n    day : float, optional\n        Day of year, 0-366 [day]\n    seconds : float, optional\n        Seconds since start of day, in UT1 time; using UTC provides no loss in\n        accuracy [s]\n    geomagnetic_disturbance_index : float, optional\n        Average daily `Ap` or also known as planetary magnetic index.\n        \n    Returns\n    -------\n    v_north : float\n        Wind velocity, meridional (Northward) [m/s]\n    v_east : float\n        Wind velocity, zonal (Eastward) [m/s]\n        \n\n    Examples\n    --------\n    >>> hwm14(5E5, 45, 50, 365)\n    (-38.64341354370117, 12.871272087097168)\n\n    Notes\n    -----\n    No full description has been published of this model; it has been defined by\n    its implementation only. It was written in FORTRAN, and is accessible\n    at http://onlinelibrary.wiley.com/store/10.1002/2014EA000089/asset/supinfo/ess224-sup-0002-supinfo.tgz?v=1&s=2a957ba70b7cf9dd0612d9430076297c3634ea75.\n    \n    F2PY auto-compilation support is not yet currently supported.\n    To compile this file, run the following command in a shell after navigating\n    to $FLUIDSPATH/fluids/optional/. This should generate the file hwm14.so\n    in that directory.\n        \n    f2py -c hwm14.pyf hwm14.f90\n    \n    The fortran .pyf signature file is included with this project, but it can\n    also be re-created with the command:\n        \n    f2py -m hwm14 -h hwm14.pyf hwm14.f90\n    \n    If the module is not compiled, an import error will be raised.\n    \n    No patches were necessary to either the generated pyf or hwm14.f90 file,\n    as the authors of [1]_ have made it F2PY compatible.\n    \n    Developed using 73 million data points taken by 44 instruments over 60 \n    years.\n    \n    References\n    ----------\n    .. [1] Drob, Douglas P., John T. Emmert, John W. Meriwether, Jonathan J. \n       Makela, Eelco Doornbos, Mark Conde, Gonzalo Hernandez, et al. \"An Update\n       to the Horizontal Wind Model (HWM): The Quiet Time Thermosphere.\" Earth\n       and Space Science 2, no. 7 (July 1, 2015): 2014EA000089. \n       doi:10.1002/2014EA000089.\n    '''\n    # Needed by hwm14\n    os.environ[\"HWMPATH\"] = os.path.join(os.path.dirname(__file__), 'optional')\n    try:\n        import optional.hwm14\n    except: # pragma: no cover\n        raise ImportError(no_gfortran_error)\n    ans = optional.hwm14.hwm14(day, seconds, Z/1000., latitude, longitude, 0, 0, \n               0, np.array([np.nan, geomagnetic_disturbance_index]))\n    return tuple(ans.tolist())", "response": "Horizontal Wind Model 2014 for calculating wind velocity in the\n    atmosphere."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef earthsun_distance(moment):\n    r'''Calculates the distance between the earth and the sun as a function \n    of date and time. Uses the Reda and Andreas (2004) model described in [1]_, \n    originally incorporated into the excellent \n    `pvlib library <https://github.com/pvlib/pvlib-python>`_\n    \n    Parameters\n    ----------\n    moment : datetime\n        Time and date for the calculation, in UTC time (or GMT, which is\n        almost the same thing); not local time, [-]\n        \n    Returns\n    -------\n    distance : float\n        Distance between the center of the earth and the center of the sun,\n        [m]        \n\n    Examples\n    --------\n    >>> earthsun_distance(datetime(2003, 10, 17, 13, 30, 30))\n    149090925951.18338\n    \n    The distance at perihelion, which occurs at 4:21 according to this\n    algorithm. The real value is 04:38 (January 2nd).\n        \n    >>> earthsun_distance(datetime(2013, 1, 2, 4, 21, 50))\n    147098089490.67123\n    \n    The distance at aphelion, which occurs at 14:44 according to this\n    algorithm. The real value is dead on - 14:44 (July 5).\n    \n    >>> earthsun_distance(datetime(2013, 7, 5, 14, 44, 51, 0))\n    152097354414.36044\n        \n    Notes\n    -----\n    This function is quite accurate. The difference comes from the impact of \n    the moon.\n\n    Note this function is not continuous; the sun-earth distance is not \n    sufficiently accurately modeled for the change to be continuous throughout\n    each day.\n\n    References\n    ----------\n    .. [1] Reda, Ibrahim, and Afshin Andreas. \"Solar Position Algorithm for \n       Solar Radiation Applications.\" Solar Energy 76, no. 5 (January 1, 2004):\n       577-89. https://doi.org/10.1016/j.solener.2003.12.003.\n    '''\n    from fluids.optional import spa\n    delta_t = spa.calculate_deltat(moment.year, moment.month)\n    import calendar\n    unixtime = calendar.timegm(moment.timetuple())\n    # Convert datetime object to unixtime\n    return float(spa.earthsun_distance(unixtime, delta_t=delta_t))*au", "response": "r Returns the distance between the earth and the sun."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sunrise_sunset(moment, latitude, longitude):\n    r'''Calculates the times at which the sun is at sunset; sunrise; and \n    halfway between sunrise and sunset (transit).\n    \n    Uses the Reda and Andreas (2004) model described in [1]_, \n    originally incorporated into the excellent \n    `pvlib library <https://github.com/pvlib/pvlib-python>`_    \n\n    Parameters\n    ----------\n    moment : datetime\n        Date for the calculationl; needs to contain only the year, month, and\n        day, [-]\n    latitude : float\n        Latitude, between -90 and 90 [degrees]\n    longitude : float\n        Longitude, between -180 and 180, [degrees]\n\n    Returns\n    -------\n    sunrise : datetime\n        The time at the specified day when the sun rises **IN UTC**, [-]\n    sunset : datetime\n        The time at the specified day when the sun sets **IN UTC**, [-]\n    transit : datetime\n        The time at the specified day when the sun is at solar noon - halfway \n        between sunrise and sunset **IN UTC**, [-]\n\n    Examples\n    --------\n    >>> sunrise, sunset, transit = sunrise_sunset(datetime(2018, 4, 17), \n    ... 51.0486, -114.07)\n    >>> sunrise\n    datetime.datetime(2018, 4, 17, 12, 36, 55, 782660)\n    >>> sunset\n    datetime.datetime(2018, 4, 18, 2, 34, 4, 249326)\n    >>> transit\n    datetime.datetime(2018, 4, 17, 19, 35, 46, 686265)\n    \n    Notes\n    -----    \n    This functions takes on the order of 2 ms per calculation.\n    \n    The reason the function cannot return the time correct the local\n    timezone is that the function does not know the timezone at the specified\n    lat/long.\n\n    References\n    ----------\n    .. [1] Reda, Ibrahim, and Afshin Andreas. \"Solar Position Algorithm for \n       Solar Radiation Applications.\" Solar Energy 76, no. 5 (January 1, 2004):\n       577-89. https://doi.org/10.1016/j.solener.2003.12.003.\n    '''\n    from fluids.optional import spa\n    delta_t = spa.calculate_deltat(moment.year, moment.month)\n    # Strip the part of the day\n    moment = datetime(moment.year, moment.month, moment.day)\n    import calendar \n    unixtime = calendar.timegm(moment.timetuple())\n    unixtime = unixtime - unixtime % (86400) # Remove the remainder of the value, rounding it to the day it is\n    transit, sunrise, sunset = spa.transit_sunrise_sunset(np.array([unixtime]), lat=latitude, lon=longitude, delta_t=delta_t, numthreads=1)\n    \n    transit = datetime.utcfromtimestamp(float(transit))\n    sunrise = datetime.utcfromtimestamp(float(sunrise))\n    sunset = datetime.utcfromtimestamp(float(sunset))\n    return sunrise, sunset, transit", "response": "r Returns a new object that represents the sunrise sunset and transit times at the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solar_irradiation(latitude, longitude, Z, moment, surface_tilt, \n                      surface_azimuth, T=None, P=None, solar_constant=1366.1,\n                      atmos_refract=0.5667, albedo=0.25, linke_turbidity=None, \n                      extraradiation_method='spencer',\n                      airmass_model='kastenyoung1989',\n                      cache=None):\n    r'''Calculates the amount of solar radiation and radiation reflected back\n    the atmosphere which hits a surface at a specified tilt, and facing a\n    specified azimuth. \n    \n    This functions is a wrapper for the incredibly \n    comprehensive `pvlib library <https://github.com/pvlib/pvlib-python>`_, \n    and requires it to be installed.\n    \n    Parameters\n    ----------\n    latitude : float\n        Latitude, between -90 and 90 [degrees]\n    longitude : float\n        Longitude, between -180 and 180, [degrees]\n    Z : float, optional\n        Elevation above sea level for the position, [m]\n    moment : datetime\n        Time and date for the calculation, in local UTC time (not daylight \n        savings time), [-]\n    surface_tilt : float\n        The angle above the horizontal of the object being hit by radiation,\n        [degrees]\n    surface_azimuth : float\n        The angle the object is facing (positive North eastwards 0\u00b0 to 360\u00b0),\n        [degrees]\n    T : float, optional\n        Temperature of atmosphere at ground level, [K]\n    P : float, optional\n        Pressure of atmosphere at ground level, [Pa]\n    solar_constant : float, optional\n        The amount of solar radiation which reaches earth's disk (at a \n        standardized distance of 1 AU); this constant is independent of \n        activity or conditions on earth, but will vary throughout the sun's\n        lifetime and may increase or decrease slightly due to solar activity,\n        [W/m^2]\n    atmos_refract : float, optional\n        Atmospheric refractivity at sunrise/sunset (0.5667 deg is an often used\n        value; this varies substantially and has an impact of a few minutes on \n        when sunrise and sunset is), [degrees]\n    albedo : float, optional\n        The average amount of reflection of the terrain surrounding the object\n        at quite a distance; this impacts how much sunlight reflected off the\n        ground, gest reflected back off clouds, [-]\n    linke_turbidity : float, optional\n        The amount of pollution/water in the sky versus a perfect clear sky;\n        If not specified, this will be retrieved from a historical grid;\n        typical values are 3 for cloudy, and 7 for severe pollution around a\n        city, [-]\n    extraradiation_method : str, optional\n        The specified method to calculate the effect of earth's position on the\n        amount of radiation which reaches earth according to the methods \n        available in the `pvlib` library, [-]\n    airmass_model : str, optional\n        The specified method to calculate the amount of air the sunlight\n        needs to travel through to reach the earth according to the methods \n        available in the `pvlib` library, [-]\n    cache : dict, optional\n        Dictionary to to check for values to use to skip some calculations;\n        `apparent_zenith`, `zenith`, `azimuth` supported, [-]\n\n    Returns\n    -------\n    poa_global : float\n        The total irradiance in the plane of the surface, [W/m^2]\n    poa_direct : float\n        The total beam irradiance in the plane of the surface, [W/m^2]\n    poa_diffuse : float\n        The total diffuse irradiance in the plane of the surface, [W/m^2]\n    poa_sky_diffuse : float\n        The sky component of the diffuse irradiance, excluding the impact \n        from the ground, [W/m^2]\n    poa_ground_diffuse : float\n        The ground-sky diffuse irradiance component, [W/m^2]\n\n    Examples\n    --------\n    >>> solar_irradiation(Z=1100.0, latitude=51.0486, longitude=-114.07, \n    ... moment=datetime(2018, 4, 15, 13, 43, 5), surface_tilt=41.0, \n    ... surface_azimuth=180.0)\n    (1065.7621896280812, 945.2656564506323, 120.49653317744884, 95.31535344213178, 25.181179735317063)\n    \n    >>> cache = {'apparent_zenith': 41.099082295767545, 'zenith': 41.11285376417578, 'azimuth': 182.5631874250523}\n    >>> solar_irradiation(Z=1100.0, latitude=51.0486, longitude=-114.07, \n    ... moment=datetime(2018, 4, 15, 13, 43, 5), surface_tilt=41.0, \n    ... linke_turbidity=3, T=300, P=1E5,\n    ... surface_azimuth=180.0, cache=cache)\n    (1042.5677703677097, 918.2377548545295, 124.33001551318027, 99.6228657378363, 24.70714977534396)\n\n    At night, there is no solar radiation and this function returns zeros:\n        \n    >>> solar_irradiation(Z=1100.0, latitude=51.0486, longitude=-114.07, \n    ... moment=datetime(2018, 4, 15, 2, 43, 5), surface_tilt=41.0, \n    ... surface_azimuth=180.0)\n    (0.0, -0.0, 0.0, 0.0, 0.0)\n    \n\n    Notes\n    -----    \n    The retrieval of `linke_turbidity` requires the pytables library (and \n    Pandas); if it is not installed, specify a value of `linke_turbidity` to \n    avoid the dependency.\n    \n    There is some redundancy of the calculated results, according to the \n    following relations. The total irradiance is normally that desired for \n    engineering calculations.\n    \n    poa_diffuse = poa_ground_diffuse + poa_sky_diffuse\n    \n    poa_global = poa_direct + poa_diffuse\n    \n    FOr a surface such as a pipe or vessel, an approach would be to split it\n    into a number of rectangles and sum up the radiation absorbed by each.\n    \n    This calculation is fairly slow. \n\n    References\n    ----------\n    .. [1] Will Holmgren, Calama-Consulting, Tony Lorenzo, Uwe Krien, bmu, \n       DaCoEx, mayudong, et al. Pvlib/Pvlib-Python: 0.5.1. Zenodo, 2017. \n       https://doi.org/10.5281/zenodo.1016425.\n    '''\n    # Atmospheric refraction at sunrise/sunset (0.5667 deg is an often used value)\n    from fluids.optional import spa\n    from fluids.optional.irradiance import (get_relative_airmass, get_absolute_airmass,\n                                            ineichen, get_relative_airmass, \n                                            get_absolute_airmass, get_total_irradiance)\n#    try:\n#        import pvlib\n#    except:\n#        raise ImportError(PVLIB_MISSING_MSG)\n\n    moment_timetuple = moment.timetuple()\n    moment_arg_dni = (moment_timetuple.tm_yday if \n                      extraradiation_method == 'spencer' else moment)\n\n    dni_extra = _get_extra_radiation_shim(moment_arg_dni, solar_constant=solar_constant, \n                               method=extraradiation_method, \n                               epoch_year=moment.year)\n    \n    if T is None or P is None:\n        atmosphere = ATMOSPHERE_NRLMSISE00(Z=Z, latitude=latitude, \n                                           longitude=longitude, \n                                           day=moment_timetuple.tm_yday)\n        if T is None:\n            T = atmosphere.T\n        if P is None:\n            P = atmosphere.P\n    \n    if cache is not None and 'zenith' in cache:\n        zenith = cache['zenith']\n        apparent_zenith = cache['apparent_zenith']\n        azimuth = cache['azimuth']\n    else:\n        apparent_zenith, zenith, _, _, azimuth, _ = solar_position(moment=moment,\n                                                                   latitude=latitude, \n                                                                   longitude=longitude,\n                                                                   Z=Z, T=T, P=P, \n                                                                   atmos_refract=atmos_refract)\n    \n    if linke_turbidity is None:\n        from pvlib.clearsky import lookup_linke_turbidity\n        import pandas as pd\n        linke_turbidity = float(lookup_linke_turbidity(\n            pd.DatetimeIndex([moment]), latitude, longitude).values)\n\n        \n    if airmass_model in apparent_zenith_airmass_models:\n        used_zenith = apparent_zenith\n    elif airmass_model in true_zenith_airmass_models:\n        used_zenith = zenith\n    else:\n        raise Exception('Unrecognized airmass model')\n    \n    relative_airmass = get_relative_airmass(used_zenith, model=airmass_model)\n    airmass_absolute = get_absolute_airmass(relative_airmass, pressure=P)\n\n\n    ans = ineichen(apparent_zenith=apparent_zenith,\n                   airmass_absolute=airmass_absolute, \n                   linke_turbidity=linke_turbidity,\n                   altitude=Z, dni_extra=solar_constant, perez_enhancement=True)\n    ghi = ans['ghi']\n    dni = ans['dni']\n    dhi = ans['dhi']\n    \n    \n#    from pvlib.irradiance import get_total_irradiance\n    ans = get_total_irradiance(surface_tilt=surface_tilt, \n                      surface_azimuth=surface_azimuth,\n                      solar_zenith=apparent_zenith, solar_azimuth=azimuth,\n                      dni=dni, ghi=ghi, dhi=dhi, dni_extra=dni_extra, \n                      airmass=airmass_absolute, albedo=albedo)\n    poa_global = float(ans['poa_global'])\n    poa_direct = float(ans['poa_direct'])\n    poa_diffuse = float(ans['poa_diffuse'])\n    poa_sky_diffuse = float(ans['poa_sky_diffuse'])\n    poa_ground_diffuse = float(ans['poa_ground_diffuse'])\n    return (poa_global, poa_direct, poa_diffuse, poa_sky_diffuse, \n            poa_ground_diffuse)", "response": "r Calculates the amount of solar irradiation for a given location."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pressure_integral(T1, P1, dH):\n        r'''Method to compute an integral of the pressure differential of an\n        elevation difference with a base elevation defined by temperature `T1`\n        and pressure `P1`. This is \n        similar to subtracting the pressures at two different elevations,\n        except it allows for local conditions (temperature and pressure) to be\n        taken into account. This is useful for e.x. evaluating the pressure\n        difference between the top and bottom of a natural draft cooling tower.\n        \n    \n        Parameters\n        ----------\n        T1 : float\n            Temperature at the lower elevation condition, [K]\n        P1 : float\n            Pressure at the lower elevation condition, [Pa]\n        dH : float\n            Elevation difference for which to evaluate the pressure difference,\n            [m]\n            \n        Returns\n        -------\n        delta_P : float\n            Pressure difference between the elevations, [Pa]\n        '''\n        # Compute the elevation to obtain the pressure specified\n        def to_solve(H):\n            return ATMOSPHERE_1976(H).P - P1\n        H_ref = brenth(to_solve, -610.0, 86000)\n        \n        # Compute the temperature delta\n        dT = T1 - ATMOSPHERE_1976(H_ref).T\n        \n        def to_int(Z):\n            atm = ATMOSPHERE_1976(Z, dT=dT)\n            return atm.g*atm.rho\n        from scipy.integrate import quad\n        return float(quad(to_int, H_ref, H_ref+dH)[0])", "response": "r Compute an integral of the pressure differential of an animal with a base elevation defined by temperature T1 and pressure P1. This method computes the integral of the pressure differential of animal with a base elevation defined by temperature T1 and pressure P1."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef API520_SH(T1, P1):\n    r'''Calculates correction due to steam superheat for steam flow for use in\n    API 520 relief valve sizing. 2D interpolation among a table with 28\n    pressures and 10 temperatures is performed.\n\n\n    Parameters\n    ----------\n    T1 : float\n        Temperature of the fluid entering the valve [K]\n    P1 : float\n        Upstream relieving pressure; the set pressure plus the allowable\n        overpressure, plus atmospheric pressure, [Pa]\n\n    Returns\n    -------\n    KSH : float\n        Correction due to steam superheat [-]\n\n    Notes\n    -----\n    For P above 20679 kPag, use the critical flow model.\n    Superheat cannot be above 649 degrees Celsius.\n    If T1 is above 149 degrees Celsius, returns 1.\n\n    Examples\n    --------\n    Custom example from table 9:\n\n    >>> API520_SH(593+273.15, 1066.325E3)\n    0.7201800000000002\n\n    References\n    ----------\n    .. [1] API Standard 520, Part 1 - Sizing and Selection.\n    '''\n    if P1 > 20780325.0: # 20679E3+atm\n        raise Exception('For P above 20679 kPag, use the critical flow model')\n    if T1 > 922.15:\n        raise Exception('Superheat cannot be above 649 degrees Celcius')\n    if T1 < 422.15:\n        return 1. # No superheat under 15 psig\n    return float(bisplev(T1, P1, API520_KSH_tck))", "response": "r Calculates the correction due to steam superheat for use in a fluid in a specific order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the font face of the current element.", "response": "def atFontFace(self, declarations):\n        \"\"\"\n        Embed fonts\n        \"\"\"\n        result = self.ruleset([self.selector('*')], declarations)\n        data = list(result[0].values())[0]\n        if \"src\" not in data:\n            # invalid - source is required, ignore this specification\n            return {}, {}\n        names = data[\"font-family\"]\n\n        # Font weight\n        fweight = str(data.get(\"font-weight\", \"normal\")).lower()\n        bold = fweight in (\"bold\", \"bolder\", \"500\", \"600\", \"700\", \"800\", \"900\")\n        if not bold and fweight != \"normal\":\n            log.warn(\n                self.c.warning(\"@fontface, unknown value font-weight '%s'\", fweight))\n\n        # Font style\n        italic = str(\n            data.get(\"font-style\", \"\")).lower() in (\"italic\", \"oblique\")\n\n        # The \"src\" attribute can be a CSS group but in that case\n        # ignore everything except the font URI\n        uri = data['src']\n        if not isinstance(data['src'], str):\n            for part in uri:\n                if isinstance(part, str):\n                    uri = part\n                    break\n\n        src = self.c.getFile(uri, relative=self.c.cssParser.rootPath)\n        self.c.loadFont(\n            names,\n            src,\n            bold=bold,\n            italic=italic)\n        return {}, {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getFile(self, name, relative=None):\n        if self.pathCallback is not None:\n            return getFile(self._getFileDeprecated(name, relative))\n        return getFile(name, relative or self.pathDirectory)", "response": "Returns a file name or None if no such file exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of a font in the current font list.", "response": "def getFontName(self, names, default=\"helvetica\"):\n        \"\"\"\n        Name of a font\n        \"\"\"\n        # print names, self.fontList\n        if type(names) is not ListType:\n            if type(names) not in six.string_types:\n                names = str(names)\n            names = names.strip().split(\",\")\n        for name in names:\n            if type(name) not in six.string_types:\n                name = str(name)\n            font = self.fontList.get(name.strip().lower(), None)\n            if font is not None:\n                return font\n        return self.fontList.get(default, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncollects all CSS definitions", "response": "def pisaPreLoop(node, context, collect=False):\n    \"\"\"\n    Collect all CSS definitions\n    \"\"\"\n\n    data = u\"\"\n    if node.nodeType == Node.TEXT_NODE and collect:\n        data = node.data\n\n    elif node.nodeType == Node.ELEMENT_NODE:\n        name = node.tagName.lower()\n\n        if name in (\"style\", \"link\"):\n            attr = pisaGetAttributes(context, name, node.attributes)\n            media = [x.strip()\n                     for x in attr.media.lower().split(\",\") if x.strip()]\n\n            if attr.get(\"type\", \"\").lower() in (\"\", \"text/css\") and \\\n                    (not media or \"all\" in media or \"print\" in media or \"pdf\" in media):\n\n                if name == \"style\":\n                    for node in node.childNodes:\n                        data += pisaPreLoop(node, context, collect=True)\n                    context.addCSS(data)\n                    return u\"\"\n\n                if name == \"link\" and attr.href and attr.rel.lower() == \"stylesheet\":\n                    # print \"CSS LINK\", attr\n                    context.addCSS('\\n@import \"%s\" %s;' %\n                                   (attr.href, \",\".join(media)))\n\n    for node in node.childNodes:\n        result = pisaPreLoop(node, context, collect=collect)\n        if collect:\n            data += result\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pisaParser(src, context, default_css=\"\", xhtml=False, encoding=None, xml_output=None):\n\n    global CSSAttrCache\n    CSSAttrCache = {}\n\n    if xhtml:\n        # TODO: XHTMLParser doesn't see to exist...\n        parser = html5lib.XHTMLParser(tree=treebuilders.getTreeBuilder(\"dom\"))\n    else:\n        parser = html5lib.HTMLParser(tree=treebuilders.getTreeBuilder(\"dom\"))\n\n    if isinstance(src, six.text_type):\n        # If an encoding was provided, do not change it.\n        if not encoding:\n            encoding = \"utf-8\"\n        src = src.encode(encoding)\n        src = pisaTempFile(src, capacity=context.capacity)\n\n    # # Test for the restrictions of html5lib\n    # if encoding:\n    #     # Workaround for html5lib<0.11.1\n    #     if hasattr(inputstream, \"isValidEncoding\"):\n    #         if encoding.strip().lower() == \"utf8\":\n    #             encoding = \"utf-8\"\n    #         if not inputstream.isValidEncoding(encoding):\n    #             log.error(\"%r is not a valid encoding e.g. 'utf8' is not valid but 'utf-8' is!\", encoding)\n    #     else:\n    #         if inputstream.codecName(encoding) is None:\n    #             log.error(\"%r is not a valid encoding\", encoding)\n    document = parser.parse(\n        src,\n    )  # encoding=encoding)\n\n    if xml_output:\n        if encoding:\n            xml_output.write(document.toprettyxml(encoding=encoding))\n        else:\n            xml_output.write(document.toprettyxml(encoding=\"utf8\"))\n\n    if default_css:\n        context.addDefaultCSS(default_css)\n\n    pisaPreLoop(document, context)\n    # try:\n    context.parseCSS()\n    # except:\n    #    context.cssText = DEFAULT_CSS\n    #    context.parseCSS()\n    # context.debug(9, pprint.pformat(context.css))\n\n    pisaLoop(document, context)\n    return context", "response": "Parse HTML and get miniDOM\n    - Parse CSS and add default CSS and parse CSS"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naligning words in previous line.", "response": "def doLayout(self, width):\n        \"\"\"\n        Align words in previous line.\n        \"\"\"\n\n        # Calculate dimensions\n        self.width = width\n\n        font_sizes = [0] + [frag.get(\"fontSize\", 0) for frag in self]\n        self.fontSize = max(font_sizes)\n        self.height = self.lineHeight = max(frag * self.LINEHEIGHT for frag in font_sizes)\n\n        # Apply line height\n        y = (self.lineHeight - self.fontSize) # / 2\n        for frag in self:\n            frag[\"y\"] = y\n\n        return self.height"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef splitIntoLines(self, maxWidth, maxHeight, splitted=False):\n        self.lines = []\n        self.height = 0\n        self.maxWidth = self.width = maxWidth\n        self.maxHeight = maxHeight\n        boxStack = []\n\n        style = self.style\n        x = 0\n\n        # Start with indent in first line of text\n        if not splitted:\n            x = style[\"textIndent\"]\n\n        lenText = len(self)\n        pos = 0\n        while pos < lenText:\n\n            # Reset values for new line\n            posBegin = pos\n            line = Line(style)\n\n            # Update boxes for next line\n            for box in copy.copy(boxStack):\n                box[\"x\"] = 0\n                line.append(BoxBegin(box))\n\n            while pos < lenText:\n\n                # Get fragment, its width and set X\n                frag = self[pos]\n                fragWidth = frag[\"width\"]\n                frag[\"x\"] = x\n                pos += 1\n\n                # Keep in mind boxes for next lines\n                if isinstance(frag, BoxBegin):\n                    boxStack.append(frag)\n                elif isinstance(frag, BoxEnd):\n                    boxStack.pop()\n\n                # If space or linebreak handle special way\n                if frag.isSoft:\n                    if frag.isLF:\n                        line.append(frag)\n                        break\n                        # First element of line should not be a space\n                    if x == 0:\n                        continue\n                        # Keep in mind last possible line break\n\n                # The elements exceed the current line\n                elif fragWidth + x > maxWidth:\n                    break\n\n                # Add fragment to line and update x\n                x += fragWidth\n                line.append(frag)\n\n            # Remove trailing white spaces\n            while line and line[-1].name in (\"space\", \"br\"):\n                line.pop()\n\n            # Add line to list\n            line.dumpFragments()\n            # if line:\n            self.height += line.doLayout(self.width)\n            self.lines.append(line)\n\n            # If not enough space for current line force to split\n            if self.height > maxHeight:\n                return posBegin\n\n            # Reset variables\n            x = 0\n\n        # Apply alignment\n        self.lines[- 1].isLast = True\n        for line in self.lines:\n            line.doAlignment(maxWidth, style[\"textAlign\"])\n\n        return None", "response": "Split text into lines and calculate X positions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dumpLines(self):\n        for i, line in enumerate(self.lines):\n            logger.debug(\"Line %d:\", i)\n            logger.debug(line.dumpFragments())", "response": "For debugging dump all lines and their content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine the rectangle this paragraph really needs.", "response": "def wrap(self, availWidth, availHeight):\n        \"\"\"\n        Determine the rectangle this paragraph really needs.\n        \"\"\"\n\n        # memorize available space\n        self.avWidth = availWidth\n        self.avHeight = availHeight\n\n        logger.debug(\"*** wrap (%f, %f)\", availWidth, availHeight)\n\n        if not self.text:\n            logger.debug(\"*** wrap (%f, %f) needed\", 0, 0)\n            return 0, 0\n\n        # Split lines\n        width = availWidth\n        self.splitIndex = self.text.splitIntoLines(width, availHeight)\n\n        self.width, self.height = availWidth, self.text.height\n\n        logger.debug(\"*** wrap (%f, %f) needed, splitIndex %r\", self.width, self.height, self.splitIndex)\n\n        return self.width, self.height"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split(self, availWidth, availHeight):\n\n        logger.debug(\"*** split (%f, %f)\", availWidth, availHeight)\n\n        splitted = []\n        if self.splitIndex:\n            text1 = self.text[:self.splitIndex]\n            text2 = self.text[self.splitIndex:]\n            p1 = Paragraph(Text(text1), self.style, debug=self.debug)\n            p2 = Paragraph(Text(text2), self.style, debug=self.debug, splitted=True)\n            splitted = [p1, p2]\n\n            logger.debug(\"*** text1 %s / text %s\", len(text1), len(text2))\n\n        logger.debug('*** return %s', self.splitted)\n\n        return splitted", "response": "Split ourselves in two paragraphs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw(self):\n\n        logger.debug(\"*** draw\")\n\n        if not self.text:\n            return\n\n        canvas = self.canv\n        style = self.style\n\n        canvas.saveState()\n\n        # Draw box arround paragraph for debugging\n        if self.debug:\n            bw = 0.5\n            bc = Color(1, 1, 0)\n            bg = Color(0.9, 0.9, 0.9)\n            canvas.setStrokeColor(bc)\n            canvas.setLineWidth(bw)\n            canvas.setFillColor(bg)\n            canvas.rect(\n                style.leftIndent,\n                0,\n                self.width,\n                self.height,\n                fill=1,\n                stroke=1)\n\n        y = 0\n        dy = self.height\n        for line in self.text.lines:\n            y += line.height\n            for frag in line:\n\n                # Box\n                if hasattr(frag, \"draw\"):\n                    frag.draw(canvas, dy - y)\n\n                # Text\n                if frag.get(\"text\", \"\"):\n                    canvas.setFont(frag[\"fontName\"], frag[\"fontSize\"])\n                    canvas.setFillColor(frag.get(\"color\", style[\"color\"]))\n                    canvas.drawString(frag[\"x\"], dy - y + frag[\"y\"], frag[\"text\"])\n\n                # XXX LINK\n                link = frag.get(\"link\", None)\n                if link:\n                    _scheme_re = re.compile('^[a-zA-Z][-+a-zA-Z0-9]+$')\n                    x, y, w, h = frag[\"x\"], dy - y, frag[\"width\"], frag[\"fontSize\"]\n                    rect = (x, y, w, h)\n                    if isinstance(link, six.text_type):\n                        link = link.encode('utf8')\n                    parts = link.split(':', 1)\n                    scheme = len(parts) == 2 and parts[0].lower() or ''\n                    if _scheme_re.match(scheme) and scheme != 'document':\n                        kind = scheme.lower() == 'pdf' and 'GoToR' or 'URI'\n                        if kind == 'GoToR':\n                            link = parts[1]\n\n                        canvas.linkURL(link, rect, relative=1, kind=kind)\n                    else:\n                        if link[0] == '#':\n                            link = link[1:]\n                            scheme = ''\n                        canvas.linkRect(\"\", scheme != 'document' and link or parts[1], rect, relative=1)\n\n        canvas.restoreState()", "response": "Render the content of the paragraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef showLogging(debug=False):\n\n    try:\n        log_level = logging.WARN\n        log_format = LOG_FORMAT_DEBUG\n        if debug:\n            log_level = logging.DEBUG\n        logging.basicConfig(\n            level=log_level,\n            format=log_format)\n    except:\n        logging.basicConfig()", "response": "Shortcut for enabling log dump\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits a list of border styles into three elements.", "response": "def splitBorder(parts):\n    \"\"\"\n    The order of the elements seems to be of no importance:\n\n    http://www.w3.org/TR/CSS21/box.html#border-shorthand-properties\n    \"\"\"\n\n    width = style = color = None\n\n    if len(parts) > 3:\n        log.warn(\"To many elements for border style %r\", parts)\n\n    for part in parts:\n        # Width\n        if isSize(part):\n            width = part\n\n        # Style\n        elif hasattr(part, 'lower') and part.lower() in _borderStyleTable:\n            style = part\n\n        # Color\n        else:\n            color = part\n\n    # log.debug(\"Border styles: %r -> %r \", copy_parts, (width, style, color))\n\n    return (width, style, color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseFile(self, srcFile, closeFile=False):\n\n        try:\n            result = self.parse(srcFile.read())\n        finally:\n            if closeFile:\n                srcFile.close()\n        return result", "response": "Parses a CSS file - like object using the current cssBuilder.\n        Use for external stylesheets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the given CSS string source using the current cssBuilder. Use for embedded stylesheets.", "response": "def parse(self, src):\n        \"\"\"Parses CSS string source using the current cssBuilder.\n        Use for embedded stylesheets.\"\"\"\n\n        self.cssBuilder.beginStylesheet()\n        try:\n\n            # XXX Some simple preprocessing\n            src = cssSpecial.cleanupCSS(src)\n\n            try:\n                src, stylesheet = self._parseStylesheet(src)\n            except self.ParseError as err:\n                err.setFullCSSSource(src)\n                raise\n        finally:\n            self.cssBuilder.endStylesheet()\n        return stylesheet"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseInline(self, src):\n\n        self.cssBuilder.beginInline()\n        try:\n            try:\n                src, properties = self._parseDeclarationGroup(src.strip(), braces=False)\n            except self.ParseError as err:\n                err.setFullCSSSource(src, inline=True)\n                raise\n\n            result = self.cssBuilder.inline(properties)\n        finally:\n            self.cssBuilder.endInline()\n        return result", "response": "Parses the CSS inline source string using the current cssBuilder.\n        Use to parse a tag s sytle - like attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseAttributes(self, attributes=None, **kwAttributes):\n        attributes = attributes if attributes is not None else {}\n        if attributes:\n            kwAttributes.update(attributes)\n\n        self.cssBuilder.beginInline()\n        try:\n            properties = []\n            try:\n                for propertyName, src in six.iteritems(kwAttributes):\n                    src, property = self._parseDeclarationProperty(src.strip(), propertyName)\n                    properties.append(property)\n\n            except self.ParseError as err:\n                err.setFullCSSSource(src, inline=True)\n                raise\n\n            result = self.cssBuilder.inline(properties)\n        finally:\n            self.cssBuilder.endInline()\n        return result", "response": "Parses CSS attribute source strings and returns as an inline stylesheet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a single CSS attribute source string and returns the built CSS expression.", "response": "def parseSingleAttr(self, attrValue):\n        \"\"\"Parse a single CSS attribute source string, and returns the built CSS expression.\n        Use to parse a tag's highly CSS-based attributes like 'font'.\n\n        See also: parseAttributes\n        \"\"\"\n\n        results = self.parseAttributes(temp=attrValue)\n        if 'temp' in results[1]:\n            return results[1]['temp']\n        else:\n            return results[0]['temp']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a stylesheet from a source string.", "response": "def _parseStylesheet(self, src):\n        \"\"\"stylesheet\n        : [ CHARSET_SYM S* STRING S* ';' ]?\n            [S|CDO|CDC]* [ import [S|CDO|CDC]* ]*\n            [ [ ruleset | media | page | font_face ] [S|CDO|CDC]* ]*\n        ;\n        \"\"\"\n        # FIXME: BYTES to STR \n        if type(src) == six.binary_type:\n            src=six.text_type(src)\n        # Get rid of the comments\n        src = self.re_comment.sub('', src)\n\n        # [ CHARSET_SYM S* STRING S* ';' ]?\n        src = self._parseAtCharset(src)\n\n        # [S|CDO|CDC]*\n        src = self._parseSCDOCDC(src)\n        #  [ import [S|CDO|CDC]* ]*\n        src, stylesheetImports = self._parseAtImports(src)\n\n        # [ namespace [S|CDO|CDC]* ]*\n        src = self._parseAtNamespace(src)\n\n        stylesheetElements = []\n\n        # [ [ ruleset | atkeywords ] [S|CDO|CDC]* ]*\n        while src: # due to ending with ]*\n            if src.startswith('@'):\n                # @media, @page, @font-face\n                src, atResults = self._parseAtKeyword(src)\n                if atResults is not None and atResults != NotImplemented:\n                    stylesheetElements.extend(atResults)\n            else:\n                # ruleset\n                src, ruleset = self._parseRuleset(src)\n                stylesheetElements.append(ruleset)\n\n            # [S|CDO|CDC]*\n            src = self._parseSCDOCDC(src)\n\n        stylesheet = self.cssBuilder.stylesheet(stylesheetElements, stylesheetImports)\n        return src, stylesheet"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the SCDOC - DC source string.", "response": "def _parseSCDOCDC(self, src):\n        \"\"\"[S|CDO|CDC]*\"\"\"\n        while 1:\n            src = src.lstrip()\n            if src.startswith('<!--'):\n                src = src[4:]\n            elif src.startswith('-->'):\n                src = src[3:]\n            else:\n                break\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the at - charset rule.", "response": "def _parseAtCharset(self, src):\n        \"\"\"[ CHARSET_SYM S* STRING S* ';' ]?\"\"\"\n        if isAtRuleIdent(src, 'charset'):\n            src = stripAtRuleIdent(src)\n            charset, src = self._getString(src)\n            src = src.lstrip()\n            if src[:1] != ';':\n                raise self.ParseError('@charset expected a terminating \\';\\'', src, self.ctxsrc)\n            src = src[1:].lstrip()\n\n            self.cssBuilder.atCharset(charset)\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the atImports rule.", "response": "def _parseAtImports(self, src):\n        \"\"\"[ import [S|CDO|CDC]* ]*\"\"\"\n        result = []\n        while isAtRuleIdent(src, 'import'):\n            ctxsrc = src\n            src = stripAtRuleIdent(src)\n\n            import_, src = self._getStringOrURI(src)\n            if import_ is None:\n                raise self.ParseError('Import expecting string or url', src, ctxsrc)\n\n            mediums = []\n            medium, src = self._getIdent(src.lstrip())\n            while medium is not None:\n                mediums.append(medium)\n                if src[:1] == ',':\n                    src = src[1:].lstrip()\n                    medium, src = self._getIdent(src)\n                else:\n                    break\n\n            # XXX No medium inherits and then \"all\" is appropriate\n            if not mediums:\n                mediums = [\"all\"]\n\n            if src[:1] != ';':\n                raise self.ParseError('@import expected a terminating \\';\\'', src, ctxsrc)\n            src = src[1:].lstrip()\n\n            stylesheet = self.cssBuilder.atImport(import_, mediums, self)\n            if stylesheet is not None:\n                result.append(stylesheet)\n\n            src = self._parseSCDOCDC(src)\n        return src, result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parseAtNamespace(self, src):\n\n        src = self._parseSCDOCDC(src)\n        while isAtRuleIdent(src, 'namespace'):\n            ctxsrc = src\n            src = stripAtRuleIdent(src)\n\n            namespace, src = self._getStringOrURI(src)\n            if namespace is None:\n                nsPrefix, src = self._getIdent(src)\n                if nsPrefix is None:\n                    raise self.ParseError('@namespace expected an identifier or a URI', src, ctxsrc)\n                namespace, src = self._getStringOrURI(src.lstrip())\n                if namespace is None:\n                    raise self.ParseError('@namespace expected a URI', src, ctxsrc)\n            else:\n                nsPrefix = None\n\n            src = src.lstrip()\n            if src[:1] != ';':\n                raise self.ParseError('@namespace expected a terminating \\';\\'', src, ctxsrc)\n            src = src[1:].lstrip()\n\n            self.cssBuilder.atNamespace(nsPrefix, namespace)\n\n            src = self._parseSCDOCDC(src)\n        return src", "response": "namespace :\n\n        @namespace S* [IDENT S*]? [STRING|URI] S* ';' S*"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the at keyword.", "response": "def _parseAtKeyword(self, src):\n        \"\"\"[media | page | font_face | unknown_keyword]\"\"\"\n        ctxsrc = src\n        if isAtRuleIdent(src, 'media'):\n            src, result = self._parseAtMedia(src)\n        elif isAtRuleIdent(src, 'page'):\n            src, result = self._parseAtPage(src)\n        elif isAtRuleIdent(src, 'font-face'):\n            src, result = self._parseAtFontFace(src)\n        # XXX added @import, was missing!\n        elif isAtRuleIdent(src, 'import'):\n            src, result = self._parseAtImports(src)\n        elif isAtRuleIdent(src, 'frame'):\n            src, result = self._parseAtFrame(src)\n        elif src.startswith('@'):\n            src, result = self._parseAtIdent(src)\n        else:\n            raise self.ParseError('Unknown state in atKeyword', src, ctxsrc)\n        return src, result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parseAtMedia(self, src):\n        ctxsrc = src\n        src = src[len('@media '):].lstrip()\n        mediums = []\n        while src and src[0] != '{':\n            medium, src = self._getIdent(src)\n            if medium is None:\n                raise self.ParseError('@media rule expected media identifier', src, ctxsrc)\n            # make \"and ... {\" work\n            if medium == 'and':\n                # strip up to curly bracket\n                pattern = re.compile('.*({.*)')\n                match = re.match(pattern, src)\n                src = src[match.end()-1:]\n                break\n            mediums.append(medium)\n            if src[0] == ',':\n                src = src[1:].lstrip()\n            else:\n                src = src.lstrip()\n\n        if not src.startswith('{'):\n            raise self.ParseError('Ruleset opening \\'{\\' not found', src, ctxsrc)\n        src = src[1:].lstrip()\n\n        stylesheetElements = []\n        #while src and not src.startswith('}'):\n        #    src, ruleset = self._parseRuleset(src)\n        #    stylesheetElements.append(ruleset)\n        #    src = src.lstrip()\n\n        # Containing @ where not found and parsed\n        while src and not src.startswith('}'):\n            if src.startswith('@'):\n                # @media, @page, @font-face\n                src, atResults = self._parseAtKeyword(src)\n                if atResults is not None:\n                    stylesheetElements.extend(atResults)\n            else:\n                # ruleset\n                src, ruleset = self._parseRuleset(src)\n                stylesheetElements.append(ruleset)\n            src = src.lstrip()\n\n        if not src.startswith('}'):\n            raise self.ParseError('Ruleset closing \\'}\\' not found', src, ctxsrc)\n        else:\n            src = src[1:].lstrip()\n\n        result = self.cssBuilder.atMedia(mediums, stylesheetElements)\n        return src, result", "response": "Parse the at - media rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the at - page rule.", "response": "def _parseAtPage(self, src):\n        \"\"\"page\n        : PAGE_SYM S* IDENT? pseudo_page? S*\n            '{' S* declaration [ ';' S* declaration ]* '}' S*\n        ;\n        \"\"\"\n        ctxsrc = src\n        src = src[len('@page'):].lstrip()\n        page, src = self._getIdent(src)\n        if src[:1] == ':':\n            pseudopage, src = self._getIdent(src[1:])\n            page = page + '_' + pseudopage\n        else:\n            pseudopage = None\n\n        #src, properties = self._parseDeclarationGroup(src.lstrip())\n\n        # Containing @ where not found and parsed\n        stylesheetElements = []\n        src = src.lstrip()\n        properties = []\n\n        # XXX Extended for PDF use\n        if not src.startswith('{'):\n            raise self.ParseError('Ruleset opening \\'{\\' not found', src, ctxsrc)\n        else:\n            src = src[1:].lstrip()\n\n        while src and not src.startswith('}'):\n            if src.startswith('@'):\n                # @media, @page, @font-face\n                src, atResults = self._parseAtKeyword(src)\n                if atResults is not None:\n                    stylesheetElements.extend(atResults)\n            else:\n                src, nproperties = self._parseDeclarationGroup(src.lstrip(), braces=False)\n                properties += nproperties\n            src = src.lstrip()\n\n        result = [self.cssBuilder.atPage(page, pseudopage, properties)]\n\n        return src[1:].lstrip(), result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an atFrame tag.", "response": "def _parseAtFrame(self, src):\n        \"\"\"\n        XXX Proprietary for PDF\n        \"\"\"\n        src = src[len('@frame '):].lstrip()\n        box, src = self._getIdent(src)\n        src, properties = self._parseDeclarationGroup(src.lstrip())\n        result = [self.cssBuilder.atFrame(box, properties)]\n        return src.lstrip(), result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parseRuleset(self, src):\n        src, selectors = self._parseSelectorGroup(src)\n        src, properties = self._parseDeclarationGroup(src.lstrip())\n        result = self.cssBuilder.ruleset(selectors, properties)\n        return src, result", "response": "parse a set of CSS rules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a selector from a source string.", "response": "def _parseSelector(self, src):\n        \"\"\"selector\n        : simple_selector [ combinator simple_selector ]*\n        ;\n        \"\"\"\n        src, selector = self._parseSimpleSelector(src)\n        srcLen = len(src) # XXX\n        while src[:1] not in ('', ',', ';', '{', '}', '[', ']', '(', ')'):\n            for combiner in self.SelectorCombiners:\n                if src.startswith(combiner):\n                    src = src[len(combiner):].lstrip()\n                    break\n            else:\n                combiner = ' '\n            src, selectorB = self._parseSimpleSelector(src)\n\n            # XXX Fix a bug that occured here e.g. : .1 {...}\n            if len(src) >= srcLen:\n                src = src[1:]\n                while src and (src[:1] not in ('', ',', ';', '{', '}', '[', ']', '(', ')')):\n                    src = src[1:]\n                return src.lstrip(), None\n\n            selector = self.cssBuilder.combineSelectors(selector, combiner, selectorB)\n\n        return src.lstrip(), selector"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parseSimpleSelector(self, src):\n        ctxsrc = src.lstrip()\n        nsPrefix, src = self._getMatchResult(self.re_namespace_selector, src)\n        name, src = self._getMatchResult(self.re_element_name, src)\n        if name:\n            pass # already *successfully* assigned\n        elif src[:1] in self.SelectorQualifiers:\n            name = '*'\n        else:\n            raise self.ParseError('Selector name or qualifier expected', src, ctxsrc)\n\n        name = self.cssBuilder.resolveNamespacePrefix(nsPrefix, name)\n        selector = self.cssBuilder.selector(name)\n        while src and src[:1] in self.SelectorQualifiers:\n            hash_, src = self._getMatchResult(self.re_hash, src)\n            if hash_ is not None:\n                selector.addHashId(hash_)\n                continue\n\n            class_, src = self._getMatchResult(self.re_class, src)\n            if class_ is not None:\n                selector.addClass(class_)\n                continue\n\n            if src.startswith('['):\n                src, selector = self._parseSelectorAttribute(src, selector)\n            elif src.startswith(':'):\n                src, selector = self._parseSelectorPseudo(src, selector)\n            else:\n                break\n\n        return src.lstrip(), selector", "response": "Parses a simple selector from the source string src."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a selector attribute.", "response": "def _parseSelectorAttribute(self, src, selector):\n        \"\"\"attrib\n        : '[' S* [ namespace_selector ]? IDENT S* [ [ '=' | INCLUDES | DASHMATCH ] S*\n            [ IDENT | STRING ] S* ]? ']'\n        ;\n        \"\"\"\n        ctxsrc = src\n        if not src.startswith('['):\n            raise self.ParseError('Selector Attribute opening \\'[\\' not found', src, ctxsrc)\n        src = src[1:].lstrip()\n\n        nsPrefix, src = self._getMatchResult(self.re_namespace_selector, src)\n        attrName, src = self._getIdent(src)\n\n        src = src.lstrip()\n\n        if attrName is None:\n            raise self.ParseError('Expected a selector attribute name', src, ctxsrc)\n        if nsPrefix is not None:\n            attrName = self.cssBuilder.resolveNamespacePrefix(nsPrefix, attrName)\n\n        for op in self.AttributeOperators:\n            if src.startswith(op):\n                break\n        else:\n            op = ''\n        src = src[len(op):].lstrip()\n\n        if op:\n            attrValue, src = self._getIdent(src)\n            if attrValue is None:\n                attrValue, src = self._getString(src)\n                if attrValue is None:\n                    raise self.ParseError('Expected a selector attribute value', src, ctxsrc)\n        else:\n            attrValue = None\n\n        if not src.startswith(']'):\n            raise self.ParseError('Selector Attribute closing \\']\\' not found', src, ctxsrc)\n        else:\n            src = src[1:]\n\n        if op:\n            selector.addAttributeOperation(attrName, op, attrValue)\n        else:\n            selector.addAttribute(attrName)\n        return src, selector"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a selector pseudo.", "response": "def _parseSelectorPseudo(self, src, selector):\n        \"\"\"pseudo\n        : ':' [ IDENT | function ]\n        ;\n        \"\"\"\n        ctxsrc = src\n        if not src.startswith(':'):\n            raise self.ParseError('Selector Pseudo \\':\\' not found', src, ctxsrc)\n        src = re.search('^:{1,2}(.*)', src, re.M | re.S).group(1)\n\n        name, src = self._getIdent(src)\n        if not name:\n            raise self.ParseError('Selector Pseudo identifier not found', src, ctxsrc)\n\n        if src.startswith('('):\n            # function\n            src = src[1:].lstrip()\n            src, term = self._parseExpression(src, True)\n            if not src.startswith(')'):\n                raise self.ParseError('Selector Pseudo Function closing \\')\\' not found', src, ctxsrc)\n            src = src[1:]\n            selector.addPseudoFunction(name, term)\n        else:\n            selector.addPseudo(name)\n\n        return src, selector"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the declaration of a we and return the source and the property.", "response": "def _parseDeclaration(self, src):\n        \"\"\"declaration\n        : ident S* ':' S* expr prio?\n        | /* empty */\n        ;\n        \"\"\"\n        # property\n        propertyName, src = self._getIdent(src)\n\n        if propertyName is not None:\n            src = src.lstrip()\n            # S* : S*\n            if src[:1] in (':', '='):\n                # Note: we are being fairly flexable here...  technically, the\n                # \":\" is *required*, but in the name of flexibility we\n                # suppor a null transition, as well as an \"=\" transition\n                src = src[1:].lstrip()\n\n            src, property = self._parseDeclarationProperty(src, propertyName)\n        else:\n            property = None\n\n        return src, property"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parseExpression(self, src, returnList=False):\n        src, term = self._parseExpressionTerm(src)\n        operator = None\n        while src[:1] not in ('', ';', '{', '}', '[', ']', ')'):\n            for operator in self.ExpressionOperators:\n                if src.startswith(operator):\n                    src = src[len(operator):]\n                    break\n            else:\n                operator = ' '\n            src, term2 = self._parseExpressionTerm(src.lstrip())\n            if term2 is NotImplemented:\n                break\n            else:\n                term = self.cssBuilder.combineTerms(term, operator, term2)\n\n        if operator is None and returnList:\n            term = self.cssBuilder.combineTerms(term, None, None)\n            return src, term\n        else:\n            return src, term", "response": "Parse an expression from the source string and return the term and the operator term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parseExpressionTerm(self, src):\n        ctxsrc = src\n\n        result, src = self._getMatchResult(self.re_num, src)\n        if result is not None:\n            units, src = self._getMatchResult(self.re_unit, src)\n            term = self.cssBuilder.termNumber(result, units)\n            return src.lstrip(), term\n\n        result, src = self._getString(src, self.re_uri)\n        if result is not None:\n            # XXX URL!!!!\n            term = self.cssBuilder.termURI(result)\n            return src.lstrip(), term\n\n        result, src = self._getString(src)\n        if result is not None:\n            term = self.cssBuilder.termString(result)\n            return src.lstrip(), term\n\n        result, src = self._getMatchResult(self.re_functionterm, src)\n        if result is not None:\n            src, params = self._parseExpression(src, True)\n            if src[0] != ')':\n                raise self.ParseError('Terminal function expression expected closing \\')\\'', src, ctxsrc)\n            src = src[1:].lstrip()\n            term = self.cssBuilder.termFunction(result, params)\n            return src, term\n\n        result, src = self._getMatchResult(self.re_rgbcolor, src)\n        if result is not None:\n            term = self.cssBuilder.termRGB(result)\n            return src.lstrip(), term\n\n        result, src = self._getMatchResult(self.re_unicoderange, src)\n        if result is not None:\n            term = self.cssBuilder.termUnicodeRange(result)\n            return src.lstrip(), term\n\n        nsPrefix, src = self._getMatchResult(self.re_namespace_selector, src)\n        result, src = self._getIdent(src)\n        if result is not None:\n            if nsPrefix is not None:\n                result = self.cssBuilder.resolveNamespacePrefix(nsPrefix, result)\n            term = self.cssBuilder.termIdent(result)\n            return src.lstrip(), term\n\n        result, src = self._getMatchResult(self.re_unicodeid, src)\n        if result is not None:\n            term = self.cssBuilder.termIdent(result)\n            return src.lstrip(), term\n\n        result, src = self._getMatchResult(self.re_unicodestr, src)\n        if result is not None:\n            term = self.cssBuilder.termString(result)\n            return src.lstrip(), term\n\n        return self.cssBuilder.termUnknown(src)", "response": "Parses a term in the expression src and returns the term and the remaining parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies one function to set of keys cheching if key is in container and sets it as attribute of reportlab.", "response": "def transform_attrs(obj, keys, container, func, extras=None):\n    \"\"\"\n    Allows to apply one function to set of keys cheching if key is in container,\n    also trasform ccs key to report lab keys.\n\n    extras = Are extra params for func, it will be call like func(*[param1, param2]) \n\n    obj = frag\n    keys = [(reportlab, css), ... ]\n    container = cssAttr\n    \"\"\"\n    cpextras = extras\n\n    for reportlab, css in keys:\n        extras = cpextras\n        if extras is None:\n            extras = []\n        elif not isinstance(extras, list):\n            extras = [extras]\n        if css in container:\n            extras.insert(0, container[css])\n            setattr(obj,\n                    reportlab,\n                    func(*extras)\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_attrs(obj1, obj2, attrs):\n    for attr in attrs:\n        value = getattr(obj2, attr) if hasattr(obj2, attr) else None\n        if value is None and isinstance(obj2, dict) and attr in obj2:\n            value = obj2[attr]\n        setattr(obj1, attr, value)", "response": "Copies attributes from obj2 to obj1."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_value(obj, attrs, value, _copy=False):\n    for attr in attrs:\n        if _copy:\n            value = copy(value)\n        setattr(obj, attr, value)", "response": "Allows to set the value of a list of attributes \n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts to color value.", "response": "def getColor(value, default=None):\n    \"\"\"\n    Convert to color value.\n    This returns a Color object instance from a text bit.\n    \"\"\"\n\n    if isinstance(value, Color):\n        return value\n    value = str(value).strip().lower()\n    if value == \"transparent\" or value == \"none\":\n        return default\n    if value in COLOR_BY_NAME:\n        return COLOR_BY_NAME[value]\n    if value.startswith(\"#\") and len(value) == 4:\n        value = \"#\" + value[1] + value[1] + \\\n            value[2] + value[2] + value[3] + value[3]\n    elif rgb_re.search(value):\n        # e.g., value = \"<css function: rgb(153, 51, 153)>\", go figure:\n        r, g, b = [int(x) for x in rgb_re.search(value).groups()]\n        value = \"#%02x%02x%02x\" % (r, g, b)\n    else:\n        # Shrug\n        pass\n\n    return toColor(value, default)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getSize(value, relative=0, base=None, default=0.0):\n    try:\n        original = value\n        if value is None:\n            return relative\n        elif type(value) is float:\n            return value\n        elif isinstance(value, int):\n            return float(value)\n        elif type(value) in (tuple, list):\n            value = \"\".join(value)\n        value = str(value).strip().lower().replace(\",\", \".\")\n        if value[-2:] == 'cm':\n            return float(value[:-2].strip()) * cm\n        elif value[-2:] == 'mm':\n            return float(value[:-2].strip()) * mm  # 1mm = 0.1cm\n        elif value[-2:] == 'in':\n            return float(value[:-2].strip()) * inch  # 1pt == 1/72inch\n        elif value[-2:] == 'inch':\n            return float(value[:-4].strip()) * inch  # 1pt == 1/72inch\n        elif value[-2:] == 'pt':\n            return float(value[:-2].strip())\n        elif value[-2:] == 'pc':\n            return float(value[:-2].strip()) * 12.0  # 1pc == 12pt\n        elif value[-2:] == 'px':\n            # XXX W3C says, use 96pdi\n            # http://www.w3.org/TR/CSS21/syndata.html#length-units\n            return float(value[:-2].strip()) * dpi96\n        elif value[-1:] == 'i':  # 1pt == 1/72inch\n            return float(value[:-1].strip()) * inch\n        elif value in (\"none\", \"0\", \"auto\"):\n            return 0.0\n        elif relative:\n            if value[-2:] == 'em':  # XXX\n                # 1em = 1 * fontSize\n                return float(value[:-2].strip()) * relative\n            elif value[-2:] == 'ex':  # XXX\n                # 1ex = 1/2 fontSize\n                return float(value[:-2].strip()) * (relative / 2.0)\n            elif value[-1:] == '%':\n                # 1% = (fontSize * 1) / 100\n                return (relative * float(value[:-1].strip())) / 100.0\n            elif value in (\"normal\", \"inherit\"):\n                return relative\n            elif value in _relativeSizeTable:\n                if base:\n                    return max(MIN_FONT_SIZE, base * _relativeSizeTable[value])\n                return max(MIN_FONT_SIZE, relative * _relativeSizeTable[value])\n            elif value in _absoluteSizeTable:\n                if base:\n                    return max(MIN_FONT_SIZE, base * _absoluteSizeTable[value])\n                return max(MIN_FONT_SIZE, relative * _absoluteSizeTable[value])\n            else:\n                return max(MIN_FONT_SIZE, relative * float(value))\n        try:\n            value = float(value)\n        except ValueError:\n            log.warn(\"getSize: Not a float %r\", value)\n            return default  # value = 0\n        return max(0, value)\n    except Exception:\n        log.warn(\"getSize %r %r\", original, relative, exc_info=1)\n        return default", "response": "Converts a string of CSS sizes to standard sizes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getBox(box, pagesize):\n    box = str(box).split()\n    if len(box) != 4:\n        raise Exception(\"box not defined right way\")\n    x, y, w, h = [getSize(pos) for pos in box]\n    return getCoords(x, y, w, h, pagesize)", "response": "Parse sizes by corners in the form of a tuple of x y w h pagesize"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getFrameDimensions(data, page_width, page_height):\n    box = data.get(\"-pdf-frame-box\", [])\n    if len(box) == 4:\n        return [getSize(x) for x in box]\n    top = getSize(data.get(\"top\", 0))\n    left = getSize(data.get(\"left\", 0))\n    bottom = getSize(data.get(\"bottom\", 0))\n    right = getSize(data.get(\"right\", 0))\n    if \"height\" in data:\n        height = getSize(data[\"height\"])\n        if \"top\" in data:\n            top = getSize(data[\"top\"])\n            bottom = page_height - (top + height)\n        elif \"bottom\" in data:\n            bottom = getSize(data[\"bottom\"])\n            top = page_height - (bottom + height)\n    if \"width\" in data:\n        width = getSize(data[\"width\"])\n        if \"left\" in data:\n            left = getSize(data[\"left\"])\n            right = page_width - (left + width)\n        elif \"right\" in data:\n            right = getSize(data[\"right\"])\n            left = page_width - (right + width)\n    top += getSize(data.get(\"margin-top\", 0))\n    left += getSize(data.get(\"margin-left\", 0))\n    bottom += getSize(data.get(\"margin-bottom\", 0))\n    right += getSize(data.get(\"margin-right\", 0))\n\n    width = page_width - (left + right)\n    height = page_height - (top + bottom)\n    return left, top, width, height", "response": "Calculate the dimensions of a single frame in points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the coordinates of a single page in a sequence of pagesize.", "response": "def getPos(position, pagesize):\n    \"\"\"\n    Pair of coordinates\n    \"\"\"\n    position = str(position).split()\n    if len(position) != 2:\n        raise Exception(\"position not defined right way\")\n    x, y = [getSize(pos) for pos in position]\n    return getCoords(x, y, None, None, pagesize)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef makeTempFile(self):\n\n        if self.strategy == 0:\n            try:\n                new_delegate = self.STRATEGIES[1]()\n                new_delegate.write(self.getvalue())\n                self._delegate = new_delegate\n                self.strategy = 1\n                log.warn(\"Created temporary file %s\", self.name)\n            except:\n                self.capacity = - 1", "response": "Create a temporary file for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getvalue(self):\n\n        if self.strategy == 0:\n            return self._delegate.getvalue()\n        self._delegate.flush()\n        self._delegate.seek(0)\n        value = self._delegate.read()\n        if not isinstance(value, six.binary_type):\n            value = value.encode('utf-8')\n        return value", "response": "Get the value of the current file. Work around for second strategy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the value to the file.", "response": "def write(self, value):\n        \"\"\"\n        If capacity != -1 and length of file > capacity it is time to switch\n        \"\"\"\n\n        if self.capacity > 0 and self.strategy == 0:\n            len_value = len(value)\n            if len_value >= self.capacity:\n                needs_new_strategy = True\n            else:\n                self.seek(0, 2)  # find end of file\n                needs_new_strategy = \\\n                    (self.tell() + len_value) >= self.capacity\n            if needs_new_strategy:\n                self.makeTempFile()\n\n        if not isinstance(value, six.binary_type):\n            value = value.encode('utf-8')\n\n        self._delegate.write(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setMimeTypeByName(self, name):\n        \" Guess the mime type \"\n        mimetype = mimetypes.guess_type(name)[0]\n        if mimetype is not None:\n            self.mimetype = mimetypes.guess_type(name)[0].split(\";\")[0]", "response": "Guess the mime type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imgVRange(h, va, fontSize):\n\n    if va == 'baseline':\n        iyo = 0\n    elif va in ('text-top', 'top'):\n        iyo = fontSize - h\n    elif va == 'middle':\n        iyo = fontSize - (1.2 * fontSize + h) * 0.5\n    elif va in ('text-bottom', 'bottom'):\n        iyo = fontSize - 1.2 * fontSize\n    elif va == 'super':\n        iyo = 0.5 * fontSize\n    elif va == 'sub':\n        iyo = -0.5 * fontSize\n    elif hasattr(va, 'normalizedValue'):\n        iyo = va.normalizedValue(fontSize)\n    else:\n        iyo = va\n    return iyo, iyo + h", "response": "returns bottom top offsets relative to baseline"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sameFrag(f, g):\n\n    if (hasattr(f, 'cbDefn') or hasattr(g, 'cbDefn')\n        or hasattr(f, 'lineBreak') or hasattr(g, 'lineBreak')): return 0\n    for a in ('fontName', 'fontSize', 'textColor', 'backColor', 'rise', 'underline', 'strike', 'link'):\n        if getattr(f, a, None) != getattr(g, a, None): return 0\n    return 1", "response": "Returns 1 if two ParaFrags map out the same\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a list of Parafrag objects return a list of fragwords that are in a single order.", "response": "def _getFragWords(frags):\n    \"\"\"\n    given a Parafrag list return a list of fragwords\n        [[size, (f00,w00), ..., (f0n,w0n)],....,[size, (fm0,wm0), ..., (f0n,wmn)]]\n        each pair f,w represents a style and some string\n        each sublist represents a word\n    \"\"\"\n    R = []\n    W = []\n    n = 0\n    hangingStrip = False\n    for f in frags:\n        text = f.text\n        if type(text) is bytes:\n            text = text.decode('utf8')\n        # of paragraphs\n        if text != '':\n            if hangingStrip:\n                hangingStrip = False\n                text = text.lstrip()\n\n            S = split(text)\n            if S == []:\n                S = ['']\n            if W != [] and text[0] in whitespace:\n                W.insert(0, n)\n                R.append(W)\n                W = []\n                n = 0\n\n            for w in S[:-1]:\n                W.append((f, w))\n                n += stringWidth(w, f.fontName, f.fontSize)\n                W.insert(0, n)\n                R.append(W)\n                W = []\n                n = 0\n\n            w = S[-1]\n            W.append((f, w))\n            n += stringWidth(w, f.fontName, f.fontSize)\n            if text and text[-1] in whitespace:\n                W.insert(0, n)\n                R.append(W)\n                W = []\n                n = 0\n        elif hasattr(f, 'cbDefn'):\n            w = getattr(f.cbDefn, 'width', 0)\n            if w:\n                if W != []:\n                    W.insert(0, n)\n                    R.append(W)\n                    W = []\n                    n = 0\n                R.append([w, (f, '')])\n            else:\n                W.append((f, ''))\n        elif hasattr(f, 'lineBreak'):\n            #pass the frag through.  The line breaker will scan for it.\n            if W != []:\n                W.insert(0, n)\n                R.append(W)\n                W = []\n                n = 0\n            R.append([0, (f, '')])\n            hangingStrip = True\n\n    if W != []:\n        W.insert(0, n)\n        R.append(W)\n\n    return R"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw a bullet text", "response": "def _drawBullet(canvas, offset, cur_y, bulletText, style):\n    \"\"\"\n    draw a bullet text could be a simple string or a frag list\n    \"\"\"\n\n    tx2 = canvas.beginText(style.bulletIndent, cur_y + getattr(style, \"bulletOffsetY\", 0))\n    tx2.setFont(style.bulletFontName, style.bulletFontSize)\n    tx2.setFillColor(hasattr(style, 'bulletColor') and style.bulletColor or style.textColor)\n    if isinstance(bulletText, basestring):\n        tx2.textOut(bulletText)\n    else:\n        for f in bulletText:\n            if hasattr(f, \"image\"):\n                image = f.image\n                width = image.drawWidth\n                height = image.drawHeight\n                gap = style.bulletFontSize * 0.25\n                img = image.getImage()\n                # print style.bulletIndent, offset, width\n                canvas.drawImage(\n                    img,\n                    style.leftIndent - width - gap,\n                    cur_y + getattr(style, \"bulletOffsetY\", 0),\n                    width,\n                    height)\n            else:\n                tx2.setFont(f.fontName, f.fontSize)\n                tx2.setFillColor(f.textColor)\n                tx2.textOut(f.text)\n    canvas.drawText(tx2)\n    #AR making definition lists a bit less ugly\n    #bulletEnd = tx2.getX()\n    bulletEnd = tx2.getX() + style.bulletFontSize * 0.6\n    offset = max(offset, bulletEnd - style.leftIndent)\n    return offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nworks out bullet width and adjust maxWidths[0] if neccessary", "response": "def _handleBulletWidth(bulletText, style, maxWidths):\n    \"\"\"\n    work out bullet width and adjust maxWidths[0] if neccessary\n    \"\"\"\n    if bulletText:\n        if isinstance(bulletText, basestring):\n            bulletWidth = stringWidth(bulletText, style.bulletFontName, style.bulletFontSize)\n        else:\n            #it's a list of fragments\n            bulletWidth = 0\n            for f in bulletText:\n                bulletWidth = bulletWidth + stringWidth(f.text, f.fontName, f.fontSize)\n        bulletRight = style.bulletIndent + bulletWidth + 0.6 * style.bulletFontSize\n        indent = style.leftIndent + style.firstLineIndent\n        if bulletRight > indent:\n            #..then it overruns, and we have less space available on line 1\n            maxWidths[0] -= (bulletRight - indent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of ParaFrags we return a list of ParaLines where each ParaLine is a ParaLine and each ParaLine is a ParaLine and each ParaLine is a ParaLine with the first ParaLine. Each ParaLine is a ParaLine with the first ParaLine and the second ParaLine is a ParaLine with the first ParaLine.", "response": "def splitLines0(frags, widths):\n    \"\"\"\n    given a list of ParaFrags we return a list of ParaLines\n\n    each ParaLine has\n    1)  ExtraSpace\n    2)  blankCount\n    3)  [textDefns....]\n        each text definition is a (ParaFrag, start, limit) triplet\n    \"\"\"\n\n    #initialise the algorithm\n    lineNum = 0\n    maxW = widths[lineNum]\n    i = -1\n    l = len(frags)\n    lim = start = 0\n    text = frags[0]\n    while 1:\n        #find a non whitespace character\n        while i < l:\n            while start < lim and text[start] == ' ': start += 1\n            if start == lim:\n                i += 1\n                if i == l: break\n                start = 0\n                f = frags[i]\n                text = f.text\n                lim = len(text)\n            else:\n                break   # we found one\n\n        if start == lim: break    # if we didn't find one we are done\n\n        #start of a line\n        g = (None, None, None)\n        line = []\n        cLen = 0\n        nSpaces = 0\n        while cLen < maxW:\n            j = text.find(' ', start)\n            if j < 0:\n                j == lim\n            w = stringWidth(text[start:j], f.fontName, f.fontSize)\n            cLen += w\n            if cLen > maxW and line != []:\n                cLen = cLen - w\n                #this is the end of the line\n                while g.text[lim] == ' ':\n                    lim -= 1\n                    nSpaces -= 1\n                break\n            if j < 0:\n                j = lim\n            if g[0] is f:\n                g[2] = j  #extend\n            else:\n                g = (f, start, j)\n                line.append(g)\n            if j == lim:\n                i += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to find out what the variables mean: tx A structure containing more informations about paragraph ??? leading Height of lines ff 1/8 of the font size y0 The \"baseline\" postion ??? y 1/8 below the baseline", "response": "def _do_post_text(tx):\n    \"\"\"\n    Try to find out what the variables mean:\n\n    tx         A structure containing more informations about paragraph ???\n\n    leading    Height of lines\n    ff         1/8 of the font size\n    y0         The \"baseline\" postion ???\n    y          1/8 below the baseline\n    \"\"\"\n\n    xs = tx.XtraState\n    leading = xs.style.leading\n    autoLeading = xs.autoLeading\n    f = xs.f\n    if autoLeading == 'max':\n        # leading = max(leading, f.fontSize)\n        leading = max(leading, LEADING_FACTOR * f.fontSize)\n    elif autoLeading == 'min':\n        leading = LEADING_FACTOR * f.fontSize\n    ff = 0.125 * f.fontSize\n    y0 = xs.cur_y\n    y = y0 - ff\n\n    # Background\n    for x1, x2, c, fs in xs.backgrounds:\n        inlineFF = fs * 0.125\n        gap = inlineFF * 1.25\n        tx._canvas.setFillColor(c)\n        tx._canvas.rect(x1, y - gap, x2 - x1, fs + 1, fill=1, stroke=0)\n    xs.backgrounds = []\n    xs.background = 0\n    xs.backgroundColor = None\n    xs.backgroundFontSize = None\n\n    # Underline\n    yUnderline = y0 - 1.5 * ff\n    tx._canvas.setLineWidth(ff * 0.75)\n    csc = None\n    for x1, x2, c in xs.underlines:\n        if c != csc:\n            tx._canvas.setStrokeColor(c)\n            csc = c\n        tx._canvas.line(x1, yUnderline, x2, yUnderline)\n    xs.underlines = []\n    xs.underline = 0\n    xs.underlineColor = None\n\n    # Strike\n    for x1, x2, c, fs in xs.strikes:\n        inlineFF = fs * 0.125\n        ys = y0 + 2 * inlineFF\n        if c != csc:\n            tx._canvas.setStrokeColor(c)\n            csc = c\n        tx._canvas.setLineWidth(inlineFF * 0.75)\n        tx._canvas.line(x1, ys, x2, ys)\n    xs.strikes = []\n    xs.strike = 0\n    xs.strikeColor = None\n\n    yl = y + leading\n    for x1, x2, link, c in xs.links:\n        # No automatic underlining for links, never!\n        _doLink(tx, link, (x1, y, x2, yl))\n    xs.links = []\n    xs.link = None\n    xs.linkColor = None\n    xs.cur_y -= leading"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cjkFragSplit(frags, maxWidths, calcBounds, encoding='utf8'):\n\n    from reportlab.rl_config import _FUZZ\n\n    U = []  # get a list of single glyphs with their widths etc etc\n    for f in frags:\n        text = f.text\n        if not isinstance(text, unicode):\n            text = text.decode(encoding)\n        if text:\n            U.extend([cjkU(t, f, encoding) for t in text])\n        else:\n            U.append(cjkU(text, f, encoding))\n\n    lines = []\n    widthUsed = lineStartPos = 0\n    maxWidth = maxWidths[0]\n\n    for i, u in enumerate(U):\n        w = u.width\n        widthUsed += w\n        lineBreak = hasattr(u.frag, 'lineBreak')\n        endLine = (widthUsed > maxWidth + _FUZZ and widthUsed > 0) or lineBreak\n        if endLine:\n            if lineBreak: continue\n            extraSpace = maxWidth - widthUsed + w\n            #This is the most important of the Japanese typography rules.\n            #if next character cannot start a line, wrap it up to this line so it hangs\n            #in the right margin. We won't do two or more though - that's unlikely and\n            #would result in growing ugliness.\n            nextChar = U[i]\n            if nextChar in ALL_CANNOT_START:\n                extraSpace -= w\n                i += 1\n            lines.append(makeCJKParaLine(U[lineStartPos:i], extraSpace, calcBounds))\n            try:\n                maxWidth = maxWidths[len(lines)]\n            except IndexError:\n                maxWidth = maxWidths[-1]  # use the last one\n\n            lineStartPos = i\n            widthUsed = w\n            i -= 1\n        #any characters left?\n    if widthUsed > 0:\n        lines.append(makeCJKParaLine(U[lineStartPos:], maxWidth - widthUsed, calcBounds))\n\n    return ParaLines(kind=1, lines=lines)", "response": "This function attempts to be wordSplit for frags using the dumb algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef minWidth(self):\n\n        frags = self.frags\n        nFrags = len(frags)\n        if not nFrags: return 0\n        if nFrags == 1:\n            f = frags[0]\n            fS = f.fontSize\n            fN = f.fontName\n            words = hasattr(f, 'text') and split(f.text, ' ') or f.words\n            func = lambda w, fS=fS, fN=fN: stringWidth(w, fN, fS)\n        else:\n            words = _getFragWords(frags)\n            func = lambda x: x[0]\n        return max(map(func, words))", "response": "Attempt to determine a minimum sensible width\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef breakLines(self, width):\n\n        if self.debug:\n            print (id(self), \"breakLines\")\n\n        if not isinstance(width, (tuple, list)):\n            maxWidths = [width]\n        else:\n            maxWidths = width\n        lines = []\n        lineno = 0\n        style = self.style\n\n        #for bullets, work out width and ensure we wrap the right amount onto line one\n        _handleBulletWidth(self.bulletText, style, maxWidths)\n\n        maxWidth = maxWidths[0]\n\n        self.height = 0\n        autoLeading = getattr(self, 'autoLeading', getattr(style, 'autoLeading', ''))\n        calcBounds = autoLeading not in ('', 'off')\n        frags = self.frags\n        nFrags = len(frags)\n        if nFrags == 1 and not hasattr(frags[0], 'cbDefn'):\n            f = frags[0]\n            fontSize = f.fontSize\n            fontName = f.fontName\n            ascent, descent = getAscentDescent(fontName, fontSize)\n            words = hasattr(f, 'text') and split(f.text, ' ') or f.words\n            spaceWidth = stringWidth(' ', fontName, fontSize, self.encoding)\n            cLine = []\n            currentWidth = -spaceWidth   # hack to get around extra space for word 1\n            for word in words:\n                #this underscores my feeling that Unicode throughout would be easier!\n                wordWidth = stringWidth(word, fontName, fontSize, self.encoding)\n                newWidth = currentWidth + spaceWidth + wordWidth\n                if newWidth <= maxWidth or not len(cLine):\n                    # fit one more on this line\n                    cLine.append(word)\n                    currentWidth = newWidth\n                else:\n                    if currentWidth > self.width: self.width = currentWidth\n                    #end of line\n                    lines.append((maxWidth - currentWidth, cLine))\n                    cLine = [word]\n                    currentWidth = wordWidth\n                    lineno += 1\n                    try:\n                        maxWidth = maxWidths[lineno]\n                    except IndexError:\n                        maxWidth = maxWidths[-1]  # use the last one\n\n            #deal with any leftovers on the final line\n            if cLine != []:\n                if currentWidth > self.width: self.width = currentWidth\n                lines.append((maxWidth - currentWidth, cLine))\n\n            return f.clone(kind=0, lines=lines, ascent=ascent, descent=descent, fontSize=fontSize)\n        elif nFrags <= 0:\n            return ParaLines(kind=0, fontSize=style.fontSize, fontName=style.fontName,\n                             textColor=style.textColor, ascent=style.fontSize, descent=-0.2 * style.fontSize,\n                             lines=[])\n        else:\n            if hasattr(self, 'blPara') and getattr(self, '_splitpara', 0):\n                #NB this is an utter hack that awaits the proper information\n                #preserving splitting algorithm\n                return self.blPara\n            n = 0\n            words = []\n            for w in _getFragWords(frags):\n                f = w[-1][0]\n                fontName = f.fontName\n                fontSize = f.fontSize\n                spaceWidth = stringWidth(' ', fontName, fontSize)\n\n                if not words:\n                    currentWidth = -spaceWidth   # hack to get around extra space for word 1\n                    maxSize = fontSize\n                    maxAscent, minDescent = getAscentDescent(fontName, fontSize)\n\n                wordWidth = w[0]\n                f = w[1][0]\n                if wordWidth > 0:\n                    newWidth = currentWidth + spaceWidth + wordWidth\n                else:\n                    newWidth = currentWidth\n\n                #test to see if this frag is a line break. If it is we will only act on it\n                #if the current width is non-negative or the previous thing was a deliberate lineBreak\n                lineBreak = hasattr(f, 'lineBreak')\n                endLine = (newWidth > maxWidth and n > 0) or lineBreak\n                if not endLine:\n                    if lineBreak: continue      #throw it away\n                    if type(w[1][1]) != six.text_type:\n                        nText = six.text_type(w[1][1], 'utf-8')\n                    else:\n                        nText = w[1][1]\n                        \n                    if nText: n += 1\n                    fontSize = f.fontSize\n                    if calcBounds:\n                        cbDefn = getattr(f, 'cbDefn', None)\n                        if getattr(cbDefn, 'width', 0):\n                            descent, ascent = imgVRange(cbDefn.height, cbDefn.valign, fontSize)\n                        else:\n                            ascent, descent = getAscentDescent(f.fontName, fontSize)\n                    else:\n                        ascent, descent = getAscentDescent(f.fontName, fontSize)\n                    maxSize = max(maxSize, fontSize)\n                    maxAscent = max(maxAscent, ascent)\n                    minDescent = min(minDescent, descent)\n                    if not words:\n                        g = f.clone()\n                        words = [g]\n                        g.text = nText\n                    elif not _sameFrag(g, f):\n                        if currentWidth > 0 and ((nText != '' and nText[0] != ' ') or hasattr(f, 'cbDefn')):\n                            if hasattr(g, 'cbDefn'):\n                                i = len(words) - 1\n                                while i >= 0:\n                                    wi = words[i]\n                                    cbDefn = getattr(wi, 'cbDefn', None)\n                                    if cbDefn:\n                                        if not getattr(cbDefn, 'width', 0):\n                                            i -= 1\n                                            continue\n                                    if not wi.text.endswith(' '):\n                                        wi.text += ' '\n                                    break\n                            else:\n                                if type(g.text) == type(' '):\n                                    space = \" \"\n                                else:\n                                    space = b\" \"\n                                if not g.text.endswith(space):\n                                    g.text += space\n                        g = f.clone()\n                        words.append(g)\n                        g.text = nText\n                    else:\n                        if type(g.text) is bytes:\n                            g.text = g.text.decode(\"utf8\")\n                        if type(nText) is bytes:\n                            nText = nText.decode(\"utf8\")\n                        if nText != '' and nText[0] != ' ':\n                            g.text += ' ' + nText\n\n                    for i in w[2:]:\n                        g = i[0].clone()\n                        g.text = i[1]\n                        words.append(g)\n                        fontSize = g.fontSize\n                        if calcBounds:\n                            cbDefn = getattr(g, 'cbDefn', None)\n                            if getattr(cbDefn, 'width', 0):\n                                descent, ascent = imgVRange(cbDefn.height, cbDefn.valign, fontSize)\n                            else:\n                                ascent, descent = getAscentDescent(g.fontName, fontSize)\n                        else:\n                            ascent, descent = getAscentDescent(g.fontName, fontSize)\n                        maxSize = max(maxSize, fontSize)\n                        maxAscent = max(maxAscent, ascent)\n                        minDescent = min(minDescent, descent)\n\n                    currentWidth = newWidth\n                else:  # either it won't fit, or it's a lineBreak tag\n                    if lineBreak:\n                        g = f.clone()\n                        words.append(g)\n\n                    if currentWidth > self.width: self.width = currentWidth\n                    #end of line\n                    lines.append(FragLine(extraSpace=maxWidth - currentWidth, wordCount=n,\n                                          lineBreak=lineBreak, words=words, fontSize=maxSize, ascent=maxAscent,\n                                          descent=minDescent))\n\n                    #start new line\n                    lineno += 1\n                    try:\n                        maxWidth = maxWidths[lineno]\n                    except IndexError:\n                        maxWidth = maxWidths[-1]  # use the last one\n\n                    if lineBreak:\n                        n = 0\n                        words = []\n                        continue\n\n                    currentWidth = wordWidth\n                    n = 1\n                    g = f.clone()\n                    maxSize = g.fontSize\n                    if calcBounds:\n                        cbDefn = getattr(g, 'cbDefn', None)\n                        if getattr(cbDefn, 'width', 0):\n                            minDescent, maxAscent = imgVRange(cbDefn.height, cbDefn.valign, maxSize)\n                        else:\n                            maxAscent, minDescent = getAscentDescent(g.fontName, maxSize)\n                    else:\n                        maxAscent, minDescent = getAscentDescent(g.fontName, maxSize)\n                    words = [g]\n                    g.text = w[1][1]\n\n                    for i in w[2:]:\n                        g = i[0].clone()\n                        g.text = i[1]\n                        words.append(g)\n                        fontSize = g.fontSize\n                        if calcBounds:\n                            cbDefn = getattr(g, 'cbDefn', None)\n                            if getattr(cbDefn, 'width', 0):\n                                descent, ascent = imgVRange(cbDefn.height, cbDefn.valign, fontSize)\n                            else:\n                                ascent, descent = getAscentDescent(g.fontName, fontSize)\n                        else:\n                            ascent, descent = getAscentDescent(g.fontName, fontSize)\n                        maxSize = max(maxSize, fontSize)\n                        maxAscent = max(maxAscent, ascent)\n                        minDescent = min(minDescent, descent)\n\n            #deal with any leftovers on the final line\n            if words != []:\n                if currentWidth > self.width: self.width = currentWidth\n                lines.append(ParaLines(extraSpace=(maxWidth - currentWidth), wordCount=n,\n                                       words=words, fontSize=maxSize, ascent=maxAscent, descent=minDescent))\n            return ParaLines(kind=1, lines=lines)\n\n        return lines", "response": "Returns a broken line structure for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing a paragraph according to the given style. Returns the final y position at the bottom.", "response": "def drawPara(self, debug=0):\n        \"\"\"Draws a paragraph according to the given style.\n        Returns the final y position at the bottom. Not safe for\n        paragraphs without spaces e.g. Japanese; wrapping\n        algorithm will go infinite.\"\"\"\n\n        if self.debug:\n            print (id(self), \"drawPara\", self.blPara.kind)\n\n        #stash the key facts locally for speed\n        canvas = self.canv\n        style = self.style\n        blPara = self.blPara\n        lines = blPara.lines\n        leading = style.leading\n        autoLeading = getattr(self, 'autoLeading', getattr(style, 'autoLeading', ''))\n\n        #work out the origin for line 1\n        leftIndent = style.leftIndent\n        cur_x = leftIndent\n\n        if debug:\n            bw = 0.5\n            bc = Color(1, 1, 0)\n            bg = Color(0.9, 0.9, 0.9)\n        else:\n            bw = getattr(style, 'borderWidth', None)\n            bc = getattr(style, 'borderColor', None)\n            bg = style.backColor\n\n        #if has a background or border, draw it\n        if bg or (bc and bw):\n            canvas.saveState()\n            op = canvas.rect\n            kwds = dict(fill=0, stroke=0)\n            if bc and bw:\n                canvas.setStrokeColor(bc)\n                canvas.setLineWidth(bw)\n                kwds['stroke'] = 1\n                br = getattr(style, 'borderRadius', 0)\n                if br and not debug:\n                    op = canvas.roundRect\n                    kwds['radius'] = br\n            if bg:\n                canvas.setFillColor(bg)\n                kwds['fill'] = 1\n            bp = getattr(style, 'borderPadding', 0)\n            op(leftIndent - bp,\n               -bp,\n               self.width - (leftIndent + style.rightIndent) + 2 * bp,\n               self.height + 2 * bp,\n               **kwds)\n            canvas.restoreState()\n\n        nLines = len(lines)\n        bulletText = self.bulletText\n        if nLines > 0:\n            _offsets = getattr(self, '_offsets', [0])\n            _offsets += (nLines - len(_offsets)) * [_offsets[-1]]\n            canvas.saveState()\n            alignment = style.alignment\n            offset = style.firstLineIndent + _offsets[0]\n            lim = nLines - 1\n            noJustifyLast = not (hasattr(self, '_JustifyLast') and self._JustifyLast)\n\n            if blPara.kind == 0:\n                if alignment == TA_LEFT:\n                    dpl = _leftDrawParaLine\n                elif alignment == TA_CENTER:\n                    dpl = _centerDrawParaLine\n                elif self.style.alignment == TA_RIGHT:\n                    dpl = _rightDrawParaLine\n                elif self.style.alignment == TA_JUSTIFY:\n                    dpl = _justifyDrawParaLine\n                f = blPara\n                cur_y = self.height - getattr(f, 'ascent', f.fontSize)    # TODO fix XPreformatted to remove this hack\n                if bulletText:\n                    offset = _drawBullet(canvas, offset, cur_y, bulletText, style)\n\n                #set up the font etc.\n                canvas.setFillColor(f.textColor)\n\n                tx = self.beginText(cur_x, cur_y)\n                if autoLeading == 'max':\n                    leading = max(leading, LEADING_FACTOR * f.fontSize)\n                elif autoLeading == 'min':\n                    leading = LEADING_FACTOR * f.fontSize\n\n                #now the font for the rest of the paragraph\n                tx.setFont(f.fontName, f.fontSize, leading)\n                ws = getattr(tx, '_wordSpace', 0)  \n                t_off = dpl(tx, offset, ws, lines[0][1], noJustifyLast and nLines == 1)\n                if f.underline or f.link or f.strike:\n                    xs = tx.XtraState = ABag()\n                    xs.cur_y = cur_y\n                    xs.f = f\n                    xs.style = style\n                    xs.lines = lines\n                    xs.underlines = []\n                    xs.underlineColor = None\n                    # XXX Modified for XHTML2PDF\n                    xs.backgrounds = []\n                    xs.backgroundColor = None\n                    xs.backgroundFontSize = None\n                    xs.strikes = []\n                    xs.strikeColor = None\n                    # XXX Modified for XHTML2PDF\n                    xs.strikeFontSize = None\n                    xs.links = []\n                    xs.link = f.link\n                    canvas.setStrokeColor(f.textColor)\n                    dx = t_off + leftIndent\n                    if dpl != _justifyDrawParaLine: ws = 0\n                    # XXX Never underline!\n                    underline = f.underline\n                    strike = f.strike\n                    link = f.link\n                    if underline:\n                        _do_under_line(0, dx, ws, tx)\n                    if strike:\n                        _do_under_line(0, dx, ws, tx, lm=0.125)\n                    if link: _do_link_line(0, dx, ws, tx)\n\n                    #now the middle of the paragraph, aligned with the left margin which is our origin.\n                    for i in six.moves.range(1, nLines):\n                        ws = lines[i][0]\n                        t_off = dpl(tx, _offsets[i], ws, lines[i][1], noJustifyLast and i == lim)\n                        if dpl != _justifyDrawParaLine: ws = 0\n                        if underline: _do_under_line(i, t_off + leftIndent, ws, tx)\n                        if strike: _do_under_line(i, t_off + leftIndent, ws, tx, lm=0.125)\n                        if link: _do_link_line(i, t_off + leftIndent, ws, tx)\n                else:\n                    for i in six.moves.range(1, nLines):\n                        dpl(tx, _offsets[i], lines[i][0], lines[i][1], noJustifyLast and i == lim)\n            else:\n                f = lines[0]\n                cur_y = self.height - getattr(f, 'ascent', f.fontSize)    # TODO fix XPreformatted to remove this hack\n                # default?\n                dpl = _leftDrawParaLineX\n                if bulletText:\n                    offset = _drawBullet(canvas, offset, cur_y, bulletText, style)\n                if alignment == TA_LEFT:\n                    dpl = _leftDrawParaLineX\n                elif alignment == TA_CENTER:\n                    dpl = _centerDrawParaLineX\n                elif self.style.alignment == TA_RIGHT:\n                    dpl = _rightDrawParaLineX\n                elif self.style.alignment == TA_JUSTIFY:\n                    dpl = _justifyDrawParaLineX\n                else:\n                    raise ValueError(\"bad align %s\" % repr(alignment))\n\n                #set up the font etc.\n                tx = self.beginText(cur_x, cur_y)\n                xs = tx.XtraState = ABag()\n                xs.textColor = None\n                # XXX Modified for XHTML2PDF\n                xs.backColor = None\n                xs.rise = 0\n                xs.underline = 0\n                xs.underlines = []\n                xs.underlineColor = None\n                # XXX Modified for XHTML2PDF\n                xs.background = 0\n                xs.backgrounds = []\n                xs.backgroundColor = None\n                xs.backgroundFontSize = None\n                xs.strike = 0\n                xs.strikes = []\n                xs.strikeColor = None\n                # XXX Modified for XHTML2PDF\n                xs.strikeFontSize = None\n                xs.links = []\n                xs.link = None\n                xs.leading = style.leading\n                xs.leftIndent = leftIndent\n                tx._leading = None\n                tx._olb = None\n                xs.cur_y = cur_y\n                xs.f = f\n                xs.style = style\n                xs.autoLeading = autoLeading\n\n                tx._fontname, tx._fontsize = None, None\n                dpl(tx, offset, lines[0], noJustifyLast and nLines == 1)\n                _do_post_text(tx)\n\n                #now the middle of the paragraph, aligned with the left margin which is our origin.\n                for i in six.moves.range(1, nLines):\n                    f = lines[i]\n                    dpl(tx, _offsets[i], f, noJustifyLast and i == lim)\n                    _do_post_text(tx)\n\n            canvas.drawText(tx)\n            canvas.restoreState()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the raw text of the current object.", "response": "def getPlainText(self, identify=None):\n        \"\"\"\n        Convenience function for templates which want access\n        to the raw text, without XML tags.\n        \"\"\"\n\n        frags = getattr(self, 'frags', None)\n        if frags:\n            plains = []\n            for frag in frags:\n                if hasattr(frag, 'text'):\n                    plains.append(frag.text)\n            return ''.join(plains)\n        elif identify:\n            text = getattr(self, 'text', None)\n            if text is None: text = repr(self)\n            return text\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of line widths that are not longer than the wrap width.", "response": "def getActualLineWidths0(self):\n        \"\"\"\n        Convenience function; tells you how wide each line\n        actually is.  For justified styles, this will be\n        the same as the wrap width; for others it might be\n        useful for seeing if paragraphs will fit in spaces.\n        \"\"\"\n\n        assert hasattr(self, 'width'), \"Cannot call this method before wrap()\"\n        if self.blPara.kind:\n            func = lambda frag, w=self.width: w - frag.extraSpace\n        else:\n            func = lambda frag, w=self.width: w - frag[0]\n        return map(func, self.blPara.lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert HTML URIs to absolute system paths so xhtml2pdf can access those resources", "response": "def link_callback(uri, rel):\n    \"\"\"\n    Convert HTML URIs to absolute system paths so xhtml2pdf can access those\n    resources\n    \"\"\"\n    # use short variable names\n    sUrl = settings.STATIC_URL      # Typically /static/\n    sRoot = settings.STATIC_ROOT    # Typically /home/userX/project_static/\n    mUrl = settings.MEDIA_URL       # Typically /static/media/\n    # Typically /home/userX/project_static/media/\n    mRoot = settings.MEDIA_ROOT\n\n    # convert URIs to absolute system paths\n    if uri.startswith(mUrl):\n        path = os.path.join(mRoot, uri.replace(mUrl, \"\"))\n    elif uri.startswith(sUrl):\n        path = os.path.join(sRoot, uri.replace(sUrl, \"\"))\n    else:\n        return uri  # handle absolute uri (ie: http://some.tld/foo.png)\n\n    # make sure that file exists\n    if not os.path.isfile(path):\n        raise Exception(\n            'media URI must start with %s or %s' % (sUrl, mUrl)\n        )\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start():\n\n    setupdir = dirname(dirname(__file__))\n    curdir = os.getcwd()\n\n    # First look on the command line for a desired config file,\n    # if it's not on the command line, then look for 'setup.py'\n    # in the current directory. If there, load configuration\n    # from a file called 'dev.cfg'. If it's not there, the project\n    # is probably installed and we'll look first for a file called\n    # 'prod.cfg' in the current directory and then for a default\n    # config file called 'default.cfg' packaged in the egg.\n    if len(sys.argv) > 1:\n        configfile = sys.argv[1]\n    elif exists(join(setupdir, \"setup.py\")):\n        configfile = join(setupdir, \"dev.cfg\")\n    elif exists(join(curdir, \"prod.cfg\")):\n        configfile = join(curdir, \"prod.cfg\")\n    else:\n        try:\n            configfile = pkg_resources.resource_filename(\n              pkg_resources.Requirement.parse(\"tgpisa\"),\n                \"config/default.cfg\")\n        except pkg_resources.DistributionNotFound:\n            raise ConfigurationError(\"Could not find default configuration.\")\n\n    turbogears.update_config(configfile=configfile,\n        modulename=\"tgpisa.config\")\n\n    from tgpisa.controllers import Root\n\n    turbogears.start_server(Root())", "response": "Start the CherryPy application server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to find the style setting for attrName in the CSSRulesets.", "response": "def findStyleFor(self, element, attrName, default=NotImplemented):\n        \"\"\"Attempts to find the style setting for attrName in the CSSRulesets.\n\n        Note: This method does not attempt to resolve rules that return\n        \"inherited\", \"default\", or values that have units (including \"%\").\n        This is left up to the client app to re-query the CSS in order to\n        implement these semantics.\n        \"\"\"\n        rule = self.findCSSRulesFor(element, attrName)\n        return self._extractStyleForRule(rule, attrName, default)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef findStylesForEach(self, element, attrNames, default=NotImplemented):\n        rules = self.findCSSRulesForEach(element, attrNames)\n        return [(attrName, self._extractStyleForRule(rule, attrName, default))\n                for attrName, rule in six.iteritems(rules)]", "response": "Attempts to find the style setting for attrName in the CSSRulesets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calcSpecificity(self):\n        hashCount = 0\n        qualifierCount = 0\n        elementCount = int(self.name != '*')\n        for q in self.qualifiers:\n            if q.isHash():\n                hashCount += 1\n            elif q.isClass():\n                qualifierCount += 1\n            elif q.isAttr():\n                qualifierCount += 1\n            elif q.isPseudo():\n                elementCount += 1\n            elif q.isCombiner():\n                i, h, q, e = q.selector.specificity()\n                hashCount += h\n                qualifierCount += q\n                elementCount += e\n        return self.inline, hashCount, qualifierCount, elementCount", "response": "Calculate the specificity of the class and qualifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mergeStyles(self, styles):\n        \" XXX Bugfix for use in PISA \"\n        for k, v in six.iteritems(styles):\n            if k in self and self[k]:\n                self[k] = copy.copy(self[k])\n                self[k].update(v)\n            else:\n                self[k] = v", "response": "XXX Bugfix for use in PISA"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new CSS rule that is applied to the page.", "response": "def atPage(self, page, pseudopage, declarations):\n        \"\"\"\n        This is overriden by xhtml2pdf.context.pisaCSSBuilder\n        \"\"\"\n        return self.ruleset([self.selector('*')], declarations)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn byte array of RGB data as string", "response": "def getRGBData(self):\n        \"Return byte array of RGB data as string\"\n        if self._data is None:\n            self._dataA = None\n            if sys.platform[0:4] == 'java':\n                import jarray  # TODO: Move to top.\n                from java.awt.image import PixelGrabber\n\n                width, height = self.getSize()\n                buffer = jarray.zeros(width * height, 'i')\n                pg = PixelGrabber(self._image, 0, 0, width, height, buffer, 0, width)\n                pg.grabPixels()\n                # there must be a way to do this with a cast not a byte-level loop,\n                # I just haven't found it yet...\n                pixels = []\n                a = pixels.append\n                for rgb in buffer:\n                    a(chr((rgb >> 16) & 0xff))\n                    a(chr((rgb >> 8) & 0xff))\n                    a(chr(rgb & 0xff))\n                self._data = ''.join(pixels)\n                self.mode = 'RGB'\n            else:\n                im = self._image\n                mode = self.mode = im.mode\n                if mode == 'RGBA':\n                    im.load()\n                    self._dataA = PmlImageReader(im.split()[3])\n                    im = im.convert('RGB')\n                    self.mode = 'RGB'\n                elif mode not in ('L', 'RGB', 'CMYK'):\n                    im = im.convert('RGB')\n                    self.mode = 'RGB'\n                if hasattr(im, 'tobytes'):\n                    self._data = im.tobytes()\n                else:\n                    # PIL compatibility\n                    self._data = im.tostring()\n        return self._data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the passed - in args string into a list of dicts.", "response": "def parse_shutitfile_args(args_str):\n\t\"\"\"Parse shutitfile args (eg in the line 'RUN some args', the passed-in args_str would be 'some args').\n\tIf the string is bounded by square brackets, then it's treated in the form: ['arg1','arg2'], and the returned list looks the same.\n\tIf the string composed entirely of name-value pairs (eg RUN a=b c=d) then it's returned as a dict (eg {'a':'b','c':'d'}).\n\tIf what's passed-in is of the form: \"COMMAND ['a=b','c=d']\" then a dict is also returned.'\n\tAlso eg: [\"asd and space=value\",\"asd 2=asdgasdg\"]\"\"\"\n\tret = []\n\tif args_str == '':\n\t\treturn ret\n\tif args_str[0] == '[' and args_str[-1] == ']':\n\t\tret = eval(args_str)\n\t\tassert isinstance(ret, list)\n\telse:\n\t\tret = args_str.split()\n\t\t# if all the items have a = in them, then return a dict of nv pairs\n\tnv_pairs = True\n\tfor item in ret:\n\t\tif item.find('=') < 0:\n\t\t\tnv_pairs = False\n\tif nv_pairs:\n\t\td = {}\n\t\tfor item in ret:\n\t\t\titem_nv = item.split('=')\n\t\t\td.update({item_nv[0]:item_nv[1]})\n\t\tret = d\n\treturn ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan_text(text):\n\twhile True:\n\t\tmatch = re.match(\"(.*){{ shutit.(.*) }}(.*)$\", text)\n\t\tif match:\n\t\t\tbefore = match.group(1)\n\t\t\tname = match.group(2)\n\t\t\tafter = match.group(3)\n\t\t\ttext = before + \"\"\"''' + shutit.cfg[self.module_id][\\\"\"\"\" + name + \"\"\"\\\"] + '''\"\"\" + after\n\t\telse:\n\t\t\tbreak\n\treturn text", "response": "Scan text and replace items that match shutit s pattern format ie.\n\t{{ shutit. THING }}\n\t while True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nspawning a child process and manage the delaybefore send setting to 0", "response": "def _spawn_child(self,\n\t                 command,\n\t                 args=None,\n\t                 timeout=shutit_global.shutit_global_object.default_timeout,\n\t                 maxread=2000,\n\t                 searchwindowsize=None,\n\t                 env=None,\n\t                 ignore_sighup=False,\n\t                 echo=True,\n\t                 preexec_fn=None,\n\t                 encoding=None,\n\t                 codec_errors='strict',\n\t                 dimensions=None,\n\t                 delaybeforesend=shutit_global.shutit_global_object.delaybeforesend):\n\t\t\"\"\"spawn a child, and manage the delaybefore send setting to 0\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\targs = args or []\n\t\tpexpect_child = pexpect.spawn(command,\n\t\t                              args=args,\n\t\t                              timeout=timeout,\n\t\t                              maxread=maxread,\n\t\t                              searchwindowsize=searchwindowsize,\n\t\t                              env=env,\n\t\t                              ignore_sighup=ignore_sighup,\n\t\t                              echo=echo,\n\t\t                              preexec_fn=preexec_fn,\n\t\t                              encoding=encoding,\n\t\t                              codec_errors=codec_errors,\n\t\t                              dimensions=dimensions)\n\t\t# Set the winsize to the theoretical maximum to reduce risk of trouble from terminal line wraps.\n\t\t# Other things have been attempted, eg tput rmam/smam without success.\n\t\tpexpect_child.setwinsize(shutit_global.shutit_global_object.pexpect_window_size[0],shutit_global.shutit_global_object.pexpect_window_size[1])\n\t\tpexpect_child.delaybeforesend=delaybeforesend\n\t\tshutit.log('sessions before: ' + str(shutit.shutit_pexpect_sessions), level=logging.DEBUG)\n\t\tshutit.shutit_pexpect_sessions.update({self.pexpect_session_id:self})\n\t\tshutit.log('sessions after: ' + str(shutit.shutit_pexpect_sessions), level=logging.DEBUG)\n\t\treturn pexpect_child"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a line to the pexpect session.", "response": "def sendline(self, sendspec):\n\t\t\"\"\"Sends line, handling background and newline directives.\n\n\t\tTrue means: 'all handled here ok'\n\t\tFalse means: you'll need to 'expect' the right thing from here.\n\t\t\"\"\"\n\t\tassert not sendspec.started, shutit_util.print_debug()\n\t\tshutit = self.shutit\n\t\tshutit.log('Sending in pexpect session (' + str(id(self)) + '): ' + str(sendspec.send), level=logging.DEBUG)\n\t\tif sendspec.expect:\n\t\t\tshutit.log('Expecting: ' + str(sendspec.expect), level=logging.DEBUG)\n\t\telse:\n\t\t\tshutit.log('Not expecting anything', level=logging.DEBUG)\n\t\ttry:\n\t\t\t# Check there are no background commands running that have block_other_commands set iff\n\t\t\t# this sendspec says\n\t\t\tif self._check_blocked(sendspec) and sendspec.ignore_background != True:\n\t\t\t\tshutit.log('sendline: blocked', level=logging.DEBUG)\n\t\t\t\treturn False\n\t\t\t# If this is marked as in the background, create a background object and run in the background.\n\t\t\tif sendspec.run_in_background:\n\t\t\t\tshutit.log('sendline: run_in_background', level=logging.DEBUG)\n\t\t\t\t# If this is marked as in the background, create a background object and run in the background after newlines sorted.\n\t\t\t\tshutit_background_command_object = self.login_stack.get_current_login_item().append_background_send(sendspec)\n\t\t\t\t# Makes no sense to check exit for a background command.\n\t\t\t\tsendspec.check_exit = False\n\t\t\tif sendspec.nonewline != True:\n\t\t\t\tsendspec.send += '\\n'\n\t\t\t\t# sendspec has newline added now, so no need to keep marker\n\t\t\t\tsendspec.nonewline = True\n\t\t\tif sendspec.run_in_background:\n\t\t\t\tshutit_background_command_object.run_background_command()\n\t\t\t\treturn True\n\t\t\t#shutit.log('sendline: actually sending: ' + sendspec.send, level=logging.DEBUG)\n\t\t\tself.pexpect_child.send(sendspec.send)\n\t\t\treturn False\n\t\texcept OSError:\n\t\t\tself.shutit.fail('Caught failure to send, assuming user has exited from pause point.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes not return until all background commands are completed.", "response": "def wait(self, cadence=2, sendspec=None):\n\t\t\"\"\"Does not return until all background commands are completed.\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.log('In wait.', level=logging.DEBUG)\n\t\tif sendspec:\n\t\t\tcadence = sendspec.wait_cadence\n\t\tshutit.log('Login stack is:\\n' + str(self.login_stack), level=logging.DEBUG)\n\t\twhile True:\n\t\t\t# go through each background child checking whether they've finished\n\t\t\tres, res_str, background_object = self.login_stack.get_current_login_item().check_background_commands_complete()\n\t\t\tshutit.log('Checking: ' + str(background_object) + '\\nres: ' + str(res) + '\\nres_str' + str(res_str), level=logging.DEBUG)\n\t\t\tif res:\n\t\t\t\t# When all have completed, break return the background command objects.\n\t\t\t\tbreak\n\t\t\telif res_str in ('S','N'):\n\t\t\t\t# Do nothing, this is an started or not-running task.\n\t\t\t\tpass\n\t\t\telif res_str == 'F':\n\t\t\t\tassert background_object is not None, shutit_util.print_debug()\n\t\t\t\tassert isinstance(background_object, ShutItBackgroundCommand), shutit_util.print_debug()\n\t\t\t\tshutit.log('Failure in: ' + str(self.login_stack), level=logging.DEBUG)\n\t\t\t\tself.pause_point('Background task: ' + background_object.sendspec.original_send + ' :failed.')\n\t\t\t\treturn False\n\t\t\telse:\n\t\t\t\tself.shutit.fail('Un-handled exit code: ' + res_str) # pragma: no cover\n\t\t\ttime.sleep(cadence)\n\t\tshutit.log('Wait complete.', level=logging.DEBUG)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef login(self, sendspec):\n\t\tuser          = sendspec.user\n\t\tcommand       = sendspec.send\n\t\tprompt_prefix = sendspec.prompt_prefix\n\t\tshutit = self.shutit\n\t\t# We don't get the default expect here, as it's either passed in, or a base default regexp.\n\t\tif isinstance(sendspec.password,str):\n\t\t\tshutit_global.shutit_global_object.secret_words_set.add(sendspec.password)\n\t\tr_id = shutit_util.random_id()\n\t\tif prompt_prefix is None:\n\t\t\tprompt_prefix = r_id\n\t\t# Be helpful - if this looks like a command that requires a user, then suggest user provides one.\n\t\tif user is None:\n\t\t\tuser = self.whoami()\n\t\t\tif 'bash' not in command:\n\t\t\t\tshutit.log('No user supplied to login function, so retrieving who I am (' + user + '). You may want to override.', level=logging.WARNING)\n\t\tif ' ' in user:\n\t\t\tself.shutit.fail('user has space in it - did you mean: login(command=\"' + user + '\")?') # pragma: no cover\n\t\tif self.shutit.build['delivery'] == 'bash' and command == 'su -':\n\t\t\t# We want to retain the current working directory\n\t\t\tcommand = 'su'\n\t\t# If this is a su-type command, add the user, else assume user is in the command.\n\t\tif command == 'su -' or command == 'su' or command == 'login':\n\t\t\tsend = command + ' ' + user\n\t\telse:\n\t\t\tsend = command\n\t\tlogin_expect = sendspec.expect or shutit_global.shutit_global_object.base_prompt\n\t\t# We don't fail on empty before as many login programs mess with the output.\n\t\t# In this special case of login we expect either the prompt, or 'user@' as this has been seen to work.\n\t\tgeneral_expect = [login_expect]\n\t\t# Add in a match if we see user+ and then the login matches. Be careful not to match against 'user+@...password:'\n\t\tgeneral_expect = general_expect + [user+'@.*'+'[#$]']\n\t\t# If not an ssh login, then we can match against user + @sign because it won't clash with 'user@adasdas password:'\n\t\tif (sendspec.is_ssh != None and sendspec.is_ssh) or command.find('ssh ') != -1:\n\t\t\tshutit.log('Assumed to be an ssh command, is_ssh: ' + str(sendspec.is_ssh) + ', command: ' + command, level=logging.DEBUG)\n\t\t\t# If user@ already there, remove it, as it can conflict with password lines in ssh calls.\n\t\t\tif user+'@' in general_expect:\n\t\t\t\tgeneral_expect.remove(user+'@')\n\t\t\t# Adding the space to avoid commands which embed eg $(whoami) or ${var}\n\t\t\tgeneral_expect.append('.*[#$] ')\n\t\t\t# Don't match 'Last login:' or 'Last failed login:'\n\t\t\tsend_dict={'ontinue connecting':['yes', False]}\n\t\t\tif sendspec.password is not None:\n\t\t\t\tsend_dict.update({'assword:':[sendspec.password, True]})\n\t\t\t\tsend_dict.update({r'[^dt] login:':[sendspec.password, True]})\n\t\telse:\n\t\t\tsend_dict={'ontinue connecting':['yes', False]}\n\t\t\tif sendspec.password is not None:\n\t\t\t\tsend_dict.update({'assword:':[sendspec.password, True]})\n\t\t\t\tsend_dict.update({r'[^dt] login:':[sendspec.password, True]})\n\t\t\t\tsend_dict.update({user+'@':[sendspec.password, True]})\n\t\tif user == 'bash' and command == 'su -':\n\t\t\tshutit.log('WARNING! user is bash - if you see problems below, did you mean: login(command=\"' + user + '\")?', level=logging.WARNING)\n\t\tself.shutit.handle_note(sendspec.note,command=command + '\\n\\n[as user: \"' + user + '\"]',training_input=send)\n\t\techo = self.shutit.get_echo_override(sendspec.echo)\n\t\tshutit.log('Logging in to new ShutIt environment.' + user, level=logging.DEBUG)\n\t\tshutit.log('Logging in with command: ' + send + ' as user: ' + user, level=logging.DEBUG)\n\t\tshutit.log('Login stack before login: ' + str(self.login_stack), level=logging.DEBUG)\n\t\t# check_sudo - set to false if the password has been supplied.\n\t\tcheck_sudo = False\n\t\tif sendspec.password is None and send.strip().find('sudo') == 0:\n\t\t\tcheck_sudo = True\n\t\tres = self.multisend(ShutItSendSpec(self,\n\t\t                                    send=send,\n\t\t                                    send_dict=send_dict,\n\t\t                                    expect=general_expect,\n\t\t                                    check_exit=False,\n\t\t                                    timeout=sendspec.timeout,\n\t\t                                    fail_on_empty_before=False,\n\t\t                                    escape=sendspec.escape,\n\t\t                                    echo=echo,\n\t\t                                    remove_on_match=True,\n\t\t                                    nonewline=sendspec.nonewline,\n\t\t                                    check_sudo=check_sudo,\n\t\t                                    loglevel=sendspec.loglevel))\n\t\tif res == -1:\n\t\t\t# Should not get here as login should not be blocked.\n\t\t\tassert False, shutit_util.print_debug()\n\t\t# Setup prompt\n\t\tif prompt_prefix != None:\n\t\t\tself.setup_prompt(r_id,prefix=prompt_prefix,capture_exit_code=True)\n\t\telse:\n\t\t\tself.setup_prompt(r_id,capture_exit_code=True)\n\t\tself.login_stack.append(r_id)\n\t\tshutit.log('Login stack after login: ' + str(self.login_stack), level=logging.DEBUG)\n\t\tif self.send_and_get_output(''' echo $SHUTIT_EC && unset SHUTIT_EC''', loglevel=logging.DEBUG, echo=False) != '0':\n\t\t\t# TODO: remove just-added login stack item (since we failed to log in successfully)?\n\t\t\tif sendspec.fail_on_fail: # pragma: no cover\n\t\t\t\tself.shutit.fail('Login failure! You may want to re-run shutit with --echo or -l debug and scroll up to see what the problem was.')\n\t\t\telse:\n\t\t\t\treturn False\n\t\tif sendspec.go_home:\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send='cd',\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t                             ignore_background=True,\n\t\t\t                         loglevel=sendspec.loglevel))\n\t\tself.shutit.handle_note_after(note=sendspec.note,training_input=send)\n\t\treturn True", "response": "Logs the user in with the passed - in password and command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog the user out.", "response": "def logout(self, sendspec):\n\t\t\"\"\"Logs the user out. Assumes that login has been called.\n\t\tIf login has never been called, throw an error.\n\n\t\t\t@param command: Command to run to log out (default=exit)\n\t\t\t@param note:    See send()\n\t\t\"\"\"\n\t\t# Block until background tasks complete.\n\t\tself.wait()\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(sendspec.note,training_input=sendspec.send)\n\t\tif self.login_stack.length() > 0:\n\t\t\t_ = self.login_stack.pop()\n\t\t\tif self.login_stack.length() > 0:\n\t\t\t\told_prompt_name\t = self.login_stack.get_current_login_id()\n\t\t\t\tself.default_expect = shutit.expect_prompts[old_prompt_name]\n\t\t\telse:\n\t\t\t\t# If none are on the stack, we assume we're going to the root prompt\n\t\t\t\t# set up in shutit_setup.py\n\t\t\t\tshutit.set_default_shutit_pexpect_session_expect()\n\t\telse:\n\t\t\tshutit.fail('Logout called without corresponding login', throw_exception=False) # pragma: no cover\n\t\t# No point in checking exit here, the exit code will be\n\t\t# from the previous command from the logged in session\n\t\techo = shutit.get_echo_override(sendspec.echo)\n\t\toutput = self.send_and_get_output(sendspec.send,\n\t\t                                  fail_on_empty_before=False,\n\t\t                                  timeout=sendspec.timeout,\n\t\t                                  echo=echo,\n\t\t                                  loglevel=sendspec.loglevel,\n\t\t\t                              nonewline=sendspec.nonewline)\n\t\tshutit.handle_note_after(note=sendspec.note)\n\t\treturn output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_prompt(self,\n\t                 prompt_name,\n\t                 prefix='default',\n\t                 capture_exit_code=False,\n\t                 loglevel=logging.DEBUG):\n\t\t\"\"\"Use this when you've opened a new shell to set the PS1 to something\n\t\tsane. By default, it sets up the default expect so you don't have to\n\t\tworry about it and can just call shutit.send('a command').\n\n\t\tIf you want simple login and logout, please use login() and logout()\n\t\twithin this module.\n\n\t\tTypically it would be used in this boilerplate pattern::\n\n\t\t    shutit.send('su - auser', expect=shutit_global.shutit_global_object.base_prompt, check_exit=False)\n\t\t    shutit.setup_prompt('tmp_prompt')\n\t\t    shutit.send('some command')\n\t\t    [...]\n\t\t    shutit.set_default_shutit_pexpect_session_expect()\n\t\t    shutit.send('exit')\n\n\t\tThis function is assumed to be called whenever there is a change\n\t\tof environment.\n\n\t\t@param prompt_name:         Reference name for prompt.\n\t\t@param prefix:              Prompt prefix. Default: 'default'\n\t\t@param capture_exit_code:   Captures the exit code of the previous\n\t\t                            command into a SHUTIT_EC variable. Useful\n\t\t                            for when we want to work out whether the\n\t\t                            login worked.\n\t\t@type prompt_name:          string\n\t\t@type prefix:               string\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tlocal_prompt = prefix + ':' + shutit_util.random_id() + '# '\n\t\tshutit.expect_prompts[prompt_name] = local_prompt\n\t\t# Set up the PS1 value.\n\t\t# Override the PROMPT_COMMAND as this can cause nasty surprises in the\n\t\t# output, and we need a short pause before returning the prompt to\n\t\t# overcome an obscure bash bug (cf.\n\t\t# https://github.com/pexpect/pexpect/issues/483).\n\t\t# Set the cols value, as unpleasant escapes are put in the output if the\n\t\t# input is > n chars wide.\n\t\t# checkwinsize is required for similar reasons.\n\t\t# The newline in the expect list is a hack. On my work laptop this line hangs\n\t\t# and times out very frequently. This workaround seems to work, but I\n\t\t# haven't figured out why yet - imiell.\n\n\t\t# Split the local prompt into two parts and separate with quotes to protect against the expect matching the command rather than the output.\n\t\tshutit.log('Setting up prompt.', level=logging.DEBUG)\n\t\tsend_str = ''\n\t\tif capture_exit_code:\n\t\t\tsend_str = r' SHUTIT_EC=$? && '\n\t\tsend_str += \"\"\" export PS1_\"\"\" + str(prompt_name) + \"\"\"=$PS1 && PS1='\"\"\" + str(local_prompt[:2]) + \"''\" + str(local_prompt[2:]) + \"\"\"' && PROMPT_COMMAND=\"\"\" + shutit_global.shutit_global_object.prompt_command\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=send_str,\n\t\t                         expect=['\\r\\n' + shutit.expect_prompts[prompt_name]],\n\t\t                         fail_on_empty_before=False,\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\t\t# Set default expect to new.\n\t\tshutit.log('Resetting default expect to: ' + shutit.expect_prompts[prompt_name], level=loglevel)\n\t\tself.default_expect = shutit.expect_prompts[prompt_name]\n\n\t\t# Sometimes stty resets to 0x0 (?), so we must override here.\n\t\tself.send(ShutItSendSpec(self, send=\" stty cols 65535\", echo=False, check_exit=False, loglevel=loglevel, ignore_background=True))\n\t\tself.send(ShutItSendSpec(self, send=\" stty rows 65535\", echo=False, check_exit=False, loglevel=loglevel, ignore_background=True))\n\t\t# Avoid dumb terminals\n\t\tself.send(ShutItSendSpec(self, send=\"\"\" if [ $TERM=dumb ];then export TERM=xterm;fi\"\"\", echo=False, check_exit=False, loglevel=loglevel, ignore_background=True))\n\n\t\t# Get the hostname\n\t\t# Lack of space after > is deliberate to avoid issues with prompt matching.\n\t\thostname = shutit.send_and_get_output(\"\"\" if [ $(echo $SHELL) == '/bin/bash' ]; then echo $HOSTNAME; elif [ $(command hostname 2>/dev/null) != '' ]; then hostname -s 2>/dev/null; fi\"\"\", echo=False, loglevel=logging.DEBUG)\n\t\tlocal_prompt_with_hostname = hostname + ':' + local_prompt\n\t\tshutit.expect_prompts[prompt_name] = local_prompt_with_hostname\n\t\tself.default_expect = shutit.expect_prompts[prompt_name]\n\t\t# Set up a shell expect to check whether we're still in a shell later.\n\t\tself.shell_expect = self.default_expect\n\n\t\t# Split the local prompt into two parts and separate with quotes to protect against the expect matching the command rather than the output.\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=\"\"\" PS1='\"\"\" + shutit.expect_prompts[prompt_name][:2] + \"''\" + shutit.expect_prompts[prompt_name][2:] + \"\"\"'\"\"\",\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\n\t\t# Set up history the way shutit likes it.\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=' command export HISTCONTROL=$HISTCONTROL:ignoredups:ignorespace',\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\n\t\t# Ensure environment is set up OK.\n\t\t_ = self.init_pexpect_session_environment(prefix)\n\t\treturn True", "response": "Setup the prompt for the current environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreverts the prompt to the previous value passed - in.", "response": "def revert_prompt(self,\n\t                  old_prompt_name,\n\t                  new_expect=None):\n\t\t\"\"\"Reverts the prompt to the previous value (passed-in).\n\n\t\tIt should be fairly rare to need this. Most of the time you would just\n\t\texit a subshell rather than resetting the prompt.\n\n\t\t    - old_prompt_name -\n\t\t    - new_expect      -\n\t\t    - child           - See send()\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\texpect = new_expect or self.default_expect\n\t\t#           v the space is intentional, to avoid polluting bash history.\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=(' PS1=\"${PS1_%s}\" && unset PS1_%s') % (old_prompt_name, old_prompt_name),\n\t\t                         expect=expect,\n\t\t                         check_exit=False,\n\t\t                         fail_on_empty_before=False,\n\t\t                         echo=False,\n\t\t                         loglevel=logging.DEBUG,\n\t\t                         ignore_background=True))\n\t\tif not new_expect:\n\t\t\tshutit.log('Resetting default expect to default', level=logging.DEBUG)\n\t\t\tshutit.set_default_shutit_pexpect_session_expect()\n\t\t_ = self.init_pexpect_session_environment(old_prompt_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle child expects and add to the pane of output.", "response": "def expect(self,\n\t           expect,\n\t           searchwindowsize=None,\n\t           maxread=None,\n\t           timeout=None,\n\t           iteration_n=1):\n\t\t\"\"\"Handle child expects, with EOF and TIMEOUT handled\n\n\t\titeration_n - Number of times this expect has been called for the send.\n\t\t              If 1, (the default) then it gets added to the pane of output\n\t\t              (if applicable to this run)\n\t\t\"\"\"\n\t\tif isinstance(expect, str):\n\t\t\texpect = [expect]\n\t\tif searchwindowsize != None:\n\t\t\told_searchwindowsize = self.pexpect_child.searchwindowsize\n\t\t\tself.pexpect_child.searchwindowsize = searchwindowsize\n\t\tif maxread != None:\n\t\t\told_maxread = self.pexpect_child.maxread\n\t\t\tself.pexpect_child.maxread = maxread\n\t\tres = self.pexpect_child.expect(expect + [pexpect.TIMEOUT] + [pexpect.EOF], timeout=timeout)\n\t\tif searchwindowsize != None:\n\t\t\tself.pexpect_child.searchwindowsize = old_searchwindowsize\n\t\tif maxread != None:\n\t\t\tself.pexpect_child.maxread = old_maxread\n\t\t# Add to session lines only if pane manager exists.\n\t\tif shutit_global.shutit_global_object.pane_manager and iteration_n == 1:\n\t\t\ttime_seen = time.time()\n\t\t\tlines_to_add = []\n\t\t\tif isinstance(self.pexpect_child.before, (str,unicode)):\n\t\t\t\tfor line_str in self.pexpect_child.before.split('\\n'):\n\t\t\t\t\tlines_to_add.append(line_str)\n\t\t\tif isinstance(self.pexpect_child.after, (str,unicode)):\n\t\t\t\tfor line_str in self.pexpect_child.after.split('\\n'):\n\t\t\t\t\tlines_to_add.append(line_str)\n\t\t\t# If first or last line is empty, remove it.\n\t\t\t#if len(lines_to_add) > 0 and lines_to_add[1] == '':\n\t\t\t#\tlines_to_add = lines_to_add[1:]\n\t\t\t#if len(lines_to_add) > 0 and lines_to_add[-1] == '':\n\t\t\t#\tlines_to_add = lines_to_add[:-1]\n\t\t\tfor line in lines_to_add:\n\t\t\t\tself.session_output_lines.append(SessionPaneLine(line_str=line, time_seen=time_seen, line_type='output'))\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces a container with a new target image name.", "response": "def replace_container(self, new_target_image_name, go_home=None):\n\t\t\"\"\"Replaces a container. Assumes we are in Docker context.\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.log('Replacing container with ' + new_target_image_name + ', please wait...', level=logging.DEBUG)\n\t\tshutit.log(shutit.print_session_state(), level=logging.DEBUG)\n\n\t\t# Destroy existing container.\n\t\tconn_module = None\n\t\tfor mod in shutit.conn_modules:\n\t\t\tif mod.module_id == shutit.build['conn_module']:\n\t\t\t\tconn_module = mod\n\t\t\t\tbreak\n\t\tif conn_module is None:\n\t\t\tshutit.fail('''Couldn't find conn_module ''' + shutit.build['conn_module']) # pragma: no cover\n\t\tcontainer_id = shutit.target['container_id']\n\t\tconn_module.destroy_container(shutit, 'host_child', 'target_child', container_id)\n\n\t\t# Start up a new container.\n\t\tshutit.target['docker_image'] = new_target_image_name\n\t\ttarget_child = conn_module.start_container(shutit, self.pexpect_session_id)\n\t\tconn_module.setup_target_child(shutit, target_child)\n\t\tshutit.log('Container replaced', level=logging.DEBUG)\n\t\tshutit.log(shutit.print_session_state(), level=logging.DEBUG)\n\t\t# New session - log in. This makes the assumption that we are nested\n\t\t# the same level in in terms of shells (root shell + 1 new login shell).\n\t\ttarget_child = shutit.get_shutit_pexpect_session_from_id('target_child')\n\t\tif go_home != None:\n\t\t\ttarget_child.login(ShutItSendSpec(self,\n\t\t\t                                  send=shutit_global.shutit_global_object.bash_startup_command,\n\t\t\t                                  check_exit=False,\n\t\t\t                                  echo=False,\n\t\t\t                                  go_home=go_home))\n\t\telse:\n\t\t\ttarget_child.login(ShutItSendSpec(self,\n\t\t\t                                  send=shutit_global.shutit_global_object.bash_startup_command,\n\t\t\t                                  check_exit=False,\n\t\t\t                                  echo=False))\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the current user by executing whoami.", "response": "def whoami(self,\n\t           note=None,\n\t           loglevel=logging.DEBUG):\n\t\t\"\"\"Returns the current user by executing \"whoami\".\n\n\t\t@param note:     See send()\n\n\t\t@return: the output of \"whoami\"\n\t\t@rtype: string\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tres = self.send_and_get_output(' command whoami',\n\t\t                               echo=False,\n\t\t                               loglevel=loglevel).strip()\n\t\tif res == '':\n\t\t\tres = self.send_and_get_output(' command id -u -n',\n\t\t\t                               echo=False,\n\t\t\t                               loglevel=loglevel).strip()\n\t\tshutit.handle_note_after(note=note)\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts a pause in the build session, which allows the user to try things out before continuing. Ignored if we are not in an interactive mode. Designed to help debug the build, or drop to on failure so the situation can be debugged. @param msg: Message to display to user on pause point. @param print_input: Whether to take input at this point (i.e. interact), or simply pause pending any input. Default: True @param resize: If True, try to resize terminal. Default: False @param color: Color to print message (typically 31 for red, 32 for green) @param default_msg: Whether to print the standard blurb @param interact: Interact without mediation, and set up environment. @param wait: Wait a few seconds rather than for input (for video mode) @type msg: string @type print_input: boolean @type resize: boolean @type wait: decimal @return: True if pause point handled ok, else false", "response": "def pause_point(self,\n\t                msg='SHUTIT PAUSE POINT',\n\t                print_input=True,\n\t                resize=True,\n\t                color='32',\n\t                default_msg=None,\n\t                interact=False,\n\t                wait=-1):\n\t\t\"\"\"Inserts a pause in the build session, which allows the user to try\n\t\tthings out before continuing. Ignored if we are not in an interactive\n\t\tmode.\n\t\tDesigned to help debug the build, or drop to on failure so the\n\t\tsituation can be debugged.\n\n\t\t@param msg:          Message to display to user on pause point.\n\t\t@param print_input:  Whether to take input at this point (i.e. interact), or\n\t\t                     simply pause pending any input.\n\t\t                     Default: True\n\t\t@param resize:       If True, try to resize terminal.\n\t\t                     Default: False\n\t\t@param color:        Color to print message (typically 31 for red, 32 for green)\n\t\t@param default_msg:  Whether to print the standard blurb\n\t\t@param interact:     Interact without mediation, and set up environment.\n\t\t@param wait:         Wait a few seconds rather than for input (for video mode)\n\n\t\t@type msg:           string\n\t\t@type print_input:   boolean\n\t\t@type resize:        boolean\n\t\t@type wait:          decimal\n\n\t\t@return:             True if pause point handled ok, else false\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\t# Try and stop user being 'clever' if we are in an exam and not in debug\n\t\tif shutit.build['exam'] and shutit.loglevel not in ('DEBUG',):\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command alias exit=/bin/true && command alias logout=/bin/true && command alias kill=/bin/true && command alias alias=/bin/true',\n\t\t\t                         echo=False,\n\t\t\t                         record_command=False,\n\t\t\t                         ignore_background=True))\n\n\t\t# Flush history before we 'exit' the current session.\n\t\t# THIS CAUSES BUGS IF WE ARE NOT IN A SHELL... COMMENTING OUT\n\t\t# IF THE DEFAULT PEXPECT == THE CURRENCT EXPECTED, THEN OK, gnuplot in shutit-scripts with walkthrough=True is a good test\n\t\t# Errors seen when check_exit=True\n\t\tif self.in_shell:\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' set +m && { : $(history -a) & } 2>/dev/null',\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t\t                         record_command=False,\n\t\t\t                         ignore_background=True))\n\n\t\tif print_input:\n\t\t\t# Do not resize if we are in video mode (ie wait > 0)\n\t\t\tif resize and wait < 0:\n\t\t\t\t# It is possible we do not have distro set yet, so wrap in try/catch\n\t\t\t\ttry:\n\t\t\t\t\tassert not self.sendline(ShutItSendSpec(self,\n\t\t\t\t\t                                        send='',\n\t\t\t\t\t                                        echo=False,\n\t\t\t\t\t                                        ignore_background=True)), shutit_util.print_debug()\n\t\t\t\texcept Exception:\n\t\t\t\t\tpass\n\t\t\tif default_msg is None:\n\t\t\t\tif not shutit.build['video'] and not shutit.build['training'] and not shutit.build['exam'] and not shutit.build['walkthrough'] and self.shutit.loglevel not in ('DEBUG',):\n\t\t\t\t\tpp_msg = '\\r\\nYou now have a standard shell.'\n\t\t\t\t\tif not interact:\n\t\t\t\t\t\tpp_msg += '\\r\\nHit CTRL and then ] at the same time to continue ShutIt run, CTRL-q to quit.'\n\t\t\t\t\tif shutit.build['delivery'] == 'docker':\n\t\t\t\t\t\tpp_msg += '\\r\\nHit CTRL and u to save the state to a docker image'\n\t\t\t\t\tshutit.log(shutit_util.colorise(color,'\\r\\n' + 80*'=' + '\\r\\n' + msg + '\\r\\n' + 80*'='+'\\r\\n' + pp_msg),transient=True, level=logging.CRITICAL)\n\t\t\t\telse:\n\t\t\t\t\tshutit.log('\\r\\n' + (shutit_util.colorise(color, msg)),transient=True, level=logging.critical)\n\t\t\telse:\n\t\t\t\tshutit.log(shutit_util.colorise(color, msg) + '\\r\\n' + default_msg + '\\r\\n',transient=True, level=logging.CRITICAL)\n\t\t\toldlog = self.pexpect_child.logfile\n\t\t\tself.pexpect_child.logfile = None\n\t\t\tif wait > 0:\n\t\t\t\ttime.sleep(wait)\n\t\t\telse:\n\t\t\t\t# Re-set the window size to match the original window.\n\t\t\t\t# TODO: sigwinch. Line assumes no change.\n\t\t\t\tself.pexpect_child.setwinsize(shutit_global.shutit_global_object.root_window_size[0],shutit_global.shutit_global_object.root_window_size[1])\n\t\t\t\t# TODO: handle exams better?\n\t\t\t\tself.expect('.*')\n\t\t\t\tif not shutit.build['exam'] and self.shutit.loglevel not in ('DEBUG',):\n\t\t\t\t\tif self.in_shell:\n\t\t\t\t\t\t# Give them a 'normal' shell.\n\t\t\t\t\t\tassert not self.sendline(ShutItSendSpec(self,\n\t\t\t\t\t\t                                        send=' bash',\n\t\t\t\t\t\t                                        echo=False,\n\t\t\t\t\t\t                                        ignore_background=True)), shutit_util.print_debug()\n\t\t\t\t\t\tself.expect('.*')\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.log('Cannot create subshell, as not in a shell.', level=logging.DEBUG)\n\t\t\t\tif interact:\n\t\t\t\t\tself.pexpect_child.interact()\n\t\t\t\ttry:\n\t\t\t\t\t#shutit_global.shutit_global_object.shutit_print('pre interact')\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\t# For some reason interact barfs when we use _pause_input_filter, so drop it for PY3: https://github.com/pexpect/pexpect/blob/master/pexpect/pty_spawn.py#L819\n\t\t\t\t\t\tself.pexpect_child.interact()\n\t\t\t\t\telse:\n\t\t\t\t\t\tself.pexpect_child.interact(input_filter=self._pause_input_filter)\n\t\t\t\t\t#shutit_global.shutit_global_object.shutit_print('post interact')\n\t\t\t\t\tself.handle_pause_point_signals()\n\t\t\t\t\t#shutit_global.shutit_global_object.shutit_print('post handle_pause_point_signals')\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tshutit.fail('Terminating ShutIt within pause point.\\r\\n' + str(e)) # pragma: no cover\n\t\t\t\tif not shutit.build['exam'] and self.shutit.loglevel not in ('DEBUG',):\n\t\t\t\t\tif self.in_shell:\n\t\t\t\t\t\tassert not self.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                                    send=' exit',\n\t\t\t\t\t\t                                    check_exit=False,\n\t\t\t\t\t\t                                    echo=False,\n\t\t\t\t\t\t                                    ignore_background=True)), shutit_util.print_debug()\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.log('Cannot exit as not in shell', level=logging.DEBUG)\n\t\t\tself.pexpect_child.logfile = oldlog\n\t\telse:\n\t\t\tpass\n\t\tshutit.build['ctrlc_stop'] = False\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_exists(self,\n\t                filename,\n\t                directory=False,\n\t                note=None,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Return True if file exists on the target host, else False\n\n\t\t@param filename:   Filename to determine the existence of.\n\t\t@param directory:  Indicate that the file is a directory.\n\t\t@param note:       See send()\n\n\t\t@type filename:    string\n\t\t@type directory:   boolean\n\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, 'Looking for filename in current environment: ' + filename)\n\t\ttest_type = '-d' if directory is True else '-e' if directory is None else '-a'\n\t\t#       v the space is intentional, to avoid polluting bash history.\n\t\ttest = ' test %s %s' % (test_type, filename)\n\t\toutput = self.send_and_get_output(test + ' && echo FILEXIST-\"\"FILFIN || echo FILNEXIST-\"\"FILFIN',\n\t\t                                  record_command=False,\n\t\t                                  echo=False,\n\t\t                                  loglevel=loglevel)\n\t\tres = shutit.match_string(output, '^(FILEXIST|FILNEXIST)-FILFIN$')\n\t\tret = False\n\t\tif res == 'FILEXIST':\n\t\t\tret = True\n\t\telif res == 'FILNEXIST':\n\t\t\tpass\n\t\telse: # pragma: no cover\n\t\t\t# Change to log?\n\t\t\tshutit.log(repr('before>>>>:%s<<<< after:>>>>%s<<<<' % (self.pexpect_child.before, self.pexpect_child.after)),transient=True, level=logging.INFO)\n\t\t\tshutit.fail('Did not see FIL(N)?EXIST in output:\\n' + output)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn ret", "response": "Return True if file exists on the target host else False."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef chdir(self,\n\t          path,\n\t          timeout=shutit_global.shutit_global_object.default_timeout,\n\t          note=None,\n\t          loglevel=logging.DEBUG):\n\t\t\"\"\"How to change directory will depend on whether we are in delivery mode bash or docker.\n\n\t\t@param path:          Path to send file to.\n\t\t@param timeout:       Timeout on response\n\t\t@param note:          See send()\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, 'Changing to path: ' + path)\n\t\tshutit.log('Changing directory to path: \"' + path + '\"', level=logging.DEBUG)\n\t\tif shutit.build['delivery'] in ('bash','dockerfile'):\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command cd \"' + path + '\"',\n\t\t\t                         timeout=timeout,\n\t\t\t                         echo=False,\n\t\t\t                         loglevel=loglevel))\n\t\telif shutit.build['delivery'] in ('docker',):\n\t\t\tos.chdir(path)\n\t\telse:\n\t\t\tshutit.fail('chdir not supported for delivery method: ' + str(shutit.build['delivery'])) # pragma: no cover\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True", "response": "Chdir the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the permissions of the file on the target.", "response": "def get_file_perms(self,\n\t                   filename,\n\t                   note=None,\n\t                   loglevel=logging.DEBUG):\n\t\t\"\"\"Returns the permissions of the file on the target as an octal\n\t\tstring triplet.\n\n\t\t@param filename:  Filename to get permissions of.\n\t\t@param note:      See send()\n\n\t\t@type filename:   string\n\n\t\t@rtype:           string\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tcmd = ' command stat -c %a ' + filename\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=' ' + cmd,\n\t\t                         check_exit=False,\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\t\tres = shutit.match_string(self.pexpect_child.before, '([0-9][0-9][0-9])')\n\t\tshutit.handle_note_after(note=note)\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a line to the bashrc file.", "response": "def add_to_bashrc(self,\n\t                  line,\n\t                  match_regexp=None,\n\t                  note=None,\n\t                  loglevel=logging.DEBUG):\n\t\t\"\"\"Takes care of adding a line to everyone's bashrc\n\t\t(/etc/bash.bashrc).\n\n\t\t@param line:          Line to add.\n\t\t@param match_regexp:  See add_line_to_file()\n\t\t@param note:          See send()\n\n\t\t@return:              See add_line_to_file()\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tif not shutit_util.check_regexp(match_regexp):\n\t\t\tshutit.fail('Illegal regexp found in add_to_bashrc call: ' + match_regexp) # pragma: no cover\n\t\tif self.whoami() == 'root':\n\t\t\tshutit.add_line_to_file(line, '/root/.bashrc', match_regexp=match_regexp, loglevel=loglevel)\n\t\telse:\n\t\t\tshutit.add_line_to_file(line, '${HOME}/.bashrc', match_regexp=match_regexp, loglevel=loglevel)\n\t\tshutit.add_line_to_file(line, '/etc/bash.bashrc', match_regexp=match_regexp, loglevel=loglevel)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_user_id_available(self,\n\t                         user_id,\n\t                         note=None,\n\t                         loglevel=logging.DEBUG):\n\t\t\"\"\"Determine whether the specified user_id available.\n\n\t\t@param user_id:  User id to be checked.\n\t\t@param note:     See send()\n\n\t\t@type user_id:   integer\n\n\t\t@rtype:          boolean\n\t\t@return:         True is the specified user id is not used yet, False if it's already been assigned to a user.\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\t# v the space is intentional, to avoid polluting bash history.\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=' command cut -d: -f3 /etc/paswd | grep -w ^' + user_id + '$ | wc -l',\n\t\t                         expect=self.default_expect,\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\t\tshutit.handle_note_after(note=note)\n\t\tif shutit.match_string(self.pexpect_child.before, '^([0-9]+)$') == '1':\n\t\t\treturn False\n\t\treturn True", "response": "Returns True if the specified user_id is available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the password for the current user or passed - in user.", "response": "def set_password(self,\n\t                 password,\n\t                 user='',\n\t                 note=None):\n\t\t\"\"\"Sets the password for the current user or passed-in user.\n\n\t\tAs a side effect, installs the \"password\" package.\n\n\t\t@param user:        username to set the password for. Defaults to '' (i.e. current user)\n\t\t@param password:    password to set for the user\n\t\t@param note:        See send()\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tif isinstance(password, str):\n\t\t\tshutit_global.shutit_global_object.secret_words_set.add(password)\n\t\tself.install('passwd')\n\t\tif self.current_environment.install_type == 'apt':\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send='passwd ' + user,\n\t\t\t                         expect='Enter new',\n\t\t\t                         check_exit=False,\n\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect='Retype new',\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True\n\t\t\t                         ))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect=self.default_expect,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True,\n\t\t\t                         ))\n\t\telif self.current_environment.install_type == 'yum':\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send='passwd ' + user,\n\t\t\t                         expect='ew password',\n\t\t\t                         check_exit=False,\n\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect='ew password',\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect=self.default_expect,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True))\n\t\telse:\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send='passwd ' + user,\n\t\t\t                         expect='Enter new',\n\t\t\t                         check_exit=False,\n\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect='Retype new',\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=password,\n\t\t\t                         expect=self.default_expect,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True))\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget distro information from lsb_release.", "response": "def lsb_release(self,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Get distro information from lsb_release.\n\t\t\"\"\"\n\t\t#          v the space is intentional, to avoid polluting bash history.\n\t\tshutit = self.shutit\n\t\td = {}\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=' command lsb_release -a',\n\t\t                         check_exit=False,\n\t\t                         echo=False,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=True))\n\t\tres = shutit.match_string(self.pexpect_child.before, r'^Distributor[\\s]*ID:[\\s]*(.*)$')\n\t\tif isinstance(res, str):\n\t\t\tdist_string = res\n\t\t\td['distro']       = dist_string.lower().strip()\n\t\t\ttry:\n\t\t\t\td['install_type'] = (package_map.INSTALL_TYPE_MAP[dist_string.lower()])\n\t\t\texcept KeyError:\n\t\t\t\traise Exception(\"Distribution '%s' is not supported.\" % dist_string)\n\t\telse:\n\t\t\treturn d\n\t\tres = shutit.match_string(self.pexpect_child.before, r'^Release:[\\s*](.*)$')\n\t\tif isinstance(res, str):\n\t\t\tversion_string = res\n\t\t\td['distro_version'] = version_string\n\t\treturn d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the getting of a url for you. Example: get_url('somejar.jar', ['ftp://loc.org','http://anotherloc.com/jars']) @param filename: name of the file to download @param locations: list of URLs whence the file can be downloaded @param command: program to use to download the file (Default: wget) @param timeout: See send() @param fail_on_empty_before: See send() @param record_command: See send() @param exit_values: See send() @param retry: How many times to retry the download in case of failure. Default: 3 @param note: See send() @type filename: string @type locations: list of strings @type retry: integer @return: True if the download was completed successfully, False otherwise. @rtype: boolean", "response": "def get_url(self,\n\t            filename,\n\t            locations,\n\t            command='curl -L',\n\t            timeout=shutit_global.shutit_global_object.default_timeout,\n\t            fail_on_empty_before=True,\n\t            record_command=True,\n\t            exit_values=None,\n\t            retry=3,\n\t            note=None,\n\t            loglevel=logging.DEBUG):\n\t\t\"\"\"Handles the getting of a url for you.\n\n\t\tExample:\n\t\tget_url('somejar.jar', ['ftp://loc.org','http://anotherloc.com/jars'])\n\n\t\t@param filename:             name of the file to download\n\t\t@param locations:            list of URLs whence the file can be downloaded\n\t\t@param command:              program to use to download the file (Default: wget)\n\t\t@param timeout:              See send()\n\t\t@param fail_on_empty_before: See send()\n\t\t@param record_command:       See send()\n\t\t@param exit_values:          See send()\n\t\t@param retry:                How many times to retry the download\n\t\t                             in case of failure. Default: 3\n\t\t@param note:                 See send()\n\n\t\t@type filename:              string\n\t\t@type locations:             list of strings\n\t\t@type retry:                 integer\n\n\t\t@return: True if the download was completed successfully, False otherwise.\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tif not locations or not isinstance(locations, list):\n\t\t\traise ShutItFailException('Locations should be a list containing base of the url.')\n\t\tretry_orig = retry\n\t\tif not self.command_available(command):\n\t\t\tself.install('curl')\n\t\t\tif not self.command_available('curl'):\n\t\t\t\tself.install('wget')\n\t\t\t\tcommand = 'wget -qO- '\n\t\t\t\tif not self.command_available('wget'):\n\t\t\t\t\tshutit.fail('Could not install curl or wget, inform maintainers.') # pragma: no cover\n\t\tfor location in locations:\n\t\t\tretry = retry_orig\n\t\t\tif location[-1] == '/':\n\t\t\t\tlocation = location[0:-1]\n\t\t\twhile retry >= 0:\n\t\t\t\tsend = command + ' ' + location + '/' + filename + ' > ' + filename\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=send,\n\t\t\t\t                         check_exit=False,\n\t\t\t\t                         expect=self.default_expect,\n\t\t\t\t                         timeout=timeout,\n\t\t\t\t                         fail_on_empty_before=fail_on_empty_before,\n\t\t\t\t                         record_command=record_command,\n\t\t\t\t                         echo=False,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         ignore_background=True))\n\t\t\t\tif retry == 0:\n\t\t\t\t\tself.check_last_exit_values(send,\n\t\t\t\t\t                            expect=self.default_expect,\n\t\t\t\t\t                            exit_values=exit_values,\n\t\t\t\t\t                            retbool=False)\n\t\t\t\telif not self.check_last_exit_values(send,\n\t\t\t\t                                     expect=self.default_expect,\n\t\t\t\t                                     exit_values=exit_values,\n\t\t\t\t                                     retbool=True):\n\t\t\t\t\tshutit.log('Sending: ' + send + ' failed, retrying', level=logging.DEBUG)\n\t\t\t\t\tretry -= 1\n\t\t\t\t\tcontinue\n\t\t\t\t# If we get here, all is ok.\n\t\t\t\tshutit.handle_note_after(note=note)\n\t\t\t\treturn True\n\t\t# If we get here, it didn't work\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn true if the specified username exists.", "response": "def user_exists(self,\n\t                user,\n\t                note=None,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Returns true if the specified username exists.\n\n\t\t@param user:   username to check for\n\t\t@param note:   See send()\n\n\t\t@type user:    string\n\n\t\t@rtype:        boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\texists = False\n\t\tif user == '':\n\t\t\treturn exists\n\t\t#                v the space is intentional, to avoid polluting bash history.\n\t\t# The quotes before XIST are deliberate, to prevent the command from matching the expect.\n\t\tret = self.send(ShutItSendSpec(self,\n\t\t                               send=' command id %s && echo E\"\"XIST || echo N\"\"XIST' % user,\n\t\t                               expect=['NXIST', 'EXIST'],\n\t\t                               echo=False,\n\t\t                               loglevel=loglevel,\n\t\t                               ignore_background=True))\n\t\tif ret:\n\t\t\texists = True\n\t\t# sync with the prompt\n\t\tself.expect(self.default_expect)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef package_installed(self,\n\t                      package,\n\t                      note=None,\n\t                      echo=False,\n\t                      loglevel=logging.DEBUG):\n\t\t\"\"\"Returns True if we can be sure the package is installed.\n\n\t\t@param package:   Package as a string, eg 'wget'.\n\t\t@param note:      See send()\n\n\t\t@rtype:           boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\t# THIS DOES NOT WORK - WHY? TODO\n\t\tif self.current_environment.install_type == 'apt':\n\t\t\t#                                v the space is intentional, to avoid polluting bash history.\n\t\t\treturn self.send_and_get_output(' dpkg -s ' + package + \"\"\" | grep '^Status: install ok installed' | wc -l\"\"\", loglevel=loglevel, echo=echo) == '1'\n\t\telif self.current_environment.install_type == 'yum':\n\t\t\t# TODO: check whether it's already installed?. see yum notes  yum list installed \"$@\" >/dev/null 2>&1\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' yum list installed ' + package + ' >/dev/null 2>&1',\n\t\t\t                         echo=echo,\n\t\t\t                         check_exit=False,\n\t\t\t                         loglevel=loglevel,\n\t\t\t                         ignore_background=True))\n\t\t\treturn self.check_last_exit_values('install TODO change this',retbool=True)\n\t\treturn False", "response": "Returns True if the given package is installed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the module has already been installed.", "response": "def is_shutit_installed(self,\n\t                        module_id,\n\t                        note=None,\n\t                        loglevel=logging.DEBUG):\n\t\t\"\"\"Helper proc to determine whether shutit has installed already here by placing a file in the db.\n\n\t\t@param module_id: Identifying string of shutit module\n\t\t@param note:      See send()\n\t\t\"\"\"\n\t\t# If it's already in cache, then return True.\n\t\t# By default the cache is invalidated.\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tif not self.current_environment.modules_recorded_cache_valid:\n\t\t\tif self.file_exists(shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/module_record',directory=True):\n\t\t\t\t# Bit of a hack here to get round the long command showing up as the first line of the output.\n\t\t\t\ttmpid = shutit_util.random_id()\n\t\t\t\tcmd = 'find ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + r\"\"\"/module_record/ -name built | sed 's@^.\"\"\" + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + r\"\"\"/module_record.\\([^/]*\\).built@\\1@' > \"\"\" + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/' + tmpid\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=' ' + cmd,\n\t\t\t\t                         echo=False,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         ignore_background=True))\n\t\t\t\tbuilt = self.send_and_get_output(' command cat ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/' + tmpid,\n\t\t\t\t                                 echo=False,\n\t\t\t\t                                 loglevel=loglevel).strip()\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=' command rm -rf ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/' + tmpid,\n\t\t\t\t                         echo=False,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         ignore_background=True))\n\t\t\t\tbuilt_list = built.split('\\r\\n')\n\t\t\t\tself.current_environment.modules_recorded = built_list\n\t\t\t# Either there was no directory (so the cache is valid), or we've built the cache, so mark as good.\n\t\t\tself.current_environment.modules_recorded_cache_valid = True\n\t\t# Modules recorded cache will be valid at this point, so check the pre-recorded modules and the in-this-run installed cache.\n\t\tshutit.handle_note_after(note=note)\n\t\treturn module_id in self.current_environment.modules_recorded or module_id in self.current_environment.modules_installed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_terminal(self):\n\t\tshutit = self.shutit\n\t\tshutit.log('Resetting terminal begin.', level=logging.DEBUG)\n\t\t########################################################################\n\t\t# Cribbed from https://github.com/noahspurrier/pexpect/blob/master/pxssh.py#L145\n\t\t# All of these timing pace values are magic.\n\t\t# I came up with these based on what seemed reliable for\n\t\t# connecting to a heavily loaded machine I have.\n\t\tself.pexpect_child.sendline()\n\t\ttime.sleep(0.1)\n\t\t# If latency is worse than these values then this will fail.\n\t\ttry:\n\t\t\t# Clear the buffer before getting the prompt.\n\t\t\tself.pexpect_child.read_nonblocking(size=10000,timeout=1)\n\t\texcept pexpect.TIMEOUT:\n\t\t\tpass\n\t\ttime.sleep(0.1)\n\t\tself.pexpect_child.sendline()\n\t\ttime.sleep(0.5)\n\t\tself.pexpect_child.read_nonblocking(size=1000,timeout=1)\n\t\ttime.sleep(0.1)\n\t\tself.pexpect_child.sendline()\n\t\ttime.sleep(0.5)\n\t\ta = self.pexpect_child.read_nonblocking(size=1000,timeout=1)\n\t\ttime.sleep(0.1)\n\t\tself.pexpect_child.sendline()\n\t\ttime.sleep(0.5)\n\t\tb = self.pexpect_child.read_nonblocking(size=1000,timeout=1)\n\t\tld = self.levenshtein_distance(a,b)\n\t\tif len(a) == 0:\n\t\t\treturn False\n\t\tif float(ld)/len(a) < 0.4:\n\t\t\treturn True\n\t\treturn False", "response": "Resets the terminal to good a state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of memory available for use in k as an int", "response": "def get_memory(self, note=None):\n\t\t\"\"\"Returns memory available for use in k as an int\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tif self.current_environment.distro == 'osx':\n\t\t\tmemavail = self.send_and_get_output(\"\"\"command vm_stat | grep ^Pages.free: | awk '{print $3}' | tr -d '.'\"\"\",\n\t\t\t                                    timeout=3,\n\t\t\t                                    echo=False)\n\t\t\tmemavail = int(memavail)\n\t\t\tmemavail *= 4\n\t\telse:\n\t\t\tmemavail = self.send_and_get_output(\"\"\"command cat /proc/meminfo  | grep MemAvailable | awk '{print $2}'\"\"\",\n\t\t\t                                    timeout=3,\n\t\t\t                                    echo=False)\n\t\t\tif memavail == '':\n\t\t\t\tmemavail = self.send_and_get_output(\"\"\"command free | grep buffers.cache | awk '{print $3}'\"\"\",\n\t\t\t\t                                    timeout=3,\n\t\t\t\t                                    echo=False)\n\t\t\tmemavail = int(memavail)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn memavail"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self,\n\t           package,\n\t           echo=None,\n\t           options=None,\n\t           timeout=shutit_global.shutit_global_object.default_timeout,\n\t           note=None):\n\t\t\"\"\"Distro-independent remove function.\n\t\tTakes a package name and runs relevant remove function.\n\n\t\t@param package:  Package to remove, which is run through package_map.\n\t\t@param options:  Dict of options to pass to the remove command,\n\t\t                 mapped by install_type.\n\t\t@param timeout:  See send(). Default: 3600\n\t\t@param note:     See send()\n\n\t\t@return: True if all ok (i.e. the package was successfully removed),\n\t\t         False otherwise.\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\t# If separated by spaces, remove separately\n\t\tshutit = self.shutit\n\t\tif note != None:\n\t\t\tshutit.handle_note('Removing package: ' + package + '\\n' + note)\n\t\tif options is None: options = {}\n\t\tinstall_type = self.current_environment.install_type\n\t\tcmd = ''\n\t\tif install_type == 'src':\n\t\t\t# If this is a src build, we assume it's already installed.\n\t\t\treturn True\n\t\telif install_type == 'none':\n\t\t\t# If this is a none build, installing is invalid.\n\t\t\tshutit.fail('ShutiIt has no install type for the identified OS, so cannot use install method. Inform maintainers if believed to be a bug.') # pragma: no cover\n\t\tif install_type == 'apt':\n\t\t\tcmd += 'apt-get purge'\n\t\t\topts = options['apt'] if 'apt' in options else '-qq -y'\n\t\telif install_type == 'yum':\n\t\t\tcmd += 'yum erase'\n\t\t\topts = options['yum'] if 'yum' in options else '-y'\n\t\telif install_type == 'pacman':\n\t\t\tcmd += 'pacman -R'\n\t\t\tif 'pacman' in options:\n\t\t\t\topts = options['pacman']\n\t\telif install_type == 'apk':\n\t\t\tcmd += 'apk del'\n\t\t\topts = options['apt'] if 'apt' in options else '-q'\n\t\telif install_type == 'emerge':\n\t\t\tcmd += 'emerge -cav'\n\t\t\tif 'emerge' in options:\n\t\t\t\topts = options['emerge']\n\t\telif install_type == 'docker':\n\t\t\tcmd += 'docker rmi'\n\t\t\tif 'docker' in options:\n\t\t\t\topts = options['docker']\n\t\telif install_type == 'brew':\n\t\t\tcmd += 'brew uninstall'\n\t\t\tif 'brew' in options:\n\t\t\t\topts = options['brew']\n\t\t\telse:\n\t\t\t\topts += ' --force'\n\t\telse:\n\t\t\t# Not handled\n\t\t\treturn False\n\t\t# Get mapped package.\n\t\tpackage = package_map.map_packages(self, package, self.current_environment.install_type)\n\t\tpw = self.get_sudo_pass_if_needed(shutit, ignore_brew=True)\n\t\tif pw != '':\n\t\t\tcmd = 'sudo ' + cmd\n\t\t\tres = self.multisend(ShutItSendSpec(self,\n\t\t\t                                    send='%s %s %s' % (cmd, opts, package),\n\t\t\t                                    send_dict={'assword:':[pw, True]},\n\t\t\t                                    timeout=timeout,\n\t\t\t                                    exit_values=['0','100'],\n\t\t\t                                    echo=echo,\n\t\t\t                                    secret=True))\n\t\t\tif res == -1:\n\t\t\t\t# Should not happen\n\t\t\t\tassert False, shutit_util.print_debug()\n\t\telse:\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send='%s %s %s' % (cmd, opts, package),\n\t\t\t                         timeout=timeout,\n\t\t\t                         exit_values=['0','100'],\n\t\t\t\t                     echo=echo,\n\t\t\t                         ignore_background=False,\n\t\t\t                         run_in_background=False,\n\t\t\t                         block_other_commands=True))\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True", "response": "Distro - independent remove function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the output of the command matches any of the given regular expressions.", "response": "def send_and_match_output(self,\n\t                          send,\n\t                          matches,\n\t                          retry=3,\n\t                          strip=True,\n\t                          note=None,\n\t                          echo=False,\n\t                          loglevel=logging.DEBUG):\n\t\t\"\"\"Returns true if the output of the command matches any of the strings in\n\t\tthe matches list of regexp strings. Handles matching on a per-line basis\n\t\tand does not cross lines.\n\n\t\t@param send:     See send()\n\t\t@param matches:  String - or list of strings - of regexp(s) to check\n\t\t@param retry:    Number of times to retry command (default 3)\n\t\t@param strip:    Whether to strip output (defaults to True)\n\t\t@param note:     See send()\n\n\t\t@type send:      string\n\t\t@type matches:   list\n\t\t@type retry:     integer\n\t\t@type strip:     boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tshutit.log('Matching output from: \"' + send + '\" to one of these regexps:' + str(matches), level=logging.INFO)\n\t\techo = shutit.get_echo_override(echo)\n\t\toutput = self.send_and_get_output(send,\n\t\t                                  retry=retry,\n\t\t                                  strip=strip,\n\t\t                                  echo=echo,\n\t\t                                  loglevel=loglevel)\n\t\tif isinstance(matches, str):\n\t\t\tmatches = [matches]\n\t\tshutit.handle_note_after(note=note)\n\t\tfor match in matches:\n\t\t\tif shutit.match_string(output, match) != None:\n\t\t\t\tshutit.log('Matched output, return True', level=logging.DEBUG)\n\t\t\t\treturn True\n\t\tshutit.log('Failed to match output, return False', level=logging.DEBUG)\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a command to the target and returns the output.", "response": "def send_and_get_output(self,\n\t                        send,\n\t                        timeout=None,\n\t                        retry=3,\n\t                        strip=True,\n\t                        preserve_newline=False,\n\t                        note=None,\n\t                        record_command=True,\n\t                        echo=None,\n\t                        fail_on_empty_before=True,\n\t                        check_sudo=True,\n\t                        nonewline=False,\n\t                        ignore_background=False,\n\t                        filter_backspaces=True,\n\t                        loglevel=logging.INFO):\n\t\t\"\"\"Returns the output of a command run. send() is called, and exit is not checked.\n\n\t\t@param send:     See send()\n\t\t@param retry:    Number of times to retry command (default 3)\n\t\t@param strip:    Whether to strip output (defaults to True). Strips whitespace\n\t\t                 and ansi terminal codes\n\t\t@param note:     See send()\n\t\t@param echo:     See send()\n\n\t\t@type retry:     integer\n\t\t@type strip:     boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, command=str(send))\n\t\tshutit.log('Retrieving output from command: ' + send, level=loglevel)\n\t\t# Don't check exit, as that will pollute the output. Also, it's quite likely the submitted command is intended to fail.\n\t\techo = shutit.get_echo_override(echo)\n\t\tsend = shutit.get_send_command(send)\n\t\tself.send(ShutItSendSpec(self,\n\t\t                         send=send,\n\t\t                         check_exit=False,\n\t\t                         retry=retry,\n\t\t                         echo=echo,\n\t\t                         timeout=timeout,\n\t\t                         record_command=record_command,\n\t\t                         fail_on_empty_before=fail_on_empty_before,\n\t\t                         check_sudo=check_sudo,\n\t\t                         nonewline=nonewline,\n\t\t                         loglevel=loglevel,\n\t\t                         ignore_background=ignore_background))\n\t\tbefore = self.pexpect_child.before\n\n\t\tif before:\n\t\t\tpreserve_newline = bool(preserve_newline and before[-1] == '\\n')\n\t\t# CORNER CASE: if the terminal is eg a kubernetes one, it seems to use\n\t\t# backspaces (\\x08)s to manage newlines. So remove any line from before\n\t\t# if it has backspaces in the output\n\t\tif filter_backspaces:\n\t\t\tlines = before.split('\\n')\n\t\t\tlines = filter(lambda x: x.find('\\x08') == -1, lines)\n\t\t\tbefore = '\\n'.join(lines)\n\t\t# Remove the command we ran in from the output.\n\t\t# First, strip whitespace from the start of 'before', and the send:\n\t\tbefore = before.strip()\n\t\tsend = send.strip()\n\t\tshutit.log('send_and_get_output \"before\": ' + before + ', send_and_get_output send was: ' + send, level=logging.DEBUG)\n\t\tif strip:\n\t\t\t# cf: http://stackoverflow.com/questions/14693701/how-can-i-remove-the-ansi-escape-sequences-from-a-string-in-python\n\t\t\tansi_escape = re.compile(r'(\\x9B|\\x1B\\[)[0-?]*[ -\\/]*[@-~]')\n\t\t\tstring_with_termcodes = before.strip()\n\t\t\tstring_without_termcodes = ansi_escape.sub('', string_with_termcodes)\n\t\t\t#string_without_termcodes_stripped = string_without_termcodes.strip()\n\n\t\t\t# Occasionally we see ' \\r' without a following \\n. Remove these. This could be optional.\n\t\t\tstring_without_termcodes_stripped_no_cr = string_without_termcodes.replace(' \\r','')\n\t\t\t# Strip out \\rs to make it output the same as a typical CL. This could be optional.\n\t\t\tstring_without_termcodes_stripped_no_cr = string_without_termcodes.replace('\\r','')\n\t\t\tif preserve_newline:\n\t\t\t\tbefore = string_without_termcodes_stripped_no_cr + '\\n'\n\t\t\telse:\n\t\t\t\tbefore = string_without_termcodes_stripped_no_cr\n\t\telse:\n\t\t\tbefore = before\n\t\tif before.startswith(send):\n\t\t\tbefore = before[len(send):]\n\t\t\t# Strip whitespace again\n\t\t\tbefore = before.strip()\n\t\tshutit.log('send_and_get_output \"before\" after startswith check: ' + before, level=logging.DEBUG)\n\t\t# Too chatty, but kept here in case useful for debugging\n\t\tshutit.log('send_and_get_output got: ' + before, level=logging.DEBUG)\n\t\t# Leave this debug in in case there are any strange characters to consider.\n\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\tshutit.log('send_and_get_output returning in base64:\\n' + str(base64.b64encode(bytes(before,shutit_global.shutit_global_object.default_encoding))), level=logging.DEBUGV)\n\t\telse:\n\t\t\tshutit.log('send_and_get_output returning in base64:\\n' + base64.b64encode(before), level=logging.DEBUGV)\n\t\t## In rare cases a bell has been seen - can't see why we'd want a bell so simply remove them all.\n\t\tbefore = before.replace('\\x07','')\n\t\t# If there happens to be an escape character in there, it's likely a\n\t\t# problem - see IWT-4812.\n\t\tbefore = before.split('\\x1b')[0].strip()\n\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\tshutit.log('send_and_get_output returning in base64: ' + str(base64.b64encode(bytes(before,shutit_global.shutit_global_object.default_encoding))), level=logging.DEBUGV)\n\t\telse:\n\t\t\tshutit.log('send_and_get_output returning in base64: ' + base64.b64encode(bytes(before)), level=logging.DEBUGV)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn before"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_env_pass(self,user=None,msg=None,note=None):\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tuser = user or self.whoami()\n\t\t# cygwin does not have root\n\t\tpw = ''\n\t\tif self.current_environment.distro == 'cygwin':\n\t\t\treturn pw\n\t\tif user not in self.current_environment.users.keys():\n\t\t\tself.current_environment.users.update({user:None})\n\t\tif not self.current_environment.users[user] and user != 'root':\n\t\t\tmsg = msg or 'Please input the sudo password for user: ' + user\n\t\t\tpw = shutit_util.get_input(msg,ispass=True)\n\t\t\tself.current_environment.users[user] = pw\n\t\t\tshutit_global.shutit_global_object.secret_words_set.add(self.current_environment.users[user])\n\t\treturn pw", "response": "Gets a password from the user if one is not already recorded for this environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current group.", "response": "def whoarewe(self,\n\t             note=None,\n\t             loglevel=logging.DEBUG):\n\t\t\"\"\"Returns the current group.\n\n\t\t@param note:     See send()\n\n\t\t@return: the first group found\n\t\t@rtype: string\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tres = self.send_and_get_output(' command id -n -g',\n\t\t                               echo=False,\n\t\t                               loglevel=loglevel).strip()\n\t\tshutit.handle_note_after(note=note)\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_distro_info(self, loglevel=logging.DEBUG):\n\t\tshutit = self.shutit\n\t\tinstall_type   = ''\n\t\tdistro         = ''\n\t\tdistro_version = ''\n\t\tif shutit.build['distro_override'] != '':\n\t\t\tkey = shutit.build['distro_override']\n\t\t\tdistro = shutit.build['distro_override']\n\t\t\tinstall_type = package_map.INSTALL_TYPE_MAP[key]\n\t\t\tdistro_version = ''\n\t\t\tif install_type == 'apt' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not self.command_available('lsb_release'):\n\t\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['apt_update_done'] and self.whoami() == 'root':\n\t\t\t\t\t\tshutit.get_current_shutit_pexpect_session_environment().build['apt_update_done'] = True\n\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                         send='DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y -qq lsb-release',\n\t\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t\t                         ignore_background=True))\n\t\t\t\td = self.lsb_release()\n\t\t\t\tinstall_type   = d['install_type']\n\t\t\t\tdistro         = d['distro']\n\t\t\t\tdistro_version = d['distro_version']\n\t\t\telif install_type == 'yum' and shutit.build['delivery'] in ('docker', 'dockerfile'):\n\t\t\t\tif self.file_exists('/etc/redhat-release'):\n\t\t\t\t\toutput = self.send_and_get_output(' command cat /etc/redhat-release',\n\t\t\t\t\t                                  echo=False,\n\t\t\t\t\t                                  loglevel=loglevel)\n\t\t\t\t\tif re.match('^centos.*$', output.lower()) or re.match('^red hat.*$', output.lower()) or re.match('^fedora.*$', output.lower()) or True:\n\t\t\t\t\t\tself.send_and_match_output('yum install -y -t redhat-lsb',\n\t\t\t\t\t\t                           'Complete!',\n\t\t\t\t\t\t                           loglevel=loglevel)\n\t\t\t\telse:\n\t\t\t\t\tif not self.command_available('lsb_release'):\n\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                         send='yum install -y lsb-release',\n\t\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t\t                         ignore_background=True))\n\t\t\t\tinstall_type   = d['install_type']\n\t\t\t\tdistro         = d['distro']\n\t\t\t\tdistro_version = d['distro_version']\n\t\t\telif install_type == 'apk' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['apk_update_done'] and self.whoami() == 'root':\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send='apk -q update',\n\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t                         loglevel=logging.INFO))\n\t\t\t\t\tshutit.get_current_shutit_pexpect_session_environment().build['apk_update_done'] = True\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send='apk -q add bash',\n\t\t\t\t                         ignore_background=True,\n\t\t\t\t                         loglevel=loglevel))\n\t\t\t\tinstall_type   = 'apk'\n\t\t\t\tdistro         = 'alpine'\n\t\t\t\tdistro_version = '1.0'\n\t\t\telif install_type == 'pacman' and shutit.build['delivery'] in ('docker','dockerfile') and self.whoami() == 'root':\n\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['pacman_update_done']:\n\t\t\t\t\tshutit.get_current_shutit_pexpect_session_environment().build['pacman_update_done'] = True\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send='pacman -Syy',\n\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t                         loglevel=logging.INFO))\n\t\t\t\tinstall_type   = d['install_type']\n\t\t\t\tdistro         = d['distro']\n\t\t\t\tdistro_version = '1.0'\n\t\t\telif install_type == 'emerge' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['emerge_update_done'] and self.whoami() == 'root':\n\t\t\t\t\t# Takes bloody ages!\n\t\t\t\t\t#self.send(ShutItSendSpec(self,send='emerge --sync', loglevel=loglevel,timeout=9999,ignore_background=True))\n\t\t\t\t\tpass\n\t\t\t\tinstall_type = 'emerge'\n\t\t\t\tdistro = 'gentoo'\n\t\t\t\tdistro_version = '1.0'\n\t\t\telif install_type == 'docker' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tdistro = 'coreos'\n\t\t\t\tdistro_version = '1.0'\n\t\telif self.command_available('lsb_release'):\n\t\t\td = self.lsb_release()\n\t\t\tinstall_type   = d['install_type']\n\t\t\tdistro         = d['distro']\n\t\t\tdistro_version = d['distro_version']\n\t\telse:\n\t\t\tissue_output = self.send_and_get_output(' command cat /etc/issue',\n\t\t\t                                        echo=False,\n\t\t\t                                        ignore_background=True,\n\t\t\t                                        loglevel=loglevel).lower()\n\t\t\tif not re.match('.*No such file.*',issue_output):\n\t\t\t\tfor key in package_map.INSTALL_TYPE_MAP:\n\t\t\t\t\tif issue_output.find(key) != -1:\n\t\t\t\t\t\tdistro       = key\n\t\t\t\t\t\tinstall_type = package_map.INSTALL_TYPE_MAP[key]\n\t\t\t\t\t\tbreak\n\t\t\telif self.file_exists('/cygdrive'):\n\t\t\t\tdistro       = 'cygwin'\n\t\t\t\tinstall_type = 'apt-cyg'\n\t\t\tif install_type == '' or distro == '':\n\t\t\t\tif self.file_exists('/etc/os-release'):\n\t\t\t\t\tos_name = self.send_and_get_output(' command cat /etc/os-release | grep ^NAME',\n\t\t\t\t\t                                   echo=False,\n\t\t\t\t\t                                   ignore_background=True,\n\t\t\t\t\t                                   loglevel=loglevel).lower()\n\t\t\t\t\tif os_name.find('centos') != -1:\n\t\t\t\t\t\tdistro       = 'centos'\n\t\t\t\t\t\tinstall_type = 'yum'\n\t\t\t\t\telif os_name.find('red hat') != -1:\n\t\t\t\t\t\tdistro       = 'red hat'\n\t\t\t\t\t\tinstall_type = 'yum'\n\t\t\t\t\telif os_name.find('fedora') != -1:\n\t\t\t\t\t\t# TODO: distinguish with dnf - fedora 23+? search for dnf in here\n\t\t\t\t\t\tdistro       = 'fedora'\n\t\t\t\t\t\tinstall_type = 'yum'\n\t\t\t\t\telif os_name.find('gentoo') != -1:\n\t\t\t\t\t\tdistro       = 'gentoo'\n\t\t\t\t\t\tinstall_type = 'emerge'\n\t\t\t\t\telif os_name.find('coreos') != -1:\n\t\t\t\t\t\tdistro       = 'coreos'\n\t\t\t\t\t\tinstall_type = 'docker'\n\t\t\t\telse:\n\t\t\t\t\tuname_output = self.send_and_get_output(\" command uname -a | awk '{print $1}'\",\n\t\t\t\t\t                                        echo=False,\n\t\t\t\t\t                                        ignore_background=True,\n\t\t\t\t\t                                        loglevel=loglevel)\n\t\t\t\t\tif uname_output == 'Darwin':\n\t\t\t\t\t\tdistro = 'osx'\n\t\t\t\t\t\tinstall_type = 'brew'\n\t\t\t\t\t\tif not self.command_available('brew'):\n\t\t\t\t\t\t\tshutit.fail('ShutiIt requires brew be installed. See http://brew.sh for details on installation.') # pragma: no cover\n\t\t\t\t\t\tif not self.file_exists('/tmp/shutit_brew_list'):\n\t\t\t\t\t\t\tif self.whoami() != 'root':\n\t\t\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t\t\t                         send=' brew list > .shutit_brew_list',\n\t\t\t\t\t\t\t\t                         echo=False,\n\t\t\t\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t\t\t\t                         loglevel=loglevel))\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tpass\n\t\t\t\t\t\tfor package in ('coreutils','findutils','gnu-tar','gnu-sed','gawk','gnutls','gnu-indent','gnu-getopt'):\n\t\t\t\t\t\t\tif self.send_and_get_output(' command cat .shutit_brew_list | grep -w ' + package,\n\t\t\t\t\t\t\t                            echo=False,\n\t\t\t\t\t\t\t                            loglevel=loglevel) == '':\n\t\t\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t\t\t                         send='brew install ' + package,\n\t\t\t\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t\t\t\t                         loglevel=loglevel))\n\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                         send='rm -f .shutit_brew_list',\n\t\t\t\t\t\t                         echo=False,\n\t\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t\t                         loglevel=loglevel))\n\t\t\t\t\tif uname_output[:6] == 'CYGWIN':\n\t\t\t\t\t\tdistro       = 'cygwin'\n\t\t\t\t\t\tinstall_type = 'apt-cyg'\n\t\t\t\tif install_type == '' or distro == '':\n\t\t\t\t\tshutit.fail('Could not determine Linux distro information. ' + 'Please inform ShutIt maintainers at https://github.com/ianmiell/shutit', shutit_pexpect_child=self.pexpect_child) # pragma: no cover\n\t\t\t# The call to self.package_installed with lsb-release above\n\t\t\t# may fail if it doesn't know the install type, so\n\t\t\t# if we've determined that now\n\t\t\tif install_type == 'apt' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not self.command_available('lsb_release'):\n\t\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['apt_update_done'] and self.whoami() == 'root':\n\t\t\t\t\t\tshutit.get_current_shutit_pexpect_session_environment().build['apt_update_done'] = True\n\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                         send='DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y -qq lsb-release',\n\t\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t\t                         ignore_background=True))\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send='DEBIAN_FRONTEND=noninteractive apt-get install -y -qq lsb-release',\n\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                         ignore_background=True))\n\t\t\t\td = self.lsb_release()\n\t\t\t\tinstall_type   = d['install_type']\n\t\t\t\tdistro         = d['distro']\n\t\t\t\tdistro_version = d['distro_version']\n\t\t\telif install_type == 'yum' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif self.file_exists('/etc/redhat-release'):\n\t\t\t\t\toutput = self.send_and_get_output(' command cat /etc/redhat-release',\n\t\t\t\t\t                                  echo=False,\n\t\t\t\t\t                                  loglevel=loglevel)\n\t\t\t\t\tif re.match('^centos.*$', output.lower()) or re.match('^red hat.*$', output.lower()) or re.match('^fedora.*$', output.lower()) or True:\n\t\t\t\t\t\tself.send_and_match_output('yum install -y -t redhat-lsb',\n\t\t\t\t\t\t                           'Complete!',\n\t\t\t\t\t\t                           loglevel=loglevel)\n\t\t\t\telse:\n\t\t\t\t\tif not self.command_available('lsb_release'):\n\t\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t\t                         send='yum install -y lsb-release',\n\t\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t\t                         loglevel=loglevel))\n\t\t\t\td = self.lsb_release()\n\t\t\t\tinstall_type   = d['install_type']\n\t\t\t\tdistro         = d['distro']\n\t\t\t\tdistro_version = d['distro_version']\n\t\t\telif install_type == 'apk' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['apk_update_done'] and self.whoami() == 'root':\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send='apk -q update',\n\t\t\t\t\t                         ignore_background=True,\n\t\t\t\t\t                         loglevel=logging.INFO))\n\t\t\t\t\tshutit.get_current_shutit_pexpect_session_environment().build['apk_update_done'] = True\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send='apk -q add bash',\n\t\t\t\t                         ignore_background=True,\n\t\t\t\t                         loglevel=loglevel))\n\t\t\t\tinstall_type   = 'apk'\n\t\t\t\tdistro         = 'alpine'\n\t\t\t\tdistro_version = '1.0'\n\t\t\telif install_type == 'emerge' and shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\tif not shutit.get_current_shutit_pexpect_session_environment().build['emerge_update_done'] and self.whoami() == 'root':\n\t\t\t\t\t# Takes bloody ages!\n\t\t\t\t\t#self.send(ShutItSendSpec(self,send='emerge --sync', loglevel=logging.INFO,ignore_background=True))\n\t\t\t\t\tpass\n\t\t\t\tinstall_type = 'emerge'\n\t\t\t\tdistro = 'gentoo'\n\t\t\t\tdistro_version = '1.0'\n\t\t# We should have the distro info now, let's assign to target config\n\t\t# if this is not a one-off.\n\t\tself.current_environment.install_type   = install_type\n\t\tself.current_environment.distro         = distro\n\t\tself.current_environment.distro_version = distro_version\n\t\treturn True", "response": "Get information about the distro we are using."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_and_require(self,\n\t                     send,\n\t                     regexps,\n\t                     not_there=False,\n\t                     echo=None,\n\t                     note=None,\n\t                     loglevel=logging.INFO):\n\t\t\"\"\"Send string and require the item in the output.\n\t\tSee send_until\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\techo = shutit.get_echo_override(echo)\n\t\treturn self.send_until(send,\n\t\t                       regexps,\n\t\t                       not_there=not_there,\n\t\t                       cadence=0,\n\t\t                       retries=1,\n\t\t                       echo=echo,\n\t\t                       note=note,\n\t\t                       loglevel=loglevel)", "response": "Send string and require the item in the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_until(self,\n\t               send,\n\t               regexps,\n\t               not_there=False,\n\t               cadence=2,\n\t               retries=100,\n\t               echo=None,\n\t               note=None,\n\t               debug_command=None,\n\t               pause_point_on_fail=True,\n\t               nonewline=False,\n\t               loglevel=logging.INFO):\n\t\t\"\"\"Send string on a regular cadence until a string is either seen, or the timeout is triggered.\n\n\t\t@param send:                 See send()\n\t\t@param regexps:              List of regexps to wait for.\n\t\t@param not_there:            If True, wait until this a regexp is not seen in the output. If False\n\t\t                             wait until a regexp is seen in the output (default)\n\t\t@param echo:                 See send()\n\t\t@param note:                 See send()\n\t\t@param debug_command:        Command to send if the output was not there.\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, command=send + ' \\nuntil one of these seen:\\n' + str(regexps))\n\t\tshutit.log('Sending: \"' + send + '\" until one of these regexps seen: ' + str(regexps), level=loglevel)\n\t\tif isinstance(regexps, str):\n\t\t\tregexps = [regexps]\n\t\tif not isinstance(regexps, list):\n\t\t\tshutit.fail('regexps should be list') # pragma: no cover\n\t\twhile retries > 0:\n\t\t\tretries -= 1\n\t\t\techo = shutit.get_echo_override(echo)\n\t\t\toutput = self.send_and_get_output(send,\n\t\t\t                                  retry=1,\n\t\t\t                                  strip=True,\n\t\t\t                                  echo=echo,\n\t\t\t                                  loglevel=loglevel,\n\t\t\t                                  nonewline=nonewline,\n\t\t\t                                  fail_on_empty_before=False)\n\t\t\tshutit.log('Failed to match regexps -> ' + str(regexps) + ' <- retries left:' + str(retries), level=loglevel)\n\t\t\tif not not_there:\n\t\t\t\tfor regexp in regexps:\n\t\t\t\t\tif not shutit_util.check_regexp(regexp):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in send_until call: ' + regexp) # pragma: no cover\n\t\t\t\t\tif shutit.match_string(output, regexp):\n\t\t\t\t\t\treturn True\n\t\t\telse:\n\t\t\t\t# Only return if _not_ seen in the output\n\t\t\t\tmissing = False\n\t\t\t\tfor regexp in regexps:\n\t\t\t\t\tif not shutit_util.check_regexp(regexp):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in send_until call: ' + regexp) # pragma: no cover\n\t\t\t\t\tif not shutit.match_string(output, regexp):\n\t\t\t\t\t\tmissing = True\n\t\t\t\t\t\tbreak\n\t\t\t\tif missing:\n\t\t\t\t\tshutit.handle_note_after(note=note)\n\t\t\t\t\treturn True\n\t\t\tif debug_command is not None:\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=debug_command,\n\t\t\t\t                         check_exit=False,\n\t\t\t\t                         echo=echo,\n\t\t\t                             nonewline=nonewline,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t                             ignore_background=True))\n\t\t\ttime.sleep(cadence)\n\t\tshutit.handle_note_after(note=note)\n\t\tif pause_point_on_fail:\n\t\t\tshutit.pause_point('send_until failed sending: ' + send + '\\r\\nand expecting: ' + str(regexps))\n\t\t\treturn True\n\t\treturn False", "response": "Send a string on a regular cadence until one of the given regular expressions is seen."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the text in a file.", "response": "def change_text(self,\n\t                text,\n\t                fname,\n\t                pattern=None,\n\t                before=False,\n\t                force=False,\n\t                delete=False,\n\t                note=None,\n\t                replace=False,\n\t                line_oriented=True,\n\t                create=True,\n\t                loglevel=logging.DEBUG):\n\n\t\t\"\"\"Change text in a file.\n\n\t\tReturns None if there was no match for the regexp, True if it was matched\n\t\tand replaced, and False if the file did not exist or there was some other\n\t\tproblem.\n\n\t\t@param text:          Text to insert.\n\t\t@param fname:         Filename to insert text to\n\t\t@param pattern:       Regexp for a line to match and insert after/before/replace.\n\t\t                      If none, put at end of file.\n\t\t@param before:        Whether to place the text before or after the matched text.\n\t\t@param force:         Force the insertion even if the text is in the file.\n\t\t@param delete:        Delete text from file rather than insert\n\t\t@param replace:       Replace matched text with passed-in text. If nothing matches, then append.\n\t\t@param note:          See send()\n\t\t@param line_oriented: Consider the pattern on a per-line basis (default True).\n\t\t                      Can match any continuous section of the line, eg 'b.*d' will match the line: 'abcde'\n\t\t                      If not line_oriented, the regexp is considered on with the flags re.DOTALL, re.MULTILINE\n\t\t                      enabled\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\tfexists = self.file_exists(fname)\n\t\tif not fexists:\n\t\t\tif create:\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=' command touch ' + fname,\n\t\t\t\t                         echo=False,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         ignore_background=True))\n\t\t\telse:\n\t\t\t\tshutit.fail(fname + ' does not exist and create=False') # pragma: no cover\n\t\tif replace:\n\t\t\t# If replace and no pattern FAIL\n\t\t\tif not pattern:\n\t\t\t\tshutit.fail('replace=True requires a pattern to be passed in') # pragma: no cover\n\t\t\t# If replace and delete FAIL\n\t\t\tif delete:\n\t\t\t\tshutit.fail('cannot pass replace=True and delete=True to insert_text') # pragma: no cover\n\t\t# ftext is the original file's text. If base64 is available, use it to\n\t\t# encode the text\n\t\tif self.command_available('base64'):\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tftext = bytes(self.send_and_get_output(' command base64 ' + fname,\n\t\t\t\t                                       echo=False,\n\t\t\t\t                                       loglevel=loglevel),\n\t\t\t\t                                       shutit_global.shutit_global_object.default_encoding)\n\t\t\telse:\n\t\t\t\tftext = self.send_and_get_output(' command base64 ' + fname,\n\t\t\t\t                                 echo=False,\n\t\t\t\t                                 loglevel=loglevel)\n\t\t\tftext = base64.b64decode(ftext)\n\t\telse:\n\t\t\t# Replace the file text's ^M-newlines with simple newlines\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tftext = bytes(self.send_and_get_output(' command cat ' + fname,\n\t\t\t\t                                       echo=False,\n\t\t\t\t                                       loglevel=loglevel),\n\t\t\t\t                                       shutit_global.shutit_global_object.default_encoding)\n\t\t\t\tftext = ftext.replace(bytes('\\r\\n', shutit_global.shutit_global_object.default_encoding),bytes('\\n', shutit_global.shutit_global_object.default_encoding))\n\t\t\telse:\n\t\t\t\tftext = self.send_and_get_output(' command cat ' + fname,\n\t\t\t\t                                 echo=False,\n\t\t\t\t                                 loglevel=loglevel)\n\t\t\t\tftext = ftext.replace('\\r\\n','\\n')\n\t\t# Delete the text\n\t\tif delete:\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tloc = ftext.find(bytes(text,shutit_global.shutit_global_object.default_encoding))\n\t\t\telse:\n\t\t\t\tloc = ftext.find(text)\n\t\t\tif loc == -1:\n\t\t\t\t# No output - no match\n\t\t\t\treturn None\n\t\t\telse:\n\t\t\t\tnew_text = ftext[:loc] + ftext[loc+len(text)+1:]\n\t\telse:\n\t\t\tif pattern != None:\n\t\t\t\tif not line_oriented:\n\t\t\t\t\tif not shutit_util.check_regexp(pattern):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in change_text call: ' + pattern) # pragma: no cover\n\t\t\t\t\t# cf: http://stackoverflow.com/questions/9411041/matching-ranges-of-lines-in-python-like-sed-ranges\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\tsre_match = re.search(bytes(pattern,shutit_global.shutit_global_object.default_encoding),ftext,re.DOTALL|re.MULTILINE)\n\t\t\t\t\telse:\n\t\t\t\t\t\tsre_match = re.search(pattern,ftext,re.DOTALL|re.MULTILINE)\n\t\t\t\t\tif replace:\n\t\t\t\t\t\tif sre_match is None:\n\t\t\t\t\t\t\tcut_point = len(ftext)\n\t\t\t\t\t\t\tnewtext1 = ftext[:cut_point]\n\t\t\t\t\t\t\tnewtext2 = ftext[cut_point:]\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tcut_point = sre_match.start()\n\t\t\t\t\t\t\tcut_point_after = sre_match.end()\n\t\t\t\t\t\t\tnewtext1 = ftext[:cut_point]\n\t\t\t\t\t\t\tnewtext2 = ftext[cut_point_after:]\n\t\t\t\t\telse:\n\t\t\t\t\t\tif sre_match is None:\n\t\t\t\t\t\t\t# No output - no match\n\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\telif before:\n\t\t\t\t\t\t\tcut_point = sre_match.start()\n\t\t\t\t\t\t\t# If the text is already there and we're not forcing it, return None.\n\t\t\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\t\t\tif not force and ftext[cut_point-len(text):].find(bytes(text,shutit_global.shutit_global_object.default_encoding)) > 0:\n\t\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tif not force and ftext[cut_point-len(text):].find(text) > 0:\n\t\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tcut_point = sre_match.end()\n\t\t\t\t\t\t\t# If the text is already there and we're not forcing it, return None.\n\t\t\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\t\t\tif not force and ftext[cut_point:].find(bytes(text,shutit_global.shutit_global_object.default_encoding)) > 0:\n\t\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tif not force and ftext[cut_point:].find(text) > 0:\n\t\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\tnewtext1 = ftext[:cut_point]\n\t\t\t\t\t\tnewtext2 = ftext[cut_point:]\n\t\t\t\telse:\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\tlines = ftext.split(bytes('\\n',shutit_global.shutit_global_object.default_encoding))\n\t\t\t\t\telse:\n\t\t\t\t\t\tlines = ftext.split('\\n')\n\t\t\t\t\tcut_point   = 0\n\t\t\t\t\tline_length = 0\n\t\t\t\t\tmatched     = False\n\t\t\t\t\tif not shutit_util.check_regexp(pattern):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in change_text call: ' + pattern) # pragma: no cover\n\t\t\t\t\tfor line in lines:\n\t\t\t\t\t\t#Help the user out to make this properly line-oriented\n\t\t\t\t\t\tpattern_before=''\n\t\t\t\t\t\tpattern_after=''\n\t\t\t\t\t\tif not pattern or pattern[0] != '^':\n\t\t\t\t\t\t\tpattern_before = '^.*'\n\t\t\t\t\t\tif not pattern or pattern[-1] != '$':\n\t\t\t\t\t\t\tpattern_after = '.*$'\n\t\t\t\t\t\tnew_pattern = pattern_before+pattern+pattern_after\n\t\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\t\tmatch = re.search(bytes(new_pattern,shutit_global.shutit_global_object.default_encoding), line)\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tmatch = re.search(new_pattern, line)\n\t\t\t\t\t\tline_length = len(line)\n\t\t\t\t\t\tif match != None:\n\t\t\t\t\t\t\tmatched=True\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t# Update cut point to next line, including newline in original text\n\t\t\t\t\t\tcut_point += line_length+1\n\t\t\t\t\tif not replace and not matched:\n\t\t\t\t\t\t# No match, return none\n\t\t\t\t\t\treturn None\n\t\t\t\t\tif replace and not matched:\n\t\t\t\t\t\tcut_point = len(ftext)\n\t\t\t\t\telif not replace and not before:\n\t\t\t\t\t\tcut_point += line_length\n\t\t\t\t\t# newtext1 is everything up to the cutpoint\n\t\t\t\t\tnewtext1 = ftext[:cut_point]\n\t\t\t\t\t# newtext2 is everything after the cutpoint\n\t\t\t\t\tnewtext2 = ftext[cut_point:]\n\t\t\t\t\t# if replacing and we matched the output in a line, then set newtext2 to be everything from cutpoint's line end\n\t\t\t\t\tif replace and matched:\n\t\t\t\t\t\tnewtext2 = ftext[cut_point+line_length:]\n\t\t\t\t\telif not force:\n\t\t\t\t\t\t# If the text is already there and we're not forcing it, return None.\n\t\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\t\tif before and ftext[cut_point-len(text):].find(bytes(text,shutit_global.shutit_global_object.default_encoding)) > 0:\n\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\t\tif not before and ftext[cut_point:].find(bytes(text,shutit_global.shutit_global_object.default_encoding)) > 0:\n\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tif before and ftext[cut_point-len(text):].find(text) > 0:\n\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t\t\tif not before and ftext[cut_point:].find(text) > 0:\n\t\t\t\t\t\t\t\treturn None\n\t\t\t\t\t# Add a newline to newtext1 if it is not already there\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\tif newtext1 and bytes(newtext1.decode(shutit_global.shutit_global_object.default_encoding)[-1],shutit_global.shutit_global_object.default_encoding) != bytes('\\n',shutit_global.shutit_global_object.default_encoding):\n\t\t\t\t\t\t\tnewtext1 += bytes('\\n',shutit_global.shutit_global_object.default_encoding)\n\t\t\t\t\telse:\n\t\t\t\t\t\tif newtext1 and newtext1[-1] != '\\n':\n\t\t\t\t\t\t\tnewtext1 += '\\n'\n\t\t\t\t\t# Add a newline to newtext2 if it is not already there\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\tif newtext2 and bytes(newtext2.decode(shutit_global.shutit_global_object.default_encoding)[0],shutit_global.shutit_global_object.default_encoding) != bytes('\\n',shutit_global.shutit_global_object.default_encoding):\n\t\t\t\t\t\t\tnewtext2 = bytes('\\n',shutit_global.shutit_global_object.default_encoding) + newtext2\n\t\t\t\t\telse:\n\t\t\t\t\t\tif newtext2 and newtext2[0] != '\\n':\n\t\t\t\t\t\t\tnewtext2 = '\\n' + newtext2\n\t\t\telse:\n\t\t\t\t# Append to file absent a pattern.\n\t\t\t\tcut_point = len(ftext)\n\t\t\t\tnewtext1 = ftext[:cut_point]\n\t\t\t\tnewtext2 = ftext[cut_point:]\n\t\t\t# If adding or replacing at the end of the file, then ensure we have a newline at the end\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tif newtext2 == b'' and text and bytes(text[-1],shutit_global.shutit_global_object.default_encoding) != bytes('\\n',shutit_global.shutit_global_object.default_encoding):\n\t\t\t\t\tnewtext2 = bytes('\\n',shutit_global.shutit_global_object.default_encoding)\n\t\t\telse:\n\t\t\t\tif newtext2 == '' and text and text[-1] != '\\n':\n\t\t\t\t\tnewtext2 = '\\n'\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tnew_text = newtext1 + bytes(text,shutit_global.shutit_global_object.default_encoding) + newtext2\n\t\t\telse:\n\t\t\t\tnew_text = newtext1 + text + newtext2\n\t\tself.send_file(fname,\n\t\t               new_text,\n\t\t               truncate=True,\n\t\t               loglevel=loglevel)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_line_from_file(self,\n\t                          line,\n\t                          filename,\n\t                          match_regexp=None,\n\t                          literal=False,\n\t                          note=None,\n\t                          loglevel=logging.DEBUG):\n\t\t\"\"\"Removes line from file, if it exists.\n\t\tMust be exactly the line passed in to match.\n\t\tReturns True if there were no problems, False if there were.\n\n\t\t@param line:          Line to remove.\n\t\t@param filename       Filename to remove it from.\n\t\t@param match_regexp:  If supplied, a regexp to look for in the file\n\t\t                      instead of the line itself,\n\t\t                      handy if the line has awkward characters in it.\n\t\t@param literal:       If true, then simply grep for the exact string without\n\t\t                      bash interpretation. (Default: False)\n\t\t@param note:          See send()\n\n\t\t@type line:           string\n\t\t@type filename:       string\n\t\t@type match_regexp:   string\n\t\t@type literal:        boolean\n\n\t\t@return:              True if the line was matched and deleted, False otherwise.\n\t\t@rtype:               boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note)\n\t\t# assume we're going to add it\n\t\ttmp_filename = '/tmp/' + shutit_util.random_id()\n\t\tif self.file_exists(filename):\n\t\t\tif literal:\n\t\t\t\tif match_regexp is None:\n\t\t\t\t\t#            v the space is intentional, to avoid polluting bash history.\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send=\"\"\" grep -v '^\"\"\" + line + \"\"\"$' \"\"\" + filename + ' > ' + tmp_filename,\n\t\t\t\t\t                         exit_values=['0','1'],\n\t\t\t\t\t                         echo=False,\n\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                         ignore_background=True))\n\t\t\t\telse:\n\t\t\t\t\tif not shutit_util.check_regexp(match_regexp):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in remove_line_from_file call: ' + match_regexp) # pragma: no cover\n\t\t\t\t\t#            v the space is intentional, to avoid polluting bash history.\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send=\"\"\" grep -v '^\"\"\" + match_regexp + \"\"\"$' \"\"\" + filename + ' > ' + tmp_filename,\n\t\t\t\t\t                         exit_values=['0','1'],\n\t\t\t\t\t                         echo=False,\n\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                         ignore_background=True))\n\t\t\telse:\n\t\t\t\tif match_regexp is None:\n\t\t\t\t\t#          v the space is intentional, to avoid polluting bash history.\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send=' command grep -v \"^' + line + '$\" ' + filename + ' > ' + tmp_filename,\n\t\t\t\t\t                         exit_values=['0','1'],\n\t\t\t\t\t                         echo=False,\n\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                         ignore_background=True))\n\t\t\t\telse:\n\t\t\t\t\tif not shutit_util.check_regexp(match_regexp):\n\t\t\t\t\t\tshutit.fail('Illegal regexp found in remove_line_from_file call: ' + match_regexp) # pragma: no cover\n\t\t\t\t\t#          v the space is intentional, to avoid polluting bash history.\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send=' command grep -v \"^' + match_regexp + '$\" ' + filename + ' > ' + tmp_filename,\n\t\t\t\t\t                         exit_values=['0','1'],\n\t\t\t\t\t                         echo=False,\n\t\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                         ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command cat ' + tmp_filename + ' > ' + filename,\n\t\t\t                         check_exit=False,\n\t\t\t                         echo=False,\n\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                 ignore_background=True))\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command rm -f ' + tmp_filename,\n\t\t\t                         exit_values=['0','1'],\n\t\t\t                         echo=False,\n\t\t\t                         loglevel=loglevel,\n\t\t\t\t\t                 ignore_background=True))\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True", "response": "Removes a line from a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, sendspec):\n\t\tshutit = self.shutit\n\t\tshutit.log('In session: ' + self.pexpect_session_id + ', trying to send: ' + str(sendspec.send), level=logging.DEBUG)\n\t\tif self._check_blocked(sendspec):\n\t\t\tshutit.log('In send for ' + str(sendspec.send) + ', check_blocked called and returned True.', level=logging.DEBUG)\n\t\t\t# _check_blocked will add to the list of background tasks and handle dupes, so leave there.\n\t\t\treturn -1\n\t\tshutit = self.shutit\n\t\tcfg = shutit.cfg\n\t\t# Set up what we expect.\n\t\tsendspec.expect = sendspec.expect or self.default_expect\n\t\tassert sendspec.send is not None, shutit_util.print_debug()\n\t\tif sendspec.send.strip() == '':\n\t\t\tsendspec.fail_on_empty_before=False\n\t\t\tsendspec.check_exit=False\n\t\tif isinstance(sendspec.expect, dict):\n\t\t\treturn self.multisend(ShutItSendSpec(self,\n\t\t\t                                     send=sendspec.send,\n\t\t\t                                     send_dict=sendspec.expect,\n\t\t\t                                     expect=shutit.get_default_shutit_pexpect_session_expect(),\n\t\t\t                                     timeout=sendspec.timeout,\n\t\t\t                                     check_exit=sendspec.check_exit,\n\t\t\t                                     fail_on_empty_before=sendspec.fail_on_empty_before,\n\t\t\t                                     record_command=sendspec.record_command,\n\t\t\t                                     exit_values=sendspec.exit_values,\n\t\t\t                                     echo=sendspec.echo,\n\t\t\t                                     note=sendspec.note,\n\t\t\t                                     secret=sendspec.secret,\n\t\t\t                                     check_sudo=sendspec.check_sudo,\n\t\t\t                                     nonewline=sendspec.nonewline,\n\t\t\t                                     loglevel=sendspec.loglevel))\n\n\t\t# Before gathering expect, detect whether this is a sudo command and act accordingly.\n\t\tcommand_list = sendspec.send.strip().split()\n\t\t# If there is a first command, there is a sudo in there (we ignore\n\t\t# whether it's quoted in the command), and we do not have sudo rights\n\t\t# cached...\n\t\t# TODO: check for sudo in pipelines, eg 'cmd | sudo' or 'cmd |sudo' but not 'echo \" sudo \"'\n\t\tif sendspec.check_sudo and command_list and command_list[0] == 'sudo' and not self.check_sudo():\n\t\t\tsudo_pass = self.get_sudo_pass_if_needed(shutit)\n\t\t\t# Turn expect into a dict.\n\t\t\treturn self.multisend(ShutItSendSpec(self,\n\t\t\t                                     send=sendspec.send,\n\t\t\t                                     send_dict={'assword':[sudo_pass, True]},\n\t\t\t                                     expect=shutit.get_default_shutit_pexpect_session_expect(),\n\t\t\t                                     timeout=sendspec.timeout,\n\t\t\t                                     check_exit=sendspec.check_exit,\n\t\t\t                                     fail_on_empty_before=sendspec.fail_on_empty_before,\n\t\t\t                                     record_command=sendspec.record_command,\n\t\t\t                                     exit_values=sendspec.exit_values,\n\t\t\t                                     echo=sendspec.echo,\n\t\t\t                                     note=sendspec.note,\n\t\t\t                                     check_sudo=False,\n\t\t\t                                     nonewline=sendspec.nonewline,\n\t\t\t                                     loglevel=sendspec.loglevel))\n\n\t\tshutit.handle_note(sendspec.note, command=str(sendspec.send), training_input=str(sendspec.send))\n\t\tif sendspec.timeout is None:\n\t\t\tsendspec.timeout = 3600\n\n\t\tsendspec.echo = shutit.get_echo_override(sendspec.echo)\n\n\t\t# Handle OSX to get the GNU version of the command\n\t\tif sendspec.assume_gnu:\n\t\t\tsendspec.send = shutit.get_send_command(sendspec.send)\n\n\t\t# If check_exit is not passed in\n\t\t# - if the expect matches the default, use the default check exit\n\t\t# - otherwise, default to doing the check\n\t\tif sendspec.check_exit is None:\n\t\t\t# If we are in video mode, ignore exit value\n\t\t\tif (shutit.build['video'] != -1 or shutit.build['video'] is True) or shutit.build['training'] or shutit.build['walkthrough'] or shutit.build['exam']:\n\t\t\t\tsendspec.check_exit = False\n\t\t\telif sendspec.expect == shutit.get_default_shutit_pexpect_session_expect():\n\t\t\t\tsendspec.check_exit = shutit.get_default_shutit_pexpect_session_check_exit()\n\t\t\telse:\n\t\t\t\t# If expect given doesn't match the defaults and no argument\n\t\t\t\t# was passed in (ie check_exit was passed in as None), set\n\t\t\t\t# check_exit to true iff it matches a prompt.\n\t\t\t\texpect_matches_prompt = False\n\t\t\t\tfor prompt in shutit.expect_prompts:\n\t\t\t\t\tif prompt == sendspec.expect:\n\t\t\t\t\t\texpect_matches_prompt = True\n\t\t\t\tif not expect_matches_prompt:\n\t\t\t\t\tsendspec.check_exit = False\n\t\t\t\telse:\n\t\t\t\t\tsendspec.check_exit = True\n\n\t\t# Determine whether we record this command.\n\t\tok_to_record = False\n\t\tif not sendspec.echo and sendspec.record_command is None:\n\t\t\tsendspec.record_command = False\n\t\tif sendspec.record_command is None or sendspec.record_command:\n\t\t\tok_to_record = True\n\t\t\tfor i in cfg.keys():\n\t\t\t\tif isinstance(cfg[i], dict):\n\t\t\t\t\tfor j in cfg[i].keys():\n\t\t\t\t\t\tif (j == 'password' or j == 'passphrase') and cfg[i][j] == sendspec.send:\n\t\t\t\t\t\t\tshutit.build['shutit_command_history'].append ('#redacted command, password')\n\t\t\t\t\t\t\tok_to_record = False\n\t\t\t\t\t\t\tbreak\n\t\t\t\tif not ok_to_record or sendspec.send in shutit_global.shutit_global_object.secret_words_set:\n\t\t\t\t\tsendspec.secret = True\n\t\t\t\t\tbreak\n\t\t\tif ok_to_record:\n\t\t\t\tshutit.build['shutit_command_history'].append(sendspec.send)\n\n\t\t# Log - tho not if secret.\n\t\tif sendspec.send != None:\n\t\t\tshutit.log('================================================================================', level=logging.DEBUG)\n\t\t\tsend_and_expect_summary_msg = ''\n\t\t\tif not sendspec.echo and not sendspec.secret:\n\t\t\t\tsend_and_expect_summary_msg += 'Sending: ' + sendspec.send\n\t\t\telif not sendspec.echo and sendspec.secret:\n\t\t\t\tsend_and_expect_summary_msg += 'Sending: ' + sendspec.send\n\t\t\tif not sendspec.secret:\n\t\t\t\tsend_and_expect_summary_msg += 'Sending>>>' + sendspec.send + '<<<'\n\t\t\telse:\n\t\t\t\tsend_and_expect_summary_msg += 'Sending>>>[SECRET]<<<'\n\t\t\tsend_and_expect_summary_msg += ', expecting>>>' + str(sendspec.expect) + '<<<'\n\t\t\tshutit.log(send_and_expect_summary_msg, level=logging.DEBUG)\n\n\t\twhile sendspec.retry > 0:\n\t\t\tif sendspec.escape:\n\t\t\t\tescaped_str = \"eval $'\"\n\t\t\t\t_count = 7\n\t\t\t\tfor char in sendspec.send:\n\t\t\t\t\tif char in string.ascii_letters:\n\t\t\t\t\t\tescaped_str += char\n\t\t\t\t\t\t_count += 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tescaped_str += shutit_util.get_wide_hex(char)\n\t\t\t\t\t\t_count += 4\n\t\t\t\t\tif _count > shutit_global.shutit_global_object.line_limit:\n\t\t\t\t\t\t# The newline here is deliberate!\n\t\t\t\t\t\tescaped_str += r\"\"\"'\\\n$'\"\"\"\n\t\t\t\t\t\t_count = 0\n\t\t\t\tescaped_str += \"'\"\n\t\t\t\tif sendspec.secret:\n\t\t\t\t\tshutit.log('The string was sent safely.', level=logging.DEBUG)\n\t\t\t\telse:\n\t\t\t\t\tshutit.log('This string was sent safely: ' + sendspec.send, level=logging.DEBUG)\n\t\t\t\tstring_to_send = escaped_str\n\t\t\telse:\n\t\t\t\tstring_to_send = sendspec.send\n\t\t\tif string_to_send is not None:\n\t\t\t\tif len(string_to_send) > shutit_global.shutit_global_object.line_limit:\n\t\t\t\t\tfname = self._create_command_file(sendspec.expect,string_to_send)\n\t\t\t\t\tres = self.send(ShutItSendSpec(self,\n\t\t\t\t\t                               send=' command source ' + fname,\n\t\t\t\t\t                               expect=sendspec.expect,\n\t\t\t\t\t                               timeout=sendspec.timeout,\n\t\t\t\t\t                               check_exit=sendspec.check_exit,\n\t\t\t\t\t                               fail_on_empty_before=False,\n\t\t\t\t\t                               record_command=False,\n\t\t\t\t\t                               exit_values=sendspec.exit_values,\n\t\t\t\t\t                               echo=False,\n\t\t\t\t\t                               escape=False,\n\t\t\t\t\t                               retry=sendspec.retry,\n\t\t\t\t\t                               loglevel=sendspec.loglevel,\n\t\t\t\t\t                               follow_on_commands=sendspec.follow_on_commands,\n\t\t\t\t\t                               delaybeforesend=sendspec.delaybeforesend,\n\t\t\t                                       nonewline=sendspec.nonewline,\n\t\t\t                                       run_in_background=sendspec.run_in_background,\n\t\t\t\t\t                               ignore_background=True,\n\t\t\t                                       block_other_commands=sendspec.block_other_commands))\n\t\t\t\t\tif not self.sendline(ShutItSendSpec(self,\n\t\t\t\t\t                                    send=' rm -f ' + fname,\n\t\t\t\t\t                                    nonewline=sendspec.nonewline,\n\t\t\t                                            run_in_background=sendspec.run_in_background,\n\t\t\t\t\t                                    echo=False,\n\t\t\t\t\t                                    ignore_background=True)):\n\t\t\t\t\t\tself.expect(sendspec.expect,\n\t\t\t\t\t\t            searchwindowsize=sendspec.searchwindowsize,\n\t\t\t\t\t\t            maxread=sendspec.maxread)\n\t\t\t\t\t\t# Before returning, determine whether we are now in a shell by comparing the expect we have with the originally-created 'shell_expect'.\n\t\t\t\t\t\tself.in_shell = sendspec.expect == self.shell_expect\n\t\t\t\t\treturn res\n\t\t\t\telse:\n\t\t\t\t\tif sendspec.echo:\n\t\t\t\t\t\tshutit.divert_output(sys.stdout)\n\t\t\t\t\tif not self.sendline(sendspec):\n\t\t\t\t\t\texpect_res = shutit.expect_allow_interrupt(self.pexpect_child, sendspec.expect, sendspec.timeout)\n\t\t\t\t\telse:\n\t\t\t\t\t\texpect_res = -1\n\t\t\t\t\tif sendspec.echo:\n\t\t\t\t\t\tshutit.divert_output(None)\n\t\t\telse:\n\t\t\t\texpect_res = shutit.expect_allow_interrupt(self.pexpect_child, sendspec.expect, sendspec.timeout)\n\t\t\tif isinstance(self.pexpect_child.after, type) or isinstance(self.pexpect_child.before, type):\n\t\t\t\tshutit.log('End of pexpect session detected, bailing.', level=logging.CRITICAL)\n\t\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\t\t# Massage the output for summary sending.\n\t\t\tlogged_output = ''.join((self.pexpect_child.before + str(self.pexpect_child.after)).split('\\n')).replace(sendspec.send,'',1).replace('\\r','')[:160] + ' [...]'\n\t\t\tif not sendspec.secret:\n\t\t\t\tif not sendspec.echo:\n\t\t\t\t\tshutit.log('Output (squashed): ' + logged_output, level=logging.DEBUG)\n\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\tshutit.log('pexpect: buffer: ' + str(base64.b64encode(bytes(self.pexpect_child.buffer,shutit_global.shutit_global_object.default_encoding))) + ' before: ' + str(base64.b64encode(bytes(self.pexpect_child.before,shutit_global.shutit_global_object.default_encoding))) + ' after: ' + str(base64.b64encode(bytes(self.pexpect_child.after,shutit_global.shutit_global_object.default_encoding))), level=logging.DEBUG)\n\t\t\t\telse:\n\t\t\t\t\tshutit.log('pexpect: buffer: ' + base64.b64encode(self.pexpect_child.buffer) + ' before: ' + base64.b64encode(self.pexpect_child.before) + ' after: '  + base64.b64encode(self.pexpect_child.after), level=logging.DEBUG)\n\t\t\telse:\n\t\t\t\tshutit.log('[Send was marked secret; getting output debug will require code change]', level=logging.DEBUG)\n\t\t\tif sendspec.fail_on_empty_before:\n\t\t\t\tif self.pexpect_child.before.strip() == '':\n\t\t\t\t\tshutit.fail('before empty after sending: ' + str(sendspec.send) + '\\n\\nThis is expected after some commands that take a password.\\nIf so, add fail_on_empty_before=False to the send call.\\n\\nIf that is not the problem, did you send an empty string to a prompt by mistake?', shutit_pexpect_child=self.pexpect_child) # pragma: no cover\n\t\t\telse:\n\t\t\t\t# Don't check exit if fail_on_empty_before is False\n\t\t\t\tsendspec.check_exit = False\n\t\t\t\tfor prompt in shutit.expect_prompts:\n\t\t\t\t\tif prompt == sendspec.expect:\n\t\t\t\t\t\t# Reset prompt\n\t\t\t\t\t\tself.setup_prompt('reset_tmp_prompt')\n\t\t\t\t\t\tself.revert_prompt('reset_tmp_prompt', sendspec.expect)\n\t\t\t\t\t\tbreak\n\t\t\t# Last output - remove the first line, as it is the previous command.\n\t\t\t# Get this before we check exit.\n\t\t\tlast_output = '\\n'.join(self.pexpect_child.before.split('\\n')[1:])\n\t\t\tif sendspec.check_exit:\n\t\t\t\t# store the output\n\t\t\t\tif not self.check_last_exit_values(sendspec.send,\n\t\t\t\t                                   check_exit=sendspec.check_exit,\n\t\t\t\t                                   expect=sendspec.expect,\n\t\t\t\t                                   exit_values=sendspec.exit_values,\n\t\t\t\t                                   retry=sendspec.retry):\n\t\t\t\t\tif not sendspec.secret:\n\t\t\t\t\t\tshutit.log('Sending: ' + sendspec.send + ' : failed, retrying', level=logging.DEBUG)\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.log('Send failed, retrying', level=logging.DEBUG)\n\t\t\t\t\tsendspec.retry -= 1\n\t\t\t\t\tassert sendspec.retry > 0, shutit_util.print_debug()\n\t\t\t\t\tcontinue\n\t\t\tbreak\n\t\t# check self.pexpect_child.before for matches for follow-on commands\n\t\tif sendspec.follow_on_commands is not None:\n\t\t\tfor match in sendspec.follow_on_commands:\n\t\t\t\tsendspec.send = sendspec.follow_on_commands[match]\n\t\t\t\tif shutit.match_string(last_output, match):\n\t\t\t\t\t# send (with no follow-on commands)\n\t\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t\t                         send=sendspec.send,\n\t\t\t\t\t                         expect=sendspec.expect,\n\t\t\t\t\t                         timeout=sendspec.timeout,\n\t\t\t\t\t                         check_exit=sendspec.check_exit,\n\t\t\t\t\t                         fail_on_empty_before=False,\n\t\t\t\t\t                         record_command=sendspec.record_command,\n\t\t\t\t\t                         exit_values=sendspec.exit_values,\n\t\t\t\t\t                         echo=sendspec.echo,\n\t\t\t\t\t                         escape=sendspec.escape,\n\t\t\t\t\t                         retry=sendspec.retry,\n\t\t\t\t\t                         loglevel=sendspec.loglevel,\n\t\t\t\t\t                         delaybeforesend=sendspec.delaybeforesend,\n\t\t\t                                 run_in_background=False,\n\t\t\t\t\t                         ignore_background=True,\n\t\t\t                                 block_other_commands=sendspec.block_other_commands))\n\t\tif shutit.build['step_through']:\n\t\t\tself.pause_point('pause point: stepping through')\n\t\tif shutit.build['ctrlc_stop']:\n\t\t\tshutit.build['ctrlc_stop'] = False\n\t\t\tself.pause_point('pause point: interrupted by CTRL-c')\n\t\tshutit.handle_note_after(note=sendspec.note, training_input=str(sendspec.send))\n\t\t# Before returning, determine whether we are now in a shell by comparing the expect we have with the originally-created 'shell_expect'.\n\t\tself.in_shell = sendspec.expect == self.shell_expect\n\t\treturn expect_res", "response": "Send a string as a shell command and wait until the expected output is seen before returning."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_file(self,\n\t              path,\n\t              contents,\n\t              echo=False,\n\t              truncate=False,\n\t              note=None,\n\t              user=None,\n\t              group=None,\n\t              loglevel=logging.INFO,\n\t              encoding=None):\n\t\t\"\"\"Sends the passed-in string as a file to the passed-in path on the\n\t\ttarget.\n\n\t\t@param path:        Target location of file on target.\n\t\t@param contents:    Contents of file as a string.\n\t\t@param note:        See send()\n\t\t@param user:        Set ownership to this user (defaults to whoami)\n\t\t@param group:       Set group to this user (defaults to first group in groups)\n\n\t\t@type path:         string\n\t\t@type contents:     string\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, 'Sending contents to path: ' + path)\n\t\t# make more efficient by only looking at first 10000 chars, stop when we get to 30 chars rather than reading whole file.\n\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\tsplit_contents = ''.join((str(contents[:10000]).split()))\n\t\telse:\n\t\t\tsplit_contents = ''.join((contents[:10000].split()))\n\t\tstrings_from_file = re.findall(\"[^\\x00-\\x1F\\x7F-\\xFF]\", split_contents)\n\t\tshutit.log('Sending file contents beginning: \"' + ''.join(strings_from_file)[:30] + ' [...]\" to file: ' + path, level=loglevel)\n\t\tif user is None:\n\t\t\tuser = self.whoami()\n\t\tif group is None:\n\t\t\tgroup = self.whoarewe()\n\t\tif self.current_environment.environment_id == 'ORIGIN_ENV' and False:\n\t\t\t# If we're on the root env (ie the same one that python is running on, then use python.\n\t\t\tif isinstance(contents, str):\n\t\t\t\tf = open(path,'w')\n\t\t\t\tif truncate:\n\t\t\t\t\tf.truncate(0)\n\t\t\t\ttry:\n\t\t\t\t\tf.write(contents)\n\t\t\t\texcept (UnicodeDecodeError, TypeError) as e:\n\t\t\t\t\tshutit.log('Error decoding: ' + str(e), level=logging.DEBUG)\n\t\t\t\t\tif encoding is not None:\n\t\t\t\t\t\tf.write(contents.decode(encoding))\n\t\t\t\t\telse:\n\t\t\t\t\t\tf.write(contents.decode(shutit_global.shutit_global_object.default_encoding))\n\t\t\telif isinstance(contents, bytes):\n\t\t\t\tf = open(path,'w')\n\t\t\t\tif truncate:\n\t\t\t\t\tf.truncate(0)\n\t\t\t\ttry:\n\t\t\t\t\tf.write(contents)\n\t\t\t\texcept (UnicodeDecodeError, TypeError) as e:\n\t\t\t\t\tif encoding is not None:\n\t\t\t\t\t\tf.write(contents.decode(encoding))\n\t\t\t\t\telse:\n\t\t\t\t\t\tf.write(contents.decode(shutit_global.shutit_global_object.default_encoding))\n\t\t\telse:\n\t\t\t\tshutit.fail('type: ' + str(type(contents)) + ' not handled in 1') # pragma: no cover\n\t\t\tf.close()\n\t\telif shutit.build['delivery'] in ('bash','dockerfile'):\n\t\t\tif truncate and self.file_exists(path):\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=' command rm -f ' + path,\n\t\t\t\t                         echo=False,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         ignore_background=True))\n\t\t\trandom_id = shutit_util.random_id()\n\t\t\t# set the searchwindowsize to a low number to speed up processing of large output\n\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\tif encoding is not None:\n\t\t\t\t\tb64contents = base64.b64encode(contents.encode(encoding)).decode(encoding)\n\t\t\t\telse:\n\t\t\t\t\tif isinstance(contents, str):\n\t\t\t\t\t\tb64contents = base64.b64encode(contents.encode(shutit_global.shutit_global_object.default_encoding)).decode(shutit_global.shutit_global_object.default_encoding)\n\t\t\t\t\telif isinstance(contents, bytes):\n\t\t\t\t\t\tb64contents = base64.b64encode(contents).decode(shutit_global.shutit_global_object.default_encoding)\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.fail('type: ' + str(type(contents)) + ' not handled in 2') # pragma: no cover\n\t\t\telse:\n\t\t\t\tif encoding is not None:\n\t\t\t\t\tb64contents = base64.b64encode(contents.encode(encoding))\n\t\t\t\telse:\n\t\t\t\t\tb64contents = base64.b64encode(contents.encode(shutit_global.shutit_global_object.default_encoding))\n\t\t\t# split the contents into chunks and append to avoid PC_MAX_CANON: see https://github.com/pexpect/pexpect/commit/f3ef67b6ba5508d0d118b59837d099f5144e576b\n\t\t\ttotal_length = len(b64contents)\n\t\t\tposition = 0\n\t\t\tleap=1000\n\t\t\twhile position < total_length:\n\t\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t\t                         send=' ' + shutit.get_command('head') + ' -c -1 >> ' + path + \".\" + random_id + \" << 'END_\" + random_id + \"\"\"'\\n\"\"\" + b64contents[position:position+leap] + '''\\nEND_''' + random_id,\n\t\t\t\t                         echo=echo,\n\t\t\t\t                         loglevel=loglevel,\n\t\t\t\t                         timeout=shutit_global.shutit_global_object.default_timeout,\n\t\t\t\t                         ignore_background=True))\n\t\t\t\tposition += leap\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command cat ' + path + '.' + random_id + ' | base64 --decode > ' + path,\n\t\t\t                         echo=echo,\n\t\t\t                         loglevel=loglevel,\n\t\t\t                         ignore_background=True))\n\t\t\t# Remove the file\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command rm -f ' + path + '.' + random_id,\n\t\t\t                         loglevel=loglevel,\n\t\t\t                         echo=False,\n\t\t\t                         ignore_background=True))\n\t\telse:\n\t\t\thost_child = shutit.get_shutit_pexpect_session_from_id('host_child').pexpect_child\n\t\t\tpath = path.replace(' ', r'\\ ')\n\t\t\t# get host session\n\t\t\ttmpfile = shutit_global.shutit_global_object.shutit_state_dir + 'tmp_' + shutit_util.random_id()\n\t\t\tf = open(tmpfile,'wb')\n\t\t\tf.truncate(0)\n\t\t\t# TODO: try taking out trys\n\t\t\tif isinstance(contents, bytes):\n\t\t\t\ttry:\n\t\t\t\t\tif shutit_global.shutit_global_object.ispy3:\n\t\t\t\t\t\tf.write(contents)\n\t\t\t\t\telif encoding is not None:\n\t\t\t\t\t\tf.write(contents.encode(encoding))\n\t\t\t\t\telse:\n\t\t\t\t\t\tf.write(contents.encode(shutit_global.shutit_global_object.default_encoding))\n\t\t\t\texcept (UnicodeDecodeError, TypeError) as e:\n\t\t\t\t\tf.write(contents)\n\t\t\telse:\n\t\t\t\t# We assume it's unicode, or str. Can't be explicit because python3 and 2 differ in how they handle...\n\t\t\t\ttry:\n\t\t\t\t\tif encoding is not None:\n\t\t\t\t\t\tf.write(contents.encode(encoding))\n\t\t\t\t\telse:\n\t\t\t\t\t\tf.write(contents.encode(shutit_global.shutit_global_object.default_encoding))\n\t\t\t\texcept (UnicodeDecodeError, TypeError) as e:\n\t\t\t\t\tf.write(contents)\n\t\t\tf.close()\n\t\t\t# Create file so it has appropriate permissions\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command touch ' + path,\n\t\t\t                         loglevel=loglevel,\n\t\t\t                         echo=echo,\n\t\t\t                         ignore_background=True))\n\t\t\t# If path is not absolute, add $HOME to it.\n\t\t\tif path[0] != '/':\n\t\t\t\tshutit.send(' command cat ' + tmpfile + ' | ' + shutit.host['docker_executable'] + ' exec -i ' + shutit.target['container_id'] + \" bash -c 'cat > $HOME/\" + path + \"'\",\n\t\t\t\t            shutit_pexpect_child=host_child,\n\t\t\t\t            expect=shutit.expect_prompts['ORIGIN_ENV'],\n\t\t\t\t            loglevel=loglevel,\n\t\t\t\t            echo=echo)\n\t\t\telse:\n\t\t\t\tshutit.send(' command cat ' + tmpfile + ' | ' + shutit.host['docker_executable'] + ' exec -i ' + shutit.target['container_id'] + \" bash -c 'cat > \" + path + \"'\",\n\t\t\t\t            shutit_pexpect_child=host_child,\n\t\t\t\t            expect=shutit.expect_prompts['ORIGIN_ENV'],\n\t\t\t\t            loglevel=loglevel,\n\t\t\t\t            echo=echo)\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' command chown ' + user + ' ' + path + ' && chgrp ' + group + ' ' + path,\n\t\t\t                         echo=echo,\n\t\t\t                         loglevel=loglevel,\n\t\t\t                         ignore_background=True))\n\t\t\tos.remove(tmpfile)\n\t\tshutit.handle_note_after(note=note)\n\t\treturn True", "response": "Sends the passed - in file to the specified path on the target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_script(self,\n\t               script,\n\t               in_shell=True,\n\t               echo=None,\n\t               note=None,\n\t               loglevel=logging.DEBUG):\n\t\t\"\"\"Run the passed-in string as a script on the target's command line.\n\n\t\t@param script:   String representing the script. It will be de-indented\n\t\t\t\t\t\t and stripped before being run.\n\t\t@param in_shell: Indicate whether we are in a shell or not. (Default: True)\n\t\t@param note:     See send()\n\n\t\t@type script:    string\n\t\t@type in_shell:  boolean\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tshutit.handle_note(note, 'Script: ' + str(script))\n\t\tshutit.log('Running script beginning: \"' + ''.join(script.split())[:30] + ' [...]', level=logging.INFO)\n\t\t# Trim any whitespace lines from start and end of script, then dedent\n\t\tlines = script.split('\\n')\n\t\twhile lines and re.match('^[ \\t]*$', lines[0]):\n\t\t\tlines = lines[1:]\n\t\twhile lines and re.match('^[ \\t]*$', lines[-1]):\n\t\t\tlines = lines[:-1]\n\t\tif not lines:\n\t\t\treturn True\n\t\tscript = '\\n'.join(lines)\n\t\tscript = textwrap.dedent(script)\n\t\t# Send the script and run it in the manner specified\n\t\tif shutit.build['delivery'] in ('docker','dockerfile') and in_shell:\n\t\t\tscript = ('set -o xtrace \\n\\n' + script + '\\n\\nset +o xtrace')\n\t\tself.quick_send('command mkdir -p ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts && chmod 777 ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts', echo=False)\n\t\tself.send_file(shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh',\n\t\t               script,\n\t\t               echo=False,\n\t\t               loglevel=loglevel)\n\t\tself.quick_send('command chmod +x ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh', echo=False)\n\t\tshutit.build['shutit_command_history'].append('    ' + script.replace('\\n', '\\n    '))\n\t\tif in_shell:\n\t\t\tret = self.send(ShutItSendSpec(self,\n\t\t\t                               send=' . ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh && rm -f ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh && rm -f ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh',\n\t\t\t                               echo=False,\n\t\t\t                               loglevel=loglevel))\n\t\telse:\n\t\t\tret = self.send(ShutItSendSpec(self,\n\t\t\t                               send=' ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh && rm -f ' + shutit_global.shutit_global_object.shutit_state_dir + '/scripts/shutit_script.sh',\n\t\t\t                               echo=False,\n\t\t\t                               loglevel=loglevel))\n\t\tshutit.handle_note_after(note=note)\n\t\treturn ret", "response": "Run a script on the target."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the user a task to complete success or failure.", "response": "def challenge(self,\n\t              shutit,\n\t              task_desc,\n\t              expect=None,\n\t              hints=None,\n\t              congratulations='OK',\n\t              failed='FAILED',\n\t              expect_type='exact',\n\t              challenge_type='command',\n\t              timeout=None,\n\t              check_exit=None,\n\t              fail_on_empty_before=True,\n\t              record_command=True,\n\t              exit_values=None,\n\t              echo=True,\n\t              escape=False,\n\t              pause=1,\n\t              loglevel=logging.DEBUG,\n\t              follow_on_context=None,\n\t              difficulty=1.0,\n\t              reduction_per_minute=0.2,\n\t              reduction_per_reset=0,\n\t              reduction_per_hint=0.5,\n\t              grace_period=30,\n\t              new_stage=True,\n\t              final_stage=False,\n\t              num_stages=None):\n\t\t\"\"\"Set the user a task to complete, success being determined by matching the output.\n\n\t\tEither pass in regexp(s) desired from the output as a string or a list, or an md5sum of the output wanted.\n\n\t\t@param follow_on_context     On success, move to this context. A dict of information about that context.\n\t\t                             context              = the type of context, eg docker, bash\n\t\t                             ok_container_name    = if passed, send user to this container\n\t\t                             reset_container_name = if resetting, send user to this container\n\t\t@param challenge_type        Behaviour of challenge made to user\n\t\t                             command = check for output of single command\n\t\t                             golf    = user gets a pause point, and when leaving, command follow_on_context['check_command'] is run to check the output\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\tif new_stage and shutit.build['exam_object']:\n\t\t\tif num_stages is None:\n\t\t\t\tnum_stages = shutit.build['exam_object'].num_stages\n\t\t\telif shutit.build['exam_object'].num_stages < 1:\n\t\t\t\tshutit.build['exam_object'].num_stages = num_stages\n\t\t\telif shutit.build['exam_object'].num_stages > 0:\n\t\t\t\tshutit.fail('Error! num_stages passed in should be None if already set in exam object (ie > 0)') # pragma: no cover\n\t\t\tcurr_stage = str(shutit.build['exam_object'].curr_stage)\n\t\t\tif num_stages > 0:\n\t\t\t\ttask_desc = 80*'*' + '\\n' + '* QUESTION ' + str(curr_stage) + '/' + str(num_stages) + '\\n' + 80*'*' + '\\n' + task_desc\n\t\t\telse:\n\t\t\t\ttask_desc = 80*'*' + '\\n' + '* QUESTION \\n' + 80*'*' + '\\n' + task_desc\n\t\t\tshutit.build['exam_object'].new_stage(difficulty=difficulty,\n\t\t\t                                      reduction_per_minute=reduction_per_minute,\n\t\t\t                                      reduction_per_reset=reduction_per_reset,\n\t\t\t                                      reduction_per_hint=reduction_per_hint,\n\t\t\t                                      grace_period=grace_period)\n\t\t\t# If this is an exam, then remove history.\n\t\t\tself.send(ShutItSendSpec(self,\n\t\t\t                         send=' history -c',\n\t\t\t                         check_exit=False,\n\t\t\t                         ignore_background=True))\n\t\t# don't catch CTRL-C, pass it through.\n\t\tshutit.build['ctrlc_passthrough'] = True\n\t\tpreserve_newline                  = False\n\t\tskipped                           = False\n\t\tif expect_type == 'regexp':\n\t\t\tif isinstance(expect, str):\n\t\t\t\texpect = [expect]\n\t\t\tif not isinstance(expect, list):\n\t\t\t\tshutit.fail('expect_regexps should be list') # pragma: no cover\n\t\telif expect_type == 'md5sum':\n\t\t\tpreserve_newline = True\n\t\telif expect_type == 'exact':\n\t\t\tpass\n\t\telse:\n\t\t\tshutit.fail('Must pass either expect_regexps or md5sum in') # pragma: no cover\n\t\tif hints:\n\t\t\tshutit.build['pause_point_hints'] = hints\n\t\telse:\n\t\t\tshutit.build['pause_point_hints'] = []\n\t\tif challenge_type == 'command':\n\t\t\thelp_text = shutit_util.colorise('32','''\\nType 'help' or 'h' to get a hint, 'exit' to skip, 'shutitreset' to reset state.''')\n\t\t\tok = False\n\t\t\twhile not ok:\n\t\t\t\tshutit.log(shutit_util.colorise('32','''\\nChallenge!'''),transient=True, level=logging.INFO)\n\t\t\t\tif hints:\n\t\t\t\t\tshutit.log(shutit_util.colorise('32',help_text),transient=True, level=logging.INFO)\n\t\t\t\ttime.sleep(pause)\n\t\t\t\t# TODO: bash path completion\n\t\t\t\tsend = shutit_util.get_input(task_desc + ' => ',color='31')\n\t\t\t\tif not send or send.strip() == '':\n\t\t\t\t\tcontinue\n\t\t\t\tif send in ('help','h'):\n\t\t\t\t\tif hints:\n\t\t\t\t\t\tshutit.log(help_text,transient=True, level=logging.CRITICAL)\n\t\t\t\t\t\tshutit.log(shutit_util.colorise('32',hints.pop()),transient=True, level=logging.CRITICAL)\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.log(help_text,transient=True, level=logging.CRITICAL)\n\t\t\t\t\t\tshutit.log(shutit_util.colorise('32','No hints left, sorry! CTRL-g to reset state, CTRL-s to skip this step, CTRL-] to submit for checking'),transient=True, level=logging.CRITICAL)\n\t\t\t\t\ttime.sleep(pause)\n\t\t\t\t\tcontinue\n\t\t\t\tif send == 'shutitreset':\n\t\t\t\t\tself._challenge_done(shutit, result='reset',follow_on_context=follow_on_context,final_stage=False)\n\t\t\t\t\tcontinue\n\t\t\t\tif send == 'shutitquit':\n\t\t\t\t\tself._challenge_done(shutit, result='reset',follow_on_context=follow_on_context,final_stage=True)\n\t\t\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\t\t\tif send == 'exit':\n\t\t\t\t\tself._challenge_done(shutit, result='exited',follow_on_context=follow_on_context,final_stage=True)\n\t\t\t\t\tshutit.build['pause_point_hints'] = []\n\t\t\t\t\treturn True\n\t\t\t\toutput = self.send_and_get_output(send,\n\t\t\t\t                                  timeout=timeout,\n\t\t\t\t                                  retry=1,\n\t\t\t\t                                  record_command=record_command,\n\t\t\t\t                                  echo=echo,\n\t\t\t\t                                  loglevel=loglevel,\n\t\t\t\t                                  fail_on_empty_before=False,\n\t\t\t\t                                  preserve_newline=preserve_newline)\n\t\t\t\tmd5sum_output = md5(output).hexdigest()\n\t\t\t\tshutit.log('output: ' + output + ' is md5sum: ' + md5sum_output, level=logging.DEBUG)\n\t\t\t\tif expect_type == 'md5sum':\n\t\t\t\t\toutput = md5sum_output\n\t\t\t\t\tif output == expect:\n\t\t\t\t\t\tok = True\n\t\t\t\telif expect_type == 'exact':\n\t\t\t\t\tif output == expect:\n\t\t\t\t\t\tok = True\n\t\t\t\telif expect_type == 'regexp':\n\t\t\t\t\tfor regexp in expect:\n\t\t\t\t\t\tif shutit.match_string(output, regexp):\n\t\t\t\t\t\t\tok = True\n\t\t\t\t\t\t\tbreak\n\t\t\t\tif not ok and failed:\n\t\t\t\t\tif shutit.build['exam_object']:\n\t\t\t\t\t\tshutit.build['exam_object'].add_fail()\n\t\t\t\t\t\tshutit.build['exam_object'].end_timer()\n\t\t\t\t\tshutit.log('\\n\\n' + shutit_util.colorise('32','failed') + '\\n',transient=True, level=logging.CRITICAL)\n\t\t\t\t\tself._challenge_done(shutit, result='failed',final_stage=final_stage)\n\t\t\t\t\tcontinue\n\t\telif challenge_type == 'golf':\n\t\t\t# pause, and when done, it checks your working based on check_command.\n\t\t\tok = False\n\t\t\t# hints\n\t\t\tif hints:\n\t\t\t\t# TODO: debug this, it doesn't work!\n\t\t\t\ttask_desc_new = task_desc + '\\r\\n\\r\\nHit CTRL-h for help, CTRL-g to reset state, CTRL-s to skip, CTRL-] to submit for checking'\n\t\t\telse:\n\t\t\t\ttask_desc_new = '\\r\\n' + task_desc\n\t\t\twhile not ok:\n\t\t\t\tif shutit.build['exam_object'] and new_stage:\n\t\t\t\t\tshutit.build['exam_object'].start_timer()\n\t\t\t\t\t# Set the new_stage to False, as we're in a loop that doesn't need to mark a new state.\n\t\t\t\t\tnew_stage = False\n\t\t\t\tself.pause_point(shutit_util.colorise('31',task_desc_new),color='31')\n\t\t\t\tif shutit_global.shutit_global_object.signal_id == 8:\n\t\t\t\t\tif shutit.build['exam_object']:\n\t\t\t\t\t\tshutit.build['exam_object'].add_hint()\n\t\t\t\t\tif shutit.build['pause_point_hints']:\n\t\t\t\t\t\tshutit.log(shutit_util.colorise('31','\\r\\n========= HINT ==========\\r\\n\\r\\n' + shutit.build['pause_point_hints'].pop(0)),transient=True, level=logging.CRITICAL)\n\t\t\t\t\telse:\n\t\t\t\t\t\tshutit.log(shutit_util.colorise('31','\\r\\n\\r\\n' + 'No hints available!'),transient=True, level=logging.CRITICAL)\n\t\t\t\t\ttime.sleep(1)\n\t\t\t\t\t# clear the signal\n\t\t\t\t\tshutit_global.shutit_global_object.signal_id = 0\n\t\t\t\t\tcontinue\n\t\t\t\telif shutit_global.shutit_global_object.signal_id == 17:\n\t\t\t\t\t# clear the signal and ignore CTRL-q\n\t\t\t\t\tshutit_global.shutit_global_object.signal_id = 0\n\t\t\t\t\tcontinue\n\t\t\t\telif shutit_global.shutit_global_object.signal_id == 7:\n\t\t\t\t\tif shutit.build['exam_object']:\n\t\t\t\t\t\tshutit.build['exam_object'].add_reset()\n\t\t\t\t\tshutit.log(shutit_util.colorise('31','\\r\\n========= RESETTING STATE ==========\\r\\n\\r\\n'),transient=True, level=logging.CRITICAL)\n\t\t\t\t\tself._challenge_done(shutit, result='reset', follow_on_context=follow_on_context,final_stage=False)\n\t\t\t\t\t# clear the signal\n\t\t\t\t\tshutit_global.shutit_global_object.signal_id = 0\n\t\t\t\t\t# Get the new target child, which is the new 'self'\n\t\t\t\t\ttarget_child = shutit.get_shutit_pexpect_session_from_id('target_child')\n\t\t\t\t\treturn target_child.challenge(\n\t\t\t\t\t\tshutit,\n\t\t\t\t\t\ttask_desc=task_desc,\n\t\t\t\t\t\texpect=expect,\n\t\t\t\t\t\thints=hints,\n\t\t\t\t\t\tcongratulations=congratulations,\n\t\t\t\t\t\tfailed=failed,\n\t\t\t\t\t\texpect_type=expect_type,\n\t\t\t\t\t\tchallenge_type=challenge_type,\n\t\t\t\t\t\ttimeout=timeout,\n\t\t\t\t\t\tcheck_exit=check_exit,\n\t\t\t\t\t\tfail_on_empty_before=fail_on_empty_before,\n\t\t\t\t\t\trecord_command=record_command,\n\t\t\t\t\t\texit_values=exit_values,\n\t\t\t\t\t\techo=echo,\n\t\t\t\t\t\tescape=escape,\n\t\t\t\t\t\tpause=pause,\n\t\t\t\t\t\tloglevel=loglevel,\n\t\t\t\t\t\tfollow_on_context=follow_on_context,\n\t\t\t\t\t\tnew_stage=False\n\t\t\t\t\t)\n\t\t\t\telif shutit_global.shutit_global_object.signal_id == 19:\n\t\t\t\t\tif shutit.build['exam_object']:\n\t\t\t\t\t\tshutit.build['exam_object'].add_skip()\n\t\t\t\t\t\tshutit.build['exam_object'].end_timer()\n\t\t\t\t\t# Clear the signal.\n\t\t\t\t\tshutit_global.shutit_global_object.signal_id = 0\n\t\t\t\t\t# Skip test.\n\t\t\t\t\tshutit.log('\\r\\nTest skipped... please wait', level=logging.CRITICAL,transient=True)\n\t\t\t\t\tskipped=True\n\t\t\t\t\tself._challenge_done(shutit, result='skipped',follow_on_context=follow_on_context,skipped=True,final_stage=final_stage)\n\t\t\t\t\treturn True\n\t\t\t\telif shutit_global.shutit_global_object.signal_id == 29:\n\t\t\t\t\t# Clear the signal\n\t\t\t\t\tshutit_global.shutit_global_object.signal_id = 0\n\t\t\t\telse:\n\t\t\t\t\tshutit.log('Signal not handled: ' + str(shutit_global.shutit_global_object.signal_id), level=logging.CRITICAL,transient=True)\n\n\t\t\t\tshutit.log('\\r\\nState submitted, checking your work...', level=logging.CRITICAL,transient=True)\n\t\t\t\tcheck_command = follow_on_context.get('check_command')\n\t\t\t\toutput = self.send_and_get_output(check_command,\n\t\t\t\t                                  timeout=timeout,\n\t\t\t\t                                  retry=1,\n\t\t\t\t                                  record_command=record_command,\n\t\t\t\t                                  echo=False,\n\t\t\t\t                                  loglevel=loglevel,\n\t\t\t\t                                  fail_on_empty_before=False,\n\t\t\t\t                                  preserve_newline=preserve_newline)\n\t\t\t\tshutit.log('output: ' + output, level=logging.DEBUG)\n\t\t\t\tmd5sum_output = md5(output).hexdigest()\n\t\t\t\tif expect_type == 'md5sum':\n\t\t\t\t\tshutit.log('output: ' + output + ' is md5sum: ' + md5sum_output, level=logging.DEBUG)\n\t\t\t\t\toutput = md5sum_output\n\t\t\t\t\tif output == expect:\n\t\t\t\t\t\tok = True\n\t\t\t\telif expect_type == 'exact':\n\t\t\t\t\tif output == expect:\n\t\t\t\t\t\tok = True\n\t\t\t\telif expect_type == 'regexp':\n\t\t\t\t\tfor regexp in expect:\n\t\t\t\t\t\tif shutit.match_string(output,regexp):\n\t\t\t\t\t\t\tok = True\n\t\t\t\t\t\t\tbreak\n\t\t\t\tif not ok and failed:\n\t\t\t\t\tshutit.log('\\r\\n\\n' + shutit_util.colorise('31','Failed! CTRL-g to reset state, CTRL-h for a hint, CTRL-] to submit for checking') + '\\n',transient=True, level=logging.CRITICAL)\n\t\t\t\t\t# No second chances if exam!\n\t\t\t\t\tif shutit.build['exam_object']:\n\t\t\t\t\t\tshutit.build['exam_object'].add_fail()\n\t\t\t\t\t\tshutit.build['exam_object'].end_timer()\n\t\t\t\t\t\tself._challenge_done(shutit, result='failed_test',follow_on_context=follow_on_context,final_stage=final_stage)\n\t\t\t\t\t\treturn False\n\t\t\t\t\telse:\n\t\t\t\t\t\tcontinue\n\t\telse:\n\t\t\tshutit.fail('Challenge type: ' + challenge_type + ' not supported') # pragma: no cover\n\t\tself._challenge_done(shutit,\n\t\t                     result='ok',\n\t\t                     follow_on_context=follow_on_context,\n\t\t                     congratulations=congratulations,\n\t\t                     skipped=skipped,\n\t\t                     final_stage=final_stage)\n\t\tif shutit.build['exam_object']:\n\t\t\tshutit.build['exam_object'].add_ok()\n\t\t\tshutit.build['exam_object'].end_timer()\n\t\t# Tidy up hints\n\t\tshutit.build['pause_point_hints'] = []\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pause_input_filter(self, input_string):\n\t\t#shutit_global.shutit_global_object.shutit_print('in _pause_input_filter, ord(input_string): ' + str(ord(input_string)))\n\t\tshutit = self.shutit\n\t\t# Can get errors with eg up/down chars\n\t\tif len(input_string) == 1:\n\t\t\t# Picked CTRL-u as the rarest one accepted by terminals.\n\t\t\tif ord(input_string) == 21 and shutit.build['delivery'] == 'docker':\n\t\t\t\tshutit.log('CTRL and u caught, forcing a tag at least', level=logging.INFO)\n\t\t\t\tshutit.do_repository_work('tagged_by_shutit', password=shutit.host['password'], docker_executable=shutit.host['docker_executable'], force=True)\n\t\t\t\tshutit.log('Commit and tag done. Hit CTRL and ] to continue with build. Hit return for a prompt.', level=logging.CRITICAL)\n\t\t\t# CTRL-d\n\t\t\telif ord(input_string) == 4:\n\t\t\t\tshutit.log(\"\"\"\\r\\n\\r\\nCTRL-D ignored in pause points. Type 'exit' to log out, but be warned that continuing the run with CTRL-] may then give unexpected results!\\r\\n\"\"\", level=logging.INFO, transient=True)\n\t\t\t\treturn ''\n\t\t\t# CTRL-h\n\t\t\telif ord(input_string) == 8:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 8\n\t\t\t\t# Return the escape from pexpect char\n\t\t\t\treturn '\\x1d'\n\t\t\t# CTRL-g\n\t\t\telif ord(input_string) == 7:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 7\n\t\t\t\t# Return the escape from pexpect char\n\t\t\t\treturn '\\x1d'\n\t\t\t# CTRL-p - used as part of CTRL-p - CTRL-q\n\t\t\telif ord(input_string) == 16:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 16\n\t\t\t\tif shutit.build['exam'] and self.shutit.loglevel not in ('DEBUG','INFO'):\n\t\t\t\t\treturn ''\n\t\t\t\treturn '\\x10'\n\t\t\t# CTRL-q\n\t\t\telif ord(input_string) == 17:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 17\n\t\t\t\tif not shutit.build['exam'] and self.shutit.loglevel not in ('DEBUG',):\n\t\t\t\t\tshutit.log('CTRL-q hit, quitting ShutIt',transient=True, level=logging.CRITICAL)\n\t\t\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\t\t# CTRL-s\n\t\t\telif ord(input_string) == 19:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 19\n\t\t\t\t# Return the escape from pexpect char\n\t\t\t\treturn '\\x1d'\n\t\t\t# CTRL-]\n\t\t\t# Foreign keyboard?: http://superuser.com/questions/398/how-to-send-the-escape-character-on-os-x-terminal/427#427\n\t\t\telif ord(input_string) == 29:\n\t\t\t\tshutit_global.shutit_global_object.signal_id = 29\n\t\t\t\t# Return the escape from pexpect char\n\t\t\t\treturn '\\x1d'\n\t\treturn input_string", "response": "Input filter for pause point to catch special keystrokes\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_finalize():\n\tdef _finalize(shutit):\n\t\t# Stop all the modules\n\t\tshutit.stop_all()\n\t\t# Finalize in reverse order\n\t\tshutit.log('PHASE: finalizing object ' + str(shutit), level=logging.DEBUG)\n\t\t# Login at least once to get the exports.\n\t\tfor module_id in shutit.module_ids(rev=True):\n\t\t\t# Only finalize if it's thought to be installed.\n\t\t\tif shutit.is_installed(shutit.shutit_map[module_id]):\n\t\t\t\tshutit.login(prompt_prefix=module_id,command=shutit_global.shutit_global_object.bash_startup_command,echo=False)\n\t\t\t\tif not shutit.shutit_map[module_id].finalize(shutit):\n\t\t\t\t\tshutit.fail(module_id + ' failed on finalize', shutit_pexpect_child=shutit.get_shutit_pexpect_session_from_id('target_child').pexpect_child) # pragma: no cover\n\t\t\t\tshutit.logout(echo=False)\n\t\tfor fshutit in shutit_global.shutit_global_object.shutit_objects:\n\t\t\t_finalize(fshutit)", "response": "Runs finalize phase ; run after all builds are complete and all modules have been stopped."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether the run orders are in the appropriate order.", "response": "def check_dependee_order(depender, dependee, dependee_id):\n\t\"\"\"Checks whether run orders are in the appropriate order.\n\t\"\"\"\n\t# If it depends on a module id, then the module id should be higher up\n\t# in the run order.\n\tshutit_global.shutit_global_object.yield_to_draw()\n\tif dependee.run_order > depender.run_order:\n\t\treturn 'depender module id:\\n\\n' + depender.module_id + '\\n\\n(run order: ' + str(depender.run_order) + ') ' + 'depends on dependee module_id:\\n\\n' + dependee_id + '\\n\\n(run order: ' + str(dependee.run_order) + ') ' + 'but the latter is configured to run after the former'\n\treturn ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a digraph string fragment based on the passed - in module", "response": "def make_dep_graph(depender):\n\t\"\"\"Returns a digraph string fragment based on the passed-in module\n\t\"\"\"\n\tshutit_global.shutit_global_object.yield_to_draw()\n\tdigraph = ''\n\tfor dependee_id in depender.depends_on:\n\t\tdigraph = (digraph + '\"' + depender.module_id + '\"->\"' + dependee_id + '\";\\n')\n\treturn digraph"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set with each value per config file in it.", "response": "def get_config_set(self, section, option):\n\t\t\"\"\"Returns a set with each value per config file in it.\n\t\t\"\"\"\n\t\tvalues = set()\n\t\tfor cp, filename, fp in self.layers:\n\t\t\tfilename = filename # pylint\n\t\t\tfp = fp # pylint\n\t\t\tif cp.has_option(section, option):\n\t\t\t\tvalues.add(cp.get(section, option))\n\t\treturn values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreload all the config items in the database.", "response": "def reload(self):\n\t\t\"\"\"\n\t\tRe-reads all layers again. In theory this should overwrite all the old\n\t\tvalues with any newer ones.\n\t\tIt assumes we never delete a config item before reload.\n\t\t\"\"\"\n\t\toldlayers = self.layers\n\t\tself.layers = []\n\t\tfor cp, filename, fp in oldlayers:\n\t\t\tcp = cp # pylint\n\t\t\tif fp is None:\n\t\t\t\tself.read(filename)\n\t\t\telse:\n\t\t\t\tself.readfp(fp, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the first shutit_pexpect_session object related to the given environment_id.", "response": "def get_shutit_pexpect_session_environment(self, environment_id):\n\t\t\"\"\"Returns the first shutit_pexpect_session object related to the given\n\t\tenvironment-id\n\t\t\"\"\"\n\t\tif not isinstance(environment_id, str):\n\t\t\tself.fail('Wrong argument type in get_shutit_pexpect_session_environment') # pragma: no cover\n\t\tfor env in shutit_global.shutit_global_object.shutit_pexpect_session_environments:\n\t\t\tif env.environment_id == environment_id:\n\t\t\t\treturn env\n\t\treturn None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the current environment from the currently - set default pexpect child.", "response": "def get_current_shutit_pexpect_session_environment(self, note=None):\n\t\t\"\"\"Returns the current environment from the currently-set default\n\t\tpexpect child.\n\t\t\"\"\"\n\t\tself.handle_note(note)\n\t\tcurrent_session = self.get_current_shutit_pexpect_session()\n\t\tif current_session is not None:\n\t\t\tres = current_session.current_environment\n\t\telse:\n\t\t\tres = None\n\t\tself.handle_note_after(note)\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_shutit_pexpect_session(self, note=None):\n\t\tself.handle_note(note)\n\t\tres = self.current_shutit_pexpect_session\n\t\tself.handle_note_after(note)\n\t\treturn res", "response": "Returns the currently - set default pexpect child object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all the shutit_pexpect_session keys for this object.", "response": "def get_shutit_pexpect_sessions(self, note=None):\n\t\t\"\"\"Returns all the shutit_pexpect_session keys for this object.\n\n\t\t@return: list of all shutit_pexpect_session keys (pexpect_session_ids)\n\t\t\"\"\"\n\t\tself.handle_note(note)\n\t\tsessions = []\n\t\tfor key in self.shutit_pexpect_sessions:\n\t\t\tsessions.append(shutit_object.shutit_pexpect_sessions[key])\n\t\tself.handle_note_after(note)\n\t\treturn sessions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_default_shutit_pexpect_session(self, shutit_pexpect_session):\n\t\tassert isinstance(shutit_pexpect_session, ShutItPexpectSession), shutit_util.print_debug()\n\t\tself.current_shutit_pexpect_session = shutit_pexpect_session\n\t\treturn True", "response": "Sets the default pexpect child."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the default pexpect string for the current pexpect session.", "response": "def set_default_shutit_pexpect_session_expect(self, expect=None):\n\t\t\"\"\"Sets the default pexpect string (usually a prompt).\n\t\tDefaults to the configured root prompt if no\n\t\targument is passed.\n\n\t\t@param expect: String to expect in the output\n\t\t@type expect: string\n\t\t\"\"\"\n\t\tif expect is None:\n\t\t\tself.current_shutit_pexpect_session.default_expect = self.expect_prompts['ORIGIN_ENV']\n\t\telse:\n\t\t\tself.current_shutit_pexpect_session.default_expect = expect\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fail(self, msg, shutit_pexpect_child=None, throw_exception=False):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# Note: we must not default to a child here\n\t\tif shutit_pexpect_child is not None:\n\t\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\t\tshutit_util.print_debug(sys.exc_info())\n\t\t\tshutit_pexpect_session.pause_point('Pause point on fail: ' + msg, color='31')\n\t\tif throw_exception:\n\t\t\tsys.stderr.write('Error caught: ' + msg + '\\n')\n\t\t\tsys.stderr.write('\\n')\n\t\t\tshutit_util.print_debug(sys.exc_info())\n\t\t\traise ShutItFailException(msg)\n\t\telse:\n\t\t\t# This is an \"OK\" failure, ie we don't need to throw an exception.\n\t\t\t# However, it's still a \"failure\", so return 1\n\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1,msg=msg)\n\t\tshutit_global.shutit_global_object.yield_to_draw()", "response": "Handles a failure, pausing if a pexpect child object is passed in.\n\n\t\t@param shutit_pexpect_child: pexpect child to work on\n\t\t@param throw_exception: Whether to throw an exception.\n\t\t@type throw_exception: boolean"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current environment id from the current pexpect session.", "response": "def get_current_environment(self, note=None):\n\t\t\"\"\"Returns the current environment id from the current\n\t\tshutit_pexpect_session\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.handle_note(note)\n\t\tres = self.get_current_shutit_pexpect_session_environment().environment_id\n\t\tself.handle_note_after(note)\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending string and require the item in the output.", "response": "def send_and_require(self,\n\t                     send,\n\t                     regexps,\n\t                     not_there=False,\n\t                     shutit_pexpect_child=None,\n\t                     echo=None,\n\t                     note=None,\n\t                     loglevel=logging.INFO):\n\t\t\"\"\"Send string and require the item in the output.\n\t\tSee send_until\n\t    \"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.send_and_require(send,\n\t\t                                               regexps,\n\t\t                                               not_there=not_there,\n\t\t                                               echo=echo,\n\t\t                                               note=note,\n\t\t                                               loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_until(self,\n\t               send,\n\t               regexps,\n\t               not_there=False,\n\t               shutit_pexpect_child=None,\n\t               cadence=5,\n\t               retries=100,\n\t               echo=None,\n\t               note=None,\n\t               debug_command=None,\n\t               pause_point_on_fail=True,\n\t               nonewline=False,\n\t               loglevel=logging.INFO):\n\t\t\"\"\"Send string on a regular cadence until a string is either seen, or the timeout is triggered.\n\n\t\t@param send:                 See send()\n\t\t@param regexps:              List of regexps to wait for.\n\t\t@param not_there:            If True, wait until this a regexp is not seen in the output. If False\n\t\t                             wait until a regexp is seen in the output (default)\n\t\t@param shutit_pexpect_child:                See send()\n\t\t@param echo:                 See send()\n\t\t@param note:                 See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.send_until(send,\n\t\t                                         regexps,\n\t\t                                         not_there=not_there,\n\t\t                                         cadence=cadence,\n\t\t                                         retries=retries,\n\t\t                                         echo=echo,\n\t\t                                         note=note,\n\t\t                                         loglevel=loglevel,\n\t\t                                         debug_command=debug_command,\n\t\t                                         nonewline=nonewline,\n\t\t                                         pause_point_on_fail=pause_point_on_fail)", "response": "Send a string on a regular cadence until a string is seen or the timeout is triggered."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasks the user for a task.", "response": "def challenge(self,\n\t              task_desc,\n\t              expect=None,\n\t              hints=None,\n\t              congratulations='OK',\n\t              failed='FAILED',\n\t              expect_type='exact',\n\t              challenge_type='command',\n\t              shutit_pexpect_child=None,\n\t              timeout=None,\n\t              check_exit=None,\n\t              fail_on_empty_before=True,\n\t              record_command=True,\n\t              exit_values=None,\n\t              echo=True,\n\t              escape=False,\n\t              pause=1,\n\t              loglevel=logging.DEBUG,\n\t              follow_on_context=None,\n\t              num_stages=None):\n\t\t\"\"\"Set the user a task to complete, success being determined by matching the output.\n\n\t\tEither pass in regexp(s) desired from the output as a string or a list, or an md5sum of the output wanted.\n\n\t\t@param follow_on_context     On success, move to this context. A dict of information about that context.\n\t\t                             context              = the type of context, eg docker, bash\n\t\t                             ok_container_name    = if passed, send user to this container\n\t\t                             reset_container_name = if resetting, send user to this container\n\t\t@param challenge_type        Behaviour of challenge made to user\n\t\t                             command = check for output of single command\n\t\t                             golf    = user gets a pause point, and when leaving, command follow_on_context['check_command'] is run to check the output\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.challenge(self,\n\t\t                                        task_desc=task_desc,\n  \t\t                                        expect=expect,\n\t\t                                        hints=hints,\n\t\t                                        congratulations=congratulations,\n\t\t                                        failed=failed,\n\t\t                                        expect_type=expect_type,\n\t\t                                        challenge_type=challenge_type,\n\t\t                                        timeout=timeout,\n\t\t                                        check_exit=check_exit,\n\t\t                                        fail_on_empty_before=fail_on_empty_before,\n\t\t                                        record_command=record_command,\n\t\t                                        exit_values=exit_values,\n\t\t                                        echo=echo,\n\t\t                                        escape=escape,\n\t\t                                        pause=pause,\n\t\t                                        loglevel=loglevel,\n\t\t                                        follow_on_context=follow_on_context,\n\t\t                                        num_stages=num_stages)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a string to the current command and wait until the expected output is found.", "response": "def send(self,\n\t         send,\n\t         expect=None,\n\t         shutit_pexpect_child=None,\n\t         timeout=None,\n\t         check_exit=None,\n\t         fail_on_empty_before=True,\n\t         record_command=True,\n\t         exit_values=None,\n\t         echo=None,\n\t         escape=False,\n\t         retry=3,\n\t         note=None,\n\t         assume_gnu=True,\n\t         follow_on_commands=None,\n\t         searchwindowsize=None,\n\t         maxread=None,\n\t         delaybeforesend=None,\n\t         secret=False,\n\t         nonewline=False,\n\t         background=False,\n\t         wait=True,\n\t         block_other_commands=True,\n\t         loglevel=logging.INFO):\n\t\t\"\"\"Send string as a shell command, and wait until the expected output\n\t\tis seen (either a string or any from a list of strings) before\n\t\treturning. The expected string will default to the currently-set\n\t\tdefault expected string (see get_default_shutit_pexpect_session_expect)\n\n\t\tReturns the pexpect return value (ie which expected string in the list\n\t\tmatched)\n\n\t\t@param send: See shutit.ShutItSendSpec\n\t\t@param expect: See shutit.ShutItSendSpec\n\t\t@param shutit_pexpect_child: See shutit.ShutItSendSpec\n\t\t@param timeout: See shutit.ShutItSendSpec\n\t\t@param check_exit: See shutit.ShutItSendSpec\n\t\t@param fail_on_empty_before:See shutit.ShutItSendSpec\n\t\t@param record_command:See shutit.ShutItSendSpec\n\t\t@param exit_values:See shutit.ShutItSendSpec\n\t\t@param echo: See shutit.ShutItSendSpec\n\t\t@param escape: See shutit.ShutItSendSpec\n\t\t@param retry: See shutit.ShutItSendSpec\n\t\t@param note: See shutit.ShutItSendSpec\n\t\t@param assume_gnu: See shutit.ShutItSendSpec\n\t\t@param wait: See shutit.ShutItSendSpec\n\t\t@param block_other_commands: See shutit.ShutItSendSpec.block_other_commands\n\t\t@return: The pexpect return value (ie which expected string in the list matched)\n\t\t@rtype: string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tignore_background = not wait\n\t\treturn shutit_pexpect_session.send(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                                  send,\n\t\t                                                  expect=expect,\n\t\t                                                  timeout=timeout,\n\t\t                                                  check_exit=check_exit,\n\t\t                                                  fail_on_empty_before=fail_on_empty_before,\n\t\t                                                  record_command=record_command,\n\t\t                                                  exit_values=exit_values,\n\t\t                                                  echo=echo,\n\t\t                                                  escape=escape,\n\t\t                                                  retry=retry,\n\t\t                                                  note=note,\n\t\t                                                  assume_gnu=assume_gnu,\n\t\t                                                  loglevel=loglevel,\n\t\t                                                  follow_on_commands=follow_on_commands,\n\t\t                                                  searchwindowsize=searchwindowsize,\n\t\t                                                  maxread=maxread,\n\t\t                                                  delaybeforesend=delaybeforesend,\n\t\t                                                  secret=secret,\n\t\t                                                  nonewline=nonewline,\n\t\t                                                  run_in_background=background,\n\t\t                                                  ignore_background=ignore_background,\n\t\t                                                  block_other_commands=block_other_commands))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_and_return_status(self,\n\t                           send,\n\t                           expect=None,\n\t                           shutit_pexpect_child=None,\n\t                           timeout=None,\n\t                           fail_on_empty_before=True,\n\t                           record_command=True,\n\t                           exit_values=None,\n\t                           echo=None,\n\t                           escape=False,\n\t                           retry=3,\n\t                           note=None,\n\t                           assume_gnu=True,\n\t                           follow_on_commands=None,\n\t                           loglevel=logging.INFO):\n\t\t\"\"\"Returns true if a good exit code was received (usually 0)\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tshutit_pexpect_session.send(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                           send=send,\n\t\t                                           expect=expect,\n\t\t                                           timeout=timeout,\n\t\t                                           check_exit=False,\n\t\t                                           fail_on_empty_before=fail_on_empty_before,\n\t\t                                           record_command=record_command,\n\t\t                                           exit_values=exit_values,\n\t\t                                           echo=echo,\n\t\t                                           escape=escape,\n\t\t                                           retry=retry,\n\t\t                                           note=note,\n\t\t                                           assume_gnu=assume_gnu,\n\t\t                                           loglevel=loglevel,\n\t\t                                           follow_on_commands=follow_on_commands))\n\t\treturn shutit_pexpect_session.check_last_exit_values(send,\n\t\t                                                     check_exit=True,\n\t\t                                                     expect=expect,\n\t\t                                                     exit_values=exit_values,\n\t\t                                                     retry=retry,\n\t\t                                                     retbool=True)", "response": "Send and return status of a command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_note(self, note, command='', training_input=''):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif self.build['walkthrough'] and note != None and note != '':\n\t\t\tassert isinstance(note, str), shutit_util.print_debug()\n\t\t\twait = self.build['walkthrough_wait']\n\t\t\twrap = '\\n' + 80*'=' + '\\n'\n\t\t\tmessage = wrap + note + wrap\n\t\t\tif command != '':\n\t\t\t\tmessage += 'Command to be run is:\\n\\t' + command + wrap\n\t\t\tif wait >= 0:\n\t\t\t\tself.pause_point(message, color=31, wait=wait)\n\t\t\telse:\n\t\t\t\tif training_input != '' and self.build['training']:\n\t\t\t\t\tif len(training_input.split('\\n')) == 1:\n\t\t\t\t\t\tshutit_global.shutit_global_object.shutit_print(shutit_util.colorise('31',message))\n\t\t\t\t\t\twhile shutit_util.util_raw_input(prompt=shutit_util.colorise('32','Enter the command to continue (or \"s\" to skip typing it in): ')) not in (training_input,'s'):\n\t\t\t\t\t\t\tshutit_global.shutit_global_object.shutit_print('Wrong! Try again!')\n\t\t\t\t\t\tshutit_global.shutit_global_object.shutit_print(shutit_util.colorise('31','OK!'))\n\t\t\t\t\telse:\n\t\t\t\t\t\tself.pause_point(message + '\\nToo long to use for training, so skipping the option to type in!\\nHit CTRL-] to continue', color=31)\n\t\t\t\telse:\n\t\t\t\t\tself.pause_point(message + '\\nHit CTRL-] to continue', color=31)\n\t\treturn True", "response": "Handle a note and walkthrough option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a script on the target.", "response": "def run_script(self,\n\t               script,\n\t               shutit_pexpect_child=None,\n\t               in_shell=True,\n\t               echo=None,\n\t               note=None,\n\t               loglevel=logging.DEBUG):\n\t\t\"\"\"Run the passed-in string as a script on the target's command line.\n\n\t\t@param script:   String representing the script. It will be de-indented\n\t\t\t\t\t\t and stripped before being run.\n\t\t@param shutit_pexpect_child:    See send()\n\t\t@param in_shell: Indicate whether we are in a shell or not. (Default: True)\n\t\t@param note:     See send()\n\n\t\t@type script:    string\n\t\t@type in_shell:  boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.run_script(script,\n\t\t                                         in_shell=in_shell,\n\t\t                                         echo=echo,\n\t\t                                         note=note,\n\t\t                                         loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_file(self,\n\t              path,\n\t              contents,\n\t              shutit_pexpect_child=None,\n\t              truncate=False,\n\t              note=None,\n\t              user=None,\n\t              echo=False,\n\t              group=None,\n\t              loglevel=logging.INFO,\n\t              encoding=None):\n\t\t\"\"\"Sends the passed-in string as a file to the passed-in path on the\n\t\ttarget.\n\n\t\t@param path:        Target location of file on target.\n\t\t@param contents:    Contents of file as a string.\n\t\t@param shutit_pexpect_child:       See send()\n\t\t@param note:        See send()\n\t\t@param user:        Set ownership to this user (defaults to whoami)\n\t\t@param group:       Set group to this user (defaults to first group in groups)\n\n\t\t@type path:         string\n\t\t@type contents:     string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.send_file(path,\n\t\t                                        contents,\n\t\t                                        truncate=truncate,\n\t\t                                        note=note,\n\t\t                                        echo=echo,\n\t\t                                        user=user,\n\t\t                                        group=group,\n\t\t                                        loglevel=loglevel,\n\t\t                                        encoding=encoding)", "response": "Sends the passed - in string as a file to the passed - in path on the target."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the directory of a file.", "response": "def chdir(self,\n\t          path,\n\t          shutit_pexpect_child=None,\n\t          timeout=shutit_global.shutit_global_object.default_timeout,\n\t          note=None,\n\t          loglevel=logging.DEBUG):\n\t\t\"\"\"How to change directory will depend on whether we are in delivery mode bash or docker.\n\n\t\t@param path:          Path to send file to.\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param timeout:       Timeout on response\n\t\t@param note:          See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.chdir(path,timeout=timeout,note=note,loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a file from host machine to given path.", "response": "def send_host_file(self,\n\t                   path,\n\t                   hostfilepath,\n\t                   expect=None,\n\t                   shutit_pexpect_child=None,\n\t                   note=None,\n\t                   user=None,\n\t                   group=None,\n\t                   loglevel=logging.INFO):\n\t\t\"\"\"Send file from host machine to given path\n\n\t\t@param path:          Path to send file to.\n\t\t@param hostfilepath:  Path to file from host to send to target.\n\t\t@param expect:        See send()\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param note:          See send()\n\t\t@param user:          Set ownership to this user (defaults to whoami)\n\t\t@param group:         Set group to this user (defaults to first group in groups)\n\n\t\t@type path:           string\n\t\t@type hostfilepath:   string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\texpect = expect or self.get_current_shutit_pexpect_session().default_expect\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tself.handle_note(note, 'Sending file from host: ' + hostfilepath + ' to target path: ' + path)\n\t\tself.log('Sending file from host: ' + hostfilepath + ' to: ' + path, level=loglevel)\n\t\tif user is None:\n\t\t\tuser = shutit_pexpect_session.whoami()\n\t\tif group is None:\n\t\t\tgroup = self.whoarewe()\n\t\t# TODO: use gz for both\n\t\tif os.path.isfile(hostfilepath):\n\t\t\tshutit_pexpect_session.send_file(path,\n\t\t\t                                 codecs.open(hostfilepath,mode='rb',encoding='iso-8859-1').read(),\n\t\t\t                                 user=user,\n\t\t\t                                 group=group,\n\t\t\t                                 loglevel=loglevel,\n\t\t\t                                 encoding='iso-8859-1')\n\t\telif os.path.isdir(hostfilepath):\n\t\t\t# Need a binary type encoding for gzip(?)\n\t\t\tself.send_host_dir(path,\n\t\t\t                   hostfilepath,\n\t\t\t                   user=user,\n\t\t\t                   group=group,\n\t\t\t                   loglevel=loglevel)\n\t\telse:\n\t\t\tself.fail('send_host_file - file: ' + hostfilepath + ' does not exist as file or dir. cwd is: ' + os.getcwd(), shutit_pexpect_child=shutit_pexpect_child, throw_exception=False) # pragma: no cover\n\t\tself.handle_note_after(note=note)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_host_dir(self,\n\t                  path,\n\t                  hostfilepath,\n\t                  expect=None,\n\t                  shutit_pexpect_child=None,\n\t                  note=None,\n\t                  user=None,\n\t                  group=None,\n\t                  loglevel=logging.DEBUG):\n\t\t\"\"\"Send directory and all contents recursively from host machine to\n\t\tgiven path.  It will automatically make directories on the target.\n\n\t\t@param path:          Path to send directory to (places hostfilepath inside path as a subfolder)\n\t\t@param hostfilepath:  Path to file from host to send to target\n\t\t@param expect:        See send()\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param note:          See send()\n\t\t@param user:          Set ownership to this user (defaults to whoami)\n\t\t@param group:         Set group to this user (defaults to first group in groups)\n\n\t\t@type path:          string\n\t\t@type hostfilepath:  string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\texpect = expect or self.get_current_shutit_pexpect_session().default_expect\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tself.handle_note(note, 'Sending host directory: ' + hostfilepath + ' to target path: ' + path)\n\t\tself.log('Sending host directory: ' + hostfilepath + ' to: ' + path, level=logging.INFO)\n\t\tshutit_pexpect_session.send(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                           send=' command mkdir -p ' + path,\n\t\t                                           echo=False,\n\t\t                                           loglevel=loglevel))\n\t\tif user is None:\n\t\t\tuser = shutit_pexpect_session.whoami()\n\t\tif group is None:\n\t\t\tgroup = self.whoarewe()\n\t\t# Create gzip of folder\n\t\t#import pdb\n\t\t#pdb.set_trace()\n\t\tif shutit_pexpect_session.command_available('tar'):\n\t\t\tgzipfname = '/tmp/shutit_tar_tmp.tar.gz'\n\t\t\twith tarfile.open(gzipfname, 'w:gz') as tar:\n\t\t\t\ttar.add(hostfilepath, arcname=os.path.basename(hostfilepath))\n\t\t\tshutit_pexpect_session.send_file(gzipfname,\n\t\t\t                                 codecs.open(gzipfname,mode='rb',encoding='iso-8859-1').read(),\n\t\t\t                                 user=user,\n\t\t\t                                 group=group,\n\t\t\t                                 loglevel=loglevel,\n\t\t\t                                 encoding='iso-8859-1')\n\t\t\tshutit_pexpect_session.send(ShutItSendSpec(shutit_pexpect_session,\n\t\t\t                                           send=' command mkdir -p ' + path + ' && command tar -C ' + path + ' -zxf ' + gzipfname))\n\t\telse:\n\t\t\t# If no gunzip, fall back to old slow method.\n\t\t\tfor root, subfolders, files in os.walk(hostfilepath):\n\t\t\t\tsubfolders.sort()\n\t\t\t\tfiles.sort()\n\t\t\t\tfor subfolder in subfolders:\n\t\t\t\t\tshutit_pexpect_session.send(ShutItSendSpec(shutit_pexpect_session,\n\t\t\t\t\t                                           send=' command mkdir -p ' + path + '/' + subfolder,\n\t\t\t\t\t                                           echo=False,\n\t\t\t\t\t                                           loglevel=loglevel))\n\t\t\t\t\tself.log('send_host_dir recursing to: ' + hostfilepath + '/' + subfolder, level=logging.DEBUG)\n\t\t\t\t\tself.send_host_dir(path + '/' + subfolder,\n\t\t\t\t\t                   hostfilepath + '/' + subfolder,\n\t\t\t\t\t                   expect=expect,\n\t\t\t\t\t                   shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t\t\t                   loglevel=loglevel)\n\t\t\t\tfor fname in files:\n\t\t\t\t\thostfullfname = os.path.join(root, fname)\n\t\t\t\t\ttargetfname = os.path.join(path, fname)\n\t\t\t\t\tself.log('send_host_dir sending file ' + hostfullfname + ' to ' + 'target file: ' + targetfname, level=logging.DEBUG)\n\t\t\t\t\tshutit_pexpect_session.send_file(targetfname,\n\t\t\t\t\t                                 codecs.open(hostfullfname,mode='rb',encoding='iso-8859-1').read(),\n\t\t\t\t\t                                 user=user,\n\t\t\t\t\t                                 group=group,\n\t\t\t\t\t                                 loglevel=loglevel,\n\t\t\t\t\t                                 encoding='iso-8859-1')\n\t\tself.handle_note_after(note=note)\n\t\treturn True", "response": "Send a directory and all contents recursively from host machine to target path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_exists(self,\n\t                filename,\n\t                shutit_pexpect_child=None,\n\t                directory=False,\n\t                note=None,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Return True if file exists on the target host, else False\n\n\t\t@param filename:   Filename to determine the existence of.\n\t\t@param shutit_pexpect_child:      See send()\n\t\t@param directory:  Indicate that the file is a directory.\n\t\t@param note:       See send()\n\n\t\t@type filename:    string\n\t\t@type directory:   boolean\n\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.file_exists(filename=filename,directory=directory,note=note,loglevel=loglevel)", "response": "Returns True if the file exists on the target host else False."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_line_from_file(self,\n\t                          line,\n\t                          filename,\n\t                          shutit_pexpect_child=None,\n\t                          match_regexp=None,\n\t                          literal=False,\n\t                          note=None,\n\t                          loglevel=logging.DEBUG):\n\t\t\"\"\"Removes line from file, if it exists.\n\t\tMust be exactly the line passed in to match.\n\t\tReturns True if there were no problems, False if there were.\n\n\t\t@param line:          Line to remove.\n\t\t@param filename       Filename to remove it from.\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param match_regexp:  If supplied, a regexp to look for in the file\n\t\t                      instead of the line itself,\n\t\t                      handy if the line has awkward characters in it.\n\t\t@param literal:       If true, then simply grep for the exact string without\n\t\t                      bash interpretation. (Default: False)\n\t\t@param note:          See send()\n\n\t\t@type line:           string\n\t\t@type filename:       string\n\t\t@type match_regexp:   string\n\t\t@type literal:        boolean\n\n\t\t@return:              True if the line was matched and deleted, False otherwise.\n\t\t@rtype:               boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.remove_line_from_file(line,filename,match_regexp=match_regexp,literal=literal,note=note,loglevel=loglevel)", "response": "Removes a line from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the text in a file.", "response": "def change_text(self,\n\t                text,\n\t                fname,\n\t                pattern=None,\n\t                expect=None,\n\t                shutit_pexpect_child=None,\n\t                before=False,\n\t                force=False,\n\t                delete=False,\n\t                note=None,\n\t                replace=False,\n\t                line_oriented=True,\n\t                create=True,\n\t                loglevel=logging.DEBUG):\n\n\t\t\"\"\"Change text in a file.\n\n\t\tReturns None if there was no match for the regexp, True if it was matched\n\t\tand replaced, and False if the file did not exist or there was some other\n\t\tproblem.\n\n\t\t@param text:          Text to insert.\n\t\t@param fname:         Filename to insert text to\n\t\t@param pattern:       Regexp for a line to match and insert after/before/replace.\n\t\t                      If none, put at end of file.\n\t\t@param expect:        See send()\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param before:        Whether to place the text before or after the matched text.\n\t\t@param force:         Force the insertion even if the text is in the file.\n\t\t@param delete:        Delete text from file rather than insert\n\t\t@param replace:       Replace matched text with passed-in text. If nothing matches, then append.\n\t\t@param note:          See send()\n\t\t@param line_oriented: Consider the pattern on a per-line basis (default True).\n\t\t                      Can match any continuous section of the line, eg 'b.*d' will match the line: 'abcde'\n\t\t                      If not line_oriented, the regexp is considered on with the flags re.DOTALL, re.MULTILINE\n\t\t                      enabled\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\texpect = expect or self.get_current_shutit_pexpect_session().default_expect\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.change_text(text,\n\t\t                                          fname,\n\t\t                                          pattern=pattern,\n\t\t                                          before=before,\n\t\t                                          force=force,\n\t\t                                          delete=delete,\n\t\t                                          note=note,\n\t\t                                          replace=replace,\n\t\t                                          line_oriented=line_oriented,\n\t\t                                          create=create,\n\t\t                                          loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting a chunk of text into a file.", "response": "def insert_text(self,\n\t                text,\n\t                fname,\n\t                pattern=None,\n\t                expect=None,\n\t                shutit_pexpect_child=None,\n\t                before=False,\n\t                force=False,\n\t                note=None,\n\t                replace=False,\n\t                line_oriented=True,\n\t                create=True,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Insert a chunk of text at the end of a file, or after (or before) the first matching pattern\n\t\tin given file fname.\n\t\tSee change_text\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\treturn self.change_text(text=text,\n\t\t                        fname=fname,\n\t\t                        pattern=pattern,\n\t\t                        expect=expect,\n\t\t                        shutit_pexpect_child=shutit_pexpect_child,\n\t\t                        before=before,\n\t\t                        force=force,\n\t\t                        note=note,\n\t\t                        line_oriented=line_oriented,\n\t\t                        create=create,\n\t\t                        replace=replace,\n\t\t                        delete=False,\n\t\t                        loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_text(self,\n\t                text,\n\t                fname,\n\t                pattern=None,\n\t                expect=None,\n\t                shutit_pexpect_child=None,\n\t                note=None,\n\t                before=False,\n\t                force=False,\n\t                line_oriented=True,\n\t                loglevel=logging.DEBUG):\n\t\t\"\"\"Delete a chunk of text from a file.\n\t\tSee insert_text.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\treturn self.change_text(text,\n\t\t                        fname,\n\t\t                        pattern,\n\t\t                        expect,\n\t\t                        shutit_pexpect_child,\n\t\t                        before,\n\t\t                        force,\n\t\t                        note=note,\n\t\t                        delete=True,\n\t\t                        line_oriented=line_oriented,\n\t\t                        loglevel=loglevel)", "response": "Delete a chunk of text from a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_line_to_file(self, line, filename, expect=None, shutit_pexpect_child=None, match_regexp=None, loglevel=logging.DEBUG):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif isinstance(line, str):\n\t\t\tlines = [line]\n\t\telif isinstance(line, list):\n\t\t\tlines = line\n\t\t\tmatch_regexp = None\n\t\tfail = False\n\t\tfor fline in lines:\n\t\t\tif match_regexp is None:\n\t\t\t\tthis_match_regexp = fline\n\t\t\telse:\n\t\t\t\tthis_match_regexp = match_regexp\n\t\t\tif not self.replace_text(fline,\n\t\t\t                         filename,\n\t\t\t                         pattern=this_match_regexp,\n\t\t\t                         shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t                         expect=expect,\n\t\t\t                         loglevel=loglevel):\n\t\t\t\tfail = True\n\t\tif fail:\n\t\t\treturn False\n\t\treturn True", "response": "Deprecated. Use replace_text instead."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a line to the bashrc.", "response": "def add_to_bashrc(self, line, shutit_pexpect_child=None, match_regexp=None, note=None, loglevel=logging.DEBUG):\n\t\t\"\"\"Takes care of adding a line to everyone's bashrc\n\t\t(/etc/bash.bashrc, /etc/profile).\n\n\t\t@param line:          Line to add.\n\t\t@param shutit_pexpect_child:         See send()\n\t\t@param match_regexp:  See add_line_to_file()\n\t\t@param note:          See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tshutit_pexpect_session.add_to_bashrc(line,match_regexp=match_regexp,note=note,loglevel=loglevel)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget url for a file.", "response": "def get_url(self,\n\t            filename,\n\t            locations,\n\t            command='curl',\n\t            shutit_pexpect_child=None,\n\t            timeout=shutit_global.shutit_global_object.default_timeout,\n\t            fail_on_empty_before=True,\n\t            record_command=True,\n\t            exit_values=None,\n\t            retry=3,\n\t            note=None,\n\t            loglevel=logging.DEBUG):\n\t\t\"\"\"Handles the getting of a url for you.\n\n\t\tExample:\n\t\tget_url('somejar.jar', ['ftp://loc.org','http://anotherloc.com/jars'])\n\n\t\t@param filename:             name of the file to download\n\t\t@param locations:            list of URLs whence the file can be downloaded\n\t\t@param command:              program to use to download the file (Default: wget)\n\t\t@param shutit_pexpect_child:                See send()\n\t\t@param timeout:              See send()\n\t\t@param fail_on_empty_before: See send()\n\t\t@param record_command:       See send()\n\t\t@param exit_values:          See send()\n\t\t@param retry:                How many times to retry the download\n\t\t                             in case of failure. Default: 3\n\t\t@param note:                 See send()\n\n\t\t@type filename:              string\n\t\t@type locations:             list of strings\n\t\t@type retry:                 integer\n\n\t\t@return: True if the download was completed successfully, False otherwise.\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.get_url(filename,\n\t\t                                      locations,\n\t\t                                      send=command,\n\t\t                                      timeout=timeout,\n\t\t                                      fail_on_empty_before=fail_on_empty_before,\n\t\t                                      record_command=record_command,\n\t\t                                      exit_values=exit_values,\n\t\t                                      retry=retry,\n\t\t                                      note=note,\n\t\t                                      loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef package_installed(self,\n\t                      package,\n\t                      shutit_pexpect_child=None,\n\t                      note=None,\n\t                      loglevel=logging.DEBUG):\n\t\t\"\"\"Returns True if we can be sure the package is installed.\n\n\t\t@param package:   Package as a string, eg 'wget'.\n\t\t@param shutit_pexpect_child:     See send()\n\t\t@param note:      See send()\n\n\t\t@rtype:           boolean\n\t\t\"\"\"\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session(package,note=note,loglevel=loglevel)", "response": "Returns True if we can be sure the package is installed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the shutit has already been installed.", "response": "def is_shutit_installed(self,\n\t                        module_id,\n\t                        note=None,\n\t                        loglevel=logging.DEBUG):\n\t\t\"\"\"Helper proc to determine whether shutit has installed already here by placing a file in the db.\n\n\t\t@param module_id: Identifying string of shutit module\n\t\t@param note:      See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_session = self.get_current_shutit_pexpect_session()\n\t\treturn shutit_pexpect_session.is_shutit_installed(module_id,note=note,loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ls(self,\n\t       directory,\n\t       note=None,\n\t       loglevel=logging.DEBUG):\n\t\t\"\"\"Helper proc to list files in a directory\n\n\t\t@param directory:   directory to list.  If the directory doesn't exist, shutit.fail() is called (i.e.  the build fails.)\n\t\t@param note:        See send()\n\n\t\t@type directory:    string\n\n\t\t@rtype:             list of strings\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_session = self.get_current_shutit_pexpect_session()\n\t\treturn shutit_pexpect_session.is_shutit_installed(directory,note=note,loglevel=loglevel)", "response": "Helper function to list files in a directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies a file from the target machine to the host machine.", "response": "def get_file(self,\n\t             target_path,\n\t             host_path,\n\t             note=None,\n\t             loglevel=logging.DEBUG):\n\t\t\"\"\"Copy a file from the target machine to the host machine\n\n\t\t@param target_path: path to file in the target\n\t\t@param host_path:   path to file on the host machine (e.g. copy test)\n\t\t@param note:        See send()\n\n\t\t@type target_path: string\n\t\t@type host_path:   string\n\n\t\t@return:           boolean\n\t\t@rtype:            string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.handle_note(note)\n\t\t# Only handle for docker initially, return false in case we care\n\t\tif self.build['delivery'] != 'docker':\n\t\t\treturn False\n\t\t# on the host, run:\n\t\t#Usage:  docker cp [OPTIONS] CONTAINER:PATH LOCALPATH|-\n\t\t# Need: host env, container id, path from and path to\n\t\tshutit_pexpect_child     = self.get_shutit_pexpect_session_from_id('host_child').pexpect_child\n\t\texpect    = self.expect_prompts['ORIGIN_ENV']\n\t\tself.send('docker cp ' + self.target['container_id'] + ':' + target_path + ' ' + host_path,\n\t\t          shutit_pexpect_child=shutit_pexpect_child,\n\t\t          expect=expect,\n\t\t          check_exit=False,\n\t\t          echo=False,\n\t\t          loglevel=loglevel)\n\t\tself.handle_note_after(note=note)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprompts user for a value in a section of config.", "response": "def prompt_cfg(self, msg, sec, name, ispass=False):\n\t\t\"\"\"Prompt for a config value, optionally saving it to the user-level\n\t\tcfg. Only runs if we are in an interactive mode.\n\n\t\t@param msg:    Message to display to user.\n\t\t@param sec:    Section of config to add to.\n\t\t@param name:   Config item name.\n\t\t@param ispass: If True, hide the input from the terminal.\n\t\t               Default: False.\n\n\t\t@type msg:     string\n\t\t@type sec:     string\n\t\t@type name:    string\n\t\t@type ispass:  boolean\n\n\t\t@return: the value entered by the user\n\t\t@rtype:  string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfgstr        = '[%s]/%s' % (sec, name)\n\t\tconfig_parser = self.config_parser\n\t\tusercfg       = os.path.join(self.host['shutit_path'], 'config')\n\n\t\tself.log('\\nPROMPTING FOR CONFIG: %s' % (cfgstr,),transient=True,level=logging.INFO)\n\t\tself.log('\\n' + msg + '\\n',transient=True,level=logging.INFO)\n\n\t\tif not shutit_global.shutit_global_object.determine_interactive():\n\t\t\tself.fail('ShutIt is not in a terminal so cannot prompt for values.', throw_exception=False) # pragma: no cover\n\n\t\tif config_parser.has_option(sec, name):\n\t\t\twhereset = config_parser.whereset(sec, name)\n\t\t\tif usercfg == whereset:\n\t\t\t\tself.fail(cfgstr + ' has already been set in the user config, edit ' + usercfg + ' directly to change it', throw_exception=False) # pragma: no cover\n\t\t\tfor subcp, filename, _ in reversed(config_parser.layers):\n\t\t\t\t# Is the config file loaded after the user config file?\n\t\t\t\tif filename == whereset:\n\t\t\t\t\tself.fail(cfgstr + ' is being set in ' + filename + ', unable to override on a user config level', throw_exception=False) # pragma: no cover\n\t\t\t\telif filename == usercfg:\n\t\t\t\t\tbreak\n\t\telse:\n\t\t\t# The item is not currently set so we're fine to do so\n\t\t\tpass\n\t\tif ispass:\n\t\t\tval = getpass.getpass('>> ')\n\t\telse:\n\t\t\tval = shutit_util.util_raw_input(prompt='>> ')\n\t\tis_excluded = (\n\t\t\tconfig_parser.has_option('save_exclude', sec) and\n\t\t\tname in config_parser.get('save_exclude', sec).split()\n\t\t)\n\t\t# TODO: ideally we would remember the prompted config item for this invocation of shutit\n\t\tif not is_excluded:\n\t\t\tusercp = [\n\t\t\t\tsubcp for subcp, filename, _ in config_parser.layers\n\t\t\t\tif filename == usercfg\n\t\t\t][0]\n\t\t\tif shutit_util.util_raw_input(prompt=shutit_util.colorise('32', 'Do you want to save this to your user settings? y/n: '),default='y') == 'y':\n\t\t\t\tsec_toset, name_toset, val_toset = sec, name, val\n\t\t\telse:\n\t\t\t\t# Never save it\n\t\t\t\tif config_parser.has_option('save_exclude', sec):\n\t\t\t\t\texcluded = config_parser.get('save_exclude', sec).split()\n\t\t\t\telse:\n\t\t\t\t\texcluded = []\n\t\t\t\texcluded.append(name)\n\t\t\t\texcluded = ' '.join(excluded)\n\t\t\t\tsec_toset, name_toset, val_toset = 'save_exclude', sec, excluded\n\t\t\tif not usercp.has_section(sec_toset):\n\t\t\t\tusercp.add_section(sec_toset)\n\t\t\tusercp.set(sec_toset, name_toset, val_toset)\n\t\t\tusercp.write(open(usercfg, 'w'))\n\t\t\tconfig_parser.reload()\n\t\treturn val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step_through(self, msg='', shutit_pexpect_child=None, level=1, print_input=True, value=True):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tif (not shutit_global.shutit_global_object.determine_interactive() or not shutit_global.shutit_global_object.interactive or\n\t\t\tshutit_global.shutit_global_object.interactive < level):\n\t\t\treturn True\n\t\tself.build['step_through'] = value\n\t\tshutit_pexpect_session.pause_point(msg, print_input=print_input, level=level)\n\t\treturn True", "response": "Implements a step - through function using pause_point."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pause_point(self,\n\t                msg='SHUTIT PAUSE POINT',\n\t                shutit_pexpect_child=None,\n\t                print_input=True,\n\t                level=1,\n\t                resize=True,\n\t                color='32',\n\t                default_msg=None,\n\t                interact=False,\n\t                wait=-1):\n\t\t\"\"\"Inserts a pause in the build session, which allows the user to try\n\t\tthings out before continuing. Ignored if we are not in an interactive\n\t\tmode, or the interactive level is less than the passed-in one.\n\t\tDesigned to help debug the build, or drop to on failure so the\n\t\tsituation can be debugged.\n\n\t\t@param msg:          Message to display to user on pause point.\n\t\t@param shutit_pexpect_child:        See send()\n\t\t@param print_input:  Whether to take input at this point (i.e. interact), or\n\t\t                     simply pause pending any input.\n\t\t                     Default: True\n\t\t@param level:        Minimum level to invoke the pause_point at.\n\t\t                     Default: 1\n\t\t@param resize:       If True, try to resize terminal.\n\t\t                     Default: False\n\t\t@param color:        Color to print message (typically 31 for red, 32 for green)\n\t\t@param default_msg:  Whether to print the standard blurb\n\t\t@param wait:         Wait a few seconds rather than for input\n\n\t\t@type msg:           string\n\t\t@type print_input:   boolean\n\t\t@type level:         integer\n\t\t@type resize:        boolean\n\t\t@type wait:          decimal\n\n\t\t@return:             True if pause point handled ok, else false\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif (not shutit_global.shutit_global_object.determine_interactive() or shutit_global.shutit_global_object.interactive < 1 or\n\t\t\tshutit_global.shutit_global_object.interactive < level):\n\t\t\treturn True\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\t# Don't log log traces while in interactive\n\t\tlog_trace_when_idle_original_value = shutit_global.shutit_global_object.log_trace_when_idle\n\t\tshutit_global.shutit_global_object.log_trace_when_idle = False\n\t\tif shutit_pexpect_child:\n\t\t\tif shutit_global.shutit_global_object.pane_manager is not None:\n\t\t\t\tshutit_global.shutit_global_object.pane_manager.draw_screen(draw_type='clearscreen')\n\t\t\t\tshutit_global.shutit_global_object.pane_manager.do_render = False\n\t\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\t\t# TODO: context added to pause point message\n\t\t\tshutit_pexpect_session.pause_point(msg=msg,\n\t\t\t                                   print_input=print_input,\n\t\t\t                                   resize=resize,\n\t\t\t                                   color=color,\n\t\t\t                                   default_msg=default_msg,\n\t\t\t                                   wait=wait,\n\t\t\t                                   interact=interact)\n\t\telse:\n\t\t\tself.log(msg,level=logging.DEBUG)\n\t\t\tself.log('Nothing to interact with, so quitting to presumably the original shell',level=logging.DEBUG)\n\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\tif shutit_pexpect_child:\n\t\t\tif shutit_global.shutit_global_object.pane_manager is not None:\n\t\t\t\tshutit_global.shutit_global_object.pane_manager.do_render = True\n\t\t\t\tshutit_global.shutit_global_object.pane_manager.draw_screen(draw_type='clearscreen')\n\t\tself.build['ctrlc_stop'] = False\n\t\t# Revert value of log_trace_when_idle\n\t\tshutit_global.shutit_global_object.log_trace_when_idle = log_trace_when_idle_original_value\n\t\treturn True", "response": "This method is used to pause a build session at a specific level."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if the output of the command matches any of the strings in and matches list of regexp strings.", "response": "def send_and_match_output(self,\n\t                          send,\n\t                          matches,\n\t                          shutit_pexpect_child=None,\n\t                          retry=3,\n\t                          strip=True,\n\t                          note=None,\n\t                          echo=None,\n\t                          loglevel=logging.DEBUG):\n\t\t\"\"\"Returns true if the output of the command matches any of the strings in\n\t\tthe matches list of regexp strings. Handles matching on a per-line basis\n\t\tand does not cross lines.\n\n\t\t@param send:     See send()\n\t\t@param matches:  String - or list of strings - of regexp(s) to check\n\t\t@param shutit_pexpect_child:    See send()\n\t\t@param retry:    Number of times to retry command (default 3)\n\t\t@param strip:    Whether to strip output (defaults to True)\n\t\t@param note:     See send()\n\n\t\t@type send:      string\n\t\t@type matches:   list\n\t\t@type retry:     integer\n\t\t@type strip:     boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.send_and_match_output(send,\n\t\t                                                    matches,\n\t\t                                                    retry=retry,\n\t\t                                                    strip=strip,\n\t\t                                                    note=note,\n\t\t                                                    echo=echo,\n\t\t                                                    loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_and_get_output(self,\n\t                        send,\n\t                        shutit_pexpect_child=None,\n\t                        timeout=None,\n\t                        retry=3,\n\t                        strip=True,\n\t                        preserve_newline=False,\n\t                        note=None,\n\t                        record_command=False,\n\t                        echo=None,\n\t                        fail_on_empty_before=True,\n\t                        nonewline=False,\n\t                        wait=False,\n\t                        loglevel=logging.INFO):\n\t\t\"\"\"Returns the output of a command run. send() is called, and exit is not checked.\n\n\t\t@param send:     See send()\n\t\t@param shutit_pexpect_child:    See send()\n\t\t@param retry:    Number of times to retry command (default 3)\n\t\t@param strip:    Whether to strip output (defaults to True). Strips whitespace\n\t\t                 and ansi terminal codes\n\t\t@param note:     See send()\n\t\t@param echo:     See send()\n\n\t\t@type retry:     integer\n\t\t@type strip:     boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tignore_background = not wait\n\t\treturn shutit_pexpect_session.send_and_get_output(send,\n\t\t                                                  timeout=timeout,\n\t\t                                                  retry=retry,\n\t\t                                                  strip=strip,\n\t\t                                                  preserve_newline=preserve_newline,\n\t\t                                                  note=note,\n\t\t                                                  record_command=record_command,\n\t\t                                                  echo=echo,\n\t\t                                                  fail_on_empty_before=fail_on_empty_before,\n\t\t                                                  nonewline=nonewline,\n\t\t                                                  ignore_background=ignore_background,\n\t\t                                                  loglevel=loglevel)", "response": "Send and get the output of a command run."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls a package from the given pexpect child.", "response": "def install(self,\n\t            package,\n\t            shutit_pexpect_child=None,\n\t            options=None,\n\t            timeout=shutit_global.shutit_global_object.default_timeout,\n\t            force=False,\n\t            check_exit=True,\n\t            echo=None,\n\t            reinstall=False,\n\t            background=False,\n\t            wait=False,\n\t            block_other_commands=True,\n\t            note=None,\n\t            loglevel=logging.INFO):\n\t\t\"\"\"Distro-independent install function.\n\t\tTakes a package name and runs the relevant install function.\n\n\t\t@param package:    Package to install, which is run through package_map\n\t\t@param shutit_pexpect_child:      See send()\n\t\t@param timeout:    Timeout (s) to wait for finish of install. Defaults to 3600.\n\t\t@param options:    Dictionary for specific options per install tool.\n\t\t                   Overrides any arguments passed into this function.\n\t\t@param force:      Force if necessary. Defaults to False\n\t\t@param check_exit: If False, failure to install is ok (default True)\n\t\t@param reinstall:  Advise a reinstall where possible (default False)\n\t\t@param note:       See send()\n\n\t\t@type package:     string\n\t\t@type timeout:     integer\n\t\t@type options:     dict\n\t\t@type force:       boolean\n\t\t@type check_exit:  boolean\n\t\t@type reinstall:   boolean\n\n\t\t@return: True if all ok (ie it's installed), else False.\n\t\t@rtype: boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# If separated by spaces, install separately\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\tignore_background = not wait\n\t\treturn shutit_pexpect_session.install(package,\n\t\t                                      options=options,\n\t\t                                      timeout=timeout,\n\t\t                                      force=force,\n\t\t                                      check_exit=check_exit,\n\t\t                                      reinstall=reinstall,\n\t\t                                      echo=echo,\n\t\t                                      note=note,\n\t\t                                      run_in_background=background,\n\t\t                                      ignore_background=ignore_background,\n\t\t                                      block_other_commands=block_other_commands,\n\t\t                                      loglevel=loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a password from the user if one is not already recorded for this environment.", "response": "def get_env_pass(self,\n\t                 user=None,\n\t                 msg=None,\n\t                 shutit_pexpect_child=None,\n\t                 note=None):\n\t\t\"\"\"Gets a password from the user if one is not already recorded for this environment.\n\n\t\t@param user:    username we are getting password for\n\t\t@param msg:     message to put out there\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.get_env_pass(user=user,\n\t\t                                           msg=msg,\n\t\t                                           note=note)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef whoarewe(self,\n\t             shutit_pexpect_child=None,\n\t             note=None,\n\t             loglevel=logging.DEBUG):\n\t\t\"\"\"Returns the current group.\n\n\t\t@param shutit_pexpect_child:    See send()\n\t\t@param note:     See send()\n\n\t\t@return: the first group found\n\t\t@rtype: string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.whoarewe(note=note,\n\t\t                                       loglevel=loglevel)", "response": "Returns the current group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging user in on default child.", "response": "def login(self,\n\t          command='su -',\n\t          user=None,\n\t          password=None,\n\t          prompt_prefix=None,\n\t          expect=None,\n\t          timeout=shutit_global.shutit_global_object.default_timeout,\n\t          escape=False,\n\t          echo=None,\n\t          note=None,\n\t          go_home=True,\n\t          fail_on_fail=True,\n\t          is_ssh=True,\n\t          check_sudo=True,\n\t          loglevel=logging.DEBUG):\n\t\t\"\"\"Logs user in on default child.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_session = self.get_current_shutit_pexpect_session()\n\t\treturn shutit_pexpect_session.login(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                                   user=user,\n\t\t                                                   send=command,\n\t\t                                                   password=password,\n\t\t                                                   prompt_prefix=prompt_prefix,\n\t\t                                                   expect=expect,\n\t\t                                                   timeout=timeout,\n\t\t                                                   escape=escape,\n\t\t                                                   echo=echo,\n\t\t                                                   note=note,\n\t\t                                                   go_home=go_home,\n\t\t                                                   fail_on_fail=fail_on_fail,\n\t\t                                                   is_ssh=is_ssh,\n\t\t                                                   check_sudo=check_sudo,\n\t\t                                                   loglevel=loglevel))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logout_all(self,\n\t               command='exit',\n\t               note=None,\n\t               echo=None,\n\t               timeout=shutit_global.shutit_global_object.default_timeout,\n\t               nonewline=False,\n\t               loglevel=logging.DEBUG):\n\t\t\"\"\"Logs the user out of all pexpect sessions within this ShutIt object.\n\n\t\t\t@param command:         Command to run to log out (default=exit)\n\t\t\t@param note:            See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tfor key in self.shutit_pexpect_sessions:\n\t\t\tshutit_pexpect_session = self.shutit_pexpect_sessions[key]\n\t\t\tshutit_pexpect_session.logout_all(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                                     send=command,\n\t\t                                                     note=note,\n\t\t                                                     timeout=timeout,\n\t\t                                                     nonewline=nonewline,\n\t\t                                                     loglevel=loglevel,\n\t\t                                                     echo=echo))\n\t\treturn True", "response": "Logs the user out of all pexpect sessions within this ShutIt object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog the user out.", "response": "def logout(self,\n\t           command='exit',\n\t           note=None,\n\t           echo=None,\n\t           timeout=shutit_global.shutit_global_object.default_timeout,\n\t           nonewline=False,\n\t           loglevel=logging.DEBUG):\n\t\t\"\"\"Logs the user out. Assumes that login has been called.\n\t\tIf login has never been called, throw an error.\n\n\t\t\t@param command:         Command to run to log out (default=exit)\n\t\t\t@param note:            See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_session = self.get_current_shutit_pexpect_session()\n\t\treturn shutit_pexpect_session.logout(ShutItSendSpec(shutit_pexpect_session,\n\t\t                                                    send=command,\n\t\t                                                    note=note,\n\t\t                                                    timeout=timeout,\n\t\t                                                    nonewline=nonewline,\n\t\t                                                    loglevel=loglevel,\n\t\t                                                    echo=echo))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_memory(self,\n\t               shutit_pexpect_child=None,\n\t               note=None):\n\t\t\"\"\"Returns memory available for use in k as an int\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.get_memory(note=note)", "response": "Returns the number of memory available for use in k as an int"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the password for the current user or passed - in user.", "response": "def set_password(self,\n\t                 password,\n\t                 user='',\n\t                 shutit_pexpect_child=None,\n\t                 note=None):\n\t\t\"\"\"Sets the password for the current user or passed-in user.\n\n\t\tAs a side effect, installs the \"password\" package.\n\n\t\t@param user:        username to set the password for. Defaults to '' (i.e. current user)\n\t\t@param password:    password to set for the user\n\t\t@param shutit_pexpect_child:       See send()\n\t\t@param note:        See send()\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_current_shutit_pexpect_session().pexpect_child\n\t\tshutit_pexpect_session = self.get_shutit_pexpect_session_from_child(shutit_pexpect_child)\n\t\treturn shutit_pexpect_session.set_password(password,user=user,note=note)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes the given repository.", "response": "def push_repository(self,\n\t                    repository,\n\t                    docker_executable='docker',\n\t                    shutit_pexpect_child=None,\n\t                    expect=None,\n\t                    note=None,\n\t                    loglevel=logging.INFO):\n\t\t\"\"\"Pushes the repository.\n\n\t\t@param repository:          Repository to push.\n\t\t@param docker_executable:   Defaults to 'docker'\n\t\t@param expect:              See send()\n\t\t@param shutit_pexpect_child:               See send()\n\n\t\t@type repository:           string\n\t\t@type docker_executable:    string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.handle_note(note)\n\t\tshutit_pexpect_child = shutit_pexpect_child or self.get_shutit_pexpect_session_from_id('host_child').pexpect_child\n\t\texpect               = expect or self.expect_prompts['ORIGIN_ENV']\n\t\tsend                 = docker_executable + ' push ' + self.repository['user'] + '/' + repository\n\t\ttimeout              = 99999\n\t\tself.log('Running: ' + send,level=logging.INFO)\n\t\tself.multisend(docker_executable + ' login',\n\t\t               {'Username':self.repository['user'], 'Password':self.repository['password'], 'Email':self.repository['email']},\n\t\t               shutit_pexpect_child=shutit_pexpect_child,\n\t\t               expect=expect)\n\t\tself.send(send,\n\t\t          shutit_pexpect_child=shutit_pexpect_child,\n\t\t          expect=expect,\n\t\t          timeout=timeout,\n\t\t          check_exit=False,\n\t\t          fail_on_empty_before=False,\n\t\t          loglevel=loglevel)\n\t\tself.handle_note_after(note)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_repository_work(self,\n\t                       repo_name,\n\t                       repo_tag=None,\n\t                       docker_executable='docker',\n\t                       password=None,\n\t                       force=None,\n\t                       loglevel=logging.DEBUG,\n\t                       note=None,\n\t                       tag=None,\n\t                       push=None,\n\t                       export=None,\n\t                       save=None):\n\t\t\"\"\"Commit, tag, push, tar a docker container based on the configuration we have.\n\n\t\t@param repo_name:           Name of the repository.\n\t\t@param docker_executable:   Defaults to 'docker'\n\t\t@param password:\n\t\t@param force:\n\n\t\t@type repo_name:            string\n\t\t@type docker_executable:    string\n\t\t@type password:             string\n\t\t@type force:                boolean\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# TODO: make host and client configurable\n\t\tself.handle_note(note)\n\t\tshutit_pexpect_session = self.get_current_shutit_pexpect_session()\n\t\tif tag is None:\n\t\t\ttag    = self.repository['tag']\n\t\tif push is None:\n\t\t\tpush   = self.repository['push']\n\t\tif export is None:\n\t\t\texport = self.repository['export']\n\t\tif save is None:\n\t\t\tsave   = self.repository['save']\n\t\tif not (push or export or save or tag):\n\t\t\t# If we're forcing this, then tag as a minimum\n\t\t\tif force:\n\t\t\t\ttag = True\n\t\t\telse:\n\t\t\t\treturn True\n\n\t\tshutit_pexpect_child = self.get_shutit_pexpect_session_from_id('host_child').pexpect_child\n\t\texpect    = self.expect_prompts['ORIGIN_ENV']\n\t\tserver    = self.repository['server']\n\t\trepo_user = self.repository['user']\n\t\tif repo_tag is None:\n\t\t\trepo_tag  = self.repository['tag_name']\n\n\t\tif repo_user and repo_name:\n\t\t\trepository = '%s/%s' % (repo_user, repo_name)\n\t\t\trepository_tar = '%s%s' % (repo_user, repo_name)\n\t\telif repo_user:\n\t\t\trepository = repository_tar = repo_user\n\t\telif repo_name:\n\t\t\trepository = repository_tar = repo_name\n\t\telse:\n\t\t\trepository = repository_tar = ''\n\n\t\tif not repository:\n\t\t\tself.fail('Could not form valid repository name', shutit_pexpect_child=shutit_pexpect_child, throw_exception=False) # pragma: no cover\n\t\tif (export or save) and not repository_tar:\n\t\t\tself.fail('Could not form valid tar name', shutit_pexpect_child=shutit_pexpect_child, throw_exception=False) # pragma: no cover\n\n\t\tif server != '':\n\t\t\trepository = '%s/%s' % (server, repository)\n\n\t\tif self.build['deps_only']:\n\t\t\trepo_tag += '_deps'\n\n\t\tif self.repository['suffix_date']:\n\t\t\tsuffix_date = time.strftime(self.repository['suffix_format'])\n\t\t\trepository = '%s%s' % (repository, suffix_date)\n\t\t\trepository_tar = '%s%s' % (repository_tar, suffix_date)\n\n\t\tif repository != '' and len(repository.split(':')) > 1:\n\t\t\trepository_with_tag = repository\n\t\t\trepo_tag = repository.split(':')[1]\n\t\telif repository != '':\n\t\t\trepository_with_tag = repository + ':' + repo_tag\n\n\t\t# Commit image\n\t\t# Only lower case accepted\n\t\trepository          = repository.lower()\n\t\trepository_with_tag = repository_with_tag.lower()\n\n\t\tif server == '' and len(repository) > 30 and push:\n\t\t\tself.fail(\"\"\"repository name: '\"\"\" + repository + \"\"\"' too long to push. If using suffix_date consider shortening, or consider adding \"-s repository push no\" to your arguments to prevent pushing.\"\"\", shutit_pexpect_child=shutit_pexpect_child, throw_exception=False) # pragma: no cover\n\n\t\tif self.send(docker_executable + ' commit ' + self.target['container_id'] + ' ' + repository_with_tag,\n\t\t             expect=[expect,' assword'],\n\t\t             shutit_pexpect_child=shutit_pexpect_child,\n\t\t             timeout=99999,\n\t\t             check_exit=False,\n\t\t             loglevel=loglevel) == 1:\n\t\t\tself.send(self.host['password'],\n\t\t\t          expect=expect,\n\t\t\t          check_exit=False,\n\t\t\t          record_command=False,\n\t\t\t          shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t          echo=False,\n\t\t\t          loglevel=loglevel)\n\t\t# Tag image, force it by default\n\t\tself.build['report'] += '\\nBuild tagged as: ' + repository_with_tag\n\t\tif export or save:\n\t\t\tshutit_pexpect_session.pause_point('We are now exporting the container to a bzipped tar file, as configured in\\n[repository]\\ntar:yes', print_input=False, level=3)\n\t\t\tif export:\n\t\t\t\tbzfile = (repository_tar + 'export.tar.bz2')\n\t\t\t\tself.log('Depositing bzip2 of exported container into ' + bzfile,level=logging.DEBUG)\n\t\t\t\tif self.send(docker_executable + ' export ' + self.target['container_id'] + ' | bzip2 - > ' + bzfile,\n\t\t\t\t             expect=[expect, 'assword'],\n\t\t\t\t             timeout=99999,\n\t\t\t\t             shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t\t             loglevel=loglevel) == 1:\n\t\t\t\t\tself.send(password,\n\t\t\t\t\t          expect=expect,\n\t\t\t\t\t          shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t\t\t          loglevel=loglevel)\n\t\t\t\tself.log('Deposited bzip2 of exported container into ' + bzfile, level=loglevel)\n\t\t\t\tself.log('Run: bunzip2 -c ' + bzfile + ' | sudo docker import - to get this imported into docker.', level=logging.DEBUG)\n\t\t\t\tself.build['report'] += ('\\nDeposited bzip2 of exported container into ' + bzfile)\n\t\t\t\tself.build['report'] += ('\\nRun:\\n\\nbunzip2 -c ' + bzfile + ' | sudo docker import -\\n\\nto get this imported into docker.')\n\t\t\tif save:\n\t\t\t\tbzfile = (repository_tar + 'save.tar.bz2')\n\t\t\t\tself.log('Depositing bzip2 of exported container into ' + bzfile,level=logging.DEBUG)\n\t\t\t\tif self.send(docker_executable + ' save ' + self.target['container_id'] + ' | bzip2 - > ' + bzfile,\n\t\t\t\t             expect=[expect, 'assword'],\n\t\t\t\t             timeout=99999,\n\t\t\t\t             shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t\t             loglevel=loglevel) == 1:\n\t\t\t\t\tself.send(password,\n\t\t\t\t\t          expect=expect,\n\t\t\t\t\t          shutit_pexpect_child=shutit_pexpect_child,\n\t\t\t\t\t          loglevel=loglevel)\n\t\t\t\tself.log('Deposited bzip2 of exported container into ' + bzfile, level=logging.DEBUG)\n\t\t\t\tself.log('Run: bunzip2 -c ' + bzfile + ' | sudo docker import - to get this imported into docker.', level=logging.DEBUG)\n\t\t\t\tself.build['report'] += ('\\nDeposited bzip2 of exported container into ' + bzfile)\n\t\t\t\tself.build['report'] += ('\\nRun:\\n\\nbunzip2 -c ' + bzfile + ' | sudo docker import -\\n\\nto get this imported into docker.')\n\t\tif self.repository['push']:\n\t\t\t# Pass the child explicitly as it's the host child.\n\t\t\tself.push_repository(repository, docker_executable=docker_executable, expect=expect, shutit_pexpect_child=shutit_pexpect_child)\n\t\t\tself.build['report'] = (self.build['report'] + '\\nPushed repository: ' + repository)\n\t\tself.handle_note_after(note)\n\t\treturn True", "response": "This method is used to do the actual work of the repository."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config(self,\n\t               module_id,\n\t               option,\n\t               default=None,\n\t               boolean=False,\n\t               secret=False,\n\t               forceask=False,\n\t               forcenone=False,\n\t               hint=None):\n\t\t\"\"\"Gets a specific config from the config files, allowing for a default.\n\n\t\tHandles booleans vs strings appropriately.\n\n\t\t@param module_id:    module id this relates to, eg com.mycorp.mymodule.mymodule\n\t\t@param option:       config item to set\n\t\t@param default:      default value if not set in files\n\t\t@param boolean:      whether this is a boolean value or not (default False)\n\t\t@param secret:       whether the config item is a secret\n\t\t@param forceask: if set to True, allows you to override any value already set (default False)\n\t\t@param forcenone:    if set to True, allows you to set the value to None (default False)\n\t\t@param hint:         if we are interactive, then show this prompt to help the user input a useful value\n\n\t\t@type module_id:     string\n\t\t@type option:        string\n\t\t@type default:       string\n\t\t@type boolean:       boolean\n\t\t@type secret:        boolean\n\t\t@type forceask:  boolean\n\t\t@type forcenone:     boolean\n\t\t@type hint:          string\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tif module_id not in cfg.keys():\n\t\t\tcfg[module_id] = {}\n\t\tif not self.config_parser.has_section(module_id):\n\t\t\tself.config_parser.add_section(module_id)\n\t\tif not forceask and self.config_parser.has_option(module_id, option):\n\t\t\tif boolean:\n\t\t\t\tcfg[module_id][option] = self.config_parser.getboolean(module_id, option)\n\t\t\telse:\n\t\t\t\tcfg[module_id][option] = self.config_parser.get(module_id, option)\n\t\telse:\n\t\t\tif not forcenone:\n\t\t\t\tif shutit_global.shutit_global_object.interactive > 0:\n\t\t\t\t\tif self.build['accept_defaults'] is None:\n\t\t\t\t\t\tanswer = None\n\t\t\t\t\t\t# util_raw_input may change the interactive level, so guard for this.\n\t\t\t\t\t\twhile answer not in ('yes','no','') and shutit_global.shutit_global_object.interactive > 1:\n\t\t\t\t\t\t\tanswer = shutit_util.util_raw_input(prompt=shutit_util.colorise('32', 'Do you want to accept the config option defaults? ' + '(boolean - input \"yes\" or \"no\") (default: yes): \\n'),default='yes',ispass=secret)\n\t\t\t\t\t\t# util_raw_input may change the interactive level, so guard for this.\n\t\t\t\t\t\tself.build['accept_defaults'] = answer in ('yes','') or shutit_global.shutit_global_object.interactive < 2\n\t\t\t\t\tif self.build['accept_defaults'] and default != None:\n\t\t\t\t\t\tcfg[module_id][option] = default\n\t\t\t\t\telse:\n\t\t\t\t\t\t# util_raw_input may change the interactive level, so guard for this.\n\t\t\t\t\t\tprompt = '\\n\\nPlease input a value for ' + module_id + '.' + option\n\t\t\t\t\t\tif default != None:\n\t\t\t\t\t\t\tprompt = prompt + ' (default: ' + str(default) + ')'\n\t\t\t\t\t\tif hint != None:\n\t\t\t\t\t\t\tprompt = prompt + '\\n\\n' + hint\n\t\t\t\t\t\tanswer = None\n\t\t\t\t\t\tif boolean:\n\t\t\t\t\t\t\twhile answer not in ('yes','no'):\n\t\t\t\t\t\t\t\tanswer =  shutit_util.util_raw_input(prompt=shutit_util.colorise('32',prompt + ' (boolean - input \"yes\" or \"no\"): \\n'),ispass=secret)\n\t\t\t\t\t\t\tif answer == 'yes':\n\t\t\t\t\t\t\t\tanswer = True\n\t\t\t\t\t\t\telif answer == 'no':\n\t\t\t\t\t\t\t\tanswer = False\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tif re.search('assw',option) is None:\n\t\t\t\t\t\t\t\tanswer =  shutit_util.util_raw_input(prompt=shutit_util.colorise('32',prompt) + ': \\n',ispass=secret)\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\tanswer =  shutit_util.util_raw_input(ispass=True,prompt=shutit_util.colorise('32',prompt) + ': \\n')\n\t\t\t\t\t\tif answer == '' and default != None:\n\t\t\t\t\t\t\tanswer = default\n\t\t\t\t\t\tcfg[module_id][option] = answer\n\t\t\t\telse:\n\t\t\t\t\tif default != None:\n\t\t\t\t\t\tcfg[module_id][option] = default\n\t\t\t\t\telse:\n\t\t\t\t\t\tself.fail('Config item: ' + option + ':\\nin module:\\n[' + module_id + ']\\nmust be set!\\n\\nOften this is a deliberate requirement to place in your ~/.shutit/config file, or you can pass in with:\\n\\n-s ' + module_id + ' ' + option + ' yourvalue\\n\\nto the build command', throw_exception=False) # pragma: no cover\n\t\t\telse:\n\t\t\t\tcfg[module_id][option] = default\n\t\treturn True", "response": "Get a specific config from the config files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an emailer object", "response": "def get_emailer(self, cfg_section):\n\t\t\"\"\"Sends an email using the mailer\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\timport emailer\n\t\treturn emailer.Emailer(cfg_section, self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_shutit_pexpect_session_from_child(self, shutit_pexpect_child):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif not isinstance(shutit_pexpect_child, pexpect.pty_spawn.spawn):\n\t\t\tself.fail('Wrong type in get_shutit_pexpect_session_child: ' + str(type(shutit_pexpect_child)),throw_exception=True) # pragma: no cover\n\t\tfor key in self.shutit_pexpect_sessions:\n\t\t\tif self.shutit_pexpect_sessions[key].pexpect_child == shutit_pexpect_child:\n\t\t\t\treturn self.shutit_pexpect_sessions[key]\n\t\treturn self.fail('Should not get here in get_shutit_pexpect_session',throw_exception=True)", "response": "Given a pexpect child object return the shutit_pexpect_session object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a pexpect child object return the shutit_pexpect_session_id object.", "response": "def get_shutit_pexpect_session_id(self, shutit_pexpect_child):\n\t\t\"\"\"Given a pexpect child object, return the shutit_pexpect_session_id object.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif not isinstance(shutit_pexpect_child, pexpect.pty_spawn.spawn):\n\t\t\tself.fail('Wrong type in get_shutit_pexpect_session_id',throw_exception=True) # pragma: no cover\n\t\tfor key in self.shutit_pexpect_sessions:\n\t\t\tif self.shutit_pexpect_sessions[key].pexpect_child == shutit_pexpect_child:\n\t\t\t\treturn key\n\t\treturn self.fail('Should not get here in get_shutit_pexpect_session_id',throw_exception=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the pexpect session from the given identifier.", "response": "def get_shutit_pexpect_session_from_id(self, shutit_pexpect_id):\n\t\t\"\"\"Get the pexpect session from the given identifier.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tfor key in self.shutit_pexpect_sessions:\n\t\t\tif self.shutit_pexpect_sessions[key].pexpect_session_id == shutit_pexpect_id:\n\t\t\t\treturn self.shutit_pexpect_sessions[key]\n\t\treturn self.fail('Should not get here in get_shutit_pexpect_session_from_id',throw_exception=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_commands(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\ts = ''\n\t\tfor c in self.build['shutit_command_history']:\n\t\t\tif isinstance(c, str):\n\t\t\t\t#Ignore commands with leading spaces\n\t\t\t\tif c and c[0] != ' ':\n\t\t\t\t\ts += c + '\\n'\n\t\treturn s", "response": "Gets the list of commands that have been run and have not been redacted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_report(self, msg=''):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\ts = '\\n'\n\t\ts += '################################################################################\\n'\n\t\ts += '# COMMAND HISTORY BEGIN ' + shutit_global.shutit_global_object.build_id + '\\n'\n\t\ts += self.get_commands()\n\t\ts += '# COMMAND HISTORY END ' + shutit_global.shutit_global_object.build_id + '\\n'\n\t\ts += '################################################################################\\n'\n\t\ts += '################################################################################\\n'\n\t\ts += '# BUILD REPORT FOR BUILD BEGIN ' + shutit_global.shutit_global_object.build_id + '\\n'\n\t\ts += '# ' + msg + '\\n'\n\t\tif self.build['report'] != '':\n\t\t\ts += self.build['report'] + '\\n'\n\t\telse:\n\t\t\ts += '# Nothing to report\\n'\n\t\tif 'container_id' in self.target:\n\t\t\ts += '# CONTAINER_ID: ' + self.target['container_id'] + '\\n'\n\t\ts += '# BUILD REPORT FOR BUILD END ' + shutit_global.shutit_global_object.build_id + '\\n'\n\t\ts += '###############################################################################\\n'\n\t\ts += '# INVOKING COMMAND WAS: ' + sys.executable\n\t\tfor arg in sys.argv:\n\t\t\ts += ' ' + arg\n\t\ts += '\\n'\n\t\ts += '###############################################################################\\n'\n\t\treturn s", "response": "Resposible for constructing a report to be output as part of the build."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmatching a string against a regular expression.", "response": "def match_string(self, string_to_match, regexp):\n\t\t\"\"\"Get regular expression from the first of the lines passed\n\t\tin in string that matched. Handles first group of regexp as\n\t\ta return value.\n\n\t\t@param string_to_match: String to match on\n\t\t@param regexp: Regexp to check (per-line) against string\n\n\t\t@type string_to_match: string\n\t\t@type regexp: string\n\n\t\tReturns None if none of the lines matched.\n\n\t\tReturns True if there are no groups selected in the regexp.\n\t\telse returns matching group (ie non-None)\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif not isinstance(string_to_match, str):\n\t\t\treturn None\n\t\tlines = string_to_match.split('\\r\\n')\n\t\t# sometimes they're separated by just a carriage return...\n\t\tnew_lines = []\n\t\tfor line in lines:\n\t\t\tnew_lines = new_lines + line.split('\\r')\n\t\t# and sometimes they're separated by just a newline...\n\t\tfor line in lines:\n\t\t\tnew_lines = new_lines + line.split('\\n')\n\t\tlines = new_lines\n\t\tif not shutit_util.check_regexp(regexp):\n\t\t\tself.fail('Illegal regexp found in match_string call: ' + regexp) # pragma: no cover\n\t\tfor line in lines:\n\t\t\tmatch = re.match(regexp, line)\n\t\t\tif match is not None:\n\t\t\t\tif match.groups():\n\t\t\t\t\treturn match.group(1)\n\t\t\t\treturn True\n\t\treturn None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of module ids guaranteed to be sorted by run order ignoring conn modules", "response": "def module_ids(self, rev=False):\n\t\t\"\"\"Gets a list of module ids guaranteed to be sorted by run_order, ignoring conn modules\n\t\t(run order < 0).\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tids = sorted(list(self.shutit_map.keys()),key=lambda module_id: self.shutit_map[module_id].run_order)\n\t\tif rev:\n\t\t\treturn list(reversed(ids))\n\t\treturn ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_to_be_built_or_is_installed(self, shutit_module_obj):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tif cfg[shutit_module_obj.module_id]['shutit.core.module.build']:\n\t\t\treturn True\n\t\treturn self.is_installed(shutit_module_obj)", "response": "Returns true if this module is configured to be built or is already installed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning true if this module is installed.", "response": "def is_installed(self, shutit_module_obj):\n\t\t\"\"\"Returns true if this module is installed.\n\t\tUses cache where possible.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# Cache first\n\t\tif shutit_module_obj.module_id in self.get_current_shutit_pexpect_session_environment().modules_installed:\n\t\t\treturn True\n\t\tif shutit_module_obj.module_id in self.get_current_shutit_pexpect_session_environment().modules_not_installed:\n\t\t\treturn False\n\t\t# Is it installed?\n\t\tif shutit_module_obj.is_installed(self):\n\t\t\tself.get_current_shutit_pexpect_session_environment().modules_installed.append(shutit_module_obj.module_id)\n\t\t\treturn True\n\t\t# If not installed, and not in cache, add it.\n\t\telse:\n\t\t\tif shutit_module_obj.module_id not in self.get_current_shutit_pexpect_session_environment().modules_not_installed:\n\t\t\t\tself.get_current_shutit_pexpect_session_environment().modules_not_installed.append(shutit_module_obj.module_id)\n\t\t\treturn False\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef allowed_image(self, module_id):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.log(\"In allowed_image: \" + module_id,level=logging.DEBUG)\n\t\tcfg = self.cfg\n\t\tif self.build['ignoreimage']:\n\t\t\tself.log(\"ignoreimage == true, returning true\" + module_id,level=logging.DEBUG)\n\t\t\treturn True\n\t\tself.log(str(cfg[module_id]['shutit.core.module.allowed_images']),level=logging.DEBUG)\n\t\tif cfg[module_id]['shutit.core.module.allowed_images']:\n\t\t\t# Try allowed images as regexps\n\t\t\tfor regexp in cfg[module_id]['shutit.core.module.allowed_images']:\n\t\t\t\tif not shutit_util.check_regexp(regexp):\n\t\t\t\t\tself.fail('Illegal regexp found in allowed_images: ' + regexp) # pragma: no cover\n\t\t\t\tif re.match('^' + regexp + '$', self.target['docker_image']):\n\t\t\t\t\treturn True\n\t\treturn False", "response": "Determines whether the image is allowed to be built."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_modules(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tmodule_string = ''\n\t\tmodule_string += 'Modules: \\n'\n\t\tmodule_string += '    Run order    Build    Remove    Module ID\\n'\n\t\tfor module_id in self.module_ids():\n\t\t\tmodule_string += '    ' + str(self.shutit_map[module_id].run_order) + '        ' + str(\n\t\t\t\tcfg[module_id]['shutit.core.module.build']) + '    ' + str(\n\t\t\t\tcfg[module_id]['shutit.core.module.remove']) + '    ' + module_id + '\\n'\n\t\treturn module_string", "response": "Returns a string table representing the modules in the ShutIt module map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload all shutit modules based on the paths in the shutit_module_paths.", "response": "def load_shutit_modules(self):\n\t\t\"\"\"Responsible for loading the shutit modules based on the configured module\n\t\tpaths.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif self.loglevel <= logging.DEBUG:\n\t\t\tself.log('ShutIt module paths now: ',level=logging.DEBUG)\n\t\t\tself.log(self.host['shutit_module_path'],level=logging.DEBUG)\n\t\tfor shutit_module_path in self.host['shutit_module_path']:\n\t\t\tself.load_all_from_path(shutit_module_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the config files into the shutit global object.", "response": "def load_configs(self):\n\t\t\"\"\"Responsible for loading config files into ShutIt.\n\t\tRecurses down from configured shutit module paths.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# Get root default config.\n\t\t# TODO: change default_cnf so it places whatever the values are at this stage of the build.\n\t\tconfigs = [('defaults', StringIO(default_cnf)), os.path.expanduser('~/.shutit/config'), os.path.join(self.host['shutit_path'], 'config'), 'configs/build.cnf']\n\t\t# Add the shutit global host- and user-specific config file.\n\t\t# Add the local build.cnf\n\t\t# Get passed-in config(s)\n\t\tfor config_file_name in self.build['extra_configs']:\n\t\t\trun_config_file = os.path.expanduser(config_file_name)\n\t\t\tif not os.path.isfile(run_config_file):\n\t\t\t\tshutit_global.shutit_global_object.shutit_print('Did not recognise ' + run_config_file + ' as a file - do you need to touch ' + run_config_file + '?')\n\t\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=0)\n\t\t\tconfigs.append(run_config_file)\n\t\t# Image to use to start off. The script should be idempotent, so running it\n\t\t# on an already built image should be ok, and is advised to reduce diff space required.\n\t\tif self.action['list_configs'] or self.loglevel <= logging.DEBUG:\n\t\t\tmsg = ''\n\t\t\tfor c in configs:\n\t\t\t\tif isinstance(c, tuple):\n\t\t\t\t\tc = c[0]\n\t\t\t\tmsg = msg + '    \\n' + c\n\t\t\t\tself.log('    ' + c,level=logging.DEBUG)\n\n\t\t# Interpret any config overrides, write to a file and add them to the\n\t\t# list of configs to be interpreted\n\t\tif self.build['config_overrides']:\n\t\t\t# We don't need layers, this is a temporary configparser\n\t\t\toverride_cp = ConfigParser.RawConfigParser()\n\t\t\tfor o_sec, o_key, o_val in self.build['config_overrides']:\n\t\t\t\tif not override_cp.has_section(o_sec):\n\t\t\t\t\toverride_cp.add_section(o_sec)\n\t\t\t\toverride_cp.set(o_sec, o_key, o_val)\n\t\t\toverride_fd = StringIO()\n\t\t\toverride_cp.write(override_fd)\n\t\t\toverride_fd.seek(0)\n\t\t\tconfigs.append(('overrides', override_fd))\n\n\t\tself.config_parser = self.get_configs(configs)\n\t\tself.get_base_config()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_base_config(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcp = self.config_parser\n\t\t# TODO: what happens if a command-line arg was already set?\n\t\t# BEGIN Read from config files\n\t\t# build - details relating to the build\n\t\tself.build['privileged']                 = cp.getboolean('build', 'privileged')\n\t\tself.build['base_image']                 = cp.get('build', 'base_image')\n\t\tself.build['dotest']                     = cp.get('build', 'dotest')\n\t\tself.build['net']                        = cp.get('build', 'net')\n\t\t# Take a command-line arg if given, else default.\n\t\tif self.build['conn_module'] is None:\n\t\t\tself.build['conn_module']            = cp.get('build', 'conn_module')\n\t\t# target - the target of the build, ie the container\n\t\tself.target['hostname']                  = cp.get('target', 'hostname')\n\t\tself.target['ports']                     = cp.get('target', 'ports')\n\t\tself.target['volumes']                   = cp.get('target', 'volumes')\n\t\tself.target['volumes_from']              = cp.get('target', 'volumes_from')\n\t\tself.target['name']                      = cp.get('target', 'name')\n\t\tself.target['rm']                        = cp.getboolean('target', 'rm')\n\t\t# host - the host on which the shutit script is run\n\t\tself.host['add_shutit_to_path']          = cp.getboolean('host', 'add_shutit_to_path')\n\t\tself.host['docker_executable']           = cp.get('host', 'docker_executable')\n\t\tself.host['dns']                         = cp.get('host', 'dns')\n\t\tself.host['password']                    = cp.get('host', 'password')\n\t\tif isinstance(self.host['password'],str):\n\t\t\tshutit_global.shutit_global_object.secret_words_set.add(self.host['password'])\n\t\tself.logfile = cp.get('host', 'logfile')\n\t\tself.host['shutit_module_path']          = cp.get('host', 'shutit_module_path').split(':')\n\n\t\t# repository - information relating to docker repository/registry\n\t\tself.repository['name']                  = cp.get('repository', 'name')\n\t\tself.repository['server']                = cp.get('repository', 'server')\n\t\tself.repository['push']                  = cp.getboolean('repository', 'push')\n\t\tself.repository['tag']                   = cp.getboolean('repository', 'tag')\n\t\tself.repository['export']                = cp.getboolean('repository', 'export')\n\t\tself.repository['save']                  = cp.getboolean('repository', 'save')\n\t\tself.repository['suffix_date']           = cp.getboolean('repository', 'suffix_date')\n\t\tself.repository['suffix_format']         = cp.get('repository', 'suffix_format')\n\t\tself.repository['user']                  = cp.get('repository', 'user')\n\t\tself.repository['password']              = cp.get('repository', 'password')\n\t\tif isinstance(self.repository['password'],str):\n\t\t\tshutit_global.shutit_global_object.secret_words_set.add(self.repository['password'])\n\t\tself.repository['email']                 = cp.get('repository', 'email')\n\t\tself.repository['tag_name']              = cp.get('repository', 'tag_name')\n\t\t# END Read from config files\n\n\t\t# BEGIN tidy configs up\n\t\tif self.target['docker_image'] == '':\n\t\t\tself.target['docker_image'] = self.build['base_image']\n\t\t# END tidy configs up\n\n\t\t# FAILS begins\n\t\t# rm is incompatible with repository actions\n\t\tif self.target['rm'] and (self.repository['tag'] or self.repository['push'] or self.repository['save'] or self.repository['export']): # pragma: no cover\n\t\t\tshutit_global.shutit_global_object.shutit_print(\"Can't have [target]/rm and [repository]/(push/save/export) set to true\")\n\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\tif self.target['hostname'] != '' and self.build['net'] != '' and self.build['net'] != 'bridge': # pragma: no cover\n\t\t\tshutit_global.shutit_global_object.shutit_print('\\n\\ntarget/hostname or build/net configs must be blank\\n\\n')\n\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)", "response": "Get the base config from the config files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_all_from_path(self, path):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t#111: handle expanded paths\n\t\tpath = os.path.abspath(path)\n\t\t#http://stackoverflow.com/questions/301134/dynamic-module-import-in-python\n\t\tif os.path.abspath(path) == self.shutit_main_dir:\n\t\t\treturn\n\t\tif not os.path.exists(path):\n\t\t\treturn\n\t\tif os.path.exists(path + '/STOPBUILD') and not self.build['ignorestop']:\n\t\t\tself.log('Ignoring directory: ' + path + ' as it has a STOPBUILD file in it. Pass --ignorestop to shutit run to override.',level=logging.DEBUG)\n\t\t\treturn\n\t\tfor sub in glob.glob(os.path.join(path, '*')):\n\t\t\tsubpath = os.path.join(path, sub)\n\t\t\tif os.path.isfile(subpath):\n\t\t\t\tself.load_mod_from_file(subpath)\n\t\t\telif os.path.isdir(subpath):\n\t\t\t\tself.load_all_from_path(subpath)", "response": "Dynamically imports modules from a directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading modules from a. py file into ShutIt if there are no modules from this file.", "response": "def load_mod_from_file(self, fpath):\n\t\t\"\"\"Loads modules from a .py file into ShutIt if there are no modules from\n\t\tthis file already.\n\t\tWe expect to have a callable 'module/0' which returns one or more module\n\t\tobjects.\n\t\tIf this doesn't exist we assume that the .py file works in the old style\n\t\t(automatically inserting the module into shutit_global) or it's not a shutit\n\t\tmodule.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tfpath = os.path.abspath(fpath)\n\t\tfile_ext = os.path.splitext(os.path.split(fpath)[-1])[-1]\n\t\tif file_ext.lower() != '.py':\n\t\t\treturn\n\t\twith open(fpath) as f:\n\t\t\tcontent = f.read().splitlines()\n\t\tok = False\n\t\tfor line in content:\n\t\t\tif line.strip() == 'from shutit_module import ShutItModule':\n\t\t\t\tok = True\n\t\t\t\tbreak\n\t\tif not ok:\n\t\t\tself.log('Rejected file: ' + fpath,level=logging.DEBUG)\n\t\t\treturn\n\t\t# Note that this attribute will only be set for 'new style' module loading, # this should be ok because 'old style' loading checks for duplicate # existing modules.\n\t\t# TODO: this is quadratic complexity\n\t\texistingmodules = [\n\t\t\tm for m in self.shutit_modules\n\t\t\tif getattr(m, '__module_file', None) == fpath\n\t\t]\n\t\tif existingmodules:\n\t\t\tself.log('Module already seen: ' + fpath,level=logging.DEBUG)\n\t\t\treturn\n\t\t# Looks like it's ok to load this file\n\t\tself.log('Loading source for: ' + fpath,level=logging.DEBUG)\n\n\t\t# Add this directory to the python path iff not already there.\n\t\tdirectory = os.path.dirname(fpath)\n\t\tif directory not in sys.path:\n\t\t\tsys.path.append(os.path.dirname(fpath))\n\t\t# TODO: use bytearray to encode?\n\t\tmod_name = base64.b32encode(fpath.encode()).decode().replace('=', '')\n\t\tpymod = imp.load_source(mod_name, fpath)\n\n\t\t# Got the python module, now time to pull the shutit module(s) out of it.\n\t\ttargets = [\n\t\t\t('module', self.shutit_modules), ('conn_module', self.conn_modules)\n\t\t]\n\t\tself.build['source'] = {}\n\t\tfor attr, target in targets:\n\t\t\tmodulefunc = getattr(pymod, attr, None)\n\t\t\t# Old style or not a shutit module, nothing else to do\n\t\t\tif not callable(modulefunc):\n\t\t\t\treturn\n\t\t\tmodules = modulefunc()\n\t\t\tif not isinstance(modules, list):\n\t\t\t\tmodules = [modules]\n\t\t\tfor module in modules:\n\t\t\t\tsetattr(module, '__module_file', fpath)\n\t\t\t\tShutItModule.register(module.__class__)\n\t\t\t\ttarget.add(module)\n\t\t\t\tself.build['source'][fpath] = open(fpath).read()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect the configuration for modules that are being built.", "response": "def config_collection_for_built(self, throw_error=True,silent=False):\n\t\t\"\"\"Collect configuration for modules that are being built.\n\t\tWhen this is called we should know what's being built (ie after\n\t\tdependency resolution).\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.log('In config_collection_for_built',level=logging.DEBUG)\n\t\tcfg = self.cfg\n\t\tfor module_id in self.module_ids():\n\t\t\t# Get the config even if installed or building (may be needed in other hooks, eg test).\n\t\t\tif (self.is_to_be_built_or_is_installed(self.shutit_map[module_id]) and\n\t\t\t\tnot self.shutit_map[module_id].get_config(self)):\n\t\t\t\tself.fail(module_id + ' failed on get_config') # pragma: no cover\n\t\t\t# Collect the build.cfg if we are building here.\n\t\t\t# If this file exists, process it.\n\t\t\tif cfg[module_id]['shutit.core.module.build'] and not self.build['have_read_config_file']:\n\t\t\t\t# TODO: __module_file not accessible when within object - look to get this elsewhere and re-read in, then move this function into shutit object.\n\t\t\t\tcfg_file = os.path.dirname(self.shutit_file_map[module_id]) + '/configs/build.cnf'\n\t\t\t\tif os.path.isfile(cfg_file):\n\t\t\t\t\tself.build['have_read_config_file'] = True\n\t\t\t\t\t# use self.get_config, forcing the passed-in default\n\t\t\t\t\tconfig_parser = ConfigParser.ConfigParser()\n\t\t\t\t\tconfig_parser.read(cfg_file)\n\t\t\t\t\tfor section in config_parser.sections():\n\t\t\t\t\t\tif section == module_id:\n\t\t\t\t\t\t\tfor option in config_parser.options(section):\n\t\t\t\t\t\t\t\toverride = False\n\t\t\t\t\t\t\t\tfor mod, opt, val in self.build['config_overrides']:\n\t\t\t\t\t\t\t\t\tval = val # pylint\n\t\t\t\t\t\t\t\t\t# skip overrides\n\t\t\t\t\t\t\t\t\tif mod == module_id and opt == option:\n\t\t\t\t\t\t\t\t\t\toverride = True\n\t\t\t\t\t\t\t\tif override:\n\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\tis_bool = isinstance(cfg[module_id][option], bool)\n\t\t\t\t\t\t\t\tif is_bool:\n\t\t\t\t\t\t\t\t\tvalue = config_parser.getboolean(section,option)\n\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\tvalue = config_parser.get(section,option)\n\t\t\t\t\t\t\t\tif option == 'shutit.core.module.allowed_images':\n\t\t\t\t\t\t\t\t\tvalue = json.loads(value)\n\t\t\t\t\t\t\t\tself.get_config(module_id, option, value, forceask=True)\n\t\t# Check the allowed_images against the base_image\n\t\tpassed = True\n\t\tfor module_id in self.module_ids():\n\t\t\tif (cfg[module_id]['shutit.core.module.build'] and\n\t\t\t   (cfg[module_id]['shutit.core.module.allowed_images'] and\n\t\t\t    self.target['docker_image'] not in cfg[module_id]['shutit.core.module.allowed_images'])):\n\t\t\t\tif not self.allowed_image(module_id):\n\t\t\t\t\tpassed = False\n\t\t\t\t\tif not silent:\n\t\t\t\t\t\tshutit_global.shutit_global_object.shutit_print('\\n\\nWARNING!\\n\\nAllowed images for ' + module_id + ' are: ' + str(cfg[module_id]['shutit.core.module.allowed_images']) + ' but the configured image is: ' + self.target['docker_image'] + '\\n\\nIs your shutit_module_path set correctly?\\n\\nIf you want to ignore this, pass in the --ignoreimage flag to shutit.\\n\\n')\n\t\tif not passed:\n\t\t\tif not throw_error:\n\t\t\t\treturn False\n\t\t\tif self.build['imageerrorok']:\n\t\t\t\t# useful for test scripts\n\t\t\t\tshutit_global.shutit_global_object.shutit_print('Exiting on allowed images error, with return status 0')\n\t\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=1)\n\t\t\telse:\n\t\t\t\traise ShutItFailException('Allowed images checking failed') # pragma: no cover\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_collection(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.log('In config_collection',level=logging.DEBUG)\n\t\tcfg = self.cfg\n\t\tfor module_id in self.module_ids():\n\t\t\t# Default to None so we can interpret as ifneeded\n\t\t\tself.get_config(module_id, 'shutit.core.module.build', None, boolean=True, forcenone=True)\n\t\t\tself.get_config(module_id, 'shutit.core.module.remove', False, boolean=True)\n\t\t\tself.get_config(module_id, 'shutit.core.module.tag', False, boolean=True)\n\t\t\t# Default to allow any image\n\t\t\tself.get_config(module_id, 'shutit.core.module.allowed_images', [\".*\"])\n\t\t\tmodule = self.shutit_map[module_id]\n\t\t\tcfg_file = os.path.dirname(get_module_file(self,module)) + '/configs/build.cnf'\n\t\t\tif os.path.isfile(cfg_file):\n\t\t\t\t# use self.get_config, forcing the passed-in default\n\t\t\t\tconfig_parser = ConfigParser.ConfigParser()\n\t\t\t\tconfig_parser.read(cfg_file)\n\t\t\t\tfor section in config_parser.sections():\n\t\t\t\t\tif section == module_id:\n\t\t\t\t\t\tfor option in config_parser.options(section):\n\t\t\t\t\t\t\tif option == 'shutit.core.module.allowed_images':\n\t\t\t\t\t\t\t\toverride = False\n\t\t\t\t\t\t\t\tfor mod, opt, val in self.build['config_overrides']:\n\t\t\t\t\t\t\t\t\tval = val # pylint\n\t\t\t\t\t\t\t\t\t# skip overrides\n\t\t\t\t\t\t\t\t\tif mod == module_id and opt == option:\n\t\t\t\t\t\t\t\t\t\toverride = True\n\t\t\t\t\t\t\t\tif override:\n\t\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\t\tvalue = config_parser.get(section,option)\n\t\t\t\t\t\t\t\tif option == 'shutit.core.module.allowed_images':\n\t\t\t\t\t\t\t\t\tvalue = json.loads(value)\n\t\t\t\t\t\t\t\tself.get_config(module_id, option, value, forceask=True)\n\t\t\t# ifneeded will (by default) only take effect if 'build' is not\n\t\t\t# specified. It can, however, be forced to a value, but this\n\t\t\t# should be unusual.\n\t\t\tif cfg[module_id]['shutit.core.module.build'] is None:\n\t\t\t\tself.get_config(module_id, 'shutit.core.module.build_ifneeded', True, boolean=True)\n\t\t\t\tcfg[module_id]['shutit.core.module.build'] = False\n\t\t\telse:\n\t\t\t\tself.get_config(module_id, 'shutit.core.module.build_ifneeded', False, boolean=True)", "response": "Collect core config from config files for all seen modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_list_modules(self, long_output=None,sort_order=None):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\t# list of module ids and other details\n\t\t# will also contain column headers\n\t\ttable_list = []\n\t\tif long_output is None:\n\t\t\tlong_output = self.list_modules['long']\n\t\tif sort_order is None:\n\t\t\tsort_order = self.list_modules['sort']\n\t\tif long_output:\n\t\t\t# --long table: sort modules by run order\n\t\t\ttable_list.append([\"Order\",\"Module ID\",\"Description\",\"Run Order\",\"Built\",\"Compatible\"])\n\t\t\t#table_list.append([\"Order\",\"Module ID\",\"Description\",\"Run Order\",\"Built\"])\n\t\telse:\n\t\t\t# \"short\" table ==> sort module by module_id\n\t\t\t#table_list.append([\"Module ID\",\"Description\",\"Built\"])\n\t\t\ttable_list.append([\"Module ID\",\"Description\",\"Built\",\"Compatible\"])\n\n\t\tif sort_order == 'run_order':\n\t\t\td = {}\n\t\t\tfor m in self.shutit_modules:\n\t\t\t\td.update({m.module_id:m.run_order})\n\t\t\t# sort dict by run_order; see http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n\t\t\tb = sorted(d.items(), key=operator.itemgetter(1))\n\t\t\tcount = 0\n\t\t\t# now b is a list of tuples (module_id, run_order)\n\t\t\tfor pair in b:\n\t\t\t\t# module_id is the first item of the tuple\n\t\t\t\tk = pair[0]\n\t\t\t\tfor m in self.shutit_modules:\n\t\t\t\t\tif m.module_id == k:\n\t\t\t\t\t\tcount += 1\n\t\t\t\t\t\tcompatible = True\n\t\t\t\t\t\tif not cfg[m.module_id]['shutit.core.module.build']:\n\t\t\t\t\t\t\tcfg[m.module_id]['shutit.core.module.build'] = True\n\t\t\t\t\t\t\tcompatible = self.determine_compatibility(m.module_id) == 0\n\t\t\t\t\t\t\tcfg[m.module_id]['shutit.core.module.build'] = False\n\t\t\t\t\t\tif long_output:\n\t\t\t\t\t\t\ttable_list.append([str(count),m.module_id,m.description,str(m.run_order),str(cfg[m.module_id]['shutit.core.module.build']),str(compatible)])\n\t\t\t\t\t\t\t#table_list.append([str(count),m.module_id,m.description,str(m.run_order),str(cfg[m.module_id]['shutit.core.module.build'])])\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\ttable_list.append([m.module_id,m.description,str(cfg[m.module_id]['shutit.core.module.build']),str(compatible)])\n\t\telif sort_order == 'id':\n\t\t\tl = []\n\t\t\tfor m in self.shutit_modules:\n\t\t\t\tl.append(m.module_id)\n\t\t\tl.sort()\n\t\t\tfor k in l:\n\t\t\t\tfor m in self.shutit_modules:\n\t\t\t\t\tif m.module_id == k:\n\t\t\t\t\t\tcount = 1\n\t\t\t\t\t\tcompatible = True\n\t\t\t\t\t\tif not cfg[m.module_id]['shutit.core.module.build']:\n\t\t\t\t\t\t\tcfg[m.module_id]['shutit.core.module.build'] = True\n\t\t\t\t\t\t\tcompatible = self.determine_compatibility(m.module_id) == 0\n\t\t\t\t\t\tif long_output:\n\t\t\t\t\t\t\ttable_list.append([str(count),m.module_id,m.description,str(m.run_order),str(cfg[m.module_id]['shutit.core.module.build']),str(compatible)])\n\t\t\t\t\t\t\t#table_list.append([str(count),m.module_id,m.description,str(m.run_order),str(cfg[m.module_id]['shutit.core.module.build'])])\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t#table_list.append([m.module_id,m.description,str(cfg[m.module_id]['shutit.core.module.build'])])\n\t\t\t\t\t\t\ttable_list.append([m.module_id,m.description,str(cfg[m.module_id]['shutit.core.module.build']),str(compatible)])\n\n\t\t# format table for display\n\t\ttable = texttable.Texttable()\n\t\ttable.add_rows(table_list)\n\t\t# Base length of table on length of strings\n\t\tcolwidths = []\n\t\tfor item in table_list:\n\t\t\tfor n in range(0,len(item)):\n\t\t\t\t# default to 10 chars\n\t\t\t\tcolwidths.append(10)\n\t\t\tbreak\n\t\tfor item in table_list:\n\t\t\tfor n in range(0,len(item)-1):\n\t\t\t\tif len(str(item[n])) > colwidths[n]:\n\t\t\t\t\tcolwidths[n] = len(str(item[n]))\n\t\ttable.set_cols_width(colwidths)\n\t\tmsg = table.draw()\n\t\tshutit_global.shutit_global_object.shutit_print('\\n' + msg)", "response": "Display a list of loaded modules."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the config of this ShutIt run.", "response": "def print_config(self, cfg, hide_password=True, history=False, module_id=None):\n\t\t\"\"\"Returns a string representing the config of this ShutIt run.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcp = self.config_parser\n\t\ts = ''\n\t\tkeys1 = list(cfg.keys())\n\t\tif keys1:\n\t\t\tkeys1.sort()\n\t\tfor k in keys1:\n\t\t\tif module_id is not None and k != module_id:\n\t\t\t\tcontinue\n\t\t\tif isinstance(k, str) and isinstance(cfg[k], dict):\n\t\t\t\ts += '\\n[' + k + ']\\n'\n\t\t\t\tkeys2 = list(cfg[k].keys())\n\t\t\t\tif keys2:\n\t\t\t\t\tkeys2.sort()\n\t\t\t\tfor k1 in keys2:\n\t\t\t\t\tline = ''\n\t\t\t\t\tline += k1 + ':'\n\t\t\t\t\t# If we want to hide passwords, we do so using a sha512\n\t\t\t\t\t# done an aritrary number of times (27).\n\t\t\t\t\tif hide_password and (k1 == 'password' or k1 == 'passphrase'):\n\t\t\t\t\t\tp = hashlib.sha512(cfg[k][k1]).hexdigest()\n\t\t\t\t\t\ti = 27\n\t\t\t\t\t\twhile i > 0:\n\t\t\t\t\t\t\ti -= 1\n\t\t\t\t\t\t\tp = hashlib.sha512(s).hexdigest()\n\t\t\t\t\t\tline += p\n\t\t\t\t\telse:\n\t\t\t\t\t\tif type(cfg[k][k1] == bool):\n\t\t\t\t\t\t\tline += str(cfg[k][k1])\n\t\t\t\t\t\telif type(cfg[k][k1] == str):\n\t\t\t\t\t\t\tline += cfg[k][k1]\n\t\t\t\t\tif history:\n\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\tline += (30-len(line)) * ' ' + ' # ' + cp.whereset(k, k1)\n\t\t\t\t\t\texcept Exception:\n\t\t\t\t\t\t\t# Assume this is because it was never set by a config parser.\n\t\t\t\t\t\t\tline += (30-len(line)) * ' ' + ' # ' + \"defaults in code\"\n\t\t\t\t\ts += line + '\\n'\n\t\treturn s"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the args we have.", "response": "def process_args(self, args):\n\t\t\"\"\"Process the args we have. 'args' is always a ShutItInit object.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tassert isinstance(args,ShutItInit), shutit_util.print_debug()\n\n\t\tif args.action == 'version':\n\t\t\tshutit_global.shutit_global_object.shutit_print('ShutIt version: ' + shutit.shutit_version)\n\t\t\tshutit_global.shutit_global_object.handle_exit(exit_code=0)\n\n\t\t# What are we asking shutit to do?\n\t\tself.action['list_configs'] = args.action == 'list_configs'\n\t\tself.action['list_modules'] = args.action == 'list_modules'\n\t\tself.action['list_deps']    = args.action == 'list_deps'\n\t\tself.action['skeleton']     = args.action == 'skeleton'\n\t\tself.action['build']        = args.action == 'build'\n\t\tself.action['run']          = args.action == 'run'\n\n\t\t# Logging\n\t\tif not self.logging_setup_done:\n\t\t\tself.logfile  = args.logfile\n\t\t\tself.loglevel = args.loglevel\n\t\t\tif self.loglevel is None or self.loglevel == '':\n\t\t\t\tself.loglevel = 'INFO'\n\t\t\tself.setup_logging()\n\t\tshutit_global.shutit_global_object.setup_panes(action=args.action)\n\n\t\t# This mode is a bit special - it's the only one with different arguments\n\t\tif self.action['skeleton']:\n\t\t\tself.handle_skeleton(args)\n\t\t\tshutit_global.shutit_global_object.handle_exit()\n\t\telif self.action['run']:\n\t\t\tself.handle_run(args)\n\t\t\tsys.exit(0)\n\t\telif self.action['build'] or self.action['list_configs'] or self.action['list_modules']:\n\t\t\tself.handle_build(args)\n\t\telse:\n\t\t\tself.fail('Should not get here: action was: ' + str(self.action))\n\t\tself.nocolor = args.nocolor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading config files in checking their security first.", "response": "def get_configs(self, configs):\n\t\t\"\"\"Reads config files in, checking their security first\n\t\t(in case passwords/sensitive info is in them).\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcp  = LayerConfigParser()\n\t\tfail_str = ''\n\t\tfiles    = []\n\t\tfor config_file in configs:\n\t\t\tif isinstance(config_file, tuple):\n\t\t\t\tcontinue\n\t\t\tif not shutit_util.is_file_secure(config_file):\n\t\t\t\tfail_str = fail_str + '\\nchmod 0600 ' + config_file\n\t\t\t\tfiles.append(config_file)\n\t\tif fail_str != '':\n\t\t\tif shutit_global.shutit_global_object.interactive > 1:\n\t\t\t\tfail_str = 'Files are not secure, mode should be 0600. Running the following commands to correct:\\n' + fail_str + '\\n'\n\t\t\t\t# Actually show this to the user before failing...\n\t\t\t\tself.log(fail_str,level=logging.INFO)\n\t\t\t\tself.log('Do you want me to run this for you? (input y/n)',level=logging.INFO)\n\t\t\t\tif shutit_global.shutit_global_object.interactive == 0 or shutit_util.util_raw_input(default='y') == 'y':\n\t\t\t\t\tfor f in files:\n\t\t\t\t\t\tself.log('Correcting insecure file permissions on: ' + f,level=logging.INFO)\n\t\t\t\t\t\tos.chmod(f,0o600)\n\t\t\t\t\t# recurse\n\t\t\t\t\treturn self.get_configs(configs)\n\t\t\telse:\n\t\t\t\tfor f in files:\n\t\t\t\t\tself.log('Correcting insecure file permissions on: ' + f,level=logging.INFO)\n\t\t\t\t\tos.chmod(f,0o600)\n\t\t\t\t# recurse\n\t\t\t\treturn self.get_configs(configs)\n\t\t\tself.fail(fail_str) # pragma: no cover\n\t\tfor config in configs:\n\t\t\tif isinstance(config, tuple):\n\t\t\t\tcp.readfp(config[1], filename=config[0])\n\t\t\telse:\n\t\t\t\tcp.read(config)\n\t\t# Treat allowed_images as a special, additive case\n\t\tself.build['shutit.core.module.allowed_images'] = cp.get_config_set('build', 'shutit.core.module.allowed_images')\n\t\treturn cp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_args(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# These are in order of their creation\n\t\tactions = ['build', 'run', 'list_configs', 'list_modules', 'list_deps', 'skeleton', 'version']\n\n\t\t# COMPAT 2014-05-15 - build is the default if there is no action specified\n\t\t# and we've not asked for help and we've called via 'shutit.py'\n\t\tif len(sys.argv) == 1 or (len(sys.argv) > 1 and sys.argv[1] not in actions\n\t\t\t\tand '-h' not in sys.argv and '--help' not in sys.argv):\n\t\t\tsys.argv.insert(1, 'build')\n\n\t\tparser = argparse.ArgumentParser(description='ShutIt - a tool for managing complex Docker deployments.\\n\\nTo view help for a specific subcommand, type ./shutit <subcommand> -h',prog=\"ShutIt\")\n\t\tsubparsers = parser.add_subparsers(dest='action', help='''Action to perform - build=deploy to target, skeleton=construct a skeleton module, list_configs=show configuration as read in, list_modules=show modules available, list_deps=show dep graph ready for graphviz. Defaults to 'build'.''')\n\n\t\tsub_parsers = dict()\n\t\tfor action in actions:\n\t\t\tsub_parsers[action] = subparsers.add_parser(action)\n\n\t\targs_list = sys.argv[1:]\n\n\t\t# Applies to all\n\t\tfor action in ['build', 'list_configs', 'list_modules', 'list_deps','run','skeleton']:\n\t\t\tsub_parsers[action].add_argument('--delaybeforesend', help='Delay before send setting (see pexpect)', default='0.05')\n\t\t\tsub_parsers[action].add_argument('--promptcommand', help='Prompt command to set', default=\"'sleep .05||sleep 1'\")\n\t\t\tsub_parsers[action].add_argument('-o','--logfile',default='', help='Log output to this file')\n\t\t\tsub_parsers[action].add_argument('-l','--log',default='', help='Log level (DEBUGV, DEBUG, INFO (default), WARNING, ERROR, CRITICAL)',choices=('DEBUG','INFO','WARNING','ERROR','CRITICAL','debugv','debug','info','warning','error','critical'))\n\t\t\tsub_parsers[action].add_argument('--nocolor', help='Remove colorization from ShutIt', default=False, action='store_const', const=True)\n\t\t\tsub_parsers[action].add_argument('-d','--delivery', help='Delivery method, aka target. \"docker\" container (default)', default=None, choices=('docker','dockerfile','bash'))\n\t\t\tsub_parsers[action].add_argument('--echo', help='Always echo output', const=True, default=False, action='store_const')\n\n\t\t# All except run and skeleton\n\t\tfor action in ['build', 'list_configs', 'list_modules', 'list_deps']:\n\t\t\tsub_parsers[action].add_argument('--config', help='Config file for setup config. Must be with perms 0600. Multiple arguments allowed; config files considered in order.', default=[], action='append')\n\t\t\tsub_parsers[action].add_argument('-s', '--set', help='Override a config item, e.g. \"-s target rm no\". Can be specified multiple times.', default=[], action='append', nargs=3, metavar=('SEC', 'KEY', 'VAL'))\n\t\t\tsub_parsers[action].add_argument('--image_tag', help='Build container from specified image - if there is a symbolic reference, please use that, eg localhost.localdomain:5000/myref', default='')\n\t\t\tsub_parsers[action].add_argument('--tag_modules', help='''Tag each module after it's successfully built regardless of the module config and based on the repository config.''', default=False, const=True, action='store_const')\n\t\t\tsub_parsers[action].add_argument('-m', '--shutit_module_path', default=None, help='List of shutit module paths, separated by colons. ShutIt registers modules by running all .py files in these directories.')\n\t\t\tsub_parsers[action].add_argument('--trace', help='Trace function calls', const=True, default=False, action='store_const')\n\t\t\tsub_parsers[action].add_argument('--interactive', help='Level of interactive. 0 = none, 1 = honour pause points and config prompting, 2 = query user on each module, 3 = tutorial mode', default='1')\n\t\t\tsub_parsers[action].add_argument('--ignorestop', help='Ignore STOP files', const=True, default=False, action='store_const')\n\t\t\tsub_parsers[action].add_argument('--ignoreimage', help='Ignore disallowed images', const=True, default=None, action='store_const')\n\t\t\tsub_parsers[action].add_argument('--imageerrorok', help='Exit without error if allowed images fails (used for test scripts)', const=True, default=False, action='store_const')\n\t\t\tsub_parsers[action].add_argument('--deps_only', help='build deps only, tag with suffix \"_deps\"', const=True, default=False, action='store_const')\n\n\t\t# Just run\n\t\tsub_parsers['run'].add_argument('shutitfiles', nargs='*', default=['ShutItFile','Shutitfile','ShutItfile','ShutitFile','shutitfile'])\n\n\t\t# Just skeleton\n\t\tsub_parsers['skeleton'].add_argument('--name', help='Absolute path to new directory for module. Last part of path is taken as the module name.',default='')\n\t\tsub_parsers['skeleton'].add_argument('--domain', help='Arbitrary but unique domain for namespacing your module, eg com.mycorp',default='')\n\t\tsub_parsers['skeleton'].add_argument('--depends', help='Module id to depend on, default shutit.tk.setup (optional)', default='shutit.tk.setup')\n\t\tsub_parsers['skeleton'].add_argument('--base_image', help='FROM image, default ubuntu:16.04 (optional)', default='ubuntu:16.04')\n\t\tsub_parsers['skeleton'].add_argument('--script', help='Pre-existing shell script to integrate into module (optional)', nargs='?', default=None)\n\t\tsub_parsers['skeleton'].add_argument('--output_dir', help='Just output the created directory', default=False, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--shutitfiles', nargs='+', default=None)\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_num_machines', default=None)\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_ssh_access', default=False, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_machine_prefix', default=None)\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_docker', default=None, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_snapshot', default=None, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_upload', default=None, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--vagrant_image_name', default=None, const=True, action='store_const')\n\t\tsub_parsers['skeleton'].add_argument('--pattern', help='Pattern to use', default='')\n\t\tsub_parsers['skeleton'].add_argument('-a','--accept', help='Accept defaults', const=True, default=False, action='store_const')\n\n\t\t# Just build\n\t\tsub_parsers['build'].add_argument('--export', help='Perform docker export to a tar file', const=True, default=False, action='store_const')\n\t\tsub_parsers['build'].add_argument('--save', help='Perform docker save to a tar file', const=True, default=False, action='store_const')\n\t\tsub_parsers['build'].add_argument('--push', help='Push to a repo', const=True, default=False, action='store_const')\n\t\tsub_parsers['build'].add_argument('--distro', help='Specify the distro type', default='', choices=('ubuntu','debian','alpine','steamos','red hat','centos','fedora','shutit'))\n\t\tsub_parsers['build'].add_argument('--mount_docker', help='Mount the docker socket', default=False, action='store_const', const=True)\n\t\tsub_parsers['build'].add_argument('-w','--walkthrough', help='Run in walkthrough mode', default=False, action='store_const', const=True)\n\t\tsub_parsers['build'].add_argument('-c','--choose_config', help='Choose configuration interactively', default=False, action='store_const', const=True)\n\t\tsub_parsers['build'].add_argument('--video', help='Run in video mode. Same as walkthrough, but waits n seconds rather than for input', nargs=1, default=-1)\n\t\tsub_parsers['build'].add_argument('--training', help='Run in \"training\" mode, where correct input is required at key points', default=False, action='store_const', const=True)\n\t\tsub_parsers['build'].add_argument('--exam', help='Run in \"exam\" mode, where correct input is required at key points and progress is tracked', default=False, action='store_const', const=True)\n\t\tsub_parsers['build'].add_argument('--pane', help='Pane-based output', const=True, default=False, action='store_const')\n\n\t\t# Just list_configs\n\t\tsub_parsers['list_configs'].add_argument('--history', help='Show config with history', const=True, default=False, action='store_const')\n\n\t\t# Just list_modules\n\t\tsub_parsers['list_modules'].add_argument('--long', help='Show extended module info, including ordering', const=True, default=False, action='store_const')\n\t\tsub_parsers['list_modules'].add_argument('--sort', help='Order the modules seen, default to module id', default='id', choices=('id','run_order'))\n\n\t\tif os.environ.get('SHUTIT_OPTIONS', None) and args_list[0] != 'skeleton':\n\t\t\tenv_args = os.environ['SHUTIT_OPTIONS'].strip()\n\t\t\t# Split escaped backslashes\n\t\t\tenv_args_split = re.split(r'(\\\\\\\\)', env_args)\n\t\t\t# Split non-escaped spaces\n\t\t\tenv_args_split = [re.split(r'(?<!\\\\)( )', item) for item in env_args_split]\n\t\t\t# Flatten\n\t\t\tenv_args_split = [item for sublist in env_args_split for item in sublist]\n\t\t\t# Split escaped spaces\n\t\t\tenv_args_split = [re.split(r'(\\\\ )', item) for item in env_args_split]\n\t\t\t# Flatten\n\t\t\tenv_args_split = [item for sublist in env_args_split for item in sublist]\n\t\t\t# Trim empty strings\n\t\t\tenv_args_split = [item for item in env_args_split if item != '']\n\t\t\t# We know we don't have to deal with an empty env argument string\n\t\t\tenv_args_list = ['']\n\t\t\t# Interpret all of the escape sequences\n\t\t\tfor item in env_args_split:\n\t\t\t\tif item == ' ':\n\t\t\t\t\tenv_args_list.append('')\n\t\t\t\telif item == '\\\\ ':\n\t\t\t\t\tenv_args_list[-1] += ' '\n\t\t\t\telif item == '\\\\\\\\':\n\t\t\t\t\tenv_args_list[-1] += '\\\\'\n\t\t\t\telse:\n\t\t\t\t\tenv_args_list[-1] += item\n\t\t\targs_list[1:1] = env_args_list\n\t\targs = parser.parse_args(args_list)\n\n\t\t# Set up shutit_global\n\t\tif args.action == 'version':\n\t\t\tself.process_args(ShutItInit(args.action))\n\t\telif args.action == 'skeleton':\n\t\t\tshutit_global.shutit_global_object.delaybeforesend = float(args.delaybeforesend)\n\t\t\tshutit_global.shutit_global_object.prompt_command  = args.promptcommand\n\t\t\tself.process_args(ShutItInit(args.action,\n\t\t\t                             logfile=args.logfile,\n\t\t\t                             loglevel=args.log,\n\t\t\t                             nocolor=args.nocolor,\n\t\t\t                             delivery=args.delivery,\n\t\t\t                             shutitfiles=args.shutitfiles,\n\t\t\t                             script=args.script,\n\t\t\t                             base_image=args.base_image,\n\t\t\t                             depends=args.depends,\n\t\t\t                             name=args.name,\n\t\t\t                             domain=args.domain,\n\t\t\t                             pattern=args.pattern,\n\t\t\t                             output_dir=args.output_dir,\n\t\t\t                             vagrant_ssh_access=args.vagrant_ssh_access,\n\t\t\t                             vagrant_num_machines=args.vagrant_num_machines,\n\t\t\t                             vagrant_machine_prefix=args.vagrant_machine_prefix,\n\t\t\t                             vagrant_docker=args.vagrant_docker,\n\t\t\t                             vagrant_snapshot=args.vagrant_snapshot,\n\t\t\t                             vagrant_upload=args.vagrant_upload,\n\t\t\t                             vagrant_image_name=args.vagrant_image_name))\n\t\telif args.action == 'run':\n\t\t\tshutit_global.shutit_global_object.delaybeforesend = float(args.delaybeforesend)\n\t\t\tshutit_global.shutit_global_object.prompt_command  = args.promptcommand\n\t\t\tself.process_args(ShutItInit(args.action,\n\t\t\t                             logfile=args.logfile,\n\t\t\t                             loglevel=args.log,\n\t\t\t                             nocolor=args.nocolor,\n\t\t\t                             shutitfiles=args.shutitfiles,\n\t\t\t                             echo=args.echo,\n\t\t\t                             delivery = args.delivery))\n\t\telif args.action == 'build':\n\t\t\tshutit_global.shutit_global_object.delaybeforesend = float(args.delaybeforesend)\n\t\t\tshutit_global.shutit_global_object.prompt_command  = args.promptcommand\n\t\t\t# If we are in panes mode, tell the global object.\n\t\t\tshutit_global.shutit_global_object.managed_panes   = args.pane\n\t\t\t# If we are in panes mode, set up logIO.\n\t\t\tif shutit_global.shutit_global_object.managed_panes:\n\t\t\t\tshutit_global.shutit_global_object.logstream   = StringIO()\n\t\t\t\tif not shutit_global.shutit_global_object.determine_interactive():\n\t\t\t\t\tself.log('You cannot have panes if you are not in an interactive shell',level=logging.WARNING)\n\t\t\t\t\tshutit_global.shutit_global_object.managed_panes = False\n\t\t\tself.process_args(ShutItInit(args.action,\n\t\t\t                             logfile=args.logfile,\n\t\t\t                             loglevel=args.log,\n\t\t\t                             nocolor=args.nocolor,\n\t\t\t                             push=args.push,\n\t\t\t                             export=args.export,\n\t\t\t                             save=args.save,\n\t\t\t                             distro=args.distro,\n\t\t\t                             mount_docker=args.mount_docker,\n\t\t\t                             walkthrough=args.walkthrough,\n\t\t\t                             training=args.training,\n\t\t\t                             choose_config=args.choose_config,\n\t\t                                 config=args.config,\n\t\t                                 set=args.set,\n\t\t                                 ignorestop=args.ignorestop,\n\t\t                                 ignoreimage=args.ignoreimage,\n\t\t                                 imageerrorok=args.imageerrorok,\n\t\t                                 tag_modules=args.tag_modules,\n\t\t                                 image_tag=args.image_tag,\n\t\t                                 video=args.video,\n\t\t                                 deps_only=args.deps_only,\n\t\t                                 echo=args.echo,\n\t\t                                 delivery=args.delivery,\n\t\t                                 interactive=args.interactive,\n\t\t                                 trace=args.trace,\n\t\t                                 shutit_module_path=args.shutit_module_path,\n\t\t\t                             exam=args.exam))\n\t\t\t# Set up trace ASAP.\n\t\t\tif args.trace:\n\t\t\t\tdef tracefunc(frame, event, arg, indent=[0]):\n\t\t\t\t\tindent = indent # pylint\n\t\t\t\t\targ = arg # pylint\n\t\t\t\t\tif event == 'call':\n\t\t\t\t\t\tself.log('-> call function: ' + frame.f_code.co_name + ' ' + str(frame.f_code.co_varnames),level=logging.DEBUG)\n\t\t\t\t\telif event == 'return':\n\t\t\t\t\t\tself.log('<- exit function: ' + frame.f_code.co_name,level=logging.DEBUG)\n\t\t\t\t\treturn tracefunc\n\t\t\t\tsys.settrace(tracefunc)\n\n\t\telif args.action == 'list_configs':\n\t\t\tself.process_args(ShutItInit(args.action,\n\t\t\t                             logfile=args.logfile,\n\t\t\t                             nocolor=args.nocolor,\n\t\t\t                             history=args.history))\n\t\telif args.action == 'list_modules':\n\t\t\tself.process_args(ShutItInit(args.action,\n\t\t\t                             logfile=args.logfile,\n\t\t\t                             nocolor=args.nocolor,\n\t\t\t                             sort=args.sort,\n\t\t\t                             long_modules=args.long))", "response": "Parse command line arguments and return a list of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_deps(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tself.log('PHASE: dependencies', level=logging.DEBUG)\n\t\tself.pause_point('\\nNow checking for dependencies between modules', print_input=False, level=3)\n\t\t# Get modules we're going to build\n\t\tto_build = [\n\t\t\tself.shutit_map[module_id] for module_id in self.shutit_map\n\t\t\tif module_id in cfg and cfg[module_id]['shutit.core.module.build']\n\t\t]\n\t\t# Add any deps we may need by extending to_build and altering cfg\n\t\tfor module in to_build:\n\t\t\tself.resolve_dependencies(to_build, module)\n\n\t\t# Dep checking\n\t\tdef err_checker(errs, triples):\n\t\t\t\"\"\"Collate error information.\n\t\t\t\"\"\"\n\t\t\tnew_triples = []\n\t\t\tfor err, triple in zip(errs, triples):\n\t\t\t\tif not err:\n\t\t\t\t\tnew_triples.append(triple)\n\t\t\t\t\tcontinue\n\t\t\t\tfound_errs.append(err)\n\t\t\treturn new_triples\n\n\t\tfound_errs = []\n\t\ttriples    = []\n\t\tfor depender in to_build:\n\t\t\tfor dependee_id in depender.depends_on:\n\t\t\t\ttriples.append((depender, self.shutit_map.get(dependee_id), dependee_id))\n\n\t\ttriples = err_checker([ self.check_dependee_exists(depender, dependee, dependee_id) for depender, dependee, dependee_id in triples ], triples)\n\t\ttriples = err_checker([ self.check_dependee_build(depender, dependee, dependee_id) for depender, dependee, dependee_id in triples ], triples)\n\t\ttriples = err_checker([ check_dependee_order(depender, dependee, dependee_id) for depender, dependee, dependee_id in triples ], triples)\n\n\t\tif found_errs:\n\t\t\treturn [(err,) for err in found_errs]\n\n\t\tself.log('Modules configured to be built (in order) are: ', level=logging.DEBUG)\n\t\tfor module_id in self.module_ids():\n\t\t\tmodule = self.shutit_map[module_id]\n\t\t\tif cfg[module_id]['shutit.core.module.build']:\n\t\t\t\tself.log(module_id + '    ' + str(module.run_order), level=logging.DEBUG)\n\t\tself.log('\\n', level=logging.DEBUG)\n\n\t\treturn []", "response": "Check if dependencies between modules are present in the dependency tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_conflicts(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\t# Now consider conflicts\n\t\tself.log('PHASE: conflicts', level=logging.DEBUG)\n\t\terrs = []\n\t\tself.pause_point('\\nNow checking for conflicts between modules', print_input=False, level=3)\n\t\tfor module_id in self.module_ids():\n\t\t\tif not cfg[module_id]['shutit.core.module.build']:\n\t\t\t\tcontinue\n\t\t\tconflicter = self.shutit_map[module_id]\n\t\t\tfor conflictee in conflicter.conflicts_with:\n\t\t\t\t# If the module id isn't there, there's no problem.\n\t\t\t\tconflictee_obj = self.shutit_map.get(conflictee)\n\t\t\t\tif conflictee_obj is None:\n\t\t\t\t\tcontinue\n\t\t\t\tif ((cfg[conflicter.module_id]['shutit.core.module.build'] or\n\t\t\t\t     self.is_to_be_built_or_is_installed(conflicter)) and\n\t\t\t\t    (cfg[conflictee_obj.module_id]['shutit.core.module.build'] or\n\t\t\t\t     self.is_to_be_built_or_is_installed(conflictee_obj))):\n\t\t\t\t\terrs.append(('conflicter module id: ' + conflicter.module_id + ' is configured to be built or is already built but conflicts with module_id: ' + conflictee_obj.module_id,))\n\t\treturn errs", "response": "Checks for any conflicts between modules."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether all modules are ready to be built and if not then logs in and out.", "response": "def check_ready(self, throw_error=True):\n\t\t\"\"\"Check that all modules are ready to be built, calling check_ready on\n\t\teach of those configured to be built and not already installed\n\t\t(see shutit.is_installed).\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tself.log('PHASE: check_ready', level=logging.DEBUG)\n\t\terrs = []\n\t\tself.pause_point('\\nNow checking whether we are ready to build modules configured to be built', print_input=False, level=3)\n\t\t# Find out who we are to see whether we need to log in and out or not.\n\t\tfor module_id in self.module_ids():\n\t\t\tmodule = self.shutit_map[module_id]\n\t\t\tself.log('considering check_ready (is it ready to be built?): ' + module_id, level=logging.DEBUG)\n\t\t\tif cfg[module_id]['shutit.core.module.build'] and module.module_id not in self.get_current_shutit_pexpect_session_environment().modules_ready and not self.is_installed(module):\n\t\t\t\tself.log('checking whether module is ready to build: ' + module_id, level=logging.DEBUG)\n\t\t\t\tself.login(prompt_prefix=module_id,command=shutit_global.shutit_global_object.bash_startup_command,echo=False)\n\t\t\t\t# Move to the correct directory (eg for checking for the existence of files needed for build)\n\t\t\t\trevert_dir = os.getcwd()\n\t\t\t\tself.get_current_shutit_pexpect_session_environment().module_root_dir = os.path.dirname(self.shutit_file_map[module_id])\n\t\t\t\tself.chdir(self.get_current_shutit_pexpect_session_environment().module_root_dir)\n\t\t\t\tif not self.is_ready(module) and throw_error:\n\t\t\t\t\terrs.append((module_id + ' not ready to install.\\nRead the check_ready function in the module,\\nor log messages above to determine the issue.\\n\\n', self.get_shutit_pexpect_session_from_id('target_child')))\n\t\t\t\tself.logout(echo=False)\n\t\t\t\tself.chdir(revert_dir)\n\t\treturn errs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove modules by calling remove method on those configured for removal.", "response": "def do_remove(self, loglevel=logging.DEBUG):\n\t\t\"\"\"Remove modules by calling remove method on those configured for removal.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\t# Now get the run_order keys in order and go.\n\t\tself.log('PHASE: remove', level=loglevel)\n\t\tself.pause_point('\\nNow removing any modules that need removing', print_input=False, level=3)\n\t\t# Login at least once to get the exports.\n\t\tfor module_id in self.module_ids():\n\t\t\tmodule = self.shutit_map[module_id]\n\t\t\tself.log('considering whether to remove: ' + module_id, level=logging.DEBUG)\n\t\t\tif cfg[module_id]['shutit.core.module.remove']:\n\t\t\t\tself.log('removing: ' + module_id, level=logging.DEBUG)\n\t\t\t\tself.login(prompt_prefix=module_id,command=shutit_global.shutit_global_object.bash_startup_command,echo=False)\n\t\t\t\tif not module.remove(self):\n\t\t\t\t\tself.log(self.print_modules(), level=logging.DEBUG)\n\t\t\t\t\tself.fail(module_id + ' failed on remove', shutit_pexpect_child=self.get_shutit_pexpect_session_from_id('target_child').pexpect_child) # pragma: no cover\n\t\t\t\telse:\n\t\t\t\t\tif self.build['delivery'] in ('docker','dockerfile'):\n\t\t\t\t\t\t# Create a directory and files to indicate this has been removed.\n\t\t\t\t\t\tself.send(' command mkdir -p ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/module_record/' + module.module_id + ' && command rm -f ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/module_record/' + module.module_id + '/built && command touch ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/module_record/' + module.module_id + '/removed', loglevel=loglevel, echo=False)\n\t\t\t\t\t\t# Remove from \"installed\" cache\n\t\t\t\t\t\tif module.module_id in self.get_current_shutit_pexpect_session_environment().modules_installed:\n\t\t\t\t\t\t\tself.get_current_shutit_pexpect_session_environment().modules_installed.remove(module.module_id)\n\t\t\t\t\t\t# Add to \"not installed\" cache\n\t\t\t\t\t\tself.get_current_shutit_pexpect_session_environment().modules_not_installed.append(module.module_id)\n\t\t\t\tself.logout(echo=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning build phase, building any modules that we've determined need building.", "response": "def do_build(self):\n\t\t\"\"\"Runs build phase, building any modules that we've determined\n\t\tneed building.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\tself.log('PHASE: build, repository work', level=logging.DEBUG)\n\t\tmodule_id_list = self.module_ids()\n\t\tif self.build['deps_only']:\n\t\t\tmodule_id_list_build_only = filter(lambda x: cfg[x]['shutit.core.module.build'], module_id_list)\n\t\tfor module_id in module_id_list:\n\t\t\tmodule = self.shutit_map[module_id]\n\t\t\tself.log('Considering whether to build: ' + module.module_id, level=logging.INFO)\n\t\t\tif cfg[module.module_id]['shutit.core.module.build']:\n\t\t\t\tif self.build['delivery'] not in module.ok_delivery_methods:\n\t\t\t\t\tself.fail('Module: ' + module.module_id + ' can only be built with one of these --delivery methods: ' + str(module.ok_delivery_methods) + '\\nSee shutit build -h for more info, or try adding: --delivery <method> to your shutit invocation') # pragma: no cover\n\t\t\t\tif self.is_installed(module):\n\t\t\t\t\tself.build['report'] = (self.build['report'] + '\\nBuilt already: ' + module.module_id + ' with run order: ' + str(module.run_order))\n\t\t\t\telse:\n\t\t\t\t\t# We move to the module directory to perform the build, returning immediately afterwards.\n\t\t\t\t\tif self.build['deps_only'] and module_id == module_id_list_build_only[-1]:\n\t\t\t\t\t\t# If this is the last module, and we are only building deps, stop here.\n\t\t\t\t\t\tself.build['report'] = (self.build['report'] + '\\nSkipping: ' + module.module_id + ' with run order: ' + str(module.run_order) + '\\n\\tas this is the final module and we are building dependencies only')\n\t\t\t\t\telse:\n\t\t\t\t\t\trevert_dir = os.getcwd()\n\t\t\t\t\t\tself.get_current_shutit_pexpect_session_environment().module_root_dir = os.path.dirname(self.shutit_file_map[module_id])\n\t\t\t\t\t\tself.chdir(self.get_current_shutit_pexpect_session_environment().module_root_dir)\n\t\t\t\t\t\tself.login(prompt_prefix=module_id,command=shutit_global.shutit_global_object.bash_startup_command,echo=False)\n\t\t\t\t\t\tself.build_module(module)\n\t\t\t\t\t\tself.logout(echo=False)\n\t\t\t\t\t\tself.chdir(revert_dir)\n\t\t\tif self.is_installed(module):\n\t\t\t\tself.log('Starting module',level=logging.DEBUG)\n\t\t\t\tif not module.start(self):\n\t\t\t\t\tself.fail(module.module_id + ' failed on start', shutit_pexpect_child=self.get_shutit_pexpect_session_from_id('target_child').pexpect_child)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_finalize(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tdef _finalize(self):\n\t\t\t# Stop all the modules\n\t\t\tself.stop_all()\n\t\t\t# Finalize in reverse order\n\t\t\tself.log('PHASE: finalizing object ' + str(self), level=logging.DEBUG)\n\t\t\t# Login at least once to get the exports.\n\t\t\tfor module_id in self.module_ids(rev=True):\n\t\t\t\t# Only finalize if it's thought to be installed.\n\t\t\t\tif self.is_installed(self.shutit_map[module_id]):\n\t\t\t\t\tself.login(prompt_prefix=module_id,command=shutit_global.shutit_global_object.bash_startup_command,echo=False)\n\t\t\t\t\tif not self.shutit_map[module_id].finalize(self):\n\t\t\t\t\t\tself.fail(module_id + ' failed on finalize', shutit_pexpect_child=self.get_shutit_pexpect_session_from_id('target_child').pexpect_child) # pragma: no cover\n\t\t\t\t\tself.logout(echo=False)\n\t\t_finalize(self)", "response": "Runs finalize phase ; run after all builds are complete and all modules have been stopped and all modules have been installed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun stop method on all modules in the specified order.", "response": "def stop_all(self, run_order=-1):\n\t\t\"\"\"Runs stop method on all modules less than the passed-in run_order.\n\t\tUsed when target is exporting itself mid-build, so we clean up state\n\t\tbefore committing run files etc.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# sort them so they're stopped in reverse order\n\t\tfor module_id in self.module_ids(rev=True):\n\t\t\tshutit_module_obj = self.shutit_map[module_id]\n\t\t\tif run_order == -1 or shutit_module_obj.run_order <= run_order:\n\t\t\t\tif self.is_installed(shutit_module_obj):\n\t\t\t\t\tif not shutit_module_obj.stop(self):\n\t\t\t\t\t\tself.fail('failed to stop: ' + module_id, shutit_pexpect_child=self.get_shutit_pexpect_session_from_id('target_child').shutit_pexpect_child)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_all(self, run_order=-1):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# sort them so they're started in order\n\t\tfor module_id in self.module_ids():\n\t\t\tshutit_module_obj = self.shutit_map[module_id]\n\t\t\tif run_order == -1 or shutit_module_obj.run_order <= run_order:\n\t\t\t\tif self.is_installed(shutit_module_obj):\n\t\t\t\t\tif not shutit_module_obj.start(self):\n\t\t\t\t\t\tself.fail('failed to start: ' + module_id, shutit_pexpect_child=self.get_shutit_pexpect_session_from_id('target_child').shutit_pexpect_child)", "response": "Runs start method on all modules in the specified order."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns true if this module is ready to be built.", "response": "def is_ready(self, shutit_module_obj):\n\t\t\"\"\"Returns true if this module is ready to be built.\n\t\tCaches the result (as it's assumed not to change during the build).\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tif shutit_module_obj.module_id in self.get_current_shutit_pexpect_session_environment().modules_ready:\n\t\t\tself.log('is_ready: returning True from cache',level=logging.DEBUG)\n\t\t\treturn True\n\t\tready = shutit_module_obj.check_ready(self)\n\t\tif ready:\n\t\t\tself.get_current_shutit_pexpect_session_environment().modules_ready.append(shutit_module_obj.module_id)\n\t\t\treturn True\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_shutit_map(self):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tmodules = self.shutit_modules\n\t\t# Have we got anything to process outside of special modules?\n\t\tif len([mod for mod in modules if mod.run_order > 0]) < 1:\n\t\t\tself.log(modules,level=logging.DEBUG)\n\t\t\tpath = ':'.join(self.host['shutit_module_path'])\n\t\t\tself.log('\\nIf you are new to ShutIt, see:\\n\\n\\thttp://ianmiell.github.io/shutit/\\n\\nor try running\\n\\n\\tshutit skeleton\\n\\n',level=logging.INFO)\n\t\t\tif path == '':\n\t\t\t\tself.fail('No ShutIt modules aside from core ones found and no ShutIt module path given.\\nDid you set --shutit_module_path/-m wrongly?\\n') # pragma: no cover\n\t\t\telif path == '.':\n\t\t\t\tself.fail('No modules aside from core ones found and no ShutIt module path given apart from default (.).\\n\\n- Did you set --shutit_module_path/-m?\\n- Is there a STOP* file in your . dir?') # pragma: no cover\n\t\t\telse:\n\t\t\t\tself.fail('No modules aside from core ones found and no ShutIt modules in path:\\n\\n' + path + '\\n\\nor their subfolders. Check your --shutit_module_path/-m setting and check that there are ShutIt modules below without STOP* files in any relevant directories.') # pragma: no cover\n\n\t\tself.log('PHASE: base setup', level=logging.DEBUG)\n\n\t\trun_orders = {}\n\t\thas_core_module = False\n\t\tfor module in modules:\n\t\t\tassert isinstance(module, ShutItModule), shutit_util.print_debug()\n\t\t\tif module.module_id in self.shutit_map:\n\t\t\t\tself.fail('Duplicated module id: ' + module.module_id + '\\n\\nYou may want to check your --shutit_module_path setting') # pragma: no cover\n\t\t\tif module.run_order in run_orders:\n\t\t\t\tself.fail('Duplicate run order: ' + str(module.run_order) + ' for ' + module.module_id + ' and ' + run_orders[module.run_order].module_id + '\\n\\nYou may want to check your --shutit_module_path setting') # pragma: no cover\n\t\t\tif module.run_order == 0:\n\t\t\t\thas_core_module = True\n\t\t\tself.shutit_map[module.module_id] = run_orders[module.run_order] = module\n\t\t\tself.shutit_file_map[module.module_id] = get_module_file(self, module)\n\n\t\tif not has_core_module:\n\t\t\tself.fail('No module with run_order=0 specified! This is required.')", "response": "Initializes the module map of the modules that are not in the core modules."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the target.", "response": "def conn_target(self):\n\t\t\"\"\"Connect to the target.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tconn_module = None\n\t\tfor mod in self.conn_modules:\n\t\t\tif mod.module_id == self.build['conn_module']:\n\t\t\t\tconn_module = mod\n\t\t\t\tbreak\n\t\tif conn_module is None:\n\t\t\tself.fail('Couldn\\'t find conn_module ' + self.build['conn_module']) # pragma: no cover\n\n\t\t# Set up the target in pexpect.\n\t\tconn_module.get_config(self)\n\t\tconn_module.build(self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfinalize the target using the core finalize method.", "response": "def finalize_target(self):\n\t\t\"\"\"Finalize the target using the core finalize method.\n\t\t\"\"\"\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.pause_point('\\nFinalizing the target module (' + self.shutit_main_dir + '/shutit_setup.py)', print_input=False, level=3)\n\t\t# Can assume conn_module exists at this point\n\t\tfor mod in self.conn_modules:\n\t\t\tif mod.module_id == self.build['conn_module']:\n\t\t\t\tconn_module = mod\n\t\t\t\tbreak\n\t\tconn_module.finalize(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_dependencies(self, to_build, depender):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tself.log('In resolve_dependencies',level=logging.DEBUG)\n\t\tcfg = self.cfg\n\t\tfor dependee_id in depender.depends_on:\n\t\t\tdependee = self.shutit_map.get(dependee_id)\n\t\t\t# Don't care if module doesn't exist, we check this later\n\t\t\tif (dependee and dependee not in to_build\n\t\t\t    and cfg[dependee_id]['shutit.core.module.build_ifneeded']):\n\t\t\t\tto_build.append(dependee)\n\t\t\t\tcfg[dependee_id]['shutit.core.module.build'] = True\n\t\treturn True", "response": "Add any required dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_dependee_exists(self, depender, dependee, dependee_id):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\t# If the module id isn't there, there's a problem.\n\t\tif dependee is None:\n\t\t\treturn 'module: \\n\\n' + dependee_id + '\\n\\nnot found in paths: ' + str(self.host['shutit_module_path']) + ' but needed for ' + depender.module_id + '\\nCheck your --shutit_module_path setting and ensure that all modules configured to be built are in that path setting, eg \"--shutit_module_path /path/to/other/module/:.\"\\n\\nAlso check that the module is configured to be built with the correct module id in that module\\'s configs/build.cnf file.\\n\\nSee also help.'\n\t\treturn ''", "response": "Checks whether a depended - on module exists in the paths of the module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_dependee_build(self, depender, dependee, dependee_id):\n\t\tshutit_global.shutit_global_object.yield_to_draw()\n\t\tcfg = self.cfg\n\t\t# If depender is installed or will be installed, so must the dependee\n\t\tif not (cfg[dependee.module_id]['shutit.core.module.build'] or\n\t\t        self.is_to_be_built_or_is_installed(dependee)):\n\t\t\treturn 'depender module id:\\n\\n[' + depender.module_id + ']\\n\\nis configured: \"build:yes\" or is already built but dependee module_id:\\n\\n[' + dependee_id + ']\\n\\n is not configured: \"build:yes\"'\n\t\treturn ''", "response": "Checks whether a depended on module is configured to be built."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfinish up a session.", "response": "def destroy(self):\n\t\t\"\"\"Finish up a session.\n\t\t\"\"\"\n\t\tif self.session_type == 'bash':\n\t\t\t# TODO: does this work/handle already being logged out/logged in deep OK?\n\t\t\tself.logout()\n\t\telif self.session_type == 'vagrant':\n\t\t\t# TODO: does this work/handle already being logged out/logged in deep OK?\n\t\t\tself.logout()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shutit_method_scope(func):\n\tdef wrapper(self, shutit):\n\t\t\"\"\"Wrapper to call a shutit module method, notifying the ShutIt object.\n\t\t\"\"\"\n\t\tret = func(self, shutit)\n\t\treturn ret\n\treturn wrapper", "response": "Decorator to notify ShutIt object whenever we call a function in the scope of a function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping a package to a specific install type.", "response": "def map_package(shutit_pexpect_session, package, install_type):\n\t\"\"\"If package mapping exists, then return it, else return package.\n\t\"\"\"\n\tif package in PACKAGE_MAP.keys():\n\t\tfor itype in PACKAGE_MAP[package].keys():\n\t\t\tif itype == install_type:\n\t\t\t\tret = PACKAGE_MAP[package][install_type]\n\t\t\t\tif isinstance(ret,str):\n\t\t\t\t\treturn ret\n\t\t\t\tif callable(ret):\n\t\t\t\t\tret(shutit_pexpect_session)\n\t\t\t\t\treturn ''\n\t# Otherwise, simply return package\n\treturn package"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_file_secure(file_name):\n\tif not os.path.isfile(file_name):\n\t\treturn True\n\tfile_mode = os.stat(file_name).st_mode\n\tif file_mode & (stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IWOTH | stat.S_IXOTH):\n\t\treturn False\n\treturn True", "response": "Returns false if file is considered insecure true if secure.\n\tIf file doesn t exist it s considered secure!"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a random string of given size from the given chars.", "response": "def random_id(size=8, chars=string.ascii_letters + string.digits):\n\t\"\"\"Generates a random string of given size from the given chars.\n\n\t@param size:  The size of the random string.\n\t@param chars: Constituent pool of characters to draw random characters from.\n\t@type size:   number\n\t@type chars:  string\n\t@rtype:       string\n\t@return:      The string of random characters.\n\t\"\"\"\n\treturn ''.join(random.choice(chars) for _ in range(size))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random word in lower case.", "response": "def random_word(size=6):\n\t\"\"\"Returns a random word in lower case.\n\t\"\"\"\n\twords = shutit_assets.get_words().splitlines()\n\tword = ''\n\twhile len(word) != size or \"'\" in word:\n\t\tword = words[int(random.random() * (len(words) - 1))]\n\treturn word.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef util_raw_input(prompt='', default=None, ispass=False, use_readline=True):\n\tif use_readline:\n\t\ttry:\n\t\t\treadline.read_init_file('/etc/inputrc')\n\t\texcept IOError:\n\t\t\tpass\n\t\treadline.parse_and_bind('tab: complete')\n\tprompt = '\\r\\n' + prompt\n\tif ispass:\n\t\tprompt += '\\r\\nInput Secret: '\n\tsanitize_terminal()\n\tif shutit_global.shutit_global_object.interactive == 0:\n\t\treturn default\n\t## See: https//github.com/ianmiell/shutit/issues/299 - python3 made input == python 2's raw_input\n\t#if not shutit_global.shutit_global_object.ispy3:\n\t#\tinput = raw_input\n\t#try:\n\t#\tinput\n\t#except NameError:\n\t#\tshutit_global.shutit_global_object.shutit_print('input not available, printing debug')\n\t#\tprint_debug()\n\t#\tsys.exit(1)\n\tif not shutit_global.shutit_global_object.determine_interactive():\n\t\treturn default\n\twhile True:\n\t\ttry:\n\t\t\tif ispass:\n\t\t\t\treturn getpass.getpass(prompt=prompt)\n\t\t\telse:\n\t\t\t\treturn input(prompt).strip() or default\n\t\texcept KeyboardInterrupt:\n\t\t\tcontinue\n\t\texcept IOError:\n\t\t\tmsg = 'Problems getting raw input, assuming no controlling terminal.'\n\tif ispass:\n\t\treturn getpass.getpass(prompt=prompt)\n\telse:\n\t\treturn input(prompt).strip() or default\n\tshutit_global.shutit_global_object.set_noninteractive(msg=msg)\n\treturn default", "response": "Handles raw_input calls and switches off interactivity if there is apparently\n\tno controlling terminal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_input(msg, default='', valid=None, boolean=False, ispass=False, color=None):\n\t# switch off log tracing when in get_input\n\tlog_trace_when_idle_original_value = shutit_global.shutit_global_object.log_trace_when_idle\n\tshutit_global.shutit_global_object.log_trace_when_idle = False\n\tif boolean and valid is None:\n\t\tvalid = ('yes','y','Y','1','true','no','n','N','0','false')\n\tif color:\n\t\tanswer = util_raw_input(prompt=colorise(color,msg),ispass=ispass)\n\telse:\n\t\tanswer = util_raw_input(msg,ispass=ispass)\n\tif boolean and answer in ('', None) and default != '':\n\t\t# Revert log trace value to original\n\t\tshutit_global.shutit_global_object.log_trace_when_idle = log_trace_when_idle_original_value\n\t\treturn default\n\tif valid is not None:\n\t\twhile answer not in valid:\n\t\t\tshutit_global.shutit_global_object.shutit_print('Answer must be one of: ' + str(valid),transient=True)\n\t\t\tif color:\n\t\t\t\tanswer = util_raw_input(prompt=colorise(color,msg),ispass=ispass)\n\t\t\telse:\n\t\t\t\tanswer = util_raw_input(msg,ispass=ispass)\n\tif boolean:\n\t\tif answer.lower() in ('yes','y','1','true','t'):\n\t\t\t# Revert log trace value to original\n\t\t\tshutit_global.shutit_global_object.log_trace_when_idle = log_trace_when_idle_original_value\n\t\t\treturn True\n\t\telif answer.lower() in ('no','n','0','false','f'):\n\t\t\t# Revert log trace value to original\n\t\t\tshutit_global.shutit_global_object.log_trace_when_idle = log_trace_when_idle_original_value\n\t\t\treturn False\n\t# Revert log trace value to original\n\tshutit_global.shutit_global_object.log_trace_when_idle = log_trace_when_idle_original_value\n\treturn answer or default", "response": "Gets input from the user and returns the answer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting up the target ready for building.", "response": "def build(self, shutit):\n\t\t\"\"\"Sets up the target ready for building.\n\t\t\"\"\"\n\t\ttarget_child = self.start_container(shutit, 'target_child')\n\t\tself.setup_host_child(shutit)\n\t\t# TODO: on the host child, check that the image running has bash as its cmd/entrypoint.\n\t\tself.setup_target_child(shutit, target_child)\n\t\tshutit.send('chmod -R 777 ' + shutit_global.shutit_global_object.shutit_state_dir + ' && mkdir -p ' + shutit_global.shutit_global_object.shutit_state_dir_build_db_dir + '/' + shutit_global.shutit_global_object.build_id, shutit_pexpect_child=target_child, echo=False)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinalizes the target and exits the shell.", "response": "def finalize(self, shutit):\n\t\t\"\"\"Finalizes the target, exiting for us back to the original shell\n\t\tand performing any repository work required.\n\t\t\"\"\"\n\t\t# Finish with the target\n\t\ttarget_child_pexpect_session = shutit.get_shutit_pexpect_session_from_id('target_child')\n\t\tassert not target_child_pexpect_session.sendline(ShutItSendSpec(target_child_pexpect_session,'exit',ignore_background=True)), shutit_util.print_debug()\n\t\thost_child_pexpect_session = shutit.get_shutit_pexpect_session_from_id('host_child')\n\t\thost_child = host_child_pexpect_session.pexpect_child\n\t\tshutit.set_default_shutit_pexpect_session(host_child_pexpect_session)\n\t\tshutit.set_default_shutit_pexpect_session_expect(shutit.expect_prompts['ORIGIN_ENV'])\n\t\tshutit.do_repository_work(shutit.repository['name'], docker_executable=shutit.host['docker_executable'], password=shutit.host['password'])\n\t\t# Final exits\n\t\thost_child.sendline('rm -f ' + shutit.build['cidfile']) # Ignore response, just send.\n\t\thost_child.sendline('exit') # Exit raw bash. Ignore response, just send.\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(self, shutit):\n\t\tshutit_pexpect_session = ShutItPexpectSession(shutit, 'target_child','/bin/bash')\n\t\ttarget_child = shutit_pexpect_session.pexpect_child\n\t\tshutit_pexpect_session.expect(shutit_global.shutit_global_object.base_prompt.strip(), timeout=10)\n\t\tself.setup_host_child(shutit)\n\t\tself.setup_target_child(shutit, target_child)\n\t\treturn True", "response": "Sets up the machine ready for building."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef finalize(self, shutit):\n\t\t# Finish with the target\n\t\ttarget_child_pexpect_session = shutit.get_shutit_pexpect_session_from_id('target_child')\n\t\tassert not target_child_pexpect_session.sendline(ShutItSendSpec(target_child_pexpect_session,'exit',ignore_background=True)), shutit_util.print_debug()\n\t\treturn True", "response": "Finalizes the target exiting for us back to the original shell\n\t and performing any repository work required."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build(self, shutit):\n\t\tif shutit.build['delivery'] in ('docker','dockerfile'):\n\t\t\tif shutit.get_current_shutit_pexpect_session_environment().install_type == 'apt':\n\t\t\t\tshutit.add_to_bashrc('export DEBIAN_FRONTEND=noninteractive')\n\t\t\t\tif not shutit.command_available('lsb_release'):\n\t\t\t\t\tshutit.install('lsb-release')\n\t\t\t\tshutit.lsb_release()\n\t\t\telif shutit.get_current_shutit_pexpect_session_environment().install_type == 'yum':\n\t\t\t\t# yum updates are so often \"bad\" that we let exit codes of 1 through.\n\t\t\t\t# TODO: make this more sophisticated\n\t\t\t\tshutit.send('yum update -y', timeout=9999, exit_values=['0', '1'])\n\t\t\tshutit.pause_point('Anything you want to do to the target host ' + 'before the build starts?', level=2)\n\t\treturn True", "response": "Initializes target ready for build and updating package management if in container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __set_config(self, cfg_section):\n\t\tdefaults = [\n\t\t\t'shutit.core.alerting.emailer.mailto', None,\n\t\t\t'shutit.core.alerting.emailer.mailfrom', 'angry@shutit.tk',\n\t\t\t'shutit.core.alerting.emailer.smtp_server', 'localhost',\n\t\t\t'shutit.core.alerting.emailer.smtp_port', 25,\n\t\t\t'shutit.core.alerting.emailer.use_tls', True,\n\t\t\t'shutit.core.alerting.emailer.send_mail', True,\n\t\t\t'shutit.core.alerting.emailer.subject', 'Shutit Report',\n\t\t\t'shutit.core.alerting.emailer.signature', '--Angry Shutit',\n\t\t\t'shutit.core.alerting.emailer.compress', True,\n\t\t\t'shutit.core.alerting.emailer.username', '',\n\t\t\t'shutit.core.alerting.emailer.password', '',\n\t\t\t'shutit.core.alerting.emailer.safe_mode', True,\n\t\t\t'shutit.core.alerting.emailer.maintainer','',\n\t\t\t'shutit.core.alerting.emailer.mailto_maintainer', True\n\t\t]\n\n\t\tfor cfg_name, cfg_default in zip(defaults[0::2], defaults[1::2]):\n\t\t\ttry:\n\t\t\t\tself.config[cfg_name] = self.shutit.cfg[cfg_section][cfg_name]\n\t\t\texcept KeyError:\n\t\t\t\tif cfg_default is None:\n\t\t\t\t\traise Exception(cfg_section + ' ' + cfg_name + ' must be set')\n\t\t\t\telse:\n\t\t\t\t\tself.config[cfg_name] = cfg_default\n\n\t\t# only send a mail to the module's maintainer if configured correctly\n\t\tif self.config['shutit.core.alerting.emailer.mailto_maintainer'] and \\\n\t\t\t(self.config['shutit.core.alerting.emailer.maintainer'] == \"\" or \\\n\t\t\tself.config['shutit.core.alerting.emailer.maintainer'] == self.config['shutit.core.alerting.emailer.mailto']):\n\t\t\tself.config['shutit.core.alerting.emailer.mailto_maintainer'] = False\n\t\t\tself.config['shutit.core.alerting.emailer.maintainer'] = \"\"", "response": "Set a local config array up according to the main shutit configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompresses a file returning the new filename. gz", "response": "def __gzip(filename):\n\t\t\"\"\" Compress a file returning the new filename (.gz)\n\t\t\"\"\"\n\t\tzipname = filename + '.gz'\n\t\tfile_pointer = open(filename,'rb')\n\t\tzip_pointer = gzip.open(zipname,'wb')\n\t\tzip_pointer.writelines(file_pointer)\n\t\tfile_pointer.close()\n\t\tzip_pointer.close()\n\t\treturn zipname"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the appropraite smtplib depending on wherther we re using TLS", "response": "def __get_smtp(self):\n\t\t\"\"\" Return the appropraite smtplib depending on wherther we're using TLS\n\t\t\"\"\"\n\t\tuse_tls = self.config['shutit.core.alerting.emailer.use_tls']\n\t\tif use_tls:\n\t\t\tsmtp = SMTP(self.config['shutit.core.alerting.emailer.smtp_server'], self.config['shutit.core.alerting.emailer.smtp_port'])\n\t\t\tsmtp.starttls()\n\t\telse:\n\t\t\tsmtp = SMTP_SSL(self.config['shutit.core.alerting.emailer.smtp_server'], self.config['shutit.core.alerting.emailer.smtp_port'])\n\t\treturn smtp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattaching a file to the target host.", "response": "def attach(self, filename, filetype=\"txt\"):\n\t\t\"\"\"Attach a file - currently needs to be entered as root (shutit)\n\n\t\tFilename - absolute path, relative to the target host!\n\t\tfiletype - MIMEApplication._subtype\n\t\t\"\"\"\n\t\tshutit = self.shutit\n\t\thost_path = '/tmp'\n\t\thost_fn = shutit.get_file(filename, host_path)\n\t\tif self.config['shutit.core.alerting.emailer.compress']:\n\t\t\tfiletype = 'x-gzip-compressed'\n\t\t\tfilename = self.__gzip(host_fn)\n\t\t\thost_fn = os.path.join(host_path, os.path.basename(filename))\n\t\tfile_pointer = open(host_fn, 'rb')\n\t\tattach = MIMEApplication(file_pointer.read(), _subtype=filetype)\n\t\tfile_pointer.close()\n\t\tattach.add_header('Content-Disposition', 'attachment', filename=os.path.basename(filename))\n\t\tself.attaches.append(attach)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompose the message pulling together body and attachments etc.", "response": "def __compose(self):\n\t\t\"\"\" Compose the message, pulling together body, attachments etc\n\t\t\"\"\"\n\t\tmsg  = MIMEMultipart()\n\t\tmsg['Subject'] = self.config['shutit.core.alerting.emailer.subject']\n\t\tmsg['To']      = self.config['shutit.core.alerting.emailer.mailto']\n\t\tmsg['From']    = self.config['shutit.core.alerting.emailer.mailfrom']\n\t\t# add the module's maintainer as a CC if configured\n\t\tif self.config['shutit.core.alerting.emailer.mailto_maintainer']:\n\t\t\tmsg['Cc'] = self.config['shutit.core.alerting.emailer.maintainer']\n\t\tif self.config['shutit.core.alerting.emailer.signature'] != '':\n\t\t\tsignature = '\\n\\n' + self.config['shutit.core.alerting.emailer.signature']\n\t\telse:\n\t\t\tsignature = self.config['shutit.core.alerting.emailer.signature']\n\t\tbody = MIMEText('\\n'.join(self.lines) + signature)\n\t\tmsg.attach(body)\n\t\tfor attach in self.attaches:\n\t\t\tmsg.attach(attach)\n\t\treturn msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, attachment_failure=False):\n\t\tif not self.config['shutit.core.alerting.emailer.send_mail']:\n\t\t\tself.shutit.log('emailer.send: Not configured to send mail!',level=logging.INFO)\n\t\t\treturn True\n\t\tmsg = self.__compose()\n\t\tmailto = [self.config['shutit.core.alerting.emailer.mailto']]\n\t\tsmtp = self.__get_smtp()\n\t\tif self.config['shutit.core.alerting.emailer.username'] != '':\n\t\t\tsmtp.login(self.config['shutit.core.alerting.emailer.username'], self.config['shutit.core.alerting.emailer.password'])\n\t\tif self.config['shutit.core.alerting.emailer.mailto_maintainer']:\n\t\t\tmailto.append(self.config['shutit.core.alerting.emailer.maintainer'])\n\t\ttry:\n\t\t\tself.shutit.log('Attempting to send email',level=logging.INFO)\n\t\t\tsmtp.sendmail(self.config['shutit.core.alerting.emailer.mailfrom'], mailto, msg.as_string())\n\t\texcept SMTPSenderRefused as refused:\n\t\t\tcode = refused.args[0]\n\t\t\tif code == 552 and not attachment_failure:\n\t\t\t\tself.shutit.log(\"Mailserver rejected message due to \" + \"oversize attachments, attempting to resend without\",level=logging.INFO)\n\t\t\t\tself.attaches = []\n\t\t\t\tself.lines.append(\"Oversized attachments not sent\")\n\t\t\t\tself.send(attachment_failure=True)\n\t\t\telse:\n\t\t\t\tself.shutit.log(\"Unhandled SMTP error:\" + str(refused),level=logging.INFO)\n\t\t\t\tif not self.config['shutit.core.alerting.emailer.safe_mode']:\n\t\t\t\t\traise refused\n\t\texcept Exception as error:\n\t\t\tself.shutit.log('Unhandled exception: ' + str(error),level=logging.INFO)\n\t\t\tif not self.config['shutit.core.alerting.emailer.safe_mode']:\n\t\t\t\traise error\n\t\tfinally:\n\t\t\tsmtp.quit()", "response": "Send the email according to the configured setup\n\t\t  "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets up the signal handlers.", "response": "def setup_signals():\n\t\"\"\"Set up the signal handlers.\n\t\"\"\"\n\tsignal.signal(signal.SIGINT, shutit_util.ctrl_c_signal_handler)\n\tsignal.signal(signal.SIGQUIT, shutit_util.ctrl_quit_signal_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all the shutit_pexpect sessions in existence.", "response": "def get_shutit_pexpect_sessions():\n\t\"\"\"Returns all the shutit_pexpect sessions in existence.\n\t\"\"\"\n\tsessions = []\n\tfor shutit_object in shutit_global_object.shutit_objects:\n\t\tfor key in shutit_object.shutit_pexpect_sessions:\n\t\t\tsessions.append(shutit_object.shutit_pexpect_sessions[key])\n\treturn sessions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef determine_interactive(self):\n\t\ttry:\n\t\t\tif not sys.stdout.isatty() or os.getpgrp() != os.tcgetpgrp(sys.stdout.fileno()):\n\t\t\t\tself.interactive = 0\n\t\t\t\treturn False\n\t\texcept Exception:\n\t\t\tself.interactive = 0\n\t\t\treturn False\n\t\tif self.interactive == 0:\n\t\t\treturn False\n\t\treturn True", "response": "Determine whether we re in an interactive shell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new session.", "response": "def create_session(docker_image=None,\n                   docker_rm=None,\n                   echo=False,\n                   loglevel='WARNING',\n                   nocolor=False,\n                   session_type='bash',\n                   vagrant_session_name=None,\n                   vagrant_image='ubuntu/xenial64',\n                   vagrant_gui=False,\n                   vagrant_memory='1024',\n                   vagrant_num_machines='1',\n                   vagrant_provider='virtualbox',\n                   vagrant_root_folder=None,\n                   vagrant_swapsize='2G',\n                   vagrant_version='1.8.6',\n                   vagrant_virt_method='virtualbox',\n                   vagrant_cpu='1',\n                   video=-1,\n                   walkthrough=False):\n\t\"\"\"Creates a distinct ShutIt session. Sessions can be of type:\n\n\tbash    - a bash shell is spawned and\n\tvagrant - a Vagrantfile is created and 'vagrant up'ped\n\t\"\"\"\n\tassert session_type in ('bash','docker','vagrant'), shutit_util.print_debug()\n\tshutit_global_object = shutit_global.shutit_global_object\n\tif video != -1 and video > 0:\n\t\twalkthrough = True\n\tif session_type in ('bash','docker'):\n\t\treturn shutit_global_object.create_session(session_type,\n\t\t                                           docker_image=docker_image,\n\t\t                                           rm=docker_rm,\n\t\t                                           echo=echo,\n\t\t                                           walkthrough=walkthrough,\n\t\t                                           walkthrough_wait=video,\n\t\t                                           nocolor=nocolor,\n\t\t                                           loglevel=loglevel)\n\telif session_type == 'vagrant':\n\t\tif vagrant_session_name is None:\n\t\t\tvagrant_session_name = 'shutit' + shutit_util.random_id()\n\t\tif isinstance(vagrant_num_machines, int):\n\t\t\tvagrant_num_machines = str(vagrant_num_machines)\n\t\tassert isinstance(vagrant_num_machines, str)\n\t\tassert isinstance(int(vagrant_num_machines), int)\n\t\tif vagrant_root_folder is None:\n\t\t\tvagrant_root_folder = shutit_global.shutit_global_object.owd\n\t\treturn create_session_vagrant(vagrant_session_name,\n\t\t                              vagrant_num_machines,\n\t\t                              vagrant_image,\n\t\t                              vagrant_provider,\n\t\t                              vagrant_gui,\n\t\t                              vagrant_memory,\n\t\t                              vagrant_swapsize,\n\t\t                              echo,\n\t\t                              walkthrough,\n\t\t                              nocolor,\n\t\t                              video,\n\t\t                              vagrant_version,\n\t\t                              vagrant_virt_method,\n\t\t                              vagrant_root_folder,\n\t\t                              vagrant_cpu,\n\t\t                              loglevel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a skeleton module based on a pattern supplied as a git repo.", "response": "def create_skeleton(shutit):\n\t\"\"\"Creates module based on a pattern supplied as a git repo.\n\t\"\"\"\n\tskel_path        = shutit.cfg['skeleton']['path']\n\tskel_module_name = shutit.cfg['skeleton']['module_name']\n\tskel_domain      = shutit.cfg['skeleton']['domain']\n\tskel_domain_hash = shutit.cfg['skeleton']['domain_hash']\n\tskel_depends     = shutit.cfg['skeleton']['depends']\n\tskel_shutitfiles = shutit.cfg['skeleton']['shutitfiles']\n\tskel_delivery    = shutit.cfg['skeleton']['delivery']\n\tskel_pattern     = shutit.cfg['skeleton']['pattern']\n\t# For vagrant only\n\tskel_vagrant_num_machines   = shutit.cfg['skeleton']['vagrant_num_machines']\n\tskel_vagrant_machine_prefix = shutit.cfg['skeleton']['vagrant_machine_prefix']\n\tskel_vagrant_ssh_access     = shutit.cfg['skeleton']['vagrant_ssh_access']\n\tskel_vagrant_docker         = shutit.cfg['skeleton']['vagrant_docker']\n\tskel_vagrant_snapshot       = shutit.cfg['skeleton']['vagrant_snapshot']\n\tskel_vagrant_upload         = shutit.cfg['skeleton']['vagrant_upload']\n\tskel_vagrant_image_name     = shutit.cfg['skeleton']['vagrant_image_name']\n\n\t# Check setup\n\tif not skel_path or skel_path[0] != '/':\n\t\tshutit.fail('Must supply a directory and it must be absolute') # pragma: no cover\n\tif os.path.exists(skel_path):\n\t\tshutit.fail(skel_path + ' already exists') # pragma: no cover\n\tif not skel_module_name:\n\t\tshutit.fail('Must supply a name for your module, eg mymodulename') # pragma: no cover\n\tif not re.match('^[a-zA-z_][0-9a-zA-Z_]+$', skel_module_name):\n\t\tshutit.fail('Module names must comply with python classname standards: cf: http://stackoverflow.com/questions/10120295/valid-characters-in-a-python-class-name name: ' + skel_module_name) # pragma: no cover\n\tif not skel_domain:\n\t\tshutit.fail('Must supply a domain for your module, eg com.yourname.madeupdomainsuffix') # pragma: no cover\n\n\t# Create folders and process pattern\n\tos.makedirs(skel_path)\n\tos.chdir(skel_path)\n\t# If it's shutitfile and vagrant\n\tif shutit.cfg['skeleton']['pattern'] == 'bash':\n\t\tfrom shutit_patterns import bash\n\t\tbash.setup_bash_pattern(shutit,\n\t\t                        skel_path=skel_path,\n\t\t                        skel_delivery=skel_delivery,\n\t\t                        skel_domain=skel_domain,\n\t\t                        skel_module_name=skel_module_name,\n\t\t                        skel_shutitfiles=skel_shutitfiles,\n\t\t                        skel_domain_hash=skel_domain_hash,\n\t\t                        skel_depends=skel_depends)\n\telif shutit.cfg['skeleton']['pattern'] == 'docker':\n\t\tfrom shutit_patterns import docker\n\t\tdocker.setup_docker_pattern(shutit,\n\t\t                            skel_path=skel_path,\n\t\t                            skel_delivery=skel_delivery,\n\t\t                            skel_domain=skel_domain,\n\t\t                            skel_module_name=skel_module_name,\n\t\t                            skel_shutitfiles=skel_shutitfiles,\n\t\t                            skel_domain_hash=skel_domain_hash,\n\t\t                            skel_depends=skel_depends)\n\telif shutit.cfg['skeleton']['pattern'] == 'vagrant': # pragma: no cover\n\t\tfrom shutit_patterns import vagrant\n\t\tvagrant.setup_vagrant_pattern(shutit,\n\t\t                              skel_path=skel_path,\n\t\t                              skel_delivery=skel_delivery,\n\t\t                              skel_domain=skel_domain,\n\t\t                              skel_module_name=skel_module_name,\n\t\t                              skel_shutitfiles=skel_shutitfiles,\n\t\t                              skel_domain_hash=skel_domain_hash,\n\t\t                              skel_depends=skel_depends,\n\t\t                              skel_vagrant_num_machines=skel_vagrant_num_machines,\n\t\t                              skel_vagrant_machine_prefix=skel_vagrant_machine_prefix,\n\t\t                              skel_vagrant_ssh_access=skel_vagrant_ssh_access,\n\t\t                              skel_vagrant_docker=skel_vagrant_docker,\n\t\t                              skel_vagrant_snapshot=skel_vagrant_snapshot,\n\t\t                              skel_vagrant_upload=skel_vagrant_upload,\n\t\t                              skel_vagrant_image_name=skel_vagrant_image_name)\n\telif shutit.cfg['skeleton']['pattern'] == 'shutitfile':\n\t\tshutitfile.setup_shutitfile_pattern(shutit,\n\t\t                                    skel_path=skel_path,\n\t\t                                    skel_delivery=skel_delivery,\n\t\t                                    skel_pattern=skel_pattern,\n\t\t                                    skel_domain=skel_domain,\n\t\t                                    skel_module_name=skel_module_name,\n\t\t                                    skel_vagrant_num_machines=skel_vagrant_num_machines,\n\t\t                                    skel_vagrant_machine_prefix=skel_vagrant_machine_prefix,\n\t\t                                    skel_vagrant_ssh_access=skel_vagrant_ssh_access,\n\t\t                                    skel_vagrant_docker=skel_vagrant_docker)\n\telif shutit.cfg['skeleton']['pattern'] == 'docker_tutorial': # pragma: no cover\n\t\tshutit.fail('docker_tutorial not yet supported')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_blocking_background_send(self):\n\t\tfor background_object in self.background_objects:\n\t\t\t# If it's running, or not started yet, it should block other tasks.\n\t\t\tif background_object.block_other_commands and background_object.run_state in ('S','N'):\n\t\t\t\tself.shutit_obj.log('All objects are: ' + str(self),level=logging.DEBUG)\n\t\t\t\tself.shutit_obj.log('The current blocking send object is: ' + str(background_object),level=logging.DEBUG)\n\t\t\t\treturn True\n\t\t\telif background_object.block_other_commands and background_object.run_state in ('F','C','T'):\n\t\t\t\tassert False, shutit_util.print_debug(msg='Blocking command should have been removed, in run_state: ' + background_object.run_state)\n\t\t\telse:\n\t\t\t\tassert background_object.block_other_commands is False, shutit_util.print_debug()\n\t\treturn False", "response": "Check whether any blocking background commands are waiting to be sent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether any background commands are running or to be run.", "response": "def check_background_commands_complete(self):\n\t\t\"\"\"Check whether any background commands are running or to be run.\n\t\tIf none are, return True. If any are, return False.\n\t\t\"\"\"\n\t\tunstarted_command_exists  = False\n\t\tself.shutit_obj.log('In check_background_commands_complete: all background objects: ' + str(self.background_objects),level=logging.DEBUG)\n\t\tself.shutit_obj.log('Login id: ' + str(self.login_id),level=logging.DEBUG)\n\t\tfor background_object in self.background_objects:\n\t\t\tself.shutit_obj.log('Background object send: ' + str(background_object.sendspec.send),level=logging.DEBUG)\n\t\tbackground_objects_to_remove = []\n\t\tdef remove_background_objects(a_background_objects_to_remove):\n\t\t\tfor background_object in a_background_objects_to_remove:\n\t\t\t\tself.background_objects.remove(background_object)\n\t\tfor background_object in self.background_objects:\n\t\t\tself.shutit_obj.log('Checking background object: ' + str(background_object),level=logging.DEBUG)\n\t\t\tstate = background_object.check_background_command_state()\n\t\t\tself.shutit_obj.log('State is: ' + state,level=logging.DEBUG)\n\t\t\tif state in ('C','F','T'):\n\t\t\t\tbackground_objects_to_remove.append(background_object)\n\t\t\t\tself.background_objects_completed.append(background_object)\n\t\t\telif state == 'S':\n\t\t\t\t# Running command exists\n\t\t\t\tself.shutit_obj.log('check_background_command_state returning False (S) for ' + str(background_object),level=logging.DEBUG)\n\t\t\t\tremove_background_objects(background_objects_to_remove)\n\t\t\t\treturn False, 'S', background_object\n\t\t\telif state == 'N':\n\t\t\t\tself.shutit_obj.log('UNSTARTED COMMAND! ' + str(background_object.sendspec.send),level=logging.DEBUG)\n\t\t\t\tunstarted_command_exists = True\n\t\t\telse:\n\t\t\t\tremove_background_objects(background_objects_to_remove)\n\t\t\t\tassert False, shutit_util.print_debug(msg='Un-handled: ' + state)\n\t\t\tif state == 'F':\n\t\t\t\tself.shutit_obj.log('check_background_command_state returning False (F) for ' + str(background_object),level=logging.DEBUG)\n\t\t\t\tremove_background_objects(background_objects_to_remove)\n\t\t\t\treturn False, 'F', background_object\n\t\tremove_background_objects(background_objects_to_remove)\n\t\tself.shutit_obj.log('Checking background objects done.',level=logging.DEBUG)\n\t\tif unstarted_command_exists:\n\t\t\t# Start up an unstarted one (in order), and return False\n\t\t\tfor background_object in self.background_objects:\n\t\t\t\tstate = background_object.check_background_command_state()\n\t\t\t\tif state == 'N':\n\t\t\t\t\tbackground_object.run_background_command()\n\t\t\t\t\tself.shutit_obj.log('check_background_command_state returning False (N) for ' + str(background_object),level=logging.DEBUG)\n\t\t\t\t\treturn False, 'N', background_object\n\t\t# Nothing left to do - return True.\n\t\tself.shutit_obj.log('check_background_command_state returning True (OK)',level=logging.DEBUG)\n\t\treturn True, 'OK', None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_remote(cls, username, password, multifactor_password=None, client_id=None):\n        blob = cls.fetch_blob(username, password, multifactor_password, client_id)\n        return cls.open(blob, username, password)", "response": "Fetches a blob from the server and creates a vault"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a vault from a blob object", "response": "def open(cls, blob, username, password):\n        \"\"\"Creates a vault from a blob object\"\"\"\n        return cls(blob, blob.encryption_key(username, password))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_blob(cls, username, password, multifactor_password=None, client_id=None):\n        session = fetcher.login(username, password, multifactor_password, client_id)\n        blob = fetcher.fetch(session)\n        fetcher.logout(session)\n\n        return blob", "response": "Fetch the blob from the server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting the blob into chucks grouped by kind.", "response": "def extract_chunks(blob):\n    \"\"\"Splits the blob into chucks grouped by kind.\"\"\"\n    chunks = []\n    stream = BytesIO(blob.bytes)\n    current_pos = stream.tell()\n    stream.seek(0, 2)\n    length = stream.tell()\n    stream.seek(current_pos, 0)\n    while stream.tell() < length:\n        chunks.append(read_chunk(stream))\n\n    return chunks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_ACCT(chunk, encryption_key):\n    # TODO: Make a test case that covers secure note account\n\n    io = BytesIO(chunk.payload)\n    id = read_item(io)\n    name = decode_aes256_plain_auto(read_item(io), encryption_key)\n    group = decode_aes256_plain_auto(read_item(io), encryption_key)\n    url = decode_hex(read_item(io))\n    notes = decode_aes256_plain_auto(read_item(io), encryption_key)\n    skip_item(io, 2)\n    username = decode_aes256_plain_auto(read_item(io), encryption_key)\n    password = decode_aes256_plain_auto(read_item(io), encryption_key)\n    skip_item(io, 2)\n    secure_note = read_item(io)\n\n    # Parse secure note\n    if secure_note == b'1':\n        parsed = parse_secure_note_server(notes)\n\n        if parsed.get('type') in ALLOWED_SECURE_NOTE_TYPES:\n            url = parsed.get('url', url)\n            username = parsed.get('username', username)\n            password = parsed.get('password', password)\n\n    return Account(id, name, username, password, url, group, notes)", "response": "Parses an account chunk decrypts and creates an Account object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_PRIK(chunk, encryption_key):\n    decrypted = decode_aes256('cbc',\n                              encryption_key[:16],\n                              decode_hex(chunk.payload),\n                              encryption_key)\n\n    hex_key = re.match(br'^LastPassPrivateKey<(?P<hex_key>.*)>LastPassPrivateKey$', decrypted).group('hex_key')\n    rsa_key = RSA.importKey(decode_hex(hex_key))\n\n    rsa_key.dmp1 = rsa_key.d % (rsa_key.p - 1)\n    rsa_key.dmq1 = rsa_key.d % (rsa_key.q - 1)\n    rsa_key.iqmp = number.inverse(rsa_key.q, rsa_key.p)\n\n    return rsa_key", "response": "Parse a PRIK chunk which contains private RSA key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_aes256_plain_auto(data, encryption_key):\n    assert isinstance(data, bytes)\n    length = len(data)\n\n    if length == 0:\n        return b''\n    elif data[0] == b'!'[0] and length % 16 == 1 and length > 32:\n        return decode_aes256_cbc_plain(data, encryption_key)\n    else:\n        return decode_aes256_ecb_plain(data, encryption_key)", "response": "Guesses AES cipher from the length of the plain data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_aes256_base64_auto(data, encryption_key):\n    assert isinstance(data, bytes)\n    length = len(data)\n\n    if length == 0:\n        return b''\n    elif data[0] == b'!'[0]:\n        return decode_aes256_cbc_base64(data, encryption_key)\n    else:\n        return decode_aes256_ecb_base64(data, encryption_key)", "response": "Guesses AES cipher from the length of the base64 encoded data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_aes256_cbc_base64(data, encryption_key):\n    if not data:\n        return b''\n    else:\n        # LastPass AES-256/CBC/base64 encryted string starts with an \"!\".\n        # Next 24 bytes are the base64 encoded IV for the cipher.\n        # Then comes the \"|\".\n        # And the rest is the base64 encoded encrypted payload.\n        return decode_aes256(\n            'cbc',\n            decode_base64(data[1:25]),\n            decode_base64(data[26:]),\n            encryption_key)", "response": "Decrypts base64 encoded AES - 256 CBC bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data(self):\n        # Cache the data for next time .data is called.\n        if self._data is None:\n            self._data = self.to_value(self.instance)\n        return self._data", "response": "Get the serialized data from the serializer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a file already uploaded to Send", "response": "def api_delete(service, file_id, owner_token):\n    \"\"\"Delete a file already uploaded to Send\"\"\"\n    service += 'api/delete/%s' % file_id\n    r = requests.post(service, json={'owner_token': owner_token, 'delete_token': owner_token})\n    r.raise_for_status()\n\n    if r.text == 'OK':\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the download limit for a file hosted on a Send Server", "response": "def api_params(service, file_id, owner_token, download_limit):\n    \"\"\"Change the download limit for a file hosted on a Send Server\"\"\"\n    service += 'api/params/%s' % file_id\n    r = requests.post(service, json={'owner_token': owner_token, 'dlimit': download_limit})\n    r.raise_for_status()\n\n    if r.text == 'OK':\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef api_download(service, fileId, authorisation):\n    '''Given a Send url, download and return the encrypted data and metadata'''\n    data = tempfile.SpooledTemporaryFile(max_size=SPOOL_SIZE, mode='w+b')\n\n    headers = {'Authorization' : 'send-v1 ' + unpadded_urlsafe_b64encode(authorisation)}\n    url = service + 'api/download/' + fileId\n\n    r = requests.get(url, headers=headers, stream=True)\n    r.raise_for_status()\n    content_length = int(r.headers['Content-length'])\n\n    pbar = progbar(content_length)\n    for chunk in r.iter_content(chunk_size=CHUNK_SIZE):\n        data.write(chunk)\n        pbar.update(len(chunk))\n    pbar.close()\n\n    data.seek(0)\n    return data", "response": "Given a Send url download and return the encrypted data and metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decrypt_filedata(data, keys):\n    '''Decrypts a file from Send'''\n    # The last 16 bytes / 128 bits of data is the GCM tag\n    # https://www.w3.org/TR/WebCryptoAPI/#aes-gcm-operations :-\n    # 7. Let ciphertext be equal to C | T, where '|' denotes concatenation.\n    data.seek(-16, 2)\n    tag = data.read()\n\n    # now truncate the file to only contain encrypted data\n    data.seek(-16, 2)\n    data.truncate()\n    data.seek(0)\n\n    plain = tempfile.NamedTemporaryFile(mode='w+b', delete=False)\n\n    pbar = progbar(fileSize(data))\n\n    obj = Cryptodome.Cipher.AES.new(keys.encryptKey, Cryptodome.Cipher.AES.MODE_GCM, keys.encryptIV)\n    prev_chunk = b''\n    for chunk in iter(lambda: data.read(CHUNK_SIZE), b''):\n        plain.write(obj.decrypt(prev_chunk))\n        pbar.update(len(chunk))\n        prev_chunk = chunk\n\n    plain.write(obj.decrypt_and_verify(prev_chunk, tag))\n    data.close()\n    pbar.close()\n\n    plain.seek(0)\n    return plain", "response": "Decrypts a file from Send"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning the server nonce from the WWW - Authenticate header with an authKey", "response": "def sign_nonce(key, nonce):\n    ''' sign the server nonce from the WWW-Authenticate header with an authKey'''\n    # HMAC.new(key, msg='', digestmod=None)\n    return Cryptodome.Hash.HMAC.new(key, nonce, digestmod=Cryptodome.Hash.SHA256).digest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the authKey required to download a file hosted on a send server", "response": "def api_password(service, fileId , ownerToken, newAuthKey):\n    '''\n        changes the authKey required to download a file hosted on a send server\n    '''\n\n    service += 'api/password/%s' % fileId\n    auth = sendclient.common.unpadded_urlsafe_b64encode(newAuthKey)\n    r = requests.post(service, json={'owner_token': ownerToken, 'auth': auth})\n    r.raise_for_status()\n\n    if r.text == 'OK':\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_password(url, ownerToken, password):\n    '''\n        set or change the password required to download a file hosted on a send server.\n    '''\n    \n    service, fileId, key = sendclient.common.splitkeyurl(url)\n    rawKey = sendclient.common.unpadded_urlsafe_b64decode(key)\n    keys = sendclient.common.secretKeys(rawKey, password, url)\n    \n    return api_password(service, fileId, ownerToken, keys.newAuthKey)", "response": "set or change the password required to download a file hosted on a send server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef splitkeyurl(url):\n    '''\n       Splits a Send url into key, urlid and 'prefix' for the Send server\n       Should handle any hostname, but will brake on key & id length changes\n    '''\n    key = url[-22:]\n    urlid = url[-34:-24]\n    service = url[:-43]\n    return service, urlid, key", "response": "Splits a Send url into key urlid and prefix for the Send server\n       Should handle any hostname but will brake on the Send url length changes\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the size of a file like object in bytes / octets", "response": "def fileSize(f):\n    '''returns the size of a file like object in bytes/octets'''\n    offset = f.tell()\n\n    f.seek(0, 2)\n    size = f.tell()\n\n    f.seek(offset)  # return to the previous position in the file\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencrypting file data with the same method as the Send browser / js client", "response": "def encrypt_file(file, keys=secretKeys()):\n    '''Encrypt file data with the same method as the Send browser/js client'''\n    key = keys.encryptKey\n    iv = keys.encryptIV\n    encData = tempfile.SpooledTemporaryFile(max_size=SPOOL_SIZE, mode='w+b')\n    cipher = Cryptodome.Cipher.AES.new(key, Cryptodome.Cipher.AES.MODE_GCM, iv)\n\n    pbar = progbar(fileSize(file))\n\n    for chunk in iter(lambda: file.read(CHUNK_SIZE), b''):\n        encData.write(cipher.encrypt(chunk))\n        pbar.update(len(chunk))\n\n    pbar.close()\n    encData.write(cipher.digest())\n    file.close()\n\n    encData.seek(0)\n    return encData"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencrypt file metadata with the same method as the Send browser / js client", "response": "def encrypt_metadata(keys, fileName, fileType='application/octet-stream'):\n    '''Encrypt file metadata with the same method as the Send browser/js client'''\n    metadata = json.dumps({'iv' : unpadded_urlsafe_b64encode(keys.encryptIV), 'name' : fileName, 'type' : fileType}, sort_keys=True)\n\n    cipher = Cryptodome.Cipher.AES.new(keys.metaKey, Cryptodome.Cipher.AES.MODE_GCM, keys.metaIV)\n    encMeta, gcmTag = cipher.encrypt_and_digest(metadata.encode())\n\n    # WebcryptoAPI expects the gcm tag at the end of the ciphertext, return them concatenated\n    return encMeta + gcmTag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_file(service, file, fileName=None, password=None, ignoreVersion=False):\n\n    if checkServerVersion(service, ignoreVersion=ignoreVersion) == False:\n        print('\\033[1;41m!!! Potentially incompatible server version !!!\\033[0m')\n\n    ''' Encrypt & Upload a file to send and return the download URL'''\n    fileName = fileName if fileName != None else os.path.basename(file.name)\n\n    print('Encrypting data from \"' + fileName + '\"')\n    keys = secretKeys()\n    encData = encrypt_file(file, keys)\n    encMeta = encrypt_metadata(keys, fileName)\n\n    print('Uploading \"' + fileName + '\"')\n    secretUrl, fileId, fileNonce, owner_token = api_upload(service, encData, encMeta, keys)\n\n    if password != None:\n        print('Setting password')\n        sendclient.password.set_password(secretUrl, owner_token, password)\n\n    return secretUrl, fileId, owner_token", "response": "Send a file to the server and return the download URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch(self, endpoint, data = None):\n        payload = {\n            \"lastServerChangeId\": \"-1\",\n            \"csrf\": self.__csrf,\n            \"apiClient\": \"WEB\"\n        }\n        if data is not None:\n            payload.update(data)\n\n        return self.post(endpoint, payload)", "response": "Fetch data after logged in"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_session(self, cookies):\n        self.__session.cookies = requests.utils.cookiejar_from_dict(cookies)", "response": "Sets the cookies in the current session"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __identify_user(self, username, csrf):\n        data = {\n            \"username\": username,\n            \"csrf\": csrf,\n            \"apiClient\": \"WEB\",\n            \"bindDevice\": \"false\",\n            \"skipLinkAccount\": \"false\",\n            \"redirectTo\": \"\",\n            \"skipFirstUse\": \"\",\n            \"referrerId\": \"\",\n        }\n\n        r = self.post(\"/login/identifyUser\", data)\n\n        if r.status_code == requests.codes.ok:\n            result = r.json()\n            new_csrf = getSpHeaderValue(result, CSRF_KEY)\n            auth_level = getSpHeaderValue(result, AUTH_LEVEL_KEY)\n            return (new_csrf, auth_level)\n\n        return (None, None)", "response": "Identify a user and return the reusable CSRF code and the auth level as a 2 - tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_args(cls, dist, header=None):\n    if header is None:\n        header = cls.get_header()\n    spec = str(dist.as_requirement())\n    for type_ in 'console', 'gui':\n        group = type_ + '_scripts'\n        for name, ep in dist.get_entry_map(group).items():\n            # ensure_safe_name\n            if re.search(r'[\\\\/]', name):\n                raise ValueError(\"Path separators not allowed in script names\")\n            script_text = TEMPLATE.format(\n                ep.module_name,\n                ep.attrs[0],\n                '.'.join(ep.attrs),\n                spec,\n                group,\n                name,\n            )\n            args = cls._get_script_args(type_, name, header, script_text)\n            for res in args:\n                yield res", "response": "Overrides easy_install. ScriptWriter. get_args\n    This method returns a generator of all the script arguments that can be passed to the script writer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_zipfile():\n    if zipfile.is_zipfile(sys.argv[0]):\n        fd = open(sys.argv[0], \"rb\")\n        return zipfile.ZipFile(fd)", "response": "A function to vend the current zipfile if any"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cache_path(archive, root_dir, build_id):\n    root = root_dir or Path(\"~/.shiv\").expanduser()\n    name = Path(archive.filename).resolve().stem\n    return root / f\"{name}_{build_id}\"", "response": "Returns a ~. shiv cache directory for unzipping site - packages during bootstrapping."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting all site - packages from a zipfile to a specified path.", "response": "def extract_site_packages(archive, target_path, compile_pyc, compile_workers=0, force=False):\n    \"\"\"Extract everything in site-packages to a specified path.\n\n    :param ZipFile archive: The zipfile object we are bootstrapping from.\n    :param Path target_path: The path to extract our zip to.\n    \"\"\"\n    parent = target_path.parent\n    target_path_tmp = Path(parent, target_path.stem + \".tmp\")\n    lock = Path(parent, target_path.stem + \".lock\")\n\n    # If this is the first time that a pyz is being extracted, we'll need to create the ~/.shiv dir\n    if not parent.exists():\n        parent.mkdir(parents=True, exist_ok=True)\n\n    with FileLock(lock):\n\n        # we acquired a lock, it's possible that prior invocation was holding the lock and has\n        # completed bootstrapping, so let's check (again) if we need to do any work\n        if not target_path.exists() or force:\n\n            # extract our site-packages\n            for filename in archive.namelist():\n                if filename.startswith(\"site-packages\"):\n                    archive.extract(filename, target_path_tmp)\n\n            if compile_pyc:\n                compileall.compile_dir(target_path_tmp, quiet=2, workers=compile_workers)\n\n            # if using `force` we will need to delete our target path\n            if target_path.exists():\n                shutil.rmtree(str(target_path))\n\n            # atomic move\n            shutil.move(str(target_path_tmp), str(target_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bootstrap():  # pragma: no cover\n\n    # get a handle of the currently executing zip file\n    archive = current_zipfile()\n\n    # create an environment object (a combination of env vars and json metadata)\n    env = Environment.from_json(archive.read(\"environment.json\").decode())\n\n    # get a site-packages directory (from env var or via build id)\n    site_packages = cache_path(archive, env.root, env.build_id) / \"site-packages\"\n\n    # determine if first run or forcing extract\n    if not site_packages.exists() or env.force_extract:\n        extract_site_packages(archive, site_packages.parent, env.compile_pyc, env.compile_workers, env.force_extract)\n\n    # get sys.path's length\n    length = len(sys.path)\n\n    # Find the first instance of an existing site-packages on sys.path\n    index = _first_sitedir_index() or length\n\n    # append site-packages using the stdlib blessed way of extending path\n    # so as to handle .pth files correctly\n    site.addsitedir(site_packages)\n\n    # add our site-packages to the environment, if requested\n    if env.extend_pythonpath:\n        _extend_python_path(os.environ, sys.path[index:])\n\n    # reorder to place our site-packages before any others found\n    sys.path = sys.path[:index] + sys.path[length:] + sys.path[index:length]\n\n    # first check if we should drop into interactive mode\n    if not env.interpreter:\n\n        # do entry point import and call\n        if env.entry_point is not None:\n            mod = import_string(env.entry_point)\n            try:\n                sys.exit(mod())\n            except TypeError:\n                # catch \"<module> is not callable\", which is thrown when the entry point's\n                # callable shares a name with it's parent module\n                # e.g. \"from foo.bar import bar; bar()\"\n                sys.exit(getattr(mod, env.entry_point.replace(\":\", \".\").split(\".\")[1])())\n\n        elif env.script is not None:\n            sys.exit(runpy.run_path(site_packages / \"bin\" / env.script, run_name=\"__main__\"))\n\n    # all other options exhausted, drop into interactive mode\n    execute_interpreter()", "response": "Actually bootstrap our shiv environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_file_prefix(f: IO[Any], interpreter: str) -> None:\n    # if the provided path is too long for a shebang we should error out\n    if len(interpreter) > BINPRM_BUF_SIZE:\n        sys.exit(BINPRM_ERROR)\n\n    f.write(b\"#!\" + interpreter.encode(sys.getfilesystemencoding()) + b\"\\n\")", "response": "Write a shebang line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an application archive from SOURCE.", "response": "def create_archive(\n    source: Path,\n    target: Path,\n    interpreter: str,\n    main: str,\n    compressed: bool = True\n) -> None:\n    \"\"\"Create an application archive from SOURCE.\n\n    A slightly modified version of stdlib's\n    `zipapp.create_archive <https://docs.python.org/3/library/zipapp.html#zipapp.create_archive>`_\n\n    \"\"\"\n    # Check that main has the right format.\n    mod, sep, fn = main.partition(\":\")\n    mod_ok = all(part.isidentifier() for part in mod.split(\".\"))\n    fn_ok = all(part.isidentifier() for part in fn.split(\".\"))\n    if not (sep == \":\" and mod_ok and fn_ok):\n        raise zipapp.ZipAppError(\"Invalid entry point: \" + main)\n\n    main_py = MAIN_TEMPLATE.format(module=mod, fn=fn)\n\n    with maybe_open(target, \"wb\") as fd:\n        # write shebang\n        write_file_prefix(fd, interpreter)\n\n        # determine compression\n        compression = zipfile.ZIP_DEFLATED if compressed else zipfile.ZIP_STORED\n\n        # create zipapp\n        with zipfile.ZipFile(fd, \"w\", compression=compression) as z:\n            for child in source.rglob(\"*\"):\n\n                # skip compiled files\n                if child.suffix == '.pyc':\n                    continue\n\n                arcname = child.relative_to(source)\n                z.write(str(child), str(arcname))\n\n            # write main\n            z.writestr(\"__main__.py\", main_py.encode(\"utf-8\"))\n\n    # make executable\n    # NOTE on windows this is no-op\n    target.chmod(target.stat().st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef acquire_win(lock_file):  # pragma: no cover\n    try:\n        fd = os.open(lock_file, OPEN_MODE)\n    except OSError:\n        pass\n    else:\n        try:\n            msvcrt.locking(fd, msvcrt.LK_NBLCK, 1)\n        except (IOError, OSError):\n            os.close(fd)\n        else:\n            return fd", "response": "Acquire a lock file on windows."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef acquire_nix(lock_file):  # pragma: no cover\n    fd = os.open(lock_file, OPEN_MODE)\n\n    try:\n        fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n    except (IOError, OSError):\n        os.close(fd)\n    else:\n        return fd", "response": "Acquire a lock file on linux or osx."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a console_script in a site - packages directory.", "response": "def find_entry_point(site_packages: Path, console_script: str) -> str:\n    \"\"\"Find a console_script in a site-packages directory.\n\n    Console script metadata is stored in entry_points.txt per setuptools\n    convention. This function searches all entry_points.txt files and\n    returns the import string for a given console_script argument.\n\n    :param site_packages: A path to a site-packages directory on disk.\n    :param console_script: A console_script string.\n    \"\"\"\n\n    config_parser = ConfigParser()\n    config_parser.read(site_packages.rglob(\"entry_points.txt\"))\n    return config_parser[\"console_scripts\"][console_script]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_bootstrap(bootstrap_target: Path) -> None:\n\n    for bootstrap_file in importlib_resources.contents(bootstrap):\n        if importlib_resources.is_resource(bootstrap, bootstrap_file):\n            with importlib_resources.path(bootstrap, bootstrap_file) as f:\n                shutil.copyfile(f.absolute(), bootstrap_target / f.name)", "response": "Copy bootstrap code from shiv into the pyz directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(\n    output_file: str,\n    entry_point: Optional[str],\n    console_script: Optional[str],\n    python: Optional[str],\n    site_packages: Optional[str],\n    compressed: bool,\n    compile_pyc: bool,\n    extend_pythonpath: bool,\n    pip_args: List[str],\n) -> None:\n    \"\"\"\n    Shiv is a command line utility for building fully self-contained Python zipapps\n    as outlined in PEP 441, but with all their dependencies included!\n    \"\"\"\n\n    if not pip_args and not site_packages:\n        sys.exit(NO_PIP_ARGS_OR_SITE_PACKAGES)\n\n    if output_file is None:\n        sys.exit(NO_OUTFILE)\n\n    # check for disallowed pip arguments\n    for disallowed in DISALLOWED_ARGS:\n        for supplied_arg in pip_args:\n            if supplied_arg in disallowed:\n                sys.exit(\n                    DISALLOWED_PIP_ARGS.format(\n                        arg=supplied_arg, reason=DISALLOWED_ARGS[disallowed]\n                    )\n                )\n\n    with TemporaryDirectory() as working_path:\n        tmp_site_packages = Path(working_path, \"site-packages\")\n\n        if site_packages:\n            shutil.copytree(site_packages, tmp_site_packages)\n\n        if pip_args:\n            # install deps into staged site-packages\n            pip.install([\"--target\", str(tmp_site_packages)] + list(pip_args))\n\n        # if entry_point is a console script, get the callable\n        if entry_point is None and console_script is not None:\n            try:\n                entry_point = find_entry_point(tmp_site_packages, console_script)\n\n            except KeyError:\n                if not Path(tmp_site_packages, \"bin\", console_script).exists():\n                    sys.exit(NO_ENTRY_POINT.format(entry_point=console_script))\n\n        # create runtime environment metadata\n        env = Environment(\n            build_id=str(uuid.uuid4()),\n            entry_point=entry_point,\n            script=console_script,\n            compile_pyc=compile_pyc,\n            extend_pythonpath=extend_pythonpath,\n        )\n\n        Path(working_path, \"environment.json\").write_text(env.to_json())\n\n        # create bootstrapping directory in working path\n        bootstrap_target = Path(working_path, \"_bootstrap\")\n        bootstrap_target.mkdir(parents=True, exist_ok=True)\n\n        # copy bootstrap code\n        copy_bootstrap(bootstrap_target)\n\n        # create the zip\n        builder.create_archive(\n            Path(working_path),\n            target=Path(output_file).expanduser(),\n            interpreter=python or _interpreter_path(),\n            main=\"_bootstrap:bootstrap\",\n            compressed=compressed,\n        )", "response": "This function is a command line utility for building a new self - contained Python module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_session(*, env_vars=None, loop=None):\n    loop = loop or asyncio.get_event_loop()\n    return AioSession(session_vars=env_vars, loop=loop)", "response": "Return a new session object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def read(self, amt=None):\n        # botocore to aiohttp mapping\n        chunk = await self.__wrapped__.read(amt if amt is not None else -1)\n        self._self_amount_read += len(chunk)\n        if amt is None or (not chunk and amt > 0):\n            # If the server sends empty contents or\n            # we ask to read all of the contents, then we know\n            # we need to verify the content length.\n            self._verify_content_length()\n        return chunk", "response": "Read at most amt bytes from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def iter_lines(self, chunk_size=1024):\n        pending = b''\n        async for chunk in self.iter_chunks(chunk_size):\n            lines = (pending + chunk).splitlines(True)\n            for line in lines[:-1]:\n                await yield_(line.splitlines()[0])\n            pending = lines[-1]\n        if pending:\n            await yield_(pending.splitlines()[0])", "response": "Return an iterator to yield lines from the raw stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def iter_chunks(self, chunk_size=_DEFAULT_CHUNK_SIZE):\n        while True:\n            current_chunk = await self.read(chunk_size)\n            if current_chunk == b\"\":\n                break\n            await yield_(current_chunk)", "response": "Return an iterator to yield chunks of chunk_size bytes from the rawCOOKIE_FILE stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a sequence of dynamo items", "response": "def get_items(start_num, num_items):\n    \"\"\"\n    Generate a sequence of dynamo items\n\n    :param start_num: Start index\n    :type start_num: int\n    :param num_items: Number of items\n    :type num_items: int\n    :return: List of dictionaries\n    :rtype: list of dict\n    \"\"\"\n    result = []\n    for i in range(start_num, start_num+num_items):\n        result.append({'pk': {'S': 'item{0}'.format(i)}})\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a batch write structure for passing to batch_write_item WorkItem", "response": "def create_batch_write_structure(table_name, start_num, num_items):\n    \"\"\"\n    Create item structure for passing to batch_write_item\n\n    :param table_name: DynamoDB table name\n    :type table_name: str\n    :param start_num: Start index\n    :type start_num: int\n    :param num_items: Number of items\n    :type num_items: int\n    :return: dictionary of tables to write to\n    :rtype: dict\n    \"\"\"\n    return {\n        table_name: [\n            {'PutRequest': {'Item': item}}\n            for item in get_items(start_num, num_items)\n        ]\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a paginator for an operation.", "response": "def get_paginator(self, operation_name):\n        \"\"\"Create a paginator for an operation.\n\n        :type operation_name: string\n        :param operation_name: The operation name.  This is the same name\n            as the method name on the client.  For example, if the\n            method name is ``create_foo``, and you'd normally invoke the\n            operation as ``client.create_foo(**kwargs)``, if the\n            ``create_foo`` operation can be paginated, you can use the\n            call ``client.get_paginator(\"create_foo\")``.\n\n        :raise OperationNotPageableError: Raised if the operation is not\n            pageable.  You can use the ``client.can_paginate`` method to\n            check if an operation is pageable.\n\n        :rtype: L{botocore.paginate.Paginator}\n        :return: A paginator object.\n\n        \"\"\"\n        if not self.can_paginate(operation_name):\n            raise OperationNotPageableError(operation_name=operation_name)\n        else:\n            # substitute iterator with async one\n            Paginator.PAGE_ITERATOR_CLS = AioPageIterator\n\n            actual_operation_name = self._PY_TO_OP_NAME[operation_name]\n\n            # Create a new paginate method that will serve as a proxy to\n            # the underlying Paginator.paginate method. This is needed to\n            # attach a docstring to the method.\n            def paginate(self, **kwargs):\n                return Paginator.paginate(self, **kwargs)\n\n            paginator_config = self._cache['page_config'][\n                actual_operation_name]\n\n            # Rename the paginator class based on the type of paginator.\n            paginator_class_name = str('%s.Paginator.%s' % (\n                get_service_module_name(self.meta.service_model),\n                actual_operation_name))\n\n            # Create the new paginator class\n            documented_paginator_cls = type(\n                paginator_class_name, (Paginator,), {'paginate': paginate})\n\n            operation_model = self._service_model.\\\n                operation_model(actual_operation_name)\n            paginator = documented_paginator_cls(\n                getattr(self, operation_name),\n                paginator_config,\n                operation_model)\n\n            return paginator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an object that can wait for some condition.", "response": "def get_waiter(self, waiter_name):\n        \"\"\"Returns an object that can wait for some condition.\n\n        :type waiter_name: str\n        :param waiter_name: The name of the waiter to get. See the waiters\n            section of the service docs for a list of available waiters.\n\n        :returns: The specified waiter object.\n        :rtype: botocore.waiter.Waiter\n        \"\"\"\n        config = self._get_waiter_config()\n        if not config:\n            raise ValueError(\"Waiter does not exist: %s\" % waiter_name)\n        model = waiter.WaiterModel(config)\n        mapping = {}\n        for name in model.waiter_names:\n            mapping[xform_name(name)] = name\n        if waiter_name not in mapping:\n            raise ValueError(\"Waiter does not exist: %s\" % waiter_name)\n\n        return waiter.create_waiter_with_client(\n            mapping[waiter_name], model, self, loop=self._loop)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndrop - in replacement for py : func : ssl. wrap_socket", "response": "def fake_wrap_socket(orig_wrap_socket_fn, *args, **kw):\n    \"\"\"drop-in replacement for py:func:`ssl.wrap_socket`\n    \"\"\"\n    server_hostname = kw.get('server_hostname')\n    if server_hostname is not None:\n        matcher = httpretty.match_https_hostname(server_hostname)\n        if matcher is None:\n                return orig_wrap_socket_fn(*args, **kw)\n    if 'sock' in kw:\n        return kw['sock']\n    else:\n        return args[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fake_getaddrinfo(\n        host, port, family=None, socktype=None, proto=None, flags=None):\n    \"\"\"drop-in replacement for :py:func:`socket.getaddrinfo`\"\"\"\n    return [(socket.AF_INET, socket.SOCK_STREAM, socket.IPPROTO_TCP,\n             '', (host, port))]", "response": "Drop - in replacement for socket. getaddrinfo"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url_fix(s, charset=None):\n    if charset:\n        warnings.warn(\"{}.url_fix() charset argument is deprecated\".format(__name__), DeprecationWarning)\n\n    scheme, netloc, path, querystring, fragment = urlsplit(s)\n    path = quote(path, b'/%')\n    querystring = quote_plus(querystring, b':&=')\n    return urlunsplit((scheme, netloc, path, querystring, fragment))", "response": "escapes special characters in a URL"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattempting to parse the body based on the content - type passed.", "response": "def parse_request_body(self, body):\n        \"\"\"Attempt to parse the post based on the content-type passed.\n        Return the regular body if not\n\n        :param body: string\n        :returns: a python object such as dict or list in case the deserialization suceeded. Else returns the given param ``body``\n        \"\"\"\n\n        PARSING_FUNCTIONS = {\n            'application/json': json.loads,\n            'text/json': json.loads,\n            'application/x-www-form-urlencoded': self.parse_querystring,\n        }\n\n        content_type = self.headers.get('content-type', '')\n\n        do_parse = PARSING_FUNCTIONS.get(content_type, FALLBACK_FUNCTION)\n        try:\n            body = decode_utf8(body)\n            return do_parse(body)\n        except (Exception, BaseException):\n            return body"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfills the HTTP response data to a file descriptor", "response": "def fill_filekind(self, fk):\n        \"\"\"writes HTTP Response data to a file descriptor\n\n        :parm fk: a file-like object\n\n        .. warning:: **side-effect:** this method moves the cursor of the given file object to zero\n        \"\"\"\n        now = datetime.utcnow()\n\n        headers = {\n            'status': self.status,\n            'date': now.strftime('%a, %d %b %Y %H:%M:%S GMT'),\n            'server': 'Python/HTTPretty',\n            'connection': 'close',\n        }\n\n        if self.forcing_headers:\n            headers = self.forcing_headers\n\n        if self.adding_headers:\n            headers.update(\n                self.normalize_headers(\n                    self.adding_headers))\n\n        headers = self.normalize_headers(headers)\n        status = headers.get('status', self.status)\n        if self.body_is_callable:\n            status, headers, self.body = self.callable_body(self.request, self.info.full_url(), headers)\n            headers = self.normalize_headers(headers)\n            # TODO: document this behavior:\n            if 'content-length' not in headers:\n                headers.update({\n                    'content-length': len(self.body)\n                })\n\n        string_list = [\n            'HTTP/1.1 %d %s' % (status, STATUSES[status]),\n        ]\n\n        if 'date' in headers:\n            string_list.append('date: %s' % headers.pop('date'))\n\n        if not self.forcing_headers:\n            content_type = headers.pop('content-type',\n                                       'text/plain; charset=utf-8')\n\n            content_length = headers.pop('content-length',\n                                         self.body_length)\n\n            string_list.append('content-type: %s' % content_type)\n            if not self.streaming:\n                string_list.append('content-length: %s' % content_length)\n\n            server = headers.pop('server', None)\n            if server:\n                string_list.append('server: %s' % server)\n\n        for k, v in headers.items():\n            string_list.append(\n                '{}: {}'.format(k, v),\n            )\n\n        for item in string_list:\n            fk.write(utf8(item) + b'\\n')\n\n        fk.write(b'\\r\\n')\n\n        if self.streaming:\n            self.body, body = itertools.tee(self.body)\n            for chunk in body:\n                fk.write(utf8(chunk))\n        else:\n            fk.write(utf8(self.body))\n\n        fk.seek(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match_uriinfo(cls, info):\n        items = sorted(\n            cls._entries.items(),\n            key=lambda matcher_entries: matcher_entries[0].priority,\n            reverse=True,\n        )\n        for matcher, value in items:\n            if matcher.matches(info):\n                return (matcher, info)\n\n        return (None, [])", "response": "Returns a tuple of URLMatcher and a list of URIInfo objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an URLMatcher object for the given hostname", "response": "def match_https_hostname(cls, hostname):\n        \"\"\"\n        :param hostname: a string\n        :returns: an :py:class:`~httpretty.core.URLMatcher` or ``None``\n        \"\"\"\n        items = sorted(\n            cls._entries.items(),\n            key=lambda matcher_entries: matcher_entries[0].priority,\n            reverse=True,\n        )\n        for matcher, value in items:\n            if matcher.info is None:\n                pattern_with_port = \"https://{0}:\".format(hostname)\n                pattern_without_port = \"https://{0}/\".format(hostname)\n                hostname_pattern = (\n                    hostname_re\n                    .match(matcher.regex.pattern)\n                    .group(0)\n                )\n                for pattern in [pattern_with_port, pattern_without_port]:\n                    if re.match(hostname_pattern, pattern):\n                        return matcher\n\n            elif matcher.info.hostname == hostname:\n                return matcher\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrecord the current state of the object", "response": "def record(cls, filename, indentation=4, encoding='utf-8'):\n        \"\"\"\n        .. testcode::\n\n           import io\n           import json\n           import requests\n           import httpretty\n\n           with httpretty.record('/tmp/ip.json'):\n               data = requests.get('https://httpbin.org/ip').json()\n\n           with io.open('/tmp/ip.json') as fd:\n               assert data == json.load(fd)\n\n        :param filename: a string\n        :param indentation: an integer, defaults to **4**\n        :param encoding: a string, defaults to **\"utf-8\"**\n\n        :returns: a `context-manager <https://docs.python.org/3/reference/datamodel.html#context-managers>`_\n        \"\"\"\n        try:\n            import urllib3\n        except ImportError:\n            msg = (\n                'HTTPretty requires urllib3 installed '\n                'for recording actual requests.'\n            )\n            raise RuntimeError(msg)\n\n        http = urllib3.PoolManager()\n\n        cls.enable()\n        calls = []\n\n        def record_request(request, uri, headers):\n            cls.disable()\n\n            kw = {}\n            kw.setdefault('body', request.body)\n            kw.setdefault('headers', dict(request.headers))\n            response = http.request(request.method, uri, **kw)\n            calls.append({\n                'request': {\n                    'uri': uri,\n                    'method': request.method,\n                    'headers': dict(request.headers),\n                    'body': decode_utf8(request.body),\n                    'querystring': request.querystring\n                },\n                'response': {\n                    'status': response.status,\n                    'body': decode_utf8(response.data),\n                    # urllib3 1.10 had a bug if you just did:\n                    # dict(response.headers)\n                    # which would cause all the values to become lists\n                    # with the header name as the first item and the\n                    # true value as the second item. Workaround that\n                    'headers': dict(response.headers.items())\n                }\n            })\n            cls.enable()\n            return response.status, response.headers, response.data\n\n        for method in cls.METHODS:\n            cls.register_uri(method, MULTILINE_ANY_REGEX, body=record_request)\n\n        yield\n        cls.disable()\n        with codecs.open(filename, 'w', encoding) as f:\n            f.write(json.dumps(calls, indent=indentation))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Response(\n            cls, body,\n            method=None,\n            uri=None,\n            adding_headers=None,\n            forcing_headers=None,\n            status=200,\n            streaming=False,\n            **kw):\n        \"\"\"\n        shortcut to create an :py:class:`~httpretty.core.Entry` that takes the body as first positional argument\n\n        .. seealso:: the parameters of this function match those of the :py:class:`~httpretty.core.Entry` constructor\n        :param body:\n        :param method: one of ``httpretty.GET``, ``httpretty.PUT``, ``httpretty.POST``, ``httpretty.DELETE``, ``httpretty.HEAD``, ``httpretty.PATCH``, ``httpretty.OPTIONS``, ``httpretty.CONNECT``\n        :param uri:\n        :param adding_headers:\n        :param forcing_headers:\n        :param status: defaults to **200**\n        :param streaming: defaults to **False**\n        :param kw: keyword-arguments passed onto the :py:class:`~httpretty.core.Entry`\n        :returns: an :py:class:`~httpretty.core.Entry`\n        \"\"\"\n        kw['body'] = body\n        kw['adding_headers'] = adding_headers\n        kw['forcing_headers'] = forcing_headers\n        kw['status'] = int(status)\n        kw['streaming'] = streaming\n        return Entry(method, uri, **kw)", "response": "Shortcut to create an HTTP response object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable(cls, allow_net_connect=True):\n        cls.allow_net_connect = allow_net_connect\n        cls._is_enabled = True\n        # Some versions of python internally shadowed the\n        # SocketType variable incorrectly https://bugs.python.org/issue20386\n        bad_socket_shadow = (socket.socket != socket.SocketType)\n\n        socket.socket = fakesock.socket\n        socket._socketobject = fakesock.socket\n        if not bad_socket_shadow:\n            socket.SocketType = fakesock.socket\n\n        socket.create_connection = create_fake_connection\n        socket.gethostname = fake_gethostname\n        socket.gethostbyname = fake_gethostbyname\n        socket.getaddrinfo = fake_getaddrinfo\n\n        socket.__dict__['socket'] = fakesock.socket\n        socket.__dict__['_socketobject'] = fakesock.socket\n        if not bad_socket_shadow:\n            socket.__dict__['SocketType'] = fakesock.socket\n\n        socket.__dict__['create_connection'] = create_fake_connection\n        socket.__dict__['gethostname'] = fake_gethostname\n        socket.__dict__['gethostbyname'] = fake_gethostbyname\n        socket.__dict__['getaddrinfo'] = fake_getaddrinfo\n\n        if socks:\n            socks.socksocket = fakesock.socket\n            socks.__dict__['socksocket'] = fakesock.socket\n\n        if ssl:\n            new_wrap = partial(fake_wrap_socket, old_ssl_wrap_socket)\n            ssl.wrap_socket = new_wrap\n            ssl.SSLSocket = FakeSSLSocket\n            try:\n                ssl.SSLContext.wrap_socket = partial(fake_wrap_socket, old_sslcontext_wrap_socket)\n            except AttributeError:\n                pass\n\n            ssl.__dict__['wrap_socket'] = new_wrap\n            ssl.__dict__['SSLSocket'] = FakeSSLSocket\n\n            if not PY3:\n                ssl.sslwrap_simple = new_wrap\n                ssl.__dict__['sslwrap_simple'] = new_wrap\n\n        if requests_urllib3_connection is not None:\n            new_wrap = partial(fake_wrap_socket, old_requests_ssl_wrap_socket)\n            requests_urllib3_connection.ssl_wrap_socket = new_wrap\n            requests_urllib3_connection.__dict__['ssl_wrap_socket'] = new_wrap", "response": "Enables HTTPretty. A new instance of the class will be created and the new one is created."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw text in the given color. Duh.", "response": "def draw_text(stdscr, text, color=0, fallback=None, title=None):\n    \"\"\"\n    Draws text in the given color. Duh.\n    \"\"\"\n    if fallback is None:\n        fallback = text\n    y, x = stdscr.getmaxyx()\n    if title:\n        title = pad_to_size(title, x, 1)\n        if \"\\n\" in title.rstrip(\"\\n\"):\n            # hack to get more spacing between title and body for figlet\n            title += \"\\n\" * 5\n        text = title + \"\\n\" + pad_to_size(text, x, len(text.split(\"\\n\")))\n    lines = pad_to_size(text, x, y).rstrip(\"\\n\").split(\"\\n\")\n\n    try:\n        for i, line in enumerate(lines):\n            stdscr.insstr(i, 0, line, curses.color_pair(color))\n    except:\n        lines = pad_to_size(fallback, x, y).rstrip(\"\\n\").split(\"\\n\")\n        try:\n            for i, line in enumerate(lines[:]):\n                stdscr.insstr(i, 0, line, curses.color_pair(color))\n        except:\n            pass\n    stdscr.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a human - readable string representation of the given amount of seconds.", "response": "def format_seconds(seconds, hide_seconds=False):\n    \"\"\"\n    Returns a human-readable string representation of the given amount\n    of seconds.\n    \"\"\"\n    if seconds <= 60:\n        return str(seconds)\n    output = \"\"\n    for period, period_seconds in (\n        ('y', 31557600),\n        ('d', 86400),\n        ('h', 3600),\n        ('m', 60),\n        ('s', 1),\n    ):\n        if seconds >= period_seconds and not (hide_seconds and period == 's'):\n            output += str(int(seconds / period_seconds))\n            output += period\n            output += \" \"\n            seconds = seconds % period_seconds\n    return output.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes the decorated function exit with code 1 on CTRL+C.", "response": "def graceful_ctrlc(func):\n    \"\"\"\n    Makes the decorated function exit with code 1 on CTRL+C.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except KeyboardInterrupt:\n            exit(1)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pad_to_size(text, x, y):\n    input_lines = text.rstrip().split(\"\\n\")\n    longest_input_line = max(map(len, input_lines))\n    number_of_input_lines = len(input_lines)\n    x = max(x, longest_input_line)\n    y = max(y, number_of_input_lines)\n    output = \"\"\n\n    padding_top = int((y - number_of_input_lines) / 2)\n    padding_bottom = y - number_of_input_lines - padding_top\n    padding_left = int((x - longest_input_line) / 2)\n\n    output += padding_top * (\" \" * x + \"\\n\")\n    for line in input_lines:\n        output += padding_left * \" \" + line + \" \" * (x - padding_left - len(line)) + \"\\n\"\n    output += padding_bottom * (\" \" * x + \"\\n\")\n\n    return output", "response": "Pads text to the given dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_timestr(timestr):\n    timedelta_secs = parse_timedelta(timestr)\n    sync_start = datetime.now()\n\n    if timedelta_secs:\n        target = datetime.now() + timedelta(seconds=timedelta_secs)\n    elif timestr.isdigit():\n        target = datetime.now() + timedelta(seconds=int(timestr))\n    else:\n        try:\n            target = parse(timestr)\n        except:\n            # unfortunately, dateutil doesn't raise the best exceptions\n            raise ValueError(\"Unable to parse '{}'\".format(timestr))\n\n        # When I do \"termdown 10\" (the two cases above), I want a\n        # countdown for the next 10 seconds. Okay. But when I do\n        # \"termdown 23:52\", I want a countdown that ends at that exact\n        # moment -- the countdown is related to real time. Thus, I want\n        # my frames to be drawn at full seconds, so I enforce\n        # microsecond=0.\n        sync_start = sync_start.replace(microsecond=0)\n    try:\n        # try to convert target to naive local timezone\n        target = target.astimezone(tz=tz.tzlocal()).replace(tzinfo=None)\n    except ValueError:\n        # parse() already returned a naive datetime, all is well\n        pass\n    return (sync_start, target)", "response": "Parse a string describing a point in time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_timedelta(deltastr):\n    matches = TIMEDELTA_REGEX.match(deltastr)\n    if not matches:\n        return None\n    components = {}\n    for name, value in matches.groupdict().items():\n        if value:\n            components[name] = int(value)\n    for period, hours in (('days', 24), ('years', 8766)):\n        if period in components:\n            components['hours'] = components.get('hours', 0) + \\\n                                  components[period] * hours\n            del components[period]\n    return int(timedelta(**components).total_seconds())", "response": "Parse a string describing a period of time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap(self, message):\n        if self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SEAL:\n            encrypted_message = self._seal_message(message)\n            signature = self._get_signature(message)\n            message = encrypted_message\n\n        elif self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SIGN:\n            signature = self._get_signature(message)\n        else:\n            signature = None\n\n        return message, signature", "response": "[MS-NLMP] v28.0 2016-07-14\n\n        3.4.6 GSS_WrapEx()\n        Emulates the GSS_Wrap() implementation to sign and seal messages if the correct flags\n        are set.\n\n        @param message: The message data that will be wrapped\n        @return message: The message that has been sealed if flags are set\n        @return signature: The signature of the message, None if flags are not set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nunseal a message and verify the signature.", "response": "def unwrap(self, message, signature):\n        \"\"\"\n        [MS-NLMP] v28.0 2016-07-14\n\n        3.4.7 GSS_UnwrapEx()\n        Emulates the GSS_Unwrap() implementation to unseal messages and verify the signature\n        sent matches what has been computed locally. Will throw an Exception if the signature\n        doesn't match\n\n        @param message: The message data received from the server\n        @param signature: The signature of the message\n        @return message: The message that has been unsealed if flags are set\n        \"\"\"\n        if self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SEAL:\n            message = self._unseal_message(message)\n            self._verify_signature(message, signature)\n\n        elif self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SIGN:\n            self._verify_signature(message, signature)\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_signature(self, message):\n        signature = calc_signature(message, self.negotiate_flags, self.outgoing_signing_key, self.outgoing_seq_num, self.outgoing_handle)\n        self.outgoing_seq_num += 1\n\n        return signature.get_data()", "response": "This function will create the signature based on the message and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying that the signature received from the server matches up with the expected signature.", "response": "def _verify_signature(self, message, signature):\n        \"\"\"\n        Will verify that the signature received from the server matches up with the expected signature\n        computed locally. Will throw an exception if they do not match\n\n        @param message: The message data that is received from the server\n        @param signature: The signature of the message received from the server\n        \"\"\"\n        if self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n            actual_checksum = signature[4:12]\n            actual_seq_num = struct.unpack(\"<I\", signature[12:16])[0]\n        else:\n            actual_checksum = signature[8:12]\n            actual_seq_num = struct.unpack(\"<I\", signature[12:16])[0]\n\n        expected_signature = calc_signature(message, self.negotiate_flags, self.incoming_signing_key, self.incoming_seq_num, self.incoming_handle)\n        expected_checksum = expected_signature.checksum\n        expected_seq_num = struct.unpack(\"<I\", expected_signature.seq_num)[0]\n\n        if actual_checksum != expected_checksum:\n            raise Exception(\"The signature checksum does not match, message has been altered\")\n\n        if actual_seq_num != expected_seq_num:\n            raise Exception(\"The signature sequence number does not match up, message not received in the correct sequence\")\n\n        self.incoming_seq_num += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True,\n         allow_nan=True, cls=None, indent=None, separators=None,\n         encoding='utf-8', default=None, use_decimal=True,\n         namedtuple_as_object=True, tuple_as_array=True,\n         bigint_as_string=False, sort_keys=False, item_sort_key=None,\n         for_json=False, ignore_nan=False, int_as_string_bitcount=None,\n         iterable_as_array=False, **kw):\n    \"\"\"Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n    ``.write()``-supporting file-like object).\n\n    If *skipkeys* is true then ``dict`` keys that are not basic types\n    (``str``, ``unicode``, ``int``, ``long``, ``float``, ``bool``, ``None``)\n    will be skipped instead of raising a ``TypeError``.\n\n    If *ensure_ascii* is false, then the some chunks written to ``fp``\n    may be ``unicode`` instances, subject to normal Python ``str`` to\n    ``unicode`` coercion rules. Unless ``fp.write()`` explicitly\n    understands ``unicode`` (as in ``codecs.getwriter()``) this is likely\n    to cause an error.\n\n    If *check_circular* is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``OverflowError`` (or worse).\n\n    If *allow_nan* is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n    in strict compliance of the original JSON specification, instead of using\n    the JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``). See\n    *ignore_nan* for ECMA-262 compliant behavior.\n\n    If *indent* is a string, then JSON array elements and object members\n    will be pretty-printed with a newline followed by that string repeated\n    for each level of nesting. ``None`` (the default) selects the most compact\n    representation without any newlines. For backwards compatibility with\n    versions of simplejson earlier than 2.1.0, an integer is also accepted\n    and is converted to a string with that many spaces.\n\n    If specified, *separators* should be an\n    ``(item_separator, key_separator)`` tuple.  The default is ``(', ', ': ')``\n    if *indent* is ``None`` and ``(',', ': ')`` otherwise.  To get the most\n    compact JSON representation, you should specify ``(',', ':')`` to eliminate\n    whitespace.\n\n    *encoding* is the character encoding for str instances, default is UTF-8.\n\n    *default(obj)* is a function that should return a serializable version\n    of obj or raise ``TypeError``. The default simply raises ``TypeError``.\n\n    If *use_decimal* is true (default: ``True``) then decimal.Decimal\n    will be natively serialized to JSON with full precision.\n\n    If *namedtuple_as_object* is true (default: ``True``),\n    :class:`tuple` subclasses with ``_asdict()`` methods will be encoded\n    as JSON objects.\n\n    If *tuple_as_array* is true (default: ``True``),\n    :class:`tuple` (and subclasses) will be encoded as JSON arrays.\n\n    If *iterable_as_array* is true (default: ``False``),\n    any object not in the above table that implements ``__iter__()``\n    will be encoded as a JSON array.\n\n    If *bigint_as_string* is true (default: ``False``), ints 2**53 and higher\n    or lower than -2**53 will be encoded as strings. This is to avoid the\n    rounding that happens in Javascript otherwise. Note that this is still a\n    lossy operation that will not round-trip correctly and should be used\n    sparingly.\n\n    If *int_as_string_bitcount* is a positive number (n), then int of size\n    greater than or equal to 2**n or lower than or equal to -2**n will be\n    encoded as strings.\n\n    If specified, *item_sort_key* is a callable used to sort the items in\n    each dictionary. This is useful if you want to sort items other than\n    in alphabetical order by key. This option takes precedence over\n    *sort_keys*.\n\n    If *sort_keys* is true (default: ``False``), the output of dictionaries\n    will be sorted by item.\n\n    If *for_json* is true (default: ``False``), objects with a ``for_json()``\n    method will use the return value of that method for encoding as JSON\n    instead of the object.\n\n    If *ignore_nan* is true (default: ``False``), then out of range\n    :class:`float` values (``nan``, ``inf``, ``-inf``) will be serialized as\n    ``null`` in compliance with the ECMA-262 specification. If true, this will\n    override *allow_nan*.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg. NOTE: You should use *default* or *for_json* instead\n    of subclassing whenever possible.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        encoding == 'utf-8' and default is None and use_decimal\n        and namedtuple_as_object and tuple_as_array and not iterable_as_array\n        and not bigint_as_string and not sort_keys\n        and not item_sort_key and not for_json\n        and not ignore_nan and int_as_string_bitcount is None\n        and not kw\n    ):\n        iterable = _default_encoder.iterencode(obj)\n    else:\n        if cls is None:\n            cls = JSONEncoder\n        iterable = cls(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n            check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n            separators=separators, encoding=encoding,\n            default=default, use_decimal=use_decimal,\n            namedtuple_as_object=namedtuple_as_object,\n            tuple_as_array=tuple_as_array,\n            iterable_as_array=iterable_as_array,\n            bigint_as_string=bigint_as_string,\n            sort_keys=sort_keys,\n            item_sort_key=item_sort_key,\n            for_json=for_json,\n            ignore_nan=ignore_nan,\n            int_as_string_bitcount=int_as_string_bitcount,\n            **kw).iterencode(obj)\n    # could accelerate with writelines in some versions of Python, at\n    # a debuggability cost\n    for chunk in iterable:\n        fp.write(chunk)", "response": "Serialize obj as a JSON formatted stream to fp."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes obj to a JSON formatted string.", "response": "def dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True,\n          allow_nan=True, cls=None, indent=None, separators=None,\n          encoding='utf-8', default=None, use_decimal=True,\n          namedtuple_as_object=True, tuple_as_array=True,\n          bigint_as_string=False, sort_keys=False, item_sort_key=None,\n          for_json=False, ignore_nan=False, int_as_string_bitcount=None,\n          iterable_as_array=False, **kw):\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is false then ``dict`` keys that are not basic types\n    (``str``, ``unicode``, ``int``, ``long``, ``float``, ``bool``, ``None``)\n    will be skipped instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value will be a\n    ``unicode`` instance subject to normal Python ``str`` to ``unicode``\n    coercion rules instead of being escaped to an ASCII ``str``.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``OverflowError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a string, then JSON array elements and object members\n    will be pretty-printed with a newline followed by that string repeated\n    for each level of nesting. ``None`` (the default) selects the most compact\n    representation without any newlines. For backwards compatibility with\n    versions of simplejson earlier than 2.1.0, an integer is also accepted\n    and is converted to a string with that many spaces.\n\n    If specified, ``separators`` should be an\n    ``(item_separator, key_separator)`` tuple.  The default is ``(', ', ': ')``\n    if *indent* is ``None`` and ``(',', ': ')`` otherwise.  To get the most\n    compact JSON representation, you should specify ``(',', ':')`` to eliminate\n    whitespace.\n\n    ``encoding`` is the character encoding for str instances, default is UTF-8.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *use_decimal* is true (default: ``True``) then decimal.Decimal\n    will be natively serialized to JSON with full precision.\n\n    If *namedtuple_as_object* is true (default: ``True``),\n    :class:`tuple` subclasses with ``_asdict()`` methods will be encoded\n    as JSON objects.\n\n    If *tuple_as_array* is true (default: ``True``),\n    :class:`tuple` (and subclasses) will be encoded as JSON arrays.\n\n    If *iterable_as_array* is true (default: ``False``),\n    any object not in the above table that implements ``__iter__()``\n    will be encoded as a JSON array.\n\n    If *bigint_as_string* is true (not the default), ints 2**53 and higher\n    or lower than -2**53 will be encoded as strings. This is to avoid the\n    rounding that happens in Javascript otherwise.\n\n    If *int_as_string_bitcount* is a positive number (n), then int of size\n    greater than or equal to 2**n or lower than or equal to -2**n will be\n    encoded as strings.\n\n    If specified, *item_sort_key* is a callable used to sort the items in\n    each dictionary. This is useful if you want to sort items other than\n    in alphabetical order by key. This option takes precendence over\n    *sort_keys*.\n\n    If *sort_keys* is true (default: ``False``), the output of dictionaries\n    will be sorted by item.\n\n    If *for_json* is true (default: ``False``), objects with a ``for_json()``\n    method will use the return value of that method for encoding as JSON\n    instead of the object.\n\n    If *ignore_nan* is true (default: ``False``), then out of range\n    :class:`float` values (``nan``, ``inf``, ``-inf``) will be serialized as\n    ``null`` in compliance with the ECMA-262 specification. If true, this will\n    override *allow_nan*.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg. NOTE: You should use *default* instead of subclassing\n    whenever possible.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        encoding == 'utf-8' and default is None and use_decimal\n        and namedtuple_as_object and tuple_as_array and not iterable_as_array\n        and not bigint_as_string and not sort_keys\n        and not item_sort_key and not for_json\n        and not ignore_nan and int_as_string_bitcount is None\n        and not kw\n    ):\n        return _default_encoder.encode(obj)\n    if cls is None:\n        cls = JSONEncoder\n    return cls(\n        skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n        check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n        separators=separators, encoding=encoding, default=default,\n        use_decimal=use_decimal,\n        namedtuple_as_object=namedtuple_as_object,\n        tuple_as_array=tuple_as_array,\n        iterable_as_array=iterable_as_array,\n        bigint_as_string=bigint_as_string,\n        sort_keys=sort_keys,\n        item_sort_key=item_sort_key,\n        for_json=for_json,\n        ignore_nan=ignore_nan,\n        int_as_string_bitcount=int_as_string_bitcount,\n        **kw).encode(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loads(s, encoding=None, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None,\n        use_decimal=False, **kw):\n    \"\"\"Deserialize ``s`` (a ``str`` or ``unicode`` instance containing a JSON\n    document) to a Python object.\n\n    *encoding* determines the encoding used to interpret any\n    :class:`str` objects decoded by this instance (``'utf-8'`` by\n    default).  It has no effect when decoding :class:`unicode` objects.\n\n    Note that currently only encodings that are a superset of ASCII work,\n    strings of other encodings should be passed in as :class:`unicode`.\n\n    *object_hook*, if specified, will be called with the result of every\n    JSON object decoded and its return value will be used in place of the\n    given :class:`dict`.  This can be used to provide custom\n    deserializations (e.g. to support JSON-RPC class hinting).\n\n    *object_pairs_hook* is an optional function that will be called with\n    the result of any object literal decode with an ordered list of pairs.\n    The return value of *object_pairs_hook* will be used instead of the\n    :class:`dict`.  This feature can be used to implement custom decoders\n    that rely on the order that the key and value pairs are decoded (for\n    example, :func:`collections.OrderedDict` will remember the order of\n    insertion). If *object_hook* is also defined, the *object_pairs_hook*\n    takes priority.\n\n    *parse_float*, if specified, will be called with the string of every\n    JSON float to be decoded.  By default, this is equivalent to\n    ``float(num_str)``. This can be used to use another datatype or parser\n    for JSON floats (e.g. :class:`decimal.Decimal`).\n\n    *parse_int*, if specified, will be called with the string of every\n    JSON int to be decoded.  By default, this is equivalent to\n    ``int(num_str)``.  This can be used to use another datatype or parser\n    for JSON integers (e.g. :class:`float`).\n\n    *parse_constant*, if specified, will be called with one of the\n    following strings: ``'-Infinity'``, ``'Infinity'``, ``'NaN'``.  This\n    can be used to raise an exception if invalid JSON numbers are\n    encountered.\n\n    If *use_decimal* is true (default: ``False``) then it implies\n    parse_float=decimal.Decimal for parity with ``dump``.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg. NOTE: You should use *object_hook* or *object_pairs_hook* instead\n    of subclassing whenever possible.\n\n    \"\"\"\n    if (cls is None and encoding is None and object_hook is None and\n            parse_int is None and parse_float is None and\n            parse_constant is None and object_pairs_hook is None\n            and not use_decimal and not kw):\n        return _default_decoder.decode(s)\n    if cls is None:\n        cls = JSONDecoder\n    if object_hook is not None:\n        kw['object_hook'] = object_hook\n    if object_pairs_hook is not None:\n        kw['object_pairs_hook'] = object_pairs_hook\n    if parse_float is not None:\n        kw['parse_float'] = parse_float\n    if parse_int is not None:\n        kw['parse_int'] = parse_int\n    if parse_constant is not None:\n        kw['parse_constant'] = parse_constant\n    if use_decimal:\n        if parse_float is not None:\n            raise TypeError(\"use_decimal=True implies parse_float=Decimal\")\n        kw['parse_float'] = Decimal\n    return cls(encoding=encoding, **kw).decode(s)", "response": "Deserialize a string or unicode object containing a JSON\n    document into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a regex that matches any string in the sorted list of strings.", "response": "def regex_opt_inner(strings, open_paren):\n    \"\"\"Return a regex that matches any string in the sorted list of strings.\"\"\"\n    close_paren = open_paren and ')' or ''\n    # print strings, repr(open_paren)\n    if not strings:\n        # print '-> nothing left'\n        return ''\n    first = strings[0]\n    if len(strings) == 1:\n        # print '-> only 1 string'\n        return open_paren + escape(first) + close_paren\n    if not first:\n        # print '-> first string empty'\n        return open_paren + regex_opt_inner(strings[1:], '(?:') \\\n            + '?' + close_paren\n    if len(first) == 1:\n        # multiple one-char strings? make a charset\n        oneletter = []\n        rest = []\n        for s in strings:\n            if len(s) == 1:\n                oneletter.append(s)\n            else:\n                rest.append(s)\n        if len(oneletter) > 1:  # do we have more than one oneletter string?\n            if rest:\n                # print '-> 1-character + rest'\n                return open_paren + regex_opt_inner(rest, '') + '|' \\\n                    + make_charset(oneletter) + close_paren\n            # print '-> only 1-character'\n            return open_paren + make_charset(oneletter) + close_paren\n    prefix = commonprefix(strings)\n    if prefix:\n        plen = len(prefix)\n        # we have a prefix for all strings\n        # print '-> prefix:', prefix\n        return open_paren + escape(prefix) \\\n            + regex_opt_inner([s[plen:] for s in strings], '(?:') \\\n            + close_paren\n    # is there a suffix?\n    strings_rev = [s[::-1] for s in strings]\n    suffix = commonprefix(strings_rev)\n    if suffix:\n        slen = len(suffix)\n        # print '-> suffix:', suffix[::-1]\n        return open_paren \\\n            + regex_opt_inner(sorted(s[:-slen] for s in strings), '(?:') \\\n            + escape(suffix[::-1]) + close_paren\n    # recurse on common 1-string prefixes\n    # print '-> last resort'\n    return open_paren + \\\n        '|'.join(regex_opt_inner(list(group[1]), '')\n                 for group in groupby(strings, lambda s: s[0] == first[0])) \\\n        + close_paren"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef regex_opt(strings, prefix='', suffix=''):\n    strings = sorted(strings)\n    return prefix + regex_opt_inner(strings, '(') + suffix", "response": "Return a compiled regex that matches any string in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens a resource from the zoneinfo subdir for reading.", "response": "def open_resource(name):\n    \"\"\"Open a resource from the zoneinfo subdir for reading.\n\n    Uses the pkg_resources module if available and no standard file\n    found at the calculated location.\n    \"\"\"\n    name_parts = name.lstrip('/').split('/')\n    for part in name_parts:\n        if part == os.path.pardir or os.path.sep in part:\n            raise ValueError('Bad path segment: %r' % part)\n    filename = os.path.join(os.path.dirname(__file__),\n                            'zoneinfo', *name_parts)\n    if not os.path.exists(filename):\n        # http://bugs.launchpad.net/bugs/383171 - we avoid using this\n        # unless absolutely necessary to help when a broken version of\n        # pkg_resources is installed.\n        try:\n            from pkg_resources import resource_stream\n        except ImportError:\n            resource_stream = None\n\n        if resource_stream is not None:\n            return resource_stream(__name__, 'zoneinfo/' + name)\n    return open(filename, 'rb')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a fixed - offset timezone based off a number of minutes.", "response": "def FixedOffset(offset, _tzinfos = {}):\n    \"\"\"return a fixed-offset timezone based off a number of minutes.\n\n        >>> one = FixedOffset(-330)\n        >>> one\n        pytz.FixedOffset(-330)\n        >>> one.utcoffset(datetime.datetime.now())\n        datetime.timedelta(-1, 66600)\n        >>> one.dst(datetime.datetime.now())\n        datetime.timedelta(0)\n\n        >>> two = FixedOffset(1380)\n        >>> two\n        pytz.FixedOffset(1380)\n        >>> two.utcoffset(datetime.datetime.now())\n        datetime.timedelta(0, 82800)\n        >>> two.dst(datetime.datetime.now())\n        datetime.timedelta(0)\n\n    The datetime.timedelta must be between the range of -1 and 1 day,\n    non-inclusive.\n\n        >>> FixedOffset(1440)\n        Traceback (most recent call last):\n        ...\n        ValueError: ('absolute offset is too large', 1440)\n\n        >>> FixedOffset(-1440)\n        Traceback (most recent call last):\n        ...\n        ValueError: ('absolute offset is too large', -1440)\n\n    An offset of 0 is special-cased to return UTC.\n\n        >>> FixedOffset(0) is UTC\n        True\n\n    There should always be only one instance of a FixedOffset per timedelta.\n    This should be true for multiple creation calls.\n\n        >>> FixedOffset(-330) is one\n        True\n        >>> FixedOffset(1380) is two\n        True\n\n    It should also be true for pickling.\n\n        >>> import pickle\n        >>> pickle.loads(pickle.dumps(one)) is one\n        True\n        >>> pickle.loads(pickle.dumps(two)) is two\n        True\n    \"\"\"\n    if offset == 0:\n        return UTC\n\n    info = _tzinfos.get(offset)\n    if info is None:\n        # We haven't seen this one before. we need to save it.\n\n        # Use setdefault to avoid a race condition and make sure we have\n        # only one\n        info = _tzinfos.setdefault(offset, _FixedOffset(offset))\n\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef c2l(c):\n    \"char[4] to unsigned long\"\n    l = U32(c[0])\n    l = l | (U32(c[1]) << 8)\n    l = l | (U32(c[2]) << 16)\n    l = l | (U32(c[3]) << 24)\n    return l", "response": "char [ 4 ] to unsigned long"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef PERM_OP(tup, n, m):\n    \"tup - (a, b, t)\"\n    a, b, t = tup\n    t = ((a >> n) ^ b) & m\n    b = b ^ t\n    a = a ^ (t << n)\n    return (a, b, t)", "response": "tup - a b t"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a request using the appropriate encoding of the fields and headers.", "response": "def request(self, method, url, fields=None, headers=None, **urlopen_kw):\n        \"\"\"\n        Make a request using :meth:`urlopen` with the appropriate encoding of\n        ``fields`` based on the ``method`` used.\n\n        This is a convenience method that requires the least amount of manual\n        effort. It can be used in most situations, while still having the\n        option to drop down to more specific methods when necessary, such as\n        :meth:`request_encode_url`, :meth:`request_encode_body`,\n        or even the lowest level :meth:`urlopen`.\n        \"\"\"\n        method = method.upper()\n\n        if method in self._encode_url_methods:\n            return self.request_encode_url(method, url, fields=fields,\n                                           headers=headers,\n                                           **urlopen_kw)\n        else:\n            return self.request_encode_body(method, url, fields=fields,\n                                            headers=headers,\n                                            **urlopen_kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line arguments and configs from ~/.wakatime. cfg.", "response": "def parse_arguments():\n    \"\"\"Parse command line arguments and configs from ~/.wakatime.cfg.\n    Command line arguments take precedence over config file settings.\n    Returns instances of ArgumentParser and SafeConfigParser.\n    \"\"\"\n\n    # define supported command line arguments\n    parser = argparse.ArgumentParser(description='Common interface for the ' +\n                                                 'WakaTime api.')\n    parser.add_argument('--entity', dest='entity', metavar='FILE',\n                        action=FileAction,\n                        help='Absolute path to file for the heartbeat. Can ' +\n                             'also be a url, domain or app when ' +\n                             '--entity-type is not file.')\n    parser.add_argument('--file', dest='file', action=FileAction,\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--key', dest='key', action=StoreWithoutQuotes,\n                        help='Your wakatime api key; uses api_key from ' +\n                             '~/.wakatime.cfg by default.')\n    parser.add_argument('--write', dest='is_write', action='store_true',\n                        help='When set, tells api this heartbeat was ' +\n                             'triggered from writing to a file.')\n    parser.add_argument('--plugin', dest='plugin', action=StoreWithoutQuotes,\n                        help='Optional text editor plugin name and version ' +\n                             'for User-Agent header.')\n    parser.add_argument('--time', dest='timestamp', metavar='time',\n                        type=float, action=StoreWithoutQuotes,\n                        help='Optional floating-point unix epoch timestamp. ' +\n                             'Uses current time by default.')\n    parser.add_argument('--lineno', dest='lineno', action=StoreWithoutQuotes,\n                        help='Optional line number. This is the current ' +\n                             'line being edited.')\n    parser.add_argument('--cursorpos', dest='cursorpos',\n                        action=StoreWithoutQuotes,\n                        help='Optional cursor position in the current file.')\n    parser.add_argument('--entity-type', dest='entity_type',\n                        action=StoreWithoutQuotes,\n                        help='Entity type for this heartbeat. Can be ' +\n                             '\"file\", \"domain\" or \"app\". Defaults to \"file\".')\n    parser.add_argument('--category', dest='category',\n                        action=StoreWithoutQuotes,\n                        help='Category of this heartbeat activity. Can be ' +\n                             '\"coding\", \"building\", \"indexing\", ' +\n                             '\"debugging\", \"running tests\", ' +\n                             '\"writing tests\", \"manual testing\", ' +\n                             '\"code reviewing\", \"browsing\", or \"designing\". ' +\n                             'Defaults to \"coding\".')\n    parser.add_argument('--proxy', dest='proxy', action=StoreWithoutQuotes,\n                        help='Optional proxy configuration. Supports HTTPS '+\n                             'and SOCKS proxies. For example: '+\n                             'https://user:pass@host:port or '+\n                             'socks5://user:pass@host:port or ' +\n                             'domain\\\\user:pass')\n    parser.add_argument('--no-ssl-verify', dest='nosslverify',\n                        action='store_true',\n                        help='Disables SSL certificate verification for HTTPS '+\n                             'requests. By default, SSL certificates are ' +\n                             'verified.')\n    parser.add_argument('--ssl-certs-file', dest='ssl_certs_file',\n                        action=StoreWithoutQuotes,\n                        help='Override the bundled Python Requests CA certs ' +\n                             'file. By default, uses certifi for ca certs.')\n    parser.add_argument('--project', dest='project', action=StoreWithoutQuotes,\n                        help='Optional project name.')\n    parser.add_argument('--alternate-project', dest='alternate_project',\n                        action=StoreWithoutQuotes,\n                        help='Optional alternate project name. ' +\n                             'Auto-discovered project takes priority.')\n    parser.add_argument('--alternate-language', dest='alternate_language',\n                        action=StoreWithoutQuotes,\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--language', dest='language',\n                        action=StoreWithoutQuotes,\n                        help='Optional language name. If valid, takes ' +\n                             'priority over auto-detected language.')\n    parser.add_argument('--local-file', dest='local_file', metavar='FILE',\n                        action=FileAction,\n                        help='Absolute path to local file for the ' +\n                             'heartbeat. When --entity is a remote file, ' +\n                             'this local file will be used for stats and ' +\n                             'just the value of --entity sent with heartbeat.')\n    parser.add_argument('--hostname', dest='hostname',\n                        action=StoreWithoutQuotes,\n                        help='Hostname of current machine.')\n    parser.add_argument('--disable-offline', dest='offline',\n                        action='store_false',\n                        help='Disables offline time logging instead of ' +\n                             'queuing logged time.')\n    parser.add_argument('--disableoffline', dest='offline_deprecated',\n                        action='store_true',\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--hide-file-names', dest='hide_file_names',\n                        action='store_true',\n                        help='Obfuscate filenames. Will not send file names ' +\n                             'to api.')\n    parser.add_argument('--hide-filenames', dest='hide_filenames',\n                        action='store_true',\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--hidefilenames', dest='hidefilenames',\n                        action='store_true',\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--hide-project-names', dest='hide_project_names',\n                        action='store_true',\n                        help='Obfuscate project names. When a project ' +\n                             'folder is detected instead of using the ' +\n                             'folder name as the project, a ' +\n                             '.wakatime-project file is created with a ' +\n                             'random project name.')\n    parser.add_argument('--exclude', dest='exclude', action='append',\n                        help='Filename patterns to exclude from logging. ' +\n                             'POSIX regex syntax. Can be used more than once.')\n    parser.add_argument('--exclude-unknown-project',\n                        dest='exclude_unknown_project', action='store_true',\n                        help='When set, any activity where the project ' +\n                             'cannot be detected will be ignored.')\n    parser.add_argument('--include', dest='include', action='append',\n                        help='Filename patterns to log. When used in ' +\n                             'combination with --exclude, files matching ' +\n                             'include will still be logged. POSIX regex ' +\n                             'syntax. Can be used more than once.')\n    parser.add_argument('--include-only-with-project-file',\n                        dest='include_only_with_project_file',\n                        action='store_true',\n                        help='Disables tracking folders unless they contain ' +\n                             'a .wakatime-project file. Defaults to false.')\n    parser.add_argument('--ignore', dest='ignore', action='append',\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--extra-heartbeats', dest='extra_heartbeats',\n                        action='store_true',\n                        help='Reads extra heartbeats from STDIN as a JSON ' +\n                             'array until EOF.')\n    parser.add_argument('--log-file', dest='log_file',\n                        action=StoreWithoutQuotes,\n                        help='Defaults to ~/.wakatime.log.')\n    parser.add_argument('--logfile', dest='logfile', action=StoreWithoutQuotes,\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--api-url', dest='api_url', action=StoreWithoutQuotes,\n                        help='Heartbeats api url. For debugging with a ' +\n                             'local server.')\n    parser.add_argument('--apiurl', dest='apiurl', action=StoreWithoutQuotes,\n                        help=argparse.SUPPRESS)\n    parser.add_argument('--timeout', dest='timeout', type=int,\n                        action=StoreWithoutQuotes,\n                        help='Number of seconds to wait when sending ' +\n                             'heartbeats to api. Defaults to 60 seconds.')\n    parser.add_argument('--sync-offline-activity',\n                        dest='sync_offline_activity',\n                        action=StoreWithoutQuotes,\n                        help='Amount of offline activity to sync from your ' +\n                             'local ~/.wakatime.db sqlite3 file to your ' +\n                             'WakaTime Dashboard before exiting. Can be ' +\n                             '\"none\" or a positive integer number. Defaults ' +\n                             'to 5, meaning for every heartbeat sent while ' +\n                             'online 5 offline heartbeats are synced. Can ' +\n                             'be used without --entity to only sync offline ' +\n                             'activity without generating new heartbeats.')\n    parser.add_argument('--config', dest='config', action=StoreWithoutQuotes,\n                        help='Defaults to ~/.wakatime.cfg.')\n    parser.add_argument('--verbose', dest='verbose', action='store_true',\n                        help='Turns on debug messages in log file.')\n    parser.add_argument('--version', action='version', version=__version__)\n\n    # parse command line arguments\n    args = parser.parse_args()\n\n    # use current unix epoch timestamp by default\n    if not args.timestamp:\n        args.timestamp = time.time()\n\n    # parse ~/.wakatime.cfg file\n    configs = parseConfigFile(args.config)\n\n    # update args from configs\n    if not args.hostname:\n        if configs.has_option('settings', 'hostname'):\n            args.hostname = configs.get('settings', 'hostname')\n    if not args.key:\n        default_key = None\n        if configs.has_option('settings', 'api_key'):\n            default_key = configs.get('settings', 'api_key')\n        elif configs.has_option('settings', 'apikey'):\n            default_key = configs.get('settings', 'apikey')\n        if default_key:\n            args.key = default_key\n        else:\n            try:\n                parser.error('Missing api key. Find your api key from wakatime.com/settings/api-key.')\n            except SystemExit:\n                raise SystemExit(AUTH_ERROR)\n\n    is_valid = not not re.match(r'^[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[89ab][a-f0-9]{3}-[a-f0-9]{12}$', args.key, re.I)\n    if not is_valid:\n        try:\n            parser.error('Invalid api key. Find your api key from wakatime.com/settings/api-key.')\n        except SystemExit:\n            raise SystemExit(AUTH_ERROR)\n\n    if not args.entity:\n        if args.file:\n            args.entity = args.file\n        elif not args.sync_offline_activity or args.sync_offline_activity == 'none':\n            parser.error('argument --entity is required')\n\n    if not args.sync_offline_activity:\n        args.sync_offline_activity = DEFAULT_SYNC_OFFLINE_ACTIVITY\n    if args.sync_offline_activity == 'none':\n        args.sync_offline_activity = 0\n    try:\n        args.sync_offline_activity = int(args.sync_offline_activity)\n        if args.sync_offline_activity < 0:\n            raise Exception('Error')\n    except:\n        parser.error('argument --sync-offline-activity must be \"none\" or an integer number')\n\n    if not args.language and args.alternate_language:\n        args.language = args.alternate_language\n\n    if not args.exclude:\n        args.exclude = []\n    if configs.has_option('settings', 'ignore'):\n        try:\n            for pattern in configs.get('settings', 'ignore').split(\"\\n\"):\n                if pattern.strip() != '':\n                    args.exclude.append(pattern)\n        except TypeError:  # pragma: nocover\n            pass\n    if configs.has_option('settings', 'exclude'):\n        try:\n            for pattern in configs.get('settings', 'exclude').split(\"\\n\"):\n                if pattern.strip() != '':\n                    args.exclude.append(pattern)\n        except TypeError:  # pragma: nocover\n            pass\n    if not args.include_only_with_project_file and configs.has_option('settings', 'include_only_with_project_file'):\n        args.include_only_with_project_file = configs.get('settings', 'include_only_with_project_file') == 'true'\n    if not args.include:\n        args.include = []\n    if configs.has_option('settings', 'include'):\n        try:\n            for pattern in configs.get('settings', 'include').split(\"\\n\"):\n                if pattern.strip() != '':\n                    args.include.append(pattern)\n        except TypeError:  # pragma: nocover\n            pass\n    if not args.exclude_unknown_project and configs.has_option('settings', 'exclude_unknown_project'):\n        args.exclude_unknown_project = configs.getboolean('settings', 'exclude_unknown_project')\n    boolean_or_list('hide_file_names', args, configs, alternative_names=['hide_filenames', 'hidefilenames'])\n    boolean_or_list('hide_project_names', args, configs, alternative_names=['hide_projectnames', 'hideprojectnames'])\n    if args.offline_deprecated:\n        args.offline = False\n    if args.offline and configs.has_option('settings', 'offline'):\n        args.offline = configs.getboolean('settings', 'offline')\n    if not args.proxy and configs.has_option('settings', 'proxy'):\n        args.proxy = configs.get('settings', 'proxy')\n    if args.proxy:\n        pattern = r'^((https?|socks5)://)?([^:@]+(:([^:@])+)?@)?[^:]+(:\\d+)?$'\n        if '\\\\' in args.proxy:\n            pattern = r'^.*\\\\.+$'\n        is_valid = not not re.match(pattern, args.proxy, re.I)\n        if not is_valid:\n            parser.error('Invalid proxy. Must be in format ' +\n                         'https://user:pass@host:port or ' +\n                         'socks5://user:pass@host:port or ' +\n                         'domain\\\\user:pass.')\n    if configs.has_option('settings', 'no_ssl_verify'):\n        args.nosslverify = configs.getboolean('settings', 'no_ssl_verify')\n    if configs.has_option('settings', 'ssl_certs_file'):\n        args.ssl_certs_file = configs.get('settings', 'ssl_certs_file')\n    if not args.verbose and configs.has_option('settings', 'verbose'):\n        args.verbose = configs.getboolean('settings', 'verbose')\n    if not args.verbose and configs.has_option('settings', 'debug'):\n        args.verbose = configs.getboolean('settings', 'debug')\n    if not args.log_file and args.logfile:\n        args.log_file = args.logfile\n    if not args.log_file and configs.has_option('settings', 'log_file'):\n        args.log_file = configs.get('settings', 'log_file')\n    if not args.log_file and os.environ.get('WAKATIME_HOME'):\n        home = os.environ.get('WAKATIME_HOME')\n        args.log_file = os.path.join(os.path.expanduser(home), '.wakatime.log')\n    if not args.api_url and args.apiurl:\n        args.api_url = args.apiurl\n    if not args.api_url and configs.has_option('settings', 'api_url'):\n        args.api_url = configs.get('settings', 'api_url')\n    if not args.timeout and configs.has_option('settings', 'timeout'):\n        try:\n            args.timeout = int(configs.get('settings', 'timeout'))\n        except ValueError:\n            print(traceback.format_exc())\n\n    return args, configs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a boolean or list of regexes from args and configs.", "response": "def boolean_or_list(config_name, args, configs, alternative_names=[]):\n    \"\"\"Get a boolean or list of regexes from args and configs.\"\"\"\n\n    # when argument flag present, set to wildcard regex\n    for key in alternative_names + [config_name]:\n        if hasattr(args, key) and getattr(args, key):\n            setattr(args, config_name, ['.*'])\n            return\n\n    setattr(args, config_name, [])\n\n    option = None\n    alternative_names.insert(0, config_name)\n    for key in alternative_names:\n        if configs.has_option('settings', key):\n            option = configs.get('settings', key)\n            break\n\n    if option is not None:\n        if option.strip().lower() == 'true':\n            setattr(args, config_name, ['.*'])\n        elif option.strip().lower() != 'false':\n            for pattern in option.split(\"\\n\"):\n                if pattern.strip() != '':\n                    getattr(args, config_name).append(pattern)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef objective(baselexer):\n\n    # Have to be careful not to accidentally match JavaDoc/Doxygen syntax here,\n    # since that's quite common in ordinary C/C++ files.  It's OK to match\n    # JavaDoc/Doxygen keywords that only apply to Objective-C, mind.\n    #\n    # The upshot of this is that we CANNOT match @class or @interface\n    _oc_keywords = re.compile(r'@(?:end|implementation|protocol)')\n\n    # Matches [ <ws>? identifier <ws> ( identifier <ws>? ] |  identifier? : )\n    # (note the identifier is *optional* when there is a ':'!)\n    _oc_message = re.compile(r'\\[\\s*[a-zA-Z_]\\w*\\s+'\n                             r'(?:[a-zA-Z_]\\w*\\s*\\]|'\n                             r'(?:[a-zA-Z_]\\w*)?:)')\n\n    class GeneratedObjectiveCVariant(baselexer):\n        \"\"\"\n        Implements Objective-C syntax on top of an existing C family lexer.\n        \"\"\"\n\n        tokens = {\n            'statements': [\n                (r'@\"', String, 'string'),\n                (r'@(YES|NO)', Number),\n                (r\"@'(\\\\.|\\\\[0-7]{1,3}|\\\\x[a-fA-F0-9]{1,2}|[^\\\\\\'\\n])'\", String.Char),\n                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+)[eE][+-]?\\d+[lL]?', Number.Float),\n                (r'@(\\d+\\.\\d*|\\.\\d+|\\d+[fF])[fF]?', Number.Float),\n                (r'@0x[0-9a-fA-F]+[Ll]?', Number.Hex),\n                (r'@0[0-7]+[Ll]?', Number.Oct),\n                (r'@\\d+[Ll]?', Number.Integer),\n                (r'@\\(', Literal, 'literal_number'),\n                (r'@\\[', Literal, 'literal_array'),\n                (r'@\\{', Literal, 'literal_dictionary'),\n                (words((\n                    '@selector', '@private', '@protected', '@public', '@encode',\n                    '@synchronized', '@try', '@throw', '@catch', '@finally',\n                    '@end', '@property', '@synthesize', '__bridge', '__bridge_transfer',\n                    '__autoreleasing', '__block', '__weak', '__strong', 'weak', 'strong',\n                    'copy', 'retain', 'assign', 'unsafe_unretained', 'atomic', 'nonatomic',\n                    'readonly', 'readwrite', 'setter', 'getter', 'typeof', 'in',\n                    'out', 'inout', 'release', 'class', '@dynamic', '@optional',\n                    '@required', '@autoreleasepool'), suffix=r'\\b'),\n                 Keyword),\n                (words(('id', 'instancetype', 'Class', 'IMP', 'SEL', 'BOOL',\n                        'IBOutlet', 'IBAction', 'unichar'), suffix=r'\\b'),\n                 Keyword.Type),\n                (r'@(true|false|YES|NO)\\n', Name.Builtin),\n                (r'(YES|NO|nil|self|super)\\b', Name.Builtin),\n                # Carbon types\n                (r'(Boolean|UInt8|SInt8|UInt16|SInt16|UInt32|SInt32)\\b', Keyword.Type),\n                # Carbon built-ins\n                (r'(TRUE|FALSE)\\b', Name.Builtin),\n                (r'(@interface|@implementation)(\\s+)', bygroups(Keyword, Text),\n                 ('#pop', 'oc_classname')),\n                (r'(@class|@protocol)(\\s+)', bygroups(Keyword, Text),\n                 ('#pop', 'oc_forward_classname')),\n                # @ can also prefix other expressions like @{...} or @(...)\n                (r'@', Punctuation),\n                inherit,\n            ],\n            'oc_classname': [\n                # interface definition that inherits\n                ('([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?(\\s*)(\\{)',\n                 bygroups(Name.Class, Text, Name.Class, Text, Punctuation),\n                 ('#pop', 'oc_ivars')),\n                ('([a-zA-Z$_][\\w$]*)(\\s*:\\s*)([a-zA-Z$_][\\w$]*)?',\n                 bygroups(Name.Class, Text, Name.Class), '#pop'),\n                # interface definition for a category\n                ('([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))(\\s*)(\\{)',\n                 bygroups(Name.Class, Text, Name.Label, Text, Punctuation),\n                 ('#pop', 'oc_ivars')),\n                ('([a-zA-Z$_][\\w$]*)(\\s*)(\\([a-zA-Z$_][\\w$]*\\))',\n                 bygroups(Name.Class, Text, Name.Label), '#pop'),\n                # simple interface / implementation\n                ('([a-zA-Z$_][\\w$]*)(\\s*)(\\{)',\n                 bygroups(Name.Class, Text, Punctuation), ('#pop', 'oc_ivars')),\n                ('([a-zA-Z$_][\\w$]*)', Name.Class, '#pop')\n            ],\n            'oc_forward_classname': [\n                ('([a-zA-Z$_][\\w$]*)(\\s*,\\s*)',\n                 bygroups(Name.Class, Text), 'oc_forward_classname'),\n                ('([a-zA-Z$_][\\w$]*)(\\s*;?)',\n                 bygroups(Name.Class, Text), '#pop')\n            ],\n            'oc_ivars': [\n                include('whitespace'),\n                include('statements'),\n                (';', Punctuation),\n                (r'\\{', Punctuation, '#push'),\n                (r'\\}', Punctuation, '#pop'),\n            ],\n            'root': [\n                # methods\n                (r'^([-+])(\\s*)'                         # method marker\n                 r'(\\(.*?\\))?(\\s*)'                      # return type\n                 r'([a-zA-Z$_][\\w$]*:?)',        # begin of method name\n                 bygroups(Punctuation, Text, using(this),\n                          Text, Name.Function),\n                 'method'),\n                inherit,\n            ],\n            'method': [\n                include('whitespace'),\n                # TODO unsure if ellipses are allowed elsewhere, see\n                # discussion in Issue 789\n                (r',', Punctuation),\n                (r'\\.\\.\\.', Punctuation),\n                (r'(\\(.*?\\))(\\s*)([a-zA-Z$_][\\w$]*)',\n                 bygroups(using(this), Text, Name.Variable)),\n                (r'[a-zA-Z$_][\\w$]*:', Name.Function),\n                (';', Punctuation, '#pop'),\n                (r'\\{', Punctuation, 'function'),\n                default('#pop'),\n            ],\n            'literal_number': [\n                (r'\\(', Punctuation, 'literal_number_inner'),\n                (r'\\)', Literal, '#pop'),\n                include('statement'),\n            ],\n            'literal_number_inner': [\n                (r'\\(', Punctuation, '#push'),\n                (r'\\)', Punctuation, '#pop'),\n                include('statement'),\n            ],\n            'literal_array': [\n                (r'\\[', Punctuation, 'literal_array_inner'),\n                (r'\\]', Literal, '#pop'),\n                include('statement'),\n            ],\n            'literal_array_inner': [\n                (r'\\[', Punctuation, '#push'),\n                (r'\\]', Punctuation, '#pop'),\n                include('statement'),\n            ],\n            'literal_dictionary': [\n                (r'\\}', Literal, '#pop'),\n                include('statement'),\n            ],\n        }\n\n        def analyse_text(text):\n            if _oc_keywords.search(text):\n                return 1.0\n            elif '@\"' in text:  # strings\n                return 0.8\n            elif re.search('@[0-9]+', text):\n                return 0.7\n            elif _oc_message.search(text):\n                return 0.8\n            return 0\n\n        def get_tokens_unprocessed(self, text):\n            from pygments.lexers._cocoa_builtins import COCOA_INTERFACES, \\\n                COCOA_PROTOCOLS, COCOA_PRIMITIVES\n\n            for index, token, value in \\\n                    baselexer.get_tokens_unprocessed(self, text):\n                if token is Name or token is Name.Class:\n                    if value in COCOA_INTERFACES or value in COCOA_PROTOCOLS \\\n                       or value in COCOA_PRIMITIVES:\n                        token = Name.Builtin.Pseudo\n\n                yield index, token, value\n\n    return GeneratedObjectiveCVariant", "response": "Generates a subclass of GeneratedObjectiveCVariant that accepts the Objective - C syntax."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the content of a language string using a lexer", "response": "def language_callback(lexer, match):\n    \"\"\"Parse the content of a $-string using a lexer\n\n    The lexer is chosen looking for a nearby LANGUAGE or assumed as\n    plpgsql if inside a DO statement and no LANGUAGE has been found.\n    \"\"\"\n    l = None\n    m = language_re.match(lexer.text[match.end():match.end()+100])\n    if m is not None:\n        l = lexer._get_lexer(m.group(1))\n    else:\n        m = list(language_re.finditer(\n            lexer.text[max(0, match.start()-100):match.start()]))\n        if m:\n            l = lexer._get_lexer(m[-1].group(1))\n        else:\n            m = list(do_re.finditer(\n                lexer.text[max(0, match.start()-25):match.start()]))\n            if m:\n                l = lexer._get_lexer('plpgsql')\n    \n    # 1 = $, 2 = delimiter, 3 = $\n    yield (match.start(1), String, match.group(1))\n    yield (match.start(2), String.Delimiter, match.group(2))\n    yield (match.start(3), String, match.group(3))\n    # 4 = string contents\n    if l:\n        for x in l.get_tokens_unprocessed(match.group(4)):\n            yield x\n    else:\n        yield (match.start(4), String, match.group(4))\n    # 5 = $, 6 = delimiter, 7 = $\n    yield (match.start(5), String, match.group(5))\n    yield (match.start(6), String.Delimiter, match.group(6))\n    yield (match.start(7), String, match.group(7))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the style definitions for the command sequences needed to define the commands in verbatim environment.", "response": "def get_style_defs(self, arg=''):\n        \"\"\"\n        Return the command sequences needed to define the commands\n        used to format text in the verbatim environment. ``arg`` is ignored.\n        \"\"\"\n        cp = self.commandprefix\n        styles = []\n        for name, definition in iteritems(self.cmd2def):\n            styles.append(r'\\expandafter\\def\\csname %s@tok@%s\\endcsname{%s}' %\n                          (cp, name, definition))\n        return STYLE_TEMPLATE % {'cp': self.commandprefix,\n                                 'styles': '\\n'.join(styles)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _lmowfv1(password):\n\n    # fix the password length to 14 bytes\n    password = password.upper()\n    lm_pw = password[0:14]\n\n    # do hash\n    magic_str = b\"KGS!@#$%\"  # page 56 in [MS-NLMP v28.0]\n\n    res = b''\n    dobj = des.DES(lm_pw[0:7])\n    res = res + dobj.encrypt(magic_str)\n\n    dobj = des.DES(lm_pw[7:14])\n    res = res + dobj.encrypt(magic_str)\n\n    return res", "response": "Create a one way Lan Manager hash of the password"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether the supplied file name fn matches pattern filename.", "response": "def _fn_matches(fn, glob):\n    \"\"\"Return whether the supplied file name fn matches pattern filename.\"\"\"\n    if glob not in _pattern_cache:\n        pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))\n        return pattern.match(fn)\n    return _pattern_cache[glob].match(fn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a formatter from a module.", "response": "def _load_formatters(module_name):\n    \"\"\"Load a formatter (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for formatter_name in mod.__all__:\n        cls = getattr(mod, formatter_name)\n        _formatter_cache[cls.name] = cls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_formatters():\n    # NB: this returns formatter classes, not info like get_all_lexers().\n    for info in itervalues(FORMATTERS):\n        if info[1] not in _formatter_cache:\n            _load_formatters(info[0])\n        yield _formatter_cache[info[1]]\n    for _, formatter in find_plugin_formatters():\n        yield formatter", "response": "Return a generator for all formatter classes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_formatter_class(alias):\n    for module_name, name, aliases, _, _ in itervalues(FORMATTERS):\n        if alias in aliases:\n            if name not in _formatter_cache:\n                _load_formatters(module_name)\n            return _formatter_cache[name]\n    for _, cls in find_plugin_formatters():\n        if alias in cls.aliases:\n            return cls", "response": "Lookup a formatter by alias."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_formatter_by_name(_alias, **options):\n    cls = find_formatter_class(_alias)\n    if cls is None:\n        raise ClassNotFound(\"no formatter found for name %r\" % _alias)\n    return cls(**options)", "response": "Lookup and instantiate a formatter by alias."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a formatter from a file.", "response": "def load_formatter_from_file(filename, formattername=\"CustomFormatter\",\n                             **options):\n    \"\"\"Load a formatter from a file.\n\n    This method expects a file located relative to the current working\n    directory, which contains a class named CustomFormatter. By default,\n    it expects the Formatter to be named CustomFormatter; you can specify\n    your own class name as the second argument to this function.\n\n    Users should be very careful with the input, because this method\n    is equivalent to running eval on the input file.\n\n    Raises ClassNotFound if there are any problems importing the Formatter.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    try:\n        # This empty dict will contain the namespace for the exec'd file\n        custom_namespace = {}\n        exec(open(filename, 'rb').read(), custom_namespace)\n        # Retrieve the class `formattername` from that namespace\n        if formattername not in custom_namespace:\n            raise ClassNotFound('no valid %s class found in %s' %\n                                (formattername, filename))\n        formatter_class = custom_namespace[formattername]\n        # And finally instantiate it with the options\n        return formatter_class(**options)\n    except IOError as err:\n        raise ClassNotFound('cannot read %s' % filename)\n    except ClassNotFound as err:\n        raise\n    except Exception as err:\n        raise ClassNotFound('error when loading custom formatter: %s' % err)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_formatter_for_filename(fn, **options):\n    fn = basename(fn)\n    for modname, name, _, filenames, _ in itervalues(FORMATTERS):\n        for filename in filenames:\n            if _fn_matches(fn, filename):\n                if name not in _formatter_cache:\n                    _load_formatters(modname)\n                return _formatter_cache[name](**options)\n    for cls in find_plugin_formatters():\n        for filename in cls.filenames:\n            if _fn_matches(fn, filename):\n                return cls(**options)\n    raise ClassNotFound(\"no formatter found for file name %r\" % fn)", "response": "Lookup and instantiate a formatter by filename pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tokens_unprocessed(self, text, stack=('root',)):\n        self.content_type = None\n        return RegexLexer.get_tokens_unprocessed(self, text, stack)", "response": "Return a list of tokens that can be processed by the lexer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON representation of a Python string.", "response": "def encode_basestring(s, _PY3=PY3, _q=u('\"')):\n    \"\"\"Return a JSON representation of a Python string\n\n    \"\"\"\n    if _PY3:\n        if isinstance(s, binary_type):\n            s = s.decode('utf-8')\n    else:\n        if isinstance(s, str) and HAS_UTF8.search(s) is not None:\n            s = s.decode('utf-8')\n    def replace(match):\n        return ESCAPE_DCT[match.group(0)]\n    return _q + ESCAPE.sub(replace, s) + _q"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an ASCII - only JSON representation of a Python string.", "response": "def py_encode_basestring_ascii(s, _PY3=PY3):\n    \"\"\"Return an ASCII-only JSON representation of a Python string\n\n    \"\"\"\n    if _PY3:\n        if isinstance(s, binary_type):\n            s = s.decode('utf-8')\n    else:\n        if isinstance(s, str) and HAS_UTF8.search(s) is not None:\n            s = s.decode('utf-8')\n    def replace(match):\n        s = match.group(0)\n        try:\n            return ESCAPE_DCT[s]\n        except KeyError:\n            n = ord(s)\n            if n < 0x10000:\n                #return '\\\\u{0:04x}'.format(n)\n                return '\\\\u%04x' % (n,)\n            else:\n                # surrogate pair\n                n -= 0x10000\n                s1 = 0xd800 | ((n >> 10) & 0x3ff)\n                s2 = 0xdc00 | (n & 0x3ff)\n                #return '\\\\u{0:04x}\\\\u{1:04x}'.format(s1, s2)\n                return '\\\\u%04x\\\\u%04x' % (s1, s2)\n    return '\"' + str(ESCAPE_ASCII.sub(replace, s)) + '\"'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a lexer and all others in the module.", "response": "def _load_lexers(module_name):\n    \"\"\"Load a lexer (and all others in the module too).\"\"\"\n    mod = __import__(module_name, None, None, ['__all__'])\n    for lexer_name in mod.__all__:\n        cls = getattr(mod, lexer_name)\n        _lexer_cache[cls.name] = cls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_lexers():\n    for item in itervalues(LEXERS):\n        yield item[1:]\n    for lexer in find_plugin_lexers():\n        yield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes", "response": "Return a generator of tuples that yields all the lexers in the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_lexer_class(name):\n    if name in _lexer_cache:\n        return _lexer_cache[name]\n    # lookup builtin lexers\n    for module_name, lname, aliases, _, _ in itervalues(LEXERS):\n        if name == lname:\n            _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if cls.name == name:\n            return cls", "response": "Lookup a lexer class by name. Return None if not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlooks up a lexer class by its alias.", "response": "def find_lexer_class_by_name(_alias):\n    \"\"\"Lookup a lexer class by alias.\n\n    Like `get_lexer_by_name`, but does not instantiate the class.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    if not _alias:\n        raise ClassNotFound('no lexer for alias %r found' % _alias)\n    # lookup builtin lexers\n    for module_name, name, aliases, _, _ in itervalues(LEXERS):\n        if _alias.lower() in aliases:\n            if name not in _lexer_cache:\n                _load_lexers(module_name)\n            return _lexer_cache[name]\n    # continue with lexers from setuptools entrypoints\n    for cls in find_plugin_lexers():\n        if _alias.lower() in cls.aliases:\n            return cls\n    raise ClassNotFound('no lexer for alias %r found' % _alias)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_lexer_from_file(filename, lexername=\"CustomLexer\", **options):\n    try:\n        # This empty dict will contain the namespace for the exec'd file\n        custom_namespace = {}\n        exec(open(filename, 'rb').read(), custom_namespace)\n        # Retrieve the class `lexername` from that namespace\n        if lexername not in custom_namespace:\n            raise ClassNotFound('no valid %s class found in %s' %\n                                (lexername, filename))\n        lexer_class = custom_namespace[lexername]\n        # And finally instantiate it with the options\n        return lexer_class(**options)\n    except IOError as err:\n        raise ClassNotFound('cannot read %s' % filename)\n    except ClassNotFound as err:\n        raise\n    except Exception as err:\n        raise ClassNotFound('error when loading custom lexer: %s' % err)", "response": "Load a lexer from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_lexer_class_for_filename(_fn, code=None):\n    matches = []\n    fn = basename(_fn)\n    for modname, name, _, filenames, _ in itervalues(LEXERS):\n        for filename in filenames:\n            if _fn_matches(fn, filename):\n                if name not in _lexer_cache:\n                    _load_lexers(modname)\n                matches.append((_lexer_cache[name], filename))\n    for cls in find_plugin_lexers():\n        for filename in cls.filenames:\n            if _fn_matches(fn, filename):\n                matches.append((cls, filename))\n\n    if sys.version_info > (3,) and isinstance(code, bytes):\n        # decode it, since all analyse_text functions expect unicode\n        code = guess_decode(code)\n\n    def get_rating(info):\n        cls, filename = info\n        # explicit patterns get a bonus\n        bonus = '*' not in filename and 0.5 or 0\n        # The class _always_ defines analyse_text because it's included in\n        # the Lexer class.  The default implementation returns None which\n        # gets turned into 0.0.  Run scripts/detect_missing_analyse_text.py\n        # to find lexers which need it overridden.\n        if code:\n            return cls.analyse_text(code) + bonus, cls.__name__\n        return cls.priority + bonus, cls.__name__\n\n    if matches:\n        matches.sort(key=get_rating)\n        # print \"Possible lexers, after sort:\", matches\n        return matches[-1][0]", "response": "Find a lexer for a filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_lexer_for_filename(_fn, code=None, **options):\n    res = find_lexer_class_for_filename(_fn, code)\n    if not res:\n        raise ClassNotFound('no lexer for filename %r found' % _fn)\n    return res(**options)", "response": "Get a lexer for a filename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_lexer_for_mimetype(_mime, **options):\n    for modname, name, _, _, mimetypes in itervalues(LEXERS):\n        if _mime in mimetypes:\n            if name not in _lexer_cache:\n                _load_lexers(modname)\n            return _lexer_cache[name](**options)\n    for cls in find_plugin_lexers():\n        if _mime in cls.mimetypes:\n            return cls(**options)\n    raise ClassNotFound('no lexer for mimetype %r found' % _mime)", "response": "Get a lexer for a mimetype. Raises ClassNotFound if no lexer is found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all lexer classes.", "response": "def _iter_lexerclasses(plugins=True):\n    \"\"\"Return an iterator over all lexer classes.\"\"\"\n    for key in sorted(LEXERS):\n        module_name, name = LEXERS[key][:2]\n        if name not in _lexer_cache:\n            _load_lexers(module_name)\n        yield _lexer_cache[name]\n    if plugins:\n        for lexer in find_plugin_lexers():\n            yield lexer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nguessing the lexer for a given filename.", "response": "def guess_lexer_for_filename(_fn, _text, **options):\n    \"\"\"\n    Lookup all lexers that handle those filenames primary (``filenames``)\n    or secondary (``alias_filenames``). Then run a text analysis for those\n    lexers and choose the best result.\n\n    usage::\n\n        >>> from pygments.lexers import guess_lexer_for_filename\n        >>> guess_lexer_for_filename('hello.html', '<%= @foo %>')\n        <pygments.lexers.templates.RhtmlLexer object at 0xb7d2f32c>\n        >>> guess_lexer_for_filename('hello.html', '<h1>{{ title|e }}</h1>')\n        <pygments.lexers.templates.HtmlDjangoLexer object at 0xb7d2f2ac>\n        >>> guess_lexer_for_filename('style.css', 'a { color: <?= $link ?> }')\n        <pygments.lexers.templates.CssPhpLexer object at 0xb7ba518c>\n    \"\"\"\n    fn = basename(_fn)\n    primary = {}\n    matching_lexers = set()\n    for lexer in _iter_lexerclasses():\n        for filename in lexer.filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = True\n        for filename in lexer.alias_filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = False\n    if not matching_lexers:\n        raise ClassNotFound('no lexer for filename %r found' % fn)\n    if len(matching_lexers) == 1:\n        return matching_lexers.pop()(**options)\n    result = []\n    for lexer in matching_lexers:\n        rv = lexer.analyse_text(_text)\n        if rv == 1.0:\n            return lexer(**options)\n        result.append((rv, lexer))\n\n    def type_sort(t):\n        # sort by:\n        # - analyse score\n        # - is primary filename pattern?\n        # - priority\n        # - last resort: class name\n        return (t[0], primary[t[1]], t[1].priority, t[1].__name__)\n    result.sort(key=type_sort)\n\n    return result[-1][1](**options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nguessing a lexer by strong distinctions in the text.", "response": "def guess_lexer(_text, **options):\n    \"\"\"Guess a lexer by strong distinctions in the text (eg, shebang).\"\"\"\n\n    # try to get a vim modeline first\n    ft = get_filetype_from_buffer(_text)\n\n    if ft is not None:\n        try:\n            return get_lexer_by_name(ft, **options)\n        except ClassNotFound:\n            pass\n\n    best_lexer = [0.0, None]\n    for lexer in _iter_lexerclasses():\n        rv = lexer.analyse_text(_text)\n        if rv == 1.0:\n            return lexer(**options)\n        if rv > best_lexer[0]:\n            best_lexer[:] = (rv, lexer)\n    if not best_lexer[0] or best_lexer[1] is None:\n        raise ClassNotFound('no lexer matching the text found')\n    return best_lexer[1](**options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file_stats(file_name, entity_type='file', lineno=None, cursorpos=None,\n                   plugin=None, language=None, local_file=None):\n    \"\"\"Returns a hash of information about the entity.\"\"\"\n\n    language = standardize_language(language, plugin)\n    stats = {\n        'language': language,\n        'dependencies': [],\n        'lines': None,\n        'lineno': lineno,\n        'cursorpos': cursorpos,\n    }\n\n    if entity_type == 'file':\n        lexer = get_lexer(language)\n        if not language:\n            language, lexer = guess_language(file_name, local_file)\n        parser = DependencyParser(local_file or file_name, lexer)\n        stats.update({\n            'language': use_root_language(language, lexer),\n            'dependencies': parser.parse(),\n            'lines': number_lines_in_file(local_file or file_name),\n        })\n\n    return stats", "response": "Returns a hash of information about the entity."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nguessing lexer and language for a file.", "response": "def guess_language(file_name, local_file):\n    \"\"\"Guess lexer and language for a file.\n\n    Returns a tuple of (language_str, lexer_obj).\n    \"\"\"\n\n    lexer = None\n\n    language = get_language_from_extension(file_name)\n    if language:\n        lexer = get_lexer(language)\n    else:\n        lexer = smart_guess_lexer(file_name, local_file)\n        if lexer:\n            language = u(lexer.name)\n\n    return language, lexer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef smart_guess_lexer(file_name, local_file):\n    lexer = None\n\n    text = get_file_head(file_name)\n\n    lexer1, accuracy1 = guess_lexer_using_filename(local_file or file_name, text)\n    lexer2, accuracy2 = guess_lexer_using_modeline(text)\n\n    if lexer1:\n        lexer = lexer1\n    if (lexer2 and accuracy2 and\n            (not accuracy1 or accuracy2 > accuracy1)):\n        lexer = lexer2\n\n    return lexer", "response": "Guess Pygments lexer for a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef guess_lexer_using_filename(file_name, text):\n\n    lexer, accuracy = None, None\n\n    try:\n        lexer = custom_pygments_guess_lexer_for_filename(file_name, text)\n    except SkipHeartbeat as ex:\n        raise SkipHeartbeat(u(ex))\n    except:\n        log.traceback(logging.DEBUG)\n\n    if lexer is not None:\n        try:\n            accuracy = lexer.analyse_text(text)\n        except:\n            log.traceback(logging.DEBUG)\n\n    return lexer, accuracy", "response": "Guess lexer for given text using the given file name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nguessing lexer for given text using Vim modeline.", "response": "def guess_lexer_using_modeline(text):\n    \"\"\"Guess lexer for given text using Vim modeline.\n\n    Returns a tuple of (lexer, accuracy).\n    \"\"\"\n\n    lexer, accuracy = None, None\n\n    file_type = None\n    try:\n        file_type = get_filetype_from_buffer(text)\n    except:  # pragma: nocover\n        log.traceback(logging.DEBUG)\n\n    if file_type is not None:\n        try:\n            lexer = get_lexer_by_name(file_type)\n        except ClassNotFound:\n            log.traceback(logging.DEBUG)\n\n    if lexer is not None:\n        try:\n            accuracy = lexer.analyse_text(text)\n        except:  # pragma: nocover\n            log.traceback(logging.DEBUG)\n\n    return lexer, accuracy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_language_from_extension(file_name):\n\n    filepart, extension = os.path.splitext(file_name)\n    pathpart, filename = os.path.split(file_name)\n\n    if filename == 'go.mod':\n        return 'Go'\n\n    if re.match(r'\\.h.*$', extension, re.IGNORECASE) or re.match(r'\\.c.*$', extension, re.IGNORECASE):\n\n        if os.path.exists(u('{0}{1}').format(u(filepart), u('.c'))) or os.path.exists(u('{0}{1}').format(u(filepart), u('.C'))):\n            return 'C'\n\n        if os.path.exists(u('{0}{1}').format(u(filepart), u('.m'))) or os.path.exists(u('{0}{1}').format(u(filepart), u('.M'))):\n            return 'Objective-C'\n\n        if os.path.exists(u('{0}{1}').format(u(filepart), u('.mm'))) or os.path.exists(u('{0}{1}').format(u(filepart), u('.MM'))):\n            return 'Objective-C++'\n\n        available_extensions = extensions_in_same_folder(file_name)\n\n        for ext in CppLexer.filenames:\n            ext = ext.lstrip('*')\n            if ext in available_extensions:\n                return 'C++'\n\n        if '.c' in available_extensions:\n            return 'C'\n\n    if re.match(r'\\.m$', extension, re.IGNORECASE) and (os.path.exists(u('{0}{1}').format(u(filepart), u('.h'))) or os.path.exists(u('{0}{1}').format(u(filepart), u('.H')))):\n        return 'Objective-C'\n\n    if re.match(r'\\.mm$', extension, re.IGNORECASE) and (os.path.exists(u('{0}{1}').format(u(filepart), u('.h'))) or os.path.exists(u('{0}{1}').format(u(filepart), u('.H')))):\n        return 'Objective-C++'\n\n    return None", "response": "Returns a matching language for the given file extension."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmap a string to the equivalent Pygments language. Returns the standardized language string.", "response": "def standardize_language(language, plugin):\n    \"\"\"Maps a string to the equivalent Pygments language.\n\n    Returns the standardized language string.\n    \"\"\"\n\n    if not language:\n        return None\n\n    # standardize language for this plugin\n    if plugin:\n        plugin = plugin.split(' ')[-1].split('/')[0].split('-')[0]\n        standardized = get_language_from_json(language, plugin)\n        if standardized is not None:\n            return standardized\n\n    # standardize language against default languages\n    return get_language_from_json(language, 'default')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the given language in a json file.", "response": "def get_language_from_json(language, key):\n    \"\"\"Finds the given language in a json file.\"\"\"\n\n    file_name = os.path.join(\n        os.path.dirname(__file__),\n        'languages',\n        '{0}.json').format(key.lower())\n\n    if os.path.exists(file_name):\n        try:\n            with open(file_name, 'r', encoding='utf-8') as fh:\n                languages = json.loads(fh.read())\n                if languages.get(language.lower()):\n                    return languages[language.lower()]\n        except:\n            log.traceback(logging.DEBUG)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file_head(file_name):\n\n    text = None\n    try:\n        with open(file_name, 'r', encoding='utf-8') as fh:\n            text = fh.read(512000)\n    except:\n        try:\n            with open(file_name, 'r', encoding=sys.getfilesystemencoding()) as fh:\n                text = fh.read(512000)  # pragma: nocover\n        except:\n            log.traceback(logging.DEBUG)\n    return text", "response": "Returns the first 512000 bytes of the file s contents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverwrite pygments. lexers. guess_lexer_for_filename to customize the priority of different lexers based on popularity of languages.", "response": "def custom_pygments_guess_lexer_for_filename(_fn, _text, **options):\n    \"\"\"Overwrite pygments.lexers.guess_lexer_for_filename to customize the\n    priority of different lexers based on popularity of languages.\"\"\"\n\n    fn = basename(_fn)\n    primary = {}\n    matching_lexers = set()\n    for lexer in _iter_lexerclasses():\n        for filename in lexer.filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = True\n        for filename in lexer.alias_filenames:\n            if _fn_matches(fn, filename):\n                matching_lexers.add(lexer)\n                primary[lexer] = False\n    if not matching_lexers:\n        raise ClassNotFound('no lexer for filename %r found' % fn)\n    if len(matching_lexers) == 1:\n        return matching_lexers.pop()(**options)\n    result = []\n    for lexer in matching_lexers:\n        rv = lexer.analyse_text(_text)\n        if rv == 1.0:\n            return lexer(**options)\n        result.append(customize_lexer_priority(_fn, rv, lexer))\n\n    matlab = list(filter(lambda x: x[2].name.lower() == 'matlab', result))\n    if len(matlab) > 0:\n        objc = list(filter(lambda x: x[2].name.lower() == 'objective-c', result))\n        if objc and objc[0][0] == matlab[0][0]:\n            raise SkipHeartbeat('Skipping because not enough language accuracy.')\n\n    def type_sort(t):\n        # sort by:\n        # - analyse score\n        # - is primary filename pattern?\n        # - priority\n        # - last resort: class name\n        return (t[0], primary[t[2]], t[1], t[2].__name__)\n    result.sort(key=type_sort)\n\n    return result[-1][2](**options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extensions_in_same_folder(file_name):\n\n    directory = os.path.dirname(file_name)\n    files = os.listdir(directory)\n    extensions = list(zip(*map(os.path.splitext, files)))[1]\n    extensions = set([ext.lower() for ext in extensions])\n    return extensions", "response": "Returns a list of file extensions from the same folder as file_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef analyse_text(text):\n        if re.search(r'/\\*\\**\\s*rexx', text, re.IGNORECASE):\n            # Header matches MVS Rexx requirements, this is certainly a Rexx\n            # script.\n            return 1.0\n        elif text.startswith('/*'):\n            # Header matches general Rexx requirements; the source code might\n            # still be any language using C comments such as C++, C# or Java.\n            lowerText = text.lower()\n            result = sum(weight\n                         for (pattern, weight) in RexxLexer.PATTERNS_AND_WEIGHTS\n                         if pattern.search(lowerText)) + 0.01\n            return min(result, 1.0)", "response": "Analyse the text for the internal version of the Rexx file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyse_text(text):\n        result = 0.0\n        lines = text.split('\\n')\n        hasEndProc = False\n        hasHeaderComment = False\n        hasFile = False\n        hasJob = False\n        hasProc = False\n        hasParm = False\n        hasReport = False\n\n        def isCommentLine(line):\n            return EasytrieveLexer._COMMENT_LINE_REGEX.match(lines[0]) is not None\n\n        def isEmptyLine(line):\n            return not bool(line.strip())\n\n        # Remove possible empty lines and header comments.\n        while lines and (isEmptyLine(lines[0]) or isCommentLine(lines[0])):\n            if not isEmptyLine(lines[0]):\n                hasHeaderComment = True\n            del lines[0]\n\n        if EasytrieveLexer._MACRO_HEADER_REGEX.match(lines[0]):\n            # Looks like an Easytrieve macro.\n            result = 0.4\n            if hasHeaderComment:\n                result += 0.4\n        else:\n            # Scan the source for lines starting with indicators.\n            for line in lines:\n                words = line.split()\n                if (len(words) >= 2):\n                    firstWord = words[0]\n                    if not hasReport:\n                        if not hasJob:\n                            if not hasFile:\n                                if not hasParm:\n                                    if firstWord == 'PARM':\n                                        hasParm = True\n                                if firstWord == 'FILE':\n                                    hasFile = True\n                            if firstWord == 'JOB':\n                                hasJob = True\n                        elif firstWord == 'PROC':\n                            hasProc = True\n                        elif firstWord == 'END-PROC':\n                            hasEndProc = True\n                        elif firstWord == 'REPORT':\n                            hasReport = True\n\n            # Weight the findings.\n            if hasJob and (hasProc == hasEndProc):\n                if hasHeaderComment:\n                    result += 0.1\n                if hasParm:\n                    if hasProc:\n                        # Found PARM, JOB and PROC/END-PROC:\n                        # pretty sure this is Easytrieve.\n                        result += 0.8\n                    else:\n                        # Found PARAM and  JOB: probably this is Easytrieve\n                        result += 0.5\n                else:\n                    # Found JOB and possibly other keywords: might be Easytrieve\n                    result += 0.11\n                    if hasParm:\n                        # Note: PARAM is not a proper English word, so this is\n                        # regarded a much better indicator for Easytrieve than\n                        # the other words.\n                        result += 0.2\n                    if hasFile:\n                        result += 0.01\n                    if hasReport:\n                        result += 0.01\n        assert 0.0 <= result <= 1.0\n        return result", "response": "Perform a structural analysis on the given text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrecognize JCL job by header.", "response": "def analyse_text(text):\n        \"\"\"\n        Recognize JCL job by header.\n        \"\"\"\n        result = 0.0\n        lines = text.split('\\n')\n        if len(lines) > 0:\n            if JclLexer._JOB_HEADER_PATTERN.match(lines[0]):\n                result = 1.0\n        assert 0.0 <= result <= 1.0\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking an object and test to see if it can be represented as a dictionary. If it can be return a list of tuples e. g. a ::", "response": "def to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        ValueError: cannot encode objects that are not 2-tuples.\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    if isinstance(value, collections.Mapping):\n        value = value.items()\n\n    return list(value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_server_cert(response):\n    certificate_hash = None\n    raw_response = response.raw\n\n    if isinstance(raw_response, HTTPResponse):\n        if sys.version_info > (3, 0):\n            socket = raw_response._fp.fp.raw._sock\n        else:\n            socket = raw_response._fp.fp._sock\n\n        try:\n            server_certificate = socket.getpeercert(True)\n        except AttributeError:\n            pass\n        else:\n            hash_object = hashlib.sha256(server_certificate)\n            certificate_hash = hash_object.hexdigest().upper()\n    else:\n        warnings.warn(\"Requests is running with a non urllib3 backend, cannot retrieve server certificate for CBT\", NoCertificateRetrievedWarning)\n\n    return certificate_hash", "response": "Get the server certificate at the request_url and return it as a SHA256 hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattempt to authenticate using HTTP NTLM challenge or response.", "response": "def retry_using_http_NTLM_auth(self, auth_header_field, auth_header,\n                                   response, auth_type, args):\n        # Get the certificate of the server if using HTTPS for CBT\n        server_certificate_hash = _get_server_cert(response)\n\n        \"\"\"Attempt to authenticate using HTTP NTLM challenge/response.\"\"\"\n        if auth_header in response.request.headers:\n            return response\n\n        content_length = int(\n            response.request.headers.get('Content-Length', '0'), base=10)\n        if hasattr(response.request.body, 'seek'):\n            if content_length > 0:\n                response.request.body.seek(-content_length, 1)\n            else:\n                response.request.body.seek(0, 0)\n\n        # Consume content and release the original connection\n        # to allow our new request to reuse the same one.\n        response.content\n        response.raw.release_conn()\n        request = response.request.copy()\n\n        # ntlm returns the headers as a base64 encoded bytestring. Convert to\n        # a string.\n        context = ntlm.Ntlm()\n        negotiate_message = context.create_negotiate_message(self.domain).decode('ascii')\n        auth = u'%s %s' % (auth_type, negotiate_message)\n        request.headers[auth_header] = auth\n\n        # A streaming response breaks authentication.\n        # This can be fixed by not streaming this request, which is safe\n        # because the returned response3 will still have stream=True set if\n        # specified in args. In addition, we expect this request to give us a\n        # challenge and not the real content, so the content will be short\n        # anyway.\n        args_nostream = dict(args, stream=False)\n        response2 = response.connection.send(request, **args_nostream)\n\n        # needed to make NTLM auth compatible with requests-2.3.0\n\n        # Consume content and release the original connection\n        # to allow our new request to reuse the same one.\n        response2.content\n        response2.raw.release_conn()\n        request = response2.request.copy()\n\n        # this is important for some web applications that store\n        # authentication-related info in cookies (it took a long time to\n        # figure out)\n        if response2.headers.get('set-cookie'):\n            request.headers['Cookie'] = response2.headers.get('set-cookie')\n\n        # get the challenge\n        auth_header_value = response2.headers[auth_header_field]\n\n        auth_strip = auth_type + ' '\n\n        ntlm_header_value = next(\n            s for s in (val.lstrip() for val in auth_header_value.split(','))\n            if s.startswith(auth_strip)\n        ).strip()\n\n        # Parse the challenge in the ntlm context\n        context.parse_challenge_message(ntlm_header_value[len(auth_strip):])\n\n        # build response\n        # Get the response based on the challenge message\n        authenticate_message = context.create_authenticate_message(\n            self.username,\n            self.password,\n            self.domain,\n            server_certificate_hash=server_certificate_hash\n        )\n        authenticate_message = authenticate_message.decode('ascii')\n        auth = u'%s %s' % (auth_type, authenticate_message)\n        request.headers[auth_header] = auth\n\n        response3 = response2.connection.send(request, **args)\n\n        # Update the history.\n        response3.history.append(response)\n        response3.history.append(response2)\n\n        # Get the session_security object created by ntlm-auth for signing and sealing of messages\n        self.session_security = context.session_security\n\n        return response3"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a DNSName SubjectAlternativeName field to the form used by the standard library on Python 3.", "response": "def _dnsname_to_stdlib(name):\n    \"\"\"\n    Converts a dNSName SubjectAlternativeName field to the form used by the\n    standard library on the given Python version.\n\n    Cryptography produces a dNSName as a unicode string that was idna-decoded\n    from ASCII bytes. We need to idna-encode that string to get it back, and\n    then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib\n    uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).\n    \"\"\"\n    def idna_encode(name):\n        \"\"\"\n        Borrowed wholesale from the Python Cryptography Project. It turns out\n        that we can't just safely call `idna.encode`: it can explode for\n        wildcard names. This avoids that problem.\n        \"\"\"\n        import idna\n\n        for prefix in [u'*.', u'.']:\n            if name.startswith(prefix):\n                name = name[len(prefix):]\n                return prefix.encode('ascii') + idna.encode(name)\n        return idna.encode(name)\n\n    name = idna_encode(name)\n    if sys.version_info >= (3, 0):\n        name = name.decode('utf-8')\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_heartbeats(heartbeats, args, configs, use_ntlm_proxy=False):\n\n    if len(heartbeats) == 0:\n        return SUCCESS\n\n    api_url = args.api_url\n    if not api_url:\n        api_url = 'https://api.wakatime.com/api/v1/users/current/heartbeats.bulk'\n    log.debug('Sending heartbeats to api at %s' % api_url)\n    timeout = args.timeout\n    if not timeout:\n        timeout = 60\n\n    data = [h.sanitize().dict() for h in heartbeats]\n    log.debug(data)\n\n    # setup api request\n    request_body = json.dumps(data)\n    api_key = u(base64.b64encode(str.encode(args.key) if is_py3 else args.key))\n    auth = u('Basic {api_key}').format(api_key=api_key)\n    headers = {\n        'User-Agent': get_user_agent(args.plugin),\n        'Content-Type': 'application/json',\n        'Accept': 'application/json',\n        'Authorization': auth,\n    }\n\n    hostname = get_hostname(args)\n    if hostname:\n        headers['X-Machine-Name'] = u(hostname).encode('utf-8')\n\n    # add Olson timezone to request\n    try:\n        tz = tzlocal.get_localzone()\n    except:\n        tz = None\n    if tz:\n        headers['TimeZone'] = u(tz.zone).encode('utf-8')\n\n    session_cache = SessionCache()\n    session = session_cache.get()\n\n    should_try_ntlm = False\n    proxies = {}\n    if args.proxy:\n        if use_ntlm_proxy:\n            from .packages.requests_ntlm import HttpNtlmAuth\n            username = args.proxy.rsplit(':', 1)\n            password = ''\n            if len(username) == 2:\n                password = username[1]\n            username = username[0]\n            session.auth = HttpNtlmAuth(username, password, session)\n        else:\n            should_try_ntlm = '\\\\' in args.proxy\n            proxies['https'] = args.proxy\n\n    ssl_verify = not args.nosslverify\n    if args.ssl_certs_file and ssl_verify:\n        ssl_verify = args.ssl_certs_file\n\n    # send request to api\n    response, code = None, None\n    try:\n        response = session.post(api_url, data=request_body, headers=headers,\n                                proxies=proxies, timeout=timeout,\n                                verify=ssl_verify)\n    except RequestException:\n        if should_try_ntlm:\n            return send_heartbeats(heartbeats, args, configs, use_ntlm_proxy=True)\n        else:\n            exception_data = {\n                sys.exc_info()[0].__name__: u(sys.exc_info()[1]),\n            }\n            if log.isEnabledFor(logging.DEBUG):\n                exception_data['traceback'] = traceback.format_exc()\n            if args.offline:\n                queue = Queue(args, configs)\n                queue.push_many(heartbeats)\n                if log.isEnabledFor(logging.DEBUG):\n                    log.warn(exception_data)\n            else:\n                log.error(exception_data)\n\n    except:  # delete cached session when requests raises unknown exception\n        if should_try_ntlm:\n            return send_heartbeats(heartbeats, args, configs, use_ntlm_proxy=True)\n        else:\n            exception_data = {\n                sys.exc_info()[0].__name__: u(sys.exc_info()[1]),\n                'traceback': traceback.format_exc(),\n            }\n            if args.offline:\n                queue = Queue(args, configs)\n                queue.push_many(heartbeats)\n                log.warn(exception_data)\n\n    else:\n        code = response.status_code if response is not None else None\n        content = response.text if response is not None else None\n\n        if _success(code):\n            results = _get_results(response)\n            _process_server_results(heartbeats, code, content, results, args, configs)\n            session_cache.save(session)\n            return SUCCESS\n        else:\n            log.debug({\n                'response_code': code,\n                'response_text': content,\n            })\n\n        if should_try_ntlm:\n            return send_heartbeats(heartbeats, args, configs, use_ntlm_proxy=True)\n\n        _handle_unsent_heartbeats(heartbeats, code, content, args, configs)\n\n    session_cache.delete()\n    return AUTH_ERROR if code == 401 else API_ERROR", "response": "Send a list of heartbeats to WakaTime API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _can_allocate(struct):\n    try:\n        # select.poll() objects won't fail until used.\n        if struct == 'poll':\n            p = select.poll()\n            p.poll(0)\n\n        # All others will fail on allocation.\n        else:\n            getattr(select, struct)().close()\n        return True\n    except (OSError, AttributeError) as e:\n        return False", "response": "Checks that the given select struct can be allocated by the underlying system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the key associated with a registered file object.", "response": "def get_key(self, fileobj):\n        \"\"\" Return the key associated with a registered file object. \"\"\"\n        mapping = self.get_map()\n        if mapping is None:\n            raise RuntimeError(\"Selector is closed\")\n        try:\n            return mapping[fileobj]\n        except KeyError:\n            raise KeyError(\"{0!r} is not registered\".format(fileobj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscans the buffer for modelines and return filetype if one is found.", "response": "def get_filetype_from_buffer(buf, max_lines=5):\n    \"\"\"\n    Scan the buffer for modelines and return filetype if one is found.\n    \"\"\"\n    lines = buf.splitlines()\n    for l in lines[-1:-max_lines-1:-1]:\n        ret = get_filetype_from_line(l)\n        if ret:\n            return ret\n    for i in range(max_lines, -1, -1):\n        if i < len(lines):\n            ret = get_filetype_from_line(lines[i])\n            if ret:\n                return ret\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the font based on bold italic flags.", "response": "def get_font(self, bold, oblique):\n        \"\"\"\n        Get the font based on bold and italic flags.\n        \"\"\"\n        if bold and oblique:\n            return self.fonts['BOLDITALIC']\n        elif bold:\n            return self.fonts['BOLD']\n        elif oblique:\n            return self.fonts['ITALIC']\n        else:\n            return self.fonts['NORMAL']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the X coordinate of a character position.", "response": "def _get_char_x(self, charno):\n        \"\"\"\n        Get the X coordinate of a character position.\n        \"\"\"\n        return charno * self.fontw + self.image_pad + self.line_number_width"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the actual position for a character and line number.", "response": "def _get_text_pos(self, charno, lineno):\n        \"\"\"\n        Get the actual position for a character and line position.\n        \"\"\"\n        return self._get_char_x(charno), self._get_line_y(lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the required image size.", "response": "def _get_image_size(self, maxcharno, maxlineno):\n        \"\"\"\n        Get the required image size.\n        \"\"\"\n        return (self._get_char_x(maxcharno) + self.image_pad,\n                self._get_line_y(maxlineno + 0) + self.image_pad)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _draw_linenumber(self, posno, lineno):\n        self._draw_text(\n            self._get_linenumber_pos(posno),\n            str(lineno).rjust(self.line_number_chars),\n            font=self.fonts.get_font(self.line_number_bold,\n                                     self.line_number_italic),\n            fill=self.line_number_fg,\n        )", "response": "Draws a line number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing a text at the given position.", "response": "def _draw_text(self, pos, text, font, **kw):\n        \"\"\"\n        Remember a single drawable tuple to paint later.\n        \"\"\"\n        self.drawables.append((pos, text, font, kw))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate drawables for the token content.", "response": "def _create_drawables(self, tokensource):\n        \"\"\"\n        Create drawables for the token content.\n        \"\"\"\n        lineno = charno = maxcharno = 0\n        for ttype, value in tokensource:\n            while ttype not in self.styles:\n                ttype = ttype.parent\n            style = self.styles[ttype]\n            # TODO: make sure tab expansion happens earlier in the chain.  It\n            # really ought to be done on the input, as to do it right here is\n            # quite complex.\n            value = value.expandtabs(4)\n            lines = value.splitlines(True)\n            # print lines\n            for i, line in enumerate(lines):\n                temp = line.rstrip('\\n')\n                if temp:\n                    self._draw_text(\n                        self._get_text_pos(charno, lineno),\n                        temp,\n                        font = self._get_style_font(style),\n                        fill = self._get_text_color(style)\n                    )\n                    charno += len(temp)\n                    maxcharno = max(maxcharno, charno)\n                if line.endswith('\\n'):\n                    # add a line for each extra line in the value\n                    charno = 0\n                    lineno += 1\n        self.maxcharno = maxcharno\n        self.maxlineno = lineno"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _draw_line_numbers(self):\n        if not self.line_numbers:\n            return\n        for p in xrange(self.maxlineno):\n            n = p + self.line_number_start\n            if (n % self.line_number_step) == 0:\n                self._draw_linenumber(p, n)", "response": "Draw the line numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _paint_line_number_bg(self, im):\n        if not self.line_numbers:\n            return\n        if self.line_number_fg is None:\n            return\n        draw = ImageDraw.Draw(im)\n        recth = im.size[-1]\n        rectw = self.image_pad + self.line_number_width - self.line_number_pad\n        draw.rectangle([(0, 0), (rectw, recth)],\n                       fill=self.line_number_bg)\n        draw.line([(rectw, 0), (rectw, recth)], fill=self.line_number_fg)\n        del draw", "response": "Paint the line number background on the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format(self, tokensource, outfile):\n        self._create_drawables(tokensource)\n        self._draw_line_numbers()\n        im = Image.new(\n            'RGB',\n            self._get_image_size(self.maxcharno, self.maxlineno),\n            self.background_color\n        )\n        self._paint_line_number_bg(im)\n        draw = ImageDraw.Draw(im)\n        # Highlight\n        if self.hl_lines:\n            x = self.image_pad + self.line_number_width - self.line_number_pad + 1\n            recth = self._get_line_height()\n            rectw = im.size[0] - x\n            for linenumber in self.hl_lines:\n                y = self._get_line_y(linenumber - 1)\n                draw.rectangle([(x, y), (x + rectw, y + recth)],\n                               fill=self.hl_color)\n        for pos, value, font, kw in self.drawables:\n            draw.text(pos, value, font=font, **kw)\n        im.save(outfile, self.image_format.upper())", "response": "Formats the tokensource into a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, attrs):\n\n        data = self.dict()\n        data.update(attrs)\n        heartbeat = Heartbeat(data, self.args, self.configs, _clone=True)\n        return heartbeat", "response": "Return a copy of the current Heartbeat with updated attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sanitize(self):\n\n        if not self.args.hide_file_names:\n            return self\n\n        if self.entity is None:\n            return self\n\n        if self.type != 'file':\n            return self\n\n        if self.should_obfuscate_filename():\n            self._sanitize_metadata()\n            extension = u(os.path.splitext(self.entity)[1])\n            self.entity = u('HIDDEN{0}').format(extension)\n        elif self.should_obfuscate_project():\n            self._sanitize_metadata()\n\n        return self", "response": "Removes sensitive data including file names and dependencies. Returns a Heartbeat."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef should_obfuscate_filename(self):\n\n        for pattern in self.args.hide_file_names:\n            try:\n                compiled = re.compile(pattern, re.IGNORECASE)\n                if compiled.search(self.entity):\n                    return True\n            except re.error as ex:\n                log.warning(u('Regex error ({msg}) for hide_file_names pattern: {pattern}').format(\n                    msg=u(ex),\n                    pattern=u(pattern),\n                ))\n        return False", "response": "Returns True if hide_file_names is true or the entity file path\n        matches one in the list of obfuscated file paths."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _format_local_file(self):\n\n        if self.type != 'file':\n            return\n\n        if not self.entity:\n            return\n\n        if not is_win:\n            return\n\n        if self._file_exists():\n            return\n\n        self.args.local_file = self._to_unc_path(self.entity)", "response": "Formats the args. local_file if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an NTLM NEGOTIATE_MESSAGE", "response": "def create_negotiate_message(self, domain_name=None, workstation=None):\n        \"\"\"\n        Create an NTLM NEGOTIATE_MESSAGE\n\n        :param domain_name: The domain name of the user account we are authenticating with, default is None\n        :param worksation: The workstation we are using to authenticate with, default is None\n        :return: A base64 encoded string of the NEGOTIATE_MESSAGE\n        \"\"\"\n        self.negotiate_message = NegotiateMessage(self.negotiate_flags, domain_name, workstation)\n\n        return base64.b64encode(self.negotiate_message.get_data())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the CHALLENGE_MESSAGE from the server and add it to the Ntlm context", "response": "def parse_challenge_message(self, msg2):\n        \"\"\"\n        Parse the NTLM CHALLENGE_MESSAGE from the server and add it to the Ntlm context fields\n\n        :param msg2: A base64 encoded string of the CHALLENGE_MESSAGE\n        \"\"\"\n        msg2 = base64.b64decode(msg2)\n        self.challenge_message = ChallengeMessage(msg2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_authenticate_message(self, user_name, password, domain_name=None, workstation=None, server_certificate_hash=None):\n        self.authenticate_message = AuthenticateMessage(user_name, password, domain_name, workstation,\n                                                        self.challenge_message, self.ntlm_compatibility,\n                                                        server_certificate_hash)\n        self.authenticate_message.add_mic(self.negotiate_message, self.challenge_message)\n\n        # Setups up the session_security context used to sign and seal messages if wanted\n        if self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SEAL or self.negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_SIGN:\n            self.session_security = SessionSecurity(struct.unpack(\"<I\", self.authenticate_message.negotiate_flags)[0],\n                                                    self.authenticate_message.exported_session_key)\n\n        return base64.b64encode(self.authenticate_message.get_data())", "response": "Create an NTLM AUTHENTICATE_MESSAGE based on the NTLM context and the previous messages sent and received."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lex(code, lexer):\n    try:\n        return lexer.get_tokens(code)\n    except TypeError as err:\n        if (isinstance(err.args[0], str) and\n            ('unbound method get_tokens' in err.args[0] or\n             'missing 1 required positional argument' in err.args[0])):\n            raise TypeError('lex() argument must be a lexer instance, '\n                            'not a class')\n        raise", "response": "Lex a string and return an iterable of tokens."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format(tokens, formatter, outfile=None):  # pylint: disable=redefined-builtin\n    try:\n        if not outfile:\n            realoutfile = getattr(formatter, 'encoding', None) and BytesIO() or StringIO()\n            formatter.format(tokens, realoutfile)\n            return realoutfile.getvalue()\n        else:\n            formatter.format(tokens, outfile)\n    except TypeError as err:\n        if (isinstance(err.args[0], str) and\n            ('unbound method format' in err.args[0] or\n             'missing 1 required positional argument' in err.args[0])):\n            raise TypeError('format() argument must be a formatter instance, '\n                            'not a class')\n        raise", "response": "Format a list of tokens with the formatter formatter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhighlighting the given code using the given lexer and formats it with the given formatter.", "response": "def highlight(code, lexer, formatter, outfile=None):\n    \"\"\"\n    Lex ``code`` with ``lexer`` and format it with the formatter ``formatter``.\n\n    If ``outfile`` is given and a valid file object (an object\n    with a ``write`` method), the result will be written to it, otherwise\n    it is returned as a string.\n    \"\"\"\n    return format(lex(code, lexer), formatter, outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting a list of tokenstrings into a file.", "response": "def format(self, tokensource, outfile):\n        \"\"\"\n        Format ``tokensource``, an iterable of ``(tokentype, tokenstring)``\n        tuples and write it into ``outfile``.\n        \"\"\"\n        if self.encoding:\n            # wrap the outfile in a StreamWriter\n            outfile = codecs.lookup(self.encoding)[3](outfile)\n        return self.format_unencoded(tokensource, outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify a SSL certificate.", "response": "def cert_verify(self, conn, url, verify, cert):\n        \"\"\"Verify a SSL certificate. This method should not be called from user\n        code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param conn: The urllib3 connection object associated with the cert.\n        :param url: The requested URL.\n        :param verify: Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: The SSL certificate to verify.\n        \"\"\"\n        if url.lower().startswith('https') and verify:\n\n            cert_loc = None\n\n            # Allow self-specified cert location.\n            if verify is not True:\n                cert_loc = verify\n\n            if not cert_loc:\n                cert_loc = DEFAULT_CA_BUNDLE_PATH\n\n            if not cert_loc or not os.path.exists(cert_loc):\n                raise IOError(\"Could not find a suitable TLS CA certificate bundle, \"\n                              \"invalid path: {0}\".format(cert_loc))\n\n            conn.cert_reqs = 'CERT_REQUIRED'\n\n            if not os.path.isdir(cert_loc):\n                conn.ca_certs = cert_loc\n            else:\n                conn.ca_cert_dir = cert_loc\n        else:\n            conn.cert_reqs = 'CERT_NONE'\n            conn.ca_certs = None\n            conn.ca_cert_dir = None\n\n        if cert:\n            if not isinstance(cert, basestring):\n                conn.cert_file = cert[0]\n                conn.key_file = cert[1]\n            else:\n                conn.cert_file = cert\n                conn.key_file = None\n            if conn.cert_file and not os.path.exists(conn.cert_file):\n                raise IOError(\"Could not find the TLS certificate file, \"\n                              \"invalid path: {0}\".format(conn.cert_file))\n            if conn.key_file and not os.path.exists(conn.key_file):\n                raise IOError(\"Could not find the TLS key file, \"\n                              \"invalid path: {0}\".format(conn.key_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_connection(self, url, proxies=None):\n        proxy = select_proxy(url, proxies)\n\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, 'http')\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_url(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn", "response": "Returns a urllib3 connection for the given URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the config file location.", "response": "def getConfigFile():\n    \"\"\"Returns the config file location.\n\n    If $WAKATIME_HOME env varialbe is defined, returns\n    $WAKATIME_HOME/.wakatime.cfg, otherwise ~/.wakatime.cfg.\n    \"\"\"\n\n    fileName = '.wakatime.cfg'\n\n    home = os.environ.get('WAKATIME_HOME')\n    if home:\n        return os.path.join(os.path.expanduser(home), fileName)\n\n    return os.path.join(os.path.expanduser('~'), fileName)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseConfigFile(configFile=None):\n\n    # get config file location from ENV\n    if not configFile:\n        configFile = getConfigFile()\n\n    configs = configparser.ConfigParser(delimiters=('='), strict=False)\n    try:\n        with open(configFile, 'r', encoding='utf-8') as fh:\n            try:\n                configs.read_file(fh)\n            except configparser.Error:\n                print(traceback.format_exc())\n                raise SystemExit(CONFIG_FILE_PARSE_ERROR)\n    except IOError:\n        pass\n    return configs", "response": "Returns a configparser. SafeConfigParser instance with configs\n    read from the config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if pattern is valid.", "response": "def check(self, pattern):\n        \"\"\"\n        Apply `pattern` on the current position and return\n        the match object. (Doesn't touch pos). Use this for\n        lookahead.\n        \"\"\"\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        return self._re_cache[pattern].match(self.data, self.pos)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan(self, pattern):\n        if self.eos:\n            raise EndOfText()\n        if pattern not in self._re_cache:\n            self._re_cache[pattern] = re.compile(pattern, self.flags)\n        self.last = self.match\n        m = self._re_cache[pattern].match(self.data, self.pos)\n        if m is None:\n            return False\n        self.start_pos = m.start()\n        self.pos = m.end()\n        self.match = m.group()\n        return True", "response": "Scan the text for the given pattern and update pos and match."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_filter_by_name(filtername, **options):\n    cls = find_filter_class(filtername)\n    if cls:\n        return cls(**options)\n    else:\n        raise ClassNotFound('filter %r not found' % filtername)", "response": "Return an instantiated filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding the unprocessed tokens from the given text.", "response": "def get_tokens_unprocessed(self, text):\n        \"\"\"\n        Since ERB doesn't allow \"<%\" and other tags inside of ruby\n        blocks we have to use a split approach here that fails for\n        that too.\n        \"\"\"\n        tokens = self._block_re.split(text)\n        tokens.reverse()\n        state = idx = 0\n        try:\n            while True:\n                # text\n                if state == 0:\n                    val = tokens.pop()\n                    yield idx, Other, val\n                    idx += len(val)\n                    state = 1\n                # block starts\n                elif state == 1:\n                    tag = tokens.pop()\n                    # literals\n                    if tag in ('<%%', '%%>'):\n                        yield idx, Other, tag\n                        idx += 3\n                        state = 0\n                    # comment\n                    elif tag == '<%#':\n                        yield idx, Comment.Preproc, tag\n                        val = tokens.pop()\n                        yield idx + 3, Comment, val\n                        idx += 3 + len(val)\n                        state = 2\n                    # blocks or output\n                    elif tag in ('<%', '<%=', '<%-'):\n                        yield idx, Comment.Preproc, tag\n                        idx += len(tag)\n                        data = tokens.pop()\n                        r_idx = 0\n                        for r_idx, r_token, r_value in \\\n                                self.ruby_lexer.get_tokens_unprocessed(data):\n                            yield r_idx + idx, r_token, r_value\n                        idx += len(data)\n                        state = 2\n                    elif tag in ('%>', '-%>'):\n                        yield idx, Error, tag\n                        idx += len(tag)\n                        state = 0\n                    # % raw ruby statements\n                    else:\n                        yield idx, Comment.Preproc, tag[0]\n                        r_idx = 0\n                        for r_idx, r_token, r_value in \\\n                                self.ruby_lexer.get_tokens_unprocessed(tag[1:]):\n                            yield idx + 1 + r_idx, r_token, r_value\n                        idx += len(tag)\n                        state = 0\n                # block ends\n                elif state == 2:\n                    tag = tokens.pop()\n                    if tag not in ('%>', '-%>'):\n                        yield idx, Other, tag\n                    else:\n                        yield idx, Comment.Preproc, tag\n                    idx += len(tag)\n                    state = 0\n        except IndexError:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef string_to_tokentype(s):\n    if isinstance(s, _TokenType):\n        return s\n    if not s:\n        return Token\n    node = Token\n    for item in s.split('.'):\n        node = getattr(node, item)\n    return node", "response": "Convert a string into a token type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats a path as absolute and with the correct platform separator.", "response": "def format_file_path(filepath):\n    \"\"\"Formats a path as absolute and with the correct platform separator.\"\"\"\n\n    try:\n        is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN.match(filepath)\n        filepath = os.path.realpath(os.path.abspath(filepath))\n        filepath = re.sub(BACKSLASH_REPLACE_PATTERN, '/', filepath)\n        is_windows_drive = WINDOWS_DRIVE_PATTERN.match(filepath)\n        if is_windows_drive:\n            filepath = filepath.capitalize()\n        if is_windows_network_mount:\n            # Add back a / to the front, since the previous modifications\n            # will have replaced any double slashes with single\n            filepath = '/' + filepath\n    except:\n        pass\n    return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat text with a color and some attributes.", "response": "def ansiformat(attr, text):\n    \"\"\"\n    Format ``text`` with a color and/or some attributes::\n\n        color       normal color\n        *color*     bold color\n        _color_     underlined color\n        +color+     blinking color\n    \"\"\"\n    result = []\n    if attr[:1] == attr[-1:] == '+':\n        result.append(codes['blink'])\n        attr = attr[1:-1]\n    if attr[:1] == attr[-1:] == '*':\n        result.append(codes['bold'])\n        attr = attr[1:-1]\n    if attr[:1] == attr[-1:] == '_':\n        result.append(codes['underline'])\n        attr = attr[1:-1]\n    result.append(codes[attr])\n    result.append(text)\n    result.append(codes['reset'])\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing IPv6 addresses and IPv6 zone identifiers.", "response": "def _ipv6_host(host):\n    \"\"\"\n    Process IPv6 address literals\n    \"\"\"\n\n    # httplib doesn't like it when we include brackets in IPv6 addresses\n    # Specifically, if we include brackets but also pass the port then\n    # httplib crazily doubles up the square brackets on the Host header.\n    # Instead, we need to make sure we never pass ``None`` as the port.\n    # However, for backward compatibility reasons we can't actually\n    # *assert* that.  See http://bugs.python.org/issue28539\n    #\n    # Also if an IPv6 address literal has a zone identifier, the\n    # percent sign might be URIencoded, convert it back into ASCII\n    if host.startswith('[') and host.endswith(']'):\n        host = host.replace('%25', '%').strip('[]')\n    return host"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new HTTPConnection.", "response": "def _new_conn(self):\n        \"\"\"\n        Return a fresh :class:`HTTPConnection`.\n        \"\"\"\n        self.num_connections += 1\n        log.debug(\"Starting new HTTP connection (%d): %s\",\n                  self.num_connections, self.host)\n\n        conn = self.ConnectionCls(host=self.host, port=self.port,\n                                  timeout=self.timeout.connect_timeout,\n                                  strict=self.strict, **self.conn_kw)\n        return conn"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_request(self, conn, method, url, timeout=_Default, chunked=False,\n                      **httplib_request_kw):\n        \"\"\"\n        Perform a request on a given urllib connection object taken from our\n        pool.\n\n        :param conn:\n            a connection from one of our connection pools\n\n        :param timeout:\n            Socket timeout in seconds for the request. This can be a\n            float or integer, which will set the same timeout value for\n            the socket connect and the socket read, or an instance of\n            :class:`urllib3.util.Timeout`, which gives you more fine-grained\n            control over your timeouts.\n        \"\"\"\n        self.num_requests += 1\n\n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = timeout_obj.connect_timeout\n\n        # Trigger any extra validation we need to do.\n        try:\n            self._validate_conn(conn)\n        except (SocketTimeout, BaseSSLError) as e:\n            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n        # conn.request() calls httplib.*.request, not the method in\n        # urllib3.request. It also calls makefile (recv) on the socket.\n        if chunked:\n            conn.request_chunked(method, url, **httplib_request_kw)\n        else:\n            conn.request(method, url, **httplib_request_kw)\n\n        # Reset the timeout for the recv() on the socket\n        read_timeout = timeout_obj.read_timeout\n\n        # App Engine doesn't have a sock attr\n        if getattr(conn, 'sock', None):\n            # In Python 3 socket.py will catch EAGAIN and return None when you\n            # try and read into the file pointer created by http.client, which\n            # instead raises a BadStatusLine exception. Instead of catching\n            # the exception and assuming all BadStatusLine exceptions are read\n            # timeouts, check for a zero timeout before making the request.\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n            if read_timeout is Timeout.DEFAULT_TIMEOUT:\n                conn.sock.settimeout(socket.getdefaulttimeout())\n            else:  # None or a value\n                conn.sock.settimeout(read_timeout)\n\n        # Receive the response from the server\n        try:\n            try:  # Python 2.7, use buffering of HTTP responses\n                httplib_response = conn.getresponse(buffering=True)\n            except TypeError:  # Python 2.6 and older, Python 3\n                try:\n                    httplib_response = conn.getresponse()\n                except Exception as e:\n                    # Remove the TypeError from the exception chain in Python 3;\n                    # otherwise it looks like a programming error was the cause.\n                    six.raise_from(e, None)\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n            raise\n\n        # AppEngine doesn't have a version attr.\n        http_version = getattr(conn, '_http_vsn_str', 'HTTP/?')\n        log.debug(\"%s://%s:%s \\\"%s %s %s\\\" %s %s\", self.scheme, self.host, self.port,\n                  method, url, http_version, httplib_response.status,\n                  httplib_response.length)\n\n        try:\n            assert_header_parsing(httplib_response.msg)\n        except (HeaderParsingError, TypeError) as hpe:  # Platform-specific: Python 3\n            log.warning(\n                'Failed to parse headers (url=%s): %s',\n                self._absolute_url(url), hpe, exc_info=True)\n\n        return httplib_response", "response": "Perform a request on a given urllib connection object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        # Disable access to the pool\n        old_pool, self.pool = self.pool, None\n\n        try:\n            while True:\n                conn = old_pool.get(block=False)\n                if conn:\n                    conn.close()\n\n        except queue.Empty:\n            pass", "response": "Close all pooled connections and disable the pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_same_host(self, url):\n        if url.startswith('/'):\n            return True\n\n        # TODO: Add optional support for socket.gethostbyname checking.\n        scheme, host, port = get_host(url)\n\n        host = _ipv6_host(host).lower()\n\n        # Use explicit default port for comparison when none is given\n        if self.port and not port:\n            port = port_by_scheme.get(scheme)\n        elif not self.port and port == port_by_scheme.get(scheme):\n            port = None\n\n        return (scheme, host, port) == (self.scheme, self.host, self.port)", "response": "Check if the given url is a member of the same host as this connection pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nestablishes tunnel connection early because otherwise httplibConnection. set_tunnel is not available.", "response": "def _prepare_proxy(self, conn):\n        \"\"\"\n        Establish tunnel connection early, because otherwise httplib\n        would improperly set Host: header to proxy's IP:port.\n        \"\"\"\n        # Python 2.7+\n        try:\n            set_tunnel = conn.set_tunnel\n        except AttributeError:  # Platform-specific: Python 2.6\n            set_tunnel = conn._set_tunnel\n\n        if sys.version_info <= (2, 6, 4) and not self.proxy_headers:  # Python 2.6.4 and older\n            set_tunnel(self._proxy_host, self.port)\n        else:\n            set_tunnel(self._proxy_host, self.port, self.proxy_headers)\n\n        conn.connect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of option names for the given section name.", "response": "def options(self, section):\n        \"\"\"Return a list of option names for the given section name.\"\"\"\n        try:\n            opts = self._sections[section].copy()\n        except KeyError:\n            raise from_none(NoSectionError(section))\n        opts.update(self._defaults)\n        return list(opts.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading and parse a filename or a list of filenames.", "response": "def read(self, filenames, encoding=None):\n        \"\"\"Read and parse a filename or a list of filenames.\n\n        Files that cannot be opened are silently ignored; this is\n        designed so that you can specify a list of potential\n        configuration file locations (e.g. current directory, user's\n        home directory, systemwide directory), and all existing\n        configuration files in the list will be read.  A single\n        filename may also be given.\n\n        Return list of successfully read files.\n        \"\"\"\n        if PY2 and isinstance(filenames, bytes):\n            # we allow for a little unholy magic for Python 2 so that\n            # people not using unicode_literals can still use the library\n            # conveniently\n            warnings.warn(\n                \"You passed a bytestring as `filenames`. This will not work\"\n                \" on Python 3. Use `cp.read_file()` or switch to using Unicode\"\n                \" strings across the board.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            filenames = [filenames]\n        elif isinstance(filenames, str):\n            filenames = [filenames]\n        read_ok = []\n        for filename in filenames:\n            try:\n                with open(filename, encoding=encoding) as fp:\n                    self._read(fp, filename)\n            except IOError:\n                continue\n            read_ok.append(filename)\n        return read_ok"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike read but the argument must be a file - like object.", "response": "def read_file(self, f, source=None):\n        \"\"\"Like read() but the argument must be a file-like object.\n\n        The `f' argument must be iterable, returning one line at a time.\n        Optional second argument is the `source' specifying the name of the\n        file being read. If not given, it is taken from f.name. If `f' has no\n        `name' attribute, `<???>' is used.\n        \"\"\"\n        if source is None:\n            try:\n                source = f.name\n            except AttributeError:\n                source = '<???>'\n        self._read(f, source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_string(self, string, source='<string>'):\n        sfile = io.StringIO(string)\n        self.read_file(sfile, source)", "response": "Read configuration from a given string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads configuration from a dictionary.", "response": "def read_dict(self, dictionary, source='<dict>'):\n        \"\"\"Read configuration from a dictionary.\n\n        Keys are section names, values are dictionaries with keys and values\n        that should be present in the section. If the used dictionary type\n        preserves order, sections and their keys will be added in order.\n\n        All types held in the dictionary are converted to strings during\n        reading, including section names, option names and keys.\n\n        Optional second argument is the `source' specifying the name of the\n        dictionary being read.\n        \"\"\"\n        elements_added = set()\n        for section, keys in dictionary.items():\n            section = str(section)\n            try:\n                self.add_section(section)\n            except (DuplicateSectionError, ValueError):\n                if self._strict and section in elements_added:\n                    raise\n            elements_added.add(section)\n            for key, value in keys.items():\n                key = self.optionxform(str(key))\n                if value is not None:\n                    value = str(value)\n                if self._strict and (section, key) in elements_added:\n                    raise DuplicateOptionError(section, key, source)\n                elements_added.add((section, key))\n                self.set(section, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeprecates use read_file instead.", "response": "def readfp(self, fp, filename=None):\n        \"\"\"Deprecated, use read_file instead.\"\"\"\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'parser.read_file()' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        self.read_file(fp, source=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, section, option, **kwargs):\n        # keyword-only arguments\n        raw = kwargs.get('raw', False)\n        vars = kwargs.get('vars', None)\n        fallback = kwargs.get('fallback', _UNSET)\n\n        try:\n            d = self._unify_values(section, vars)\n        except NoSectionError:\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n        option = self.optionxform(option)\n        try:\n            value = d[option]\n        except KeyError:\n            if fallback is _UNSET:\n                raise NoOptionError(option, section)\n            else:\n                return fallback\n\n        if raw or value is None:\n            return value\n        else:\n            return self._interpolation.before_get(self, section, option, value,\n                                                  d)", "response": "Get an option value for a given section."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of tuples for each option in a section.", "response": "def items(self, section=_UNSET, raw=False, vars=None):\n        \"\"\"Return a list of (name, value) tuples for each option in a section.\n\n        All % interpolations are expanded in the return values, based on the\n        defaults passed into the constructor, unless the optional argument\n        `raw' is true.  Additional substitutions may be provided using the\n        `vars' argument, which must be a dictionary whose contents overrides\n        any pre-existing defaults.\n\n        The section DEFAULT is special.\n        \"\"\"\n        if section is _UNSET:\n            return super(RawConfigParser, self).items()\n        d = self._defaults.copy()\n        try:\n            d.update(self._sections[section])\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        if vars:\n            for key, value in vars.items():\n                d[self.optionxform(key)] = value\n        value_getter = lambda option: self._interpolation.before_get(self,\n            section, option, d[option], d)\n        if raw:\n            value_getter = lambda option: d[option]\n        return [(option, value_getter(option)) for option in d.keys()]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef popitem(self):\n        for key in self.sections():\n            value = self[key]\n            del self[key]\n            return key, value\n        raise KeyError", "response": "Remove a section from the parser and return it as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_option(self, section, option):\n        if not section or section == self.default_section:\n            option = self.optionxform(option)\n            return option in self._defaults\n        elif section not in self._sections:\n            return False\n        else:\n            option = self.optionxform(option)\n            return (option in self._sections[section]\n                    or option in self._defaults)", "response": "Check if a given option exists in a given section."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite an. ini - format representation of the configuration state.", "response": "def write(self, fp, space_around_delimiters=True):\n        \"\"\"Write an .ini-format representation of the configuration state.\n\n        If `space_around_delimiters' is True (the default), delimiters\n        between keys and values are surrounded by spaces.\n        \"\"\"\n        if space_around_delimiters:\n            d = \" {0} \".format(self._delimiters[0])\n        else:\n            d = self._delimiters[0]\n        if self._defaults:\n            self._write_section(fp, self.default_section,\n                                    self._defaults.items(), d)\n        for section in self._sections:\n            self._write_section(fp, section,\n                                self._sections[section].items(), d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a single section to the specified fp.", "response": "def _write_section(self, fp, section_name, section_items, delimiter):\n        \"\"\"Write a single section to the specified `fp'.\"\"\"\n        fp.write(\"[{0}]\\n\".format(section_name))\n        for key, value in section_items:\n            value = self._interpolation.before_write(self, section_name, key,\n                                                     value)\n            if value is not None or not self._allow_no_value:\n                value = delimiter + str(value).replace('\\n', '\\n\\t')\n            else:\n                value = \"\"\n            fp.write(\"{0}{1}\\n\".format(key, value))\n        fp.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_option(self, section, option):\n        if not section or section == self.default_section:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise from_none(NoSectionError(section))\n        option = self.optionxform(option)\n        existed = option in sectdict\n        if existed:\n            del sectdict[option]\n        return existed", "response": "Removes an option from the specified section."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_section(self, section):\n        existed = section in self._sections\n        if existed:\n            del self._sections[section]\n            del self._proxies[section]\n        return existed", "response": "Remove a file section."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a sectioned configuration file.", "response": "def _read(self, fp, fpname):\n        \"\"\"Parse a sectioned configuration file.\n\n        Each section in a configuration file contains a header, indicated by\n        a name in square brackets (`[]'), plus key/value options, indicated by\n        `name' and `value' delimited with a specific substring (`=' or `:' by\n        default).\n\n        Values can span multiple lines, as long as they are indented deeper\n        than the first line of the value. Depending on the parser's mode, blank\n        lines may be treated as parts of multiline values or ignored.\n\n        Configuration files may include comments, prefixed by specific\n        characters (`#' and `;' by default). Comments may appear on their own\n        in an otherwise empty line or may be entered in lines holding values or\n        section names.\n        \"\"\"\n        elements_added = set()\n        cursect = None                        # None, or a dictionary\n        sectname = None\n        optname = None\n        lineno = 0\n        indent_level = 0\n        e = None                              # None, or an exception\n        for lineno, line in enumerate(fp, start=1):\n            comment_start = sys.maxsize\n            # strip inline comments\n            inline_prefixes = dict(\n                (p, -1) for p in self._inline_comment_prefixes)\n            while comment_start == sys.maxsize and inline_prefixes:\n                next_prefixes = {}\n                for prefix, index in inline_prefixes.items():\n                    index = line.find(prefix, index+1)\n                    if index == -1:\n                        continue\n                    next_prefixes[prefix] = index\n                    if index == 0 or (index > 0 and line[index-1].isspace()):\n                        comment_start = min(comment_start, index)\n                inline_prefixes = next_prefixes\n            # strip full line comments\n            for prefix in self._comment_prefixes:\n                if line.strip().startswith(prefix):\n                    comment_start = 0\n                    break\n            if comment_start == sys.maxsize:\n                comment_start = None\n            value = line[:comment_start].strip()\n            if not value:\n                if self._empty_lines_in_values:\n                    # add empty line to the value, but only if there was no\n                    # comment on the line\n                    if (comment_start is None and\n                        cursect is not None and\n                        optname and\n                        cursect[optname] is not None):\n                        cursect[optname].append('') # newlines added at join\n                else:\n                    # empty line marks end of value\n                    indent_level = sys.maxsize\n                continue\n            # continuation line?\n            first_nonspace = self.NONSPACECRE.search(line)\n            cur_indent_level = first_nonspace.start() if first_nonspace else 0\n            if (cursect is not None and optname and\n                cur_indent_level > indent_level):\n                cursect[optname].append(value)\n            # a section header or option header?\n            else:\n                indent_level = cur_indent_level\n                # is it a section header?\n                mo = self.SECTCRE.match(value)\n                if mo:\n                    sectname = mo.group('header')\n                    if sectname in self._sections:\n                        if self._strict and sectname in elements_added:\n                            raise DuplicateSectionError(sectname, fpname,\n                                                        lineno)\n                        cursect = self._sections[sectname]\n                        elements_added.add(sectname)\n                    elif sectname == self.default_section:\n                        cursect = self._defaults\n                    else:\n                        cursect = self._dict()\n                        self._sections[sectname] = cursect\n                        self._proxies[sectname] = SectionProxy(self, sectname)\n                        elements_added.add(sectname)\n                    # So sections can't start with a continuation line\n                    optname = None\n                # no section header in the file?\n                elif cursect is None:\n                    raise MissingSectionHeaderError(fpname, lineno, line)\n                # an option line?\n                else:\n                    mo = self._optcre.match(value)\n                    if mo:\n                        optname, vi, optval = mo.group('option', 'vi', 'value')\n                        if not optname:\n                            e = self._handle_error(e, fpname, lineno, line)\n                        optname = self.optionxform(optname.rstrip())\n                        if (self._strict and\n                            (sectname, optname) in elements_added):\n                            raise DuplicateOptionError(sectname, optname,\n                                                       fpname, lineno)\n                        elements_added.add((sectname, optname))\n                        # This check is fine because the OPTCRE cannot\n                        # match if it would set optval to None\n                        if optval is not None:\n                            optval = optval.strip()\n                            cursect[optname] = [optval]\n                        else:\n                            # valueless option handling\n                            cursect[optname] = None\n                    else:\n                        # a non-fatal parsing error occurred. set up the\n                        # exception but keep going. the exception will be\n                        # raised at the end of the file and will contain a\n                        # list of all bogus lines\n                        e = self._handle_error(e, fpname, lineno, line)\n        # if any parsing errors occurred, raise an exception\n        if e:\n            raise e\n        self._join_multiline_values()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a sequence of lookups with vars taking priority over the section which takes priority over the DEFAULTSECT.", "response": "def _unify_values(self, section, vars):\n        \"\"\"Create a sequence of lookups with 'vars' taking priority over\n        the 'section' which takes priority over the DEFAULTSECT.\n\n        \"\"\"\n        sectiondict = {}\n        try:\n            sectiondict = self._sections[section]\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        vardict = {}\n        if vars:\n            for key, value in vars.items():\n                if value is not None:\n                    value = str(value)\n                vardict[self.optionxform(key)] = value\n        return _ChainMap(vardict, sectiondict, self._defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_to_boolean(self, value):\n        if value.lower() not in self.BOOLEAN_STATES:\n            raise ValueError('Not a boolean: %s' % value)\n        return self.BOOLEAN_STATES[value.lower()]", "response": "Convert a string to a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_value_types(self, **kwargs):\n        # keyword-only arguments\n        section = kwargs.get('section', \"\")\n        option = kwargs.get('option', \"\")\n        value = kwargs.get('value', \"\")\n\n        if PY2 and bytes in (type(section), type(option), type(value)):\n            # we allow for a little unholy magic for Python 2 so that\n            # people not using unicode_literals can still use the library\n            # conveniently\n            warnings.warn(\n                \"You passed a bytestring. Implicitly decoding as UTF-8 string.\"\n                \" This will not work on Python 3. Please switch to using\"\n                \" Unicode strings across the board.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            if isinstance(section, bytes):\n                section = section.decode('utf8')\n            if isinstance(option, bytes):\n                option = option.decode('utf8')\n            if isinstance(value, bytes):\n                value = value.decode('utf8')\n\n        if not isinstance(section, str):\n            raise TypeError(\"section names must be strings\")\n        if not isinstance(option, str):\n            raise TypeError(\"option keys must be strings\")\n        if not self._allow_no_value or value:\n            if not isinstance(value, str):\n                raise TypeError(\"option values must be strings\")\n\n        return section, option, value", "response": "Raises a TypeError for non - string values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextending RawConfigParser. set by validating type and interpolation syntax on the value.", "response": "def set(self, section, option, value=None):\n        \"\"\"Set an option.  Extends RawConfigParser.set by validating type and\n        interpolation syntax on the value.\"\"\"\n        _, option, value = self._validate_value_types(option=option, value=value)\n        super(ConfigParser, self).set(section, option, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextends the base class add_section by validating if the section name is a string.", "response": "def add_section(self, section):\n        \"\"\"Create a new section in the configuration.  Extends\n        RawConfigParser.add_section by validating if the section name is\n        a string.\"\"\"\n        section, _, _ = self._validate_value_types(section=section)\n        super(ConfigParser, self).add_section(section)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, option, fallback=None, **kwargs):\n        # keyword-only arguments\n        kwargs.setdefault('raw', False)\n        kwargs.setdefault('vars', None)\n        _impl = kwargs.pop('_impl', None)\n        # If `_impl` is provided, it should be a getter method on the parser\n        # object that provides the desired type conversion.\n        if not _impl:\n            _impl = self._parser.get\n        return _impl(self._name, option, fallback=fallback, **kwargs)", "response": "Get an option value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef analyse_text(text):\n        if re.match(r'^\\s*REBOL\\s*\\[', text, re.IGNORECASE):\n            # The code starts with REBOL header\n            return 1.0\n        elif re.search(r'\\s*REBOL\\s*[', text, re.IGNORECASE):\n            # The code contains REBOL header but also some text before it\n            return 0.5", "response": "Check if code contains REBOL header and if so it probably not R"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_exchange_key_ntlm_v1(negotiate_flags, session_base_key, server_challenge, lm_challenge_response, lm_hash):\n    if negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY:\n        key_exchange_key = hmac.new(session_base_key, server_challenge + lm_challenge_response[:8]).digest()\n    elif negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_LM_KEY:\n        des_handler = des.DES(lm_hash[:7])\n        first_des = des_handler.encrypt(lm_challenge_response[:8])\n        des_handler = des.DES(lm_hash[7:8] + binascii.unhexlify('bdbdbdbdbdbdbd'))\n        second_des = des_handler.encrypt(lm_challenge_response[:8])\n\n        key_exchange_key = first_des + second_des\n    elif negotiate_flags & NegotiateFlags.NTLMSSP_REQUEST_NON_NT_SESSION_KEY:\n        key_exchange_key = lm_hash[:8] + b'\\0' * 8\n    else:\n        key_exchange_key = session_base_key\n\n    return key_exchange_key", "response": "Calculates the Key Exchange Key for NTLMv1 authentication."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _wait_for_io_events(socks, events, timeout=None):\n    if not HAS_SELECT:\n        raise ValueError('Platform does not have a selector')\n    if not isinstance(socks, list):\n        # Probably just a single socket.\n        if hasattr(socks, \"fileno\"):\n            socks = [socks]\n        # Otherwise it might be a non-list iterable.\n        else:\n            socks = list(socks)\n    with DefaultSelector() as selector:\n        for sock in socks:\n            selector.register(sock, events)\n        return [key[0].fileobj for key in\n                selector.select(timeout) if key[1] & events]", "response": "Waits for IO events to be available from a list of sockets or a single socket if passed in. Returns a list of sockets that can be interacted with immediately."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling code block match", "response": "def _handle_codeblock(self, match):\n        \"\"\"\n        match args: 1:backticks, 2:lang_name, 3:newline, 4:code, 5:backticks\n        \"\"\"\n        from pygments.lexers import get_lexer_by_name\n\n        # section header\n        yield match.start(1), String        , match.group(1)\n        yield match.start(2), String        , match.group(2)\n        yield match.start(3), Text          , match.group(3)\n\n        # lookup lexer if wanted and existing\n        lexer = None\n        if self.handlecodeblocks:\n            try:\n                lexer = get_lexer_by_name( match.group(2).strip() )\n            except ClassNotFound:\n                pass\n        code = match.group(4)\n\n        # no lexer for this language. handle it like it was a code block\n        if lexer is None:\n            yield match.start(4), String, code\n            return\n\n        for item in do_insertions([], lexer.get_tokens_unprocessed(code)):\n            yield item\n\n        yield match.start(5), String        , match.group(5)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a static text analyser function that returns float values.", "response": "def make_analysator(f):\n    \"\"\"Return a static text analyser function that returns float values.\"\"\"\n    def text_analyse(text):\n        try:\n            rv = f(text)\n        except Exception:\n            return 0.0\n        if not rv:\n            return 0.0\n        try:\n            return min(1.0, max(0.0, float(rv)))\n        except (ValueError, TypeError):\n            return 0.0\n    text_analyse.__doc__ = f.__doc__\n    return staticmethod(text_analyse)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shebang_matches(text, regex):\n    index = text.find('\\n')\n    if index >= 0:\n        first_line = text[:index].lower()\n    else:\n        first_line = text.lower()\n    if first_line.startswith('#!'):\n        try:\n            found = [x for x in split_path_re.split(first_line[2:].strip())\n                     if x and not x.startswith('-')][-1]\n        except IndexError:\n            return False\n        regex = re.compile(r'^%s(\\.(exe|cmd|bat|bin))?$' % regex, re.IGNORECASE)\n        if regex.search(found) is not None:\n            return True\n    return False", "response": "r Check if the given regular expression matches the last part of the the\n    shebang if one exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the doctype matches a regular expression.", "response": "def doctype_matches(text, regex):\n    \"\"\"Check if the doctype matches a regular expression (if present).\n\n    Note that this method only checks the first part of a DOCTYPE.\n    eg: 'html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"'\n    \"\"\"\n    m = doctype_lookup_re.match(text)\n    if m is None:\n        return False\n    doctype = m.group(2)\n    return re.compile(regex, re.I).match(doctype.strip()) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef looks_like_xml(text):\n    if xml_decl_re.match(text):\n        return True\n    key = hash(text)\n    try:\n        return _looks_like_xml_cache[key]\n    except KeyError:\n        m = doctype_lookup_re.match(text)\n        if m is not None:\n            return True\n        rv = tag_re.search(text[:1000]) is not None\n        _looks_like_xml_cache[key] = rv\n        return rv", "response": "Check if a doctype exists or if we have some tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unirange(a, b):\n    if b < a:\n        raise ValueError(\"Bad character range\")\n    if a < 0x10000 or b < 0x10000:\n        raise ValueError(\"unirange is only defined for non-BMP ranges\")\n\n    if sys.maxunicode > 0xffff:\n        # wide build\n        return u'[%s-%s]' % (unichr(a), unichr(b))\n    else:\n        # narrow build stores surrogates, and the 're' module handles them\n        # (incorrectly) as characters.  Since there is still ordering among\n        # these characters, expand the range to one that it understands.  Some\n        # background in http://bugs.python.org/issue3665 and\n        # http://bugs.python.org/issue12749\n        #\n        # Additionally, the lower constants are using unichr rather than\n        # literals because jython [which uses the wide path] can't load this\n        # file if they are literals.\n        ah, al = _surrogatepair(a)\n        bh, bl = _surrogatepair(b)\n        if ah == bh:\n            return u'(?:%s[%s-%s])' % (unichr(ah), unichr(al), unichr(bl))\n        else:\n            buf = []\n            buf.append(u'%s[%s-%s]' %\n                       (unichr(ah), unichr(al),\n                        ah == bh and unichr(bl) or unichr(0xdfff)))\n            if ah - bh > 1:\n                buf.append(u'[%s-%s][%s-%s]' %\n                           unichr(ah+1), unichr(bh-1), unichr(0xdc00), unichr(0xdfff))\n            if ah != bh:\n                buf.append(u'%s[%s-%s]' %\n                           (unichr(bh), unichr(0xdc00), unichr(bl)))\n\n            return u'(?:' + u'|'.join(buf) + u')'", "response": "Returns a regular expression string to match the given non - BMP range."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_lines(var_name, seq, raw=False, indent_level=0):\n    lines = []\n    base_indent = ' ' * indent_level * 4\n    inner_indent = ' ' * (indent_level + 1) * 4\n    lines.append(base_indent + var_name + ' = (')\n    if raw:\n        # These should be preformatted reprs of, say, tuples.\n        for i in seq:\n            lines.append(inner_indent + i + ',')\n    else:\n        for i in seq:\n            # Force use of single quotes\n            r = repr(i + '\"')\n            lines.append(inner_indent + r[:-2] + r[-1] + ',')\n    lines.append(base_indent + ')')\n    return '\\n'.join(lines)", "response": "Formats a sequence of strings for output."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list with duplicates removed from the iterable it.", "response": "def duplicates_removed(it, already_seen=()):\n    \"\"\"\n    Returns a list with duplicates removed from the iterable `it`.\n\n    Order is preserved.\n    \"\"\"\n    lst = []\n    seen = set()\n    for i in it:\n        if i in seen or i in already_seen:\n            continue\n        lst.append(i)\n        seen.add(i)\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to decode text with guessed encoding.", "response": "def guess_decode(text):\n    \"\"\"Decode *text* with guessed encoding.\n\n    First try UTF-8; this should fail for non-UTF-8 encodings.\n    Then try the preferred locale encoding.\n    Fall back to latin-1, which always works.\n    \"\"\"\n    try:\n        text = text.decode('utf-8')\n        return text, 'utf-8'\n    except UnicodeDecodeError:\n        try:\n            import locale\n            prefencoding = locale.getpreferredencoding()\n            text = text.decode()\n            return text, prefencoding\n        except (UnicodeDecodeError, LookupError):\n            text = text.decode('latin1')\n            return text, 'latin1'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef guess_decode_from_terminal(text, term):\n    if getattr(term, 'encoding', None):\n        try:\n            text = text.decode(term.encoding)\n        except UnicodeDecodeError:\n            pass\n        else:\n            return text, term.encoding\n    return guess_decode(text)", "response": "Decode text coming from terminal term."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(args=sys.argv):\n    usage = USAGE % ((args[0],) * 6)\n\n    try:\n        popts, args = getopt.getopt(args[1:], \"l:f:F:o:O:P:LS:a:N:vhVHgsx\")\n    except getopt.GetoptError:\n        print(usage, file=sys.stderr)\n        return 2\n\n    try:\n        return main_inner(popts, args, usage)\n    except Exception:\n        if '-v' in dict(popts):\n            print(file=sys.stderr)\n            print('*' * 65, file=sys.stderr)\n            print('An unhandled exception occurred while highlighting.',\n                  file=sys.stderr)\n            print('Please report the whole traceback to the issue tracker at',\n                  file=sys.stderr)\n            print('<https://bitbucket.org/birkenfeld/pygments-main/issues>.',\n                  file=sys.stderr)\n            print('*' * 65, file=sys.stderr)\n            print(file=sys.stderr)\n            raise\n        import traceback\n        info = traceback.format_exception(*sys.exc_info())\n        msg = info[-1].strip()\n        if len(info) >= 3:\n            # extract relevant file and position info\n            msg += '\\n   (f%s)' % info[-2].split('\\n')[0].strip()[1:]\n        print(file=sys.stderr)\n        print('*** Error while highlighting:', file=sys.stderr)\n        print(msg, file=sys.stderr)\n        print('*** If this is a bug you want to report, please rerun with -v.',\n              file=sys.stderr)\n        return 1", "response": "Main entry point for the main command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_unencoded(self, tokensource, outfile):\n        x = self.xoffset\n        y = self.yoffset\n        if not self.nowrap:\n            if self.encoding:\n                outfile.write('<?xml version=\"1.0\" encoding=\"%s\"?>\\n' %\n                              self.encoding)\n            else:\n                outfile.write('<?xml version=\"1.0\"?>\\n')\n            outfile.write('<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.0//EN\" '\n                          '\"http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/'\n                          'svg10.dtd\">\\n')\n            outfile.write('<svg xmlns=\"http://www.w3.org/2000/svg\">\\n')\n            outfile.write('<g font-family=\"%s\" font-size=\"%s\">\\n' %\n                          (self.fontfamily, self.fontsize))\n        outfile.write('<text x=\"%s\" y=\"%s\" xml:space=\"preserve\">' % (x, y))\n        for ttype, value in tokensource:\n            style = self._get_style(ttype)\n            tspan = style and '<tspan' + style + '>' or ''\n            tspanend = tspan and '</tspan>' or ''\n            value = escape_html(value)\n            if self.spacehack:\n                value = value.expandtabs().replace(' ', '&#160;')\n            parts = value.split('\\n')\n            for part in parts[:-1]:\n                outfile.write(tspan + part + tspanend)\n                y += self.ystep\n                outfile.write('</text>\\n<text x=\"%s\" y=\"%s\" '\n                              'xml:space=\"preserve\">' % (x, y))\n            outfile.write(tspan + parts[-1] + tspanend)\n        outfile.write('</text>')\n\n        if not self.nowrap:\n            outfile.write('</g></svg>\\n')", "response": "Format unencoded text into a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the current project and branch.", "response": "def get_project_info(configs, heartbeat, data):\n    \"\"\"Find the current project and branch.\n\n    First looks for a .wakatime-project file. Second, uses the --project arg.\n    Third, uses the folder name from a revision control repository. Last, uses\n    the --alternate-project arg.\n\n    Returns a project, branch tuple.\n    \"\"\"\n\n    project_name, branch_name = heartbeat.project, heartbeat.branch\n\n    if heartbeat.type != 'file':\n        project_name = project_name or heartbeat.args.project or heartbeat.args.alternate_project\n        return project_name, branch_name\n\n    if project_name is None or branch_name is None:\n\n        for plugin_cls in CONFIG_PLUGINS:\n\n            plugin_name = plugin_cls.__name__.lower()\n            plugin_configs = get_configs_for_plugin(plugin_name, configs)\n\n            project = plugin_cls(heartbeat.entity, configs=plugin_configs)\n            if project.process():\n                project_name = project_name or project.name()\n                branch_name = project.branch()\n                break\n\n    if project_name is None:\n        project_name = data.get('project') or heartbeat.args.project\n\n    hide_project = heartbeat.should_obfuscate_project()\n    if hide_project and project_name is not None:\n        return project_name, None\n\n    if project_name is None or branch_name is None:\n\n        for plugin_cls in REV_CONTROL_PLUGINS:\n\n            plugin_name = plugin_cls.__name__.lower()\n            plugin_configs = get_configs_for_plugin(plugin_name, configs)\n\n            project = plugin_cls(heartbeat.entity, configs=plugin_configs)\n            if project.process():\n                project_name = project_name or project.name()\n                branch_name = branch_name or project.branch()\n                if hide_project:\n                    branch_name = None\n                    project_name = generate_project_name()\n                    project_file = os.path.join(project.folder(), '.wakatime-project')\n                    try:\n                        with open(project_file, 'w') as fh:\n                            fh.write(project_name)\n                    except IOError:\n                        project_name = None\n                break\n\n    if project_name is None and not hide_project:\n        project_name = data.get('alternate_project') or heartbeat.args.alternate_project\n\n    return project_name, branch_name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_project_name():\n\n    adjectives = [\n        'aged', 'ancient', 'autumn', 'billowing', 'bitter', 'black', 'blue', 'bold',\n        'broad', 'broken', 'calm', 'cold', 'cool', 'crimson', 'curly', 'damp',\n        'dark', 'dawn', 'delicate', 'divine', 'dry', 'empty', 'falling', 'fancy',\n        'flat', 'floral', 'fragrant', 'frosty', 'gentle', 'green', 'hidden', 'holy',\n        'icy', 'jolly', 'late', 'lingering', 'little', 'lively', 'long', 'lucky',\n        'misty', 'morning', 'muddy', 'mute', 'nameless', 'noisy', 'odd', 'old',\n        'orange', 'patient', 'plain', 'polished', 'proud', 'purple', 'quiet', 'rapid',\n        'raspy', 'red', 'restless', 'rough', 'round', 'royal', 'shiny', 'shrill',\n        'shy', 'silent', 'small', 'snowy', 'soft', 'solitary', 'sparkling', 'spring',\n        'square', 'steep', 'still', 'summer', 'super', 'sweet', 'throbbing', 'tight',\n        'tiny', 'twilight', 'wandering', 'weathered', 'white', 'wild', 'winter', 'wispy',\n        'withered', 'yellow', 'young'\n    ]\n    nouns = [\n        'art', 'band', 'bar', 'base', 'bird', 'block', 'boat', 'bonus',\n        'bread', 'breeze', 'brook', 'bush', 'butterfly', 'cake', 'cell', 'cherry',\n        'cloud', 'credit', 'darkness', 'dawn', 'dew', 'disk', 'dream', 'dust',\n        'feather', 'field', 'fire', 'firefly', 'flower', 'fog', 'forest', 'frog',\n        'frost', 'glade', 'glitter', 'grass', 'hall', 'hat', 'haze', 'heart',\n        'hill', 'king', 'lab', 'lake', 'leaf', 'limit', 'math', 'meadow',\n        'mode', 'moon', 'morning', 'mountain', 'mouse', 'mud', 'night', 'paper',\n        'pine', 'poetry', 'pond', 'queen', 'rain', 'recipe', 'resonance', 'rice',\n        'river', 'salad', 'scene', 'sea', 'shadow', 'shape', 'silence', 'sky',\n        'smoke', 'snow', 'snowflake', 'sound', 'star', 'sun', 'sun', 'sunset',\n        'surf', 'term', 'thunder', 'tooth', 'tree', 'truth', 'union', 'unit',\n        'violet', 'voice', 'water', 'waterfall', 'wave', 'wildflower', 'wind', 'wood'\n    ]\n    numbers = [str(x) for x in range(10)]\n    return ' '.join([\n        random.choice(adjectives).capitalize(),\n        random.choice(nouns).capitalize(),\n        random.choice(numbers) + random.choice(numbers),\n    ])", "response": "Generates a random project name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_lm_challenge_response(self):\n        if self._negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY and self._ntlm_compatibility < 3:\n            response = ComputeResponse._get_LMv1_with_session_security_response(self._client_challenge)\n\n        elif 0 <= self._ntlm_compatibility <= 1:\n            response = ComputeResponse._get_LMv1_response(self._password, self._server_challenge)\n        elif self._ntlm_compatibility == 2:\n            # Based on the compatibility level we don't want to use LM responses, ignore the session_base_key as it is returned in nt\n            response, ignore_key = ComputeResponse._get_NTLMv1_response(self._password, self._server_challenge)\n        else:\n            \"\"\"\n            [MS-NLMP] v28.0 page 45 - 2016-07-14\n\n            3.1.5.12 Client Received a CHALLENGE_MESSAGE from the Server\n            If NTLMv2 authentication is used and the CHALLENGE_MESSAGE TargetInfo field has an MsvAvTimestamp present,\n            the client SHOULD NOT send the LmChallengeResponse and SHOULD send Z(24) instead.\n            \"\"\"\n\n            response = ComputeResponse._get_LMv2_response(self._user_name, self._password, self._domain_name,\n                                                          self._server_challenge,\n                                                          self._client_challenge)\n            if self._server_target_info is not None:\n                timestamp = self._server_target_info[TargetInfo.MSV_AV_TIMESTAMP]\n                if timestamp is not None:\n                    response = b'\\0' * 24\n\n        return response", "response": "This method returns the LM challenge response for the server challenge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nt_challenge_response(self, lm_challenge_response, server_certificate_hash):\n        if self._negotiate_flags & NegotiateFlags.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY and self._ntlm_compatibility < 3:\n            # The compatibility level is less than 3 which means it doesn't support NTLMv2 but we want extended security so use NTLM2 which is different from NTLMv2\n            # [MS-NLMP] - 3.3.1 NTLMv1 Authentication\n            response, session_base_key = ComputeResponse._get_NTLM2_response(self._password, self._server_challenge, self._client_challenge)\n            key_exchange_key = compkeys._get_exchange_key_ntlm_v1(self._negotiate_flags, session_base_key,\n                                                                  self._server_challenge, lm_challenge_response,\n                                                                  comphash._lmowfv1(self._password))\n            target_info = None\n\n        elif 0 <= self._ntlm_compatibility < 3:\n            response, session_base_key = ComputeResponse._get_NTLMv1_response(self._password, self._server_challenge)\n            key_exchange_key = compkeys._get_exchange_key_ntlm_v1(self._negotiate_flags, session_base_key,\n                                                                  self._server_challenge, lm_challenge_response,\n                                                                  comphash._lmowfv1(self._password))\n            target_info = None\n        else:\n            if self._server_target_info is None:\n                target_info = TargetInfo()\n            else:\n                target_info = self._server_target_info\n\n            if target_info[TargetInfo.MSV_AV_TIMESTAMP] is None:\n                timestamp = get_windows_timestamp()\n            else:\n                timestamp = target_info[TargetInfo.MSV_AV_TIMESTAMP][1]\n\n                # [MS-NLMP] If the CHALLENGE_MESSAGE TargetInfo field has an MsvAvTimestamp present, the client SHOULD provide a MIC\n                target_info[TargetInfo.MSV_AV_FLAGS] = struct.pack(\"<L\", AvFlags.MIC_PROVIDED)\n\n            if server_certificate_hash != None:\n                channel_bindings_hash = ComputeResponse._get_channel_bindings_value(server_certificate_hash)\n                target_info[TargetInfo.MSV_AV_CHANNEL_BINDINGS] = channel_bindings_hash\n\n            response, session_base_key = ComputeResponse._get_NTLMv2_response(self._user_name, self._password, self._domain_name,\n                                                 self._server_challenge, self._client_challenge, timestamp, target_info)\n\n            key_exchange_key = compkeys._get_exchange_key_ntlm_v2(session_base_key)\n\n        return response, key_exchange_key, target_info", "response": "This method returns the NtChallengeResponse key based on the NTLMv1 NTLMv2 NTLMv1 and NTLMv2 and NTLMv2 negotiation flags and the server challenge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_LMv1_response(password, server_challenge):\n        lm_hash = comphash._lmowfv1(password)\n        response = ComputeResponse._calc_resp(lm_hash, server_challenge)\n\n        return response", "response": "Returns the LMv1 response for the given password and server challenge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_LMv2_response(user_name, password, domain_name, server_challenge, client_challenge):\n        nt_hash = comphash._ntowfv2(user_name, password, domain_name)\n        lm_hash = hmac.new(nt_hash, (server_challenge + client_challenge)).digest()\n        response = lm_hash + client_challenge\n\n        return response", "response": "Returns the LMv2_RESPONSE structure for the NTLM v2 authentication."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_NTLMv2_temp(timestamp, client_challenge, target_info):\n        resp_type = b'\\1'\n        hi_resp_type = b'\\1'\n        reserved1 = b'\\0' * 2\n        reserved2 = b'\\0' * 4\n        reserved3 = b'\\0' * 4\n        reserved4 = b'\\0' * 4  # This byte is not in the structure defined in 2.2.2.7 but is in the computation guide, works with it present\n\n        temp = resp_type + hi_resp_type + reserved1 + \\\n               reserved2 + \\\n               timestamp + \\\n               client_challenge + \\\n               reserved3 + \\\n               target_info.get_data() + reserved4\n\n        return temp", "response": "This function is used to create the NTLMv2_TEMP value for the NTLMv2_MESSAGE_RESPONSE and NTLMv2_MESSAGE_AUTHENTICATE_MESSAGE_RESPONSE fields."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the value of the channel bindings field from the server certificate hash.", "response": "def _get_channel_bindings_value(server_certificate_hash):\n        \"\"\"\n        https://msdn.microsoft.com/en-us/library/windows/desktop/dd919963%28v=vs.85%29.aspx?f=255&MSPPError=-2147217396\n        https://blogs.msdn.microsoft.com/openspecification/2013/03/26/ntlm-and-channel-binding-hash-aka-extended-protection-for-authentication/\n\n        Get's the MD5 hash of the gss_channel_bindings_struct to add to the AV_PAIR MSV_AV_CHANNEL_BINDINGS.\n        This method takes in the SHA256 hash (Hash of the DER encoded certificate of the server we are connecting to)\n        and add's it to the gss_channel_bindings_struct. It then gets the MD5 hash and converts this to a\n        byte array in preparation of adding it to the AV_PAIR structure.\n\n        :param server_certificate_hash: The SHA256 hash of the server certificate (DER encoded) NTLM is authenticated to\n        :return channel_bindings: An MD5 hash of the gss_channel_bindings_struct to add to the AV_PAIR MsvChannelBindings\n        \"\"\"\n        # Channel Binding Tokens support, used for NTLMv2\n        # Decode the SHA256 certificate hash\n        certificate_digest = base64.b16decode(server_certificate_hash)\n\n        # Initialise the GssChannelBindingsStruct and add the certificate_digest to the application_data field\n        gss_channel_bindings = GssChannelBindingsStruct()\n        gss_channel_bindings[gss_channel_bindings.APPLICATION_DATA] = 'tls-server-end-point:'.encode() + certificate_digest\n\n        # Get the gss_channel_bindings_struct and create an MD5 hash\n        channel_bindings_struct_data = gss_channel_bindings.get_data()\n        channel_bindings_hash = hashlib.md5(channel_bindings_struct_data).hexdigest()\n\n        try:\n            cbt_value = bytearray.fromhex(channel_bindings_hash)\n        except TypeError:\n            # Work-around for Python 2.6 bug\n            cbt_value = bytearray.fromhex(unicode(channel_bindings_hash))\n\n        channel_bindings = bytes(cbt_value)\n        return channel_bindings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_httplib(cls, message):  # Python 2\n        # python2.7 does not expose a proper API for exporting multiheaders\n        # efficiently. This function re-reads raw lines from the message\n        # object and extracts the multiheaders properly.\n        headers = []\n\n        for line in message.headers:\n            if line.startswith((' ', '\\t')):\n                key, value = headers[-1]\n                headers[-1] = (key, value + '\\r\\n' + line.rstrip())\n                continue\n\n            key, value = line.split(':', 1)\n            headers.append((key, value.strip()))\n\n        return cls(headers)", "response": "Read headers from a Python 2 httplib message object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, session):\n\n        if not HAS_SQL:  # pragma: nocover\n            return\n        try:\n            conn, c = self.connect()\n            c.execute('DELETE FROM {0}'.format(self.table_name))\n            values = {\n                'value': sqlite3.Binary(pickle.dumps(session, protocol=2)),\n            }\n            c.execute('INSERT INTO {0} VALUES (:value)'.format(self.table_name), values)\n            conn.commit()\n            conn.close()\n        except:  # pragma: nocover\n            log.traceback(logging.DEBUG)", "response": "Saves a requests. Session object for the next heartbeat process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self):\n\n        if not HAS_SQL:  # pragma: nocover\n            return requests.session()\n\n        try:\n            conn, c = self.connect()\n        except:\n            log.traceback(logging.DEBUG)\n            return requests.session()\n\n        session = None\n        try:\n            c.execute('BEGIN IMMEDIATE')\n            c.execute('SELECT value FROM {0} LIMIT 1'.format(self.table_name))\n            row = c.fetchone()\n            if row is not None:\n                session = pickle.loads(row[0])\n        except:  # pragma: nocover\n            log.traceback(logging.DEBUG)\n\n        try:\n            conn.close()\n        except:  # pragma: nocover\n            log.traceback(logging.DEBUG)\n\n        return session if session is not None else requests.session()", "response": "Gets a requests. Session object from sqlite3 cache or creates a new Session object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear all cached Session objects.", "response": "def delete(self):\n        \"\"\"Clears all cached Session objects.\n        \"\"\"\n\n        if not HAS_SQL:  # pragma: nocover\n            return\n        try:\n            conn, c = self.connect()\n            c.execute('DELETE FROM {0}'.format(self.table_name))\n            conn.commit()\n            conn.close()\n        except:\n            log.traceback(logging.DEBUG)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the decoder attribute if necessary.", "response": "def _init_decoder(self):\n        \"\"\"\n        Set-up the _decoder attribute if necessary.\n        \"\"\"\n        # Note: content-encoding value should be case-insensitive, per RFC 7230\n        # Section 3.2\n        content_encoding = self.headers.get('content-encoding', '').lower()\n        if self._decoder is None and content_encoding in self.CONTENT_DECODERS:\n            self._decoder = _get_decoder(content_encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_redirects(self, resp, req, stream=False, timeout=None,\n                          verify=True, cert=None, proxies=None, yield_requests=False, **adapter_kwargs):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith('//'):\n                parsed_rurl = urlparse(resp.url)\n                url = '%s:%s' % (to_native_string(parsed_rurl.scheme), url)\n\n            # The scheme should be lower case...\n            parsed = urlparse(url)\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/requests/requests/issues/1084\n            if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n                # https://github.com/requests/requests/issues/3490\n                purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            try:\n                del headers['Cookie']\n            except KeyError:\n                pass\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = (\n                prepared_request._body_position is not None and\n                ('Content-Length' in headers or 'Transfer-Encoding' in headers)\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp", "response": "Receives a Response. Returns a generator of Responses or Requests."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rebuild_auth(self, prepared_request, response):\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if 'Authorization' in headers:\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            original_parsed = urlparse(response.request.url)\n            redirect_parsed = urlparse(url)\n\n            if (original_parsed.hostname != redirect_parsed.hostname):\n                del headers['Authorization']\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if self.trust_env else None\n        if new_auth is not None:\n            prepared_request.prepare_auth(new_auth)\n\n        return", "response": "Rebuilds the authentication headers for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrebuilds the method of the current request based on the status code of the response.", "response": "def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # http://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != 'HEAD':\n            method = 'GET'\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != 'HEAD':\n            method = 'GET'\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == 'POST':\n            method = 'GET'\n\n        prepared_request.method = method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_filters(stream, filters, lexer=None):\n    def _apply(filter_, stream):\n        for token in filter_.filter(lexer, stream):\n            yield token\n    for filter_ in filters:\n        stream = _apply(filter_, stream)\n    return stream", "response": "Apply a list of filters to a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef simplefilter(f):\n    return type(f.__name__, (FunctionFilter,), {\n        '__module__': getattr(f, '__module__'),\n        '__doc__': f.__doc__,\n        'function': f,\n    })", "response": "Decorator that converts a function into a filter::\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the connection is dropped and should be closed.", "response": "def is_connection_dropped(conn):  # Platform-specific\n    \"\"\"\n    Returns True if the connection is dropped and should be closed.\n\n    :param conn:\n        :class:`httplib.HTTPConnection` object.\n\n    Note: For platforms like AppEngine, this will always return ``False`` to\n    let the platform handle connection recycling transparently for us.\n    \"\"\"\n    sock = getattr(conn, 'sock', False)\n    if sock is False:  # Platform-specific: AppEngine\n        return False\n    if sock is None:  # Connection already closed (such as by httplib).\n        return True\n\n    if not HAS_SELECT:\n        return False\n\n    try:\n        return bool(wait_for_read(sock, timeout=0.0))\n    except SelectorError:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassert that all headers have been successfully parsed.", "response": "def assert_header_parsing(headers):\n    \"\"\"\n    Asserts whether all headers have been successfully parsed.\n    Extracts encountered errors from the result of parsing headers.\n\n    Only works on Python 3.\n\n    :param headers: Headers to verify.\n    :type headers: `httplib.HTTPMessage`.\n\n    :raises urllib3.exceptions.HeaderParsingError:\n        If parsing errors are found.\n    \"\"\"\n\n    # This will fail silently if we pass in the wrong kind of parameter.\n    # To make debugging easier add an explicit check.\n    if not isinstance(headers, httplib.HTTPMessage):\n        raise TypeError('expected httplib.Message, got {0}.'.format(\n            type(headers)))\n\n    defects = getattr(headers, 'defects', None)\n    get_payload = getattr(headers, 'get_payload', None)\n\n    unparsed_data = None\n    if get_payload:  # Platform-specific: Python 3.\n        unparsed_data = get_payload()\n\n    if defects or unparsed_data:\n        raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset_indent(token_class):\n        def callback(lexer, match, context):\n            text = match.group()\n            context.indent_stack = []\n            context.indent = -1\n            context.next_indent = 0\n            context.block_scalar_indent = None\n            yield match.start(), token_class, text\n            context.pos = match.end()\n        return callback", "response": "Reset the indentation levels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_indent(token_class, start=False):\n        def callback(lexer, match, context):\n            text = match.group()\n            extra = ''\n            if start:\n                context.next_indent = len(text)\n                if context.next_indent < context.indent:\n                    while context.next_indent < context.indent:\n                        context.indent = context.indent_stack.pop()\n                    if context.next_indent > context.indent:\n                        extra = text[context.indent:]\n                        text = text[:context.indent]\n            else:\n                context.next_indent += len(text)\n            if text:\n                yield match.start(), token_class, text\n            if extra:\n                yield match.start()+len(text), token_class.Error, extra\n            context.pos = match.end()\n        return callback", "response": "Save a possible indentation level."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets an explicit indentation level for a block scalar.", "response": "def set_block_scalar_indent(token_class):\n        \"\"\"Set an explicit indentation level for a block scalar.\"\"\"\n        def callback(lexer, match, context):\n            text = match.group()\n            context.block_scalar_indent = None\n            if not text:\n                return\n            increment = match.group(1)\n            if increment:\n                current_indent = max(context.indent, 0)\n                increment = int(increment)\n                context.block_scalar_indent = current_indent + increment\n            if text:\n                yield match.start(), token_class, text\n                context.pos = match.end()\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a callback that yields a match for an empty line in a block scalar.", "response": "def parse_block_scalar_empty_line(indent_token_class, content_token_class):\n        \"\"\"Process an empty line in a block scalar.\"\"\"\n        def callback(lexer, match, context):\n            text = match.group()\n            if (context.block_scalar_indent is None or\n                    len(text) <= context.block_scalar_indent):\n                if text:\n                    yield match.start(), indent_token_class, text\n            else:\n                indentation = text[:context.block_scalar_indent]\n                content = text[context.block_scalar_indent:]\n                yield match.start(), indent_token_class, indentation\n                yield (match.start()+context.block_scalar_indent,\n                       content_token_class, content)\n            context.pos = match.end()\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_block_scalar_indent(token_class):\n        def callback(lexer, match, context):\n            text = match.group()\n            if context.block_scalar_indent is None:\n                if len(text) <= max(context.indent, 0):\n                    context.stack.pop()\n                    context.stack.pop()\n                    return\n                context.block_scalar_indent = len(text)\n            else:\n                if len(text) < context.block_scalar_indent:\n                    context.stack.pop()\n                    context.stack.pop()\n                    return\n            if text:\n                yield match.start(), token_class, text\n                context.pos = match.end()\n        return callback", "response": "Return a callback that processes indentation spaces in a block scalar."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to find the local timezone configuration.", "response": "def _get_localzone(_root='/'):\n    \"\"\"Tries to find the local timezone configuration.\n\n    This method prefers finding the timezone name and passing that to pytz,\n    over passing in the localtime file, as in the later case the zoneinfo\n    name is unknown.\n\n    The parameter _root makes the function look for files like /etc/localtime\n    beneath the _root directory. This is primarily used by the tests.\n    In normal usage you call the function without parameters.\"\"\"\n\n    tzenv = os.environ.get('TZ')\n    if tzenv:\n        try:\n            return _tz_from_env(tzenv)\n        except pytz.UnknownTimeZoneError:\n            pass\n\n    # Now look for distribution specific configuration files\n    # that contain the timezone name.\n    for configfile in ('etc/timezone', 'var/db/zoneinfo'):\n        tzpath = os.path.join(_root, configfile)\n        if os.path.exists(tzpath):\n            with open(tzpath, 'rb') as tzfile:\n                data = tzfile.read()\n\n                # Issue #3 was that /etc/timezone was a zoneinfo file.\n                # That's a misconfiguration, but we need to handle it gracefully:\n                if data[:5] != 'TZif2':\n                    etctz = data.strip().decode()\n                    # Get rid of host definitions and comments:\n                    if ' ' in etctz:\n                        etctz, dummy = etctz.split(' ', 1)\n                    if '#' in etctz:\n                        etctz, dummy = etctz.split('#', 1)\n                    return pytz.timezone(etctz.replace(' ', '_'))\n\n    # CentOS has a ZONE setting in /etc/sysconfig/clock,\n    # OpenSUSE has a TIMEZONE setting in /etc/sysconfig/clock and\n    # Gentoo has a TIMEZONE setting in /etc/conf.d/clock\n    # We look through these files for a timezone:\n\n    zone_re = re.compile('\\s*ZONE\\s*=\\s*\\\"')\n    timezone_re = re.compile('\\s*TIMEZONE\\s*=\\s*\\\"')\n    end_re = re.compile('\\\"')\n\n    for filename in ('etc/sysconfig/clock', 'etc/conf.d/clock'):\n        tzpath = os.path.join(_root, filename)\n        if not os.path.exists(tzpath):\n            continue\n        with open(tzpath, 'rt') as tzfile:\n            data = tzfile.readlines()\n\n        for line in data:\n            # Look for the ZONE= setting.\n            match = zone_re.match(line)\n            if match is None:\n                # No ZONE= setting. Look for the TIMEZONE= setting.\n                match = timezone_re.match(line)\n            if match is not None:\n                # Some setting existed\n                line = line[match.end():]\n                etctz = line[:end_re.search(line).start()]\n\n                # We found a timezone\n                return pytz.timezone(etctz.replace(' ', '_'))\n\n    # systemd distributions use symlinks that include the zone name,\n    # see manpage of localtime(5) and timedatectl(1)\n    tzpath = os.path.join(_root, 'etc/localtime')\n    if os.path.exists(tzpath) and os.path.islink(tzpath):\n        tzpath = os.path.realpath(tzpath)\n        start = tzpath.find(\"/\")+1\n        while start is not 0:\n            tzpath = tzpath[start:]\n            try:\n                return pytz.timezone(tzpath)\n            except pytz.UnknownTimeZoneError:\n                pass\n            start = tzpath.find(\"/\")+1\n\n    # No explicit setting existed. Use localtime\n    for filename in ('etc/localtime', 'usr/local/etc/localtime'):\n        tzpath = os.path.join(_root, filename)\n\n        if not os.path.exists(tzpath):\n            continue\n        with open(tzpath, 'rb') as tzfile:\n            return pytz.tzfile.build_tzinfo('local', tzfile)\n\n    raise pytz.UnknownTimeZoneError('Can not find any timezone configuration')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over the response data one line at a time.", "response": "def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            for line in lines:\n                yield line\n\n        if pending is not None:\n            yield pending"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the content of the response in bytes.", "response": "def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\n                    'The content for this response was already consumed')\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nscans the string s for a JSON string.", "response": "def py_scanstring(s, end, encoding=None, strict=True,\n        _b=BACKSLASH, _m=STRINGCHUNK.match, _join=u('').join,\n        _PY3=PY3, _maxunicode=sys.maxunicode):\n    \"\"\"Scan the string s for a JSON string. End is the index of the\n    character in s after the quote that started the JSON string.\n    Unescapes all valid JSON string escape sequences and raises ValueError\n    on attempt to decode an invalid string. If strict is False then literal\n    control characters are allowed in the string.\n\n    Returns a tuple of the decoded string and the index of the character in s\n    after the end quote.\"\"\"\n    if encoding is None:\n        encoding = DEFAULT_ENCODING\n    chunks = []\n    _append = chunks.append\n    begin = end - 1\n    while 1:\n        chunk = _m(s, end)\n        if chunk is None:\n            raise JSONDecodeError(\n                \"Unterminated string starting at\", s, begin)\n        end = chunk.end()\n        content, terminator = chunk.groups()\n        # Content is contains zero or more unescaped string characters\n        if content:\n            if not _PY3 and not isinstance(content, text_type):\n                content = text_type(content, encoding)\n            _append(content)\n        # Terminator is the end of string, a literal control character,\n        # or a backslash denoting that an escape sequence follows\n        if terminator == '\"':\n            break\n        elif terminator != '\\\\':\n            if strict:\n                msg = \"Invalid control character %r at\"\n                raise JSONDecodeError(msg, s, end)\n            else:\n                _append(terminator)\n                continue\n        try:\n            esc = s[end]\n        except IndexError:\n            raise JSONDecodeError(\n                \"Unterminated string starting at\", s, begin)\n        # If not a unicode escape sequence, must be in the lookup table\n        if esc != 'u':\n            try:\n                char = _b[esc]\n            except KeyError:\n                msg = \"Invalid \\\\X escape sequence %r\"\n                raise JSONDecodeError(msg, s, end)\n            end += 1\n        else:\n            # Unicode escape sequence\n            msg = \"Invalid \\\\uXXXX escape sequence\"\n            esc = s[end + 1:end + 5]\n            escX = esc[1:2]\n            if len(esc) != 4 or escX == 'x' or escX == 'X':\n                raise JSONDecodeError(msg, s, end - 1)\n            try:\n                uni = int(esc, 16)\n            except ValueError:\n                raise JSONDecodeError(msg, s, end - 1)\n            end += 5\n            # Check for surrogate pair on UCS-4 systems\n            # Note that this will join high/low surrogate pairs\n            # but will also pass unpaired surrogates through\n            if (_maxunicode > 65535 and\n                uni & 0xfc00 == 0xd800 and\n                s[end:end + 2] == '\\\\u'):\n                esc2 = s[end + 2:end + 6]\n                escX = esc2[1:2]\n                if len(esc2) == 4 and not (escX == 'x' or escX == 'X'):\n                    try:\n                        uni2 = int(esc2, 16)\n                    except ValueError:\n                        raise JSONDecodeError(msg, s, end)\n                    if uni2 & 0xfc00 == 0xdc00:\n                        uni = 0x10000 + (((uni - 0xd800) << 10) |\n                                         (uni2 - 0xdc00))\n                        end += 6\n            char = unichr(uni)\n        # Append the unescaped character\n        _append(char)\n    return _join(chunks), end"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode a string or unicode object into a Python object.", "response": "def decode(self, s, _w=WHITESPACE.match, _PY3=PY3):\n        \"\"\"Return the Python representation of ``s`` (a ``str`` or ``unicode``\n        instance containing a JSON document)\n\n        \"\"\"\n        if _PY3 and isinstance(s, binary_type):\n            s = s.decode(self.encoding)\n        obj, end = self.raw_decode(s)\n        end = _w(s, end).end()\n        if end != len(s):\n            raise JSONDecodeError(\"Extra data\", s, end, len(s))\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes a JSON document from s and return a 2 - tuple of the Python version and the index in s where the document begins.", "response": "def raw_decode(self, s, idx=0, _w=WHITESPACE.match, _PY3=PY3):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` or ``unicode``\n        beginning with a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n        Optionally, ``idx`` can be used to specify an offset in ``s`` where\n        the JSON document begins.\n\n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n\n        \"\"\"\n        if idx < 0:\n            # Ensure that raw_decode bails on negative indexes, the regex\n            # would otherwise mask this behavior. #98\n            raise JSONDecodeError('Expecting value', s, idx)\n        if _PY3 and not isinstance(s, text_type):\n            raise TypeError(\"Input string must be text, not bytes\")\n        # strip UTF-8 bom\n        if len(s) > idx:\n            ord0 = ord(s[idx])\n            if ord0 == 0xfeff:\n                idx += 1\n            elif ord0 == 0xef and s[idx:idx + 3] == '\\xef\\xbb\\xbf':\n                idx += 3\n        return self.scan_once(s, idx=_w(s, idx).end())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the css class of this token type prefixed with the classprefix option.", "response": "def _get_css_class(self, ttype):\n        \"\"\"Return the css class of this token type prefixed with\n        the classprefix option.\"\"\"\n        ttypeclass = _get_ttype_class(ttype)\n        if ttypeclass:\n            return self.classprefix + ttypeclass\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_css_classes(self, ttype):\n        cls = self._get_css_class(ttype)\n        while ttype not in STANDARD_TYPES:\n            ttype = ttype.parent\n            cls = self._get_css_class(ttype) + ' ' + cls\n        return cls", "response": "Return the css classes of this token type prefixed with\n        the classprefix option."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns CSS style definitions for the current token type classes produced by the current language.", "response": "def get_style_defs(self, arg=None):\n        \"\"\"\n        Return CSS style definitions for the classes produced by the current\n        highlighting style. ``arg`` can be a string or list of selectors to\n        insert before the token type classes.\n        \"\"\"\n        if arg is None:\n            arg = ('cssclass' in self.options and '.'+self.cssclass or '')\n        if isinstance(arg, string_types):\n            args = [arg]\n        else:\n            args = list(arg)\n\n        def prefix(cls):\n            if cls:\n                cls = '.' + cls\n            tmp = []\n            for arg in args:\n                tmp.append((arg and arg + ' ' or '') + cls)\n            return ', '.join(tmp)\n\n        styles = [(level, ttype, cls, style)\n                  for cls, (style, ttype, level) in iteritems(self.class2style)\n                  if cls and style]\n        styles.sort()\n        lines = ['%s { %s } /* %s */' % (prefix(cls), style, repr(ttype)[6:])\n                 for (level, ttype, cls, style) in styles]\n        if arg and not self.nobackground and \\\n           self.style.background_color is not None:\n            text_style = ''\n            if Text in self.ttype2class:\n                text_style = ' ' + self.class2style[self.ttype2class[Text]][0]\n            lines.insert(0, '%s { background: %s;%s }' %\n                         (prefix(''), self.style.background_color, text_style))\n        if self.style.highlight_color is not None:\n            lines.insert(0, '%s.hll { background-color: %s }' %\n                         (prefix(''), self.style.highlight_color))\n        return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _format_lines(self, tokensource):\n        nocls = self.noclasses\n        lsep = self.lineseparator\n        # for <span style=\"\"> lookup only\n        getcls = self.ttype2class.get\n        c2s = self.class2style\n        escape_table = _escape_html_table\n        tagsfile = self.tagsfile\n\n        lspan = ''\n        line = []\n        for ttype, value in tokensource:\n            if nocls:\n                cclass = getcls(ttype)\n                while cclass is None:\n                    ttype = ttype.parent\n                    cclass = getcls(ttype)\n                cspan = cclass and '<span style=\"%s\">' % c2s[cclass][0] or ''\n            else:\n                cls = self._get_css_classes(ttype)\n                cspan = cls and '<span class=\"%s\">' % cls or ''\n\n            parts = value.translate(escape_table).split('\\n')\n\n            if tagsfile and ttype in Token.Name:\n                filename, linenumber = self._lookup_ctag(value)\n                if linenumber:\n                    base, filename = os.path.split(filename)\n                    if base:\n                        base += '/'\n                    filename, extension = os.path.splitext(filename)\n                    url = self.tagurlformat % {'path': base, 'fname': filename,\n                                               'fext': extension}\n                    parts[0] = \"<a href=\\\"%s#%s-%d\\\">%s\" % \\\n                        (url, self.lineanchors, linenumber, parts[0])\n                    parts[-1] = parts[-1] + \"</a>\"\n\n            # for all but the last line\n            for part in parts[:-1]:\n                if line:\n                    if lspan != cspan:\n                        line.extend(((lspan and '</span>'), cspan, part,\n                                     (cspan and '</span>'), lsep))\n                    else:  # both are the same\n                        line.extend((part, (lspan and '</span>'), lsep))\n                    yield 1, ''.join(line)\n                    line = []\n                elif part:\n                    yield 1, ''.join((cspan, part, (cspan and '</span>'), lsep))\n                else:\n                    yield 1, lsep\n            # for the last line\n            if line and parts[-1]:\n                if lspan != cspan:\n                    line.extend(((lspan and '</span>'), cspan, parts[-1]))\n                    lspan = cspan\n                else:\n                    line.append(parts[-1])\n            elif parts[-1]:\n                line = [cspan, parts[-1]]\n                lspan = cspan\n            # else we neither have to open a new span nor set lspan\n\n        if line:\n            line.extend(((lspan and '</span>'), lsep))\n            yield 1, ''.join(line)", "response": "Yields the lines of the tokens in the source."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhighlighting the lines specified in the hl_lines option by post - processing the token stream coming from _format_lines.", "response": "def _highlight_lines(self, tokensource):\n        \"\"\"\n        Highlighted the lines specified in the `hl_lines` option by\n        post-processing the token stream coming from `_format_lines`.\n        \"\"\"\n        hls = self.hl_lines\n\n        for i, (t, value) in enumerate(tokensource):\n            if t != 1:\n                yield t, value\n            if i + 1 in hls:  # i + 1 because Python indexes start at 0\n                if self.noclasses:\n                    style = ''\n                    if self.style.highlight_color is not None:\n                        style = (' style=\"background-color: %s\"' %\n                                 (self.style.highlight_color,))\n                    yield 1, '<span%s>%s</span>' % (style, value)\n                else:\n                    yield 1, '<span class=\"hll\">%s</span>' % value\n            else:\n                yield 1, value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the source tokensource into a single file.", "response": "def format_unencoded(self, tokensource, outfile):\n        \"\"\"\n        The formatting process uses several nested generators; which of\n        them are used is determined by the user's options.\n\n        Each generator should take at least one argument, ``inner``,\n        and wrap the pieces of text generated by this.\n\n        Always yield 2-tuples: (code, text). If \"code\" is 1, the text\n        is part of the original tokensource being highlighted, if it's\n        0, the text is some piece of wrapping. This makes it possible to\n        use several different wrappers that process the original source\n        linewise, e.g. line number generators.\n        \"\"\"\n        source = self._format_lines(tokensource)\n        if self.hl_lines:\n            source = self._highlight_lines(source)\n        if not self.nowrap:\n            if self.linenos == 2:\n                source = self._wrap_inlinelinenos(source)\n            if self.lineanchors:\n                source = self._wrap_lineanchors(source)\n            if self.linespans:\n                source = self._wrap_linespans(source)\n            source = self.wrap(source, outfile)\n            if self.linenos == 1:\n                source = self._wrap_tablelinenos(source)\n            if self.full:\n                source = self._wrap_full(source, outfile)\n\n        for t, piece in source:\n            outfile.write(piece)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bygroups(*args):\n    def callback(lexer, match, ctx=None):\n        for i, action in enumerate(args):\n            if action is None:\n                continue\n            elif type(action) is _TokenType:\n                data = match.group(i + 1)\n                if data:\n                    yield match.start(i + 1), action, data\n            else:\n                data = match.group(i + 1)\n                if data is not None:\n                    if ctx:\n                        ctx.pos = match.start(i + 1)\n                    for item in action(lexer,\n                                       _PseudoMatch(match.start(i + 1), data), ctx):\n                        if item:\n                            yield item\n        if ctx:\n            ctx.pos = match.end()\n    return callback", "response": "Callback that yields multiple actions for each group in the match."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a callback that processes the match with a different lexer.", "response": "def using(_other, **kwargs):\n    \"\"\"\n    Callback that processes the match with a different lexer.\n\n    The keyword arguments are forwarded to the lexer, except `state` which\n    is handled separately.\n\n    `state` specifies the state that the new lexer will start in, and can\n    be an enumerable such as ('root', 'inline', 'string') or a simple\n    string which is assumed to be on top of the root state.\n\n    Note: For that to work, `_other` must not be an `ExtendedRegexLexer`.\n    \"\"\"\n    gt_kwargs = {}\n    if 'state' in kwargs:\n        s = kwargs.pop('state')\n        if isinstance(s, (list, tuple)):\n            gt_kwargs['stack'] = s\n        else:\n            gt_kwargs['stack'] = ('root', s)\n\n    if _other is this:\n        def callback(lexer, match, ctx=None):\n            # if keyword arguments are given the callback\n            # function has to create a new lexer instance\n            if kwargs:\n                # XXX: cache that somehow\n                kwargs.update(lexer.options)\n                lx = lexer.__class__(**kwargs)\n            else:\n                lx = lexer\n            s = match.start()\n            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):\n                yield i + s, t, v\n            if ctx:\n                ctx.pos = match.end()\n    else:\n        def callback(lexer, match, ctx=None):\n            # XXX: cache that somehow\n            kwargs.update(lexer.options)\n            lx = _other(**kwargs)\n\n            s = match.start()\n            for i, t, v in lx.get_tokens_unprocessed(match.group(), **gt_kwargs):\n                yield i + s, t, v\n            if ctx:\n                ctx.pos = match.end()\n    return callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_regex(cls, regex, rflags, state):\n        if isinstance(regex, Future):\n            regex = regex.get()\n        return re.compile(regex, rflags).match", "response": "Preprocess the regular expression component of a token definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_token(cls, token):\n        assert type(token) is _TokenType or callable(token), \\\n            'token type must be simple type or callable, not %r' % (token,)\n        return token", "response": "Preprocess the token component of a token definition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_new_state(cls, new_state, unprocessed, processed):\n        if isinstance(new_state, str):\n            # an existing state\n            if new_state == '#pop':\n                return -1\n            elif new_state in unprocessed:\n                return (new_state,)\n            elif new_state == '#push':\n                return new_state\n            elif new_state[:5] == '#pop:':\n                return -int(new_state[5:])\n            else:\n                assert False, 'unknown new state %r' % new_state\n        elif isinstance(new_state, combined):\n            # combine a new state from existing ones\n            tmp_state = '_tmp_%d' % cls._tmpname\n            cls._tmpname += 1\n            itokens = []\n            for istate in new_state:\n                assert istate != new_state, 'circular state ref %r' % istate\n                itokens.extend(cls._process_state(unprocessed,\n                                                  processed, istate))\n            processed[tmp_state] = itokens\n            return (tmp_state,)\n        elif isinstance(new_state, tuple):\n            # push more than one state\n            for istate in new_state:\n                assert (istate in unprocessed or\n                        istate in ('#pop', '#push')), \\\n                    'unknown new state ' + istate\n            return new_state\n        else:\n            assert False, 'unknown new state def %r' % new_state", "response": "Preprocess the state transition action of a token definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_tokendef(cls, name, tokendefs=None):\n        processed = cls._all_tokens[name] = {}\n        tokendefs = tokendefs or cls.tokens[name]\n        for state in list(tokendefs):\n            cls._process_state(tokendefs, processed, state)\n        return processed", "response": "Preprocess a dictionary of token definitions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tokendefs(cls):\n        tokens = {}\n        inheritable = {}\n        for c in cls.__mro__:\n            toks = c.__dict__.get('tokens', {})\n\n            for state, items in iteritems(toks):\n                curitems = tokens.get(state)\n                if curitems is None:\n                    # N.b. because this is assigned by reference, sufficiently\n                    # deep hierarchies are processed incrementally (e.g. for\n                    # A(B), B(C), C(RegexLexer), B will be premodified so X(B)\n                    # will not see any inherits in B).\n                    tokens[state] = items\n                    try:\n                        inherit_ndx = items.index(inherit)\n                    except ValueError:\n                        continue\n                    inheritable[state] = inherit_ndx\n                    continue\n\n                inherit_ndx = inheritable.pop(state, None)\n                if inherit_ndx is None:\n                    continue\n\n                # Replace the \"inherit\" value with the items\n                curitems[inherit_ndx:inherit_ndx+1] = items\n                try:\n                    # N.b. this is the index in items (that is, the superclass\n                    # copy), so offset required when storing below.\n                    new_inh_ndx = items.index(inherit)\n                except ValueError:\n                    pass\n                else:\n                    inheritable[state] = inherit_ndx + new_inh_ndx\n\n        return tokens", "response": "Returns a dictionary of all tokendef items for the class cls."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield a list of tokens that are not in the state of the current state.", "response": "def get_tokens_unprocessed(self, text=None, context=None):\n        \"\"\"\n        Split ``text`` into (tokentype, text) pairs.\n        If ``context`` is given, use this lexer context instead.\n        \"\"\"\n        tokendefs = self._tokens\n        if not context:\n            ctx = LexerContext(text, 0)\n            statetokens = tokendefs['root']\n        else:\n            ctx = context\n            statetokens = tokendefs[ctx.stack[-1]]\n            text = ctx.text\n        while 1:\n            for rexmatch, action, new_state in statetokens:\n                m = rexmatch(text, ctx.pos, ctx.end)\n                if m:\n                    if action is not None:\n                        if type(action) is _TokenType:\n                            yield ctx.pos, action, m.group()\n                            ctx.pos = m.end()\n                        else:\n                            for item in action(self, m, ctx):\n                                yield item\n                            if not new_state:\n                                # altered the state stack?\n                                statetokens = tokendefs[ctx.stack[-1]]\n                    # CAUTION: callback must set ctx.pos!\n                    if new_state is not None:\n                        # state transition\n                        if isinstance(new_state, tuple):\n                            for state in new_state:\n                                if state == '#pop':\n                                    ctx.stack.pop()\n                                elif state == '#push':\n                                    ctx.stack.append(ctx.stack[-1])\n                                else:\n                                    ctx.stack.append(state)\n                        elif isinstance(new_state, int):\n                            # pop\n                            del ctx.stack[new_state:]\n                        elif new_state == '#push':\n                            ctx.stack.append(ctx.stack[-1])\n                        else:\n                            assert False, \"wrong state def: %r\" % new_state\n                        statetokens = tokendefs[ctx.stack[-1]]\n                    break\n            else:\n                try:\n                    if ctx.pos >= ctx.end:\n                        break\n                    if text[ctx.pos] == '\\n':\n                        # at EOL, reset state to \"root\"\n                        ctx.stack = ['root']\n                        statetokens = tokendefs['root']\n                        yield ctx.pos, Text, u'\\n'\n                        ctx.pos += 1\n                        continue\n                    yield ctx.pos, Error, text[ctx.pos]\n                    ctx.pos += 1\n                except IndexError:\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef memorized_timedelta(seconds):\n    '''Create only one instance of each distinct timedelta'''\n    try:\n        return _timedelta_cache[seconds]\n    except KeyError:\n        delta = timedelta(seconds=seconds)\n        _timedelta_cache[seconds] = delta\n        return delta", "response": "Create only one instance of each distinct timedelta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate only one instance of each distinct datetime", "response": "def memorized_datetime(seconds):\n    '''Create only one instance of each distinct datetime'''\n    try:\n        return _datetime_cache[seconds]\n    except KeyError:\n        # NB. We can't just do datetime.utcfromtimestamp(seconds) as this\n        # fails with negative values under Windows (Bug #90096)\n        dt = _epoch + timedelta(seconds=seconds)\n        _datetime_cache[seconds] = dt\n        return dt"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates only one instance of each distinct tuple'''", "response": "def memorized_ttinfo(*args):\n    '''Create only one instance of each distinct tuple'''\n    try:\n        return _ttinfo_cache[args]\n    except KeyError:\n        ttinfo = (\n                memorized_timedelta(args[0]),\n                memorized_timedelta(args[1]),\n                args[2]\n                )\n        _ttinfo_cache[args] = ttinfo\n        return ttinfo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unpickler(zone, utcoffset=None, dstoffset=None, tzname=None):\n    # Raises a KeyError if zone no longer exists, which should never happen\n    # and would be a bug.\n    tz = pytz.timezone(zone)\n\n    # A StaticTzInfo - just return it\n    if utcoffset is None:\n        return tz\n\n    # This pickle was created from a DstTzInfo. We need to\n    # determine which of the list of tzinfo instances for this zone\n    # to use in order to restore the state of any datetime instances using\n    # it correctly.\n    utcoffset = memorized_timedelta(utcoffset)\n    dstoffset = memorized_timedelta(dstoffset)\n    try:\n        return tz._tzinfos[(utcoffset, dstoffset, tzname)]\n    except KeyError:\n        # The particular state requested in this timezone no longer exists.\n        # This indicates a corrupt pickle, or the timezone database has been\n        # corrected violently enough to make this particular\n        # (utcoffset,dstoffset) no longer exist in the zone, or the\n        # abbreviation has been changed.\n        pass\n\n    # See if we can find an entry differing only by tzname. Abbreviations\n    # get changed from the initial guess by the database maintainers to\n    # match reality when this information is discovered.\n    for localized_tz in tz._tzinfos.values():\n        if (localized_tz._utcoffset == utcoffset\n                and localized_tz._dst == dstoffset):\n            return localized_tz\n\n    # This (utcoffset, dstoffset) information has been removed from the\n    # zone. Add it back. This might occur when the database maintainers have\n    # corrected incorrect information. datetime instances using this\n    # incorrect information will continue to do so, exactly as they were\n    # before being pickled. This is purely an overly paranoid safety net - I\n    # doubt this will ever been needed in real life.\n    inf = (utcoffset, dstoffset, tzname)\n    tz._tzinfos[inf] = tz.__class__(inf, tz._tzinfos)\n    return tz._tzinfos[inf]", "response": "Returns a pickler for a specific pytz tzinfo instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromutc(self, dt):\n        '''See datetime.tzinfo.fromutc'''\n        if dt.tzinfo is not None and dt.tzinfo is not self:\n            raise ValueError('fromutc: dt.tzinfo is not self')\n        return (dt + self._utcoffset).replace(tzinfo=self)", "response": "See datetime. tzinfo. fromutc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(self, dt):\n        '''Correct the timezone information on the given datetime\n\n        If date arithmetic crosses DST boundaries, the tzinfo\n        is not magically adjusted. This method normalizes the\n        tzinfo to the correct one.\n\n        To test, first we need to do some setup\n\n        >>> from pytz import timezone\n        >>> utc = timezone('UTC')\n        >>> eastern = timezone('US/Eastern')\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n\n        We next create a datetime right on an end-of-DST transition point,\n        the instant when the wallclocks are wound back one hour.\n\n        >>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)\n        >>> loc_dt = utc_dt.astimezone(eastern)\n        >>> loc_dt.strftime(fmt)\n        '2002-10-27 01:00:00 EST (-0500)'\n\n        Now, if we subtract a few minutes from it, note that the timezone\n        information has not changed.\n\n        >>> before = loc_dt - timedelta(minutes=10)\n        >>> before.strftime(fmt)\n        '2002-10-27 00:50:00 EST (-0500)'\n\n        But we can fix that by calling the normalize method\n\n        >>> before = eastern.normalize(before)\n        >>> before.strftime(fmt)\n        '2002-10-27 01:50:00 EDT (-0400)'\n\n        The supported method of converting between timezones is to use\n        datetime.astimezone(). Currently, normalize() also works:\n\n        >>> th = timezone('Asia/Bangkok')\n        >>> am = timezone('Europe/Amsterdam')\n        >>> dt = th.localize(datetime(2011, 5, 7, 1, 2, 3))\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n        >>> am.normalize(dt).strftime(fmt)\n        '2011-05-06 20:02:03 CEST (+0200)'\n        '''\n        if dt.tzinfo is None:\n            raise ValueError('Naive time - no tzinfo set')\n\n        # Convert dt in localtime to UTC\n        offset = dt.tzinfo._utcoffset\n        dt = dt.replace(tzinfo=None)\n        dt = dt - offset\n        # convert it back, and return it\n        return self.fromutc(dt)", "response": "Correct the timezone information on the given datetime and return a new object with the correct timezone information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting naive time to local time.", "response": "def localize(self, dt, is_dst=False):\n        '''Convert naive time to local time.\n\n        This method should be used to construct localtimes, rather\n        than passing a tzinfo argument to a datetime constructor.\n\n        is_dst is used to determine the correct timezone in the ambigous\n        period at the end of daylight saving time.\n\n        >>> from pytz import timezone\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n        >>> amdam = timezone('Europe/Amsterdam')\n        >>> dt  = datetime(2004, 10, 31, 2, 0, 0)\n        >>> loc_dt1 = amdam.localize(dt, is_dst=True)\n        >>> loc_dt2 = amdam.localize(dt, is_dst=False)\n        >>> loc_dt1.strftime(fmt)\n        '2004-10-31 02:00:00 CEST (+0200)'\n        >>> loc_dt2.strftime(fmt)\n        '2004-10-31 02:00:00 CET (+0100)'\n        >>> str(loc_dt2 - loc_dt1)\n        '1:00:00'\n\n        Use is_dst=None to raise an AmbiguousTimeError for ambiguous\n        times at the end of daylight saving time\n\n        >>> try:\n        ...     loc_dt1 = amdam.localize(dt, is_dst=None)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n\n        is_dst defaults to False\n\n        >>> amdam.localize(dt) == amdam.localize(dt, False)\n        True\n\n        is_dst is also used to determine the correct timezone in the\n        wallclock times jumped over at the start of daylight saving time.\n\n        >>> pacific = timezone('US/Pacific')\n        >>> dt = datetime(2008, 3, 9, 2, 0, 0)\n        >>> ploc_dt1 = pacific.localize(dt, is_dst=True)\n        >>> ploc_dt2 = pacific.localize(dt, is_dst=False)\n        >>> ploc_dt1.strftime(fmt)\n        '2008-03-09 02:00:00 PDT (-0700)'\n        >>> ploc_dt2.strftime(fmt)\n        '2008-03-09 02:00:00 PST (-0800)'\n        >>> str(ploc_dt2 - ploc_dt1)\n        '1:00:00'\n\n        Use is_dst=None to raise a NonExistentTimeError for these skipped\n        times.\n\n        >>> try:\n        ...     loc_dt1 = pacific.localize(dt, is_dst=None)\n        ... except NonExistentTimeError:\n        ...     print('Non-existent')\n        Non-existent\n        '''\n        if dt.tzinfo is not None:\n            raise ValueError('Not naive datetime (tzinfo is already set)')\n\n        # Find the two best possibilities.\n        possible_loc_dt = set()\n        for delta in [timedelta(days=-1), timedelta(days=1)]:\n            loc_dt = dt + delta\n            idx = max(0, bisect_right(\n                self._utc_transition_times, loc_dt) - 1)\n            inf = self._transition_info[idx]\n            tzinfo = self._tzinfos[inf]\n            loc_dt = tzinfo.normalize(dt.replace(tzinfo=tzinfo))\n            if loc_dt.replace(tzinfo=None) == dt:\n                possible_loc_dt.add(loc_dt)\n\n        if len(possible_loc_dt) == 1:\n            return possible_loc_dt.pop()\n\n        # If there are no possibly correct timezones, we are attempting\n        # to convert a time that never happened - the time period jumped\n        # during the start-of-DST transition period.\n        if len(possible_loc_dt) == 0:\n            # If we refuse to guess, raise an exception.\n            if is_dst is None:\n                raise NonExistentTimeError(dt)\n\n            # If we are forcing the pre-DST side of the DST transition, we\n            # obtain the correct timezone by winding the clock forward a few\n            # hours.\n            elif is_dst:\n                return self.localize(\n                    dt + timedelta(hours=6), is_dst=True) - timedelta(hours=6)\n\n            # If we are forcing the post-DST side of the DST transition, we\n            # obtain the correct timezone by winding the clock back.\n            else:\n                return self.localize(\n                    dt - timedelta(hours=6), is_dst=False) + timedelta(hours=6)\n\n\n        # If we get this far, we have multiple possible timezones - this\n        # is an ambiguous case occuring during the end-of-DST transition.\n\n        # If told to be strict, raise an exception since we have an\n        # ambiguous case\n        if is_dst is None:\n            raise AmbiguousTimeError(dt)\n\n        # Filter out the possiblilities that don't match the requested\n        # is_dst\n        filtered_possible_loc_dt = [\n            p for p in possible_loc_dt\n                if bool(p.tzinfo._dst) == is_dst\n            ]\n\n        # Hopefully we only have one possibility left. Return it.\n        if len(filtered_possible_loc_dt) == 1:\n            return filtered_possible_loc_dt[0]\n\n        if len(filtered_possible_loc_dt) == 0:\n            filtered_possible_loc_dt = list(possible_loc_dt)\n\n        # If we get this far, we have in a wierd timezone transition\n        # where the clocks have been wound back but is_dst is the same\n        # in both (eg. Europe/Warsaw 1915 when they switched to CET).\n        # At this point, we just have to guess unless we allow more\n        # hints to be passed in (such as the UTC offset or abbreviation),\n        # but that is just getting silly.\n        #\n        # Choose the earliest (by UTC) applicable timezone if is_dst=True\n        # Choose the latest (by UTC) applicable timezone if is_dst=False\n        # i.e., behave like end-of-DST transition\n        dates = {} # utc -> local\n        for local_dt in filtered_possible_loc_dt:\n            utc_time = local_dt.replace(tzinfo=None) - local_dt.tzinfo._utcoffset\n            assert utc_time not in dates\n            dates[utc_time] = local_dt\n        return dates[[min, max][not is_dst](dates)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef utcoffset(self, dt, is_dst=None):\n        '''See datetime.tzinfo.utcoffset\n\n        The is_dst parameter may be used to remove ambiguity during DST\n        transitions.\n\n        >>> from pytz import timezone\n        >>> tz = timezone('America/St_Johns')\n        >>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\n        >>> tz.utcoffset(ambiguous, is_dst=False)\n        datetime.timedelta(-1, 73800)\n\n        >>> tz.utcoffset(ambiguous, is_dst=True)\n        datetime.timedelta(-1, 77400)\n\n        >>> try:\n        ...     tz.utcoffset(ambiguous)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n\n        '''\n        if dt is None:\n            return None\n        elif dt.tzinfo is not self:\n            dt = self.localize(dt, is_dst)\n            return dt.tzinfo._utcoffset\n        else:\n            return self._utcoffset", "response": "See datetime. tzinfo. utcoffset\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsee datetime. tzinfo. dst", "response": "def dst(self, dt, is_dst=None):\n        '''See datetime.tzinfo.dst\n\n        The is_dst parameter may be used to remove ambiguity during DST\n        transitions.\n\n        >>> from pytz import timezone\n        >>> tz = timezone('America/St_Johns')\n\n        >>> normal = datetime(2009, 9, 1)\n\n        >>> tz.dst(normal)\n        datetime.timedelta(0, 3600)\n        >>> tz.dst(normal, is_dst=False)\n        datetime.timedelta(0, 3600)\n        >>> tz.dst(normal, is_dst=True)\n        datetime.timedelta(0, 3600)\n\n        >>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\n        >>> tz.dst(ambiguous, is_dst=False)\n        datetime.timedelta(0)\n        >>> tz.dst(ambiguous, is_dst=True)\n        datetime.timedelta(0, 3600)\n        >>> try:\n        ...     tz.dst(ambiguous)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n\n        '''\n        if dt is None:\n            return None\n        elif dt.tzinfo is not self:\n            dt = self.localize(dt, is_dst)\n            return dt.tzinfo._dst\n        else:\n            return self._dst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsee datetime. tzinfo. tzname", "response": "def tzname(self, dt, is_dst=None):\n        '''See datetime.tzinfo.tzname\n\n        The is_dst parameter may be used to remove ambiguity during DST\n        transitions.\n\n        >>> from pytz import timezone\n        >>> tz = timezone('America/St_Johns')\n\n        >>> normal = datetime(2009, 9, 1)\n\n        >>> tz.tzname(normal)\n        'NDT'\n        >>> tz.tzname(normal, is_dst=False)\n        'NDT'\n        >>> tz.tzname(normal, is_dst=True)\n        'NDT'\n\n        >>> ambiguous = datetime(2009, 10, 31, 23, 30)\n\n        >>> tz.tzname(ambiguous, is_dst=False)\n        'NST'\n        >>> tz.tzname(ambiguous, is_dst=True)\n        'NDT'\n        >>> try:\n        ...     tz.tzname(ambiguous)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n        '''\n        if dt is None:\n            return self.zone\n        elif dt.tzinfo is not self:\n            dt = self.localize(dt, is_dst)\n            return dt.tzinfo._tzname\n        else:\n            return self._tzname"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_in(self, w, mapping):\n        p = bisect(mapping, (w,))\n        if p > 0:\n            if mapping[p-1][0] == w[:len(mapping[p-1][0])] and \\\n               mapping[p-1][1][:len(w)] == w:\n                return True\n        if p < len(mapping):\n            return mapping[p][0] == w[:len(mapping[p][0])] and \\\n                mapping[p][1][:len(w)] == w\n        return False", "response": "r Returns True if the entry w is in the entry mapping False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_range(number, min_r, max_r, name=\"\"):\n    try:\n        number = float(number)\n        if number < min_r or number > max_r:\n            raise FFmpegNormalizeError(\n                \"{} must be within [{},{}]\".format(\n                    name, min_r, max_r\n                )\n            )\n        return number\n        pass\n    except Exception as e:\n        raise e", "response": "Check if a number is within a given range"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_media_file(self, input_file, output_file):\n        if not os.path.exists(input_file):\n            raise FFmpegNormalizeError(\"file \" + input_file + \" does not exist\")\n\n        ext = os.path.splitext(output_file)[1][1:]\n        if (self.audio_codec is None or 'pcm' in self.audio_codec) and ext in PCM_INCOMPATIBLE_EXTS:\n            raise FFmpegNormalizeError(\n                \"Output extension {} does not support PCM audio. Please choose a suitable audio codec with the -c:a option.\".format(ext)\n            )\n\n        mf = MediaFile(self, input_file, output_file)\n        self.media_files.append(mf)\n\n        self.file_count += 1", "response": "Add a media file to the list of media files that can be normalized."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the normalization procedures for all media files in the archive.", "response": "def run_normalization(self):\n        \"\"\"\n        Run the normalization procedures\n        \"\"\"\n        for index, media_file in enumerate(\n                tqdm(\n                    self.media_files,\n                    desc=\"File\",\n                    disable=not self.progress,\n                    position=0\n                )):\n            logger.info(\"Normalizing file {} ({} of {})\".format(media_file, index + 1, self.file_count))\n\n            media_file.run_normalization()\n\n            logger.info(\"Normalized file written to {}\".format(media_file.output_file))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef which(program):\n    def is_exe(fpath):\n        found = os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n        if not found and sys.platform == 'win32':\n            fpath = fpath + \".exe\"\n            found = os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n        return found\n\n    fpath, _ = os.path.split(program)\n    if fpath:\n        if is_exe(program):\n            logger.debug(\"found executable: \" + str(program))\n            return program\n    else:\n        for path in os.environ[\"PATH\"].split(os.pathsep):\n            path = os.path.expandvars(os.path.expanduser(path)).strip('\"')\n            exe_file = os.path.join(path, program)\n            if is_exe(exe_file):\n                logger.debug(\"found executable in path: \" + str(exe_file))\n                return exe_file\n\n    return None", "response": "Find a program in PATH and return path\n attack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn path to ffmpeg executable", "response": "def get_ffmpeg_exe():\n    \"\"\"\n    Return path to ffmpeg executable\n    \"\"\"\n    if 'FFMPEG_PATH' in os.environ:\n        ffmpeg_exe = os.environ['FFMPEG_PATH']\n    else:\n        ffmpeg_exe = which('ffmpeg')\n\n    if not ffmpeg_exe:\n        if which('avconv'):\n            raise FFmpegNormalizeError(\n                \"avconv is not supported. \"\n                \"Please install ffmpeg from http://ffmpeg.org instead.\"\n            )\n        else:\n            raise FFmpegNormalizeError(\n                \"Could not find ffmpeg in your $PATH or $FFMPEG_PATH. \"\n                \"Please install ffmpeg from http://ffmpeg.org\"\n            )\n\n    return ffmpeg_exe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ffmpeg_has_loudnorm():\n    cmd_runner = CommandRunner([get_ffmpeg_exe(), '-filters'])\n    cmd_runner.run_command()\n    output = cmd_runner.get_output()\n    if 'loudnorm' in output:\n        return True\n    else:\n        logger.warning(\n            \"Your ffmpeg version does not support the 'loudnorm' filter. \"\n            \"Please make sure you are running ffmpeg v3.1 or above.\"\n        )\n        return False", "response": "Run feature detection on ffmpeg returns True if ffmpeg supports the loudnorm filter otherwise returns False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns an ffmpeg command and yield the progress in percent.", "response": "def run_ffmpeg_command(self):\n        \"\"\"\n        Run an ffmpeg command, trying to capture the process output and calculate\n        the duration / progress.\n        Yields the progress in percent.\n        \"\"\"\n        logger.debug(\"Running ffmpeg command: {}\".format(self.cmd))\n\n        if self.dry:\n            logger.debug(\"Dry mode specified, not actually running command\")\n            return\n\n        total_dur = None\n\n        stderr = []\n\n        p = subprocess.Popen(\n            self.cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=False\n        )\n\n        # for stderr_line in iter(p.stderr):\n        while True:\n            line = p.stderr.readline().decode(\"utf8\", errors='replace')\n            if line == '' and p.poll() is not None:\n                break\n            stderr.append(line.strip())\n            self.output = \"\\n\".join(stderr)\n\n            if not total_dur and CommandRunner.DUR_REGEX.search(line):\n                total_dur = CommandRunner.DUR_REGEX.search(line).groupdict()\n                total_dur = to_ms(**total_dur)\n                continue\n            if total_dur:\n                result = CommandRunner.TIME_REGEX.search(line)\n                if result:\n                    elapsed_time = to_ms(**result.groupdict())\n                    yield int(elapsed_time / total_dur * 100)\n\n        if p.returncode != 0:\n            raise RuntimeError(\"Error running command {}: {}\".format(self.cmd, str(\"\\n\".join(stderr))))\n\n        yield 100"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_streams(self):\n        logger.debug(\"Parsing streams of {}\".format(self.input_file))\n\n        cmd = [\n            self.ffmpeg_normalize.ffmpeg_exe, '-i', self.input_file,\n            '-c', 'copy', '-t', '0', '-map', '0',\n            '-f', 'null', NUL\n        ]\n\n        cmd_runner = CommandRunner(cmd)\n        cmd_runner.run_command()\n        output = cmd_runner.get_output()\n\n        logger.debug(\"Stream parsing command output:\")\n        logger.debug(output)\n\n        output_lines = [line.strip() for line in output.split('\\n')]\n\n        for line in output_lines:\n\n            if not line.startswith('Stream'):\n                continue\n\n            stream_id_match = re.search(r'#0:([\\d]+)', line)\n            if stream_id_match:\n                stream_id = int(stream_id_match.group(1))\n                if stream_id in self._stream_ids():\n                    continue\n            else:\n                continue\n\n            if 'Audio' in line:\n                logger.debug(\"Found audio stream at index {}\".format(stream_id))\n                sample_rate_match = re.search(r'(\\d+) Hz', line)\n                sample_rate = int(sample_rate_match.group(1)) if sample_rate_match else None\n                bit_depth_match = re.search(r's(\\d+)p?,', line)\n                bit_depth = int(bit_depth_match.group(1)) if bit_depth_match else None\n                self.streams['audio'][stream_id] = AudioStream(self, stream_id, sample_rate, bit_depth)\n\n            elif 'Video' in line:\n                logger.debug(\"Found video stream at index {}\".format(stream_id))\n                self.streams['video'][stream_id] = VideoStream(self, stream_id)\n\n            elif 'Subtitle' in line:\n                logger.debug(\"Found subtitle stream at index {}\".format(stream_id))\n                self.streams['subtitle'][stream_id] = SubtitleStream(self, stream_id)\n\n        if not self.streams['audio']:\n            raise FFmpegNormalizeError(\n                \"Input file {} does not contain any audio streams\"\n                .format(self.input_file))\n\n        if os.path.splitext(self.output_file)[1].lower() in ['.wav', '.mp3', '.aac']:\n            logger.warning(\n                \"Output file only supports one stream. \"\n                \"Keeping only first audio stream.\"\n            )\n            first_stream = list(self.streams['audio'].values())[0]\n            self.streams['audio'] = {first_stream.stream_id: first_stream}\n            self.streams['video'] = {}\n            self.streams['subtitle'] = {}", "response": "Parses all input streams from file and stores them in self. streams."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_audio_filter_cmd(self):\n        all_filters = []\n        output_labels = []\n\n        for audio_stream in self.streams['audio'].values():\n            if self.ffmpeg_normalize.normalization_type == 'ebu':\n                stream_filter = audio_stream.get_second_pass_opts_ebu()\n            else:\n                stream_filter = audio_stream.get_second_pass_opts_peakrms()\n            input_label = '[0:{}]'.format(audio_stream.stream_id)\n            output_label = '[norm{}]'.format(audio_stream.stream_id)\n            output_labels.append(output_label)\n            all_filters.append(input_label + stream_filter + output_label)\n\n        filter_complex_cmd = ';'.join(all_filters)\n\n        return filter_complex_cmd, output_labels", "response": "Return the filter_complex command and output labels needed\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct the second pass command and run it", "response": "def _second_pass(self):\n        \"\"\"\n        Construct the second pass command and run it\n\n        FIXME: make this method simpler\n        \"\"\"\n        logger.info(\"Running second pass for {}\".format(self.input_file))\n\n        # get the target output stream types depending on the options\n        output_stream_types = ['audio']\n        if not self.ffmpeg_normalize.video_disable:\n            output_stream_types.append('video')\n        if not self.ffmpeg_normalize.subtitle_disable:\n            output_stream_types.append('subtitle')\n\n        # get complex filter command\n        audio_filter_cmd, output_labels = self._get_audio_filter_cmd()\n\n        # base command, here we will add all other options\n        cmd = [\n            self.ffmpeg_normalize.ffmpeg_exe, '-y', '-nostdin', '-i', self.input_file,\n            '-filter_complex', audio_filter_cmd\n        ]\n\n        # map metadata, only if needed\n        if self.ffmpeg_normalize.metadata_disable:\n            cmd.extend(['-map_metadata', '-1'])\n        else:\n            # map global metadata\n            cmd.extend(['-map_metadata', '0'])\n            # map per-stream metadata (e.g. language tags)\n            for stream_type in output_stream_types:\n                stream_key = stream_type[0]\n                if stream_type not in self.streams:\n                    continue\n                for idx, _ in enumerate(self.streams[stream_type].items()):\n                    cmd.extend([\n                        '-map_metadata:s:{}:{}'.format(stream_key, idx),\n                        '0:s:{}:{}'.format(stream_key, idx)\n                    ])\n\n        # map chapters if needed\n        if self.ffmpeg_normalize.chapters_disable:\n            cmd.extend(['-map_chapters', '-1'])\n        else:\n            cmd.extend(['-map_chapters', '0'])\n\n        # collect all '-map' and codecs needed for output video based on input video\n        if not self.ffmpeg_normalize.video_disable:\n            for s in self.streams['video'].keys():\n                cmd.extend(['-map', '0:{}'.format(s)])\n            # set codec (copy by default)\n            cmd.extend(['-c:v', self.ffmpeg_normalize.video_codec])\n\n        # ... and map the output of the normalization filters\n        for ol in output_labels:\n            cmd.extend(['-map', ol])\n\n        # set audio codec (never copy)\n        if self.ffmpeg_normalize.audio_codec:\n            cmd.extend(['-c:a', self.ffmpeg_normalize.audio_codec])\n        else:\n            for index, (_, audio_stream) in enumerate(self.streams['audio'].items()):\n                cmd.extend(['-c:a:{}'.format(index), audio_stream.get_pcm_codec()])\n\n        # other audio options (if any)\n        if self.ffmpeg_normalize.audio_bitrate:\n            cmd.extend(['-b:a', str(self.ffmpeg_normalize.audio_bitrate)])\n        if self.ffmpeg_normalize.sample_rate:\n            cmd.extend(['-ar', str(self.ffmpeg_normalize.sample_rate)])\n\n        # ... and subtitles\n        if not self.ffmpeg_normalize.subtitle_disable:\n            for s in self.streams['subtitle'].keys():\n                cmd.extend(['-map', '0:{}'.format(s)])\n            # copy subtitles\n            cmd.extend(['-c:s', 'copy'])\n\n        if self.ffmpeg_normalize.keep_original_audio:\n            highest_index = len(self.streams['audio'])\n            for index, (_, s) in enumerate(self.streams['audio'].items()):\n                cmd.extend(['-map', '0:a:{}'.format(index)])\n                cmd.extend(['-c:a:{}'.format(highest_index + index), 'copy'])\n\n        # extra options (if any)\n        if self.ffmpeg_normalize.extra_output_options:\n            cmd.extend(self.ffmpeg_normalize.extra_output_options)\n\n        # output format (if any)\n        if self.ffmpeg_normalize.output_format:\n            cmd.extend(['-f', self.ffmpeg_normalize.output_format])\n\n        # if dry run, only show sample command\n        if self.ffmpeg_normalize.dry_run:\n            cmd.append(self.output_file)\n            cmd_runner = CommandRunner(cmd, dry=True)\n            cmd_runner.run_command()\n            yield 100\n            return\n\n        # create a temporary output file name\n        temp_dir = tempfile.gettempdir()\n        output_file_suffix = os.path.splitext(self.output_file)[1]\n        temp_file_name = os.path.join(\n            temp_dir,\n            next(tempfile._get_candidate_names()) + output_file_suffix\n        )\n        cmd.append(temp_file_name)\n\n        # run the actual command\n        try:\n            cmd_runner = CommandRunner(cmd)\n            for progress in cmd_runner.run_ffmpeg_command():\n                yield progress\n\n            # move file from TMP to output file\n            logger.debug(\n                \"Moving temporary file from {} to {}\"\n                .format(temp_file_name, self.output_file)\n            )\n            shutil.move(temp_file_name, self.output_file)\n        except Exception as e:\n            logger.error(\"Error while running command {}!\".format(cmd))\n            # remove dangling temporary file\n            if os.path.isfile(temp_file_name):\n                os.remove(temp_file_name)\n            raise e\n\n        logger.debug(\"Normalization finished\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stats(self):\n        stats = {\n            \"input_file\": self.media_file.input_file,\n            \"output_file\": self.media_file.output_file,\n            \"stream_id\": self.stream_id\n        }\n        stats.update(self.loudness_statistics)\n        return stats", "response": "Returns statistics of the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_volumedetect_stats(self):\n        logger.info(\n            \"Running first pass volumedetect filter for stream {}\".format(self.stream_id)\n        )\n\n        filter_str = '[0:{}]volumedetect'.format(self.stream_id)\n\n        cmd = [\n            self.media_file.ffmpeg_normalize.ffmpeg_exe, '-nostdin', '-y',\n            '-i', self.media_file.input_file,\n            '-filter_complex', filter_str,\n            '-vn', '-sn', '-f', 'null', NUL\n        ]\n\n        cmd_runner = CommandRunner(cmd)\n        for progress in cmd_runner.run_ffmpeg_command():\n            yield progress\n        output = cmd_runner.get_output()\n\n        logger.debug(\"Volumedetect command output:\")\n        logger.debug(output)\n\n        mean_volume_matches = re.findall(r\"mean_volume: ([\\-\\d\\.]+) dB\", output)\n        if mean_volume_matches:\n            self.loudness_statistics['mean'] = float(mean_volume_matches[0])\n        else:\n            raise FFmpegNormalizeError(\n                \"Could not get mean volume for {}\".format(self.media_file.input_file)\n            )\n\n        max_volume_matches = re.findall(r\"max_volume: ([\\-\\d\\.]+) dB\", output)\n        if max_volume_matches:\n            self.loudness_statistics['max'] = float(max_volume_matches[0])\n        else:\n            raise FFmpegNormalizeError(\n                \"Could not get max volume for {}\".format(self.media_file.input_file)\n            )", "response": "Parse the volumedetect statistics from ffmpeg and store them in self. loudness_statistics."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_loudnorm_stats(self):\n        logger.info(\n            \"Running first pass loudnorm filter for stream {}\".format(self.stream_id)\n        )\n\n        opts = {\n            'i': self.media_file.ffmpeg_normalize.target_level,\n            'lra': self.media_file.ffmpeg_normalize.loudness_range_target,\n            'tp': self.media_file.ffmpeg_normalize.true_peak,\n            'offset': self.media_file.ffmpeg_normalize.offset,\n            'print_format': 'json'\n        }\n\n        if self.media_file.ffmpeg_normalize.dual_mono:\n            opts['dual_mono'] = 'true'\n\n        filter_str = '[0:{}]'.format(self.stream_id) + \\\n            'loudnorm=' + dict_to_filter_opts(opts)\n\n        cmd = [\n            self.media_file.ffmpeg_normalize.ffmpeg_exe, '-nostdin', '-y',\n            '-i', self.media_file.input_file,\n            '-filter_complex', filter_str,\n            '-vn', '-sn', '-f', 'null', NUL\n        ]\n\n        cmd_runner = CommandRunner(cmd)\n        for progress in cmd_runner.run_ffmpeg_command():\n            yield progress\n        output = cmd_runner.get_output()\n\n        logger.debug(\"Loudnorm first pass command output:\")\n        logger.debug(output)\n\n        output_lines = [line.strip() for line in output.split('\\n')]\n        loudnorm_start = False\n        loudnorm_end = False\n        for index, line in enumerate(output_lines):\n            if line.startswith('[Parsed_loudnorm'):\n                loudnorm_start = index + 1\n                continue\n            if loudnorm_start and line.startswith('}'):\n                loudnorm_end = index + 1\n                break\n\n        if not (loudnorm_start and loudnorm_end):\n            raise FFmpegNormalizeError(\"Could not parse loudnorm stats; no loudnorm-related output found\")\n\n        try:\n            loudnorm_stats = json.loads('\\n'.join(output_lines[loudnorm_start:loudnorm_end]))\n        except Exception as e:\n            raise FFmpegNormalizeError(\"Could not parse loudnorm stats; wrong JSON format in string: {}\".format(e))\n\n        logger.debug(\"Loudnorm stats parsed: {}\".format(json.dumps(loudnorm_stats)))\n\n        self.loudness_statistics['ebu'] = loudnorm_stats\n        for key, val in self.loudness_statistics['ebu'].items():\n            if key == 'normalization_type':\n                continue\n            # FIXME: drop Python 2 support and just use math.inf\n            if float(val) == -float(\"inf\"):\n                self.loudness_statistics['ebu'][key] = -99\n            elif float(val) == float(\"inf\"):\n                self.loudness_statistics['ebu'][key] = 0", "response": "Yields a generator that yields each entry in the output of ffmpeg loudnorm filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn second pass loudnorm filter options string for ffmpeg", "response": "def get_second_pass_opts_ebu(self):\n        \"\"\"\n        Return second pass loudnorm filter options string for ffmpeg\n        \"\"\"\n\n        if not self.loudness_statistics['ebu']:\n            raise FFmpegNormalizeError(\n                \"First pass not run, you must call parse_loudnorm_stats first\"\n            )\n\n        input_i = float(self.loudness_statistics['ebu'][\"input_i\"])\n        if input_i > 0:\n            logger.warn(\"Input file had measured input loudness greater than zero ({}), capping at 0\".format(\"input_i\"))\n            self.loudness_statistics['ebu']['input_i'] = 0\n\n        opts = {\n            'i': self.media_file.ffmpeg_normalize.target_level,\n            'lra': self.media_file.ffmpeg_normalize.loudness_range_target,\n            'tp': self.media_file.ffmpeg_normalize.true_peak,\n            'offset': self.media_file.ffmpeg_normalize.offset,\n            'measured_i': float(self.loudness_statistics['ebu']['input_i']),\n            'measured_lra': float(self.loudness_statistics['ebu']['input_lra']),\n            'measured_tp': float(self.loudness_statistics['ebu']['input_tp']),\n            'measured_thresh': float(self.loudness_statistics['ebu']['input_thresh']),\n            'linear': 'true',\n            'print_format': 'json'\n        }\n\n        if self.media_file.ffmpeg_normalize.dual_mono:\n            opts['dual_mono'] = 'true'\n\n        return 'loudnorm=' + dict_to_filter_opts(opts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the adjustment gain based on chosen option and mean / max volume and return the matching ffmpeg volume filter.", "response": "def get_second_pass_opts_peakrms(self):\n        \"\"\"\n        Set the adjustment gain based on chosen option and mean/max volume,\n        return the matching ffmpeg volume filter.\n        \"\"\"\n        normalization_type = self.media_file.ffmpeg_normalize.normalization_type\n        target_level = self.media_file.ffmpeg_normalize.target_level\n\n        if normalization_type == 'peak':\n            adjustment = 0 + target_level - \\\n                self.loudness_statistics['max']\n        elif normalization_type == 'rms':\n            adjustment = target_level - \\\n                self.loudness_statistics['mean']\n        else:\n            raise FFmpegNormalizeError(\n                \"Can only set adjustment for peak and RMS normalization\"\n            )\n\n        logger.info(\n            \"Adjusting stream {} by {} dB to reach {}\"\n            .format(self.stream_id, adjustment, target_level)\n        )\n\n        if self.loudness_statistics['max'] + adjustment > 0:\n            logger.warning(\n                \"Adjusting will lead to clipping of {} dB\"\n                .format(self.loudness_statistics['max'] + adjustment)\n            )\n\n        return 'volume={}dB'.format(adjustment)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a custom logger with a certain name and level", "response": "def setup_custom_logger(name):\n    \"\"\"\n    Create a logger with a certain name and level\n    \"\"\"\n    global loggers\n\n    if loggers.get(name):\n        return loggers.get(name)\n\n    formatter = logging.Formatter(\n        fmt='%(levelname)s: %(message)s'\n    )\n\n    # handler = logging.StreamHandler()\n    handler = TqdmLoggingHandler()\n    handler.setFormatter(formatter)\n\n    # \\033[1;30m - black\n    # \\033[1;31m - red\n    # \\033[1;32m - green\n    # \\033[1;33m - yellow\n    # \\033[1;34m - blue\n    # \\033[1;35m - magenta\n    # \\033[1;36m - cyan\n    # \\033[1;37m - white\n\n    if system() not in ['Windows', 'cli']:\n        logging.addLevelName(logging.ERROR, \"\\033[1;31m%s\\033[1;0m\" % logging.getLevelName(logging.ERROR))\n        logging.addLevelName(logging.WARNING, \"\\033[1;33m%s\\033[1;0m\" % logging.getLevelName(logging.WARNING))\n        logging.addLevelName(logging.INFO, \"\\033[1;34m%s\\033[1;0m\" % logging.getLevelName(logging.INFO))\n        logging.addLevelName(logging.DEBUG, \"\\033[1;35m%s\\033[1;0m\" % logging.getLevelName(logging.DEBUG))\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.WARNING)\n\n    # if (logger.hasHandlers()):\n    #     logger.handlers.clear()\n    if logger.handlers:\n        logger.handlers = []\n    logger.addHandler(handler)\n    loggers.update(dict(name=logger))\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequires method to auto register this checker.", "response": "def register(linter):\n    \"\"\"Required method to auto register this checker.\"\"\"\n    linter.register_checker(NewDbFieldWithDefaultChecker(linter))\n    if not compat.LOAD_CONFIGURATION_SUPPORTED:\n        load_configuration(linter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride leave_module method to ignore unused - import warnings for related fields.", "response": "def ignore_import_warnings_for_related_fields(orig_method, self, node):\n    \"\"\"\n    Replaces the leave_module method on the VariablesChecker class to\n    prevent unused-import warnings which are caused by the ForeignKey\n    and OneToOneField transformations. By replacing the nodes in the\n    AST with their type rather than the django field, imports of the\n    form 'from django.db.models import OneToOneField' raise an unused-import\n    warning\n    \"\"\"\n    consumer = self._to_consume[0]  # pylint: disable=W0212\n    # we can disable this warning ('Access to a protected member _to_consume of a client class')\n    # as it's not actually a client class, but rather, this method is being monkey patched\n    # onto the class and so the access is valid\n\n    new_things = {}\n\n    iterat = consumer.to_consume.items if PY3 else consumer.to_consume.iteritems\n    for name, stmts in iterat():\n        if isinstance(stmts[0], ImportFrom):\n            if any([n[0] in ('ForeignKey', 'OneToOneField') for n in stmts[0].names]):\n                continue\n        new_things[name] = stmts\n\n    consumer._atomic = ScopeConsumer(new_things, consumer.consumed, consumer.scope_type)  # pylint: disable=W0212\n    self._to_consume = [consumer]  # pylint: disable=W0212\n\n    return orig_method(self, node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef foreign_key_sets(chain, node):\n    quack = False\n\n    if node.attrname in MANAGER_ATTRS or node.attrname.endswith('_set'):\n        # if this is a X_set method, that's a pretty strong signal that this is the default\n        # Django name, rather than one set by related_name\n        quack = True\n    else:\n        # we will\n        if isinstance(node.parent, Attribute):\n            func_name = getattr(node.parent, 'attrname', None)\n            if func_name in MANAGER_ATTRS:\n                quack = True\n\n    if quack:\n        children = list(node.get_children())\n        for child in children:\n            try:\n                inferred_cls = child.inferred()\n            except InferenceError:\n                pass\n            else:\n                for cls in inferred_cls:\n                    if (node_is_subclass(cls,\n                                         'django.db.models.manager.Manager',\n                                         'django.db.models.base.Model',\n                                         '.Model',\n                                         'django.db.models.fields.related.ForeignObject')):\n                        # This means that we are looking at a subclass of models.Model\n                        # and something is trying to access a <something>_set attribute.\n                        # Since this could exist, we will return so as not to raise an\n                        # error.\n                        return\n    chain()", "response": "This function returns a list of all foreign key sets that are related to the given node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that node is derivative of ModelAdmin class.", "response": "def is_model_admin_subclass(node):\n    \"\"\"Checks that node is derivative of ModelAdmin class.\"\"\"\n    if node.name[-5:] != 'Admin' or isinstance(node.parent, ClassDef):\n        return False\n\n    return node_is_subclass(node, 'django.contrib.admin.options.ModelAdmin')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_model_factory(node):\n    try:\n        parent_classes = node.expr.inferred()\n    except:  # noqa: E722, pylint: disable=bare-except\n        return False\n\n    parents = ('factory.declarations.LazyFunction',\n               'factory.declarations.SubFactory',\n               'factory.django.DjangoModelFactory')\n\n    for parent_class in parent_classes:\n        try:\n            if parent_class.qname() in parents:\n                return True\n\n            if node_is_subclass(parent_class, *parents):\n                return True\n        except AttributeError:\n            continue\n\n    return False", "response": "Checks that the given node is derivative of DjangoModelFactory or SubFactory class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_model_mpttmeta_subclass(node):\n    if node.name != 'MPTTMeta' or not isinstance(node.parent, ClassDef):\n        return False\n\n    parents = ('django.db.models.base.Model',\n               '.Model',  # for the transformed version used in this plugin\n               'django.forms.forms.Form',\n               '.Form',\n               'django.forms.models.ModelForm',\n               '.ModelForm')\n    return node_is_subclass(node.parent, *parents)", "response": "Checks that node is derivative of MPTTMeta class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _attribute_is_magic(node, attrs, parents):\n    if node.attrname not in attrs:\n        return False\n    if not node.last_child():\n        return False\n\n    try:\n        for cls in node.last_child().inferred():\n            if isinstance(cls, Super):\n                cls = cls._self_class  # pylint: disable=protected-access\n            if node_is_subclass(cls, *parents) or cls.qname() in parents:\n                return True\n    except InferenceError:\n        pass\n    return False", "response": "Checks that node is an attribute used inside one of allowed parents"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generic_is_view_attribute(parents, attrs):\n    def is_attribute(node):\n        return _attribute_is_magic(node, attrs, parents)\n    return is_attribute", "response": "Generates is_X_attribute function for given parents and attrs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_model_view_subclass_method_shouldnt_be_function(node):\n    if node.name not in ('get', 'post'):\n        return False\n\n    parent = node.parent\n    while parent and not isinstance(parent, ScopedClass):\n        parent = parent.parent\n\n    subclass = ('django.views.View',\n                'django.views.generic.View',\n                'django.views.generic.base.View',)\n\n    return parent is not None and node_is_subclass(parent, *subclass)", "response": "Checks that the node is a get or post method of the View class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naccepting model s fields with get_*_display names.", "response": "def is_model_field_display_method(node):\n    \"\"\"Accept model's fields with get_*_display names.\"\"\"\n    if not node.attrname.endswith('_display'):\n        return False\n    if not node.attrname.startswith('get_'):\n        return False\n\n    if node.last_child():\n        # TODO: could validate the names of the fields on the model rather than\n        # blindly accepting get_*_display\n        try:\n            for cls in node.last_child().inferred():\n                if node_is_subclass(cls, 'django.db.models.base.Model', '.Model'):\n                    return True\n        except InferenceError:\n            return False\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_model_media_valid_attributes(node):\n    if node.name not in ('js', ):\n        return False\n\n    parent = node.parent\n    while parent and not isinstance(parent, ScopedClass):\n        parent = parent.parent\n\n    if parent is None or parent.name != \"Media\":\n        return False\n\n    return True", "response": "Suppress warnings for valid attributes of Media class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsuppress warnings for valid constants in templatetags module.", "response": "def is_templatetags_module_valid_constant(node):\n    \"\"\"Suppress warnings for valid constants in templatetags module.\"\"\"\n    if node.name not in ('register', ):\n        return False\n\n    parent = node.parent\n    while not isinstance(parent, Module):\n        parent = parent.parent\n\n    if \"templatetags.\" not in parent.name:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_urls_module_valid_constant(node):\n    if node.name not in ('urlpatterns', 'app_name'):\n        return False\n\n    parent = node.parent\n    while not isinstance(parent, Module):\n        parent = parent.parent\n\n    if not parent.name.endswith('urls'):\n        return False\n\n    return True", "response": "Suppress warnings for valid constants in urls module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_augmentations(linter):\n    augment_visit(linter, TypeChecker.visit_attribute, foreign_key_sets)\n    augment_visit(linter, TypeChecker.visit_attribute, foreign_key_ids)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_model_field_display_method)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_style_attribute)\n    suppress_message(linter, NameChecker.visit_assignname, 'invalid-name', is_urls_module_valid_constant)\n\n    # supress errors when accessing magical class attributes\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_manager_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_admin_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_model_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_field_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_charfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_datefield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_decimalfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_filefield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_imagefield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_ipfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_slugfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_foreignkeyfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_manytomanyfield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_onetoonefield_attribute)\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_form_attribute)\n\n    for parents, attrs in VIEW_ATTRS:\n        suppress_message(linter, TypeChecker.visit_attribute, 'no-member', generic_is_view_attribute(parents, attrs))\n\n    # formviews have too many ancestors, there's nothing the user of the library can do about that\n    suppress_message(linter, MisdesignChecker.visit_classdef, 'too-many-ancestors',\n                     is_class('django.views.generic.edit.FormView'))\n\n    # model forms have no __init__ method anywhere in their bases\n    suppress_message(linter, ClassChecker.visit_classdef, 'W0232', is_class('django.forms.models.ModelForm'))\n\n    # Meta\n    suppress_message(linter, DocStringChecker.visit_classdef, 'missing-docstring', is_model_meta_subclass)\n    pylint_newstyle_classdef_compat(linter, 'old-style-class', is_model_meta_subclass)\n    suppress_message(linter, ClassChecker.visit_classdef, 'no-init', is_model_meta_subclass)\n    suppress_message(linter, MisdesignChecker.leave_classdef, 'too-few-public-methods', is_model_meta_subclass)\n    suppress_message(linter, ClassChecker.visit_attribute, 'protected-access', allow_meta_protected_access)\n\n    # Media\n    suppress_message(linter, NameChecker.visit_assignname, 'C0103', is_model_media_valid_attributes)\n    suppress_message(linter, DocStringChecker.visit_classdef, 'missing-docstring', is_model_media_subclass)\n    pylint_newstyle_classdef_compat(linter, 'old-style-class', is_model_media_subclass)\n    suppress_message(linter, ClassChecker.visit_classdef, 'no-init', is_model_media_subclass)\n    suppress_message(linter, MisdesignChecker.leave_classdef, 'too-few-public-methods', is_model_media_subclass)\n\n    # Admin\n    # Too many public methods (40+/20)\n    # TODO: Count public methods of django.contrib.admin.options.ModelAdmin and increase\n    # MisdesignChecker.config.max_public_methods to this value to count only user' methods.\n    # nb_public_methods = 0\n    # for method in node.methods():\n    #     if not method.name.startswith('_'):\n    #         nb_public_methods += 1\n    suppress_message(linter, MisdesignChecker.leave_classdef, 'R0904', is_model_admin_subclass)\n\n    # Tests\n    suppress_message(linter, MisdesignChecker.leave_classdef, 'R0904', is_model_test_case_subclass)\n\n    # View\n    # Method could be a function (get, post)\n    suppress_message(linter, ClassChecker.leave_functiondef, 'no-self-use',\n                     is_model_view_subclass_method_shouldnt_be_function)\n    # Unused argument 'request' (get, post)\n    suppress_message(linter, VariablesChecker.leave_functiondef, 'unused-argument',\n                     is_model_view_subclass_unused_argument)\n    suppress_message(linter, VariablesChecker.leave_functiondef, 'unused-argument', is_argument_named_request)\n\n    # django-mptt\n    suppress_message(linter, DocStringChecker.visit_classdef, 'missing-docstring', is_model_mpttmeta_subclass)\n    pylint_newstyle_classdef_compat(linter, 'old-style-class', is_model_mpttmeta_subclass)\n    suppress_message(linter, ClassChecker.visit_classdef, 'W0232', is_model_mpttmeta_subclass)\n    suppress_message(linter, MisdesignChecker.leave_classdef, 'too-few-public-methods', is_model_mpttmeta_subclass)\n\n    # factory_boy's DjangoModelFactory\n    suppress_message(linter, TypeChecker.visit_attribute, 'no-member', is_model_factory)\n    suppress_message(linter, ClassChecker.visit_functiondef, 'no-self-argument', is_factory_post_generation_method)\n\n    # ForeignKey and OneToOneField\n    # Must update this in a thread safe way to support the parallel option on pylint (-j)\n    current_leave_module = VariablesChecker.leave_module\n    if current_leave_module.__name__ == 'leave_module':\n        # current_leave_module is not wrapped\n        # Two threads may hit the next assignment concurrently, but the result is the same\n        VariablesChecker.leave_module = wrap(current_leave_module, ignore_import_warnings_for_related_fields)\n        # VariablesChecker.leave_module is now wrapped\n    # else VariablesChecker.leave_module is already wrapped\n\n    # wsgi.py\n    suppress_message(linter, NameChecker.visit_assignname, 'invalid-name', is_wsgi_application)", "response": "Apply augmentation and suppression rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_configuration(linter):\n    name_checker = get_checker(linter, NameChecker)\n    name_checker.config.good_names += ('qs', 'urlpatterns', 'register', 'app_name', 'handler500')\n\n    # we don't care about South migrations\n    linter.config.black_list += ('migrations', 'south_migrations')", "response": "Load configuration for the linter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def execute(query):\n    if isinstance(query, (peewee.Select, peewee.ModelCompoundSelectQuery)):\n        coroutine = select\n    elif isinstance(query, peewee.Update):\n        coroutine = update\n    elif isinstance(query, peewee.Insert):\n        coroutine = insert\n    elif isinstance(query, peewee.Delete):\n        coroutine = delete\n    else:\n        coroutine = raw_query\n\n    return (await coroutine(query))", "response": "Execute a query asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates object asynchronously. :param model: mode class :param data: data for initializing object :return: new object saved to database", "response": "async def create_object(model, **data):\n    \"\"\"Create object asynchronously.\n\n    :param model: mode class\n    :param data: data for initializing object\n    :return: new object saved to database\n    \"\"\"\n    # NOTE! Here are internals involved:\n    #\n    # - obj._data\n    # - obj._get_pk_value()\n    # - obj._set_pk_value()\n    # - obj._prepare_instance()\n    #\n    warnings.warn(\"create_object() is deprecated, Manager.create() \"\n                  \"should be used instead\",\n                  DeprecationWarning)\n\n    obj = model(**data)\n\n    pk = await insert(model.insert(**dict(obj.__data__)))\n\n    if obj._pk is None:\n        obj._pk = pk\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_object(source, *args):\n    warnings.warn(\"get_object() is deprecated, Manager.get() \"\n                  \"should be used instead\",\n                  DeprecationWarning)\n\n    if isinstance(source, peewee.Query):\n        query = source\n        model = query.model\n    else:\n        query = source.select()\n        model = source\n\n    # Return first object from query\n    for obj in (await select(query.where(*args))):\n        return obj\n\n    # No objects found\n    raise model.DoesNotExist", "response": "Get object from a mode class or query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def delete_object(obj, recursive=False, delete_nullable=False):\n    warnings.warn(\"delete_object() is deprecated, Manager.delete() \"\n                  \"should be used instead\",\n                  DeprecationWarning)\n\n    # Here are private calls involved:\n    # - obj._pk_expr()\n    if recursive:\n        dependencies = obj.dependencies(delete_nullable)\n        for query, fk in reversed(list(dependencies)):\n            model = fk.model\n            if fk.null and not delete_nullable:\n                await update(model.update(**{fk.name: None}).where(query))\n            else:\n                await delete(model.delete().where(query))\n    result = await delete(obj.delete().where(obj._pk_expr()))\n    return result", "response": "Delete an object asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates object asynchronously. :param obj: object to update :param only: list or tuple of fields to updata, is `None` then all fields updated This function does the same as `Model.save()`_ for already saved object, but it doesn't invoke ``save()`` method on model class. That is important to know if you overrided save method for your model. .. _Model.save(): http://peewee.readthedocs.io/en/latest/peewee/ api.html#Model.save", "response": "async def update_object(obj, only=None):\n    \"\"\"Update object asynchronously.\n\n    :param obj: object to update\n    :param only: list or tuple of fields to updata, is `None` then all fields\n        updated\n\n    This function does the same as `Model.save()`_ for already saved object,\n        but it doesn't invoke ``save()`` method on model class. That is\n        important to know if you overrided save method for your model.\n\n    .. _Model.save(): http://peewee.readthedocs.io/en/latest/peewee/\n        api.html#Model.save\n    \"\"\"\n    # Here are private calls involved:\n    #\n    # - obj._data\n    # - obj._meta\n    # - obj._prune_fields()\n    # - obj._pk_expr()\n    # - obj._dirty.clear()\n    #\n    warnings.warn(\"update_object() is deprecated, Manager.update() \"\n                  \"should be used instead\",\n                  DeprecationWarning)\n\n    field_dict = dict(obj.__data__)\n    pk_field = obj._meta.primary_key\n\n    if only:\n        field_dict = obj._prune_fields(field_dict, only)\n\n    if not isinstance(pk_field, peewee.CompositeKey):\n        field_dict.pop(pk_field.name, None)\n    else:\n        field_dict = obj._prune_fields(field_dict, obj.dirty_fields)\n    rows = await update(obj.update(**field_dict).where(obj._pk_expr()))\n\n    obj._dirty.clear()\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform SELECT query asynchronously.", "response": "async def select(query):\n    \"\"\"Perform SELECT query asynchronously.\n    \"\"\"\n    assert isinstance(query, peewee.SelectQuery),\\\n        (\"Error, trying to run select coroutine\"\n         \"with wrong query class %s\" % str(query))\n\n    cursor = await _execute_query_async(query)\n\n    result = AsyncQueryWrapper(cursor=cursor, query=query)\n\n    try:\n        while True:\n            await result.fetchone()\n    except GeneratorExit:\n        pass\n    finally:\n        await cursor.release()\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming INSERT query asynchronously. Returns last insert ID.", "response": "async def insert(query):\n    \"\"\"Perform INSERT query asynchronously. Returns last insert ID.\n    This function is called by object.create for single objects only.\n    \"\"\"\n    assert isinstance(query, peewee.Insert),\\\n        (\"Error, trying to run insert coroutine\"\n         \"with wrong query class %s\" % str(query))\n\n    cursor = await _execute_query_async(query)\n\n    try:\n        if query._returning:\n            row = await cursor.fetchone()\n            result = row[0]\n        else:\n            database = _query_db(query)\n            last_id = await database.last_insert_id_async(cursor)\n            result = last_id\n    finally:\n        await cursor.release()\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms UPDATE query asynchronously. Returns number of rows updated.", "response": "async def update(query):\n    \"\"\"Perform UPDATE query asynchronously. Returns number of rows updated.\n    \"\"\"\n    assert isinstance(query, peewee.Update),\\\n        (\"Error, trying to run update coroutine\"\n         \"with wrong query class %s\" % str(query))\n\n    cursor = await _execute_query_async(query)\n    rowcount = cursor.rowcount\n\n    await cursor.release()\n    return rowcount"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def delete(query):\n    assert isinstance(query, peewee.Delete),\\\n        (\"Error, trying to run delete coroutine\"\n         \"with wrong query class %s\" % str(query))\n\n    cursor = await _execute_query_async(query)\n    rowcount = cursor.rowcount\n\n    await cursor.release()\n    return rowcount", "response": "Perform DELETE query asynchronously. Returns number of rows deleted."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a COUNT query asynchronously.", "response": "async def count(query, clear_limit=False):\n    \"\"\"Perform *COUNT* aggregated query asynchronously.\n\n    :return: number of objects in ``select()`` query\n    \"\"\"\n    clone = query.clone()\n    if query._distinct or query._group_by or query._limit or query._offset:\n        if clear_limit:\n            clone._limit = clone._offset = None\n        sql, params = clone.sql()\n        wrapped = 'SELECT COUNT(1) FROM (%s) AS wrapped_select' % sql\n        raw = query.model.raw(wrapped, *params)\n        return (await scalar(raw)) or 0\n    else:\n        clone._returning = [peewee.fn.Count(peewee.SQL('*'))]\n        clone._order_by = None\n        return (await scalar(clone)) or 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def scalar(query, as_tuple=False):\n    cursor = await _execute_query_async(query)\n\n    try:\n        row = await cursor.fetchone()\n    finally:\n        await cursor.release()\n\n    if row and not as_tuple:\n        return row[0]\n    else:\n        return row", "response": "Get single value from select query i. e. for aggregation.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning SQL operation against database.", "response": "async def _run_sql(database, operation, *args, **kwargs):\n    \"\"\"Run SQL operation (query or command) against database.\n    \"\"\"\n    __log__.debug((operation, args, kwargs))\n\n    with peewee.__exception_wrapper__:\n        cursor = await database.cursor_async()\n\n        try:\n            await cursor.execute(operation, *args, **kwargs)\n        except:\n            await cursor.release()\n            raise\n\n        return cursor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get(self, source_, *args, **kwargs):\n        await self.connect()\n\n        if isinstance(source_, peewee.Query):\n            query = source_\n            model = query.model\n        else:\n            query = source_.select()\n            model = source_\n\n        conditions = list(args) + [(getattr(model, k) == v)\n                                   for k, v in kwargs.items()]\n\n        if conditions:\n            query = query.where(*conditions)\n\n        try:\n            result = await self.execute(query)\n            return list(result)[0]\n        except IndexError:\n            raise model.DoesNotExist", "response": "Get the model instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create(self, model_, **data):\n        inst = model_(**data)\n        query = model_.insert(**dict(inst.__data__))\n\n        pk = await self.execute(query)\n        if inst._pk is None:\n            inst._pk = pk\n        return inst", "response": "Create a new object saved to database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to get an object or create it with the specified defaults.", "response": "async def get_or_create(self, model_, defaults=None, **kwargs):\n        \"\"\"Try to get an object or create it with the specified defaults.\n\n        Return 2-tuple containing the model instance and a boolean\n        indicating whether the instance was created.\n        \"\"\"\n        try:\n            return (await self.get(model_, **kwargs)), False\n        except model_.DoesNotExist:\n            data = defaults or {}\n            data.update({k: v for k, v in kwargs.items() if '__' not in k})\n            return (await self.create(model_, **data)), True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def update(self, obj, only=None):\n        field_dict = dict(obj.__data__)\n        pk_field = obj._meta.primary_key\n\n        if only:\n            self._prune_fields(field_dict, only)\n\n        if obj._meta.only_save_dirty:\n            self._prune_fields(field_dict, obj.dirty_fields)\n\n        if obj._meta.composite_key:\n            for pk_part_name in pk_field.field_names:\n                field_dict.pop(pk_part_name, None)\n        else:\n            field_dict.pop(pk_field.name, None)\n\n        query = obj.update(**field_dict).where(obj._pk_expr())\n        result = await self.execute(query)\n        obj._dirty.clear()\n        return result", "response": "Update the object in the database. Optionally update only\n                     the specified fields. For creating an object use obj. create."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def create_or_get(self, model_, **kwargs):\n        try:\n            return (await self.create(model_, **kwargs)), True\n        except IntegrityErrors:\n            query = []\n            for field_name, value in kwargs.items():\n                field = getattr(model_, field_name)\n                if field.unique or field.primary_key:\n                    query.append(field == value)\n            return (await self.get(model_, *query)), False", "response": "Try to create new object with specified data. If the object already exists then try to get it by unique fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform * COUNT * aggregated query asynchronously.", "response": "async def count(self, query, clear_limit=False):\n        \"\"\"Perform *COUNT* aggregated query asynchronously.\n\n        :return: number of objects in ``select()`` query\n        \"\"\"\n        query = self._swap_database(query)\n        return (await count(query, clear_limit=clear_limit))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets single value from select query i. e. for aggregation.", "response": "async def scalar(self, query, as_tuple=False):\n        \"\"\"Get single value from ``select()`` query, i.e. for aggregation.\n\n        :return: result is the same as after sync ``query.scalar()`` call\n        \"\"\"\n        query = self._swap_database(query)\n        return (await scalar(query, as_tuple=as_tuple))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nswapping database for query if swappable. Return new query if swappable.", "response": "def _swap_database(self, query):\n        \"\"\"Swap database for query if swappable. Return **new query**\n        with swapped database.\n\n        This is experimental feature which allows us to have multiple\n        managers configured against different databases for single model\n        definition.\n\n        The essential limitation though is that database backend have\n        to be **the same type** for model and manager!\n        \"\"\"\n        database = _query_db(query)\n\n        if database == self.database:\n            return query\n\n        if self._subclassed(peewee.PostgresqlDatabase, database,\n                            self.database):\n            can_swap = True\n        elif self._subclassed(peewee.MySQLDatabase, database,\n                              self.database):\n            can_swap = True\n        else:\n            can_swap = False\n\n        if can_swap:\n            # **Experimental** database swapping!\n            query = query.clone()\n            query._database = self.database\n            return query\n\n        assert False, (\n            \"Error, query's database and manager's database are \"\n            \"different. Query: %s Manager: %s\" % (database, self.database)\n        )\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if all classes are subclassed from base.", "response": "def _subclassed(base, *classes):\n        \"\"\"Check if all classes are subclassed from base.\n        \"\"\"\n        return all(map(lambda obj: isinstance(obj, base), classes))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prune_fields(field_dict, only):\n        fields = [(isinstance(f, str) and f or f.name) for f in only]\n        for f in list(field_dict.keys()):\n            if f not in fields:\n                field_dict.pop(f)\n        return field_dict", "response": "Filter fields data in place with only list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget result wrapper class.", "response": "def _get_result_wrapper(self, query):\n        \"\"\"Get result wrapper class.\n        \"\"\"\n        cursor = RowsCursor(self._rows, self._cursor.description)\n        return query._get_cursor_wrapper(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches a single row from the cursor.", "response": "async def fetchone(self):\n        \"\"\"Fetch single row from the cursor.\n        \"\"\"\n        row = await self._cursor.fetchone()\n        if not row:\n            raise GeneratorExit\n        self._rows.append(row)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def connect_async(self, loop=None, timeout=None):\n        if self.deferred:\n            raise Exception(\"Error, database not properly initialized \"\n                            \"before opening connection\")\n\n        if self._async_conn:\n            return\n        elif self._async_wait:\n            await self._async_wait\n        else:\n            self._loop = loop\n            self._async_wait = asyncio.Future(loop=self._loop)\n\n            conn = self._async_conn_cls(\n                database=self.database,\n                loop=self._loop,\n                timeout=timeout,\n                **self.connect_params_async)\n\n            try:\n                await conn.connect()\n            except Exception as e:\n                if not self._async_wait.done():\n                    self._async_wait.set_exception(e)\n                self._async_wait = None\n                raise\n            else:\n                self._task_data = TaskLocals(loop=self._loop)\n                self._async_conn = conn\n                self._async_wait.set_result(True)", "response": "Connect to the database async method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def push_transaction_async(self):\n        await self.connect_async(loop=self.loop)\n        depth = self.transaction_depth_async()\n        if not depth:\n            conn = await self._async_conn.acquire()\n            self._task_data.set('conn', conn)\n        self._task_data.set('depth', depth + 1)", "response": "Increment async transaction depth."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def pop_transaction_async(self):\n        depth = self.transaction_depth_async()\n        if depth > 0:\n            depth -= 1\n            self._task_data.set('depth', depth)\n            if depth == 0:\n                conn = self._task_data.get('conn')\n                self._async_conn.release(conn)\n        else:\n            raise ValueError(\"Invalid async transaction depth value\")", "response": "Decrement async transaction depth."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allow_sync(self):\n        old_allow_sync = self._allow_sync\n        self._allow_sync = True\n\n        try:\n            yield\n        except:\n            raise\n        finally:\n            try:\n                self.close()\n            except self.Error:\n                pass  # already closed\n\n        self._allow_sync = old_allow_sync", "response": "Allow sync queries within context. Close sync\n            connection on exit if connected."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_sql(self, *args, **kwargs):\n        assert self._allow_sync, (\n            \"Error, sync query is not allowed! Call the `.set_allow_sync()` \"\n            \"or use the `.allow_sync()` context manager.\")\n        if self._allow_sync in (logging.ERROR, logging.WARNING):\n            logging.log(self._allow_sync,\n                        \"Error, sync query is not allowed: %s %s\" %\n                        (str(args), str(kwargs)))\n        return super().execute_sql(*args, **kwargs)", "response": "Sync execute SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def connect(self):\n        self.pool = await aiopg.create_pool(\n            loop=self.loop,\n            timeout=self.timeout,\n            database=self.database,\n            **self.connect_params)", "response": "Create connection pool asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def cursor(self, conn=None, *args, **kwargs):\n        in_transaction = conn is not None\n        if not conn:\n            conn = await self.acquire()\n        cursor = await conn.cursor(*args, **kwargs)\n        cursor.release = functools.partial(\n            self.release_cursor, cursor,\n            in_transaction=in_transaction)\n        return cursor", "response": "Get a cursor for the specified transaction connection\n            or acquire from the pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the connection parameters for a given AIOPG. Connection object.", "response": "def connect_params_async(self):\n        \"\"\"Connection parameters for `aiopg.Connection`\n        \"\"\"\n        kwargs = self.connect_params.copy()\n        kwargs.update({\n            'minsize': self.min_connections,\n            'maxsize': self.max_connections,\n            'enable_json': self._enable_json,\n            'enable_hstore': self._enable_hstore,\n        })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def connect(self):\n        self.pool = await aiomysql.create_pool(\n            loop=self.loop,\n            db=self.database,\n            connect_timeout=self.timeout,\n            **self.connect_params)", "response": "Create connection pool asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrelease the cursor coroutine.", "response": "async def release_cursor(self, cursor, in_transaction=False):\n        \"\"\"Release cursor coroutine. Unless in transaction,\n        the connection is also released back to the pool.\n        \"\"\"\n        conn = cursor.connection\n        await cursor.close()\n        if not in_transaction:\n            self.release(conn)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting value stored for current running task. Optionally a value can be provided. Raises KeyError when no value is provided.", "response": "def get(self, key, *val):\n        \"\"\"Get value stored for current running task. Optionally\n        you may provide the default value. Raises `KeyError` when\n        can't get the value and no default one is provided.\n        \"\"\"\n        data = self.get_data()\n        if data is not None:\n            return data.get(key, *val)\n        if val:\n            return val[0]\n        raise KeyError(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of a key in the current running task.", "response": "def set(self, key, val):\n        \"\"\"Set value stored for current running task.\n        \"\"\"\n        data = self.get_data(True)\n        if data is not None:\n            data[key] = val\n        else:\n            raise RuntimeError(\"No task is currently running\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget dict stored for current running task. Return None if no data was found depending on the argument value.", "response": "def get_data(self, create=False):\n        \"\"\"Get dict stored for current running task. Return `None`\n        or an empty dict if no data was found depending on the\n        `create` argument value.\n\n        :param create: if argument is `True`, create empty dict\n                       for task, default: `False`\n        \"\"\"\n        task = asyncio_current_task(loop=self.loop)\n        if task:\n            task_id = id(task)\n            if create and task_id not in self.data:\n                self.data[task_id] = {}\n                task.add_done_callback(self.del_data)\n            return self.data.get(task_id)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _javahome_binary(self):\n        import platform\n        import subprocess\n        from distutils.version import StrictVersion\n\n        current = StrictVersion(platform.mac_ver()[0][:4])\n        if current >= StrictVersion('10.6') and current < StrictVersion('10.9'):\n            if hasattr(subprocess, 'check_output'):\n                java_home = subprocess.check_output(['/usr/libexec/java_home']).strip()\n            else:\n                java_home = subprocess.Popen(['/usr/libexec/java_home'], stdout=subprocess.PIPE).communicate()[0]\n            return java_home", "response": "Returns the path to the Java home binary for the current version of the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the path to the default Java installation stored in the Windows registry.", "response": "def _get_from_registry(self):\n        \"\"\"\n        Retrieves the path to the default Java installation stored in the\n        Windows registry\n\n        :return: The path found in the registry, or None\n        \"\"\"\n        # Winreg is an optional package in cygwin\n        winreg = self._get_winreg()\n        if not winreg:\n            return None\n        for location in reg_keys:\n            try:\n                jreKey = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, location)\n                cv = winreg.QueryValueEx(jreKey, \"CurrentVersion\")\n                versionKey = winreg.OpenKey(jreKey, cv[0])\n                winreg.CloseKey(jreKey)\n\n                cv = winreg.QueryValueEx(versionKey, \"RuntimeLib\")\n                winreg.CloseKey(versionKey)\n\n                return cv[0]\n            except WindowsError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_from_bin(self):\n        # Find the real interpreter installation path\n        java_bin = os.path.realpath(self._java)\n        if os.path.exists(java_bin):\n            # Get to the home directory\n            java_home = os.path.abspath(os.path.join(os.path.dirname(java_bin),\n                                                     '..'))\n\n            # Look for the JVM library\n            return self.find_libjvm(java_home)", "response": "Returns the path to the Java library if it exists else None."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _JModule(spec, javaname):\n    cls = _JImportFactory(spec, javaname)\n    out = cls(spec.name)\n    return out", "response": "Internal method to create a Java module dynamically."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract pairs of corresponding property access methods from a Java class s members.", "response": "def _extract_accessor_pairs(members):\n    \"\"\"Extract pairs of corresponding property access methods\n    (getter and setter) from a Java class's members (attributes).\n\n    If a public method with a property's name exists no pair for\n    that property will be extracted.\n\n    Returns a dictionary with the property name as key and a tuple\n    of (getter method, setter method) as value. A tuple element\n    value might be `None` if only a getter or only a setter\n    exists.\n    \"\"\"\n    accessor_pairs = {}\n\n    for name, member in members.items():\n        if not (len(name) > _PROPERTY_ACCESSOR_PREFIX_LEN \\\n                        and _is_java_method(member)):\n            continue\n        access, rest = ( name[:_PROPERTY_ACCESSOR_PREFIX_LEN],\n                         name[_PROPERTY_ACCESSOR_PREFIX_LEN:] )\n        property_name = rest[:1].lower() + rest[1:]\n        if property_name in members:\n            if _is_java_method(members[property_name]):\n                continue\n        if access == 'get' and member.isBeanAccessor():\n            try:\n                pair = accessor_pairs[property_name]\n                pair[0] = member\n            except KeyError:\n                accessor_pairs[property_name] = [member, None]\n        elif access == 'set' and member.isBeanMutator():\n            try:\n                pair = accessor_pairs[property_name]\n                pair[1] = member\n            except KeyError:\n                accessor_pairs[property_name] = [None, member]\n    return accessor_pairs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nomitting - Wstrict - prototypes from CFLAGS since its only valid for C code.", "response": "def initialize_options(self, *args):\n        \"\"\"omit -Wstrict-prototypes from CFLAGS since its only valid for C code.\"\"\"\n        import distutils.sysconfig\n        cfg_vars = distutils.sysconfig.get_config_vars()\n#        if 'CFLAGS' in cfg_vars:\n#            cfg_vars['CFLAGS'] = cfg_vars['CFLAGS'].replace('-Wstrict-prototypes', '')\n        for k,v in cfg_vars.items():\n            if isinstance(v,str) and v.find(\"-Wstrict-prototypes\"):\n                v=v.replace('-Wstrict-prototypes', '')\n                cfg_vars[k]=v\n                \n            if isinstance(v,str) and v.find(\"-Wimplicit-function-declaration\"):\n                v=v.replace('-Wimplicit-function-declaration', '')\n                cfg_vars[k]=v \n        build_ext.initialize_options(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the path to the default Java installation stored in the Windows registry or None if the path is not found in the Windows registry.", "response": "def _get_from_registry(self):\n        \"\"\"\n        Retrieves the path to the default Java installation stored in the\n        Windows registry\n\n        :return: The path found in the registry, or None\n        \"\"\"\n        from ._windows import reg_keys\n        for location in reg_keys:\n            location = location.replace('\\\\', '/')\n            jreKey = \"/proc/registry/HKEY_LOCAL_MACHINE/{}\".format(location)\n            try:\n                with open(jreKey + \"/CurrentVersion\") as f:\n                    cv = f.read().split('\\x00')\n                versionKey = jreKey + \"/\" + cv[0]\n\n                with open(versionKey + \"/RunTimeLib\") as f:\n                    cv = f.read().split('\\x00')\n\n                return cv[0]\n\n            except OSError:\n                pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a path to the java class path", "response": "def addClassPath(path1):\n    \"\"\" Add a path to the java class path\"\"\"\n    global _CLASSPATHS\n    path1=_os.path.abspath(path1)\n    if _sys.platform=='cygwin':\n        path1=_posix2win(path1)\n    _CLASSPATHS.add(str(path1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the full java class path.", "response": "def getClassPath():\n    \"\"\" Get the full java class path.\n\n    Includes user added paths and the environment CLASSPATH.\n    \"\"\"\n    global _CLASSPATHS\n    global _SEP\n    out=[]\n    for path in _CLASSPATHS:\n        if path=='':\n            continue\n        if path.endswith('*'):\n            paths=_glob.glob(path+\".jar\")\n            if len(path)==0:\n                continue \n            out.extend(paths)\n        else:\n            out.append(path)\n    return _SEP.join(out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a Java Virtual Machine.", "response": "def startJVM(jvm=None, *args, **kwargs):\n    \"\"\"\n    Starts a Java Virtual Machine.  Without options it will start\n    the JVM with the default classpath and jvm.  The default classpath\n    will be determined by jpype.getClassPath().  The default JVM is \n    determined by jpype.getDefaultJVMPath().\n\n    Args:\n      jvm (str):  Path to the jvm library file (libjvm.so, jvm.dll, ...)\n        default=None will use jpype.getDefaultJVMPath()\n      *args (str[]): Arguments to give to the JVM\n      classpath (Optional[string]): set the classpath for the jvm.\n        This will override any classpath supplied in the arguments\n        list.\n      ignoreUnrecognized (Optional[bool]): option to jvm to ignore\n        invalid jvm arguments.  (Default False)\n    \"\"\"\n    if jvm is None:\n        jvm = get_default_jvm_path()\n\n        # Check to see that the user has not set the classpath\n        # Otherwise use the default if not specified\n        if not _hasClassPath(args) and 'classpath' not in kwargs:\n           kwargs['classpath']=_classpath.getClassPath()\n           print(\"Use default classpath\")\n\n    if 'ignoreUnrecognized' not in kwargs:\n        kwargs['ignoreUnrecognized']=False\n\n    # Classpath handling\n    args = list(args)\n    if 'classpath' in kwargs and kwargs['classpath']!=None:\n        args.append('-Djava.class.path=%s'%(kwargs['classpath']))\n        print(\"Set classpath\")\n\n    _jpype.startup(jvm, tuple(args), kwargs['ignoreUnrecognized'])\n    _initialize()\n\n    # start the reference daemon thread\n    if _usePythonThreadForDaemon:\n        _refdaemon.startPython()\n    else:\n        _refdaemon.startJava()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_default_jvm_path():\n    if sys.platform == \"cygwin\":\n        # Cygwin\n        from ._cygwin import WindowsJVMFinder\n        finder = WindowsJVMFinder()\n    elif sys.platform == \"win32\":\n        # Windows\n        from ._windows import WindowsJVMFinder\n        finder = WindowsJVMFinder()\n    elif sys.platform == \"darwin\":\n        # Mac OS X\n        from ._darwin import DarwinJVMFinder\n        finder = DarwinJVMFinder()\n    else:\n        # Use the Linux way for other systems\n        from ._linux import LinuxJVMFinder\n        finder = LinuxJVMFinder()\n\n    return finder.get_jvm_path()", "response": "Retrieves the path to the default JVM shared library file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_libjvm(self, java_home):\n        found_jamvm = False\n        non_supported_jvm = ('cacao', 'jamvm')\n        found_non_supported_jvm = False\n\n        # Look for the file\n        for root, _, names in os.walk(java_home):\n            if self._libfile in names:\n                # Found it, but check for non supported jvms\n                candidate = os.path.split(root)[1]\n                if candidate in non_supported_jvm:\n                    found_non_supported_jvm = True\n                    continue # maybe we will find another one?\n                return os.path.join(root, self._libfile)\n\n        else:\n            if found_non_supported_jvm:\n                raise JVMNotSupportedException(\"Sorry '{0}' is known to be \"\n                                               \"broken. Please ensure your \"\n                                               \"JAVA_HOME contains at least \"\n                                               \"another JVM implementation \"\n                                               \"(eg. server)\"\n                                               .format(candidate))\n            # File not found\n            raise JVMNotFoundException(\"Sorry no JVM could be found. \"\n                                       \"Please ensure your JAVA_HOME \"\n                                       \"environment variable is pointing \"\n                                       \"to correct installation.\")", "response": "Recursively looks for the given file in the given Java home folder and returns the first found file path or None if no such file is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the path to the JVM shared library file.", "response": "def get_jvm_path(self):\n        \"\"\"\n        Retrieves the path to the default or first found JVM library\n\n        :return: The path to the JVM shared library file\n        :raise ValueError: No JVM library found\n        \"\"\"\n        for method in self._methods:\n            try:\n                jvm = method()\n\n                # If found check the architecture \n                if jvm:\n                    self.check(jvm)\n            except NotImplementedError:\n                # Ignore missing implementations\n                pass\n            except JVMNotFoundException:\n                # Ignore not successful methods\n                pass\n            except JVMNotSupportedException:\n                pass\n\n            else:\n                if jvm is not None:\n                    return jvm\n\n        else:\n            raise JVMNotFoundException(\"No JVM shared library file ({0}) \"\n                                       \"found. Try setting up the JAVA_HOME \"\n                                       \"environment variable properly.\"\n                                       .format(self._libfile))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_from_java_home(self):\n        # Get the environment variable\n        java_home = os.getenv(\"JAVA_HOME\")\n        if java_home and os.path.exists(java_home):\n            # Get the real installation path\n            java_home = os.path.realpath(java_home)\n\n            # Cygwin has a bug in realpath\n            if not os.path.exists(java_home):\n                java_home = os.getenv(\"JAVA_HOME\")\n\n            # Look for the library file\n            return self.find_libjvm(java_home)", "response": "Retrieves the Java library path according to the JAVA_HOME environment variable\n        Returns None if no Java library is found."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the first existing Java library path in the predefined known locations or None if no such path exists.", "response": "def _get_from_known_locations(self):\n        \"\"\"\n        Retrieves the first existing Java library path in the predefined known\n        locations\n\n        :return: The path to the JVM library, or None\n        \"\"\"\n        for home in self.find_possible_homes(self._locations):\n            jvm = self.find_libjvm(home)\n            if jvm is not None:\n                return jvm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef node_query(self, node):\n\n        if isinstance(node, ast.Call):\n            assert node.args\n            arg = node.args[0]\n            if not isinstance(arg, ast.Str):\n                return\n        else:\n            raise TypeError(type(node))\n\n        return arg.s", "response": "Return the query for the gql call node\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alias(thumbnailer, thumbnail_options, source_filename,\n            thumbnail_extension, **kwargs):\n    \"\"\"\n    Generate filename based on thumbnail alias name (option ``THUMBNAIL_ALIASES``).\n\n    For example: ``source.jpg.medium_large.jpg``\n    \"\"\"\n    return '.'.join([source_filename, thumbnail_options.get('ALIAS', ''), thumbnail_extension])", "response": "Generate filename based on alias name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a short hashed thumbnail filename.", "response": "def hashed(source_filename, prepared_options, thumbnail_extension, **kwargs):\n    \"\"\"\n    Generate a short hashed thumbnail filename.\n\n    Creates a 12 character url-safe base64 sha1 filename (plus the extension),\n    for example: ``6qW1buHgLaZ9.jpg``.\n    \"\"\"\n    parts = ':'.join([source_filename] + prepared_options)\n    short_sha = hashlib.sha1(parts.encode('utf-8')).digest()\n    short_hash = base64.urlsafe_b64encode(short_sha[:9]).decode('utf-8')\n    return '.'.join([short_hash, thumbnail_extension])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef source_hashed(source_filename, prepared_options, thumbnail_extension,\n                  **kwargs):\n    \"\"\"\n    Generate a thumbnail filename of the source filename and options separately\n    hashed, along with the size.\n\n    The format of the filename is a 12 character base64 sha1 hash of the source\n    filename, the size surrounded by underscores, and an 8 character options\n    base64 sha1 hash of the thumbnail options. For example:\n    ``1xedFtqllFo9_100x100_QHCa6G1l.jpg``.\n    \"\"\"\n    source_sha = hashlib.sha1(source_filename.encode('utf-8')).digest()\n    source_hash = base64.urlsafe_b64encode(source_sha[:9]).decode('utf-8')\n    parts = ':'.join(prepared_options[1:])\n    parts_sha = hashlib.sha1(parts.encode('utf-8')).digest()\n    options_hash = base64.urlsafe_b64encode(parts_sha[:6]).decode('utf-8')\n    return '%s_%s_%s.%s' % (\n        source_hash, prepared_options[0], options_hash, thumbnail_extension)", "response": "Generates a thumbnail filename of the source filename and options separately with the size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_image(source, processor_options, processors=None):\n    processor_options = ThumbnailOptions(processor_options)\n    if processors is None:\n        processors = [\n            utils.dynamic_import(name)\n            for name in settings.THUMBNAIL_PROCESSORS]\n    image = source\n    for processor in processors:\n        image = processor(image, **processor_options)\n    return image", "response": "Process a PIL image through a series of image processors returning\n    the potentialentially altered image."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves an image to a file.", "response": "def save_image(image, destination=None, filename=None, **options):\n    \"\"\"\n    Save a PIL image.\n    \"\"\"\n    if destination is None:\n        destination = BytesIO()\n    filename = filename or ''\n    # Ensure plugins are fully loaded so that Image.EXTENSION is populated.\n    Image.init()\n    format = Image.EXTENSION.get(os.path.splitext(filename)[1].lower(), 'JPEG')\n    if format in ('JPEG', 'WEBP'):\n        options.setdefault('quality', 85)\n    saved = False\n    if format == 'JPEG':\n        if image.mode.endswith('A'):\n            # From PIL 4.2, saving an image with a transparency layer raises an\n            # IOError, so explicitly remove it.\n            image = image.convert(image.mode[:-1])\n        if settings.THUMBNAIL_PROGRESSIVE and (\n                max(image.size) >= settings.THUMBNAIL_PROGRESSIVE):\n            options['progressive'] = True\n        try:\n            image.save(destination, format=format, optimize=1, **options)\n            saved = True\n        except IOError:\n            # Try again, without optimization (PIL can't optimize an image\n            # larger than ImageFile.MAXBLOCK, which is 64k by default). This\n            # shouldn't be triggered very often these days, as recent versions\n            # of pillow avoid the MAXBLOCK limitation.\n            pass\n    if not saved:\n        image.save(destination, format=format, **options)\n    if hasattr(destination, 'seek'):\n        destination.seek(0)\n    return destination"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating an image from a source file.", "response": "def generate_source_image(source_file, processor_options, generators=None,\n                          fail_silently=True):\n    \"\"\"\n    Processes a source ``File`` through a series of source generators, stopping\n    once a generator returns an image.\n\n    The return value is this image instance or ``None`` if no generators\n    return an image.\n\n    If the source file cannot be opened, it will be set to ``None`` and still\n    passed to the generators.\n    \"\"\"\n    processor_options = ThumbnailOptions(processor_options)\n    # Keep record of whether the source file was originally closed. Not all\n    # file-like objects provide this attribute, so just fall back to False.\n    was_closed = getattr(source_file, 'closed', False)\n    if generators is None:\n        generators = [\n            utils.dynamic_import(name)\n            for name in settings.THUMBNAIL_SOURCE_GENERATORS]\n    exceptions = []\n    try:\n        for generator in generators:\n            source = source_file\n            # First try to open the file.\n            try:\n                source.open()\n            except Exception:\n                # If that failed, maybe the file-like object doesn't support\n                # reopening so just try seeking back to the start of the file.\n                try:\n                    source.seek(0)\n                except Exception:\n                    source = None\n            try:\n                image = generator(source, **processor_options)\n            except Exception as e:\n                if not fail_silently:\n                    if len(generators) == 1:\n                        raise\n                    exceptions.append(e)\n                image = None\n            if image:\n                return image\n    finally:\n        # Attempt to close the file if it was closed originally (but fail\n        # silently).\n        if was_closed:\n            try:\n                source_file.close()\n            except Exception:\n                pass\n    if exceptions and not fail_silently:\n        raise NoSourceGenerator(*exceptions)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef revert(self):\n        for attr, value in self._changed.items():\n            setattr(django_settings, attr, value)\n        for attr in self._added:\n            delattr(django_settings, attr)\n        self._changed = {}\n        self._added = []\n        if self.isolated:\n            self._isolated_overrides = BaseSettings()", "response": "Revert any changes made to settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pil_image(source, exif_orientation=True, **options):\n    # Use a BytesIO wrapper because if the source is an incomplete file like\n    # object, PIL may have problems with it. For example, some image types\n    # require tell and seek methods that are not present on all storage\n    # File objects.\n    if not source:\n        return\n    source = BytesIO(source.read())\n\n    image = Image.open(source)\n    # Fully load the image now to catch any problems with the image contents.\n    try:\n        # An \"Image file truncated\" exception can occur for some images that\n        # are still mostly valid -- we'll swallow the exception.\n        image.load()\n    except IOError:\n        pass\n    # Try a second time to catch any other potential exceptions.\n    image.load()\n\n    if exif_orientation:\n        image = utils.exif_orientation(image)\n    return image", "response": "Open the source file using PIL and return the image object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef optimize_thumbnail(thumbnail):\n    '''Optimize thumbnail images by removing unnecessary data'''\n    try:\n        optimize_command = settings.THUMBNAIL_OPTIMIZE_COMMAND[\n            determinetype(thumbnail.path)]\n        if not optimize_command:\n            return\n    except (TypeError, KeyError, NotImplementedError):\n        return\n    storage = thumbnail.storage\n    try:\n        with NamedTemporaryFile() as temp_file:\n            thumbnail.seek(0)\n            temp_file.write(thumbnail.read())\n            temp_file.flush()\n            optimize_command = optimize_command.format(filename=temp_file.name)\n            output = check_output(\n                optimize_command, stderr=subprocess.STDOUT, shell=True)\n            if output:\n                logger.warning(\n                    '{0} returned {1}'.format(optimize_command, output))\n            else:\n                logger.info('{0} returned nothing'.format(optimize_command))\n            with open(temp_file.name, 'rb') as f:\n                thumbnail.file = ContentFile(f.read())\n                storage.delete(thumbnail.path)\n                storage.save(thumbnail.path, thumbnail)\n    except Exception as e:\n        logger.error(e)", "response": "Optimize thumbnail images by removing unnecessary data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_args(args):\n    args_dict = {}\n    for arg in args:\n        split_arg = arg.split('=', 1)\n        if len(split_arg) > 1:\n            value = split_arg[1]\n        else:\n            value = True\n        args_dict[split_arg[0]] = value\n    return args_dict", "response": "Split a list of argument strings into a dictionary where each key is an argument name and each value is a value of True."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef thumbnail(parser, token):\n    args = token.split_contents()\n    tag = args[0]\n\n    # Check to see if we're setting to a context variable.\n    if len(args) > 4 and args[-2] == 'as':\n        context_name = args[-1]\n        args = args[:-2]\n    else:\n        context_name = None\n\n    if len(args) < 3:\n        raise TemplateSyntaxError(\n            \"Invalid syntax. Expected \"\n            \"'{%% %s source size [option1 option2 ...] %%}' or \"\n            \"'{%% %s source size [option1 option2 ...] as variable %%}'\" %\n            (tag, tag))\n\n    opts = {}\n\n    # The first argument is the source file.\n    source_var = parser.compile_filter(args[1])\n\n    # The second argument is the requested size. If it's the static \"10x10\"\n    # format, wrap it in quotes so that it is compiled correctly.\n    size = args[2]\n    match = RE_SIZE.match(size)\n    if match:\n        size = '\"%s\"' % size\n    opts['size'] = parser.compile_filter(size)\n\n    # All further arguments are options.\n    args_list = split_args(args[3:]).items()\n    for arg, value in args_list:\n        if arg in VALID_OPTIONS:\n            if value and value is not True:\n                value = parser.compile_filter(value)\n            opts[arg] = value\n        else:\n            raise TemplateSyntaxError(\"'%s' tag received a bad argument: \"\n                                      \"'%s'\" % (tag, arg))\n    return ThumbnailNode(source_var, opts=opts, context_name=context_name)", "response": "This tag creates a thumbnail of an ImageField."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the thumbnail url for a source file using an aliased set of thumbnail options.", "response": "def thumbnail_url(source, alias):\n    \"\"\"\n    Return the thumbnail url for a source file using an aliased set of\n    thumbnail options.\n\n    If no matching alias is found, returns an empty string.\n\n    Example usage::\n\n        <img src=\"{{ person.photo|thumbnail_url:'small' }}\" alt=\"\">\n    \"\"\"\n    try:\n        thumb = get_thumbnailer(source)[alias]\n    except Exception:\n        return ''\n    return thumb.url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the contents of one or more files to a single concatenated string.", "response": "def read_files(*filenames):\n    \"\"\"\n    Output the contents of one or more files to a single concatenated string.\n    \"\"\"\n    output = []\n    for filename in filenames:\n        f = codecs.open(filename, encoding='utf-8')\n        try:\n            output.append(f.read())\n        finally:\n            f.close()\n    return '\\n\\n'.join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_thumbnails(path, recursive=True, prefix=None, subdir=None):\n    if prefix is None:\n        prefix = settings.THUMBNAIL_PREFIX\n    if subdir is None:\n        subdir = settings.THUMBNAIL_SUBDIR\n    thumbnail_files = {}\n    if not path.endswith('/'):\n        path = '%s/' % path\n    len_path = len(path)\n    if recursive:\n        all = os.walk(path)\n    else:\n        files = []\n        for file in os.listdir(path):\n            if os.path.isfile(os.path.join(path, file)):\n                files.append(file)\n        all = [(path, [], files)]\n    for dir_, subdirs, files in all:\n        rel_dir = dir_[len_path:]\n        for file in files:\n            thumb = re_thumbnail_file.match(file)\n            if not thumb:\n                continue\n            d = thumb.groupdict()\n            source_filename = d.pop('source_filename')\n            if prefix:\n                source_path, source_filename = os.path.split(source_filename)\n                if not source_filename.startswith(prefix):\n                    continue\n                source_filename = os.path.join(\n                    source_path, source_filename[len(prefix):])\n            d['options'] = d['options'] and d['options'].split('_') or []\n            if subdir and rel_dir.endswith(subdir):\n                rel_dir = rel_dir[:-len(subdir)]\n            # Corner-case bug: if the filename didn't have an extension but did\n            # have an underscore, the last underscore will get converted to a\n            # '.'.\n            m = re.match(r'(.*)_(.*)', source_filename)\n            if m:\n                source_filename = '%s.%s' % m.groups()\n            filename = os.path.join(rel_dir, source_filename)\n            thumbnail_file = thumbnail_files.setdefault(filename, [])\n            d['filename'] = os.path.join(dir_, file)\n            thumbnail_file.append(d)\n    return thumbnail_files", "response": "Return a dictionary referencing all files which match the thumbnail format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of dictionaries one for each thumbnail belonging to the source image.", "response": "def thumbnails_for_file(relative_source_path, root=None, basedir=None,\n                        subdir=None, prefix=None):\n    \"\"\"\n    Return a list of dictionaries, one for each thumbnail belonging to the\n    source image.\n\n    The following list explains each key of the dictionary:\n\n      `filename`  -- absolute thumbnail path\n      `x` and `y` -- the size of the thumbnail\n      `options`   -- list of options for this thumbnail\n      `quality`   -- quality setting for this thumbnail\n    \"\"\"\n    if root is None:\n        root = settings.MEDIA_ROOT\n    if prefix is None:\n        prefix = settings.THUMBNAIL_PREFIX\n    if subdir is None:\n        subdir = settings.THUMBNAIL_SUBDIR\n    if basedir is None:\n        basedir = settings.THUMBNAIL_BASEDIR\n    source_dir, filename = os.path.split(relative_source_path)\n    thumbs_path = os.path.join(root, basedir, source_dir, subdir)\n    if not os.path.isdir(thumbs_path):\n        return []\n    files = all_thumbnails(thumbs_path, recursive=False, prefix=prefix,\n                           subdir='')\n    return files.get(filename, [])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes all thumbnails for a source image.", "response": "def delete_thumbnails(relative_source_path, root=None, basedir=None,\n                      subdir=None, prefix=None):\n    \"\"\"\n    Delete all thumbnails for a source image.\n    \"\"\"\n    thumbs = thumbnails_for_file(relative_source_path, root, basedir, subdir,\n                                 prefix)\n    return _delete_using_thumbs_list(thumbs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_all_thumbnails(path, recursive=True):\n    total = 0\n    for thumbs in all_thumbnails(path, recursive=recursive).values():\n        total += _delete_using_thumbs_list(thumbs)\n    return total", "response": "Delete all thumbnails in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds uncommitted FileFields for this object.", "response": "def find_uncommitted_filefields(sender, instance, **kwargs):\n    \"\"\"\n    A pre_save signal handler which attaches an attribute to the model instance\n    containing all uncommitted ``FileField``s, which can then be used by the\n    :func:`signal_committed_filefields` post_save handler.\n    \"\"\"\n    uncommitted = instance._uncommitted_filefields = []\n\n    fields = sender._meta.fields\n    if kwargs.get('update_fields', None):\n        update_fields = set(kwargs['update_fields'])\n        fields = update_fields.intersection(fields)\n    for field in fields:\n        if isinstance(field, FileField):\n            fieldfile = getattr(instance, field.name)\n            if fieldfile and not fieldfile._committed:\n                uncommitted.append(field.name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signal_committed_filefields(sender, instance, **kwargs):\n    for field_name in getattr(instance, '_uncommitted_filefields', ()):\n        fieldfile = getattr(instance, field_name)\n        # Don't send the signal for deleted files.\n        if fieldfile:\n            signals.saved_file.send_robust(sender=sender, fieldfile=fieldfile)", "response": "A signal handler which sends a signal for each FileField that was committed this save."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_aliases(fieldfile, **kwargs):\n    # Avoids circular import.\n    from easy_thumbnails.files import generate_all_aliases\n    generate_all_aliases(fieldfile, include_global=False)", "response": "A signal handler which generates thumbnails for all fieldfile and app specific aliases matching the saved file s field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _compare_entropy(start_slice, end_slice, slice, difference):\n    start_entropy = utils.image_entropy(start_slice)\n    end_entropy = utils.image_entropy(end_slice)\n    if end_entropy and abs(start_entropy / end_entropy - 1) < 0.01:\n        # Less than 1% difference, remove from both sides.\n        if difference >= slice * 2:\n            return slice, slice\n        half_slice = slice // 2\n        return half_slice, slice - half_slice\n    if start_entropy > end_entropy:\n        return 0, slice\n    else:\n        return slice, 0", "response": "Calculate the entropy of two slices and compare them to the image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef colorspace(im, bw=False, replace_alpha=False, **kwargs):\n    if im.mode == 'I':\n        # PIL (and pillow) have can't convert 16 bit grayscale images to lower\n        # modes, so manually convert them to an 8 bit grayscale.\n        im = im.point(list(_points_table()), 'L')\n\n    is_transparent = utils.is_transparent(im)\n    is_grayscale = im.mode in ('L', 'LA')\n    new_mode = im.mode\n    if is_grayscale or bw:\n        new_mode = 'L'\n    else:\n        new_mode = 'RGB'\n\n    if is_transparent:\n        if replace_alpha:\n            if im.mode != 'RGBA':\n                im = im.convert('RGBA')\n            base = Image.new('RGBA', im.size, replace_alpha)\n            base.paste(im, mask=im)\n            im = base\n        else:\n            new_mode = new_mode + 'A'\n\n    if im.mode != new_mode:\n        im = im.convert(new_mode)\n\n    return im", "response": "Convert images to the correct color space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef autocrop(im, autocrop=False, **kwargs):\n    if autocrop:\n        # If transparent, flatten.\n        if utils.is_transparent(im):\n            no_alpha = Image.new('L', im.size, (255))\n            no_alpha.paste(im, mask=im.split()[-1])\n        else:\n            no_alpha = im.convert('L')\n        # Convert to black and white image.\n        bw = no_alpha.convert('L')\n        # bw = bw.filter(ImageFilter.MedianFilter)\n        # White background.\n        bg = Image.new('L', im.size, 255)\n        bbox = ImageChops.difference(bw, bg).getbbox()\n        if bbox:\n            im = im.crop(bbox)\n    return im", "response": "A wrapper around autocrop method for the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle scaling and cropping the source image. Images can be scaled / cropped against a single dimension by using zero as the placeholder in the size. For example, ``size=(100, 0)`` will cause the image to be resized to 100 pixels wide, keeping the aspect ratio of the source image. crop Crop the source image height or width to exactly match the requested thumbnail size (the default is to proportionally resize the source image to fit within the requested thumbnail size). By default, the image is centered before being cropped. To crop from the edges, pass a comma separated string containing the ``x`` and ``y`` percentage offsets (negative values go from the right/bottom). Some examples follow: * ``crop=\"0,0\"`` will crop from the left and top edges. * ``crop=\"-10,-0\"`` will crop from the right edge (with a 10% offset) and the bottom edge. * ``crop=\",0\"`` will keep the default behavior for the x axis (horizontally centering the image) and crop from the top edge. The image can also be \"smart cropped\" by using ``crop=\"smart\"``. The image is incrementally cropped down to the requested size by removing slices from edges with the least entropy. Finally, you can use ``crop=\"scale\"`` to simply scale the image so that at least one dimension fits within the size dimensions given (you may want to use the upscale option too). upscale Allow upscaling of the source image during scaling. zoom A percentage to zoom in on the scaled image. For example, a zoom of ``40`` will clip 20% off each side of the source image before thumbnailing. target Set the focal point as a percentage for the image if it needs to be cropped (defaults to ``(50, 50)``). For example, ``target=\"10,20\"`` will set the focal point as 10% and 20% from the left and top of the image, respectively. If the image needs to be cropped, it will trim off the right and bottom edges until the focal point is centered. Can either be set as a two-item tuple such as ``(20, 30)`` or a comma separated string such as ``\"20,10\"``. A null value such as ``(20, None)`` or ``\",60\"`` will default to 50%.", "response": "def scale_and_crop(im, size, crop=False, upscale=False, zoom=None, target=None,\n                   **kwargs):\n    \"\"\"\n    Handle scaling and cropping the source image.\n\n    Images can be scaled / cropped against a single dimension by using zero\n    as the placeholder in the size. For example, ``size=(100, 0)`` will cause\n    the image to be resized to 100 pixels wide, keeping the aspect ratio of\n    the source image.\n\n    crop\n        Crop the source image height or width to exactly match the requested\n        thumbnail size (the default is to proportionally resize the source\n        image to fit within the requested thumbnail size).\n\n        By default, the image is centered before being cropped. To crop from\n        the edges, pass a comma separated string containing the ``x`` and ``y``\n        percentage offsets (negative values go from the right/bottom). Some\n        examples follow:\n\n        * ``crop=\"0,0\"`` will crop from the left and top edges.\n\n        * ``crop=\"-10,-0\"`` will crop from the right edge (with a 10% offset)\n          and the bottom edge.\n\n        * ``crop=\",0\"`` will keep the default behavior for the x axis\n          (horizontally centering the image) and crop from the top edge.\n\n        The image can also be \"smart cropped\" by using ``crop=\"smart\"``. The\n        image is incrementally cropped down to the requested size by removing\n        slices from edges with the least entropy.\n\n        Finally, you can use ``crop=\"scale\"`` to simply scale the image so that\n        at least one dimension fits within the size dimensions given (you may\n        want to use the upscale option too).\n\n    upscale\n        Allow upscaling of the source image during scaling.\n\n    zoom\n        A percentage to zoom in on the scaled image. For example, a zoom of\n        ``40`` will clip 20% off each side of the source image before\n        thumbnailing.\n\n    target\n        Set the focal point as a percentage for the image if it needs to be\n        cropped (defaults to ``(50, 50)``).\n\n        For example, ``target=\"10,20\"`` will set the focal point as 10% and 20%\n        from the left and top of the image, respectively. If the image needs to\n        be cropped, it will trim off the right and bottom edges until the focal\n        point is centered.\n\n        Can either be set as a two-item tuple such as ``(20, 30)`` or a comma\n        separated string such as ``\"20,10\"``.\n\n        A null value such as ``(20, None)`` or ``\",60\"`` will default to 50%.\n    \"\"\"\n    source_x, source_y = [float(v) for v in im.size]\n    target_x, target_y = [int(v) for v in size]\n\n    if crop or not target_x or not target_y:\n        scale = max(target_x / source_x, target_y / source_y)\n    else:\n        scale = min(target_x / source_x, target_y / source_y)\n\n    # Handle one-dimensional targets.\n    if not target_x:\n        target_x = round(source_x * scale)\n    elif not target_y:\n        target_y = round(source_y * scale)\n\n    if zoom:\n        if not crop:\n            target_x = round(source_x * scale)\n            target_y = round(source_y * scale)\n            crop = True\n        scale *= (100 + int(zoom)) / 100.0\n\n    if scale < 1.0 or (scale > 1.0 and upscale):\n        # Resize the image to the target size boundary. Round the scaled\n        # boundary sizes to avoid floating point errors.\n        im = im.resize((int(round(source_x * scale)),\n                        int(round(source_y * scale))),\n                       resample=Image.ANTIALIAS)\n\n    if crop:\n        # Use integer values now.\n        source_x, source_y = im.size\n        # Difference between new image size and requested size.\n        diff_x = int(source_x - min(source_x, target_x))\n        diff_y = int(source_y - min(source_y, target_y))\n        if crop != 'scale' and (diff_x or diff_y):\n            if isinstance(target, six.string_types):\n                target = re.match(r'(\\d+)?,(\\d+)?$', target)\n                if target:\n                    target = target.groups()\n            if target:\n                focal_point = [int(n) if (n or n == 0) else 50 for n in target]\n            else:\n                focal_point = 50, 50\n            # Crop around the focal point\n            halftarget_x, halftarget_y = int(target_x / 2), int(target_y / 2)\n            focal_point_x = int(source_x * focal_point[0] / 100)\n            focal_point_y = int(source_y * focal_point[1] / 100)\n            box = [\n                max(0, min(source_x - target_x, focal_point_x - halftarget_x)),\n                max(0, min(source_y - target_y, focal_point_y - halftarget_y)),\n            ]\n            box.append(int(min(source_x, box[0] + target_x)))\n            box.append(int(min(source_y, box[1] + target_y)))\n            # See if an edge cropping argument was provided.\n            edge_crop = (isinstance(crop, six.string_types) and\n                         re.match(r'(?:(-?)(\\d+))?,(?:(-?)(\\d+))?$', crop))\n            if edge_crop and filter(None, edge_crop.groups()):\n                x_right, x_crop, y_bottom, y_crop = edge_crop.groups()\n                if x_crop:\n                    offset = min(int(target_x) * int(x_crop) // 100, diff_x)\n                    if x_right:\n                        box[0] = diff_x - offset\n                        box[2] = source_x - offset\n                    else:\n                        box[0] = offset\n                        box[2] = source_x - (diff_x - offset)\n                if y_crop:\n                    offset = min(int(target_y) * int(y_crop) // 100, diff_y)\n                    if y_bottom:\n                        box[1] = diff_y - offset\n                        box[3] = source_y - offset\n                    else:\n                        box[1] = offset\n                        box[3] = source_y - (diff_y - offset)\n            # See if the image should be \"smart cropped\".\n            elif crop == 'smart':\n                left = top = 0\n                right, bottom = source_x, source_y\n                while diff_x:\n                    slice = min(diff_x, max(diff_x // 5, 10))\n                    start = im.crop((left, 0, left + slice, source_y))\n                    end = im.crop((right - slice, 0, right, source_y))\n                    add, remove = _compare_entropy(start, end, slice, diff_x)\n                    left += add\n                    right -= remove\n                    diff_x = diff_x - add - remove\n                while diff_y:\n                    slice = min(diff_y, max(diff_y // 5, 10))\n                    start = im.crop((0, top, source_x, top + slice))\n                    end = im.crop((0, bottom - slice, source_x, bottom))\n                    add, remove = _compare_entropy(start, end, slice, diff_y)\n                    top += add\n                    bottom -= remove\n                    diff_y = diff_y - add - remove\n                box = (left, top, right, bottom)\n            # Finally, crop the image!\n            im = im.crop(box)\n    return im"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filters(im, detail=False, sharpen=False, **kwargs):\n    if detail:\n        im = im.filter(ImageFilter.DETAIL)\n    if sharpen:\n        im = im.filter(ImageFilter.SHARPEN)\n    return im", "response": "Pass the source image through post - processing filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef background(im, size, background=None, **kwargs):\n    if not background:\n        # Primary option not given, nothing to do.\n        return im\n    if not size[0] or not size[1]:\n        # One of the dimensions aren't specified, can't do anything.\n        return im\n    x, y = im.size\n    if x >= size[0] and y >= size[1]:\n        # The image is already equal to (or larger than) the expected size, so\n        # there's nothing to do.\n        return im\n    im = colorspace(im, replace_alpha=background, **kwargs)\n    new_im = Image.new('RGB', size, background)\n    if new_im.mode != im.mode:\n        new_im = new_im.convert(im.mode)\n    offset = (size[0]-x)//2, (size[1]-y)//2\n    new_im.paste(im, offset)\n    return new_im", "response": "Add borders of a certain color to make the resized image fit exactly within the given dimensions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a Thumbnailer instance for a source file.", "response": "def get_thumbnailer(obj, relative_name=None):\n    \"\"\"\n    Get a :class:`Thumbnailer` for a source file.\n\n    The ``obj`` argument is usually either one of the following:\n\n        * ``FieldFile`` instance (i.e. a model instance file/image field\n          property).\n\n        * A string, which will be used as the relative name (the source will be\n          set to the default storage).\n\n        * ``Storage`` instance - the ``relative_name`` argument must also be\n          provided.\n\n    Or it could be:\n\n        * A file-like instance - the ``relative_name`` argument must also be\n          provided.\n\n          In this case, the thumbnailer won't use or create a cached reference\n          to the thumbnail (i.e. a new thumbnail will be created for every\n          :meth:`Thumbnailer.get_thumbnail` call).\n\n    If ``obj`` is a ``Thumbnailer`` instance, it will just be returned. If it's\n    an object with an ``easy_thumbnails_thumbnailer`` then the attribute is\n    simply returned under the assumption it is a Thumbnailer instance)\n    \"\"\"\n    if hasattr(obj, 'easy_thumbnails_thumbnailer'):\n        return obj.easy_thumbnails_thumbnailer\n    if isinstance(obj, Thumbnailer):\n        return obj\n    elif isinstance(obj, FieldFile):\n        if not relative_name:\n            relative_name = obj.name\n        return ThumbnailerFieldFile(obj.instance, obj.field, relative_name)\n\n    source_storage = None\n\n    if isinstance(obj, six.string_types):\n        relative_name = obj\n        obj = None\n\n    if not relative_name:\n        raise ValueError(\n            \"If object is not a FieldFile or Thumbnailer instance, the \"\n            \"relative name must be provided\")\n\n    if isinstance(obj, File):\n        obj = obj.file\n    if isinstance(obj, Storage) or obj == default_storage:\n        source_storage = obj\n        obj = None\n\n    return Thumbnailer(\n        file=obj, name=relative_name, source_storage=source_storage,\n        remote_source=obj is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating all of a file s aliases.", "response": "def generate_all_aliases(fieldfile, include_global):\n    \"\"\"\n    Generate all of a file's aliases.\n\n    :param fieldfile: A ``FieldFile`` instance.\n    :param include_global: A boolean which determines whether to generate\n        thumbnails for project-wide aliases in addition to field, model, and\n        app specific aliases.\n    \"\"\"\n    all_options = aliases.all(fieldfile, include_global=include_global)\n    if all_options:\n        thumbnailer = get_thumbnailer(fieldfile)\n        for key, options in six.iteritems(all_options):\n            options['ALIAS'] = key\n            thumbnailer.get_thumbnail(options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef database_get_image_dimensions(file, close=False, dimensions=None):\n    storage_hash = utils.get_storage_hash(file.storage)\n    dimensions = None\n    dimensions_cache = None\n    try:\n        thumbnail = models.Thumbnail.objects.select_related('dimensions').get(\n            storage_hash=storage_hash, name=file.name)\n    except models.Thumbnail.DoesNotExist:\n        thumbnail = None\n    else:\n        try:\n            dimensions_cache = thumbnail.dimensions\n        except models.ThumbnailDimensions.DoesNotExist:\n            dimensions_cache = None\n        if dimensions_cache:\n            return dimensions_cache.width, dimensions_cache.height\n    dimensions = get_image_dimensions(file, close=close)\n    if settings.THUMBNAIL_CACHE_DIMENSIONS and thumbnail:\n        # Using get_or_create in case dimensions were created\n        # while running get_image_dimensions.\n        models.ThumbnailDimensions.objects.get_or_create(\n            thumbnail=thumbnail,\n            defaults={'width': dimensions[0], 'height': dimensions[1]})\n    return dimensions", "response": "Returns the width height of an image given ThumbnailFile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a PIL Image instance of this file.", "response": "def _get_image(self):\n        \"\"\"\n        Get a PIL Image instance of this file.\n\n        The image is cached to avoid the file needing to be read again if the\n        function is called again.\n        \"\"\"\n        if not hasattr(self, '_image_cache'):\n            from easy_thumbnails.source_generators import pil_image\n            self.image = pil_image(self)\n        return self._image_cache"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the image for this file.", "response": "def _set_image(self, image):\n        \"\"\"\n        Set the image for this file.\n\n        This also caches the dimensions of the image.\n        \"\"\"\n        if image:\n            self._image_cache = image\n            self._dimensions_cache = image.size\n        else:\n            if hasattr(self, '_image_cache'):\n                del self._cached_image\n            if hasattr(self, '_dimensions_cache'):\n                del self._dimensions_cache"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag(self, alt='', use_size=None, **attrs):\n        if use_size is None:\n            if getattr(self, '_dimensions_cache', None):\n                use_size = True\n            else:\n                try:\n                    self.storage.path(self.name)\n                    use_size = True\n                except NotImplementedError:\n                    use_size = False\n        attrs['alt'] = alt\n        attrs['src'] = self.url\n        if use_size:\n            attrs.update(dict(width=self.width, height=self.height))\n        attrs = ' '.join(['%s=\"%s\"' % (key, escape(value))\n                          for key, value in sorted(attrs.items())])\n        return mark_safe('<img %s />' % attrs)", "response": "Return a standard XHTML image tag for this field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_image_dimensions(self, thumbnail):\n        try:\n            dimensions = getattr(thumbnail, 'dimensions', None)\n        except models.ThumbnailDimensions.DoesNotExist:\n            dimensions = None\n        if not dimensions:\n            return False\n        self._dimensions_cache = dimensions.size\n        return self._dimensions_cache", "response": "Sets the image dimensions from the cached dimensions of a Thumbnail object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_options(self, thumbnail_options, **kwargs):\n        if isinstance(thumbnail_options, ThumbnailOptions):\n            return thumbnail_options\n        args = []\n        if thumbnail_options is not None:\n            args.append(thumbnail_options)\n        opts = ThumbnailOptions(*args, **kwargs)\n        if 'quality' not in thumbnail_options:\n            opts['quality'] = self.thumbnail_quality\n        return opts", "response": "Get the thumbnail options that includes the default options for this image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_thumbnail(self, thumbnail_options, high_resolution=False,\n                           silent_template_exception=False):\n        \"\"\"\n        Return an unsaved ``ThumbnailFile`` containing a thumbnail image.\n\n        The thumbnail image is generated using the ``thumbnail_options``\n        dictionary.\n        \"\"\"\n        thumbnail_options = self.get_options(thumbnail_options)\n        orig_size = thumbnail_options['size']  # remember original size\n        # Size sanity check.\n        min_dim, max_dim = 0, 0\n        for dim in orig_size:\n            try:\n                dim = int(dim)\n            except (TypeError, ValueError):\n                continue\n            min_dim, max_dim = min(min_dim, dim), max(max_dim, dim)\n        if max_dim == 0 or min_dim < 0:\n            raise exceptions.EasyThumbnailsError(\n                \"The source image is an invalid size (%sx%s)\" % orig_size)\n\n        if high_resolution:\n            thumbnail_options['size'] = (orig_size[0] * 2, orig_size[1] * 2)\n        image = engine.generate_source_image(\n            self, thumbnail_options, self.source_generators,\n            fail_silently=silent_template_exception)\n        if image is None:\n            raise exceptions.InvalidImageFormatError(\n                \"The source file does not appear to be an image\")\n\n        thumbnail_image = engine.process_image(image, thumbnail_options,\n                                               self.thumbnail_processors)\n        if high_resolution:\n            thumbnail_options['size'] = orig_size  # restore original size\n\n        filename = self.get_thumbnail_name(\n            thumbnail_options,\n            transparent=utils.is_transparent(thumbnail_image),\n            high_resolution=high_resolution)\n        quality = thumbnail_options['quality']\n        subsampling = thumbnail_options['subsampling']\n\n        img = engine.save_image(\n            thumbnail_image, filename=filename, quality=quality,\n            subsampling=subsampling)\n        data = img.read()\n\n        thumbnail = ThumbnailFile(\n            filename, file=ContentFile(data), storage=self.thumbnail_storage,\n            thumbnail_options=thumbnail_options)\n        thumbnail.image = thumbnail_image\n        thumbnail._committed = False\n\n        return thumbnail", "response": "Generate a thumbnail image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a thumbnail filename for the given thumbnail_options dictionary and source_name.", "response": "def get_thumbnail_name(self, thumbnail_options, transparent=False,\n                           high_resolution=False):\n        \"\"\"\n        Return a thumbnail filename for the given ``thumbnail_options``\n        dictionary and ``source_name`` (which defaults to the File's ``name``\n        if not provided).\n        \"\"\"\n        thumbnail_options = self.get_options(thumbnail_options)\n        path, source_filename = os.path.split(self.name)\n        source_extension = os.path.splitext(source_filename)[1][1:]\n        preserve_extensions = self.thumbnail_preserve_extensions\n        if preserve_extensions and (\n                preserve_extensions is True or\n                source_extension.lower() in preserve_extensions):\n            extension = source_extension\n        elif transparent:\n            extension = self.thumbnail_transparency_extension\n        else:\n            extension = self.thumbnail_extension\n        extension = extension or 'jpg'\n\n        prepared_opts = thumbnail_options.prepared_options()\n        opts_text = '_'.join(prepared_opts)\n\n        data = {'opts': opts_text}\n        basedir = self.thumbnail_basedir % data\n        subdir = self.thumbnail_subdir % data\n\n        if isinstance(self.thumbnail_namer, six.string_types):\n            namer_func = utils.dynamic_import(self.thumbnail_namer)\n        else:\n            namer_func = self.thumbnail_namer\n        filename = namer_func(\n            thumbnailer=self,\n            source_filename=source_filename,\n            thumbnail_extension=extension,\n            thumbnail_options=thumbnail_options,\n            prepared_options=prepared_opts,\n        )\n        if high_resolution:\n            filename = self.thumbnail_highres_infix.join(\n                os.path.splitext(filename))\n        filename = '%s%s' % (self.thumbnail_prefix, filename)\n\n        return os.path.join(basedir, path, subdir, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an existing ThumbnailFile containing an existing thumbnail for a set of thumbnail options.", "response": "def get_existing_thumbnail(self, thumbnail_options, high_resolution=False):\n        \"\"\"\n        Return a ``ThumbnailFile`` containing an existing thumbnail for a set\n        of thumbnail options, or ``None`` if not found.\n        \"\"\"\n        thumbnail_options = self.get_options(thumbnail_options)\n        names = [\n            self.get_thumbnail_name(\n                thumbnail_options, transparent=False,\n                high_resolution=high_resolution)]\n        transparent_name = self.get_thumbnail_name(\n            thumbnail_options, transparent=True,\n            high_resolution=high_resolution)\n        if transparent_name not in names:\n            names.append(transparent_name)\n\n        for filename in names:\n            exists = self.thumbnail_exists(filename)\n            if exists:\n                thumbnail_file = ThumbnailFile(\n                    name=filename, storage=self.thumbnail_storage,\n                    thumbnail_options=thumbnail_options)\n                if settings.THUMBNAIL_CACHE_DIMENSIONS:\n                    # If this wasn't local storage, exists will be a thumbnail\n                    # instance so we can store the image dimensions now to save\n                    # a future potential query.\n                    thumbnail_file.set_image_dimensions(exists)\n                return thumbnail_file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_thumbnail(self, thumbnail_options, save=True, generate=None,\n                      silent_template_exception=False):\n        \"\"\"\n        Return a ``ThumbnailFile`` containing a thumbnail.\n\n        If a matching thumbnail already exists, it will simply be returned.\n\n        By default (unless the ``Thumbnailer`` was instanciated with\n        ``generate=False``), thumbnails that don't exist are generated.\n        Otherwise ``None`` is returned.\n\n        Force the generation behaviour by setting the ``generate`` param to\n        either ``True`` or ``False`` as required.\n\n        The new thumbnail image is generated using the ``thumbnail_options``\n        dictionary. If the ``save`` argument is ``True`` (default), the\n        generated thumbnail will be saved too.\n        \"\"\"\n        thumbnail_options = self.get_options(thumbnail_options)\n        if generate is None:\n            generate = self.generate\n\n        thumbnail = self.get_existing_thumbnail(thumbnail_options)\n        if not thumbnail:\n            if generate:\n                thumbnail = self.generate_thumbnail(\n                    thumbnail_options,\n                    silent_template_exception=silent_template_exception)\n                if save:\n                    self.save_thumbnail(thumbnail)\n            else:\n                signals.thumbnail_missed.send(\n                    sender=self, options=thumbnail_options,\n                    high_resolution=False)\n\n        if 'HIGH_RESOLUTION' in thumbnail_options:\n            generate_high_resolution = thumbnail_options.get('HIGH_RESOLUTION')\n        else:\n            generate_high_resolution = self.thumbnail_high_resolution\n        if generate_high_resolution:\n            thumbnail.high_resolution = self.get_existing_thumbnail(\n                thumbnail_options, high_resolution=True)\n            if not thumbnail.high_resolution:\n                if generate:\n                    thumbnail.high_resolution = self.generate_thumbnail(\n                        thumbnail_options, high_resolution=True,\n                        silent_template_exception=silent_template_exception)\n                    if save:\n                        self.save_thumbnail(thumbnail.high_resolution)\n                else:\n                    signals.thumbnail_missed.send(\n                        sender=self, options=thumbnail_options,\n                        high_resolution=False)\n\n        return thumbnail", "response": "Returns a ThumbnailFile containing a thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a thumbnail to the thumbnail_storage.", "response": "def save_thumbnail(self, thumbnail):\n        \"\"\"\n        Save a thumbnail to the thumbnail_storage.\n\n        Also triggers the ``thumbnail_created`` signal and caches the\n        thumbnail values and dimensions for future lookups.\n        \"\"\"\n        filename = thumbnail.name\n        try:\n            self.thumbnail_storage.delete(filename)\n        except Exception:\n            pass\n        self.thumbnail_storage.save(filename, thumbnail)\n\n        thumb_cache = self.get_thumbnail_cache(\n            thumbnail.name, create=True, update=True)\n\n        # Cache thumbnail dimensions.\n        if settings.THUMBNAIL_CACHE_DIMENSIONS:\n            dimensions_cache, created = (\n                models.ThumbnailDimensions.objects.get_or_create(\n                    thumbnail=thumb_cache,\n                    defaults={'width': thumbnail.width,\n                              'height': thumbnail.height}))\n            if not created:\n                dimensions_cache.width = thumbnail.width\n                dimensions_cache.height = thumbnail.height\n                dimensions_cache.save()\n\n        signals.thumbnail_created.send(sender=thumbnail)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef thumbnail_exists(self, thumbnail_name):\n        if self.remote_source:\n            return False\n\n        if utils.is_storage_local(self.source_storage):\n            source_modtime = utils.get_modified_time(\n                self.source_storage, self.name)\n        else:\n            source = self.get_source_cache()\n            if not source:\n                return False\n            source_modtime = source.modified\n\n        if not source_modtime:\n            return False\n\n        local_thumbnails = utils.is_storage_local(self.thumbnail_storage)\n        if local_thumbnails:\n            thumbnail_modtime = utils.get_modified_time(\n                self.thumbnail_storage, thumbnail_name)\n            if not thumbnail_modtime:\n                return False\n            return source_modtime <= thumbnail_modtime\n\n        thumbnail = self.get_thumbnail_cache(thumbnail_name)\n        if not thumbnail:\n            return False\n        thumbnail_modtime = thumbnail.modified\n\n        if thumbnail.modified and source_modtime <= thumbnail.modified:\n            return thumbnail\n        return False", "response": "Calculate whether the thumbnail already exists and that the source is newer than the thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, name, content, *args, **kwargs):\n        super(ThumbnailerFieldFile, self).save(name, content, *args, **kwargs)\n        self.get_source_cache(create=True, update=True)", "response": "Save the file and also save a reference to the thumbnail cache"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete the image along with any generated thumbnails.", "response": "def delete(self, *args, **kwargs):\n        \"\"\"\n        Delete the image, along with any generated thumbnails.\n        \"\"\"\n        source_cache = self.get_source_cache()\n        # First, delete any related thumbnails.\n        self.delete_thumbnails(source_cache)\n        # Next, delete the source image.\n        super(ThumbnailerFieldFile, self).delete(*args, **kwargs)\n        # Finally, delete the source cache entry.\n        if source_cache and source_cache.pk is not None:\n            source_cache.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting any thumbnails generated from the source image.", "response": "def delete_thumbnails(self, source_cache=None):\n        \"\"\"\n        Delete any thumbnails generated from the source image.\n\n        :arg source_cache: An optional argument only used for optimisation\n          where the source cache instance is already known.\n        :returns: The number of files deleted.\n        \"\"\"\n        source_cache = self.get_source_cache()\n        deleted = 0\n        if source_cache:\n            thumbnail_storage_hash = utils.get_storage_hash(\n                self.thumbnail_storage)\n            for thumbnail_cache in source_cache.thumbnails.all():\n                # Only attempt to delete the file if it was stored using the\n                # same storage as is currently used.\n                if thumbnail_cache.storage_hash == thumbnail_storage_hash:\n                    self.thumbnail_storage.delete(thumbnail_cache.name)\n                    # Delete the cache thumbnail instance too.\n                    thumbnail_cache.delete()\n                    deleted += 1\n        return deleted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator which returns ThumbnailFile instances.", "response": "def get_thumbnails(self, *args, **kwargs):\n        \"\"\"\n        Return an iterator which returns ThumbnailFile instances.\n        \"\"\"\n        # First, delete any related thumbnails.\n        source_cache = self.get_source_cache()\n        if source_cache:\n            thumbnail_storage_hash = utils.get_storage_hash(\n                self.thumbnail_storage)\n            for thumbnail_cache in source_cache.thumbnails.all():\n                # Only iterate files which are stored using the current\n                # thumbnail storage.\n                if thumbnail_cache.storage_hash == thumbnail_storage_hash:\n                    yield ThumbnailFile(name=thumbnail_cache.name,\n                                        storage=self.thumbnail_storage)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the image. The image will be resized down using a ``ThumbnailField`` if ``resize_source`` (a dictionary of thumbnail options) is provided by the field.", "response": "def save(self, name, content, *args, **kwargs):\n        \"\"\"\n        Save the image.\n\n        The image will be resized down using a ``ThumbnailField`` if\n        ``resize_source`` (a dictionary of thumbnail options) is provided by\n        the field.\n        \"\"\"\n        options = getattr(self.field, 'resize_source', None)\n        if options:\n            if 'quality' not in options:\n                options['quality'] = self.thumbnail_quality\n            content = Thumbnailer(content, name).generate_thumbnail(options)\n            # If the generated extension differs from the original, use it\n            # instead.\n            orig_name, ext = os.path.splitext(name)\n            generated_ext = os.path.splitext(content.name)[1]\n            if generated_ext.lower() != ext.lower():\n                name = orig_name + generated_ext\n        super(ThumbnailerImageFieldFile, self).save(name, content, *args,\n                                                    **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_up(self, dry_run=False, verbosity=1, last_n_days=0,\n                 cleanup_path=None, storage=None):\n        \"\"\"\n        Iterate through sources. Delete database references to sources\n        not existing, including its corresponding thumbnails (files and\n        database references).\n        \"\"\"\n        if dry_run:\n            print (\"Dry run...\")\n\n        if not storage:\n            storage = get_storage_class(settings.THUMBNAIL_DEFAULT_STORAGE)()\n\n        sources_to_delete = []\n        time_start = time.time()\n\n        query = Source.objects.all()\n        if last_n_days > 0:\n            today = date.today()\n            query = query.filter(\n                modified__range=(today - timedelta(days=last_n_days), today))\n        if cleanup_path:\n            query = query.filter(name__startswith=cleanup_path)\n\n        for source in queryset_iterator(query):\n            self.sources += 1\n            abs_source_path = self._get_absolute_path(source.name)\n\n            if not self._check_if_exists(storage, abs_source_path):\n                if verbosity > 0:\n                    print (\"Source not present:\", abs_source_path)\n                self.source_refs_deleted += 1\n                sources_to_delete.append(source.id)\n\n                for thumb in source.thumbnails.all():\n                    self.thumbnails_deleted += 1\n                    abs_thumbnail_path = self._get_absolute_path(thumb.name)\n\n                    if self._check_if_exists(storage, abs_thumbnail_path):\n                        if not dry_run:\n                            storage.delete(abs_thumbnail_path)\n                        if verbosity > 0:\n                            print (\"Deleting thumbnail:\", abs_thumbnail_path)\n\n            if len(sources_to_delete) >= 1000 and not dry_run:\n                self._delete_sources_by_id(sources_to_delete)\n                sources_to_delete = []\n\n        if not dry_run:\n            self._delete_sources_by_id(sources_to_delete)\n        self.execution_time = round(time.time() - time_start)", "response": "Delete all sources and thumbnails from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_stats(self):\n        print(\n            \"{0:-<48}\".format(str(datetime.now().strftime('%Y-%m-%d %H:%M '))))\n        print(\"{0:<40} {1:>7}\".format(\"Sources checked:\", self.sources))\n        print(\"{0:<40} {1:>7}\".format(\n            \"Source references deleted from DB:\", self.source_refs_deleted))\n        print(\"{0:<40} {1:>7}\".format(\"Thumbnails deleted from disk:\",\n                                    self.thumbnails_deleted))\n        print(\"(Completed in %s seconds)\\n\" % self.execution_time)", "response": "Print statistics about the cleanup performed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef populate_from_settings(self):\n        settings_aliases = settings.THUMBNAIL_ALIASES\n        if settings_aliases:\n            for target, aliases in settings_aliases.items():\n                target_aliases = self._aliases.setdefault(target, {})\n                target_aliases.update(aliases)", "response": "Populate the aliases from the THUMBNAIL_ALIASES setting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an alias. :param alias: The name of the alias to add. :param options: The easy-thumbnails options dictonary for this alias (should include ``size``). :param target: A field, model, or app to limit this alias to (optional).", "response": "def set(self, alias, options, target=None):\n        \"\"\"\n        Add an alias.\n\n        :param alias: The name of the alias to add.\n        :param options: The easy-thumbnails options dictonary for this alias\n            (should include ``size``).\n        :param target: A field, model, or app to limit this alias to\n            (optional).\n        \"\"\"\n        target = self._coerce_target(target) or ''\n        target_aliases = self._aliases.setdefault(target, {})\n        target_aliases[alias] = options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, alias, target=None):\n        for target_part in reversed(list(self._get_targets(target))):\n            options = self._get(target_part, alias)\n            if options:\n                return options", "response": "Get a dictionary of aliased options."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a dictionary of all aliases and their options.", "response": "def all(self, target=None, include_global=True):\n        \"\"\"\n        Get a dictionary of all aliases and their options.\n\n        :param target: Include aliases for this specific field, model or app\n            (optional).\n        :param include_global: Include all non target-specific aliases\n            (default ``True``).\n\n        For example::\n\n            >>> aliases.all(target='my_app.MyModel')\n            {'small': {'size': (100, 100)}, 'large': {'size': (400, 400)}}\n        \"\"\"\n        aliases = {}\n        for target_part in self._get_targets(target, include_global):\n            aliases.update(self._aliases.get(target_part, {}))\n        return aliases"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get(self, target, alias):\n        if target not in self._aliases:\n            return\n        return self._aliases[target].get(alias)", "response": "Internal method to get a specific alias."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_targets(self, target, include_global=True):\n        target = self._coerce_target(target)\n        if include_global:\n            yield ''\n        if not target:\n            return\n        target_bits = target.split('.')\n        for i in range(len(target_bits)):\n            yield '.'.join(target_bits[:i + 1])", "response": "Internal iterator to split up a complete target into possible parts\n        it may match."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the entropy of an image. Used for smart cropping.", "response": "def image_entropy(im):\n    \"\"\"\n    Calculate the entropy of an image. Used for \"smart cropping\".\n    \"\"\"\n    if not isinstance(im, Image.Image):\n        # Can only deal with PIL images. Fall back to a constant entropy.\n        return 0\n    hist = im.histogram()\n    hist_size = float(sum(hist))\n    hist = [h / hist_size for h in hist]\n    return -sum([p * math.log(p, 2) for p in hist if p != 0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef valid_processor_options(processors=None):\n    if processors is None:\n        processors = [\n            dynamic_import(p) for p in\n            tuple(settings.THUMBNAIL_PROCESSORS) +\n            tuple(settings.THUMBNAIL_SOURCE_GENERATORS)]\n    valid_options = set(['size', 'quality', 'subsampling'])\n    for processor in processors:\n        args = inspect.getfullargspec(processor)[0] if six.PY3 else inspect.getargspec(processor)[0]\n        # Add all arguments apart from the first (the source image).\n        valid_options.update(args[1:])\n    return list(valid_options)", "response": "Return a list of unique valid options for a list of image processors\n    and source generators\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_storage_hash(storage):\n    # If storage is wrapped in a lazy object we need to get the real thing.\n    if isinstance(storage, LazyObject):\n        if storage._wrapped is None:\n            storage._setup()\n        storage = storage._wrapped\n    if not isinstance(storage, six.string_types):\n        storage_cls = storage.__class__\n        storage = '%s.%s' % (storage_cls.__module__, storage_cls.__name__)\n    return hashlib.md5(storage.encode('utf8')).hexdigest()", "response": "Return a hex string hash for a storage object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks to see if an image is transparent.", "response": "def is_transparent(image):\n    \"\"\"\n    Check to see if an image is transparent.\n    \"\"\"\n    if not isinstance(image, Image.Image):\n        # Can only deal with PIL images, fall back to the assumption that that\n        # it's not transparent.\n        return False\n    return (image.mode in ('RGBA', 'LA') or\n            (image.mode == 'P' and 'transparency' in image.info))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks to see if an image is progressive.", "response": "def is_progressive(image):\n    \"\"\"\n    Check to see if an image is progressive.\n    \"\"\"\n    if not isinstance(image, Image.Image):\n        # Can only check PIL images for progressive encoding.\n        return False\n    return ('progressive' in image.info) or ('progression' in image.info)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exif_orientation(im):\n    try:\n        exif = im._getexif()\n    except Exception:\n        # There are many ways that _getexif fails, we're just going to blanket\n        # cover them all.\n        exif = None\n    if exif:\n        orientation = exif.get(0x0112)\n        if orientation == 2:\n            im = im.transpose(Image.FLIP_LEFT_RIGHT)\n        elif orientation == 3:\n            im = im.transpose(Image.ROTATE_180)\n        elif orientation == 4:\n            im = im.transpose(Image.FLIP_TOP_BOTTOM)\n        elif orientation == 5:\n            im = im.transpose(Image.ROTATE_270).transpose(Image.FLIP_LEFT_RIGHT)\n        elif orientation == 6:\n            im = im.transpose(Image.ROTATE_270)\n        elif orientation == 7:\n            im = im.transpose(Image.ROTATE_90).transpose(Image.FLIP_LEFT_RIGHT)\n        elif orientation == 8:\n            im = im.transpose(Image.ROTATE_90)\n    return im", "response": "Rotate and flip an image to respect the image s EXIF orientation data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_modified_time(storage, name):\n    try:\n        try:\n            # Prefer Django 1.10 API and fall back to old one\n            modified_time = storage.get_modified_time(name)\n        except AttributeError:\n            modified_time = storage.modified_time(name)\n    except OSError:\n        return 0\n    except NotImplementedError:\n        return None\n    if modified_time and timezone.is_naive(modified_time):\n        if getattr(settings, 'USE_TZ', False):\n            default_timezone = timezone.get_default_timezone()\n            return timezone.make_aware(modified_time, default_timezone)\n    return modified_time", "response": "Get modified time from storage ensuring the result is a timezone - aware datetime."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namedtuple(typename, field_names, verbose=False, rename=False):\n\n    if isinstance(field_names, str):\n        field_names = field_names.replace(',', ' ').split()\n    field_names = list(map(str, field_names))\n    typename = str(typename)\n    for name in [typename] + field_names:\n        if type(name) != str:\n            raise TypeError('Type names and field names must be strings')\n        if _iskeyword(name):\n            raise ValueError('Type names and field names cannot be a '\n                             'keyword: %r' % name)\n    if not _isidentifier(typename):\n        raise ValueError('Type names must be valid '\n                         'identifiers: %r' % name)\n    seen = set()\n    for name in field_names:\n        if name.startswith('_') and not rename:\n            raise ValueError('Field names cannot start with an underscore: '\n                             '%r' % name)\n        if name in seen:\n            raise ValueError('Encountered duplicate field name: %r' % name)\n        seen.add(name)\n    arg_names = ['_' + str(i) for i in range(len(field_names))]\n    # Fill-in the class template\n    class_definition = _class_template.format(\n        typename=typename,\n        field_names=tuple(field_names),\n        num_fields=len(field_names),\n        arg_list=repr(tuple(arg_names)).replace(\"'\", \"\")[1:-1],\n        repr_fmt=', '.join(_repr_template.format(name=name)\n                           for name in field_names),\n        field_defs='\\n'.join(_field_template.format(index=index, name=name)\n                             for index, name in enumerate(field_names) if _isidentifier(name))\n    )\n\n    # Execute the template string in a temporary namespace and support\n    # tracing utilities by setting a value for frame.f_globals['__name__']\n    namespace = dict(__name__='namedtuple_%s' % typename)\n    exec(class_definition, namespace)\n    result = namespace[typename]\n    result._source = class_definition\n    if verbose:\n        print(result._source)\n\n    # For pickling to work, the __module__ variable needs to be set to the frame\n    # where the named tuple is created.  Bypass this step in environments where\n    # sys._getframe is not defined (Jython for example) or sys._getframe is not\n    # defined for arguments greater than 0 (IronPython).\n    try:\n        result.__module__ = _sys._getframe(\n            1).f_globals.get('__name__', '__main__')\n    except (AttributeError, ValueError):\n        pass\n\n    return result", "response": "Returns a new subclass of namedtuple with named fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves source to file by calling write on the root element.", "response": "def write_source(self, filename):\r\n        '''\r\n        Save source to file by calling `write` on the root element.\r\n        '''\r\n        with open(filename, 'w') as fp:\r\n            return json.dump(self.message._elem, fp, indent=4, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef international_str(self, name, sdmxobj):\r\n        '''\r\n        return DictLike of xml:lang attributes. If node has no attributes,\r\n        assume that language is 'en'.\r\n        '''\r\n        # Get language tokens like 'en', 'fr'...\r\n        elem_attrib = self._paths['int_str_names'](sdmxobj._elem, name=name)\r\n        values = self._paths['int_str_values'](sdmxobj._elem, name=name)\r\n        # Unilingual strings have no attributes. Assume 'en' instead.\r\n        if not elem_attrib:\r\n            elem_attrib = ['en']\r\n        return DictLike(zip(elem_attrib, values))", "response": "Returns a dictionary of the attributes of the given name and values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget SDMX message from REST service or local file - like object.", "response": "def get(self, url, fromfile=None, params={}, headers={}):\r\n        '''Get SDMX message from REST service or local file\r\n\r\n        Args:\r\n\r\n            url(str): URL of the REST service without the query part\r\n                If None, fromfile must be set. Default is None\r\n            params(dict): will be appended as query part to the URL after a '?'\r\n            fromfile(str): path to SDMX file containing an SDMX message.\r\n                It will be passed on to the\r\n                reader for parsing.\r\n            headers(dict): http headers. Overwrite instance-wide headers.\r\n                Default is {}\r\n\r\n        Returns:\r\n            tuple: three objects:\r\n\r\n                0. file-like object containing the SDMX message\r\n                1. the complete URL, if any, including the query part\r\n                   constructed from params\r\n                2. the status code\r\n\r\n        Raises:\r\n            HTTPError if SDMX service responded with\r\n                status code 401. Otherwise, the status code\r\n                is returned\r\n '''\r\n        if fromfile:\r\n            try:\r\n                # Load data from local file\r\n                # json files must be opened in text mode, all others in binary as\r\n                # they may be zip files or xml.\r\n                if fromfile.endswith('.json'):\r\n                    mode_str = 'r'\r\n                else:\r\n                    mode_str = 'rb'\r\n                source = open(fromfile, mode_str)\r\n            except TypeError:\r\n                # so fromfile must be file-like\r\n                source = fromfile\r\n            final_url = resp_headers = status_code = None\r\n        else:\r\n            source, final_url, resp_headers, status_code = self.request(\r\n                url, params=params, headers=headers)\r\n        return source, final_url, resp_headers, status_code"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving SDMX messages and return the xml data as file - like object.", "response": "def request(self, url, params={}, headers={}):\r\n        \"\"\"\r\n        Retrieve SDMX messages.\r\n        If needed, override in subclasses to support other data providers.\r\n\r\n        :param url: The URL of the message.\r\n        :type url: str\r\n        :return: the xml data as file-like object\r\n        \"\"\"\r\n        # Generate current config. Merge in any given headers\r\n        cur_config = self.config.copy()\r\n        if 'headers' in cur_config:\r\n            cur_config['headers'] = cur_config['headers'].copy()\r\n            cur_config['headers'].update(headers)\r\n        else:\r\n            cur_config['headers'] = headers\r\n\r\n        with closing(requests.get(url, params=params, **cur_config)) as response:\r\n            if response.status_code == requests.codes.OK:\r\n                # Prepare the temp file. xml content will be\r\n                # stored in a binary file, json in a textfile.\r\n                if (response.headers.get('Content-Type')\r\n                        and ('json' in response.headers['Content-Type'])):\r\n                    enc, fmode = response.encoding, 'w+t'\r\n                else:\r\n                    enc, fmode = None, 'w+b'\r\n                # Create temp file ensuring 2to3 compatibility\r\n                if str_type == str:  # we are on py3\r\n                    source = STF(\r\n                        max_size=self.max_size, mode=fmode, encoding=enc)\r\n                else:\r\n                    # On py27 we must omit the 'encoding' kwarg\r\n                    source = STF(max_size=self.max_size, mode=fmode)\r\n                for c in response.iter_content(chunk_size=1000000,\r\n                                               decode_unicode=bool(enc)):\r\n                    source.write(c)\r\n\r\n            else:\r\n                source = None\r\n            code = int(response.status_code)\r\n            if 400 <= code <= 499:\r\n                raise response.raise_for_status()\r\n            return source, response.url, response.headers, code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef odo_register():\n    '''\n    Enable conversion of .sdmx files with odo (http://odo.readthedocs.org).\n    Adds conversion from sdmx to PD.DataFrame to odo graph.\n    Note that native discovery of sdmx files is not yet supported. odo will thus \n    convert to PD.DataFrame\n    and discover the data shape from there.\n    '''\n    logger.info('Registering with odo...')\n    import odo\n    from odo.utils import keywords\n    import pandas as PD\n    from toolz import keyfilter\n    import toolz.curried.operator as op\n\n    class PandaSDMX(object):\n\n        def __init__(self, uri):\n            self.uri = uri\n\n    @odo.resource.register(r'.*\\.sdmx')\n    def resource_sdmx(uri, **kwargs):\n        return PandaSDMX(uri)\n\n    @odo.discover.register(PandaSDMX)\n    def _(sdmx):\n        return odo.discover(Request().get(fromfile=sdmx.uri).write())\n\n    @odo.convert.register(PD.DataFrame, PandaSDMX)\n    def convert_sdmx(sdmx, **kwargs):\n        write = Request().get(fromfile=sdmx.uri).write\n        return write(**keyfilter(op.contains(keywords(write)), kwargs))\n    logger.info('odo registration complete.')", "response": "Register a new resource with odo."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef concat_namedtuples(*tup, **kwargs):\r\n    '''\r\n    Concatenate 2 or more namedtuples. The new namedtuple type\r\n    is provided by :class:`NamedTupleFactory`\r\n    return new namedtuple instance\r\n    '''\r\n    name = kwargs['name'] if 'name' in kwargs else None\r\n\r\n    # filter out empty elements\r\n    filtered = [i for i in filter(None, tup)]\r\n    if filtered:\r\n        if len(filtered) == 1:\r\n            return filtered[0]\r\n        else:\r\n            fields = chain(*(t._fields for t in filtered))\r\n            values = chain(*(t for t in filtered))\r\n            if not name:\r\n                name = 'SDMXNamedTuple'\r\n            ConcatType = namedtuple_factory(name, fields)\r\n            return ConcatType(*values)\r\n    else:\r\n        return ()", "response": "Concatenate 2 or more namedtuples. The new namedtuple instance is provided by NamedTupleFactory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects values by attribute searchstr language = en", "response": "def find(self, search_str, by='name', language='en'):\r\n        '''Select values by attribute\r\n\r\n        Args:\r\n\r\n            searchstr(str): the string to search for\r\n            by(str): the name of the attribute to search by, defaults to 'name'\r\n                The specified attribute must be either a string\r\n                or a dict mapping language codes to strings.\r\n                Such attributes occur, e.g. in :class:`pandasdmx.model.NameableArtefact` which is\r\n                a base class for :class:`pandasdmx.model.DataFlowDefinition` and many others.\r\n            language(str): language code specifying the language of the text to be searched, defaults to 'en'\r\n\r\n        Returns:\r\n            DictLike: items where value.<by> contains the search_str. International strings\r\n                stored as dict with language codes as keys are\r\n                searched. Capitalization is ignored.\r\n\r\n        '''\r\n\r\n        s = search_str.lower()\r\n        # We distinguish between international strings stored as dict such as\r\n        # name.en, name.fr, and normal strings.\r\n        if by in ['name', 'description']:\r\n            get_field = lambda obj: getattr(obj, by)[language]\r\n        else:  # normal string\r\n            get_field = lambda obj: getattr(obj, by)\r\n        return DictLike(result for result in self.items()\r\n                        if s in get_field(result[1]).lower())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the XML source of the message to a file.", "response": "def write_source(self, filename):\r\n        '''\r\n        Save XML source to file by calling `write` on the root element.\r\n        '''\r\n        return self.message._elem.getroottree().write(filename, encoding='utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef obs(self, with_values=True, with_attributes=True):\r\n        '''\r\n        return an iterator over observations in a flat dataset.\r\n        An observation is represented as a namedtuple with 3 fields ('key', 'value', 'attrib').\r\n\r\n        obs.key is a namedtuple of dimensions. Its field names represent dimension names,\r\n        its values the dimension values.\r\n\r\n        obs.value is a string that can in in most cases be interpreted as float64\r\n        obs.attrib is a namedtuple of attribute names and values.\r\n\r\n        with_values and with_attributes: If one or both of these flags\r\n        is False, the respective value will be None. Use these flags to\r\n        increase performance. The flags default to True.\r\n        '''\r\n        # distinguish between generic and structure-specific observations\r\n        # only generic ones are currently implemented.\r\n        return self._reader.iter_generic_obs(\r\n            self, with_values, with_attributes)", "response": "return an iterator over observations in a flat dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator over the generic series observations in a single object.", "response": "def obs(self, with_values=True, with_attributes=True, reverse_obs=False):\r\n        '''\r\n        return an iterator over observations in a series.\r\n        An observation is represented as a namedtuple with 3 fields ('key', 'value', 'attrib').\r\n        obs.key is a namedtuple of dimensions, obs.value is a string value and\r\n        obs.attrib is a namedtuple of attributes. If with_values or with_attributes\r\n        is False, the respective value is None. Use these flags to\r\n        increase performance. The flags default to True.\r\n        '''\r\n        return self._reader.iter_generic_series_obs(self,\r\n                                                    with_values, with_attributes, reverse_obs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, source=None, asframe=True, dtype=NP.float64,\r\n              attributes='', reverse_obs=False, fromfreq=False, parse_time=True):\r\n        '''Transfform a :class:`pandasdmx.model.DataMessage` instance to a pandas DataFrame\r\n        or iterator over pandas Series.\r\n\r\n        Args:\r\n            source(pandasdmx.model.DataMessage): a pandasdmx.model.DataSet or iterator \r\n                of pandasdmx.model.Series\r\n\r\n            asframe(bool): if True, merge the series of values and/or attributes\r\n                into one or two multi-indexed\r\n                pandas.DataFrame(s), otherwise return an iterator of pandas.Series.\r\n                (default: True)\r\n\r\n            dtype(str, NP.dtype, None): datatype for values. Defaults to NP.float64\r\n                if None, do not return the values of a series. In this case,\r\n                attributes must not be an empty string so that some attribute is returned.\r\n\r\n            attributes(str, None): string determining which attributes, if any,\r\n                should be returned in separate series or a separate DataFrame.\r\n                Allowed values: '', 'o', 's', 'g', 'd'\r\n                or any combination thereof such as 'os', 'go'. Defaults to 'osgd'.\r\n                Where 'o', 's', 'g', and 'd' mean that attributes at observation,\r\n                series, group and dataset level will be returned as members of\r\n                per-observation namedtuples.\r\n            reverse_obs(bool): if True, return observations in \r\n                reverse order. Default: False\r\n            fromfreq(bool): if True, extrapolate time periods \r\n                from the first item and FREQ dimension. Default: False\r\n            parse_time(bool): if True (default), try to generate datetime index, provided that\r\n                dim_at_obs is 'TIME' or 'TIME_PERIOD'. Otherwise, ``parse_time`` is ignored. If False,\r\n                always generate index of strings. \r\n                Set it to False to increase performance and avoid \r\n                parsing errors for exotic date-time formats unsupported by pandas.\r\n        '''\r\n\r\n        # Preparations\r\n        dim_at_obs = self.msg.header.dim_at_obs\r\n\r\n        # validate 'attributes'\r\n        if attributes is None or attributes == False:\r\n            attributes = ''\r\n        else:\r\n            try:\r\n                attributes = attributes.lower()\r\n            except AttributeError:\r\n                raise TypeError(\"'attributes' argument must be of type str.\")\r\n            if set(attributes) - {'o', 's', 'g', 'd'}:\r\n                raise ValueError(\r\n                    \"'attributes' must only contain 'o', 's', 'd' or 'g'.\")\r\n\r\n        # Allow source to be either an iterable or a model.DataSet instance\r\n        if hasattr(source, '__iter__'):\r\n            iter_series = source\r\n        elif hasattr(source, 'series'):\r\n            iter_series = source.series\r\n        elif hasattr(source, 'data') and dim_at_obs != 'AllDimensions':\r\n            iter_series = source.data.series\r\n\r\n        # Is 'data' a flat dataset with just a list of obs?\r\n        if dim_at_obs == 'AllDimensions':\r\n            obs_zip = iter(zip(*source.data.obs()))\r\n            dimensions = next(obs_zip)\r\n            idx = PD.MultiIndex.from_tuples(\r\n                dimensions, names=dimensions[0]._fields)\r\n            if dtype:\r\n                values_series = PD.Series(\r\n                    next(obs_zip), dtype=dtype, index=idx)\r\n            if attributes:\r\n                obs_attrib = NP.asarray(next(obs_zip), dtype='object')\r\n                attrib_series = PD.Series(\r\n                    obs_attrib, dtype='object', index=idx)\r\n            # Decide what to return\r\n            if dtype and attributes:\r\n                return values_series, attrib_series\r\n            elif dtype:\r\n                return values_series\r\n            elif attributes:\r\n                return attrib_series\r\n\r\n        # So dataset has series:\r\n        else:\r\n            if asframe:\r\n                series_list = list(s for s in self.iter_pd_series(\r\n                    iter_series, dim_at_obs, dtype, attributes,\r\n                    reverse_obs, fromfreq, parse_time))\r\n                if dtype and attributes:\r\n                    # series_list is actually a list of pairs of series\r\n                    # containing data and metadata respectively\r\n                    key_fields = series_list[0][0].name._fields\r\n                    pd_series, pd_attributes = zip(*series_list)\r\n                elif dtype:\r\n                    key_fields = series_list[0].name._fields\r\n                    pd_series = series_list\r\n                elif attributes:\r\n                    key_fields = series_list[0].name._fields\r\n                    pd_attributes = series_list\r\n\r\n                if dtype:\r\n                    # Merge series into multi-indexed DataFrame and return it.\r\n                    d_frame = PD.concat(list(pd_series), axis=1, copy=False)\r\n                    d_frame.columns.set_names(key_fields, inplace=True)\r\n\r\n                if attributes:\r\n                    a_frame = PD.concat(pd_attributes, axis=1, copy=False)\r\n                    a_frame.columns.set_names(key_fields, inplace=True)\r\n                # decide what to return\r\n                if dtype and attributes:\r\n                    return d_frame, a_frame\r\n                elif dtype:\r\n                    return d_frame\r\n                else:\r\n                    return a_frame\r\n\r\n            # return an iterator\r\n            else:\r\n                return self.iter_pd_series(iter_series, dim_at_obs, dtype,\r\n                                           attributes, reverse_obs, fromfreq, parse_time)", "response": "Transfform a pandas. DataFrame instance to a pandas. DataFrame or iterator over pandas. Series."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns dictLike of modelized elements with their id attribute set.", "response": "def read_identifiables(self, cls,  sdmxobj, offset=None):\r\n        '''\r\n        If sdmxobj inherits from dict: update it  with modelized elements.\r\n        These must be instances of model.IdentifiableArtefact,\r\n        i.e. have an 'id' attribute. This will be used as dict keys.\r\n        If sdmxobj does not inherit from dict: return a new DictLike.\r\n        '''\r\n        path = self._paths[cls]\r\n        if offset:\r\n            try:\r\n                base = self._paths[offset](sdmxobj._elem)[0]\r\n            except IndexError:\r\n                return None\r\n        else:\r\n            base = sdmxobj._elem\r\n        result = {e.get('id'): cls(self, e) for e in path(base)}\r\n        if isinstance(sdmxobj, dict):\r\n            sdmxobj.update(result)\r\n        else:\r\n            return DictLike(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading an instance of cls from the given SDMX object.", "response": "def read_instance(self, cls, sdmxobj, offset=None, first_only=True):\r\n        '''\r\n        If cls in _paths and matches,\r\n        return an instance of cls with the first XML element,\r\n        or, if first_only is False, a list of cls instances \r\n        for all elements found,\r\n        If no matches were found, return None.  \r\n        '''\r\n        if offset:\r\n            try:\r\n                base = self._paths[offset](sdmxobj._elem)[0]\r\n            except IndexError:\r\n                return None\r\n        else:\r\n            base = sdmxobj._elem\r\n        result = self._paths[cls](base)\r\n        if result:\r\n            if first_only:\r\n                return cls(self, result[0])\r\n            else:\r\n                return [cls(self, i) for i in result]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, source=None, rows=None, **kwargs):\r\n        '''\r\n        Transfform structural metadata, i.e. codelists, concept-schemes,\r\n        lists of dataflow definitions or category-schemes  \r\n        from a :class:`pandasdmx.model.StructureMessage` instance into a pandas DataFrame.\r\n        This method is called by :meth:`pandasdmx.api.Response.write` . It is not\r\n        part of the public-facing API. Yet, certain kwargs are \r\n        propagated from there.\r\n\r\n        Args:\r\n            source(pandasdmx.model.StructureMessage): a :class:`pandasdmx.model.StructureMessage` instance.\r\n\r\n            rows(str): sets the desired content \r\n                to be extracted from the StructureMessage.\r\n                Must be a name of an attribute of the StructureMessage. The attribute must\r\n                be an instance of `dict` whose keys are strings. These will be\r\n                interpreted as ID's and used for the MultiIndex of the DataFrame\r\n                to be returned. Values can be either instances of `dict` such as for codelists and categoryscheme, \r\n                or simple nameable objects\r\n                such as for dataflows. In the latter case, the DataFrame will have a flat index.  \r\n                (default: depends on content found in Message. \r\n                Common is 'codelist')\r\n            columns(str, list): if str, it denotes the attribute of attributes of the\r\n                values (nameable SDMX objects such as Code or ConceptScheme) that will be stored in the\r\n                DataFrame. If a list, it must contain strings\r\n                that are valid attibute values. Defaults to: ['name', 'description']\r\n            lang(str): locale identifier. Specifies the preferred \r\n                language for international strings such as names.\r\n                Default is 'en'.\r\n        '''\r\n\r\n        # Set convenient default values for args\r\n        # is rows a string?\r\n        if rows is not None and not isinstance(rows, (list, tuple)):\r\n            rows = [rows]\r\n            return_df = True\r\n        elif isinstance(rows, (list, tuple)) and len(rows) == 1:\r\n            return_df = True\r\n        else:\r\n            return_df = False\r\n        if rows is None:\r\n            rows = [i for i in self._row_content if hasattr(source, i)]\r\n        # Generate the DataFrame or -Frames and store them in a DictLike with\r\n        # content-type names as keys\r\n        frames = DictLike(\r\n            {r: self._make_dataframe(source, r, **kwargs) for r in rows})\r\n        if return_df:\r\n            # There is only one item. So return the only value.\r\n            return frames.any()\r\n        else:\r\n            return frames", "response": "Returns a pandas DataFrame containing the modified fields of a structure message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_agency_profile(cls, source):\n        '''\n        Classmethod loading metadata on a data provider. ``source`` must\n        be a json-formated string or file-like object describing one or more data providers\n        (URL of the SDMX web API, resource types etc.\n        The dict ``Request._agencies`` is updated with the metadata from the\n        source.\n\n        Returns None\n        '''\n        if not isinstance(source, str_type):\n            # so it must be a text file\n            source = source.read()\n        new_agencies = json.loads(source)\n        cls._agencies.update(new_agencies)", "response": "Load the agency profile from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an empty dataset with all possible series keys.", "response": "def series_keys(self, flow_id, cache=True):\n        '''\n        Get an empty dataset with all possible series keys.\n\n        Return a pandas DataFrame. Each\n        column represents a dimension, each row\n        a series key of datasets of \n        the given dataflow.\n        '''\n        # Check if requested series keys are already cached\n        cache_id = 'series_keys_' + flow_id\n        if cache_id in self.cache:\n            return self.cache[cache_id]\n        else:\n            # download an empty dataset with all available series keys\n            resp = self.data(flow_id, params={'detail': 'serieskeysonly'})\n            l = list(s.key for s in resp.data.series)\n            df = PD.DataFrame(l, columns=l[0]._fields, dtype='category')\n            if cache:\n                self.cache[cache_id] = df\n            return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets SDMX data or metadata and return it as a PandasDMX Response object.", "response": "def get(self, resource_type='', resource_id='', agency='',\n            version=None, key='',\n            params={}, headers={},\n            fromfile=None, tofile=None, url=None, get_footer_url=(30, 3),\n            memcache=None, writer=None):\n        '''get SDMX data or metadata and return it as a :class:`pandasdmx.api.Response` instance.\n\n        While 'get' can load any SDMX file (also as zip-file) specified by 'fromfile',\n        it can only construct URLs for the SDMX service set for this instance.\n        Hence, you have to instantiate a :class:`pandasdmx.api.Request` instance for each data provider you want to access, or\n        pass a pre-fabricated URL through the ``url`` parameter.\n\n        Args:\n            resource_type(str): the type of resource to be requested. Values must be\n                one of the items in Request._resources such as 'data', 'dataflow', 'categoryscheme' etc.\n                It is used for URL construction, not to read the received SDMX file.\n                Hence, if `fromfile` is given, `resource_type` may be ''.\n                Defaults to ''.\n            resource_id(str): the id of the resource to be requested.\n                It is used for URL construction. Defaults to ''.\n            agency(str): ID of the agency providing the data or metadata.\n                Used for URL construction only. It tells the SDMX web service\n                which agency the requested information originates from. Note that\n                an SDMX service may provide information from multiple data providers.\n                may be '' if `fromfile` is given. Not to be confused\n                with the agency ID passed to :meth:`__init__` which specifies\n                the SDMX web service to be accessed.\n            key(str, dict): select columns from a dataset by specifying dimension values.\n                If type is str, it must conform to the SDMX REST API, i.e. dot-separated dimension values.\n                If 'key' is of type 'dict', it must map dimension names to allowed dimension values. Two or more\n                values can be separated by '+' as in the str form. The DSD will be downloaded \n                and the items are validated against it before downloading the dataset.  \n            params(dict): defines the query part of the URL.\n                The SDMX web service guidelines (www.sdmx.org) explain the meaning of\n                permissible parameters. It can be used to restrict the\n                time range of the data to be delivered (startperiod, endperiod), whether parents, siblings or descendants of the specified\n                resource should be returned as well (e.g. references='parentsandsiblings'). Sensible defaults\n                are set automatically\n                depending on the values of other args such as `resource_type`.\n                Defaults to {}.\n            headers(dict): http headers. Given headers will overwrite instance-wide headers passed to the\n                constructor. Defaults to None, i.e. use defaults \n                from agency configuration\n            fromfile(str): path to the file to be loaded instead of\n                accessing an SDMX web service. Defaults to None. If `fromfile` is\n                given, args relating to URL construction will be ignored.\n            tofile(str): file path to write the received SDMX file on the fly. This\n                is useful if you want to load data offline using\n                `fromfile` or if you want to open an SDMX file in\n                an XML editor.\n            url(str): URL of the resource to download.\n                If given, any other arguments such as\n                ``resource_type`` or ``resource_id`` are ignored. Default is None.\n            get_footer_url((int, int)): \n                tuple of the form (seconds, number_of_attempts). Determines the\n                behavior in case the received SDMX message has a footer where\n                one of its lines is a valid URL. ``get_footer_url`` defines how many attempts should be made to\n                request the resource at that URL after waiting so many seconds before each attempt.\n                This behavior is useful when requesting large datasets from Eurostat. Other agencies do not seem to\n                send such footers. Once an attempt to get the resource has been \n                successful, the original message containing the footer is dismissed and the dataset\n                is returned. The ``tofile`` argument is propagated. Note that the written file may be\n                a zip archive. pandaSDMX handles zip archives since version 0.2.1. Defaults to (30, 3).\n            memcache(str): If given, return Response instance if already in self.cache(dict), \n            otherwise download resource and cache Response instance.             \n        writer(str): optional custom writer class. \n            Should inherit from pandasdmx.writer.BaseWriter. Defaults to None, \n            i.e. one of the included writers is selected as appropriate. \n\n        Returns:\n            pandasdmx.api.Response: instance containing the requested\n                SDMX Message.\n\n        '''\n        # Try to get resource from memory cache if specified\n        if memcache in self.cache:\n            return self.cache[memcache]\n\n        if url:\n            base_url = url\n        else:\n            # Construct URL from args unless ``tofile`` is given\n            # Validate args\n            agency = agency or self._agencies[self.agency]['id']\n            # Validate resource if no filename is specified\n            if not fromfile and resource_type not in self._resources:\n                raise ValueError(\n                    'resource must be one of {0}'.format(self._resources))\n            # resource_id: if it is not a str or unicode type,\n            # but, e.g., an invalid Dataflow Definition,\n            # extract its ID\n            if resource_id and not isinstance(resource_id, (str_type, str)):\n                resource_id = resource_id.id\n\n            # If key is a dict, validate items against the DSD\n            # and construct the key string which becomes part of the URL\n            # Otherwise, do nothing as key must be a str confirming to the REST\n            # API spec.\n            if resource_type == 'data' and isinstance(key, dict):\n                # select validation method based on agency capabilities\n                if self._agencies[self.agency].get('supports_series_keys_only'):\n                    key = self._make_key_from_series(resource_id, key)\n                else:\n                    key = self._make_key_from_dsd(resource_id, key)\n\n            # Get http headers from agency config if not given by the caller\n            if not (fromfile or headers):\n                # Check for default headers\n                resource_cfg = self._agencies[self.agency][\n                    'resources'].get(resource_type)\n                if resource_cfg:\n                    headers = resource_cfg.get('headers') or {}\n\n            # Construct URL from the given non-empty substrings.\n            # if data is requested, omit the agency part. See the query\n            # examples\n            if resource_type in ['data', 'categoryscheme']:\n                agency_id = None\n            else:\n                agency_id = agency\n            if (version is None) and (resource_type != 'data'):\n                version = 'latest'\n            # Remove None's and '' first. Then join them to form the base URL.\n            # Any parameters are appended by remote module.\n            if self.agency:\n                parts = [self._agencies[self.agency]['url'],\n                         resource_type,\n                         agency_id,\n                         resource_id, version, key]\n                base_url = '/'.join(filter(None, parts))\n\n                # Set references to sensible defaults\n                if 'references' not in params:\n                    if resource_type in [\n                            'dataflow', 'datastructure'] and resource_id:\n                        params['references'] = 'all'\n                    elif resource_type == 'categoryscheme':\n                        params['references'] = 'parentsandsiblings'\n\n            elif fromfile:\n                base_url = ''\n            else:\n                raise ValueError(\n                    'If `` url`` is not specified, either agency or fromfile must be given.')\n\n        # Now get the SDMX message either via http or as local file\n        logger.info(\n            'Requesting resource from URL/file %s', (base_url or fromfile))\n        source, url, resp_headers, status_code = self.client.get(\n            base_url, params=params, headers=headers, fromfile=fromfile)\n        if source is None:\n            raise SDMXException('Server error:', status_code, url)\n        logger.info(\n            'Loaded file into memory from URL/file: %s', (url or fromfile))\n        # write msg to file and unzip it as required, then parse it\n        with source:\n            if tofile:\n                logger.info('Writing to file %s', tofile)\n                with open(tofile, 'wb') as dest:\n                    source.seek(0)\n                    dest.write(source.read())\n                    source.seek(0)\n            # handle zip files\n            if is_zipfile(source):\n                temp = source\n                with ZipFile(temp, mode='r') as zf:\n                    info = zf.infolist()[0]\n                    source = zf.open(info)\n            else:\n                # undo side effect of is_zipfile\n                source.seek(0)\n            # select reader class\n            if ((fromfile and fromfile.endswith('.json'))\n                    or (self.agency and self._agencies[self.agency]['resources'].get(resource_type)\n                        and self._agencies[self.agency]['resources'][resource_type].get('json'))):\n                reader_module = import_module('pandasdmx.reader.sdmxjson')\n            else:\n                reader_module = import_module('pandasdmx.reader.sdmxml')\n            reader_cls = reader_module.Reader\n            msg = reader_cls(self).initialize(source)\n        # Check for URL in a footer and get the real data if so configured\n        if get_footer_url and hasattr(msg, 'footer'):\n            logger.info('Footer found in SDMX message.')\n            # Retrieve the first URL in the footer, if any\n            url_l = [\n                i for i in msg.footer.text if remote.is_url(i)]\n            if url_l:\n                # found an URL. Wait and try to request it\n                footer_url = url_l[0]\n                seconds, attempts = get_footer_url\n                logger.info(\n                    'Found URL in footer. Making %i requests, waiting %i seconds in between.', attempts, seconds)\n                for a in range(attempts):\n                    sleep(seconds)\n                    try:\n                        return self.get(tofile=tofile, url=footer_url, headers=headers)\n                    except Exception as e:\n                        logger.info(\n                            'Attempt #%i raised the following exeption: %s', a, str(e))\n        # Select default writer\n        if not writer:\n            if hasattr(msg, 'data'):\n                writer = 'pandasdmx.writer.data2pandas'\n            else:\n                writer = 'pandasdmx.writer.structure2pd'\n        r = Response(msg, url, resp_headers, status_code, writer=writer)\n        # store in memory cache if needed\n        if memcache and r.status_code == 200:\n            self.cache[memcache] = r\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_key_from_dsd(self, flow_id, key):\n        '''\n        Download the dataflow def. and DSD and validate \n        key(dict) against it. \n\n        Return: key(str)\n        '''\n        # get the dataflow and the DSD ID\n        dataflow = self.get('dataflow', flow_id,\n                            memcache='dataflow' + flow_id)\n        dsd_id = dataflow.msg.dataflow[flow_id].structure.id\n        dsd_resp = self.get('datastructure', dsd_id,\n                            memcache='datastructure' + dsd_id)\n        dsd = dsd_resp.msg.datastructure[dsd_id]\n        # Extract dimensions excluding the dimension at observation (time, time-period)\n        # as we are only interested in dimensions for columns, not rows.\n        dimensions = [d for d in dsd.dimensions.aslist() if d.id not in\n                      ['TIME', 'TIME_PERIOD']]\n        dim_names = [d.id for d in dimensions]\n        # Retrieve any ContentConstraint\n        try:\n            constraint_l = [c for c in dataflow.constraint.aslist()\n                            if c.constraint_attachment.id == flow_id]\n            if constraint_l:\n                constraint = constraint_l[0]\n        except:\n            constraint = None\n        # Validate the key dict\n        # First, check correctness of dimension names\n        invalid = [d for d in key.keys()\n                   if d not in dim_names]\n        if invalid:\n            raise ValueError(\n                'Invalid dimension name {0}, allowed are: {1}'.format(invalid, dim_names))\n        # Check for each dimension name if values are correct and construct\n        # string of the form 'value1.value2.value3+value4' etc.\n        parts = []\n        # Iterate over the dimensions. If the key dict\n        # contains a value for the dimension, append it to the 'parts' list. Otherwise\n        # append ''. Then join the parts to form the dotted str.\n        for d in dimensions:\n            try:\n                values = key[d.id]\n                values_l = values.split('+')\n                codelist = d.local_repr.enum\n                codes = codelist.keys()\n                invalid = [v for v in values_l if v not in codes]\n                if invalid:\n                    # ToDo: attach codelist to exception.\n                    raise ValueError(\"'{0}' is not in codelist for dimension '{1}: {2}'\".\n                                     format(invalid, d.id, codes))\n                # Check if values are in Contentconstraint if present\n                if constraint:\n                    try:\n                        invalid = [\n                            v for v in values_l if (d.id, v) not in constraint]\n                        if invalid:\n                            raise ValueError(\"'{0}' out of content_constraint for '{1}'.\".\n                                             format(invalid, d.id))\n                    except NotImplementedError:\n                        pass\n                part = values\n            except KeyError:\n                part = ''\n            parts.append(part)\n        return '.'.join(parts)", "response": "Get the key from the dataflow def and DSD and validate the key dict against it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a key from a series dictionary.", "response": "def _make_key_from_series(self, flow_id, key):\n        '''\n        Get all series keys by calling\n        self.series_keys, and validate \n        the key(dict) against it. Raises ValueError if\n        a value does not occur in the respective\n        set of dimension values. Multiple values per\n        dimension can be provided as a list or in 'V1+V2' notation.\n\n        Return: key(str) \n        '''\n        # get all series keys\n        all_keys = self.series_keys(flow_id)\n        dim_names = list(all_keys)\n        # Validate the key dict\n        # First, check correctness of dimension names\n        invalid = [d for d in key\n                   if d not in dim_names]\n        if invalid:\n            raise ValueError(\n                'Invalid dimension name {0}, allowed are: {1}'.format(invalid, dim_names))\n        # Pre-process key by expanding multiple values as list\n        key = {k: v.split('+') if '+' in v else v for k, v in key.items()}\n        # Check for each dimension name if values are correct and construct\n        # string of the form 'value1.value2.value3+value4' etc.\n        # First, wrap each single dim value in a list to allow\n        # uniform treatment of single and multiple dim values.\n        key_l = {k: [v] if isinstance(v, str_type) else v\n                 for k, v in key.items()}\n        # Iterate over the dimensions. If the key dict\n        # contains an allowed value for the dimension,\n        # it will become part of the string.\n        invalid = list(chain.from_iterable((((k, v) for v in vl if v not in all_keys[k].values)\n                                            for k, vl in key_l.items())))\n        if invalid:\n            raise ValueError(\"The following dimension values are invalid: {0}\".\n                             format(invalid))\n        # Generate the 'Val1+Val2' notation for multiple dim values and remove the\n        # lists\n        for k, v in key_l.items():\n            key_l[k] = '+'.join(v)\n        # assemble the key string which goes into the URL\n        parts = [key_l.get(name, '') for name in dim_names]\n        return '.'.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets keys or number of series for a prospective dataset query allowing for keys with multiple values per dimension. It downloads the complete list of series keys for a dataflow rather than using constraints and DSD. This feature is, however, not supported by all data providers. ECB and UNSD are known to work. Args: flow_id(str): dataflow id key(dict): optional key mapping dimension names to values or lists of values. Must have been validated before. It is not checked if key values are actually valid dimension names and values. Default: {} count(bool): if True (default), return the number of series of the dataset designated by flow_id and key. If False, the actual keys are returned as a pandas DataFrame or dict of dataframes, depending on the value of 'total'. total(bool): if True (default), return the aggregate number of series or a single dataframe (depending on the value of 'count'). If False, return a dict mapping keys to dataframes of series keys. E.g., if key={'COUNTRY':'IT+CA+AU'}, the dict will have 3 items describing the series keys for each country respectively. If 'count' is True, dict values will be int rather than PD.DataFrame.", "response": "def preview_data(self, flow_id, key=None, count=True, total=True):\n        '''\n        Get keys or number of series for a prospective dataset query allowing for\n        keys with multiple values per dimension.\n        It downloads the complete list of series keys for a dataflow rather than using constraints and DSD. This feature is,\n        however, not supported by all data providers.\n        ECB and UNSD are known to work.\n\n        Args:\n\n        flow_id(str): dataflow id\n\n        key(dict): optional key mapping dimension names to values or lists of values.\n            Must have been validated before. It is not checked if key values\n            are actually valid dimension names and values. Default: {}\n\n        count(bool): if True (default), return the number of series\n            of the dataset designated by flow_id and key. If False,\n            the actual keys are returned as a pandas DataFrame or dict of dataframes, depending on\n            the value of 'total'.\n\n        total(bool): if True (default), return the aggregate number\n            of series or a single dataframe (depending on the value of 'count'). If False,\n            return a dict mapping keys to dataframes of series keys.\n            E.g., if key={'COUNTRY':'IT+CA+AU'}, the dict will\n            have 3 items describing the series keys for each country\n            respectively. If 'count' is True, dict values will be int rather than\n            PD.DataFrame.\n        '''\n        all_keys = self.series_keys(flow_id)\n        # Handle the special case that no key is provided\n        if not key:\n            if count:\n                return all_keys.shape[0]\n            else:\n                return all_keys\n\n        # So there is a key specifying at least one dimension value.\n        # Wrap single values in 1-elem list for uniform treatment\n        key_l = {k: [v] if isinstance(v, str_type) else v\n                 for k, v in key.items()}\n        # order dim_names that are present in the key\n        dim_names = [k for k in all_keys if k in key]\n        # Drop columns that are not in the key\n        key_df = all_keys.loc[:, dim_names]\n        if total:\n            # DataFrame with matching series keys\n            bool_series = reduce(\n                and_, (key_df.isin(key_l)[col] for col in dim_names))\n            if count:\n                return bool_series.value_counts()[True]\n            else:\n                return all_keys[bool_series]\n        else:\n            # Dict of value combinations as dict keys\n            key_product = product(*(key_l[k] for k in dim_names))\n            # Replace key tuples by namedtuples\n            PartialKey = namedtuple_factory('PartialKey', dim_names)\n\n            matches = {PartialKey(k): reduce(and_, (key_df.isin({k1: [v1]\n                                                                 for k1, v1 in zip(dim_names, k)})[col]\n                                                    for col in dim_names))\n                       for k in key_product}\n\n            if not count:\n                # dict mapping each key to DataFrame with selected key-set\n                return {k: all_keys[v] for k, v in matches.items()}\n            else:\n                # Number of series per key\n                return {k: v.value_counts()[True] for k, v in matches.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, source=None, **kwargs):\n        '''Wrappe    r to call the writer's write method if present.\n\n        Args:\n            source(pandasdmx.model.Message, iterable): stuff to be written.\n                If a :class:`pandasdmx.model.Message` is given, the writer\n                itself must determine what to write unless specified in the\n                keyword arguments. If an iterable is given,\n                the writer should write each item. Keyword arguments may\n                specify what to do with the output depending on the writer's API. Defaults to self.msg.\n\n        Returns:\n            type: anything the writer returns.\n        '''\n\n        if not source:\n            source = self.msg\n        return self._writer.write(source=source, **kwargs)", "response": "Wrappe    r to call the writer s write method if present."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_json(path):\n    # type: (str) -> List[FunctionInfo]\n    \"\"\"Deserialize a JSON file containing runtime collected types.\n\n    The input JSON is expected to to have a list of RawEntry items.\n    \"\"\"\n    with open(path) as f:\n        data = json.load(f)  # type: List[RawEntry]\n    result = []\n\n    def assert_type(value, typ):\n        # type: (object, type) -> None\n        assert isinstance(value, typ), '%s: Unexpected type %r' % (path, type(value).__name__)\n\n    def assert_dict_item(dictionary, key, typ):\n        # type: (Mapping[Any, Any], str, type) -> None\n        assert key in dictionary, '%s: Missing dictionary key %r' % (path, key)\n        value = dictionary[key]\n        assert isinstance(value, typ), '%s: Unexpected type %r for key %r' % (\n            path, type(value).__name__, key)\n\n    assert_type(data, list)\n    for item in data:\n        assert_type(item, dict)\n        assert_dict_item(item, 'path', Text)\n        assert_dict_item(item, 'line', int)\n        assert_dict_item(item, 'func_name', Text)\n        assert_dict_item(item, 'type_comments', list)\n        for comment in item['type_comments']:\n            assert_type(comment, Text)\n        assert_type(item['samples'], int)\n        info = FunctionInfo(encode(item['path']),\n                            item['line'],\n                            encode(item['func_name']),\n                            [encode(comment) for comment in item['type_comments']],\n                            item['samples'])\n        result.append(info)\n    return result", "response": "Deserialize a JSON file containing runtime collected types."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntranslates a type comment into a list of tokens.", "response": "def tokenize(s):\n    # type: (str) -> List[Token]\n    \"\"\"Translate a type comment into a list of tokens.\"\"\"\n    original = s\n    tokens = []  # type: List[Token]\n    while True:\n        if not s:\n            tokens.append(End())\n            return tokens\n        elif s[0] == ' ':\n            s = s[1:]\n        elif s[0] in '()[],*':\n            tokens.append(Separator(s[0]))\n            s = s[1:]\n        elif s[:2] == '->':\n            tokens.append(Separator('->'))\n            s = s[2:]\n        else:\n            m = re.match(r'[-\\w]+(\\s*(\\.|:)\\s*[-/\\w]*)*', s)\n            if not m:\n                raise ParseError(original)\n            fullname = m.group(0)\n            fullname = fullname.replace(' ', '')\n            if fullname in TYPE_FIXUPS:\n                fullname = TYPE_FIXUPS[fullname]\n            # pytz creates classes with the name of the timezone being used:\n            # https://github.com/stub42/pytz/blob/f55399cddbef67c56db1b83e0939ecc1e276cf42/src/pytz/tzfile.py#L120-L123\n            # This causes pyannotates to crash as it's invalid to have a class\n            # name with a `/` in it (e.g. \"pytz.tzfile.America/Los_Angeles\")\n            if fullname.startswith('pytz.tzfile.'):\n                fullname = 'datetime.tzinfo'\n            if '-' in fullname or '/' in fullname:\n                # Not a valid Python name; there are many places that\n                # generate these, so we just substitute Any rather\n                # than crashing.\n                fullname = 'Any'\n            tokens.append(DottedName(fullname))\n            s = s[len(m.group(0)):]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproducing annotation data JSON file from a JSON file with runtime - collected types.", "response": "def generate_annotations_json_string(source_path, only_simple=False):\n    # type: (str, bool) -> List[FunctionData]\n    \"\"\"Produce annotation data JSON file from a JSON file with runtime-collected types.\n\n    Data formats:\n\n    * The source JSON is a list of pyannotate_tools.annotations.parse.RawEntry items.\n    * The output JSON is a list of FunctionData items.\n    \"\"\"\n    items = parse_json(source_path)\n    results = []\n    for item in items:\n        signature = unify_type_comments(item.type_comments)\n        if is_signature_simple(signature) or not only_simple:\n            data = {\n                'path': item.path,\n                'line': item.line,\n                'func_name': item.func_name,\n                'signature': signature,\n                'samples': item.samples\n            }  # type: FunctionData\n            results.append(data)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_annotations_json(source_path, target_path, only_simple=False):\n    # type: (str, str, bool) -> None\n    \"\"\"Like generate_annotations_json_string() but writes JSON to a file.\"\"\"\n    results = generate_annotations_json_string(source_path, only_simple=only_simple)\n    with open(target_path, 'w') as f:\n        json.dump(results, f, sort_keys=True, indent=4)", "response": "Like generate_annotations_json_string but writes JSON to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef name_from_type(type_):\n    # type: (InternalType) -> str\n    \"\"\"\n    Helper function to get PEP-484 compatible string representation of our internal types.\n    \"\"\"\n    if isinstance(type_, (DictType, ListType, TupleType, SetType, IteratorType)):\n        return repr(type_)\n    else:\n        if type_.__name__ != 'NoneType':\n            module = type_.__module__\n            if module in BUILTIN_MODULES or module == '<unknown>':\n                # Omit module prefix for known built-ins, for convenience. This\n                # makes unit tests for this module simpler.\n                # Also ignore '<uknown>' modules so pyannotate can parse these types\n                return type_.__name__\n            else:\n                name = getattr(type_, '__qualname__', None) or type_.__name__\n                delim = '.' if '.' not in name else ':'\n                return '%s%s%s' % (module, delim, name)\n        else:\n            return 'None'", "response": "Returns a PEP - 484 compatible string representation of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_function_name_from_frame(frame):\n    # type: (Any) -> str\n    \"\"\"\n    Heuristic to find the class-specified name by @guido\n\n    For instance methods we return \"ClassName.method_name\"\n    For functions we return \"function_name\"\n    \"\"\"\n\n    def bases_to_mro(cls, bases):\n        # type: (type, List[type]) -> List[type]\n        \"\"\"\n        Convert __bases__ to __mro__\n        \"\"\"\n        mro = [cls]\n        for base in bases:\n            if base not in mro:\n                mro.append(base)\n            sub_bases = getattr(base, '__bases__', None)\n            if sub_bases:\n                sub_bases = [sb for sb in sub_bases if sb not in mro and sb not in bases]\n                if sub_bases:\n                    mro.extend(bases_to_mro(base, sub_bases))\n        return mro\n\n    code = frame.f_code\n    # This ought to be aggressively cached with the code object as key.\n    funcname = code.co_name\n    if code.co_varnames:\n        varname = code.co_varnames[0]\n        if varname == 'self':\n            inst = frame.f_locals.get(varname)\n            if inst is not None:\n                try:\n                    mro = inst.__class__.__mro__\n                except AttributeError:\n                    mro = None\n                    try:\n                        bases = inst.__class__.__bases__\n                    except AttributeError:\n                        bases = None\n                    else:\n                        mro = bases_to_mro(inst.__class__, bases)\n                if mro:\n                    for cls in mro:\n                        bare_method = cls.__dict__.get(funcname)\n                        if bare_method and getattr(bare_method, '__code__', None) is code:\n                            return '%s.%s' % (cls.__name__, funcname)\n    return funcname", "response": "This function returns the name of the function in the given frame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve object to one of our internal collection types or generic built - in type.", "response": "def resolve_type(arg):\n    # type: (object) -> InternalType\n    \"\"\"\n    Resolve object to one of our internal collection types or generic built-in type.\n\n    Args:\n        arg: object to resolve\n    \"\"\"\n    arg_type = type(arg)\n    if arg_type == list:\n        assert isinstance(arg, list)  # this line helps mypy figure out types\n        sample = arg[:min(4, len(arg))]\n        tentative_type = TentativeType()\n        for sample_item in sample:\n            tentative_type.add(resolve_type(sample_item))\n        return ListType(tentative_type)\n    elif arg_type == set:\n        assert isinstance(arg, set)  # this line helps mypy figure out types\n        sample = []\n        iterator = iter(arg)\n        for i in range(0, min(4, len(arg))):\n            sample.append(next(iterator))\n        tentative_type = TentativeType()\n        for sample_item in sample:\n            tentative_type.add(resolve_type(sample_item))\n        return SetType(tentative_type)\n    elif arg_type == FakeIterator:\n        assert isinstance(arg, FakeIterator)  # this line helps mypy figure out types\n        sample = []\n        iterator = iter(arg)\n        for i in range(0, min(4, len(arg))):\n            sample.append(next(iterator))\n        tentative_type = TentativeType()\n        for sample_item in sample:\n            tentative_type.add(resolve_type(sample_item))\n        return IteratorType(tentative_type)\n    elif arg_type == tuple:\n        assert isinstance(arg, tuple)  # this line helps mypy figure out types\n        sample = list(arg[:min(10, len(arg))])\n        return TupleType([resolve_type(sample_item) for sample_item in sample])\n    elif arg_type == dict:\n        assert isinstance(arg, dict)  # this line helps mypy figure out types\n        key_tt = TentativeType()\n        val_tt = TentativeType()\n        for i, (k, v) in enumerate(iteritems(arg)):\n            if i > 4:\n                break\n            key_tt.add(resolve_type(k))\n            val_tt.add(resolve_type(v))\n        return DictType(key_tt, val_tt)\n    else:\n        return type(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prep_args(arg_info):\n    # type: (ArgInfo) -> ResolvedTypes\n    \"\"\"\n    Resolve types from ArgInfo\n    \"\"\"\n\n    # pull out any varargs declarations\n    filtered_args = [a for a in arg_info.args if getattr(arg_info, 'varargs', None) != a]\n\n    # we don't care about self/cls first params (perhaps we can test if it's an instance/class method another way?)\n    if filtered_args and (filtered_args[0] in ('self', 'cls')):\n        filtered_args = filtered_args[1:]\n\n    pos_args = []  # type: List[InternalType]\n    if filtered_args:\n        for arg in filtered_args:\n            if isinstance(arg, str) and arg in arg_info.locals:\n                # here we know that return type will be of type \"type\"\n                resolved_type = resolve_type(arg_info.locals[arg])\n                pos_args.append(resolved_type)\n            else:\n                pos_args.append(type(UnknownType()))\n\n    varargs = None  # type: Optional[List[InternalType]]\n    if arg_info.varargs:\n        varargs_tuple = arg_info.locals[arg_info.varargs]\n        # It's unclear what all the possible values for 'varargs_tuple' are,\n        # so perform a defensive type check since we don't want to crash here.\n        if isinstance(varargs_tuple, tuple):\n            varargs = [resolve_type(arg) for arg in varargs_tuple[:4]]\n\n    return ResolvedTypes(pos_args=pos_args, varargs=varargs)", "response": "Resolve types from ArgInfo\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a type comment of form arg ret", "response": "def _make_type_comment(args_info, return_type):\n    # type: (ArgTypes, InternalType) -> str\n    \"\"\"Generate a type comment of form '(arg, ...) -> ret'.\"\"\"\n    if not args_info.pos_args:\n        args_string = ''\n    else:\n        args_string = ', '.join([repr(t) for t in args_info.pos_args])\n    if args_info.varargs:\n        varargs = '*%s' % repr(args_info.varargs)\n        if args_string:\n            args_string += ', %s' % varargs\n        else:\n            args_string = varargs\n    return_name = name_from_type(return_type)\n    return '(%s) -> %s' % (args_string, return_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flush_signature(key, return_type):\n    # type: (FunctionKey, InternalType) -> None\n    \"\"\"Store signature for a function.\n\n    Assume that argument types have been stored previously to\n    'collected_args'. As the 'return_type' argument provides the return\n    type, we now have a complete signature.\n\n    As a side effect, removes the argument types for the function from\n    'collected_args'.\n    \"\"\"\n    signatures = collected_signatures.setdefault(key, set())\n    args_info = collected_args.pop(key)\n    if len(signatures) < MAX_ITEMS_PER_FUNCTION:\n        signatures.add((args_info, return_type))\n    num_samples[key] = num_samples.get(key, 0) + 1", "response": "Store the signature for a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list containing the proposed call event sampling sequence.", "response": "def _make_sampling_sequence(n):\n    # type: (int) -> List[int]\n    \"\"\"\n    Return a list containing the proposed call event sampling sequence.\n\n    Return events are paired with call events and not counted separately.\n\n    This is 0, 1, 2, ..., 4 plus 50, 100, 150, 200, etc.\n\n    The total list size is n.\n    \"\"\"\n    seq = list(range(5))\n    i = 50\n    while len(seq) < n:\n        seq.append(i)\n        i += 50\n    return seq"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefault filter for filenames.", "response": "def default_filter_filename(filename):\n    # type: (Optional[str]) -> Optional[str]\n    \"\"\"Default filter for filenames.\n\n    Returns either a normalized filename or None.\n    You can pass your own filter to init_types_collection().\n    \"\"\"\n    if filename is None:\n        return None\n    elif filename.startswith(TOP_DIR):\n        if filename.startswith(TOP_DIR_DOT):\n            # Skip subdirectories starting with dot (e.g. .vagrant).\n            return None\n        else:\n            # Strip current directory and following slashes.\n            return filename[TOP_DIR_LEN:].lstrip(os.sep)\n    elif filename.startswith(os.sep):\n        # Skip absolute paths not under current directory.\n        return None\n    else:\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _filter_types(types_dict):\n    # type: (Dict[FunctionKey, T]) -> Dict[FunctionKey, T]\n    \"\"\"Filter type info before dumping it to the file.\"\"\"\n\n    def exclude(k):\n        # type: (FunctionKey) -> bool\n        \"\"\"Exclude filter\"\"\"\n        return k.path.startswith('<') or k.func_name == '<module>'\n\n    return {k: v for k, v in iteritems(types_dict) if not exclude(k)}", "response": "Filter types info before dumping it to the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump_stats(filename):\n    # type: (str) -> None\n    \"\"\"\n    Write collected information to file.\n\n    Args:\n        filename: absolute filename\n    \"\"\"\n    res = _dump_impl()\n    f = open(filename, 'w')\n    json.dump(res, f, indent=4)\n    f.close()", "response": "Write collected information to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing profiler hooks to enable type collection.", "response": "def init_types_collection(filter_filename=default_filter_filename):\n    # type: (Callable[[Optional[str]], Optional[str]]) -> None\n    \"\"\"\n    Setup profiler hooks to enable type collection.\n    Call this one time from the main thread.\n\n    The optional argument is a filter that maps a filename (from\n    code.co_filename) to either a normalized filename or None.\n    For the default filter see default_filter_filename().\n    \"\"\"\n    global _filter_filename\n    _filter_filename = filter_filename\n    sys.setprofile(_trace_dispatch)\n    threading.setprofile(_trace_dispatch)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd type to the runtime type samples.", "response": "def add(self, type):\n        # type: (InternalType) -> None\n        \"\"\"\n        Add type to the runtime type samples.\n        \"\"\"\n        try:\n            if isinstance(type, SetType):\n                if EMPTY_SET_TYPE in self.types_hashable:\n                    self.types_hashable.remove(EMPTY_SET_TYPE)\n            elif isinstance(type, ListType):\n                if EMPTY_LIST_TYPE in self.types_hashable:\n                    self.types_hashable.remove(EMPTY_LIST_TYPE)\n            elif isinstance(type, IteratorType):\n                if EMPTY_ITERATOR_TYPE in self.types_hashable:\n                    self.types_hashable.remove(EMPTY_ITERATOR_TYPE)\n            elif isinstance(type, DictType):\n                if EMPTY_DICT_TYPE in self.types_hashable:\n                    self.types_hashable.remove(EMPTY_DICT_TYPE)\n                for item in self.types_hashable:\n                    if isinstance(item, DictType):\n                        if item.key_type == type.key_type:\n                            item.val_type.merge(type.val_type)\n                            return\n            self.types_hashable.add(type)\n\n        except (TypeError, AttributeError):\n            try:\n                if type not in self.types:\n                    self.types.append(type)\n            except AttributeError:\n                if TypeWasIncomparable not in self.types:\n                    self.types.append(TypeWasIncomparable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges two TentativeTypes instances into this set.", "response": "def merge(self, other):\n        # type: (TentativeType) -> None\n        \"\"\"\n        Merge two TentativeType instances\n        \"\"\"\n        for hashables in other.types_hashable:\n            self.add(hashables)\n        for non_hashbles in other.types:\n            self.add(non_hashbles)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive some type comments return a single inferred signature.", "response": "def infer_annotation(type_comments):\n    # type: (List[str]) -> Tuple[List[Argument], AbstractType]\n    \"\"\"Given some type comments, return a single inferred signature.\n\n    Args:\n        type_comments: Strings of form '(arg1, ... argN) -> ret'\n\n    Returns: Tuple of (argument types and kinds, return type).\n    \"\"\"\n    assert type_comments\n    args = {}  # type: Dict[int, Set[Argument]]\n    returns = set()\n    for comment in type_comments:\n        arg_types, return_type = parse_type_comment(comment)\n        for i, arg_type in enumerate(arg_types):\n            args.setdefault(i, set()).add(arg_type)\n        returns.add(return_type)\n    combined_args = []\n    for i in sorted(args):\n        arg_infos = list(args[i])\n        kind = argument_kind(arg_infos)\n        if kind is None:\n            raise InferError('Ambiguous argument kinds:\\n' + '\\n'.join(type_comments))\n        types = [arg.type for arg in arg_infos]\n        combined = combine_types(types)\n        if str(combined) == 'None':\n            # It's very rare for an argument to actually be typed `None`, more likely than\n            # not we simply don't have any data points for this argument.\n            combined = UnionType([ClassType('None'), AnyType()])\n        if kind != ARG_POS and (len(str(combined)) > 120 or isinstance(combined, UnionType)):\n            # Avoid some noise.\n            combined = AnyType()\n        combined_args.append(Argument(combined, kind))\n    combined_return = combine_types(returns)\n    return combined_args, combined_return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef argument_kind(args):\n    # type: (List[Argument]) -> Optional[str]\n    \"\"\"Return the kind of an argument, based on one or more descriptions of the argument.\n\n    Return None if every item does not have the same kind.\n    \"\"\"\n    kinds = set(arg.kind for arg in args)\n    if len(kinds) != 1:\n        return None\n    return kinds.pop()", "response": "Returns the kind of an argument based on one or more descriptions of the argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving some types return a combined and simplified type.", "response": "def combine_types(types):\n    # type: (Iterable[AbstractType]) -> AbstractType\n    \"\"\"Given some types, return a combined and simplified type.\n\n    For example, if given 'int' and 'List[int]', return Union[int, List[int]]. If given\n    'int' and 'int', return just 'int'.\n    \"\"\"\n    items = simplify_types(types)\n    if len(items) == 1:\n        return items[0]\n    else:\n        return UnionType(items)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives some types give simplified types representing the union of types.", "response": "def simplify_types(types):\n    # type: (Iterable[AbstractType]) -> List[AbstractType]\n    \"\"\"Given some types, give simplified types representing the union of types.\"\"\"\n    flattened = flatten_types(types)\n    items = filter_ignored_items(flattened)\n    items = [simplify_recursive(item) for item in items]\n    items = merge_items(items)\n    items = dedupe_types(items)\n    # We have to remove reundant items after everything has been simplified and\n    # merged as this simplification may be what makes items redundant.\n    items = remove_redundant_items(items)\n    if len(items) > 3:\n        return [AnyType()]\n    else:\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimplify all components of a type.", "response": "def simplify_recursive(typ):\n    # type: (AbstractType) -> AbstractType\n    \"\"\"Simplify all components of a type.\"\"\"\n    if isinstance(typ, UnionType):\n        return combine_types(typ.items)\n    elif isinstance(typ, ClassType):\n        simplified = ClassType(typ.name, [simplify_recursive(arg) for arg in typ.args])\n        args = simplified.args\n        if (simplified.name == 'Dict' and len(args) == 2\n                and isinstance(args[0], ClassType) and args[0].name in ('str', 'Text')\n                and isinstance(args[1], UnionType) and not is_optional(args[1])):\n            # Looks like a potential case for TypedDict, which we don't properly support yet.\n            return ClassType('Dict', [args[0], AnyType()])\n        return simplified\n    elif isinstance(typ, TupleType):\n        return TupleType([simplify_recursive(item) for item in typ.items])\n    return typ"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_redundant_items(items):\n    # type: (List[AbstractType]) -> List[AbstractType]\n    \"\"\"Filter out redundant union items.\"\"\"\n    result = []\n    for item in items:\n        for other in items:\n            if item is not other and is_redundant_union_item(item, other):\n                break\n        else:\n            result.append(item)\n    return result", "response": "Filter out redundant union items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_redundant_union_item(first, other):\n    # type: (AbstractType, AbstractType) -> bool\n    \"\"\"If union has both items, is the first one redundant?\n\n    For example, if first is 'str' and the other is 'Text', return True.\n\n    If items are equal, return False.\n    \"\"\"\n    if isinstance(first, ClassType) and isinstance(other, ClassType):\n        if first.name == 'str' and other.name == 'Text':\n            return True\n        elif first.name == 'bool' and other.name == 'int':\n            return True\n        elif first.name == 'int' and other.name == 'float':\n            return True\n        elif (first.name in ('List', 'Dict', 'Set') and\n                  other.name == first.name):\n            if not first.args and other.args:\n                return True\n            elif len(first.args) == len(other.args) and first.args:\n                result = all(first_arg == other_arg or other_arg == AnyType()\n                             for first_arg, other_arg\n                             in zip(first.args, other.args))\n                return result\n\n    return False", "response": "Returns True if union has both items and other."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge union items that can be merged.", "response": "def merge_items(items):\n    # type: (List[AbstractType]) -> List[AbstractType]\n    \"\"\"Merge union items that can be merged.\"\"\"\n    result = []\n    while items:\n        item = items.pop()\n        merged = None\n        for i, other in enumerate(items):\n            merged = merged_type(item, other)\n            if merged:\n                break\n        if merged:\n            del items[i]\n            items.append(merged)\n        else:\n            result.append(item)\n    return list(reversed(result))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merged_type(t, s):\n    # type: (AbstractType, AbstractType) -> Optional[AbstractType]\n    \"\"\"Return merged type if two items can be merged in to a different, more general type.\n\n    Return None if merging is not possible.\n    \"\"\"\n    if isinstance(t, TupleType) and isinstance(s, TupleType):\n        if len(t.items) == len(s.items):\n            return TupleType([combine_types([ti, si]) for ti, si in zip(t.items, s.items)])\n        all_items = t.items + s.items\n        if all_items and all(item == all_items[0] for item in all_items[1:]):\n            # Merge multiple compatible fixed-length tuples into a variable-length tuple type.\n            return ClassType('Tuple', [all_items[0]])\n    elif (isinstance(t, TupleType) and isinstance(s, ClassType) and s.name == 'Tuple'\n          and len(s.args) == 1):\n        if all(item == s.args[0] for item in t.items):\n            # Merge fixed-length tuple and variable-length tuple.\n            return s\n    elif isinstance(s, TupleType) and isinstance(t, ClassType) and t.name == 'Tuple':\n        return merged_type(s, t)\n    elif isinstance(s, NoReturnType):\n        return t\n    elif isinstance(t, NoReturnType):\n        return s\n    elif isinstance(s, AnyType):\n        # This seems to be usually desirable, since Anys tend to come from unknown types.\n        return t\n    elif isinstance(t, AnyType):\n        # Similar to above.\n        return s\n    return None", "response": "Returns the type that can be merged in to a different type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump annotations out of type_info filtered by files.", "response": "def dump_annotations(type_info, files):\n    \"\"\"Dump annotations out of type_info, filtered by files.\n\n    If files is non-empty, only dump items either if the path in the\n    item matches one of the files exactly, or else if one of the files\n    is a path prefix of the path.\n    \"\"\"\n    with open(type_info) as f:\n        data = json.load(f)\n    for item in data:\n        path, line, func_name = item['path'], item['line'], item['func_name']\n        if files and path not in files:\n            for f in files:\n                if path.startswith(os.path.join(f, '')):\n                    break\n            else:\n                continue  # Outer loop\n        print(\"%s:%d: in %s:\" % (path, line, func_name))\n        type_comments = item['type_comments']\n        signature = unify_type_comments(type_comments)\n        arg_types = signature['arg_types']\n        return_type = signature['return_type']\n        print(\"    # type: (%s) -> %s\" % (\", \".join(arg_types), return_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef crawl_up(arg):\n    # type: (str) -> Tuple[str, str]\n    \"\"\"Given a .py[i] filename, return (root directory, module).\n    We crawl up the path until we find a directory without\n    __init__.py[i], or until we run out of path components.\n    \"\"\"\n    dir, mod = os.path.split(arg)\n    mod = strip_py(mod) or mod\n    while dir and get_init_file(dir):\n        dir, base = os.path.split(dir)\n        if not base:\n            break\n        if mod == '__init__' or not mod:\n            mod = base\n        else:\n            mod = base + '.' + mod\n    return dir, mod", "response": "Given a. py file return a root directory and module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_py(arg):\n    # type: (str) -> Optional[str]\n    \"\"\"Strip a trailing .py or .pyi suffix.\n    Return None if no such suffix is found.\n    \"\"\"\n    for ext in PY_EXTENSIONS:\n        if arg.endswith(ext):\n            return arg[:-len(ext)]\n    return None", "response": "Strip a trailing. py or. pyi suffix. Return None if no such suffix is found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_init_file(dir):\n    # type: (str) -> Optional[str]\n    \"\"\"Check whether a directory contains a file named __init__.py[i].\n    If so, return the file's name (with dir prefixed).  If not, return\n    None.\n    This prefers .pyi over .py (because of the ordering of PY_EXTENSIONS).\n    \"\"\"\n    for ext in PY_EXTENSIONS:\n        f = os.path.join(dir, '__init__' + ext)\n        if os.path.isfile(f):\n            return f\n    return None", "response": "Checks whether a directory contains a file named __init__. py [ i ].\n    If so return the file s name with dir prefixed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_funcname(name, node):\n    # type: (Leaf, Node) -> Text\n    \"\"\"Get function name by the following rules:\n\n    - function -> function_name\n    - instance method -> ClassName.function_name\n    \"\"\"\n    funcname = name.value\n    if node.parent and node.parent.parent:\n        grand = node.parent.parent\n        if grand.type == syms.classdef:\n            grandname = grand.children[1]\n            assert grandname.type == token.NAME, repr(name)\n            assert isinstance(grandname, Leaf)  # Same as previous, for mypy\n            funcname = grandname.value + '.' + funcname\n    return funcname", "response": "Get function name by the following rules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_args(node, results):\n    # type: (Node, Dict[str, Base]) -> Tuple[int, bool, bool, bool]\n    \"\"\"Count arguments and check for self and *args, **kwds.\n\n    Return (selfish, count, star, starstar) where:\n    - count is total number of args (including *args, **kwds)\n    - selfish is True if the initial arg is named 'self' or 'cls'\n    - star is True iff *args is found\n    - starstar is True iff **kwds is found\n    \"\"\"\n    count = 0\n    selfish = False\n    star = False\n    starstar = False\n    args = results.get('args')\n    if isinstance(args, Node):\n        children = args.children\n    elif isinstance(args, Leaf):\n        children = [args]\n    else:\n        children = []\n    # Interpret children according to the following grammar:\n    # (('*'|'**')? NAME ['=' expr] ','?)*\n    skip = False\n    previous_token_is_star = False\n    for child in children:\n        if skip:\n            skip = False\n        elif isinstance(child, Leaf):\n            # A single '*' indicates the rest of the arguments are keyword only\n            # and shouldn't be counted as a `*`.\n            if child.type == token.STAR:\n                previous_token_is_star = True\n            elif child.type == token.DOUBLESTAR:\n                starstar = True\n            elif child.type == token.NAME:\n                if count == 0:\n                    if child.value in ('self', 'cls'):\n                        selfish = True\n                count += 1\n                if previous_token_is_star:\n                    star = True\n            elif child.type == token.EQUAL:\n                skip = True\n            if child.type != token.STAR:\n                previous_token_is_star = False\n    return count, selfish, star, starstar", "response": "Count the number of arguments and check for self and star and starstar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_decorators(self, node):\n        if node.parent is None:\n            return []\n        results = {}\n        if not self.decorated.match(node.parent, results):\n            return []\n        decorators = results.get('dd') or [results['d']]\n        decs = []\n        for d in decorators:\n            for child in d.children:\n                if isinstance(child, Leaf) and child.type == token.NAME:\n                    decs.append(child.value)\n        return decs", "response": "Return a list of decorators found on a function definition."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn whether the node occurs directly inside a class or function.", "response": "def is_method(self, node):\n        \"\"\"Return whether the node occurs (directly) inside a class.\"\"\"\n        node = node.parent\n        while node is not None:\n            if node.type == syms.classdef:\n                return True\n            if node.type == syms.funcdef:\n                return False\n            node = node.parent\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the tree below node looking for return expr.", "response": "def has_return_exprs(self, node):\n        \"\"\"Traverse the tree below node looking for 'return expr'.\n\n        Return True if at least 'return expr' is found, False if not.\n        (If both 'return' and 'return expr' are found, return True.)\n        \"\"\"\n        results = {}\n        if self.return_expr.match(node, results):\n            return True\n        for child in node.children:\n            if child.type not in (syms.funcdef, syms.classdef):\n                if self.has_return_exprs(child):\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_generator(self, node):\n        results = {}\n        if self.yield_expr.match(node, results):\n            return True\n        for child in node.children:\n            if child.type not in (syms.funcdef, syms.classdef):\n                if self.is_generator(child):\n                    return True\n        return False", "response": "Traverse the tree below node looking for yield expr."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inform_if_paths_invalid(egrc_path, examples_dir, custom_dir, debug=True):\n    if (not debug):\n        return\n\n    if (egrc_path):\n        _inform_if_path_does_not_exist(egrc_path)\n\n    if (examples_dir):\n        _inform_if_path_does_not_exist(examples_dir)\n\n    if (custom_dir):\n        _inform_if_path_does_not_exist(custom_dir)", "response": "Informs the user that a path is not set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Config namedtuple based on the contents of the egrc.", "response": "def get_egrc_config(cli_egrc_path):\n    \"\"\"\n    Return a Config namedtuple based on the contents of the egrc.\n\n    If the egrc is not present, it returns an empty default Config.\n\n    This method tries to use the egrc at cli_egrc_path, then the default path.\n\n    cli_egrc_path: the path to the egrc as given on the command line via\n        --config-file\n    \"\"\"\n    resolved_path = get_priority(cli_egrc_path, DEFAULT_EGRC_PATH, None)\n    expanded_path = get_expanded_path(resolved_path)\n\n    # Start as if nothing was defined in the egrc.\n    egrc_config = get_empty_config()\n\n    if os.path.isfile(expanded_path):\n        egrc_config = get_config_tuple_from_egrc(expanded_path)\n\n    return egrc_config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a Config namedtuple that is correct for the passed in arguments.", "response": "def get_resolved_config(\n    egrc_path,\n    examples_dir,\n    custom_dir,\n    use_color,\n    pager_cmd,\n    squeeze,\n    debug=True,\n):\n    \"\"\"\n    Create a Config namedtuple. Passed in values will override defaults.\n\n    This function is responsible for producing a Config that is correct for the\n    passed in arguments. In general, it prefers first command line options,\n    then values from the egrc, and finally defaults.\n\n    examples_dir and custom_dir when returned from this function are fully\n    expanded.\n    \"\"\"\n    # Call this with the passed in values, NOT the resolved values. We are\n    # informing the caller only if values passed in at the command line are\n    # invalid. If you pass a path to a nonexistent egrc, for example, it's\n    # helpful to know. If you don't have an egrc, and thus one isn't found\n    # later at the default location, we don't want to notify them.\n    inform_if_paths_invalid(egrc_path, examples_dir, custom_dir)\n\n    # Expand the paths so we can use them with impunity later.\n    examples_dir = get_expanded_path(examples_dir)\n    custom_dir = get_expanded_path(custom_dir)\n\n    # The general rule is: caller-defined, egrc-defined, defaults. We'll try\n    # and get all three then use get_priority to choose the right one.\n\n    egrc_config = get_egrc_config(egrc_path)\n\n    resolved_examples_dir = get_priority(\n        examples_dir,\n        egrc_config.examples_dir,\n        DEFAULT_EXAMPLES_DIR\n    )\n    resolved_examples_dir = get_expanded_path(resolved_examples_dir)\n\n    resolved_custom_dir = get_priority(\n        custom_dir,\n        egrc_config.custom_dir,\n        DEFAULT_CUSTOM_DIR\n    )\n    resolved_custom_dir = get_expanded_path(resolved_custom_dir)\n\n    resolved_use_color = get_priority(\n        use_color,\n        egrc_config.use_color,\n        DEFAULT_USE_COLOR\n    )\n\n    resolved_pager_cmd = get_priority(\n        pager_cmd,\n        egrc_config.pager_cmd,\n        DEFAULT_PAGER_CMD\n    )\n\n    # There is no command line option for this, so in this case we will use the\n    # priority: egrc, environment, DEFAULT.\n    environment_editor_cmd = get_editor_cmd_from_environment()\n    resolved_editor_cmd = get_priority(\n        egrc_config.editor_cmd,\n        environment_editor_cmd,\n        DEFAULT_EDITOR_CMD\n    )\n\n    color_config = None\n    if resolved_use_color:\n        default_color_config = get_default_color_config()\n        color_config = merge_color_configs(\n            egrc_config.color_config,\n            default_color_config\n        )\n\n    resolved_squeeze = get_priority(\n        squeeze,\n        egrc_config.squeeze,\n        DEFAULT_SQUEEZE\n    )\n\n    # Pass in None, as subs can't be specified at the command line.\n    resolved_subs = get_priority(\n        None,\n        egrc_config.subs,\n        get_default_subs()\n    )\n\n    result = Config(\n        examples_dir=resolved_examples_dir,\n        custom_dir=resolved_custom_dir,\n        color_config=color_config,\n        use_color=resolved_use_color,\n        pager_cmd=resolved_pager_cmd,\n        editor_cmd=resolved_editor_cmd,\n        squeeze=resolved_squeeze,\n        subs=resolved_subs,\n    )\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_config_tuple_from_egrc(egrc_path):\n    with open(egrc_path, 'r') as egrc:\n        try:\n            config = ConfigParser.RawConfigParser()\n        except AttributeError:\n            config = ConfigParser()\n        config.readfp(egrc)\n\n        # default to None\n        examples_dir = None\n        custom_dir = None\n        use_color = None\n        pager_cmd = None\n        squeeze = None\n        subs = None\n        editor_cmd = None\n\n        if config.has_option(DEFAULT_SECTION, EG_EXAMPLES_DIR):\n            examples_dir = config.get(DEFAULT_SECTION, EG_EXAMPLES_DIR)\n            examples_dir = get_expanded_path(examples_dir)\n\n        if config.has_option(DEFAULT_SECTION, CUSTOM_EXAMPLES_DIR):\n            custom_dir = config.get(DEFAULT_SECTION, CUSTOM_EXAMPLES_DIR)\n            custom_dir = get_expanded_path(custom_dir)\n\n        if config.has_option(DEFAULT_SECTION, USE_COLOR):\n            use_color_raw = config.get(DEFAULT_SECTION, USE_COLOR)\n            use_color = _parse_bool_from_raw_egrc_value(use_color_raw)\n\n        if config.has_option(DEFAULT_SECTION, PAGER_CMD):\n            pager_cmd_raw = config.get(DEFAULT_SECTION, PAGER_CMD)\n            pager_cmd = ast.literal_eval(pager_cmd_raw)\n\n        if config.has_option(DEFAULT_SECTION, EDITOR_CMD):\n            editor_cmd_raw = config.get(DEFAULT_SECTION, EDITOR_CMD)\n            editor_cmd = ast.literal_eval(editor_cmd_raw)\n\n        color_config = get_custom_color_config_from_egrc(config)\n\n        if config.has_option(DEFAULT_SECTION, SQUEEZE):\n            squeeze_raw = config.get(DEFAULT_SECTION, SQUEEZE)\n            squeeze = _parse_bool_from_raw_egrc_value(squeeze_raw)\n\n        if config.has_section(SUBSTITUTION_SECTION):\n            subs = get_substitutions_from_config(config)\n\n        return Config(\n            examples_dir=examples_dir,\n            custom_dir=custom_dir,\n            color_config=color_config,\n            use_color=use_color,\n            pager_cmd=pager_cmd,\n            editor_cmd=editor_cmd,\n            squeeze=squeeze,\n            subs=subs,\n        )", "response": "Create a Config named tuple from the values specified in the. egrc file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand ~ and variables in a path.", "response": "def get_expanded_path(path):\n    \"\"\"Expand ~ and variables in a path. If path is not truthy, return None.\"\"\"\n    if path:\n        result = path\n        result = os.path.expanduser(result)\n        result = os.path.expandvars(result)\n        return result\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting and editor command from environment variables.", "response": "def get_editor_cmd_from_environment():\n    \"\"\"\n    Gets and editor command from environment variables.\n\n    It first tries $VISUAL, then $EDITOR, following the same order git uses\n    when it looks up edits. If neither is available, it returns None.\n    \"\"\"\n    result = os.getenv(ENV_VISUAL)\n    if (not result):\n        result = os.getenv(ENV_EDITOR)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninforms the user if the path does not exist.", "response": "def _inform_if_path_does_not_exist(path):\n    \"\"\"\n    If the path does not exist, print a message saying so. This is intended to\n    be helpful to users if they specify a custom path that eg cannot find.\n    \"\"\"\n    expanded_path = get_expanded_path(path)\n    if not os.path.exists(expanded_path):\n        print('Could not find custom path at: {}'.format(expanded_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the ColorConfig object from the egrc config object. Any colors not defined will be None.", "response": "def get_custom_color_config_from_egrc(config):\n    \"\"\"\n    Get the ColorConfig from the egrc config object. Any colors not defined\n    will be None.\n    \"\"\"\n    pound = _get_color_from_config(config, CONFIG_NAMES.pound)\n    heading = _get_color_from_config(config, CONFIG_NAMES.heading)\n    code = _get_color_from_config(config, CONFIG_NAMES.code)\n    backticks = _get_color_from_config(config, CONFIG_NAMES.backticks)\n    prompt = _get_color_from_config(config, CONFIG_NAMES.prompt)\n    pound_reset = _get_color_from_config(config, CONFIG_NAMES.pound_reset)\n    heading_reset = _get_color_from_config(\n        config,\n        CONFIG_NAMES.heading_reset\n    )\n    code_reset = _get_color_from_config(config, CONFIG_NAMES.code_reset)\n    backticks_reset = _get_color_from_config(\n        config,\n        CONFIG_NAMES.backticks_reset\n    )\n    prompt_reset = _get_color_from_config(config, CONFIG_NAMES.prompt_reset)\n\n    result = ColorConfig(\n        pound=pound,\n        heading=heading,\n        code=code,\n        backticks=backticks,\n        prompt=prompt,\n        pound_reset=pound_reset,\n        heading_reset=heading_reset,\n        code_reset=code_reset,\n        backticks_reset=backticks_reset,\n        prompt_reset=prompt_reset\n    )\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a substitution from the list representation in the config file.", "response": "def parse_substitution_from_list(list_rep):\n    \"\"\"\n    Parse a substitution from the list representation in the config file.\n    \"\"\"\n    # We are expecting [pattern, replacement [, is_multiline]]\n    if type(list_rep) is not list:\n        raise SyntaxError('Substitution must be a list')\n    if len(list_rep) < 2:\n        raise SyntaxError('Substitution must be a list of size 2')\n\n    pattern = list_rep[0]\n    replacement = list_rep[1]\n\n    # By default, substitutions are not multiline.\n    is_multiline = False\n    if (len(list_rep) > 2):\n        is_multiline = list_rep[2]\n        if type(is_multiline) is not bool:\n            raise SyntaxError('is_multiline must be a boolean')\n\n    result = substitute.Substitution(pattern, replacement, is_multiline)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of Substitution objects from the config sorted alphabetically by pattern name. Returns an empty list if no Substitutions are specified.", "response": "def get_substitutions_from_config(config):\n    \"\"\"\n    Return a list of Substitution objects from the config, sorted\n    alphabetically by pattern name. Returns an empty list if no Substitutions\n    are specified. If there are problems parsing the values, a help message\n    will be printed and an error will be thrown.\n    \"\"\"\n    result = []\n    pattern_names = config.options(SUBSTITUTION_SECTION)\n    pattern_names.sort()\n    for name in pattern_names:\n        pattern_val = config.get(SUBSTITUTION_SECTION, name)\n        list_rep = ast.literal_eval(pattern_val)\n        substitution = parse_substitution_from_list(list_rep)\n        result.append(substitution)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a color config object with all the defaults.", "response": "def get_default_color_config():\n    \"\"\"Get a color config object with all the defaults.\"\"\"\n    result = ColorConfig(\n        pound=DEFAULT_COLOR_POUND,\n        heading=DEFAULT_COLOR_HEADING,\n        code=DEFAULT_COLOR_CODE,\n        backticks=DEFAULT_COLOR_BACKTICKS,\n        prompt=DEFAULT_COLOR_PROMPT,\n        pound_reset=DEFAULT_COLOR_POUND_RESET,\n        heading_reset=DEFAULT_COLOR_HEADING_RESET,\n        code_reset=DEFAULT_COLOR_CODE_RESET,\n        backticks_reset=DEFAULT_COLOR_BACKTICKS_RESET,\n        prompt_reset=DEFAULT_COLOR_PROMPT_RESET\n    )\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an empty Config object with no options set.", "response": "def get_empty_config():\n    \"\"\"\n    Return an empty Config object with no options set.\n    \"\"\"\n    empty_color_config = get_empty_color_config()\n    result = Config(\n        examples_dir=None,\n        custom_dir=None,\n        color_config=empty_color_config,\n        use_color=None,\n        pager_cmd=None,\n        editor_cmd=None,\n        squeeze=None,\n        subs=None\n    )\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_empty_color_config():\n    empty_color_config = ColorConfig(\n        pound=None,\n        heading=None,\n        code=None,\n        backticks=None,\n        prompt=None,\n        pound_reset=None,\n        heading_reset=None,\n        code_reset=None,\n        backticks_reset=None,\n        prompt_reset=None\n    )\n    return empty_color_config", "response": "Return a color_config with all values set to None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge two color configs.", "response": "def merge_color_configs(first, second):\n    \"\"\"\n    Merge the color configs.\n\n    Values in the first will overwrite non-None values in the second.\n    \"\"\"\n    # We have to get the desired values first and simultaneously, as nametuple\n    # is immutable.\n    pound = get_priority(first.pound, second.pound, None)\n    heading = get_priority(first.heading, second.heading, None)\n    code = get_priority(first.code, second.code, None)\n    backticks = get_priority(first.backticks, second.backticks, None)\n    prompt = get_priority(first.prompt, second.prompt, None)\n    pound_reset = get_priority(\n        first.pound_reset,\n        second.pound_reset,\n        None\n    )\n    heading_reset = get_priority(\n        first.heading_reset,\n        second.heading_reset,\n        None\n    )\n    code_reset = get_priority(\n        first.code_reset,\n        second.code_reset,\n        None\n    )\n    backticks_reset = get_priority(\n        first.backticks_reset,\n        second.backticks_reset,\n        None\n    )\n    prompt_reset = get_priority(\n        first.prompt_reset,\n        second.prompt_reset,\n        None\n    )\n\n    result = ColorConfig(\n        pound=pound,\n        heading=heading,\n        code=code,\n        backticks=backticks,\n        prompt=prompt,\n        pound_reset=pound_reset,\n        heading_reset=heading_reset,\n        code_reset=code_reset,\n        backticks_reset=backticks_reset,\n        prompt_reset=prompt_reset\n    )\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_and_get_result(self, string):\n        if self.is_multiline:\n            compiled_pattern = re.compile(self.pattern, re.MULTILINE)\n        else:\n            compiled_pattern = re.compile(self.pattern)\n\n        result = re.sub(compiled_pattern, self.repl, string)\n        return result", "response": "Apply the substitution represented by this object on string and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _recursive_get_all_file_names(dir):\n    if not dir:\n        return []\n\n    result = []\n    for basedir, dirs, files in os.walk(dir):\n        result.extend(files)\n\n    return result", "response": "Recursively gets all the file names in the directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef edit_custom_examples(program, config):\n    if (not config.custom_dir) or (not os.path.exists(config.custom_dir)):\n        _inform_cannot_edit_no_custom_dir()\n        return\n\n    # resolve aliases\n    resolved_program = get_resolved_program(program, config)\n    custom_file_paths = get_file_paths_for_program(\n        resolved_program,\n        config.custom_dir\n    )\n\n    if (len(custom_file_paths) > 0):\n        path_to_edit = custom_file_paths[0]\n    else:\n        # A new file.\n        path_to_edit = os.path.join(config.custom_dir, resolved_program + '.md')\n\n    # Edit the first. Handles the base case.\n    subprocess.call([config.editor_cmd, path_to_edit])", "response": "Edit custom examples for the given program creating the file if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an array of full paths matching the given program.", "response": "def get_file_paths_for_program(program, dir_to_search):\n    \"\"\"\n    Return an array of full paths matching the given program. If no directory is\n    present, returns an empty list.\n\n    Path is not guaranteed to exist. Just says where it should be if it\n    existed. Paths must be fully expanded before being passed in (i.e. no ~ or\n    variables).\n    \"\"\"\n    if dir_to_search is None:\n        return []\n    else:\n        wanted_file_name = program + EXAMPLE_FILE_SUFFIX\n        result = []\n        for basedir, dirs, file_names in os.walk(dir_to_search):\n            for file_name in file_names:\n                if file_name == wanted_file_name:\n                    result.append(os.path.join(basedir, file_name))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npaging a string to the page via the pager.", "response": "def page_string(str_to_page, pager_cmd):\n    \"\"\"\n    Page str_to_page via the pager.\n    \"\"\"\n    # By default, we expect the command to be `less -R`. If that is the\n    # pager_cmd, but they don't have less on their machine, odds are they're\n    # just using the default value. In this case the pager will fail, so we'll\n    # just go via pydoc.pager, which tries to do smarter checking that we don't\n    # want to bother trying to replicate.\n    use_fallback_page_function = False\n    if pager_cmd is None:\n        use_fallback_page_function = True\n    elif pager_cmd == FLAG_FALLBACK:\n        use_fallback_page_function = True\n\n    try:\n        if use_fallback_page_function:\n            pydoc.pager(str_to_page)\n        else:\n            # Otherwise, obey the user.\n            pydoc.pipepager(str_to_page, cmd=pager_cmd)\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a list of all the commands that have examples known to eg.", "response": "def get_list_of_all_supported_commands(config):\n    \"\"\"\n    Generate a list of all the commands that have examples known to eg. The\n    format of the list is the command names. The fact that there are examples\n    for 'cp', for example, would mean that 'cp' was in the list.\n\n    The format of the list contains additional information to say if there are\n    only default examples, only custom examples, or both:\n\n        cp    (only default)\n        cp *  (only custom)\n        cp +  (default and custom)\n\n    Aliases are shown as\n    alias -> resolved, with resolved having its '*' or '+' as expected. Aliases\n    that shadow custom-only file names are expected to be shown instead of the\n    custom file names. This is intentional, as that is the behavior for file\n    resolution--an alias will hide a custom file.\n    \"\"\"\n    default_files = _recursive_get_all_file_names(config.examples_dir)\n    custom_files = _recursive_get_all_file_names(config.custom_dir)\n\n    # Now filter so we only have example files, not things like aliases.json.\n    default_files = [path for path in default_files if _is_example_file(path)]\n    custom_files = [path for path in custom_files if _is_example_file(path)]\n\n\n    def get_without_suffix(file_name):\n        \"\"\"\n        Return the file name without the suffix, or the file name itself\n        if it does not have the suffix.\n        \"\"\"\n        return file_name.split(EXAMPLE_FILE_SUFFIX)[0]\n\n    default_files = [get_without_suffix(f) for f in default_files]\n    custom_files = [get_without_suffix(f) for f in custom_files]\n\n    set_default_commands = set(default_files)\n    set_custom_commands = set(custom_files)\n\n    alias_dict = get_alias_dict(config)\n\n    both_defined = set_default_commands & set_custom_commands\n    only_default = set_default_commands - set_custom_commands\n    only_custom = set_custom_commands - set_default_commands\n\n    all_commands = both_defined | only_default | only_custom\n\n    command_to_rep = {}\n    for command in all_commands:\n        rep = None\n        if command in both_defined:\n            rep = command + ' ' + FLAG_CUSTOM_AND_DEFAULT\n        elif command in only_default:\n            rep = command\n        elif command in only_custom:\n            rep = command + ' ' + FLAG_ONLY_CUSTOM\n        else:\n            raise NameError('command not in known set: ' + str(command))\n        command_to_rep[command] = rep\n\n    result = []\n    all_commands_and_aliases = all_commands.union(alias_dict.keys())\n    for command in all_commands_and_aliases:\n        if command in alias_dict:\n            # aliases get precedence\n            target = alias_dict[command]\n            rep_of_target = command_to_rep[target]\n            result.append(command + ' -> ' + rep_of_target)\n        else:\n            rep = command_to_rep[command]\n            result.append(rep)\n\n    result.sort()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsqueezing the contents by removing blank lines between example and section and return the modified contents.", "response": "def get_squeezed_contents(contents):\n    \"\"\"\n    Squeeze the contents by removing blank lines between definition and example\n    and remove duplicate blank lines except between sections.\n    \"\"\"\n    line_between_example_code = substitute.Substitution(\n        '\\n\\n    ',\n        '\\n    ',\n        True\n    )\n    lines_between_examples = substitute.Substitution('\\n\\n\\n', '\\n\\n', True)\n    lines_between_sections = substitute.Substitution(\n        '\\n\\n\\n\\n', '\\n\\n\\n', True\n    )\n\n    result = contents\n    result = line_between_example_code.apply_and_get_result(result)\n    result = lines_between_examples.apply_and_get_result(result)\n    result = lines_between_sections.apply_and_get_result(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_colorized_contents(contents, color_config):\n    colorizer = color.EgColorizer(color_config)\n    result = colorizer.colorize_text(contents)\n    return result", "response": "Colorize the contents based on the color_config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_substituted_contents(contents, substitutions):\n    result = contents\n    for sub in substitutions:\n        result = sub.apply_and_get_result(result)\n    return result", "response": "Perform a list of substitutions and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_formatted_contents(\n    raw_contents,\n    use_color,\n    color_config,\n    squeeze,\n    subs\n):\n    \"\"\"\n    Apply formatting to raw_contents and return the result. Formatting is\n    applied in the order: color, squeeze, subs.\n    \"\"\"\n    result = raw_contents\n\n    if use_color:\n        result = get_colorized_contents(result, color_config)\n\n    if squeeze:\n        result = get_squeezed_contents(result)\n\n    if subs:\n        result = get_substituted_contents(result, subs)\n\n    return result", "response": "Apply formatting to raw_contents and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_resolved_program(program, config_obj):\n    alias_dict = get_alias_dict(config_obj)\n    if program in alias_dict:\n        return alias_dict[program]\n    else:\n        return program", "response": "Returns the resolved program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary consisting of all aliases known to eg.", "response": "def get_alias_dict(config_obj):\n    \"\"\"\n    Return a dictionary consisting of all aliases known to eg.\n\n    The format is {'alias': 'resolved_program'}.\n\n    If the aliases file does not exist, returns an empty dict.\n    \"\"\"\n    if not config_obj.examples_dir:\n        return {}\n\n    alias_file_path = _get_alias_file_path(config_obj)\n    if not os.path.isfile(alias_file_path):\n        return {}\n\n    alias_file_contents = _get_contents_of_file(alias_file_path)\n    result = json.loads(alias_file_contents)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _show_list_message(resolved_config):\n    # Show what's available.\n    supported_programs = util.get_list_of_all_supported_commands(\n        resolved_config\n    )\n    msg_line_1 = 'Legend: '\n    msg_line_2 = (\n        '    ' +\n        util.FLAG_ONLY_CUSTOM +\n        ' only custom files'\n    )\n    msg_line_3 = (\n        '    ' +\n        util.FLAG_CUSTOM_AND_DEFAULT +\n        ' custom and default files'\n    )\n    msg_line_4 = '    ' + '  only default files (no symbol)'\n    msg_line_5 = ''\n    msg_line_6 = 'Programs supported by eg: '\n\n    preamble = [\n        msg_line_1,\n        msg_line_2,\n        msg_line_3,\n        msg_line_4,\n        msg_line_5,\n        msg_line_6\n    ]\n\n    complete_message = '\\n'.join(preamble)\n    complete_message += '\\n' + '\\n'.join(supported_programs)\n\n    pydoc.pager(complete_message)", "response": "Show the message for when a user has passed in list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_arguments():\n    parser = argparse.ArgumentParser(\n        description='eg provides examples of common command usage.'\n    )\n\n    parser.add_argument(\n        '-v',\n        '--version',\n        action='store_true',\n        help='Display version information about eg'\n    )\n\n    parser.add_argument(\n        '-f',\n        '--config-file',\n        help='Path to the .egrc file, if it is not in the default location.'\n    )\n\n    parser.add_argument(\n        '-e',\n        '--edit',\n        action='store_true',\n        help=\"\"\"Edit the custom examples for the given command. If editor-cmd\n        is not set in your .egrc and $VISUAL and $EDITOR are not set, prints a\n        message and does nothing.\"\"\"\n    )\n\n    parser.add_argument(\n        '--examples-dir',\n        help='The location to the examples/ dir that ships with eg'\n    )\n\n    parser.add_argument(\n        '-c',\n        '--custom-dir',\n        help='Path to a directory containing user-defined examples.'\n    )\n\n    parser.add_argument(\n        '-p',\n        '--pager-cmd',\n        help='String literal that will be invoked to page output.'\n    )\n\n    parser.add_argument(\n        '-l',\n        '--list',\n        action='store_true',\n        help='Show all the programs with eg entries.'\n    )\n\n    parser.add_argument(\n        '--color',\n        action='store_true',\n        dest='use_color',\n        default=None,\n        help='Colorize output.'\n    )\n\n    parser.add_argument(\n        '-s',\n        '--squeeze',\n        action='store_true',\n        default=None,\n        help='Show fewer blank lines in output.'\n    )\n\n    parser.add_argument(\n        '--no-color',\n        action='store_false',\n        dest='use_color',\n        help='Do not colorize output.'\n    )\n\n    parser.add_argument(\n        'program',\n        nargs='?',\n        help='The program for which to display examples.'\n    )\n\n    args = parser.parse_args()\n\n    if len(sys.argv) < 2:\n        # Too few arguments. We can't specify this using argparse alone, so we\n        # have to manually check.\n        parser.print_help()\n        parser.exit()\n    elif not args.version and not args.list and not args.program:\n        parser.error(_MSG_BAD_ARGS)\n    else:\n        return args", "response": "Construct and parses the command line arguments for eg."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecorating a function using a caller.", "response": "def decorate(func, caller, extras=()):\n    \"\"\"\n    decorate(func, caller) decorates a function using a caller.\n    If the caller is a generator function, the resulting function\n    will be a generator function.\n    \"\"\"\n    evaldict = dict(_call_=caller, _func_=func)\n    es = ''\n    for i, extra in enumerate(extras):\n        ex = '_e%d_' % i\n        evaldict[ex] = extra\n        es += ex + ', '\n\n    if '3.5' <= sys.version < '3.6':\n        # with Python 3.5 isgeneratorfunction returns True for all coroutines\n        # however we know that it is NOT possible to have a generator\n        # coroutine in python 3.5: PEP525 was not there yet\n        generatorcaller = isgeneratorfunction(\n            caller) and not iscoroutinefunction(caller)\n    else:\n        generatorcaller = isgeneratorfunction(caller)\n    if generatorcaller:\n        fun = FunctionMaker.create(\n            func, \"for res in _call_(_func_, %s%%(shortsignature)s):\\n\"\n                  \"    yield res\" % es, evaldict, __wrapped__=func)\n    else:\n        fun = FunctionMaker.create(\n            func, \"return _call_(_func_, %s%%(shortsignature)s)\" % es,\n            evaldict, __wrapped__=func)\n    if hasattr(func, '__qualname__'):\n        fun.__qualname__ = func.__qualname__\n    return fun"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decorator(caller, _func=None):\n    if _func is not None:  # return a decorated function\n        # this is obsolete behavior; you should use decorate instead\n        return decorate(_func, caller)\n    # else return a decorator function\n    defaultargs, defaults = '', ()\n    if inspect.isclass(caller):\n        name = caller.__name__.lower()\n        doc = 'decorator(%s) converts functions/generators into ' \\\n            'factories of %s objects' % (caller.__name__, caller.__name__)\n    elif inspect.isfunction(caller):\n        if caller.__name__ == '<lambda>':\n            name = '_lambda_'\n        else:\n            name = caller.__name__\n        doc = caller.__doc__\n        nargs = caller.__code__.co_argcount\n        ndefs = len(caller.__defaults__ or ())\n        defaultargs = ', '.join(caller.__code__.co_varnames[nargs-ndefs:nargs])\n        if defaultargs:\n            defaultargs += ','\n        defaults = caller.__defaults__\n    else:  # assume caller is an object with a __call__ method\n        name = caller.__class__.__name__.lower()\n        doc = caller.__call__.__doc__\n    evaldict = dict(_call=caller, _decorate_=decorate)\n    dec = FunctionMaker.create(\n        '%s(func, %s)' % (name, defaultargs),\n        'if func is None: return lambda func:  _decorate_(func, _call, (%s))\\n'\n        'return _decorate_(func, _call, (%s))' % (defaultargs, defaultargs),\n        evaldict, doc=doc, module=caller.__module__, __wrapped__=caller)\n    if defaults:\n        dec.__defaults__ = (None,) + defaults\n    return dec", "response": "decorator that converts a caller function into a decorator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_signature_object(func, as_instance, eat_self):\n    if isinstance(func, ClassTypes) and not as_instance:\n        # If it's a type and should be modelled as a type, use __init__.\n        try:\n            func = func.__init__\n        except AttributeError:\n            return None\n        # Skip the `self` argument in __init__\n        eat_self = True\n    elif not isinstance(func, FunctionTypes):\n        # If we really want to model an instance of the passed type,\n        # __call__ should be looked up, not __init__.\n        try:\n            func = func.__call__\n        except AttributeError:\n            return None\n    if eat_self:\n        sig_func = partial(func, None)\n    else:\n        sig_func = func\n\n    try:\n        return func, inspectsignature(sig_func)\n    except ValueError:\n        # Certain callable types are not supported by inspect.signature()\n        return None", "response": "Given an arbitrary callable object try to create a suitable\n    signature object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an object return True if the object is callable. For classes return True if the object is callable. For classes return True if the object is callable.", "response": "def _instance_callable(obj):\n    \"\"\"Given an object, return True if the object is callable.\n    For classes, return True if instances would be callable.\"\"\"\n    if not isinstance(obj, ClassTypes):\n        # already an instance\n        return getattr(obj, '__call__', None) is not None\n\n    if six.PY3:\n        # *could* be broken by a class overriding __mro__ or __dict__ via\n        # a metaclass\n        for base in (obj,) + obj.__mro__:\n            if base.__dict__.get('__call__') is not None:\n                return True\n    else:\n        klass = obj\n        # uses __bases__ instead of __mro__ so that we work with old style classes\n        if klass.__dict__.get('__call__') is not None:\n            return True\n\n        for base in klass.__bases__:\n            if _instance_callable(base):\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mock_open(mock=None, read_data=''):\n    def _readlines_side_effect(*args, **kwargs):\n        if handle.readlines.return_value is not None:\n            return handle.readlines.return_value\n        return list(_state[0])\n\n    def _read_side_effect(*args, **kwargs):\n        if handle.read.return_value is not None:\n            return handle.read.return_value\n        return type(read_data)().join(_state[0])\n\n    def _readline_side_effect():\n        if handle.readline.return_value is not None:\n            while True:\n                yield handle.readline.return_value\n        for line in _state[0]:\n            yield line\n        while True:\n            yield type(read_data)()\n\n\n    global file_spec\n    if file_spec is None:\n        # set on first use\n        if six.PY3:\n            import _io\n            file_spec = list(set(dir(_io.TextIOWrapper)).union(set(dir(_io.BytesIO))))\n        else:\n            file_spec = file\n\n    if mock is None:\n        mock = MagicMock(name='open', spec=open)\n\n    handle = MagicMock(spec=file_spec)\n    handle.__enter__.return_value = handle\n\n    _state = [_iterate_read_data(read_data), None]\n\n    handle.write.return_value = None\n    handle.read.return_value = None\n    handle.readline.return_value = None\n    handle.readlines.return_value = None\n\n    handle.read.side_effect = _read_side_effect\n    _state[1] = _readline_side_effect()\n    handle.readline.side_effect = _state[1]\n    handle.readlines.side_effect = _readlines_side_effect\n\n    def reset_data(*args, **kwargs):\n        _state[0] = _iterate_read_data(read_data)\n        if handle.readline.side_effect == _state[1]:\n            # Only reset the side effect if the user hasn't overridden it.\n            _state[1] = _readline_side_effect()\n            handle.readline.side_effect = _state[1]\n        return DEFAULT\n\n    mock.side_effect = reset_data\n    mock.return_value = handle\n    return mock", "response": "This function creates a mock object that can be used to replace the use of open."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrestoring the mock object to its initial state.", "response": "def reset_mock(self,  visited=None, return_value=False, side_effect=False):\n        \"Restore the mock object to its initial state.\"\n        if visited is None:\n            visited = []\n        if id(self) in visited:\n            return\n        visited.append(id(self))\n\n        self.called = False\n        self.call_args = None\n        self.call_count = 0\n        self.mock_calls = _CallList()\n        self.call_args_list = _CallList()\n        self.method_calls = _CallList()\n\n        if return_value:\n            self._mock_return_value = DEFAULT\n        if side_effect:\n            self._mock_side_effect = None\n\n        for child in self._mock_children.values():\n            if isinstance(child, _SpecState):\n                continue\n            child.reset_mock(visited)\n\n        ret = self._mock_return_value\n        if _is_instance_mock(ret) and ret is not self:\n            ret.reset_mock(visited)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _call_matcher(self, _call):\n        sig = self._spec_signature\n        if sig is not None:\n            if len(_call) == 2:\n                name = ''\n                args, kwargs = _call\n            else:\n                name, args, kwargs = _call\n            try:\n                return name, sig.bind(*args, **kwargs)\n            except TypeError as e:\n                e.__traceback__ = None\n                return e\n        else:\n            return _call", "response": "Given a call return a comparison key suitable for matching with other calls."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_not_called(_mock_self):\n        self = _mock_self\n        if self.call_count != 0:\n            msg = (\"Expected '%s' to not have been called. Called %s times.\" %\n                   (self._mock_name or 'mock', self.call_count))\n            raise AssertionError(msg)", "response": "assert that the mock was never called."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_called(_mock_self):\n        self = _mock_self\n        if self.call_count == 0:\n            msg = (\"Expected '%s' to have been called.\" %\n                   self._mock_name or 'mock')\n            raise AssertionError(msg)", "response": "assert that the mock was called at least once\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assert_called_once(_mock_self):\n        self = _mock_self\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to have been called once. Called %s times.\" %\n                   (self._mock_name or 'mock', self.call_count))\n            raise AssertionError(msg)", "response": "assert that the mock was called only once."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_called_with(_mock_self, *args, **kwargs):\n        self = _mock_self\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            raise AssertionError('Expected call: {}\\nNot called'.format(expected))\n\n        def _error_message(cause):\n            msg = self._format_mock_failure_message(args, kwargs)\n            if six.PY2 and cause is not None:\n                # Tack on some diagnostics for Python without __cause__\n                msg = '{}\\n{}'.format(msg, str(cause))\n            return msg\n        expected = self._call_matcher((args, kwargs))\n        actual = self._call_matcher(self.call_args)\n        if expected != actual:\n            cause = expected if isinstance(expected, Exception) else None\n            six.raise_from(AssertionError(_error_message(cause)), cause)", "response": "assert that the mock was called with the specified arguments. Raises an AssertionError if the args and keyword args passed in are not the same as the last call to the mock."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assert_called_once_with(_mock_self, *args, **kwargs):\n        self = _mock_self\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.\" %\n                   (self._mock_name or 'mock', self.call_count))\n            raise AssertionError(msg)\n        return self.assert_called_with(*args, **kwargs)", "response": "assert that the mock was called exactly once and with the specified\nTaxonomy arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasserts the mock has been called with the specified calls.", "response": "def assert_has_calls(self, calls, any_order=False):\n        \"\"\"assert the mock has been called with the specified calls.\n        The `mock_calls` list is checked for the calls.\n\n        If `any_order` is False (the default) then the calls must be\n        sequential. There can be extra calls before or after the\n        specified calls.\n\n        If `any_order` is True then the calls can be in any order, but\n        they must all appear in `mock_calls`.\"\"\"\n        expected = [self._call_matcher(c) for c in calls]\n        cause = expected if isinstance(expected, Exception) else None\n        all_calls = _CallList(self._call_matcher(c) for c in self.mock_calls)\n        if not any_order:\n            if expected not in all_calls:\n                six.raise_from(AssertionError(\n                    'Calls not found.\\nExpected: %r\\n'\n                    'Actual: %r' % (_CallList(calls), self.mock_calls)\n                ), cause)\n            return\n\n        all_calls = list(all_calls)\n\n        not_found = []\n        for kall in expected:\n            try:\n                all_calls.remove(kall)\n            except ValueError:\n                not_found.append(kall)\n        if not_found:\n            six.raise_from(AssertionError(\n                '{!r} not all found in call list'.format(tuple(not_found))\n            ), cause)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_any_call(self, *args, **kwargs):\n        expected = self._call_matcher((args, kwargs))\n        actual = [self._call_matcher(c) for c in self.call_args_list]\n        if expected not in actual:\n            cause = expected if isinstance(expected, Exception) else None\n            expected_string = self._format_mock_call_signature(args, kwargs)\n            six.raise_from(AssertionError(\n                '%s call not found' % expected_string\n            ), cause)", "response": "assert the mock has been called with the specified arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n        result = self.__enter__()\n        self._active_patches.append(self)\n        return result", "response": "Activate a patch returning any created mock."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize(self):\n        chrfunc = chr if py3k else HTMLEntity._unichr\n        if self.named:\n            return chrfunc(htmlentities.name2codepoint[self.value])\n        if self.hexadecimal:\n            return chrfunc(int(self.value, 16))\n        return chrfunc(int(self.value))", "response": "Return the unicode character represented by the HTML entity."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninheriting doc from method in parent class.", "response": "def inheritdoc(method):\n    \"\"\"Set __doc__ of *method* to __doc__ of *method* in its parent class.\n\n    Since this is used on :class:`.SmartList`, the \"parent class\" used is\n    ``list``. This function can be used as a decorator.\n    \"\"\"\n    method.__doc__ = getattr(list, method.__name__).__doc__\n    return method"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a slice equivalent to the input key * key * standardized.", "response": "def _normalize_slice(self, key, clamp=False):\n        \"\"\"Return a slice equivalent to the input *key*, standardized.\"\"\"\n        if key.start is None:\n            start = 0\n        else:\n            start = (len(self) + key.start) if key.start < 0 else key.start\n        if key.stop is None or key.stop == maxsize:\n            stop = len(self) if clamp else None\n        else:\n            stop = (len(self) + key.stop) if key.stop < 0 else key.stop\n        return slice(start, stop, key.step or 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _detach_children(self):\n        children = [val[0] for val in self._children.values()]\n        for child in children:\n            child()._parent = list(self)\n        self._children.clear()", "response": "Remove all children and give them independent parent copies."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the actual list from the stored start stop and step.", "response": "def _render(self):\n        \"\"\"Return the actual list from the stored start/stop/step.\"\"\"\n        return list(self._parent)[self._start:self._stop:self._step]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, text, context=0, skip_style_tags=False):\n        tokens = self._tokenizer.tokenize(text, context, skip_style_tags)\n        code = self._builder.build(tokens)\n        return code", "response": "Parse the given text and return a Python code object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether any attribute in the tag has the given name.", "response": "def has(self, name):\n        \"\"\"Return whether any attribute in the tag has the given *name*.\n\n        Note that a tag may have multiple attributes with the same name, but\n        only the last one is read by the MediaWiki parser.\n        \"\"\"\n        for attr in self.attributes:\n            if attr.name == name.strip():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, name):\n        for attr in reversed(self.attributes):\n            if attr.name == name.strip():\n                return attr\n        raise ValueError(name)", "response": "Get the attribute with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an attribute with the given name and value.", "response": "def add(self, name, value=None, quotes='\"', pad_first=\" \",\n            pad_before_eq=\"\", pad_after_eq=\"\"):\n        \"\"\"Add an attribute with the given *name* and *value*.\n\n        *name* and *value* can be anything parsable by\n        :func:`.utils.parse_anything`; *value* can be omitted if the attribute\n        is valueless. If *quotes* is not ``None``, it should be a string\n        (either ``\"`` or ``'``) that *value* will be wrapped in (this is\n        recommended). ``None`` is only legal if *value* contains no spacing.\n\n        *pad_first*, *pad_before_eq*, and *pad_after_eq* are whitespace used as\n        padding before the name, before the equal sign (or after the name if no\n        value), and after the equal sign (ignored if no value), respectively.\n        \"\"\"\n        if value is not None:\n            value = parse_anything(value)\n        quotes = Attribute.coerce_quotes(quotes)\n        attr = Attribute(parse_anything(name), value, quotes)\n        attr.pad_first = pad_first\n        attr.pad_before_eq = pad_before_eq\n        attr.pad_after_eq = pad_after_eq\n        self.attributes.append(attr)\n        return attr"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all attributes with the given name. Raises a ValueError if none were found.", "response": "def remove(self, name):\n        \"\"\"Remove all attributes with the given *name*.\n\n        Raises :exc:`ValueError` if none were found.\n        \"\"\"\n        attrs = [attr for attr in self.attributes if attr.name == name.strip()]\n        if not attrs:\n            raise ValueError(name)\n        for attr in attrs:\n            self.attributes.remove(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inheritdoc(method):\n    method.__doc__ = getattr(str, method.__name__).__doc__\n    return method", "response": "Set __doc__ of method to __doc__ of its parent class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a string or iterable of strings.", "response": "def parse_anything(value, context=0, skip_style_tags=False):\n    \"\"\"Return a :class:`.Wikicode` for *value*, allowing multiple types.\n\n    This differs from :meth:`.Parser.parse` in that we accept more than just a\n    string to be parsed. Unicode objects (strings in py3k), strings (bytes in\n    py3k), integers (converted to strings), ``None``, existing :class:`.Node`\n    or :class:`.Wikicode` objects, as well as an iterable of these types, are\n    supported. This is used to parse input on-the-fly by various methods of\n    :class:`.Wikicode` and others like :class:`.Template`, such as\n    :meth:`wikicode.insert() <.Wikicode.insert>` or setting\n    :meth:`template.name <.Template.name>`.\n\n    Additional arguments are passed directly to :meth:`.Parser.parse`.\n    \"\"\"\n    from .parser import Parser\n    from .wikicode import Wikicode\n\n    if isinstance(value, Wikicode):\n        return value\n    elif isinstance(value, Node):\n        return Wikicode(SmartList([value]))\n    elif isinstance(value, str):\n        return Parser().parse(value, context, skip_style_tags)\n    elif isinstance(value, bytes):\n        return Parser().parse(value.decode(\"utf8\"), context, skip_style_tags)\n    elif isinstance(value, int):\n        return Parser().parse(str(value), context, skip_style_tags)\n    elif value is None:\n        return Wikicode(SmartList())\n    elif hasattr(value, \"read\"):\n        return parse_anything(value.read(), context, skip_style_tags)\n    try:\n        nodelist = SmartList()\n        for item in value:\n            nodelist += parse_anything(item, context, skip_style_tags).nodes\n        return Wikicode(nodelist)\n    except TypeError:\n        error = \"Needs string, Node, Wikicode, file, int, None, or iterable of these, but got {0}: {1}\"\n        raise ValueError(error.format(type(value).__name__, value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling a case where a parameter is at the head of the tokens.", "response": "def _handle_parameter(self, default):\n        \"\"\"Handle a case where a parameter is at the head of the tokens.\n\n        *default* is the value to use if no parameter name is defined.\n        \"\"\"\n        key = None\n        showkey = False\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.TemplateParamEquals):\n                key = self._pop()\n                showkey = True\n                self._push()\n            elif isinstance(token, (tokens.TemplateParamSeparator,\n                                    tokens.TemplateClose)):\n                self._tokens.append(token)\n                value = self._pop()\n                if key is None:\n                    key = Wikicode(SmartList([Text(str(default))]))\n                return Parameter(key, value, showkey)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_parameter() missed a close token\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_template(self, token):\n        params = []\n        default = 1\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.TemplateParamSeparator):\n                if not params:\n                    name = self._pop()\n                param = self._handle_parameter(default)\n                params.append(param)\n                if not param.showkey:\n                    default += 1\n            elif isinstance(token, tokens.TemplateClose):\n                if not params:\n                    name = self._pop()\n                return Template(name, params)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_template() missed a close token\")", "response": "Handle a case where a template is at the head of the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_argument(self, token):\n        name = None\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.ArgumentSeparator):\n                name = self._pop()\n                self._push()\n            elif isinstance(token, tokens.ArgumentClose):\n                if name is not None:\n                    return Argument(name, self._pop())\n                return Argument(self._pop())\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_argument() missed a close token\")", "response": "Handle a case where an argument is at the head of the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a case where a wikilink is at the head of the tokens.", "response": "def _handle_wikilink(self, token):\n        \"\"\"Handle a case where a wikilink is at the head of the tokens.\"\"\"\n        title = None\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.WikilinkSeparator):\n                title = self._pop()\n                self._push()\n            elif isinstance(token, tokens.WikilinkClose):\n                if title is not None:\n                    return Wikilink(title, self._pop())\n                return Wikilink(self._pop())\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_wikilink() missed a close token\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_external_link(self, token):\n        brackets, url = token.brackets, None\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.ExternalLinkSeparator):\n                url = self._pop()\n                self._push()\n            elif isinstance(token, tokens.ExternalLinkClose):\n                if url is not None:\n                    return ExternalLink(url, self._pop(), brackets)\n                return ExternalLink(self._pop(), brackets=brackets)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_external_link() missed a close token\")", "response": "Handle when an external link is at the head of the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a case where an HTML entity is at the head of the tokens.", "response": "def _handle_entity(self, token):\n        \"\"\"Handle a case where an HTML entity is at the head of the tokens.\"\"\"\n        token = self._tokens.pop()\n        if isinstance(token, tokens.HTMLEntityNumeric):\n            token = self._tokens.pop()\n            if isinstance(token, tokens.HTMLEntityHex):\n                text = self._tokens.pop()\n                self._tokens.pop()  # Remove HTMLEntityEnd\n                return HTMLEntity(text.text, named=False, hexadecimal=True,\n                                  hex_char=token.char)\n            self._tokens.pop()  # Remove HTMLEntityEnd\n            return HTMLEntity(token.text, named=False, hexadecimal=False)\n        self._tokens.pop()  # Remove HTMLEntityEnd\n        return HTMLEntity(token.text, named=True, hexadecimal=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a case where a heading is at the head of the tokens.", "response": "def _handle_heading(self, token):\n        \"\"\"Handle a case where a heading is at the head of the tokens.\"\"\"\n        level = token.level\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.HeadingEnd):\n                title = self._pop()\n                return Heading(title, level)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_heading() missed a close token\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_comment(self, token):\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.CommentEnd):\n                contents = self._pop()\n                return Comment(contents)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_comment() missed a close token\")", "response": "Handle a case where an HTML comment is at the head of the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a case where a tag attribute is at the head of the tokens.", "response": "def _handle_attribute(self, start):\n        \"\"\"Handle a case where a tag attribute is at the head of the tokens.\"\"\"\n        name = quotes = None\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.TagAttrEquals):\n                name = self._pop()\n                self._push()\n            elif isinstance(token, tokens.TagAttrQuote):\n                quotes = token.char\n            elif isinstance(token, (tokens.TagAttrStart, tokens.TagCloseOpen,\n                                    tokens.TagCloseSelfclose)):\n                self._tokens.append(token)\n                if name:\n                    value = self._pop()\n                else:\n                    name, value = self._pop(), None\n                return Attribute(name, value, quotes, start.pad_first,\n                                 start.pad_before_eq, start.pad_after_eq)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_attribute() missed a close token\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_tag(self, token):\n        close_tokens = (tokens.TagCloseSelfclose, tokens.TagCloseClose)\n        implicit, attrs, contents, closing_tag = False, [], None, None\n        wiki_markup, invalid = token.wiki_markup, token.invalid or False\n        wiki_style_separator, closing_wiki_markup = None, wiki_markup\n        self._push()\n        while self._tokens:\n            token = self._tokens.pop()\n            if isinstance(token, tokens.TagAttrStart):\n                attrs.append(self._handle_attribute(token))\n            elif isinstance(token, tokens.TagCloseOpen):\n                wiki_style_separator = token.wiki_markup\n                padding = token.padding or \"\"\n                tag = self._pop()\n                self._push()\n            elif isinstance(token, tokens.TagOpenClose):\n                closing_wiki_markup = token.wiki_markup\n                contents = self._pop()\n                self._push()\n            elif isinstance(token, close_tokens):\n                if isinstance(token, tokens.TagCloseSelfclose):\n                    closing_wiki_markup = token.wiki_markup\n                    tag = self._pop()\n                    self_closing = True\n                    padding = token.padding or \"\"\n                    implicit = token.implicit or False\n                else:\n                    self_closing = False\n                    closing_tag = self._pop()\n                return Tag(tag, contents, attrs, wiki_markup, self_closing,\n                           invalid, implicit, padding, closing_tag,\n                           wiki_style_separator, closing_wiki_markup)\n            else:\n                self._write(self._handle_token(token))\n        raise ParserError(\"_handle_tag() missed a close token\")", "response": "Handle a case where a tag is at the head of the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a single token.", "response": "def _handle_token(self, token):\n        \"\"\"Handle a single token.\"\"\"\n        try:\n            return _HANDLERS[type(token)](self, token)\n        except KeyError:\n            err = \"_handle_token() got unexpected {0}\"\n            raise ParserError(err.format(type(token).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a Wikicode object from a list of tokens and return it.", "response": "def build(self, tokenlist):\n        \"\"\"Build a Wikicode object from a list tokens and return it.\"\"\"\n        self._tokens = tokenlist\n        self._tokens.reverse()\n        self._push()\n        while self._tokens:\n            node = self._handle_token(self._tokens.pop())\n            self._write(node)\n        return self._pop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_scheme(scheme, slashes=True):\n    scheme = scheme.lower()\n    if slashes:\n        return scheme in URI_SCHEMES\n    return scheme in URI_SCHEMES and not URI_SCHEMES[scheme]", "response": "Return whether the given scheme is valid for external links."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning *code* with char escaped as an HTML entity.", "response": "def _surface_escape(code, char):\n        \"\"\"Return *code* with *char* escaped as an HTML entity.\n\n        The main use of this is to escape pipes (``|``) or equal signs (``=``)\n        in parameter names or values so they are not mistaken for new\n        parameters.\n        \"\"\"\n        replacement = str(HTMLEntity(value=ord(char)))\n        for node in code.filter_text(recursive=False):\n            if char in node:\n                code.replace(node, node.replace(char, replacement), False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _select_theory(theories):\n        if theories:\n            values = tuple(theories.values())\n            best = max(values)\n            confidence = float(best) / sum(values)\n            if confidence > 0.5:\n                return tuple(theories.keys())[values.index(best)]", "response": "Select the most likely spacing convention given different options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _blank_param_value(value):\n        sval = str(value)\n        if sval.isspace():\n            before, after = \"\", sval\n        else:\n            match = re.search(r\"^(\\s*).*?(\\s*)$\", sval, FLAGS)\n            before, after = match.group(1), match.group(2)\n        value.nodes = [Text(before), Text(after)]", "response": "Remove the content from value while keeping its whitespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to determine the whitespace conventions for parameters.", "response": "def _get_spacing_conventions(self, use_names):\n        \"\"\"Try to determine the whitespace conventions for parameters.\n\n        This will examine the existing parameters and use\n        :meth:`_select_theory` to determine if there are any preferred styles\n        for how much whitespace to put before or after the value.\n        \"\"\"\n        before_theories = defaultdict(lambda: 0)\n        after_theories = defaultdict(lambda: 0)\n        for param in self.params:\n            if not param.showkey:\n                continue\n            if use_names:\n                component = str(param.name)\n            else:\n                component = str(param.value)\n            match = re.search(r\"^(\\s*).*?(\\s*)$\", component, FLAGS)\n            before, after = match.group(1), match.group(2)\n            if not use_names and component.isspace() and \"\\n\" in before:\n                # If the value is empty, we expect newlines in the whitespace\n                # to be after the content, not before it:\n                before, after = before.split(\"\\n\", 1)\n                after = \"\\n\" + after\n            before_theories[before] += 1\n            after_theories[after] += 1\n\n        before = self._select_theory(before_theories)\n        after = self._select_theory(after_theories)\n        return before, after"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_dependendent_params(self, i):\n        if not self.params[i].showkey:\n            for param in self.params[i + 1:]:\n                if not param.showkey:\n                    param.showkey = True", "response": "Unhide keys if necessary after removing the param at index i."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a specific parameter from the template.", "response": "def _remove_exact(self, needle, keep_field):\n        \"\"\"Remove a specific parameter, *needle*, from the template.\"\"\"\n        for i, param in enumerate(self.params):\n            if param is needle:\n                if keep_field:\n                    self._blank_param_value(param.value)\n                else:\n                    self._fix_dependendent_params(i)\n                    self.params.pop(i)\n                return\n        raise ValueError(needle)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _should_remove(self, i, name):\n        if self.params[i].showkey:\n            following = self.params[i + 1:]\n            better_matches = [after.name.strip() == name and not after.showkey\n                              for after in following]\n            return any(better_matches)\n        return False", "response": "Check if a parameter with the same name but hidden."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has(self, name, ignore_empty=False):\n        name = str(name).strip()\n        for param in self.params:\n            if param.name.strip() == name:\n                if ignore_empty and not param.value.strip():\n                    continue\n                return True\n        return False", "response": "Return True if any parameter in the template contains the name name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, name):\n        name = str(name).strip()\n        for param in reversed(self.params):\n            if param.name.strip() == name:\n                return param\n        raise ValueError(name)", "response": "Get the parameter whose name is name*."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a parameter to the template with a given name and value.", "response": "def add(self, name, value, showkey=None, before=None,\n            preserve_spacing=True):\n        \"\"\"Add a parameter to the template with a given *name* and *value*.\n\n        *name* and *value* can be anything parsable by\n        :func:`.utils.parse_anything`; pipes and equal signs are automatically\n        escaped from *value* when appropriate.\n\n        If *name* is already a parameter in the template, we'll replace its\n        value.\n\n        If *showkey* is given, this will determine whether or not to show the\n        parameter's name (e.g., ``{{foo|bar}}``'s parameter has a name of\n        ``\"1\"`` but it is hidden); otherwise, we'll make a safe and intelligent\n        guess.\n\n        If *before* is given (either a :class:`.Parameter` object or a name),\n        then we will place the parameter immediately before this one.\n        Otherwise, it will be added at the end. If *before* is a name and\n        exists multiple times in the template, we will place it before the last\n        occurrence. If *before* is not in the template, :exc:`ValueError` is\n        raised. The argument is ignored if *name* is an existing parameter.\n\n        If *preserve_spacing* is ``True``, we will try to preserve whitespace\n        conventions around the parameter, whether it is new or we are updating\n        an existing value. It is disabled for parameters with hidden keys,\n        since MediaWiki doesn't strip whitespace in this case.\n        \"\"\"\n        name, value = parse_anything(name), parse_anything(value)\n        self._surface_escape(value, \"|\")\n\n        if self.has(name):\n            self.remove(name, keep_field=True)\n            existing = self.get(name)\n            if showkey is not None:\n                existing.showkey = showkey\n            if not existing.showkey:\n                self._surface_escape(value, \"=\")\n            nodes = existing.value.nodes\n            if preserve_spacing and existing.showkey:\n                for i in range(2):  # Ignore empty text nodes\n                    if not nodes[i]:\n                        nodes[i] = None\n                existing.value = parse_anything([nodes[0], value, nodes[1]])\n            else:\n                existing.value = value\n            return existing\n\n        if showkey is None:\n            if Parameter.can_hide_key(name):\n                int_name = int(str(name))\n                int_keys = set()\n                for param in self.params:\n                    if not param.showkey:\n                        int_keys.add(int(str(param.name)))\n                expected = min(set(range(1, len(int_keys) + 2)) - int_keys)\n                if expected == int_name:\n                    showkey = False\n                else:\n                    showkey = True\n            else:\n                showkey = True\n        if not showkey:\n            self._surface_escape(value, \"=\")\n\n        if preserve_spacing and showkey:\n            before_n, after_n = self._get_spacing_conventions(use_names=True)\n            before_v, after_v = self._get_spacing_conventions(use_names=False)\n            name = parse_anything([before_n, name, after_n])\n            value = parse_anything([before_v, value, after_v])\n\n        param = Parameter(name, value, showkey)\n        if before:\n            if not isinstance(before, Parameter):\n                before = self.get(before)\n            self.params.insert(self.params.index(before), param)\n        else:\n            self.params.append(param)\n        return param"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a parameter from the template identified by param.", "response": "def remove(self, param, keep_field=False):\n        \"\"\"Remove a parameter from the template, identified by *param*.\n\n        If *param* is a :class:`.Parameter` object, it will be matched exactly,\n        otherwise it will be treated like the *name* argument to :meth:`has`\n        and :meth:`get`.\n\n        If *keep_field* is ``True``, we will keep the parameter's name, but\n        blank its value. Otherwise, we will remove the parameter completely.\n\n        When removing a parameter with a hidden name, subsequent parameters\n        with hidden names will be made visible. For example, removing ``bar``\n        from ``{{foo|bar|baz}}`` produces ``{{foo|2=baz}}`` because\n        ``{{foo|baz}}`` is incorrect.\n\n        If the parameter shows up multiple times in the template and *param* is\n        not a :class:`.Parameter` object, we will remove all instances of it\n        (and keep only one if *keep_field* is ``True`` - either the one with a\n        hidden name, if it exists, or the first instance).\n        \"\"\"\n        if isinstance(param, Parameter):\n            return self._remove_exact(param, keep_field)\n\n        name = str(param).strip()\n        removed = False\n        to_remove = []\n\n        for i, param in enumerate(self.params):\n            if param.name.strip() == name:\n                if keep_field:\n                    if self._should_remove(i, name):\n                        to_remove.append(i)\n                    else:\n                        self._blank_param_value(param.value)\n                        keep_field = False\n                else:\n                    self._fix_dependendent_params(i)\n                    to_remove.append(i)\n                if not removed:\n                    removed = True\n\n        if not removed:\n            raise ValueError(name)\n        for i in reversed(to_remove):\n            self.params.pop(i)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new token stack context and textbuffer to the list.", "response": "def _push(self, context=0):\n        \"\"\"Add a new token stack, context, and textbuffer to the list.\"\"\"\n        new_ident = (self._head, context)\n        if new_ident in self._bad_routes:\n            raise BadRoute(context)\n\n        self._stacks.append([[], context, [], new_ident])\n        self._depth += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npushing the textbuffer onto the stack and clear it.", "response": "def _push_textbuffer(self):\n        \"\"\"Push the textbuffer onto the stack as a Text node and clear it.\"\"\"\n        if self._textbuffer:\n            self._stack.append(tokens.Text(text=\"\".join(self._textbuffer)))\n            self._textbuffer = []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pop(self, keep_context=False):\n        self._push_textbuffer()\n        self._depth -= 1\n        if keep_context:\n            context = self._context\n            stack = self._stacks.pop()[0]\n            self._context = context\n            return stack\n        return self._stacks.pop()[0]", "response": "Pop the current stack and return the stack s context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfail the current tokenization route.", "response": "def _fail_route(self):\n        \"\"\"Fail the current tokenization route.\n\n        Discards the current stack/context/textbuffer and raises\n        :exc:`.BadRoute`.\n        \"\"\"\n        context = self._context\n        self._memoize_bad_route()\n        self._pop()\n        raise BadRoute(context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _emit_all(self, tokenlist):\n        if tokenlist and isinstance(tokenlist[0], tokens.Text):\n            self._emit_text(tokenlist.pop(0).text)\n        self._push_textbuffer()\n        self._stack.extend(tokenlist)", "response": "Write a series of tokens to the current stack at once."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npop the current stack write text and then write the stack.", "response": "def _emit_text_then_stack(self, text):\n        \"\"\"Pop the current stack, write *text*, and then write the stack.\"\"\"\n        stack = self._pop()\n        self._emit_text(text)\n        if stack:\n            self._emit_all(stack)\n        self._head -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the value at a relative point in the wikicode.", "response": "def _read(self, delta=0, wrap=False, strict=False):\n        \"\"\"Read the value at a relative point in the wikicode.\n\n        The value is read from :attr:`self._head <_head>` plus the value of\n        *delta* (which can be negative). If *wrap* is ``False``, we will not\n        allow attempts to read from the end of the string if ``self._head +\n        delta`` is negative. If *strict* is ``True``, the route will be failed\n        (with :meth:`_fail_route`) if we try to read from past the end of the\n        string; otherwise, :attr:`self.END <END>` is returned. If we try to\n        read from before the start of the string, :attr:`self.START <START>` is\n        returned.\n        \"\"\"\n        index = self._head + delta\n        if index < 0 and (not wrap or abs(index) > len(self._text)):\n            return self.START\n        try:\n            return self._text[index]\n        except IndexError:\n            if strict:\n                self._fail_route()\n            return self.END"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_template(self, has_content):\n        reset = self._head\n        context = contexts.TEMPLATE_NAME\n        if has_content:\n            context |= contexts.HAS_TEMPLATE\n        try:\n            template = self._parse(context)\n        except BadRoute:\n            self._head = reset\n            raise\n        self._emit_first(tokens.TemplateOpen())\n        self._emit_all(template)\n        self._emit(tokens.TemplateClose())", "response": "Parse a template at the head of the wikicode string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses an argument at the head of the wikicode string.", "response": "def _parse_argument(self):\n        \"\"\"Parse an argument at the head of the wikicode string.\"\"\"\n        reset = self._head\n        try:\n            argument = self._parse(contexts.ARGUMENT_NAME)\n        except BadRoute:\n            self._head = reset\n            raise\n        self._emit_first(tokens.ArgumentOpen())\n        self._emit_all(argument)\n        self._emit(tokens.ArgumentClose())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a template or argument at the head of the wikicode string.", "response": "def _parse_template_or_argument(self):\n        \"\"\"Parse a template or argument at the head of the wikicode string.\"\"\"\n        self._head += 2\n        braces = 2\n        while self._read() == \"{\":\n            self._head += 1\n            braces += 1\n        has_content = False\n        self._push()\n\n        while braces:\n            if braces == 1:\n                return self._emit_text_then_stack(\"{\")\n            if braces == 2:\n                try:\n                    self._parse_template(has_content)\n                except BadRoute:\n                    return self._emit_text_then_stack(\"{{\")\n                break\n            try:\n                self._parse_argument()\n                braces -= 3\n            except BadRoute:\n                try:\n                    self._parse_template(has_content)\n                    braces -= 2\n                except BadRoute:\n                    return self._emit_text_then_stack(\"{\" * braces)\n            if braces:\n                has_content = True\n                self._head += 1\n\n        self._emit_all(self._pop())\n        if self._context & contexts.FAIL_NEXT:\n            self._context ^= contexts.FAIL_NEXT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a template parameter at the head of the string.", "response": "def _handle_template_param(self):\n        \"\"\"Handle a template parameter at the head of the string.\"\"\"\n        if self._context & contexts.TEMPLATE_NAME:\n            if not self._context & (contexts.HAS_TEXT | contexts.HAS_TEMPLATE):\n                self._fail_route()\n            self._context ^= contexts.TEMPLATE_NAME\n        elif self._context & contexts.TEMPLATE_PARAM_VALUE:\n            self._context ^= contexts.TEMPLATE_PARAM_VALUE\n        else:\n            self._emit_all(self._pop())\n        self._context |= contexts.TEMPLATE_PARAM_KEY\n        self._emit(tokens.TemplateParamSeparator())\n        self._push(self._context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_template_param_value(self):\n        self._emit_all(self._pop())\n        self._context ^= contexts.TEMPLATE_PARAM_KEY\n        self._context |= contexts.TEMPLATE_PARAM_VALUE\n        self._emit(tokens.TemplateParamEquals())", "response": "Handle a template parameter s value at the head of the string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the end of a template at the head of the string.", "response": "def _handle_template_end(self):\n        \"\"\"Handle the end of a template at the head of the string.\"\"\"\n        if self._context & contexts.TEMPLATE_NAME:\n            if not self._context & (contexts.HAS_TEXT | contexts.HAS_TEMPLATE):\n                self._fail_route()\n        elif self._context & contexts.TEMPLATE_PARAM_KEY:\n            self._emit_all(self._pop())\n        self._head += 1\n        return self._pop()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_argument_separator(self):\n        self._context ^= contexts.ARGUMENT_NAME\n        self._context |= contexts.ARGUMENT_DEFAULT\n        self._emit(tokens.ArgumentSeparator())", "response": "Handle the separator between an argument s name and default."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an internal wikilink at the head of the wikicode string.", "response": "def _parse_wikilink(self):\n        \"\"\"Parse an internal wikilink at the head of the wikicode string.\"\"\"\n        reset = self._head + 1\n        self._head += 2\n        try:\n            # If the wikilink looks like an external link, parse it as such:\n            link, extra, delta = self._really_parse_external_link(True)\n        except BadRoute:\n            self._head = reset + 1\n            try:\n                # Otherwise, actually parse it as a wikilink:\n                wikilink = self._parse(contexts.WIKILINK_TITLE)\n            except BadRoute:\n                self._head = reset\n                self._emit_text(\"[[\")\n            else:\n                self._emit(tokens.WikilinkOpen())\n                self._emit_all(wikilink)\n                self._emit(tokens.WikilinkClose())\n        else:\n            if self._context & contexts.EXT_LINK_TITLE:\n                # In this exceptional case, an external link that looks like a\n                # wikilink inside of an external link is parsed as text:\n                self._head = reset\n                self._emit_text(\"[[\")\n                return\n            self._emit_text(\"[\")\n            self._emit(tokens.ExternalLinkOpen(brackets=True))\n            self._emit_all(link)\n            self._emit(tokens.ExternalLinkClose())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the separator between a wikilink s title and its text.", "response": "def _handle_wikilink_separator(self):\n        \"\"\"Handle the separator between a wikilink's title and its text.\"\"\"\n        self._context ^= contexts.WIKILINK_TITLE\n        self._context |= contexts.WIKILINK_TEXT\n        self._emit(tokens.WikilinkSeparator())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_bracketed_uri_scheme(self):\n        self._push(contexts.EXT_LINK_URI)\n        if self._read() == self._read(1) == \"/\":\n            self._emit_text(\"//\")\n            self._head += 2\n        else:\n            valid = \"abcdefghijklmnopqrstuvwxyz0123456789+.-\"\n            all_valid = lambda: all(char in valid for char in self._read())\n            scheme = \"\"\n            while self._read() is not self.END and all_valid():\n                scheme += self._read()\n                self._emit_text(self._read())\n                self._head += 1\n            if self._read() != \":\":\n                self._fail_route()\n            self._emit_text(\":\")\n            self._head += 1\n            slashes = self._read() == self._read(1) == \"/\"\n            if slashes:\n                self._emit_text(\"//\")\n                self._head += 2\n            if not is_scheme(scheme, slashes):\n                self._fail_route()", "response": "Parse the URI scheme of a bracket - enclosed external link."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the URI scheme of a free external link.", "response": "def _parse_free_uri_scheme(self):\n        \"\"\"Parse the URI scheme of a free (no brackets) external link.\"\"\"\n        valid = \"abcdefghijklmnopqrstuvwxyz0123456789+.-\"\n        scheme = []\n        try:\n            # We have to backtrack through the textbuffer looking for our\n            # scheme since it was just parsed as text:\n            for chunk in reversed(self._textbuffer):\n                for char in reversed(chunk):\n                    if char.isspace() or char in self.MARKERS:\n                        raise StopIteration()\n                    if char not in valid:\n                        raise BadRoute()\n                    scheme.append(char)\n        except StopIteration:\n            pass\n        scheme = \"\".join(reversed(scheme))\n        slashes = self._read() == self._read(1) == \"/\"\n        if not is_scheme(scheme, slashes):\n            raise BadRoute()\n        self._push(self._context | contexts.EXT_LINK_URI)\n        self._emit_text(scheme)\n        self._emit_text(\":\")\n        if slashes:\n            self._emit_text(\"//\")\n            self._head += 2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_free_link_text(self, punct, tail, this):\n        if \"(\" in this and \")\" in punct:\n            punct = punct[:-1]  # ')' is not longer valid punctuation\n        if this.endswith(punct):\n            for i in range(len(this) - 1, 0, -1):\n                if this[i - 1] not in punct:\n                    break\n            else:\n                i = 0\n            stripped = this[:i]\n            if stripped and tail:\n                self._emit_text(tail)\n                tail = \"\"\n            tail += this[i:]\n            this = stripped\n        elif tail:\n            self._emit_text(tail)\n            tail = \"\"\n        self._emit_text(this)\n        return punct, tail", "response": "Handle text in a free ext link including trailing punctuation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_free_link_end(self, this, next):\n        # Built from _parse()'s end sentinels:\n        after, ctx = self._read(2), self._context\n        equal_sign_contexts = contexts.TEMPLATE_PARAM_KEY | contexts.HEADING\n        return (this in (self.END, \"\\n\", \"[\", \"]\", \"<\", \">\") or\n                this == next == \"'\" or\n                (this == \"|\" and ctx & contexts.TEMPLATE) or\n                (this == \"=\" and ctx & equal_sign_contexts) or\n                (this == next == \"}\" and ctx & contexts.TEMPLATE) or\n                (this == next == after == \"}\" and ctx & contexts.ARGUMENT))", "response": "Return whether the current head is the end of a free link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the URI scheme of a new external link from the textbuffer.", "response": "def _remove_uri_scheme_from_textbuffer(self, scheme):\n        \"\"\"Remove the URI scheme of a new external link from the textbuffer.\"\"\"\n        length = len(scheme)\n        while length:\n            if length < len(self._textbuffer[-1]):\n                self._textbuffer[-1] = self._textbuffer[-1][:-length]\n                break\n            length -= len(self._textbuffer[-1])\n            self._textbuffer.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an external link at the head of the wikicode string.", "response": "def _parse_external_link(self, brackets):\n        \"\"\"Parse an external link at the head of the wikicode string.\"\"\"\n        if self._context & contexts.NO_EXT_LINKS or not self._can_recurse():\n            if not brackets and self._context & contexts.DL_TERM:\n                self._handle_dl_term()\n            else:\n                self._emit_text(self._read())\n            return\n\n        reset = self._head\n        self._head += 1\n        try:\n            link, extra, delta = self._really_parse_external_link(brackets)\n        except BadRoute:\n            self._head = reset\n            if not brackets and self._context & contexts.DL_TERM:\n                self._handle_dl_term()\n            else:\n                self._emit_text(self._read())\n        else:\n            if not brackets:\n                scheme = link[0].text.split(\":\", 1)[0]\n                self._remove_uri_scheme_from_textbuffer(scheme)\n            self._emit(tokens.ExternalLinkOpen(brackets=brackets))\n            self._emit_all(link)\n            self._emit(tokens.ExternalLinkClose())\n            self._head += delta\n            if extra:\n                self._emit_text(extra)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_heading(self):\n        self._global |= contexts.GL_HEADING\n        reset = self._head\n        self._head += 1\n        best = 1\n        while self._read() == \"=\":\n            best += 1\n            self._head += 1\n        context = contexts.HEADING_LEVEL_1 << min(best - 1, 5)\n\n        try:\n            title, level = self._parse(context)\n        except BadRoute:\n            self._head = reset + best - 1\n            self._emit_text(\"=\" * best)\n        else:\n            self._emit(tokens.HeadingStart(level=level))\n            if level < best:\n                self._emit_text(\"=\" * (best - level))\n            self._emit_all(title)\n            self._emit(tokens.HeadingEnd())\n        finally:\n            self._global ^= contexts.GL_HEADING", "response": "Parse a section heading at the head of the wikicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_heading_end(self):\n        reset = self._head\n        self._head += 1\n        best = 1\n        while self._read() == \"=\":\n            best += 1\n            self._head += 1\n        current = int(log(self._context / contexts.HEADING_LEVEL_1, 2)) + 1\n        level = min(current, min(best, 6))\n\n        try:  # Try to check for a heading closure after this one\n            after, after_level = self._parse(self._context)\n        except BadRoute:\n            if level < best:\n                self._emit_text(\"=\" * (best - level))\n            self._head = reset + best - 1\n            return self._pop(), level\n        else:  # Found another closure\n            self._emit_text(\"=\" * best)\n            self._emit_all(after)\n            return self._pop(), after_level", "response": "Handle the end of a section heading at the head of the string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _really_parse_entity(self):\n        self._emit(tokens.HTMLEntityStart())\n        self._head += 1\n\n        this = self._read(strict=True)\n        if this == \"#\":\n            numeric = True\n            self._emit(tokens.HTMLEntityNumeric())\n            self._head += 1\n            this = self._read(strict=True)\n            if this[0].lower() == \"x\":\n                hexadecimal = True\n                self._emit(tokens.HTMLEntityHex(char=this[0]))\n                this = this[1:]\n                if not this:\n                    self._fail_route()\n            else:\n                hexadecimal = False\n        else:\n            numeric = hexadecimal = False\n\n        valid = \"0123456789abcdefABCDEF\" if hexadecimal else \"0123456789\"\n        if not numeric and not hexadecimal:\n            valid += \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n        if not all([char in valid for char in this]):\n            self._fail_route()\n\n        self._head += 1\n        if self._read() != \";\":\n            self._fail_route()\n        if numeric:\n            test = int(this, 16) if hexadecimal else int(this)\n            if test < 1 or test > 0x10FFFF:\n                self._fail_route()\n        else:\n            if this not in htmlentities.entitydefs:\n                self._fail_route()\n\n        self._emit(tokens.Text(text=this))\n        self._emit(tokens.HTMLEntityEnd())", "response": "Actually parse an HTML entity and ensure that it is valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an HTML entity at the head of the wikicode string.", "response": "def _parse_entity(self):\n        \"\"\"Parse an HTML entity at the head of the wikicode string.\"\"\"\n        reset = self._head\n        try:\n            self._push(contexts.HTML_ENTITY)\n            self._really_parse_entity()\n        except BadRoute:\n            self._head = reset\n            self._emit_text(self._read())\n        else:\n            self._emit_all(self._pop())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an HTML comment at the head of the wikicode string.", "response": "def _parse_comment(self):\n        \"\"\"Parse an HTML comment at the head of the wikicode string.\"\"\"\n        self._head += 4\n        reset = self._head - 1\n        self._push()\n        while True:\n            this = self._read()\n            if this == self.END:\n                self._pop()\n                self._head = reset\n                self._emit_text(\"<!--\")\n                return\n            if this == self._read(1) == \"-\" and self._read(2) == \">\":\n                self._emit_first(tokens.CommentStart())\n                self._emit(tokens.CommentEnd())\n                self._emit_all(self._pop())\n                self._head += 2\n                if self._context & contexts.FAIL_NEXT:\n                    # _verify_safe() sets this flag while parsing a template\n                    # or link when it encounters what might be a comment -- we\n                    # must unset it to let _verify_safe() know it was correct:\n                    self._context ^= contexts.FAIL_NEXT\n                return\n            self._emit_text(this)\n            self._head += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _push_tag_buffer(self, data):\n        if data.context & data.CX_QUOTED:\n            self._emit_first(tokens.TagAttrQuote(char=data.quoter))\n            self._emit_all(self._pop())\n        buf = data.padding_buffer\n        self._emit_first(tokens.TagAttrStart(\n            pad_first=buf[\"first\"], pad_before_eq=buf[\"before_eq\"],\n            pad_after_eq=buf[\"after_eq\"]))\n        self._emit_all(self._pop())\n        for key in data.padding_buffer:\n            data.padding_buffer[key] = \"\"", "response": "Write a pending tag attribute from data to the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_tag_space(self, data, text):\n        ctx = data.context\n        end_of_value = ctx & data.CX_ATTR_VALUE and not ctx & (data.CX_QUOTED | data.CX_NOTE_QUOTE)\n        if end_of_value or (ctx & data.CX_QUOTED and ctx & data.CX_NOTE_SPACE):\n            self._push_tag_buffer(data)\n            data.context = data.CX_ATTR_READY\n        elif ctx & data.CX_NOTE_SPACE:\n            data.context = data.CX_ATTR_READY\n        elif ctx & data.CX_ATTR_NAME:\n            data.context |= data.CX_NOTE_EQUALS\n            data.padding_buffer[\"before_eq\"] += text\n        if ctx & data.CX_QUOTED and not ctx & data.CX_NOTE_SPACE:\n            self._emit_text(text)\n        elif data.context & data.CX_ATTR_READY:\n            data.padding_buffer[\"first\"] += text\n        elif data.context & data.CX_ATTR_VALUE:\n            data.padding_buffer[\"after_eq\"] += text", "response": "Handle whitespace inside of an HTML open tag."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_tag_text(self, text):\n        next = self._read(1)\n        if not self._can_recurse() or text not in self.MARKERS:\n            self._emit_text(text)\n        elif text == next == \"{\":\n            self._parse_template_or_argument()\n        elif text == next == \"[\":\n            self._parse_wikilink()\n        elif text == \"<\":\n            self._parse_tag()\n        else:\n            self._emit_text(text)", "response": "Handle regular text inside of an HTML open tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling all sorts of text data inside of an HTML open tag.", "response": "def _handle_tag_data(self, data, text):\n        \"\"\"Handle all sorts of *text* data inside of an HTML open tag.\"\"\"\n        for chunk in self.tag_splitter.split(text):\n            if not chunk:\n                continue\n            if data.context & data.CX_NAME:\n                if chunk in self.MARKERS or chunk.isspace():\n                    self._fail_route()  # Tags must start with text, not spaces\n                data.context = data.CX_NOTE_SPACE\n            elif chunk.isspace():\n                self._handle_tag_space(data, chunk)\n                continue\n            elif data.context & data.CX_NOTE_SPACE:\n                if data.context & data.CX_QUOTED:\n                    data.context = data.CX_ATTR_VALUE\n                    self._memoize_bad_route()\n                    self._pop()\n                    self._head = data.reset - 1  # Will be auto-incremented\n                    return  # Break early\n                self._fail_route()\n            elif data.context & data.CX_ATTR_READY:\n                data.context = data.CX_ATTR_NAME\n                self._push(contexts.TAG_ATTR)\n            elif data.context & data.CX_ATTR_NAME:\n                if chunk == \"=\":\n                    data.context = data.CX_ATTR_VALUE | data.CX_NOTE_QUOTE\n                    self._emit(tokens.TagAttrEquals())\n                    continue\n                if data.context & data.CX_NOTE_EQUALS:\n                    self._push_tag_buffer(data)\n                    data.context = data.CX_ATTR_NAME\n                    self._push(contexts.TAG_ATTR)\n            else:  # data.context & data.CX_ATTR_VALUE assured\n                escaped = self._read(-1) == \"\\\\\" and self._read(-2) != \"\\\\\"\n                if data.context & data.CX_NOTE_QUOTE:\n                    data.context ^= data.CX_NOTE_QUOTE\n                    if chunk in \"'\\\"\" and not escaped:\n                        data.context |= data.CX_QUOTED\n                        data.quoter = chunk\n                        data.reset = self._head\n                        try:\n                            self._push(self._context)\n                        except BadRoute:\n                            # Already failed to parse this as a quoted string\n                            data.context = data.CX_ATTR_VALUE\n                            self._head -= 1\n                            return\n                        continue\n                elif data.context & data.CX_QUOTED:\n                    if chunk == data.quoter and not escaped:\n                        data.context |= data.CX_NOTE_SPACE\n                        continue\n            self._handle_tag_text(chunk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_tag_close_open(self, data, token):\n        if data.context & (data.CX_ATTR_NAME | data.CX_ATTR_VALUE):\n            self._push_tag_buffer(data)\n        self._emit(token(padding=data.padding_buffer[\"first\"]))\n        self._head += 1", "response": "Handle the closing of a tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_tag_open_close(self):\n        self._emit(tokens.TagOpenClose())\n        self._push(contexts.TAG_CLOSE)\n        self._head += 1", "response": "Handle the opening of a closing tag."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_tag_close_close(self):\n        strip = lambda tok: tok.text.rstrip().lower()\n        closing = self._pop()\n        if len(closing) != 1 or (not isinstance(closing[0], tokens.Text) or\n                                 strip(closing[0]) != strip(self._stack[1])):\n            self._fail_route()\n        self._emit_all(closing)\n        self._emit(tokens.TagCloseClose())\n        return self._pop()", "response": "Handle the ending of a closing tag ("}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the body of an HTML tag that is parser - blacklisted.", "response": "def _handle_blacklisted_tag(self):\n        \"\"\"Handle the body of an HTML tag that is parser-blacklisted.\"\"\"\n        strip = lambda text: text.rstrip().lower()\n        while True:\n            this, next = self._read(), self._read(1)\n            if this is self.END:\n                self._fail_route()\n            elif this == \"<\" and next == \"/\":\n                self._head += 3\n                if self._read() != \">\" or (strip(self._read(-1)) !=\n                                           strip(self._stack[1].text)):\n                    self._head -= 1\n                    self._emit_text(\"</\")\n                    continue\n                self._emit(tokens.TagOpenClose())\n                self._emit_text(self._read(-1))\n                self._emit(tokens.TagCloseClose())\n                return self._pop()\n            elif this == \"&\":\n                self._parse_entity()\n            else:\n                self._emit_text(this)\n            self._head += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the end of an implicitly closing single - only HTML tag.", "response": "def _handle_single_only_tag_end(self):\n        \"\"\"Handle the end of an implicitly closing single-only HTML tag.\"\"\"\n        padding = self._stack.pop().padding\n        self._emit(tokens.TagCloseSelfclose(padding=padding, implicit=True))\n        self._head -= 1  # Offset displacement done by _handle_tag_close_open\n        return self._pop()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_single_tag_end(self):\n        stack = self._stack\n        # We need to find the index of the TagCloseOpen token corresponding to\n        # the TagOpenOpen token located at index 0:\n        depth = 1\n        for index, token in enumerate(stack[2:], 2):\n            if isinstance(token, tokens.TagOpenOpen):\n                depth += 1\n            elif isinstance(token, tokens.TagCloseOpen):\n                depth -= 1\n                if depth == 0:\n                    break\n            elif isinstance(token, tokens.TagCloseSelfclose):\n                depth -= 1\n                if depth == 0:  # pragma: no cover (untestable/exceptional)\n                    raise ParserError(\n                        \"_handle_single_tag_end() got an unexpected \"\n                        \"TagCloseSelfclose\")\n        else:  # pragma: no cover (untestable/exceptional case)\n            raise ParserError(\"_handle_single_tag_end() missed a TagCloseOpen\")\n        padding = stack[index].padding\n        stack[index] = tokens.TagCloseSelfclose(padding=padding, implicit=True)\n        return self._pop()", "response": "Handle the end when inside a single - supporting HTML tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the start of an implicitly closing single tag.", "response": "def _handle_invalid_tag_start(self):\n        \"\"\"Handle the (possible) start of an implicitly closing single tag.\"\"\"\n        reset = self._head + 1\n        self._head += 2\n        try:\n            if not is_single_only(self.tag_splitter.split(self._read())[0]):\n                raise BadRoute()\n            tag = self._really_parse_tag()\n        except BadRoute:\n            self._head = reset\n            self._emit_text(\"</\")\n        else:\n            tag[0].invalid = True  # Set flag of TagOpenOpen\n            self._emit_all(tag)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an HTML tag at the head of the wikicode string.", "response": "def _parse_tag(self):\n        \"\"\"Parse an HTML tag at the head of the wikicode string.\"\"\"\n        reset = self._head\n        self._head += 1\n        try:\n            tag = self._really_parse_tag()\n        except BadRoute:\n            self._head = reset\n            self._emit_text(\"<\")\n        else:\n            self._emit_all(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _emit_style_tag(self, tag, markup, body):\n        self._emit(tokens.TagOpenOpen(wiki_markup=markup))\n        self._emit_text(tag)\n        self._emit(tokens.TagCloseOpen())\n        self._emit_all(body)\n        self._emit(tokens.TagOpenClose())\n        self._emit_text(tag)\n        self._emit(tokens.TagCloseClose())", "response": "Write the body of a tag and the tokens that should surround it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_italics(self):\n        reset = self._head\n        try:\n            stack = self._parse(contexts.STYLE_ITALICS)\n        except BadRoute as route:\n            self._head = reset\n            if route.context & contexts.STYLE_PASS_AGAIN:\n                new_ctx = contexts.STYLE_ITALICS | contexts.STYLE_SECOND_PASS\n                stack = self._parse(new_ctx)\n            else:\n                return self._emit_text(\"''\")\n        self._emit_style_tag(\"i\", \"''\", stack)", "response": "Parse wiki - style italics."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses wiki - style bold.", "response": "def _parse_bold(self):\n        \"\"\"Parse wiki-style bold.\"\"\"\n        reset = self._head\n        try:\n            stack = self._parse(contexts.STYLE_BOLD)\n        except BadRoute:\n            self._head = reset\n            if self._context & contexts.STYLE_SECOND_PASS:\n                self._emit_text(\"'\")\n                return True\n            elif self._context & contexts.STYLE_ITALICS:\n                self._context |= contexts.STYLE_PASS_AGAIN\n                self._emit_text(\"'''\")\n            else:\n                self._emit_text(\"'\")\n                self._parse_italics()\n        else:\n            self._emit_style_tag(\"b\", \"'''\", stack)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_italics_and_bold(self):\n        reset = self._head\n        try:\n            stack = self._parse(contexts.STYLE_BOLD)\n        except BadRoute:\n            self._head = reset\n            try:\n                stack = self._parse(contexts.STYLE_ITALICS)\n            except BadRoute:\n                self._head = reset\n                self._emit_text(\"'''''\")\n            else:\n                reset = self._head\n                try:\n                    stack2 = self._parse(contexts.STYLE_BOLD)\n                except BadRoute:\n                    self._head = reset\n                    self._emit_text(\"'''\")\n                    self._emit_style_tag(\"i\", \"''\", stack)\n                else:\n                    self._push()\n                    self._emit_style_tag(\"i\", \"''\", stack)\n                    self._emit_all(stack2)\n                    self._emit_style_tag(\"b\", \"'''\", self._pop())\n        else:\n            reset = self._head\n            try:\n                stack2 = self._parse(contexts.STYLE_ITALICS)\n            except BadRoute:\n                self._head = reset\n                self._emit_text(\"''\")\n                self._emit_style_tag(\"b\", \"'''\", stack)\n            else:\n                self._push()\n                self._emit_style_tag(\"b\", \"'''\", stack)\n                self._emit_all(stack2)\n                self._emit_style_tag(\"i\", \"''\", self._pop())", "response": "Parse wiki - style italics and bold together ( i. e. five ticks )."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_style(self):\n        self._head += 2\n        ticks = 2\n        while self._read() == \"'\":\n            self._head += 1\n            ticks += 1\n        italics = self._context & contexts.STYLE_ITALICS\n        bold = self._context & contexts.STYLE_BOLD\n\n        if ticks > 5:\n            self._emit_text(\"'\" * (ticks - 5))\n            ticks = 5\n        elif ticks == 4:\n            self._emit_text(\"'\")\n            ticks = 3\n\n        if (italics and ticks in (2, 5)) or (bold and ticks in (3, 5)):\n            if ticks == 5:\n                self._head -= 3 if italics else 2\n            return self._pop()\n        elif not self._can_recurse():\n            if ticks == 3:\n                if self._context & contexts.STYLE_SECOND_PASS:\n                    self._emit_text(\"'\")\n                    return self._pop()\n                if self._context & contexts.STYLE_ITALICS:\n                    self._context |= contexts.STYLE_PASS_AGAIN\n            self._emit_text(\"'\" * ticks)\n        elif ticks == 2:\n            self._parse_italics()\n        elif ticks == 3:\n            if self._parse_bold():\n                return self._pop()\n        else:  # ticks == 5\n            self._parse_italics_and_bold()\n        self._head -= 1", "response": "Parse wiki - style formatting."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle a list marker at the head.", "response": "def _handle_list_marker(self):\n        \"\"\"Handle a list marker at the head (``#``, ``*``, ``;``, ``:``).\"\"\"\n        markup = self._read()\n        if markup == \";\":\n            self._context |= contexts.DL_TERM\n        self._emit(tokens.TagOpenOpen(wiki_markup=markup))\n        self._emit_text(get_html_tag(markup))\n        self._emit(tokens.TagCloseSelfclose())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a wiki - style list.", "response": "def _handle_list(self):\n        \"\"\"Handle a wiki-style list (``#``, ``*``, ``;``, ``:``).\"\"\"\n        self._handle_list_marker()\n        while self._read(1) in (\"#\", \"*\", \";\", \":\"):\n            self._head += 1\n            self._handle_list_marker()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling a wiki - style horizontal rule in the string.", "response": "def _handle_hr(self):\n        \"\"\"Handle a wiki-style horizontal rule (``----``) in the string.\"\"\"\n        length = 4\n        self._head += 3\n        while self._read(1) == \"-\":\n            length += 1\n            self._head += 1\n        self._emit(tokens.TagOpenOpen(wiki_markup=\"-\" * length))\n        self._emit_text(\"hr\")\n        self._emit(tokens.TagCloseSelfclose())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the term in a description list.", "response": "def _handle_dl_term(self):\n        \"\"\"Handle the term in a description list (``foo`` in ``;foo:bar``).\"\"\"\n        self._context ^= contexts.DL_TERM\n        if self._read() == \":\":\n            self._handle_list_marker()\n        else:\n            self._emit_text(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nemit a table tag.", "response": "def _emit_table_tag(self, open_open_markup, tag, style, padding,\n                        close_open_markup, contents, open_close_markup):\n        \"\"\"Emit a table tag.\"\"\"\n        self._emit(tokens.TagOpenOpen(wiki_markup=open_open_markup))\n        self._emit_text(tag)\n        if style:\n            self._emit_all(style)\n        if close_open_markup:\n            self._emit(tokens.TagCloseOpen(wiki_markup=close_open_markup,\n                                           padding=padding))\n        else:\n            self._emit(tokens.TagCloseOpen(padding=padding))\n        if contents:\n            self._emit_all(contents)\n        self._emit(tokens.TagOpenClose(wiki_markup=open_close_markup))\n        self._emit_text(tag)\n        self._emit(tokens.TagCloseClose())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_table_style(self, end_token):\n        data = _TagOpenData()\n        data.context = _TagOpenData.CX_ATTR_READY\n        while True:\n            this = self._read()\n            can_exit = (not data.context & data.CX_QUOTED or\n                        data.context & data.CX_NOTE_SPACE)\n            if this == end_token and can_exit:\n                if data.context & (data.CX_ATTR_NAME | data.CX_ATTR_VALUE):\n                    self._push_tag_buffer(data)\n                if this.isspace():\n                    data.padding_buffer[\"first\"] += this\n                return data.padding_buffer[\"first\"]\n            elif this is self.END or this == end_token:\n                if self._context & contexts.TAG_ATTR:\n                    if data.context & data.CX_QUOTED:\n                        # Unclosed attribute quote: reset, don't die\n                        data.context = data.CX_ATTR_VALUE\n                        self._memoize_bad_route()\n                        self._pop()\n                        self._head = data.reset\n                        continue\n                    self._pop()\n                self._fail_route()\n            else:\n                self._handle_tag_data(data, this)\n            self._head += 1", "response": "Handle style attributes for a table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_table(self):\n        reset = self._head\n        self._head += 2\n        try:\n            self._push(contexts.TABLE_OPEN)\n            padding = self._handle_table_style(\"\\n\")\n        except BadRoute:\n            self._head = reset\n            self._emit_text(\"{\")\n            return\n        style = self._pop()\n\n        self._head += 1\n        restore_point = self._stack_ident\n        try:\n            table = self._parse(contexts.TABLE_OPEN)\n        except BadRoute:\n            while self._stack_ident != restore_point:\n                self._memoize_bad_route()\n                self._pop()\n            self._head = reset\n            self._emit_text(\"{\")\n            return\n\n        self._emit_table_tag(\"{|\", \"table\", style, padding, None, table, \"|}\")\n        # Offset displacement done by _parse():\n        self._head -= 1", "response": "Parse a wikicode table by starting with the first line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses as style until end of the line then continue.", "response": "def _handle_table_row(self):\n        \"\"\"Parse as style until end of the line, then continue.\"\"\"\n        self._head += 2\n        if not self._can_recurse():\n            self._emit_text(\"|-\")\n            self._head -= 1\n            return\n\n        self._push(contexts.TABLE_OPEN | contexts.TABLE_ROW_OPEN)\n        padding = self._handle_table_style(\"\\n\")\n        style = self._pop()\n\n        # Don't parse the style separator:\n        self._head += 1\n        row = self._parse(contexts.TABLE_OPEN | contexts.TABLE_ROW_OPEN)\n\n        self._emit_table_tag(\"|-\", \"tr\", style, padding, None, row, \"\")\n        # Offset displacement done by parse():\n        self._head -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a table cell.", "response": "def _handle_table_cell(self, markup, tag, line_context):\n        \"\"\"Parse as normal syntax unless we hit a style marker, then parse\n        style as HTML attributes and the remainder as normal syntax.\"\"\"\n        old_context = self._context\n        padding, style = \"\", None\n        self._head += len(markup)\n        reset = self._head\n        if not self._can_recurse():\n            self._emit_text(markup)\n            self._head -= 1\n            return\n\n        cell = self._parse(contexts.TABLE_OPEN | contexts.TABLE_CELL_OPEN |\n                           line_context | contexts.TABLE_CELL_STYLE)\n        cell_context = self._context\n        self._context = old_context\n        reset_for_style = cell_context & contexts.TABLE_CELL_STYLE\n        if reset_for_style:\n            self._head = reset\n            self._push(contexts.TABLE_OPEN | contexts.TABLE_CELL_OPEN |\n                       line_context)\n            padding = self._handle_table_style(\"|\")\n            style = self._pop()\n            # Don't parse the style separator:\n            self._head += 1\n            cell = self._parse(contexts.TABLE_OPEN | contexts.TABLE_CELL_OPEN |\n                               line_context)\n            cell_context = self._context\n            self._context = old_context\n\n        close_open_markup = \"|\" if reset_for_style else None\n        self._emit_table_tag(markup, tag, style, padding, close_open_markup,\n                             cell, \"\")\n        # Keep header/cell line contexts:\n        self._context |= cell_context & (contexts.TABLE_TH_LINE |\n                                         contexts.TABLE_TD_LINE)\n        # Offset displacement done by parse():\n        self._head -= 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle the end of a table cell.", "response": "def _handle_table_cell_end(self, reset_for_style=False):\n        \"\"\"Returns the current context, with the TABLE_CELL_STYLE flag set if\n        it is necessary to reset and parse style attributes.\"\"\"\n        if reset_for_style:\n            self._context |= contexts.TABLE_CELL_STYLE\n        else:\n            self._context &= ~contexts.TABLE_CELL_STYLE\n        return self._pop(keep_context=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the end of the stream of wikitext.", "response": "def _handle_end(self):\n        \"\"\"Handle the end of the stream of wikitext.\"\"\"\n        if self._context & contexts.FAIL:\n            if self._context & contexts.TAG_BODY:\n                if is_single(self._stack[1].text):\n                    return self._handle_single_tag_end()\n            if self._context & contexts.TABLE_CELL_OPEN:\n                self._pop()\n            if self._context & contexts.DOUBLE:\n                self._pop()\n            self._fail_route()\n        return self._pop()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verify_safe(self, this):\n        context = self._context\n        if context & contexts.FAIL_NEXT:\n            return False\n        if context & contexts.WIKILINK_TITLE:\n            if this == \"]\" or this == \"{\":\n                self._context |= contexts.FAIL_NEXT\n            elif this == \"\\n\" or this == \"[\" or this == \"}\" or this == \">\":\n                return False\n            elif this == \"<\":\n                if self._read(1) == \"!\":\n                    self._context |= contexts.FAIL_NEXT\n                else:\n                    return False\n            return True\n        elif context & contexts.EXT_LINK_TITLE:\n            return this != \"\\n\"\n        elif context & contexts.TEMPLATE_NAME:\n            if this == \"{\":\n                self._context |= contexts.HAS_TEMPLATE | contexts.FAIL_NEXT\n                return True\n            if this == \"}\" or (this == \"<\" and self._read(1) == \"!\"):\n                self._context |= contexts.FAIL_NEXT\n                return True\n            if this == \"[\" or this == \"]\" or this == \"<\" or this == \">\":\n                return False\n            if this == \"|\":\n                return True\n            if context & contexts.HAS_TEXT:\n                if context & contexts.FAIL_ON_TEXT:\n                    if this is self.END or not this.isspace():\n                        return False\n                elif this == \"\\n\":\n                    self._context |= contexts.FAIL_ON_TEXT\n            elif this is self.END or not this.isspace():\n                self._context |= contexts.HAS_TEXT\n            return True\n        elif context & contexts.TAG_CLOSE:\n            return this != \"<\"\n        else:\n            if context & contexts.FAIL_ON_EQUALS:\n                if this == \"=\":\n                    return False\n            elif context & contexts.FAIL_ON_LBRACE:\n                if this == \"{\" or (self._read(-1) == self._read(-2) == \"{\"):\n                    if context & contexts.TEMPLATE:\n                        self._context |= contexts.FAIL_ON_EQUALS\n                    else:\n                        self._context |= contexts.FAIL_NEXT\n                    return True\n                self._context ^= contexts.FAIL_ON_LBRACE\n            elif context & contexts.FAIL_ON_RBRACE:\n                if this == \"}\":\n                    self._context |= contexts.FAIL_NEXT\n                    return True\n                self._context ^= contexts.FAIL_ON_RBRACE\n            elif this == \"{\":\n                self._context |= contexts.FAIL_ON_LBRACE\n            elif this == \"}\":\n                self._context |= contexts.FAIL_ON_RBRACE\n            return True", "response": "Verify that the current character is not a valid character."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the wikicode string.", "response": "def _parse(self, context=0, push=True):\n        \"\"\"Parse the wikicode string, using *context* for when to stop.\"\"\"\n        if push:\n            self._push(context)\n        while True:\n            this = self._read()\n            if self._context & contexts.UNSAFE:\n                if not self._verify_safe(this):\n                    if self._context & contexts.DOUBLE:\n                        self._pop()\n                    self._fail_route()\n            if this not in self.MARKERS:\n                self._emit_text(this)\n                self._head += 1\n                continue\n            if this is self.END:\n                return self._handle_end()\n            next = self._read(1)\n            if this == next == \"{\":\n                if self._can_recurse():\n                    self._parse_template_or_argument()\n                else:\n                    self._emit_text(\"{\")\n            elif this == \"|\" and self._context & contexts.TEMPLATE:\n                self._handle_template_param()\n            elif this == \"=\" and self._context & contexts.TEMPLATE_PARAM_KEY:\n                self._handle_template_param_value()\n            elif this == next == \"}\" and self._context & contexts.TEMPLATE:\n                return self._handle_template_end()\n            elif this == \"|\" and self._context & contexts.ARGUMENT_NAME:\n                self._handle_argument_separator()\n            elif this == next == \"}\" and self._context & contexts.ARGUMENT:\n                if self._read(2) == \"}\":\n                    return self._handle_argument_end()\n                else:\n                    self._emit_text(\"}\")\n            elif this == next == \"[\" and self._can_recurse():\n                if not self._context & contexts.NO_WIKILINKS:\n                    self._parse_wikilink()\n                else:\n                    self._emit_text(\"[\")\n            elif this == \"|\" and self._context & contexts.WIKILINK_TITLE:\n                self._handle_wikilink_separator()\n            elif this == next == \"]\" and self._context & contexts.WIKILINK:\n                return self._handle_wikilink_end()\n            elif this == \"[\":\n                self._parse_external_link(True)\n            elif this == \":\" and self._read(-1) not in self.MARKERS:\n                self._parse_external_link(False)\n            elif this == \"]\" and self._context & contexts.EXT_LINK_TITLE:\n                return self._pop()\n            elif this == \"=\" and not self._global & contexts.GL_HEADING:\n                if self._read(-1) in (\"\\n\", self.START):\n                    self._parse_heading()\n                else:\n                    self._emit_text(\"=\")\n            elif this == \"=\" and self._context & contexts.HEADING:\n                return self._handle_heading_end()\n            elif this == \"\\n\" and self._context & contexts.HEADING:\n                self._fail_route()\n            elif this == \"&\":\n                self._parse_entity()\n            elif this == \"<\" and next == \"!\":\n                if self._read(2) == self._read(3) == \"-\":\n                    self._parse_comment()\n                else:\n                    self._emit_text(this)\n            elif this == \"<\" and next == \"/\" and self._read(2) is not self.END:\n                if self._context & contexts.TAG_BODY:\n                    self._handle_tag_open_close()\n                else:\n                    self._handle_invalid_tag_start()\n            elif this == \"<\" and not self._context & contexts.TAG_CLOSE:\n                if self._can_recurse():\n                    self._parse_tag()\n                else:\n                    self._emit_text(\"<\")\n            elif this == \">\" and self._context & contexts.TAG_CLOSE:\n                return self._handle_tag_close_close()\n            elif this == next == \"'\" and not self._skip_style_tags:\n                result = self._parse_style()\n                if result is not None:\n                    return result\n            elif self._read(-1) in (\"\\n\", self.START) and this in (\"#\", \"*\", \";\", \":\"):\n                self._handle_list()\n            elif self._read(-1) in (\"\\n\", self.START) and (\n                    this == next == self._read(2) == self._read(3) == \"-\"):\n                self._handle_hr()\n            elif this in (\"\\n\", \":\") and self._context & contexts.DL_TERM:\n                self._handle_dl_term()\n                if this == \"\\n\":\n                    # Kill potential table contexts\n                    self._context &= ~contexts.TABLE_CELL_LINE_CONTEXTS\n            # Start of table parsing\n            elif this == \"{\" and next == \"|\" and (\n                    self._read(-1) in (\"\\n\", self.START) or\n                    (self._read(-2) in (\"\\n\", self.START) and self._read(-1).isspace())):\n                if self._can_recurse():\n                    self._parse_table()\n                else:\n                    self._emit_text(\"{\")\n            elif self._context & contexts.TABLE_OPEN:\n                if this == next == \"|\" and self._context & contexts.TABLE_TD_LINE:\n                    if self._context & contexts.TABLE_CELL_OPEN:\n                        return self._handle_table_cell_end()\n                    self._handle_table_cell(\"||\", \"td\", contexts.TABLE_TD_LINE)\n                elif this == next == \"|\" and self._context & contexts.TABLE_TH_LINE:\n                    if self._context & contexts.TABLE_CELL_OPEN:\n                        return self._handle_table_cell_end()\n                    self._handle_table_cell(\"||\", \"th\", contexts.TABLE_TH_LINE)\n                elif this == next == \"!\" and self._context & contexts.TABLE_TH_LINE:\n                    if self._context & contexts.TABLE_CELL_OPEN:\n                        return self._handle_table_cell_end()\n                    self._handle_table_cell(\"!!\", \"th\", contexts.TABLE_TH_LINE)\n                elif this == \"|\" and self._context & contexts.TABLE_CELL_STYLE:\n                    return self._handle_table_cell_end(reset_for_style=True)\n                # on newline, clear out cell line contexts\n                elif this == \"\\n\" and self._context & contexts.TABLE_CELL_LINE_CONTEXTS:\n                    self._context &= ~contexts.TABLE_CELL_LINE_CONTEXTS\n                    self._emit_text(this)\n                elif (self._read(-1) in (\"\\n\", self.START) or\n                      (self._read(-2) in (\"\\n\", self.START) and self._read(-1).isspace())):\n                    if this == \"|\" and next == \"}\":\n                        if self._context & contexts.TABLE_CELL_OPEN:\n                            return self._handle_table_cell_end()\n                        if self._context & contexts.TABLE_ROW_OPEN:\n                            return self._handle_table_row_end()\n                        return self._handle_table_end()\n                    elif this == \"|\" and next == \"-\":\n                        if self._context & contexts.TABLE_CELL_OPEN:\n                            return self._handle_table_cell_end()\n                        if self._context & contexts.TABLE_ROW_OPEN:\n                            return self._handle_table_row_end()\n                        self._handle_table_row()\n                    elif this == \"|\":\n                        if self._context & contexts.TABLE_CELL_OPEN:\n                            return self._handle_table_cell_end()\n                        self._handle_table_cell(\"|\", \"td\", contexts.TABLE_TD_LINE)\n                    elif this == \"!\":\n                        if self._context & contexts.TABLE_CELL_OPEN:\n                            return self._handle_table_cell_end()\n                        self._handle_table_cell(\"!\", \"th\", contexts.TABLE_TH_LINE)\n                    else:\n                        self._emit_text(this)\n                else:\n                    self._emit_text(this)\n\n            else:\n                self._emit_text(this)\n            self._head += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a list of tokens from a string of wikicode and return it.", "response": "def tokenize(self, text, context=0, skip_style_tags=False):\n        \"\"\"Build a list of tokens from a string of wikicode and return it.\"\"\"\n        split = self.regex.split(text)\n        self._text = [segment for segment in split if segment]\n        self._head = self._global = self._depth = 0\n        self._bad_routes = set()\n        self._skip_style_tags = skip_style_tags\n\n        try:\n            tokens = self._parse(context)\n        except BadRoute:  # pragma: no cover (untestable/exceptional case)\n            raise ParserError(\"Python tokenizer exited with BadRoute\")\n        if self._stacks:  # pragma: no cover (untestable/exceptional case)\n            err = \"Python tokenizer exited with non-empty token stack\"\n            raise ParserError(err)\n        return tokens"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn valid quotes for the given value or None if unneeded.", "response": "def _value_needs_quotes(val):\n        \"\"\"Return valid quotes for the given value, or None if unneeded.\"\"\"\n        if not val:\n            return None\n        val = \"\".join(str(node) for node in val.filter_text(recursive=False))\n        if not any(char.isspace() for char in val):\n            return None\n        if \"'\" in val and '\"' not in val:\n            return '\"'\n        if '\"' in val and \"'\" not in val:\n            return \"'\"\n        return \"\\\"'\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_padding(self, attr, value):\n        if not value:\n            setattr(self, attr, \"\")\n        else:\n            value = str(value)\n            if not value.isspace():\n                raise ValueError(\"padding must be entirely whitespace\")\n            setattr(self, attr, value)", "response": "Setter for the value of a padding attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coerce_quotes(quotes):\n        orig, quotes = quotes, str(quotes) if quotes else None\n        if quotes not in [None, '\"', \"'\"]:\n            raise ValueError(\"{!r} is not a valid quote type\".format(orig))\n        return quotes", "response": "Coerce a quote type into an acceptable value or raise an error."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make(name):\n    __all__.append(name)\n    return type(name if py3k else name.encode(\"utf8\"), (Token,), {})", "response": "Create a new Token class using type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_children(node, contexts=False, restrict=None, parent=None):\n        yield (parent, node) if contexts else node\n        if restrict and isinstance(node, restrict):\n            return\n        for code in node.__children__():\n            for child in code.nodes:\n                sub = Wikicode._get_children(child, contexts, restrict, code)\n                for result in sub:\n                    yield result", "response": "Iterate over all child nodes of a given node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing the string old with new across index in code.", "response": "def _slice_replace(code, index, old, new):\n        \"\"\"Replace the string *old* with *new* across *index* in *code*.\"\"\"\n        nodes = [str(node) for node in code.get(index)]\n        substring = \"\".join(nodes).replace(old, new)\n        code.nodes[index] = parse_anything(substring).nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_matcher(matches, flags):\n        if matches:\n            if callable(matches):\n                return matches\n            return lambda obj: re.search(matches, str(obj), flags)\n        return lambda obj: True", "response": "Helper for _indexed_ifilter and others."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _indexed_ifilter(self, recursive=True, matches=None, flags=FLAGS,\n                         forcetype=None):\n        \"\"\"Iterate over nodes and their corresponding indices in the node list.\n\n        The arguments are interpreted as for :meth:`ifilter`. For each tuple\n        ``(i, node)`` yielded by this method, ``self.index(node) == i``. Note\n        that if *recursive* is ``True``, ``self.nodes[i]`` might not be the\n        node itself, but will still contain it.\n        \"\"\"\n        match = self._build_matcher(matches, flags)\n        if recursive:\n            restrict = forcetype if recursive == self.RECURSE_OTHERS else None\n            def getter(i, node):\n                for ch in self._get_children(node, restrict=restrict):\n                    yield (i, ch)\n            inodes = chain(*(getter(i, n) for i, n in enumerate(self.nodes)))\n        else:\n            inodes = enumerate(self.nodes)\n        for i, node in inodes:\n            if (not forcetype or isinstance(node, forcetype)) and match(node):\n                yield (i, node)", "response": "Iterate over nodes and their corresponding indices in the node list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_child_wikicode(self, obj, recursive=True):\n        def deref(nodes):\n            if isinstance(nodes, _ListProxy):\n                return nodes._parent  # pylint: disable=protected-access\n            return nodes\n\n        target = deref(obj.nodes)\n        if target is deref(self.nodes):\n            return True\n        if recursive:\n            todo = [self]\n            while todo:\n                code = todo.pop()\n                if target is deref(code.nodes):\n                    return True\n                for node in code.nodes:\n                    todo += list(node.__children__())\n        return False", "response": "Return whether the given object is a descendant of this one."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_strong_search(self, obj, recursive=True):\n        if isinstance(obj, Wikicode):\n            if not self._is_child_wikicode(obj, recursive):\n                raise ValueError(obj)\n            return obj, slice(0, len(obj.nodes))\n\n        if isinstance(obj, Node):\n            mkslice = lambda i: slice(i, i + 1)\n            if not recursive:\n                return self, mkslice(self.index(obj))\n            for node in self.nodes:\n                for context, child in self._get_children(node, contexts=True):\n                    if obj is child:\n                        if not context:\n                            context = self\n                        return context, mkslice(context.index(child))\n            raise ValueError(obj)\n\n        raise TypeError(obj)", "response": "Searches for the specific element obj within the node list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for an element that looks like obj within the node list.", "response": "def _do_weak_search(self, obj, recursive):\n        \"\"\"Search for an element that looks like *obj* within the node list.\n\n        This follows the same rules as :meth:`_do_strong_search` with some\n        differences. *obj* is treated as a string that might represent any\n        :class:`.Node`, :class:`.Wikicode`, or combination of the two present\n        in the node list. Thus, matching is weak (using string comparisons)\n        rather than strong (using ``is``). Because multiple nodes can match\n        *obj*, the result is a list of tuples instead of just one (however,\n        :exc:`ValueError` is still raised if nothing is found). Individual\n        matches will never overlap.\n\n        The tuples contain a new first element, *exact*, which is ``True`` if\n        we were able to match *obj* exactly to one or more adjacent nodes, or\n        ``False`` if we found *obj* inside a node or incompletely spanning\n        multiple nodes.\n        \"\"\"\n        obj = parse_anything(obj)\n        if not obj or obj not in self:\n            raise ValueError(obj)\n        results = []\n        contexts = [self]\n        while contexts:\n            context = contexts.pop()\n            i = len(context.nodes) - 1\n            while i >= 0:\n                node = context.get(i)\n                if obj.get(-1) == node:\n                    for j in range(-len(obj.nodes), -1):\n                        if obj.get(j) != context.get(i + j + 1):\n                            break\n                    else:\n                        i -= len(obj.nodes) - 1\n                        index = slice(i, i + len(obj.nodes))\n                        results.append((True, context, index))\n                elif recursive and obj in node:\n                    contexts.extend(node.__children__())\n                i -= 1\n        if not results:\n            if not recursive:\n                raise ValueError(obj)\n            results.append((False, self, slice(0, len(self.nodes))))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_tree(self, code, lines, marker, indent):\n        def write(*args):\n            \"\"\"Write a new line following the proper indentation rules.\"\"\"\n            if lines and lines[-1] is marker:  # Continue from the last line\n                lines.pop()  # Remove the marker\n                last = lines.pop()\n                lines.append(last + \" \".join(args))\n            else:\n                lines.append(\" \" * 6 * indent + \" \".join(args))\n\n        get = lambda code: self._get_tree(code, lines, marker, indent + 1)\n        mark = lambda: lines.append(marker)\n        for node in code.nodes:\n            node.__showtree__(write, get, mark)\n        return lines", "response": "Build a tree from a Wikicode object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_filter_methods(cls, **meths):\n        doc = \"\"\"Iterate over {0}.\n\n        This is equivalent to :meth:`{1}` with *forcetype* set to\n        :class:`~{2.__module__}.{2.__name__}`.\n        \"\"\"\n        make_ifilter = lambda ftype: (lambda self, *a, **kw:\n                                      self.ifilter(forcetype=ftype, *a, **kw))\n        make_filter = lambda ftype: (lambda self, *a, **kw:\n                                     self.filter(forcetype=ftype, *a, **kw))\n        for name, ftype in (meths.items() if py3k else meths.iteritems()):\n            ifilter = make_ifilter(ftype)\n            filter = make_filter(ftype)\n            ifilter.__doc__ = doc.format(name, \"ifilter\", ftype)\n            filter.__doc__ = doc.format(name, \"filter\", ftype)\n            setattr(cls, \"ifilter_\" + name, ifilter)\n            setattr(cls, \"filter_\" + name, filter)", "response": "Given a dict of methods and a class cls build the corresponding i?filter shortcuts."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the node at the given index to value.", "response": "def set(self, index, value):\n        \"\"\"Set the ``Node`` at *index* to *value*.\n\n        Raises :exc:`IndexError` if *index* is out of range, or\n        :exc:`ValueError` if *value* cannot be coerced into one :class:`.Node`.\n        To insert multiple nodes at an index, use :meth:`get` with either\n        :meth:`remove` and :meth:`insert` or :meth:`replace`.\n        \"\"\"\n        nodes = parse_anything(value).nodes\n        if len(nodes) > 1:\n            raise ValueError(\"Cannot coerce multiple nodes into one index\")\n        if index >= len(self.nodes) or -1 * index > len(self.nodes):\n            raise IndexError(\"List assignment index out of range\")\n        if nodes:\n            self.nodes[index] = nodes[0]\n        else:\n            self.nodes.pop(index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contains(self, obj):\n        if not isinstance(obj, (Node, Wikicode)):\n            return obj in self\n        try:\n            self._do_strong_search(obj, recursive=True)\n        except ValueError:\n            return False\n        return True", "response": "Return whether this Wikicode object contains obj."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the index of obj in the list of nodes.", "response": "def index(self, obj, recursive=False):\n        \"\"\"Return the index of *obj* in the list of nodes.\n\n        Raises :exc:`ValueError` if *obj* is not found. If *recursive* is\n        ``True``, we will look in all nodes of ours and their descendants, and\n        return the index of our direct descendant node within *our* list of\n        nodes. Otherwise, the lookup is done only on direct descendants.\n        \"\"\"\n        strict = isinstance(obj, Node)\n        equivalent = (lambda o, n: o is n) if strict else (lambda o, n: o == n)\n        for i, node in enumerate(self.nodes):\n            if recursive:\n                for child in self._get_children(node):\n                    if equivalent(obj, child):\n                        return i\n            elif equivalent(obj, node):\n                return i\n        raise ValueError(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ancestors(self, obj):\n        def _get_ancestors(code, needle):\n            for node in code.nodes:\n                if node is needle:\n                    return []\n                for code in node.__children__():\n                    ancestors = _get_ancestors(code, needle)\n                    if ancestors is not None:\n                        return [node] + ancestors\n\n        if isinstance(obj, Wikicode):\n            obj = obj.get(0)\n        elif not isinstance(obj, Node):\n            raise ValueError(obj)\n\n        ancestors = _get_ancestors(self, obj)\n        if ancestors is None:\n            raise ValueError(obj)\n        return ancestors", "response": "Return a list of all ancestors of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert(self, index, value):\n        nodes = parse_anything(value).nodes\n        for node in reversed(nodes):\n            self.nodes.insert(index, node)", "response": "Insert value at index in the list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_before(self, obj, value, recursive=True):\n        if isinstance(obj, (Node, Wikicode)):\n            context, index = self._do_strong_search(obj, recursive)\n            context.insert(index.start, value)\n        else:\n            for exact, context, index in self._do_weak_search(obj, recursive):\n                if exact:\n                    context.insert(index.start, value)\n                else:\n                    obj = str(obj)\n                    self._slice_replace(context, index, obj, str(value) + obj)", "response": "Insert value immediately before obj."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace(self, obj, value, recursive=True):\n        if isinstance(obj, (Node, Wikicode)):\n            context, index = self._do_strong_search(obj, recursive)\n            for i in range(index.start, index.stop):\n                context.nodes.pop(index.start)\n            context.insert(index.start, value)\n        else:\n            for exact, context, index in self._do_weak_search(obj, recursive):\n                if exact:\n                    for i in range(index.start, index.stop):\n                        context.nodes.pop(index.start)\n                    context.insert(index.start, value)\n                else:\n                    self._slice_replace(context, index, str(obj), str(value))", "response": "Replace obj with value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts value at the end of the list of nodes.", "response": "def append(self, value):\n        \"\"\"Insert *value* at the end of the list of nodes.\n\n        *value* can be anything parsable by :func:`.parse_anything`.\n        \"\"\"\n        nodes = parse_anything(value).nodes\n        for node in nodes:\n            self.nodes.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing a loose equivalency test suitable for comparing page names.", "response": "def matches(self, other):\n        \"\"\"Do a loose equivalency test suitable for comparing page names.\n\n        *other* can be any string-like object, including :class:`.Wikicode`, or\n        an iterable of these. This operation is symmetric; both sides are\n        adjusted. Specifically, whitespace and markup is stripped and the first\n        letter's case is normalized. Typical usage is\n        ``if template.name.matches(\"stub\"): ...``.\n        \"\"\"\n        cmp = lambda a, b: (a[0].upper() + a[1:] == b[0].upper() + b[1:]\n                            if a and b else a == b)\n        this = self.strip_code().strip()\n        if isinstance(other, (str, bytes, Wikicode, Node)):\n            that = parse_anything(other).strip_code().strip()\n            return cmp(this, that)\n\n        for obj in other:\n            that = parse_anything(obj).strip_code().strip()\n            if cmp(this, that):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ifilter(self, recursive=True, matches=None, flags=FLAGS,\n                forcetype=None):\n        \"\"\"Iterate over nodes in our list matching certain conditions.\n\n        If *forcetype* is given, only nodes that are instances of this type (or\n        tuple of types) are yielded. Setting *recursive* to ``True`` will\n        iterate over all children and their descendants. ``RECURSE_OTHERS``\n        will only iterate over children that are not the instances of\n        *forcetype*. ``False`` will only iterate over immediate children.\n\n        ``RECURSE_OTHERS`` can be used to iterate over all un-nested templates,\n        even if they are inside of HTML tags, like so:\n\n            >>> code = mwparserfromhell.parse(\"{{foo}}<b>{{foo|{{bar}}}}</b>\")\n            >>> code.filter_templates(code.RECURSE_OTHERS)\n            [\"{{foo}}\", \"{{foo|{{bar}}}}\"]\n\n        *matches* can be used to further restrict the nodes, either as a\n        function (taking a single :class:`.Node` and returning a boolean) or a\n        regular expression (matched against the node's string representation\n        with :func:`re.search`). If *matches* is a regex, the flags passed to\n        :func:`re.search` are :const:`re.IGNORECASE`, :const:`re.DOTALL`, and\n        :const:`re.UNICODE`, but custom flags can be specified by passing\n        *flags*.\n        \"\"\"\n        gen = self._indexed_ifilter(recursive, matches, flags, forcetype)\n        return (node for i, node in gen)", "response": "Iterate over nodes in our list matching certain conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sections(self, levels=None, matches=None, flags=FLAGS, flat=False,\n                     include_lead=None, include_headings=True):\n        \"\"\"Return a list of sections within the page.\n\n        Sections are returned as :class:`.Wikicode` objects with a shared node\n        list (implemented using :class:`.SmartList`) so that changes to\n        sections are reflected in the parent Wikicode object.\n\n        Each section contains all of its subsections, unless *flat* is\n        ``True``. If *levels* is given, it should be a iterable of integers;\n        only sections whose heading levels are within it will be returned. If\n        *matches* is given, it should be either a function or a regex; only\n        sections whose headings match it (without the surrounding equal signs)\n        will be included. *flags* can be used to override the default regex\n        flags (see :meth:`ifilter`) if a regex *matches* is used.\n\n        If *include_lead* is ``True``, the first, lead section (without a\n        heading) will be included in the list; ``False`` will not include it;\n        the default will include it only if no specific *levels* were given. If\n        *include_headings* is ``True``, the section's beginning\n        :class:`.Heading` object will be included; otherwise, this is skipped.\n        \"\"\"\n        title_matcher = self._build_matcher(matches, flags)\n        matcher = lambda heading: (title_matcher(heading.title) and\n                                   (not levels or heading.level in levels))\n        iheadings = self._indexed_ifilter(recursive=False, forcetype=Heading)\n        sections = []  # Tuples of (index_of_first_node, section)\n        open_headings = [] # Tuples of (index, heading), where index and\n                           # heading.level are both monotonically increasing\n\n        # Add the lead section if appropriate:\n        if include_lead or not (include_lead is not None or matches or levels):\n            itr = self._indexed_ifilter(recursive=False, forcetype=Heading)\n            try:\n                first = next(itr)[0]\n                sections.append((0, Wikicode(self.nodes[:first])))\n            except StopIteration:  # No headings in page\n                sections.append((0, Wikicode(self.nodes[:])))\n\n        # Iterate over headings, adding sections to the list as they end:\n        for i, heading in iheadings:\n            if flat:  # With flat, all sections close at the next heading\n                newly_closed, open_headings = open_headings, []\n            else:  # Otherwise, figure out which sections have closed, if any\n                closed_start_index = len(open_headings)\n                for j, (start, last_heading) in enumerate(open_headings):\n                    if heading.level <= last_heading.level:\n                        closed_start_index = j\n                        break\n                newly_closed = open_headings[closed_start_index:]\n                del open_headings[closed_start_index:]\n            for start, closed_heading in newly_closed:\n                if matcher(closed_heading):\n                    sections.append((start, Wikicode(self.nodes[start:i])))\n            start = i if include_headings else (i + 1)\n            open_headings.append((start, heading))\n\n        # Add any remaining open headings to the list of sections:\n        for start, heading in open_headings:\n            if matcher(heading):\n                sections.append((start, Wikicode(self.nodes[start:])))\n\n        # Ensure that earlier sections are earlier in the returned list:\n        return [section for i, section in sorted(sections)]", "response": "Return a list of sections within the page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a rendered string without unprintable code such as templates tags and links.", "response": "def strip_code(self, normalize=True, collapse=True,\n                   keep_template_params=False):\n        \"\"\"Return a rendered string without unprintable code such as templates.\n\n        The way a node is stripped is handled by the\n        :meth:`~.Node.__strip__` method of :class:`.Node` objects, which\n        generally return a subset of their nodes or ``None``. For example,\n        templates and tags are removed completely, links are stripped to just\n        their display part, headings are stripped to just their title.\n\n        If *normalize* is ``True``, various things may be done to strip code\n        further, such as converting HTML entities like ``&Sigma;``, ``&#931;``,\n        and ``&#x3a3;`` to ``\u03a3``. If *collapse* is ``True``, we will try to\n        remove excess whitespace as well (three or more newlines are converted\n        to two, for example). If *keep_template_params* is ``True``, then\n        template parameters will be preserved in the output (normally, they are\n        removed completely).\n        \"\"\"\n        kwargs = {\n            \"normalize\": normalize,\n            \"collapse\": collapse,\n            \"keep_template_params\": keep_template_params\n        }\n\n        nodes = []\n        for node in self.nodes:\n            stripped = node.__strip__(**kwargs)\n            if stripped:\n                nodes.append(str(stripped))\n\n        if collapse:\n            stripped = \"\".join(nodes).strip(\"\\n\")\n            while \"\\n\\n\\n\" in stripped:\n                stripped = stripped.replace(\"\\n\\n\\n\", \"\\n\\n\")\n            return stripped\n        else:\n            return \"\".join(nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_literal(s, start, level, parts, exprs):\n    i = start\n    parse_expr = True\n\n    while i < len(s):\n        ch = s[i]\n\n        if ch in ('{', '}'):\n            if level == 0:\n                if i + 1 < len(s) and s[i + 1] == ch:\n                    i += 2\n                    parse_expr = False\n                    break\n                elif ch == '}':\n                    raise SyntaxError(\"f-string: single '}' is not allowed\")\n            break\n\n        i += 1\n\n    parts.append(s[start:i])\n    return i, parse_expr and i < len(s)", "response": "Roughly Python / ast. c : fstring_find_literal"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fstring_parse(s, i, level, parts, exprs):\n    while True:\n        i, parse_expr = _find_literal(s, i, level, parts, exprs)\n        if i == len(s) or s[i] == '}':\n            return i\n        if parse_expr:\n            i = _find_expr(s, i, level, parts, exprs)", "response": "Roughly Python / ast. c : fstring_find_literal_and_expr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a file with our PID.", "response": "def write_pid_file(fn):\n    \"\"\" Create a file with our PID. \"\"\"\n    if not fn:\n        return None\n    if fn == '' or fn == \"''\":\n        # work around argument passings in init-scripts\n        return None\n    f = open(fn, \"w\")\n    f.write(\"%s\\n\" % (os.getpid()))\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hexdump(src, length=8):\n    if not src:\n        return str(src)\n    src = input_validate_str(src, 'src')\n    offset = 0\n    result = ''\n    for this in group(src, length):\n        hex_s = ' '.join([\"%02x\" % ord(x) for x in this])\n        result += \"%04X   %s\\n\" % (offset, hex_s)\n        offset += length\n    return result", "response": "Produce a string hexdump of src for debug output."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit data into chunks of num chars each", "response": "def group(data, num):\n    \"\"\" Split data into chunks of num chars each \"\"\"\n    return [data[i:i+num] for i in xrange(0, len(data), num)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef key_handle_to_int(this):\n    try:\n        num = int(this)\n        return num\n    except ValueError:\n        if this[:2] == \"0x\":\n            return int(this, 16)\n        if (len(this) == 4):\n            num = struct.unpack('<I', this)[0]\n            return num\n    raise pyhsm.exception.YHSM_Error(\"Could not parse key_handle '%s'\" % (this))", "response": "Turn a key_handle into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninputting validation for strings.", "response": "def input_validate_str(string, name, max_len=None, exact_len=None):\n    \"\"\" Input validation for strings. \"\"\"\n    if type(string) is not str:\n        raise pyhsm.exception.YHSM_WrongInputType(name, str, type(string))\n    if max_len != None and len(string) > max_len:\n        raise pyhsm.exception.YHSM_InputTooLong(name, max_len, len(string))\n    if exact_len != None and len(string) != exact_len:\n        raise pyhsm.exception.YHSM_WrongInputSize(name, exact_len, len(string))\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninput validation for integers.", "response": "def input_validate_int(value, name, max_value=None):\n    \"\"\" Input validation for integers. \"\"\"\n    if type(value) is not int:\n        raise pyhsm.exception.YHSM_WrongInputType(name, int, type(value))\n    if max_value != None and value > max_value:\n        raise pyhsm.exception.YHSM_WrongInputSize(name, max_value, value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef input_validate_nonce(nonce, name='nonce', pad = False):\n    if type(nonce) is not str:\n        raise pyhsm.exception.YHSM_WrongInputType( \\\n            name, str, type(nonce))\n    if len(nonce) > pyhsm.defines.YSM_AEAD_NONCE_SIZE:\n        raise pyhsm.exception.YHSM_InputTooLong(\n            name, pyhsm.defines.YSM_AEAD_NONCE_SIZE, len(nonce))\n    if pad:\n        return nonce.ljust(pyhsm.defines.YSM_AEAD_NONCE_SIZE, chr(0x0))\n    else:\n        return nonce", "response": "Input validation for nonces."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef input_validate_key_handle(key_handle, name='key_handle'):\n    if type(key_handle) is not int:\n        try:\n            return key_handle_to_int(key_handle)\n        except pyhsm.exception.YHSM_Error:\n            raise pyhsm.exception.YHSM_WrongInputType(name, int, type(key_handle))\n    return key_handle", "response": "Input validation for key_handles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef input_validate_yubikey_secret(data, name='data'):\n    if isinstance(data, pyhsm.aead_cmd.YHSM_YubiKeySecret):\n        data = data.pack()\n    return input_validate_str(data, name)", "response": "Input validation for YHSM_YubiKeySecret or string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninput validation for YHSM_GeneratedAEAD or string.", "response": "def input_validate_aead(aead, name='aead', expected_len=None, max_aead_len = pyhsm.defines.YSM_AEAD_MAX_SIZE):\n    \"\"\" Input validation for YHSM_GeneratedAEAD or string. \"\"\"\n    if isinstance(aead, pyhsm.aead_cmd.YHSM_GeneratedAEAD):\n        aead = aead.data\n    if expected_len != None:\n        return input_validate_str(aead, name, exact_len = expected_len)\n    else:\n        return input_validate_str(aead, name, max_len=max_aead_len)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_cmd_response_int(name, got, expected):\n    if got != expected:\n        raise(pyhsm.exception.YHSM_Error(\"Bad %s in response (got %i, expected %i)\" \\\n                                             % (name, got, expected)))\n    return got", "response": "Validate that the response from a YHSM command is correct."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_cmd_response_hex(name, got, expected):\n    if got != expected:\n        raise(pyhsm.exception.YHSM_Error(\"Bad %s in response (got 0x%x, expected 0x%x)\" \\\n                                             % (name, got, expected)))\n    return got", "response": "Validate that the response from a YHSM command is correct."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_cmd_response_str(name, got, expected, hex_encode=True):\n    if got != expected:\n        if hex_encode:\n            got_s = got.encode('hex')\n            exp_s = expected.encode('hex')\n        else:\n            got_s = got\n            exp_s = expected\n        raise(pyhsm.exception.YHSM_Error(\"Bad %s in response (got %s, expected %s)\" \\\n                                             % (name, got_s, exp_s)))\n    return got", "response": "Validate that the response string returned in a command matches what we put in the request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that the nonce in response matches the nonce used in request.", "response": "def validate_cmd_response_nonce(got, used):\n    \"\"\"\n    Check that the returned nonce matches nonce used in request.\n\n    A request nonce of 000000000000 means the HSM should generate a nonce internally though,\n    so if 'used' is all zeros we actually check that 'got' does NOT match 'used'.\n    \"\"\"\n    if used == '000000000000'.decode('hex'):\n        if got == used:\n            raise(pyhsm.exception.YHSM_Error(\"Bad nonce in response (got %s, expected HSM generated nonce)\" \\\n                                                 % (got.encode('hex'))))\n        return got\n    return validate_cmd_response_str('nonce', got, used)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_result(self, data):\n        # typedef struct {\n        #   uint8_t numBytes;                   // Number of bytes in buffer now\n        # } YSM_BUFFER_LOAD_RESP;\n        count = ord(data[0])\n        if self.offset == 0:\n            # if offset was 0, the buffer was reset and\n            # we can verify the length returned\n            if count != self.data_len:\n                raise pyhsm.exception.YHSM_Error(\"Incorrect number of bytes in buffer (got %i, expected %i)\" \\\n                                               % (self.data_len, count))\n        return count", "response": "Parse the result of a YSM_BUFFER_LOAD command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _raw_pack(key_handle, flags, data):\n    # #define YHSM_HMAC_RESET          0x01    // Flag to indicate reset at first packet\n    # #define YHSM_HMAC_FINAL          0x02    // Flag to indicate that the hash shall be calculated\n    # typedef struct {\n    #   uint32_t keyHandle;                 // Key handle\n    #   uint8_t flags;                      // Flags\n    #   uint8_t numBytes;                   // Number of bytes in data packet\n    #   uint8_t data[YHSM_MAX_PKT_SIZE - 6]; // Data to be written\n    # } YHSM_HMAC_SHA1_GENERATE_REQ;\n    return struct.pack('<IBB', key_handle, flags, len(data)) + data", "response": "Packs the data into a raw packet."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding more input to the HMAC SHA1.", "response": "def next(self, data, final = False, to_buffer = False):\n        \"\"\"\n        Add more input to the HMAC SHA1.\n        \"\"\"\n        if final:\n            self.flags = pyhsm.defines.YSM_HMAC_SHA1_FINAL\n        else:\n            self.flags = 0x0\n        if to_buffer:\n            self.flags |= pyhsm.defines.YSM_HMAC_SHA1_TO_BUFFER\n        self.payload = _raw_pack(self.key_handle, self.flags, data)\n        self.final = final\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the HMAC - SHA1 hash of the current session.", "response": "def get_hash(self):\n        \"\"\"\n        Get the HMAC-SHA1 that has been calculated this far.\n        \"\"\"\n        if not self.executed:\n            raise pyhsm.exception.YHSM_Error(\"HMAC-SHA1 hash not available, before execute().\")\n        return self.result.hash_result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite data to YHSM device.", "response": "def write(self, data, debug_info=None):\n        \"\"\"\n        Write data to YHSM device.\n        \"\"\"\n        self.num_write_bytes += len(data)\n        if self.debug:\n            if not debug_info:\n                debug_info = str(len(data))\n            sys.stderr.write(\"%s: WRITE %s:\\n%s\\n\" % (\n                self.__class__.__name__,\n                debug_info,\n                pyhsm.util.hexdump(data)\n            ))\n        write_sock(self.socket_file, CMD_WRITE, data)\n        return read_sock(self.socket_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, num_bytes, debug_info=None):\n        if self.debug:\n            if not debug_info:\n                debug_info = str(num_bytes)\n            sys.stderr.write(\"%s: READING %s\\n\" % (\n                self.__class__.__name__,\n                debug_info\n            ))\n        write_sock(self.socket_file, CMD_READ, num_bytes)\n        res = read_sock(self.socket_file)\n        if isinstance(res, Exception):\n            raise res\n\n        if self.debug:\n            sys.stderr.write(\"%s: READ %i:\\n%s\\n\" % (\n                self.__class__.__name__,\n                len(res),\n                pyhsm.util.hexdump(res)\n            ))\n        self.num_read_bytes += len(res)\n        return res", "response": "Read a number of bytes from YubiHSM device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate YubiKey OTP using YubiHSM internal database.", "response": "def validate_yubikey_otp_short(self, params):\n    \"\"\"\n    Validate YubiKey OTP using YubiHSM internal database.\n    \"\"\"\n    from_key = params[\"otp\"][0]\n    if not re.match(ykotp_valid_input, from_key):\n        self.log_error(\"IN: %s, Invalid OTP\" % (from_key))\n        return \"ERR Invalid OTP\"\n    try:\n        res = pyhsm.yubikey.validate_otp(hsm, from_key)\n        return \"OK counter=%04x low=%04x high=%02x use=%02x\" % \\\n            (res.use_ctr, res.ts_low, res.ts_high, res.session_ctr)\n    except pyhsm.exception.YHSM_CommandFailed, e:\n        return \"ERR %s\" % (pyhsm.defines.status2str(e.status))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates YubiKey OTP using YubiHSM internal database.", "response": "def validate_yubikey_otp(self, params):\n    \"\"\"\n    Validate YubiKey OTP using YubiHSM internal database.\n    \"\"\"\n    vres = {}\n    from_key = params[\"otp\"][0]\n    if not re.match(ykotp_valid_input, from_key):\n        self.log_error(\"IN: %s, Invalid OTP\" % (from_key))\n        vres[\"status\"] = \"BAD_OTP\"\n    else:\n        vres[\"otp\"] = from_key\n    if not \"nonce\" in params:\n        self.log_error(\"IN: %s, no nonce\" % (from_key))\n        vres[\"status\"] = \"MISSING_PARAMETER\"\n    else:\n        nonce = params[\"nonce\"][0]\n        if len(nonce) < 16 or len(nonce) > 40:\n            self.log_error(\"IN: %s, bad nonce : %s\" % (from_key, nonce))\n            vres[\"status\"] = \"MISSING_PARAMETER\"\n        else:\n            vres[\"nonce\"] = nonce\n    if \"sl\" in params and not (params[\"sl\"] == \"100\" or params[\"sl\"] == \"secure\"):\n        self.log_error(\"IN: %s, sync level unsupported\" % (from_key))\n        vres[\"status\"] = \"BACKEND_ERROR\"\n    sig, client_key, = check_signature(params)\n    if sig != True:\n        self.log_error(\"IN: %s, signature validation error\" % (from_key))\n        if client_key == None:\n            vres[\"status\"] = \"NO_SUCH_CLIENT\"\n            # To be compatible with YK-VAL, we will sign this response using a null key\n            client_key = chr(0)\n        else:\n            vres[\"status\"] = \"BAD_SIGNATURE\"\n    if \"status\" not in vres:\n        try:\n            res = pyhsm.yubikey.validate_otp(hsm, from_key)\n            vres.update({\"status\": \"OK\",\n                         \"sessioncounter\": str(res.use_ctr), # known confusion\n                         \"sessionuse\": str(res.session_ctr), # known confusion\n                         \"timestamp\": str((res.ts_high << 16 | res.ts_low) / 8)\n                         }\n                        )\n            if \"sl\" in params:\n                vres[\"sl\"] = \"100\"\n                if \"timestamp\" in params:\n                    vres[\"t\"] = time.strftime(\"%FT%TZ0000\", time.gmtime())\n        except pyhsm.exception.YHSM_CommandFailed, e:\n            if e.status == pyhsm.defines.YSM_ID_NOT_FOUND:\n                vres[\"status\"] = \"BAD_OTP\"\n            elif e.status == pyhsm.defines.YSM_OTP_REPLAY:\n                vres[\"status\"] = \"REPLAYED_OTP\"\n            elif e.status == pyhsm.defines.YSM_OTP_INVALID:\n                vres[\"status\"] = \"BAD_OTP\"\n            else:\n                vres[\"status\"] = \"BACKEND_ERROR\"\n            self.log_error(\"IN: %s, validation result %s (replying %s)\" % (from_key, pyhsm.defines.status2str(e.status), vres[\"status\"]))\n\n    return make_otp_response(vres, client_key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating validation response from a dictionary.", "response": "def make_otp_response(vres, client_key):\n    \"\"\"\n    Create validation response (signed, if a client key is supplied).\n    \"\"\"\n    if client_key is not None:\n        sig = make_signature(vres, client_key)\n        vres['h'] = sig\n    # produce \"key=value\" pairs from vres\n    pairs = [x + \"=\" + ''.join(vres[x]) for x in sorted(vres.keys())]\n    return '\\n'.join(pairs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify the signature of the parameters in an OTP v2. 0 verify request.", "response": "def check_signature(params):\n    \"\"\"\n    Verify the signature of the parameters in an OTP v2.0 verify request.\n\n    Returns ValResultBool, Key\n    \"\"\"\n    if 'id' in params:\n        try:\n            id_int = int(params['id'][0])\n        except:\n            my_log_message(args, syslog.LOG_INFO, \"Non-numerical client id (%s) in request.\" % (params['id'][0]))\n            return False, None\n        key = client_ids.get(id_int)\n        if key:\n            if 'h' in params:\n                sig = params['h'][0]\n                good_sig = make_signature(params, key)\n                if sig == good_sig:\n                    #my_log_message(args, syslog.LOG_DEBUG, \"Good signature (client id '%i')\" % id_int)\n                    return True, key\n                else:\n                    my_log_message(args, syslog.LOG_INFO, \"Bad signature from client id '%i' (%s, expected %s).\" \\\n                                       % (id_int, sig, good_sig))\n            else:\n                my_log_message(args, syslog.LOG_INFO, \"Client id (%i) but no HMAC in request.\" % (id_int))\n                return False, key\n        else:\n            my_log_message(args, syslog.LOG_INFO, \"Unknown client id '%i'\" % (id_int))\n            return False, None\n    return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_signature(params, hmac_key):\n    # produce a list of \"key=value\" for all entries in params except `h'\n    pairs = [x + \"=\" + ''.join(params[x]) for x in sorted(params.keys()) if x != \"h\"]\n    sha = hmac.new(hmac_key, '&'.join(pairs), hashlib.sha1)\n    return base64.b64encode(sha.digest())", "response": "Calculates a HMAC - SHA - 1 of all the params except h =."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate OATH - HOTP code using YubiHSM HMAC - SHA1 hashing with token keys secured in AEADs that we have stored in an SQLite3 database.", "response": "def validate_oath_hotp(self, params):\n    \"\"\"\n    Validate OATH-HOTP code using YubiHSM HMAC-SHA1 hashing with token keys\n    secured in AEAD's that we have stored in an SQLite3 database.\n    \"\"\"\n    from_key = params[\"hotp\"][0]\n    if not re.match(hotp_valid_input, from_key):\n        self.log_error(\"IN: %s, Invalid OATH-HOTP OTP\" % (params))\n        return \"ERR Invalid OATH-HOTP OTP\"\n    uid, otp, = get_oath_hotp_bits(params)\n    if not uid or not otp:\n        self.log_error(\"IN: %s, could not get UID/OTP ('%s'/'%s')\" % (params, uid, otp))\n        return \"ERR Invalid OATH-HOTP input\"\n    if args.debug:\n        print \"OATH-HOTP uid %s, OTP %s\" % (uid, otp)\n\n    # Fetch counter value for `uid' from database\n    try:\n        db = ValOathDb(args.db_file)\n        entry = db.get(uid)\n    except Exception, e:\n        self.log_error(\"IN: %s, database error : '%s'\" % (params, e))\n        return \"ERR Internal error\"\n\n    # Check for correct OATH-HOTP OTP\n    nonce = entry.data[\"nonce\"].decode('hex')\n    aead = entry.data[\"aead\"].decode('hex')\n    new_counter = pyhsm.oath_hotp.search_for_oath_code(hsm, entry.data[\"key_handle\"], nonce, aead, \\\n                                                           entry.data[\"oath_c\"], otp, args.look_ahead)\n    if args.debug:\n        print \"OATH-HOTP %i..%i -> new C == %s\" \\\n            % (entry.data[\"oath_c\"], entry.data[\"oath_c\"] + args.look_ahead, new_counter)\n    if type(new_counter) != int:\n        # XXX increase 'throttling parameter' to make brute forcing harder/impossible\n        return \"ERR Could not validate OATH-HOTP OTP\"\n    try:\n        # Must successfully store new_counter before we return OK\n        if db.update_oath_hotp_c(entry, new_counter):\n            return \"OK counter=%04x\" % (new_counter)\n        else:\n            return \"ERR replayed OATH-HOTP\"\n    except Exception, e:\n        self.log_error(\"IN: %s, database error updating counter : %s\" % (params, e))\n        return \"ERR Internal error\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_oath_totp(self, params):\n    from_key = params[\"totp\"][0]\n    if not re.match(totp_valid_input, from_key):\n        self.log_error(\"IN: %s, Invalid OATH-TOTP OTP\" % (params))\n        return \"ERR Invalid OATH-TOTP OTP\"\n    uid, otp, = get_oath_totp_bits(params)\n    if not uid or not otp:\n        self.log_error(\"IN: %s, could not get UID/OTP ('%s'/'%s')\" % (params, uid, otp))\n        return \"ERR Invalid OATH-TOTP input\"\n    if args.debug:\n        print \"OATH-TOTP uid %s, OTP %s\" % (uid, otp)\n\n    # Fetch counter value for `uid' from database\n    try:\n        db = ValOathDb(args.db_file)\n        entry = db.get(uid)\n    except Exception, e:\n        self.log_error(\"IN: %s, database error : '%s'\" % (params, e))\n        return \"ERR Internal error\"\n\n    # Check for correct OATH-TOTP OTP\n    nonce = entry.data[\"nonce\"].decode('hex')\n    aead = entry.data[\"aead\"].decode('hex')\n    new_timecounter = pyhsm.oath_totp.search_for_oath_code(\n        hsm, entry.data[\"key_handle\"], nonce, aead, otp, args.interval, args.tolerance)\n\n    if args.debug:\n        print \"OATH-TOTP counter: %i, interval: %i -> new timecounter == %s\" \\\n             % (entry.data[\"oath_c\"], args.interval, new_timecounter)\n    if type(new_timecounter) != int:\n        return \"ERR Could not validate OATH-TOTP OTP\"\n    try:\n        # Must successfully store new_timecounter before we return OK\n        # Can use existing hotp function since it would be identical\n        if db.update_oath_hotp_c(entry, new_timecounter):\n            return \"OK timecounter=%04x\" % (new_timecounter)\n        else:\n            return \"ERR replayed OATH-TOTP\"\n    except Exception, e:\n        self.log_error(\"IN: %s, database error updating counter : %s\" % (params, e))\n        return \"ERR Internal error\"", "response": "Validate OATH - TOTP code using YubiHSM HMAC - SHA1 hashing with token keys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates password hash using YubiHSM.", "response": "def validate_pwhash(_self, params):\n    \"\"\"\n    Validate password hash using YubiHSM.\n    \"\"\"\n    pwhash, nonce, aead, key_handle = get_pwhash_bits(params)\n    d_aead = aead.decode('hex')\n    plaintext_len = len(d_aead) - pyhsm.defines.YSM_AEAD_MAC_SIZE\n    pw = pwhash.ljust(plaintext_len, chr(0x0))\n    if hsm.validate_aead(nonce.decode('hex'), key_handle, d_aead, pw):\n        return \"OK pwhash validated\"\n    return \"ERR Could not validate pwhash\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pwhash_bits(params):\n    if not \"pwhash\" in params or \\\n            not \"nonce\" in params or \\\n            not \"aead\" in params or \\\n            not \"kh\" in params:\n        raise Exception(\"Missing required parameter in request (pwhash, nonce, aead or kh)\")\n    pwhash = params[\"pwhash\"][0]\n    nonce = params[\"nonce\"][0]\n    aead = params[\"aead\"][0]\n    key_handle = pyhsm.util.key_handle_to_int(params[\"kh\"][0])\n    return pwhash, nonce, aead, key_handle", "response": "Extract bits for password hash validation from params."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the OATH - HOTP uid and OTP from params.", "response": "def get_oath_hotp_bits(params):\n    \"\"\" Extract the OATH-HOTP uid and OTP from params. \"\"\"\n    if \"uid\" in params:\n        return params[\"uid\"][0], int(params[\"hotp\"][0])\n    m = re.match(\"^([cbdefghijklnrtuv]*)([0-9]{6,8})\", params[\"hotp\"][0])\n    uid, otp, = m.groups()\n    return uid, int(otp),"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the command line arguments for YubiKey validation.", "response": "def parse_args():\n    \"\"\"\n    Parse the command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(description = \"Validate secrets using YubiHSM\",\n                                     add_help=True,\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device',\n                        )\n    parser.add_argument('-U', '--serve-url',\n                        dest='serve_url',\n                        default=default_serve_url,\n                        required=False,\n                        help='Base URL for validation web service',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation',\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation',\n                        )\n    parser.add_argument('--port',\n                        dest='listen_port',\n                        type=int, default=8003,\n                        required=False,\n                        help='Port to listen on',\n                        metavar='PORT',\n                        )\n    parser.add_argument('--addr',\n                        dest='listen_addr',\n                        default=\"127.0.0.1\",\n                        required=False,\n                        help='Address to bind to',\n                        metavar='ADDR',\n                        )\n    parser.add_argument('--hmac-kh',\n                        dest='hmac_kh',\n                        required=False, default=0,\n                        help='Key handle to use for creating HMAC-SHA1 hashes',\n                        metavar='KEY_HANDLE',\n                        )\n    parser.add_argument('--short-otp',\n                        dest='mode_short_otp',\n                        action='store_true', default=False,\n                        help='Enable YubiKey OTP validation (KSM style response)',\n                        )\n    parser.add_argument('--otp',\n                        dest='mode_otp',\n                        action='store_true', default=False,\n                        help='Enable YubiKey OTP validation 2.0',\n                        )\n    parser.add_argument('--hotp',\n                        dest='mode_hotp',\n                        action='store_true', default=False,\n                        help='Enable OATH-HOTP validation',\n                        )\n    parser.add_argument('--totp',\n                        dest='mode_totp',\n                        action='store_true', default=False,\n                        help='Enable OATH-TOTP validation',\n                        )\n    parser.add_argument('--pwhash',\n                        dest='mode_pwhash',\n                        action='store_true', default=False,\n                        help='Enable password hash validation',\n                        )\n    parser.add_argument('--db-file',\n                        dest='db_file',\n                        default=default_db_file,\n                        required=False,\n                        help='DB file for storing AEAD\\'s etc. for --pwhash and --hotp',\n                        metavar='FILENAME',\n                        )\n    # XXX bad interaction with argparse.ArgumentDefaultsHelpFormatter here - we don't want to\n    # use default=default_clients_file since we need to know if this option was specified explicitly\n    # or not.\n    parser.add_argument('--clients-file',\n                        dest='clients_file',\n                        default=None,\n                        required=False,\n                        help='File with OTP validation clients shared secrets. for --otp. Default : %s' % (default_clients_file),\n                        metavar='FILENAME',\n                        )\n    parser.add_argument('--hotp-window',\n                        dest='look_ahead',\n                        type=int, required=False,\n                        default = default_hotp_window,\n                        help='Number of OATH-HOTP codes to search',\n                        metavar='NUM',\n                        )\n    parser.add_argument('--totp-interval',\n                        dest='interval',\n                        type=int, required=False,\n                        default = default_totp_interval,\n                        help='Timeframe in seconds for a valid OATH-TOTP code',\n                        metavar='NUM',\n                        )\n    parser.add_argument('--totp-tolerance',\n                        dest='tolerance',\n                        type=int, required=False,\n                        default = default_totp_tolerance,\n                        help='Tolerance in time-steps for a valid OATH-TOTP code',\n                        metavar='NUM',\n                        )\n    parser.add_argument('--pid-file',\n                        dest='pid_file',\n                        default=default_pid_file,\n                        required=False,\n                        help='PID file',\n                        metavar='FILENAME',\n                        )\n\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a list of base64 encoded shared secrets for numerical client ids.", "response": "def load_clients_file(filename):\n    \"\"\"\n    Load a list of base64 encoded shared secrets for numerical client ids.\n\n    Returns a dict.\n\n    Format of file is expected to be\n\n        # This is a comment. Blank lines are OK.\n\n        123,c2hhcmVkIHNlY3JldA==\n        456,MTIzNDU2Nzg5MDEyMw==\n    \"\"\"\n    res = {}\n    content = []\n    try:\n        fhandle = file(filename)\n        content = fhandle.readlines()\n        fhandle.close()\n    except IOError:\n        return None\n    linenum = 0\n    for line in content:\n        linenum += 1\n        while line.endswith(\"\\r\") or line.endswith(\"\\n\"):\n            line = line[:-1]\n        if re.match(\"(^\\s*#|^\\s*$)\", line):\n            # skip comments and empty lines\n            continue\n        parts = [x.strip() for x in line.split(',')]\n        try:\n            if len(parts) != 2:\n                raise Exception()\n            id_num = int(parts[0])\n            key = base64.b64decode(parts[1])\n            res[id_num] = key\n        except:\n            my_log_message(args, syslog.LOG_ERR, 'Bad data on line %i of clients file \"%s\" : \"%s\"' % (linenum, filename, line))\n            return None\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run():\n    server_address = (args.listen_addr, args.listen_port)\n    httpd = YHSM_VALServer(server_address, YHSM_VALRequestHandler)\n    my_log_message(args, syslog.LOG_INFO, \"Serving requests to 'http://%s:%s%s' (YubiHSM: '%s')\" \\\n                       % (args.listen_addr, args.listen_port, args.serve_url, args.device))\n    httpd.serve_forever()", "response": "Start the BaseHTTPServer and serve requests forever."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    my_name = os.path.basename(sys.argv[0])\n    if not my_name:\n        my_name = \"yhsm-validation-server\"\n    syslog.openlog(my_name, syslog.LOG_PID, syslog.LOG_LOCAL0)\n\n    global args\n    args = parse_args()\n    args_fixup()\n\n    global hsm\n    try:\n        hsm = pyhsm.YHSM(device = args.device, debug = args.debug)\n    except serial.SerialException, e:\n        my_log_message(args, syslog.LOG_ERR, 'Failed opening YubiHSM device \"%s\" : %s' %(args.device, e))\n        return 1\n\n    write_pid_file(args.pid_file)\n\n    try:\n        run()\n    except KeyboardInterrupt:\n        print \"\"\n        print \"Shutting down\"\n        print \"\"", "response": "The main function that will be executed when running this as a stand alone script."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses validation GET requests. All modes of validation (OTP, OATH and PWHASH) must be explicitly enabled in `args' to be allowed.", "response": "def do_GET(self):\n        \"\"\"\n        Process validation GET requests.\n\n        All modes of validation (OTP, OATH and PWHASH) must be explicitly\n        enabled in `args' to be allowed.\n        \"\"\"\n        if self.path.startswith(args.serve_url):\n            res = None\n            log_res = None\n            mode = None\n            params = urlparse.parse_qs(self.path[len(args.serve_url):])\n            if \"otp\" in params:\n                if args.mode_short_otp:\n                    # YubiKey internal db OTP in KSM mode\n                    mode = 'YubiKey OTP (short)'\n                    res = validate_yubikey_otp_short(self, params)\n                elif args.mode_otp:\n                    # YubiKey internal db OTP validation 2.0\n                    mode = 'YubiKey OTP'\n                    res = validate_yubikey_otp(self, params)\n                    #status = [x for x in res.split('\\n') if x.startswith(\"status=\")]\n                    #if len(status) == 1:\n                    #    res = status[0][7:]\n                    log_res = '&'.join(res.split('\\n'))\n                else:\n                    res = \"ERR 'otp/otp2' disabled\"\n            elif \"hotp\" in params:\n                if args.mode_hotp:\n                    mode = 'OATH-HOTP'\n                    res = validate_oath_hotp(self, params)\n                else:\n                    res = \"ERR 'hotp' disabled\"\n            elif \"totp\" in params:\n                if args.mode_totp:\n                    mode = 'OATH-TOTP'\n                    res = validate_oath_totp(self, params)\n                else:\n                    res = \"ERR 'totp' disabled\"\n            elif \"pwhash\" in params:\n                if args.mode_pwhash:\n                    mode = 'Password hash'\n                    res = validate_pwhash(self, params)\n                else:\n                    res = \"ERR 'pwhash' disabled\"\n\n            if not log_res:\n                log_res = res\n\n            self.log_message(\"%s validation result: %s -> %s\", mode, self.path, log_res)\n\n            if res != None:\n                self.send_response(200)\n                self.send_header('Content-type', 'text/plain')\n                self.end_headers()\n                self.wfile.write(res)\n                self.wfile.write(\"\\n\")\n            else:\n                self.log_error (\"No validation result to '%s' (responding 403)\" % (self.path))\n                self.send_response(403, 'Forbidden')\n                self.end_headers()\n        else:\n            self.log_error (\"Bad URL '%s' - I'm serving '%s' (responding 403)\" % (self.path, args.serve_url))\n            self.send_response(403, 'Forbidden')\n            self.end_headers()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, key):\n        c = self.conn.cursor()\n        for row in c.execute(\"SELECT key, nonce, key_handle, aead, oath_C, oath_T FROM oath WHERE key = ?\", (key,)):\n            return ValOathEntry(row)\n        raise Exception(\"OATH token for '%s' not found in database (%s)\" % (key, self.filename))", "response": "Fetch a single entry from database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the OATH - HOTP counter value for entry in the database.", "response": "def update_oath_hotp_c(self, entry, new_c):\n        \"\"\"\n        Update the OATH-HOTP counter value for `entry' in the database.\n\n        Use SQL statement to ensure we only ever increase the counter.\n        \"\"\"\n        key = entry.data[\"key\"]\n        c = self.conn.cursor()\n        c.execute(\"UPDATE oath SET oath_c = ? WHERE key = ? AND ? > oath_c\",\n                  (new_c, key, new_c,))\n        self.conn.commit()\n        return c.rowcount == 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args():\n    global default_device\n\n    parser = argparse.ArgumentParser(description = \"Generate password AEAD using YubiHSM\",\n                                     add_help=True\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device (default : \"%s\").' % default_device\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation.'\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation.'\n                        )\n    parser.add_argument('--key-handle',\n                        type=int, dest='key_handle',\n                        required=True,\n                        help='Key handle to use. Must have YHSM_ECB_BLOCK_ENCRYPT and/or YHSM_ECB_BLOCK_DECRYPT_CMP flag set.'\n                        )\n    parser.add_argument('-N', '--nonce',\n                        dest='nonce',\n                        required=True,\n                        help='Nonce to use. 6 bytes encoded as 12 chars hex.'\n                        )\n    parser.add_argument('--set',\n                        dest='set',\n                        action='store_true', default=False,\n                        help='Set password mode.'\n                        )\n    parser.add_argument('--validate',\n                        dest='validate',\n                        help='AEAD to validate.'\n                        )\n    parser.add_argument('--min_length',\n                        type=int, dest='min_len',\n                        required=False, default=20,\n                        help='Minimum length to pad passwords to (default: 20).'\n                        )\n\n    args = parser.parse_args()\n\n    if args.set and args.validate:\n        sys.stderr.write(\"Arguments --set and --validate are mutually exclusive.\\n\")\n        sys.exit(1)\n    if not args.set and not args.validate:\n        sys.stderr.write(\"Either --set or --validate must be specified.\\n\")\n        sys.exit(1)\n\n    return args", "response": "Parse the command line arguments and return a tuple of the base class and the command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_aead(hsm, args, password):\n    try:\n        pw = password.ljust(args.min_len, chr(0x0))\n        return hsm.generate_aead_simple(args.nonce.decode('hex'), args.key_handle, pw)\n    except pyhsm.exception.YHSM_CommandFailed, e:\n        if e.status_str == 'YHSM_FUNCTION_DISABLED':\n            print \"ERROR: The key handle %s is not permitted to YSM_AEAD_GENERATE.\" % (args.key_handle)\n            return None\n        else:\n            print \"ERROR: %s\" % (e.reason)", "response": "Generate an AEAD using the YubiHSM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_args():\n    parser = argparse.ArgumentParser(description = 'Decrypt AEADs',\n                                     add_help = True,\n                                     formatter_class = argparse.ArgumentDefaultsHelpFormatter,\n                                     )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation',\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation',\n                        )\n    parser.add_argument('--format',\n                        dest='format',\n                        default='raw',\n                        help='Select output format (aead, raw or yubikey-csv)',\n                        )\n    parser.add_argument('--output-dir',\n                        dest='output_dir',\n                        help='Output dir basename (for --format aead)',\n                        metavar='DIR',\n                        )\n    parser.add_argument('--print-filename',\n                        dest='print_filename',\n                        action='store_true', default=False,\n                        help='Prefix each row with the AEAD filename',\n                        )\n    parser.add_argument('--key-handle',\n                        dest='key_handle',\n                        help='Key handle used when generating the AEADs.',\n                        metavar='HANDLE',\n                        )\n    parser.add_argument('--key-handle-out',\n                        dest='key_handle_out',\n                        help='Key handle used when generating *new* AEADs (with --format aead).',\n                        metavar='HANDLE',\n                        )\n    parser.add_argument('--aes-key',\n                        dest='aes_key',\n                        required=True,\n                        help='AES key used when generating the AEADs.',\n                        metavar='HEXSTR',\n                        )\n    parser.add_argument('--aes-key-out',\n                        dest='aes_key_out',\n                        required=False,\n                        help='AES key used when generating *new* AEADs (with --format aead).',\n                        metavar='HEXSTR',\n                        )\n    parser.add_argument('--start-public-id',\n                        dest='start_id',\n                        required=False, default=None,\n                        help='The first public id to decrypt',\n                        metavar='INT-OR-MODHEX',\n                        )\n    parser.add_argument('--stop-public-id',\n                        dest='stop_id',\n                        required=False, default=None,\n                        help='The last public id to decrypt',\n                        metavar='INT-OR-MODHEX',\n                        )\n    parser.add_argument('--fail-fast',\n                        dest='fail_fast',\n                        action='store_true', default=False,\n                        help='Terminate on the first AEAD failure, rather than keep going.',\n                        )\n    parser.add_argument('paths',\n                        nargs='+',\n                        help='Files and/or directories to process.',\n                        metavar='FILE-OR-DIR'\n                        )\n    args = parser.parse_args()\n    # argument fixups\n    args.format = args.format.lower()\n    args.aes_key = args.aes_key.decode('hex')\n    if args.key_handle:\n        args.key_handle = pyhsm.util.key_handle_to_int(args.key_handle)\n    if args.start_id is not None:\n        try:\n            n = int(args.start_id)\n        except ValueError:\n            hexstr = pyhsm.yubikey.modhex_decode(args.start_id)\n            n = int(hexstr, 16)\n        args.start_id = n\n    if args.stop_id is not None:\n        try:\n            n = int(args.stop_id)\n        except ValueError:\n            hexstr = pyhsm.yubikey.modhex_decode(args.stop_id)\n            n = int(hexstr, 16)\n        args.stop_id = n\n    # some checks\n    if args.format == 'aead':\n        if not args.output_dir:\n            sys.stderr.write(\"error: --output-dir is required when using --format aead.\\n\")\n            return False\n        if not os.path.isdir(args.output_dir):\n            sys.stderr.write(\"error: Output directory '%s' not found\\n\" % (args.output_dir))\n            return False\n        if not args.aes_key_out:\n            sys.stderr.write(\"error: --aes-key-out is required when using --format aead.\\n\")\n            return False\n        if not args.key_handle_out:\n            sys.stderr.write(\"error: --key-handle-out is required when using --format aead.\\n\")\n            return False\n        # argument fixups\n        args.aes_key_out = args.aes_key_out.decode('hex')\n        args.key_handle_out_orig = args.key_handle_out # save to use in AEAD output paths\n        args.key_handle_out = pyhsm.util.key_handle_to_int(args.key_handle_out)\n    return args", "response": "Parse the command line arguments for the AEADs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aead_filename(aead_dir, key_handle, public_id):\n    parts = [aead_dir, key_handle] + pyhsm.util.group(public_id, 2)\n    path = os.path.join(*parts)\n\n    if not os.path.isdir(path):\n        os.makedirs(path)\n\n    return os.path.join(path, public_id)", "response": "Return the filename of the AEAD for this public_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a number of files in a directory and checks if we should continue.", "response": "def safe_process_files(path, files, args, state):\n    \"\"\"\n    Process a number of files in a directory. Catches any exception from the\n    processing and checks if we should fail directly or keep going.\n    \"\"\"\n    for fn in files:\n        full_fn = os.path.join(path, fn)\n        try:\n            if not process_file(path, fn, args, state):\n                return False\n        except Exception, e:\n            sys.stderr.write(\"error: %s\\n%s\\n\" % (os.path.join(path, fn), traceback.format_exc()))\n            state.log_failed(full_fn)\n        if state.should_quit():\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef walk_dir(path, args, state):\n    if args.debug:\n        sys.stderr.write(\"Walking %s\\n\" % path)\n\n    for root, _dirs, files in os.walk(path):\n        if not safe_process_files(root, files, args, state):\n            return False\n        if state.should_quit():\n            return False\n    return True", "response": "Walk a directory and check if there are any requests that we should send out on the bus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    global args\n    args = parse_args()\n\n    if not args:\n        return 1\n\n    state = MyState(args)\n\n    for path in args.paths:\n        if os.path.isdir(path):\n            walk_dir(path, args, state)\n        else:\n            safe_process_files(os.path.dirname(path), [os.path.basename(path)], args, state)\n        if state.should_quit():\n            break\n    if state.failed_files:\n        sys.stderr.write(\"error: %i/%i AEADs failed\\n\" % (len(state.failed_files), state.file_count))\n        return 1\n    if args.debug:\n        sys.stderr.write(\"Successfully processed %i AEADs\\n\" % (state.file_count))", "response": "Main function when running as a program."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_for_oath_code(hsm, key_handle, nonce, aead, counter, user_code, look_ahead=1):\n    key_handle = pyhsm.util.input_validate_key_handle(key_handle)\n    nonce = pyhsm.util.input_validate_nonce(nonce, pad = False)\n    aead = pyhsm.util.input_validate_aead(aead)\n    counter = pyhsm.util.input_validate_int(counter, 'counter')\n    user_code = pyhsm.util.input_validate_int(user_code, 'user_code')\n    hsm.load_temp_key(nonce, key_handle, aead)\n    # User might have produced codes never sent to us, so we support trying look_ahead\n    # codes to see if we find the user's current code.\n    for j in xrange(look_ahead):\n        this_counter = counter + j\n        secret = struct.pack(\"> Q\", this_counter)\n        hmac_result = hsm.hmac_sha1(pyhsm.defines.YSM_TEMP_KEY_HANDLE, secret).get_hash()\n        this_code = truncate(hmac_result)\n        if this_code == user_code:\n            return this_counter + 1\n    return None", "response": "Search for an OATH HOTP OTP generated by a token whose secret key is available to the YubiHSM through the AEAD."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncate(hmac_result, length=6):\n    assert(len(hmac_result) == 20)\n    offset   =  ord(hmac_result[19]) & 0xf\n    bin_code = (ord(hmac_result[offset]) & 0x7f) << 24 \\\n        | (ord(hmac_result[offset+1]) & 0xff) << 16 \\\n        | (ord(hmac_result[offset+2]) & 0xff) <<  8 \\\n        | (ord(hmac_result[offset+3]) & 0xff)\n    return bin_code % (10 ** length)", "response": "Truncate the HMAC result to the specified length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data, debug_info=None):\n        self.num_write_bytes += len(data)\n        if self.debug:\n            if not debug_info:\n                debug_info = str(len(data))\n            sys.stderr.write(\"%s: WRITE %s:\\n%s\\n\" %(\n                    self.__class__.__name__,\n                    debug_info,\n                    pyhsm.util.hexdump(data)\n                    ))\n        return self.ser.write(data)", "response": "Write data to YHSM device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, num_bytes, debug_info=None):\n        if self.debug:\n            if not debug_info:\n                debug_info = str(num_bytes)\n            sys.stderr.write(\"%s: READING %s\\n\" %(\n                    self.__class__.__name__,\n                    debug_info\n                    ))\n        res = self.ser.read(num_bytes)\n        if self.debug:\n            sys.stderr.write(\"%s: READ %i:\\n%s\\n\" %(\n                    self.__class__.__name__,\n                    len(res),\n                    pyhsm.util.hexdump(res)\n                    ))\n        self.num_read_bytes += len(res)\n        return res", "response": "Read a number of bytes from YubiHSM device."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract keyhandle value from the path", "response": "def extract_keyhandle(path, filepath):\n    \"\"\"extract keyhandle value from the path\"\"\"\n\n    keyhandle = filepath.lstrip(path)\n    keyhandle = keyhandle.split(\"/\")\n    return keyhandle[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_query(connection, publicId, aead, keyhandle, aeadobj):\n\n    # turn the keyhandle into an integer\n    keyhandle = key_handle_to_int(keyhandle)\n    if not keyhandle == aead.key_handle:\n        print(\"WARNING: keyhandle does not match aead.key_handle\")\n        return None\n\n    # creates the query object\n    try:\n        sql = aeadobj.insert().values(public_id=publicId, keyhandle=aead.key_handle, nonce=aead.nonce, aead=aead.data)\n        # insert the query\n        result = connection.execute(sql)\n        return result\n    except sqlalchemy.exc.IntegrityError:\n        pass\n    return None", "response": "this functions creates sql query and inserts everything inside the database"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse command line arguments and return a list of tuples.", "response": "def parse_args():\n    \"\"\"\n    Parse the command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Import existing secrets to YubiHSM eco system\",\n        add_help=True, formatter_class=argparse.ArgumentDefaultsHelpFormatter,)\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device',\n                        )\n    parser.add_argument('-O', '--output-dir', '--aead-dir',\n                        dest='output_dir',\n                        default=default_dir,\n                        required=False,\n                        help='Output directory (AEAD base dir)',\n                        metavar='DIR',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation',\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation',\n                        )\n    parser.add_argument('--public-id-chars',\n                        dest='public_id_chars',\n                        type=int, default=default_public_id_chars,\n                        required=False,\n                        help='Number of chars in generated public ids',\n                        metavar='NUM',\n                        )\n    parser.add_argument(\n        '--key-handles',\n        dest='key_handles',\n        nargs='+',\n        required=True,\n        help='Key handle(s) to encrypt the imported secrets with',\n        metavar='HANDLE',\n     )\n    parser.add_argument('--internal-db',\n                        dest='internal_db',\n                        action='store_true', default=False,\n                        help='Store key in YubiHSM internal database',\n                        )\n    parser.add_argument(\n        '--aes-key',\n        dest='aes_key',\n        required=False,\n        default=None,\n        help='AES key to use when generating AEADs (no YubiHSM)',\n        metavar='HEXSTR',\n     )\n    parser.add_argument('--random-nonce',\n                        dest='random_nonce',\n                        action='store_true', default=False,\n                        help='Let the HSM generate random nonce',\n                        )\n\n    args = parser.parse_args()\n    if args.internal_db:\n        if len(args.key_handles) != 1:\n            sys.stderr.write(\"--internal-db requires exactly one key handle.\\n\")\n            sys.exit(1)\n        if args.aes_key:\n            sys.stderr.write(\"--internal-db incompatible with --aes-key.\\n\")\n            sys.exit(1)\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keyhandles_fixup(args):\n    new_handles = {}\n    for val in args.key_handles:\n        n = pyhsm.util.key_handle_to_int(val)\n        new_handles[n] = val\n\n    args.key_handles = new_handles", "response": "Normalize the key handles in the input format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_keys(hsm, args):\n    res = True\n\n    # ykksm 1\n    #123456,ftftftcccc,534543524554,fcacd309a20ce1809c2db257f0e8d6ea,000000000000,,,\n\n    for line in sys.stdin:\n        if line[0] == '#':\n            continue\n\n        l = line.split(',')\n        modhex_id = l[1]\n        uid = l[2].decode('hex')\n        key = l[3].decode('hex')\n\n        if modhex_id and uid and key:\n            public_id = pyhsm.yubikey.modhex_decode(modhex_id)\n            padded_id = modhex_id.rjust(args.public_id_chars, 'c')\n\n        if int(public_id, 16) == 0:\n            print \"WARNING: Skipping import of key with public ID: %s\" % (padded_id)\n            print \"This public ID is unsupported by the YubiHSM.\\n\"\n            continue\n\n        if args.verbose:\n            print \"  %s\" % (padded_id)\n\n        secret = pyhsm.aead_cmd.YHSM_YubiKeySecret(key, uid)\n        hsm.load_secret(secret)\n\n        for kh in args.key_handles.keys():\n            if(args.random_nonce):\n                nonce = \"\"\n            else:\n                nonce = public_id.decode('hex')\n            aead = hsm.generate_aead(nonce, kh)\n\n            if args.internal_db:\n                if not store_in_internal_db(\n                        args, hsm, modhex_id, public_id, kh, aead):\n                    res = False\n                continue\n\n            filename = output_filename(\n                args.output_dir, args.key_handles[kh], padded_id)\n\n            if args.verbose:\n                print \"    %4s, %i bytes (%s) -> %s\" % \\\n                    (args.key_handles[kh], len(aead.data), shorten_aead(aead), filename)\n\n            aead.save(filename)\n\n        if args.verbose:\n            print \"\"\n\n    if res:\n        print \"\\nDone\\n\"\n    else:\n        print \"\\nDone (one or more entries rejected)\"\n    return res", "response": "Import all keys from stdin into a new YubiKey."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores record in internal db.", "response": "def store_in_internal_db(args, hsm, modhex_id, public_id, kh, aead):\n    \"\"\" Store record (AEAD) in YubiHSM internal DB \"\"\"\n    if args.verbose:\n        print \"    %i bytes (%s) -> internal db...\" % \\\n            (len(aead.data), shorten_aead(aead)),\n    try:\n        hsm.db_store_yubikey(public_id.decode('hex'), kh, aead)\n        if args.verbose:\n            print \"OK\"\n    except pyhsm.exception.YHSM_CommandFailed as e:\n        if args.verbose:\n            print \"%s\" % (pyhsm.defines.status2str(e.status))\n        else:\n            print \"Storing ID %s FAILED: %s\" % (modhex_id, pyhsm.defines.status2str(e.status))\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing pretty - printable version of long AEAD.", "response": "def shorten_aead(aead):\n    \"\"\" Produce pretty-printable version of long AEAD. \"\"\"\n    head = aead.data[:4].encode('hex')\n    tail = aead.data[-4:].encode('hex')\n    return \"%s...%s\" % (head, tail)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_filename(output_dir, key_handle, public_id):\n    parts = [output_dir, key_handle] + pyhsm.util.group(public_id, 2)\n    path = os.path.join(*parts)\n\n    if not os.path.isdir(path):\n        os.makedirs(path)\n\n    return os.path.join(path, public_id)", "response": "Return a filename for a generated AEAD."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_result(self, data):\n        # typedef struct {\n        #   uint8_t publicId[YSM_PUBLIC_ID_SIZE]; // Public id (nonce)\n        #   uint32_t keyHandle;                 // Key handle\n        #   YSM_STATUS status;                  // Validation status\n        # } YSM_DB_YUBIKEY_AEAD_STORE_RESP;\n        public_id, \\\n            key_handle, \\\n            self.status = struct.unpack(\"< %is I B\" % (pyhsm.defines.YSM_AEAD_NONCE_SIZE), data)\n\n        pyhsm.util.validate_cmd_response_str('public_id', public_id, self.public_id)\n        pyhsm.util.validate_cmd_response_hex('key_handle', key_handle, self.key_handle)\n\n        if self.status == pyhsm.defines.YSM_STATUS_OK:\n            return True\n        else:\n            raise pyhsm.exception.YHSM_CommandFailed(pyhsm.defines.cmd2str(self.command), self.status)", "response": "Parse the response from the AEAD store command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_args():\n    parser = argparse.ArgumentParser(description = \"Generate secrets for YubiKeys using YubiHSM\",\n                                     add_help=True,\n                                     formatter_class = argparse.ArgumentDefaultsHelpFormatter,\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device',\n                        )\n    parser.add_argument('-O', '--output-dir', '--aead-dir',\n                        dest='output_dir',\n                        default=default_dir,\n                        required=False,\n                        help='Output directory (AEAD base dir)',\n                        )\n    parser.add_argument('-c', '--count',\n                        dest='count',\n                        type=int, default=1,\n                        required=False,\n                        help='Number of secrets to generate',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation',\n                        )\n    parser.add_argument('--public-id-chars',\n                        dest='public_id_chars',\n                        type=int, default=12,\n                        required=False,\n                        help='Number of chars in generated public ids',\n                        )\n    parser.add_argument('--key-handles',\n                        dest='key_handles',\n                        nargs='+',\n                        required=True,\n                        help='Key handles to encrypt the generated secrets with',\n                        )\n    parser.add_argument('--start-public-id',\n                        dest='start_id',\n                        required=True,\n                        help='The first public id to generate AEAD for',\n                        )\n\n    parser.add_argument('--random-nonce',\n                        dest='random_nonce',\n                        required=False,\n                        action='store_true', default=False,\n                        help='Let the HSM generate nonce',\n                        )\n\n    return parser.parse_args()", "response": "Parse the command line arguments for the AEAD generation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_keys(hsm, args):\n\n    if args.verbose:\n        print \"Generating %i keys :\\n\" % (args.count)\n    else:\n        print \"Generating %i keys\" % (args.count)\n\n    for int_id in range(args.start_id, args.start_id + args.count):\n        public_id = (\"%x\" % int_id).rjust(args.public_id_chars, '0')\n        padded_id = pyhsm.yubikey.modhex_encode(public_id)\n\n        if args.verbose:\n            print \"  %s\" % (padded_id)\n\n        num_bytes = len(pyhsm.aead_cmd.YHSM_YubiKeySecret('a' * 16, 'b' * 6).pack())\n        hsm.load_random(num_bytes)\n        for kh in args.key_handles.keys():\n            if args.random_nonce:\n                nonce = \"\"\n            else:\n                nonce = public_id.decode('hex')\n            aead = hsm.generate_aead(nonce, kh)\n\n            filename = output_filename(args.output_dir, args.key_handles[kh], padded_id)\n\n            if args.verbose:\n                print \"    %4s, %i bytes (%s) -> %s\" % \\\n                    (args.key_handles[kh], len(aead.data), shorten_aead(aead), filename)\n            aead.save(filename)\n\n        if args.verbose:\n            print \"\"\n\n    print \"\\nDone\\n\"", "response": "Generate the keys for the current YubiKey."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset(stick):\n    nulls = (pyhsm.defines.YSM_MAX_PKT_SIZE - 1) * '\\x00'\n    res = YHSM_Cmd(stick, pyhsm.defines.YSM_NULL, payload = nulls).execute(read_response = False)\n    unlock = stick.acquire()\n    try:\n        stick.drain()\n        stick.flush()\n    finally:\n        unlock()\n    return res == 0", "response": "Send a bunch of zero - bytes to the YubiHSM and flush the input buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting command to HSM and read response.", "response": "def execute(self, read_response=True):\n        \"\"\"\n        Write command to HSM and read response.\n\n        @param read_response: Whether to expect a response or not.\n        @type read_response: bool\n        \"\"\"\n        # // Up- and downlink packet\n        # typedef struct {\n        #   uint8_t bcnt;                       // Number of bytes (cmd + payload)\n        #   uint8_t cmd;                        // YSM_xxx command\n        #   uint8_t payload[YSM_MAX_PKT_SIZE];  // Payload\n        # } YSM_PKT;\n        if self.command != pyhsm.defines.YSM_NULL:\n            # YSM_NULL is the exception to the rule - it should NOT be prefixed with YSM_PKT.bcnt\n            cmd_buf = struct.pack('BB', len(self.payload) + 1, self.command)\n        else:\n            cmd_buf = chr(self.command)\n        cmd_buf += self.payload\n        debug_info = None\n        unlock = self.stick.acquire()\n        try:\n            if self.stick.debug:\n                debug_info = \"%s (payload %i/0x%x)\" % (pyhsm.defines.cmd2str(self.command), \\\n                                                        len(self.payload), len(self.payload))\n            self.stick.write(cmd_buf, debug_info)\n            if not read_response:\n                return None\n            return self._read_response()\n        finally:\n            unlock()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_response(self):\n        # // Up- and downlink packet\n        # typedef struct {\n        #   uint8_t bcnt;                       // Number of bytes (cmd + payload)\n        #   uint8_t cmd;                        // YSM_xxx command\n        #   uint8_t payload[YSM_MAX_PKT_SIZE];  // Payload\n        # } YSM_PKT;\n\n        # read YSM_PKT.bcnt and YSM_PKT.cmd\n        res = self.stick.read(2, 'response length + response status')\n        if len(res) != 2:\n            self._handle_invalid_read_response(res, 2)\n        response_len, response_status = struct.unpack('BB', res)\n        response_len -= 1 # the status byte has been read already\n        debug_info = None\n        if response_status & pyhsm.defines.YSM_RESPONSE:\n            debug_info = \"%s response (%i/0x%x bytes)\" \\\n                % (pyhsm.defines.cmd2str(response_status - pyhsm.defines.YSM_RESPONSE), \\\n                       response_len, response_len)\n        # read YSM_PKT.payload\n        res = self.stick.read(response_len, debug_info)\n        if res:\n            if response_status == self.command | pyhsm.defines.YSM_RESPONSE:\n                self.executed = True\n                self.response_status = response_status\n                return self.parse_result(res)\n            else:\n                reset(self.stick)\n                raise pyhsm.exception.YHSM_Error('YubiHSM responded to wrong command')\n        else:\n            raise pyhsm.exception.YHSM_Error('YubiHSM did not respond')", "response": "Read response from YubiHSM and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_invalid_read_response(self, res, expected_len):\n        if not res:\n            reset(self.stick)\n            raise pyhsm.exception.YHSM_Error('YubiHSM did not respond to command %s' \\\n                                                 % (pyhsm.defines.cmd2str(self.command)) )\n        # try to check if it is a YubiHSM in configuration mode\n        self.stick.write('\\r\\r\\r', '(mode test)')\n        res2 = self.stick.read(50) # expect a timeout\n        lines = res2.split('\\n')\n        for this in lines:\n            if re.match('^(NO_CFG|WSAPI|HSM).*> .*', this):\n                raise pyhsm.exception.YHSM_Error('YubiHSM is in configuration mode')\n        raise pyhsm.exception.YHSM_Error('Unknown response from serial device %s : \"%s\"' \\\n                                             % (self.stick.device, res.encode('hex')))", "response": "This function is called when we do not get the expected frame header from YubiHSM."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset(self, test_sync = True):\n        pyhsm.cmd.reset(self.stick)\n        if test_sync:\n            # Now verify we are in sync\n            data = 'ekoeko'\n            echo = self.echo(data)\n            # XXX analyze 'echo' to see if we are in config mode, and produce a\n            # nice exception if we are.\n            return data == echo\n        else:\n            return True", "response": "Perform stream resynchronization.\n\n        @param test_sync: Verify sync with YubiHSM after reset\n        @type test_sync: bool\n\n        @return: True if successful\n        @rtype: bool"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_debug(self, new):\n        if type(new) is not bool:\n            raise pyhsm.exception.YHSM_WrongInputType(\n                'new', bool, type(new))\n        old = self.debug\n        self.debug = new\n        self.stick.set_debug(new)\n        return old", "response": "Set debug mode.\n\n        @param new: new value\n        @type new: bool\n\n        @return: old value\n        @rtype: bool"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef echo(self, data):\n        return pyhsm.basic_cmd.YHSM_Cmd_Echo(self.stick, data).execute()", "response": "Echo data from YubiHSM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random(self, num_bytes):\n        return pyhsm.basic_cmd.YHSM_Cmd_Random(self.stick, num_bytes).execute()", "response": "Get random bytes from YubiHSM."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovide YubiHSM DRBG_CTR with a new seed.", "response": "def random_reseed(self, seed):\n        \"\"\"\n        Provide YubiHSM DRBG_CTR with a new seed.\n\n        @param seed: new seed -- must be exactly 32 bytes\n        @type seed: string\n\n        @returns: True on success\n        @rtype: bool\n\n        @see: L{pyhsm.basic_cmd.YHSM_Cmd_Random_Reseed}\n        \"\"\"\n        return pyhsm.basic_cmd.YHSM_Cmd_Random_Reseed(self.stick, seed).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the current nonce value from YubiHSM.", "response": "def get_nonce(self, increment=1):\n        \"\"\"\n        Get current nonce from YubiHSM.\n\n        Use increment 0 to just fetch the value without incrementing it.\n\n        @keyword increment: requested increment (optional)\n\n        @return: nonce value _before_ increment\n        @rtype: L{YHSM_NonceResponse}\n\n        @see: L{pyhsm.basic_cmd.YHSM_Cmd_Nonce_Get}\n       \"\"\"\n        return pyhsm.basic_cmd.YHSM_Cmd_Nonce_Get(self.stick, increment).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the contents of an AEAD into the phantom key handle 0xffffffff.", "response": "def load_temp_key(self, nonce, key_handle, aead):\n        \"\"\"\n        Load the contents of an AEAD into the phantom key handle 0xffffffff.\n\n        @param nonce: The nonce used when creating the AEAD\n        @param key_handle: The key handle that can decrypt the AEAD\n        @param aead: AEAD containing the cryptographic key and permission flags\n        @type nonce: string\n        @type key_handle: integer or string\n        @type aead: L{YHSM_GeneratedAEAD} or string\n\n        @returns: True on success\n        @rtype: bool\n\n        @see: L{pyhsm.basic_cmd.YHSM_Cmd_Temp_Key_Load}\n        \"\"\"\n        return pyhsm.basic_cmd.YHSM_Cmd_Temp_Key_Load(self.stick, nonce, key_handle, aead).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nunlocking the YubiHSM using the master key and or an OTP.", "response": "def unlock(self, password = None, otp = None):\n        \"\"\"\n        Unlock the YubiHSM using the master key and/or a YubiKey OTP.\n\n        If the master key is given during configuration, all key handles will be\n        encrypted (with AES-256) using that passphrase.\n\n        If one or more admin Yubikey public id's are given during configuration,\n        an OTP from one of these must be provided to the YubiHSM for it to start\n        responding to cryptographic requests. The admin YubiKeys must be present\n        in the internal database for this validation to work.\n\n        @param password: The 'master key' set during YubiHSM configuration\n        @type password: NoneType or string\n        @param otp: A YubiKey OTP from an 'admin' YubiKey (modhex), to unlock YubiHSM.\n        @type otp: NoneType or string\n\n        @returns: Only returns (True) on success\n        @rtype: bool\n\n        @see: L{pyhsm.basic_cmd.YHSM_Cmd_Key_Storage_Unlock}\n        @see: L{pyhsm.basic_cmd.YHSM_Cmd_HSM_Unlock}\n        \"\"\"\n        if otp is not None and not self.version.have_unlock():\n            # only in 1.0\n            raise pyhsm.exception.YHSM_Error(\"Your YubiHSM does not support OTP unlocking.\")\n        if password is not None:\n            if self.version.have_key_storage_unlock():\n                # 0.9.x\n                res = pyhsm.basic_cmd.YHSM_Cmd_Key_Storage_Unlock(self.stick, password).execute()\n            elif self.version.have_key_store_decrypt():\n                # 1.0\n                res = pyhsm.basic_cmd.YHSM_Cmd_Key_Store_Decrypt(self.stick, password).execute()\n            else:\n                raise pyhsm.exception.YHSM_Error(\"Don't know how to unlock your YubiHSM.\")\n        else:\n            res = True\n        if res and otp is not None:\n            (public_id, otp,) = pyhsm.yubikey.split_id_otp(otp)\n            public_id = pyhsm.yubikey.modhex_decode(public_id).decode('hex')\n            otp = pyhsm.yubikey.modhex_decode(otp).decode('hex')\n            return pyhsm.basic_cmd.YHSM_Cmd_HSM_Unlock(self.stick, public_id, otp).execute()\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a pre - existing YubiKey secret into the internal buffer.", "response": "def load_secret(self, secret):\n        \"\"\"\n        Ask YubiHSM to load a pre-existing YubiKey secret.\n\n        The data is stored internally in the YubiHSM in temporary memory -\n        this operation would typically be followed by one or more L{generate_aead}\n        commands to actually retreive the generated secret (in encrypted form).\n\n        @param secret: YubiKey secret to load\n        @type secret: L{pyhsm.aead_cmd.YHSM_YubiKeySecret} or string\n\n        @returns: Number of bytes in YubiHSM internal buffer after load\n        @rtype: integer\n\n        @see: L{pyhsm.buffer_cmd.YHSM_Cmd_Buffer_Load}\n        \"\"\"\n        if isinstance(secret, pyhsm.aead_cmd.YHSM_YubiKeySecret):\n            secret = secret.pack()\n        return pyhsm.buffer_cmd.YHSM_Cmd_Buffer_Load(self.stick, secret).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_data(self, data, offset):\n        return pyhsm.buffer_cmd.YHSM_Cmd_Buffer_Load(self.stick, data, offset).execute()", "response": "Load data into the internal buffer at any offset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a number of random bytes from the YubiHSM internal buffer.", "response": "def load_random(self, num_bytes, offset = 0):\n        \"\"\"\n        Ask YubiHSM to generate a number of random bytes to any offset of it's internal\n        buffer.\n\n        The data is stored internally in the YubiHSM in temporary memory -\n        this operation would typically be followed by one or more L{generate_aead}\n        commands to actually retreive the generated secret (in encrypted form).\n\n        @param num_bytes: Number of bytes to generate\n        @type num_bytes: integer\n\n        @returns: Number of bytes in YubiHSM internal buffer after load\n        @rtype: integer\n\n        @see: L{pyhsm.buffer_cmd.YHSM_Cmd_Buffer_Random_Load}\n        \"\"\"\n        return pyhsm.buffer_cmd.YHSM_Cmd_Buffer_Random_Load(self.stick, num_bytes, offset).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates an AEAD block from data for a specific key in a single step.", "response": "def generate_aead_simple(self, nonce, key_handle, data):\n        \"\"\"\n        Generate AEAD block from data for a specific key in a single step\n        (without using the YubiHSM internal buffer).\n\n        @param nonce: The nonce to use when creating the AEAD\n        @param key_handle: The key handle that can encrypt data into an AEAD\n        @param data: Data to put inside the AEAD\n        @type nonce: string\n        @type key_handle: integer or string\n        @type data: string\n\n        @returns: The generated AEAD on success.\n        @rtype: L{YHSM_GeneratedAEAD}\n\n        @see: L{pyhsm.aead_cmd.YHSM_Cmd_AEAD_Generate}\n        \"\"\"\n        return pyhsm.aead_cmd.YHSM_Cmd_AEAD_Generate(self.stick, nonce, key_handle, data).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_aead_random(self, nonce, key_handle, num_bytes):\n        return pyhsm.aead_cmd.YHSM_Cmd_AEAD_Random_Generate(self.stick, nonce, key_handle, num_bytes).execute()", "response": "Generate a random AEAD block using the YubiHSM internal DRBG_CTR random generator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_aead(self, nonce, key_handle):\n        return pyhsm.aead_cmd.YHSM_Cmd_AEAD_Buffer_Generate(self.stick, nonce, key_handle).execute()", "response": "Ask YubiHSM to generate an AEAD for the contents of the internal buffer of the specified nonce and key handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_aead(self, nonce, key_handle, aead, cleartext):\n        return pyhsm.aead_cmd.YHSM_Cmd_AEAD_Decrypt_Cmp(self.stick, nonce, key_handle, aead, cleartext).execute()", "response": "Validate the contents of an AEAD using YubiHSM."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasking YubiHSM to validate an OTP using an AEAD and a key handle to validate the OTP.", "response": "def validate_aead_otp(self, public_id, otp, key_handle, aead):\n        \"\"\"\n        Ask YubiHSM to validate a YubiKey OTP using an AEAD and a key_handle to\n        decrypt the AEAD.\n\n        @param public_id: The six bytes public id of the YubiKey\n        @param otp: The one time password (OTP) to validate\n        @param key_handle: The key handle that can decrypt the AEAD\n        @param aead: AEAD containing the cryptographic key and permission flags\n        @type public_id: string\n        @type otp: string\n        @type key_handle: integer or string\n        @type aead: L{YHSM_GeneratedAEAD} or string\n\n        @returns: validation response\n        @rtype: L{YHSM_ValidationResult}\n\n        @see: L{pyhsm.validate_cmd.YHSM_Cmd_AEAD_Validate_OTP}\n        \"\"\"\n        if type(public_id) is not str:\n            assert()\n        if type(otp) is not str:\n            assert()\n        if type(key_handle) is not int:\n            assert()\n        if type(aead) is not str:\n            assert()\n        return pyhsm.validate_cmd.YHSM_Cmd_AEAD_Validate_OTP( \\\n            self.stick, public_id, otp, key_handle, aead).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef monitor_exit(self):\n        return pyhsm.debug_cmd.YHSM_Cmd_Monitor_Exit(self.stick).execute(read_response=False)", "response": "Ask YubiHSM to exit configuration mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef drain(self):\n        try:\n            unlock = self.stick.acquire()\n            return self.stick.drain()\n        finally:\n            unlock()", "response": "Reads until there is nothing more to be read."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aes_ecb_encrypt(self, key_handle, plaintext):\n        return pyhsm.aes_ecb_cmd.YHSM_Cmd_AES_ECB_Encrypt( \\\n            self.stick, key_handle, plaintext).execute()", "response": "AES ECB encryption using a key handle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aes_ecb_decrypt(self, key_handle, ciphertext):\n        return pyhsm.aes_ecb_cmd.YHSM_Cmd_AES_ECB_Decrypt( \\\n            self.stick, key_handle, ciphertext).execute()", "response": "AES ECB decrypt using a key handle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aes_ecb_compare(self, key_handle, ciphertext, plaintext):\n        return pyhsm.aes_ecb_cmd.YHSM_Cmd_AES_ECB_Compare( \\\n            self.stick, key_handle, ciphertext, plaintext).execute()", "response": "AES ECB decrypt and then compare using a key handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a HMAC SHA1 of data using a key handle.", "response": "def hmac_sha1(self, key_handle, data, flags = None, final = True, to_buffer = False):\n        \"\"\"\n        Have the YubiHSM generate a HMAC SHA1 of 'data' using a key handle.\n\n        Use the L{pyhsm.hmac_cmd.YHSM_Cmd_HMAC_SHA1_Write.next} to add more input (until\n        'final' has been set to True).\n\n        Use the L{pyhsm.hmac_cmd.YHSM_Cmd_HMAC_SHA1_Write.get_hash} to get the hash result\n        this far.\n\n        @param key_handle: Key handle to use when generating HMAC SHA1\n        @param data: what to calculate the HMAC SHA1 checksum of\n        @keyword flags: bit-flags, overrides 'final' and 'to_buffer'\n        @keyword final: True when there is no more data, False if there is more\n        @keyword to_buffer: Should the final result be stored in the YubiHSM internal buffer or not\n        @type key_handle: integer or string\n        @type data: string\n        @type flags: None or integer\n\n        @returns: HMAC-SHA1 instance\n        @rtype: L{YHSM_Cmd_HMAC_SHA1_Write}\n\n        @see: L{pyhsm.hmac_cmd.YHSM_Cmd_HMAC_SHA1_Write}\n        \"\"\"\n        return pyhsm.hmac_cmd.YHSM_Cmd_HMAC_SHA1_Write( \\\n            self.stick, key_handle, data, flags = flags, final = final, to_buffer = to_buffer).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef db_store_yubikey(self, public_id, key_handle, aead, nonce = None):\n        if nonce is not None and not self.version.have_YSM_DB_YUBIKEY_AEAD_STORE2():\n            # introduced in 1.0.4\n            raise pyhsm.exception.YHSM_Error(\"YubiHSM does not support nonce != public_id.\")\n        return pyhsm.db_cmd.YHSM_Cmd_DB_YubiKey_Store( \\\n            self.stick, public_id, key_handle, aead, nonce = nonce).execute()", "response": "Store data about a YubiKey in the internal database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequest the YubiHSM to validate an OTP for a YubiKey stored in the internal database.", "response": "def db_validate_yubikey_otp(self, public_id, otp):\n        \"\"\"\n        Request the YubiHSM to validate an OTP for a YubiKey stored\n        in the internal database.\n\n        @param public_id: The six bytes public id of the YubiKey\n        @param otp: The OTP from a YubiKey in binary form (16 bytes)\n        @type public_id: string\n        @type otp: string\n\n        @returns: validation response\n        @rtype: L{YHSM_ValidationResult}\n\n        @see: L{pyhsm.db_cmd.YHSM_Cmd_DB_Validate_OTP}\n        \"\"\"\n        return pyhsm.db_cmd.YHSM_Cmd_DB_Validate_OTP( \\\n            self.stick, public_id, otp).execute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef aead_filename(aead_dir, key_handle, public_id):\n    parts = [aead_dir, key_handle] + pyhsm.util.group(public_id, 2) + [public_id]\n    return os.path.join(*parts)", "response": "Return the filename of the AEAD for this public_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the command line arguments for YubiKey OTPs using YubiHSM.", "response": "def parse_args():\n    \"\"\"\n    Parse the command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Decrypt YubiKey OTPs using YubiHSM\",\n                                     add_help=True,\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device'\n                        )\n    parser.add_argument('-B', '--aead-dir',\n                        dest='aead_dir',\n                        default=default_dir,\n                        required=False,\n                        help='AEAD directory - base directory of your AEADs',\n                        metavar='DIR',\n                        )\n    parser.add_argument('-U', '--serve-url',\n                        dest='serve_url',\n                        default=default_serve_url,\n                        required=False,\n                        help='Base URL for decrypt web service',\n                        metavar='URL',\n                        )\n    parser.add_argument('-S', '--stats-url',\n                        dest='stats_url',\n                        required=False,\n                        help='URL where statistics can be retrieved',\n                        metavar='URL',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation'\n                        )\n    parser.add_argument('-d', '--daemon',\n                        dest='daemon',\n                        action='store_true', default=False,\n                        help='Run as daemon'\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation'\n                        )\n    parser.add_argument('--port',\n                        dest='listen_port',\n                        type=int, default=default_port,\n                        required=False,\n                        help='Port to listen on',\n                        metavar='PORT',\n                        )\n    parser.add_argument('--addr',\n                        dest='listen_addr',\n                        default=default_listen_addr,\n                        required=False,\n                        help='Address to bind to',\n                        metavar='ADDR',\n                        )\n    parser.add_argument('--reqtimeout',\n                        dest='reqtimeout',\n                        type=int, default=default_reqtimeout,\n                        required=False,\n                        help='Request timeout in seconds',\n                        metavar='SECONDS',\n                        )\n    parser.add_argument('--key-handle', '--key-handles',\n                        dest='key_handles',\n                        nargs='+',\n                        required=True,\n                        help='Key handle(s) to use to decrypt AEADs on the YHSM.',\n                        metavar='HANDLE',\n                        )\n    parser.add_argument('--pid-file',\n                        dest='pid_file',\n                        default=default_pid_file,\n                        required=False,\n                        help='PID file',\n                        metavar='FILENAME',\n                        )\n    parser.add_argument('--db-url',\n                        dest='db_url',\n                        default=default_db_url,\n                        required=False,\n                        help='The database url to read the AEADs from, you can '\n                        'also use env:YOURENVVAR to instead read the URL from '\n                        'the YOURENVVAR environment variable.',\n                        metavar='DBURL',\n                        )\n    parser.add_argument('--proxy', '--proxies',\n                        dest='proxies',\n                        nargs='+',\n                        required=False,\n                        default=[],\n                        help='IP addresses of proxies where the IP in '\n                        'X-Forwarded-For should be used for logging purposes.',\n                        metavar='IP',\n                        )\n\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(hsm, aead_backend, args):\n\n    write_pid_file(args.pid_file)\n\n    server_address = (args.listen_addr, args.listen_port)\n    httpd = YHSM_KSMServer(server_address,\n                           partial(YHSM_KSMRequestHandler, hsm, aead_backend, args))\n    my_log_message(args.debug or args.verbose, syslog.LOG_INFO,\n                   \"Serving requests to 'http://%s:%s%s' with key handle(s) %s (YubiHSM: '%s', AEADs in '%s', DB in '%s')\"\n                   % (args.listen_addr, args.listen_port, args.serve_url, args.key_handles, args.device, args.aead_dir, args.db_url))\n    httpd.serve_forever()", "response": "Start a BaseHTTPServer. HTTPServer and serve requests forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs a message to syslog and possibly also to stderr.", "response": "def my_log_message(verbose, prio, msg):\n    \"\"\"\n    Log to syslog, and possibly also to stderr.\n    \"\"\"\n    syslog.syslog(prio, msg)\n    if verbose or prio == syslog.LOG_ERR:\n        sys.stderr.write(\"%s\\n\" % (msg))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_GET(self):\n        # Example session:\n        # in  : GET /wsapi/decrypt?otp=ftftftccccdvvbfcfduvvcubikngtchlubtutucrld HTTP/1.0\n        # out : OK counter=0004 low=f585 high=3e use=03\n        if self.path.startswith(self.serve_url):\n            from_key = self.path[len(self.serve_url):]\n\n            val_res = self.decrypt_yubikey_otp(from_key)\n\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(val_res)\n            self.wfile.write(\"\\n\")\n        elif self.stats_url and self.path == self.stats_url:\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            for key in stats:\n                self.wfile.write(\"%s %d\\n\" % (key, stats[key]))\n        else:\n            self.log_error(\"Bad URL '%s' - I'm serving '%s' (responding 403)\" % (self.path, self.serve_url))\n            self.send_response(403, 'Forbidden')\n            self.end_headers()", "response": "Handle a HTTP GET request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to decrypt a YubiKey OTP.", "response": "def decrypt_yubikey_otp(self, from_key):\n        \"\"\"\n        Try to decrypt a YubiKey OTP.\n\n        Returns a string starting with either 'OK' or 'ERR' :\n\n        'OK counter=ab12 low=dd34 high=2a use=0a'\n\n        'ERR Unknown public_id'\n\n        on YubiHSM errors (or bad OTP), only 'ERR' is returned.\n        \"\"\"\n        if not re.match(valid_input_from_key, from_key):\n            self.log_error(\"IN: %s, Invalid OTP\" % (from_key))\n            if self.stats_url:\n                stats['invalid'] += 1\n            return \"ERR Invalid OTP\"\n\n        public_id, _otp = pyhsm.yubikey.split_id_otp(from_key)\n\n        try:\n            aead = self.aead_backend.load_aead(public_id)\n        except Exception as e:\n            self.log_error(str(e))\n            if self.stats_url:\n                stats['no_aead'] += 1\n            return \"ERR Unknown public_id\"\n\n        try:\n            res = pyhsm.yubikey.validate_yubikey_with_aead(\n                self.hsm, from_key, aead, aead.key_handle)\n            # XXX double-check public_id in res, in case BaseHTTPServer suddenly becomes multi-threaded\n            # XXX fix use vs session counter confusion\n            val_res = \"OK counter=%04x low=%04x high=%02x use=%02x\" % \\\n                (res.use_ctr, res.ts_low, res.ts_high, res.session_ctr)\n            if self.stats_url:\n                stats['ok'] += 1\n        except pyhsm.exception.YHSM_Error as e:\n            self.log_error (\"IN: %s, Validate FAILED: %s\" % (from_key, str(e)))\n            val_res = \"ERR\"\n            if self.stats_url:\n                stats['err'] += 1\n\n        self.log_message(\"SUCCESS OTP %s PT hsm %s\", from_key, val_res)\n        return val_res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_aead(self, public_id):\n        connection = self.engine.connect()\n        trans = connection.begin()\n\n        try:\n            s = sqlalchemy.select([self.aead_table]).where(\n                (self.aead_table.c.public_id == public_id)\n                & self.aead_table.c.keyhandle.in_([kh[1] for kh in self.key_handles]))\n            result = connection.execute(s)\n\n            for row in result:\n                kh_int = row['keyhandle']\n                aead = pyhsm.aead_cmd.YHSM_GeneratedAEAD(None, kh_int, '')\n                aead.data = row['aead']\n                aead.nonce = row['nonce']\n            return aead\n        except Exception as e:\n            trans.rollback()\n            raise Exception(\"No AEAD in DB for public_id %s (%s)\" % (public_id, str(e)))\n        finally:\n            connection.close()", "response": "Loads AEAD from the specified database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line arguments and return a list of AEADs.", "response": "def parse_args():\n    \"\"\"\n    Parse the command line arguments\n    \"\"\"\n    global default_device\n\n    parser = argparse.ArgumentParser(description = 'Initialize OATH token for use with yhsm-validation-server',\n                                     add_help=True,\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation',\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation',\n                        )\n    parser.add_argument('--force',\n                        dest='force',\n                        action='store_true', default=False,\n                        help='Overwrite any present entry',\n                        )\n    parser.add_argument('--key-handle',\n                        dest='key_handle',\n                        required=True,\n                        help='Key handle to create AEAD',\n                        metavar='HANDLE',\n                        )\n    parser.add_argument('--uid',\n                        dest='uid',\n                        required=True,\n                        help='User ID',\n                        metavar='STR',\n                        )\n    parser.add_argument('--oath-c',\n                        dest='oath_c',\n                        required=False,\n                        default = 0,\n                        help='Initial OATH counter value',\n                        metavar='INT',\n                        )\n    parser.add_argument('--test-oath-window',\n                        dest='look_ahead',\n                        required=False,\n                        default = 10,\n                        help='Number of codes to search with --test-code',\n                        metavar='INT',\n                        )\n    parser.add_argument('--test-code',\n                        dest='test_code',\n                        type=int, required=False,\n                        help='Optional OTP from token for verification',\n                        metavar='INT',\n                        )\n    parser.add_argument('--oath-k',\n                        dest='oath_k',\n                        required=False,\n                        help='The secret key of the token, hex encoded',\n                        metavar='HEXSTR',\n                        )\n    parser.add_argument('--db-file',\n                        dest='db_file',\n                        default=default_db_file,\n                        required=False,\n                        help='DB file for storing AEAD\\'s for --pwhash and --oath in the yhsm-validation-server',\n                        metavar='FN',\n                        )\n\n    args = parser.parse_args()\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_aead(hsm, args):\n    key = get_oath_k(args)\n    # Enabled flags 00010000 = YSM_HMAC_SHA1_GENERATE\n    flags = struct.pack(\"< I\", 0x10000)\n    hsm.load_secret(key + flags)\n    nonce = hsm.get_nonce().nonce\n    aead = hsm.generate_aead(nonce, args.key_handle)\n    if args.debug:\n        print \"AEAD: %s (%s)\" % (aead.data.encode('hex'), aead)\n    return nonce, aead", "response": "Generate an AEAD for the current oath - k."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the OATH K value from args. oath_k or by prompting.", "response": "def get_oath_k(args):\n    \"\"\" Get the OATH K value (secret key), either from args or by prompting. \"\"\"\n    if args.oath_k:\n        decoded = args.oath_k.decode('hex')\n    else:\n        t = raw_input(\"Enter OATH key (hex encoded) : \")\n        decoded = t.decode('hex')\n\n    if len(decoded) > 20:\n        decoded = sha1(decoded).digest()\n    decoded = decoded.ljust(20, '\\0')\n    return decoded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore the AEAD in the database.", "response": "def store_oath_entry(args, nonce, aead, oath_c):\n    \"\"\" Store the AEAD in the database. \"\"\"\n    data = {\"key\": args.uid,\n            \"aead\": aead.data.encode('hex'),\n            \"nonce\": nonce.encode('hex'),\n            \"key_handle\": args.key_handle,\n            \"oath_C\": oath_c,\n            \"oath_T\": None,\n            }\n    entry = ValOathEntry(data)\n    db = ValOathDb(args.db_file)\n    try:\n        if args.force:\n            db.delete(entry)\n        db.add(entry)\n    except sqlite3.IntegrityError, e:\n        sys.stderr.write(\"ERROR: %s\\n\" % (e))\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, entry):\n        c = self.conn.cursor()\n        c.execute(\"INSERT INTO oath (key, aead, nonce, key_handle, oath_C, oath_T) VALUES (?, ?, ?, ?, ?, ?)\",\n                  (entry.data[\"key\"], \\\n                       entry.data[\"aead\"], \\\n                       entry.data[\"nonce\"], \\\n                       entry.data[\"key_handle\"], \\\n                       entry.data[\"oath_C\"], \\\n                       entry.data[\"oath_T\"],))\n        self.conn.commit()\n        return c.rowcount == 1", "response": "Add entry to database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete entry from database.", "response": "def delete(self, entry):\n        \"\"\" Delete entry from database. \"\"\"\n        c = self.conn.cursor()\n        c.execute(\"DELETE FROM oath WHERE key = ?\", (entry.data[\"key\"],))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a slash into the end of the string", "response": "def insert_slash(string, every=2):\n    \"\"\"insert_slash insert / every 2 char\"\"\"\n    return os.path.join(string[i:i+every] for i in xrange(0, len(string), every))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the response from YubiKey AEAD command.", "response": "def parse_result(self, data):\n        \"\"\"\n        Returns a YHSM_GeneratedAEAD instance, or throws pyhsm.exception.YHSM_CommandFailed.\n        \"\"\"\n        # typedef struct {\n        #   uint8_t nonce[YSM_AEAD_NONCE_SIZE]; // Nonce (publicId for Yubikey AEADs)\n        #   uint32_t keyHandle;                 // Key handle\n        #   YSM_STATUS status;                  // Status\n        #   uint8_t numBytes;                   // Number of bytes in AEAD block\n        #   uint8_t aead[YSM_AEAD_MAX_SIZE];    // AEAD block\n        # } YSM_AEAD_GENERATE_RESP;\n\n        nonce, \\\n            key_handle, \\\n            self.status, \\\n            num_bytes = struct.unpack_from(\"< %is I B B\" % (pyhsm.defines.YSM_AEAD_NONCE_SIZE), data, 0)\n\n        pyhsm.util.validate_cmd_response_hex('key_handle', key_handle, self.key_handle)\n\n        if self.status == pyhsm.defines.YSM_STATUS_OK:\n            pyhsm.util.validate_cmd_response_nonce(nonce, self.nonce)\n            offset = pyhsm.defines.YSM_AEAD_NONCE_SIZE + 6\n            aead = data[offset:offset + num_bytes]\n            self.response = YHSM_GeneratedAEAD(nonce, key_handle, aead)\n            return self.response\n        else:\n            raise pyhsm.exception.YHSM_CommandFailed(pyhsm.defines.cmd2str(self.command), self.status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename):\n        aead_f = open(filename, \"wb\")\n        fmt = \"< B I %is %is\" % (pyhsm.defines.YSM_AEAD_NONCE_SIZE, len(self.data))\n        version = 1\n        packed = struct.pack(fmt, version, self.key_handle, self.nonce, self.data)\n        aead_f.write(YHSM_AEAD_File_Marker + packed)\n        aead_f.close()", "response": "Store AEAD in a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, filename):\n        aead_f = open(filename, \"rb\")\n        buf = aead_f.read(1024)\n        if buf.startswith(YHSM_AEAD_CRLF_File_Marker):\n            buf = YHSM_AEAD_File_Marker + buf[len(YHSM_AEAD_CRLF_File_Marker):]\n        if buf.startswith(YHSM_AEAD_File_Marker):\n            if buf[len(YHSM_AEAD_File_Marker)] == chr(1):\n                # version 1 format\n                fmt = \"< I %is\" % (pyhsm.defines.YSM_AEAD_NONCE_SIZE)\n                self.key_handle, self.nonce = struct.unpack_from(fmt, buf, len(YHSM_AEAD_File_Marker) + 1)\n                self.data = buf[len(YHSM_AEAD_File_Marker) + 1 + struct.calcsize(fmt):]\n            else:\n                raise pyhsm.exception.YHSM_Error('Unknown AEAD file format')\n        else:\n            # version 0 format, just AEAD data\n            self.data = buf[:pyhsm.defines.YSM_MAX_KEY_SIZE + pyhsm.defines.YSM_BLOCK_SIZE]\n        aead_f.close()", "response": "Load AEAD from a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the key and uid for sending in a command to the YubiHSM.", "response": "def pack(self):\n        \"\"\" Return key and uid packed for sending in a command to the YubiHSM. \"\"\"\n        # # 22-bytes Yubikey secrets block\n        # typedef struct {\n        #   uint8_t key[KEY_SIZE];              // AES key\n        #   uint8_t uid[UID_SIZE];              // Unique (secret) ID\n        # } YUBIKEY_SECRETS;\n        return self.key + self.uid.ljust(pyhsm.defines.UID_SIZE, chr(0))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_args():\n    parser = argparse.ArgumentParser(description = \"Add random data from YubiHSM to Linux entropy\",\n                                     add_help = True,\n                                     formatter_class = argparse.ArgumentDefaultsHelpFormatter,\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device',\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation'\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation'\n                        )\n    parser.add_argument('-r', '--ratio',\n                        dest='ratio',\n                        type=int, default=default_entropy_ratio,\n                        help='Bits per byte of data read to use as entropy',\n                        )\n    parser.add_argument('-c', '--count',\n                        dest='iterations',\n                        type=int, default=default_iterations,\n                        help='Number of iterations to run',\n                        )\n\n    args = parser.parse_args()\n\n    return args", "response": "Parse the command line arguments for YubiHSM to Linux entropy"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_entropy(hsm, iterations, entropy_ratio):\n    fd = os.open(\"/dev/random\", os.O_WRONLY)\n    # struct rand_pool_info {\n    #    int     entropy_count;\n    #    int     buf_size;\n    #    __u32   buf[0];\n    # };\n    fmt = 'ii%is' % (pyhsm.defines.YSM_MAX_PKT_SIZE - 1)\n    for _ in xrange(iterations):\n        rnd = hsm.random(pyhsm.defines.YSM_MAX_PKT_SIZE - 1)\n        this = struct.pack(fmt, entropy_ratio * len(rnd), len(rnd), rnd)\n        fcntl.ioctl(fd, RNDADDENTROPY, this)\n    os.close(fd)", "response": "Read entropy from YubiHSM and feed it to Linux as entropy using ioctl."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the entropy of a random key list.", "response": "def main():\n    \"\"\"\n    What will be executed when running as a stand alone program.\n    \"\"\"\n    args = parse_args()\n\n    try:\n        s = pyhsm.base.YHSM(device=args.device, debug=args.debug)\n        get_entropy(s, args.iterations, args.ratio)\n        return 0\n    except pyhsm.exception.YHSM_Error as e:\n        sys.stderr.write(\"ERROR: %s\" % (e.reason))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args():\n    global default_device\n\n    parser = argparse.ArgumentParser(description = \"Validate YubiKey OTP's using YubiHSM\",\n                                     add_help=True\n                                     )\n    parser.add_argument('-D', '--device',\n                        dest='device',\n                        default=default_device,\n                        required=False,\n                        help='YubiHSM device (default : %s).' % default_device\n                        )\n    parser.add_argument('-v', '--verbose',\n                        dest='verbose',\n                        action='store_true', default=False,\n                        help='Enable verbose operation.'\n                        )\n    parser.add_argument('--debug',\n                        dest='debug',\n                        action='store_true', default=False,\n                        help='Enable debug operation.'\n                        )\n    group = parser.add_argument_group('Modes', 'What you want to validate')\n    mode_group = group.add_mutually_exclusive_group(required = True)\n    mode_group.add_argument('--otp',\n                            dest='otp',\n                            help='The output from your YubiKey.'\n                            )\n    mode_group.add_argument('--oath',\n                            dest='oath',\n                            help='The output from your OATH-HOTP token.'\n                            )\n\n    args = parser.parse_args()\n    return args", "response": "Parse the command line arguments for YubiKey OTP validation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for OATH TOTP OTP generated by a token using a YubiHSM.", "response": "def search_for_oath_code(hsm, key_handle, nonce, aead, user_code, interval=30,\n                         tolerance=0):\n    \"\"\"\n    Try to validate an OATH TOTP OTP generated by a token whose secret key is\n    available to the YubiHSM through the AEAD.\n\n    The parameter `aead' is either a string, or an instance of YHSM_GeneratedAEAD.\n\n    Returns timecounter value on successful auth, and None otherwise.\n    \"\"\"\n\n    # timecounter is the lowest acceptable value based on tolerance\n    timecounter = timecode(datetime.datetime.now(), interval) - tolerance\n\n    return search_hotp(\n        hsm, key_handle, nonce, aead, timecounter, user_code, 1 + 2*tolerance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef timecode(time_now, interval):\n    i = time.mktime(time_now.timetuple())\n    return int(i / interval)", "response": "make integer and divide by time interval of valid OTP"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the response from the unlock key storage command.", "response": "def parse_result(self, data):\n        \"\"\"\n        Parse result of L{pyhsm.defines.YSM_KEY_STORAGE_UNLOCK} command.\n\n        @return: Only returns (True) on successful unlock\n        @rtype: bool\n\n        @raise pyhsm.exception.YHSM_CommandFailed: YubiHSM failed to unlock key storage\n        \"\"\"\n        # typedef struct {\n        #   YSM_STATUS status;                  // Unlock status\n        # } YSM_KEY_STORAGE_UNLOCK_RESP;\n        fmt = \"B\"\n        self.status, = struct.unpack(fmt, data)\n\n        if self.status == pyhsm.defines.YSM_STATUS_OK:\n            return True\n        else:\n            raise pyhsm.exception.YHSM_CommandFailed(pyhsm.defines.cmd2str(self.command), self.status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _xor_block(a, b):\n    return ''.join([chr(ord(x) ^ ord(y)) for (x, y) in zip(a, b)])", "response": "XOR two blocks of equal length."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aesCCM(key, key_handle, nonce, data, decrypt=False):\n    if decrypt:\n        (data, saved_mac) = _split_data(data, len(data) - pyhsm.defines.YSM_AEAD_MAC_SIZE)\n\n    nonce = pyhsm.util.input_validate_nonce(nonce, pad = True)\n    mac = _cbc_mac(key, key_handle, nonce, len(data))\n\n    counter = _ctr_counter(key_handle, nonce, value = 0)\n    ctr_aes = AES.new(key, AES.MODE_CTR, counter = counter.next)\n    out = []\n    while data:\n        (thisblock, data) = _split_data(data, pyhsm.defines.YSM_BLOCK_SIZE)\n\n        # encrypt/decrypt and CBC MAC\n        if decrypt:\n            aes_out = ctr_aes.decrypt(thisblock)\n            mac.update(aes_out)\n        else:\n            mac.update(thisblock)\n            aes_out = ctr_aes.encrypt(thisblock)\n\n        out.append(aes_out)\n\n    # Finalize MAC\n    counter.value = 0\n    mac.finalize(counter.pack())\n    if decrypt:\n        if mac.get() != saved_mac:\n            raise pyhsm.exception.YHSM_Error('AEAD integrity check failed')\n    else:\n        out.append(mac.get())\n    return ''.join(out)", "response": "Function implementing YubiHSM AEAD encrypt / decrypt in software."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef crc16(data):\n    m_crc = 0xffff\n    for this in data:\n        m_crc ^= ord(this)\n        for _ in range(8):\n            j = m_crc & 1\n            m_crc >>= 1\n            if j:\n                m_crc ^= 0x8408\n    return m_crc", "response": "Calculate an ISO13239 CRC checksum of the input buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinalizing the CBC - MAC encryption before XOR.", "response": "def finalize(self, block):\n        \"\"\"\n        The final step of CBC-MAC encrypts before xor.\n        \"\"\"\n        t1 = self.mac_aes.encrypt(block)\n        t2 = _xor_block(self.mac, t1)\n        self.mac = t2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_otp(hsm, from_key):\n    public_id, otp = split_id_otp(from_key)\n    return hsm.db_validate_yubikey_otp(modhex_decode(public_id).decode('hex'),\n                                       modhex_decode(otp).decode('hex')\n                                       )", "response": "Validate an OTP from a YubiKey using the internal database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating an OTP from a YubiKey using the AEAD.", "response": "def validate_yubikey_with_aead(hsm, from_key, aead, key_handle):\n    \"\"\"\n    Try to validate an OTP from a YubiKey using the AEAD that can decrypt this YubiKey's\n    internal secret, using the key_handle for the AEAD.\n\n    `from_key' is the modhex encoded string emitted when you press the\n    button on your YubiKey.\n\n    Will only return on succesfull validation. All failures will result\n    in an L{pyhsm.exception.YHSM_CommandFailed}.\n\n    @param hsm: The YHSM instance\n    @param from_key: The OTP from a YubiKey (in modhex)\n    @param aead: AEAD containing the cryptographic key and permission flags\n    @param key_handle: The key handle that can decrypt the AEAD\n    @type hsm: L{pyhsm.YHSM}\n    @type from_key: string\n    @type aead: L{YHSM_GeneratedAEAD} or string\n    @type key_handle: integer or string\n\n    @returns: validation response\n    @rtype: L{YHSM_ValidationResult}\n\n    @see: L{pyhsm.validate_cmd.YHSM_Cmd_AEAD_Validate_OTP.parse_result}\n    \"\"\"\n\n    from_key = pyhsm.util.input_validate_str(from_key, 'from_key', max_len = 48)\n    nonce = aead.nonce\n    aead = pyhsm.util.input_validate_aead(aead)\n    key_handle = pyhsm.util.input_validate_key_handle(key_handle)\n\n    public_id, otp = split_id_otp(from_key)\n\n    public_id = modhex_decode(public_id)\n    otp = modhex_decode(otp)\n\n    if not nonce:\n        nonce = public_id.decode('hex')\n\n    return hsm.validate_aead_otp(nonce, otp.decode('hex'),\n        key_handle, aead)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nseparate public id from OTP given a YubiKey OTP as input.", "response": "def split_id_otp(from_key):\n    \"\"\"\n    Separate public id from OTP given a YubiKey OTP as input.\n\n    @param from_key: The OTP from a YubiKey (in modhex)\n    @type from_key: string\n\n    @returns: public_id and OTP\n    @rtype: tuple of string\n    \"\"\"\n    if len(from_key) > 32:\n        public_id, otp = from_key[:-32], from_key[-32:]\n    elif len(from_key) == 32:\n        public_id = ''\n        otp = from_key\n    else:\n        raise pyhsm.exception.YHSM_Error(\"Bad from_key length %i < 32 : %s\" \\\n                                       % (len(from_key), from_key))\n    return public_id, otp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_password(hsm, args):\n    expected_len = 32\n    name = 'HSM password'\n    if hsm.version.have_key_store_decrypt():\n        expected_len = 64\n        name = 'master key'\n\n    if args.stdin:\n        password = sys.stdin.readline()\n        while password and password[-1] == '\\n':\n            password = password[:-1]\n    else:\n        if args.debug:\n            password = raw_input('Enter %s (press enter to skip) (will be echoed) : ' % (name))\n        else:\n            password = getpass.getpass('Enter %s (press enter to skip) : ' % (name))\n\n    if len(password) <= expected_len:\n        password = password.decode('hex')\n        if not password:\n            return None\n        return password\n    else:\n        sys.stderr.write(\"ERROR: Invalid HSM password (expected max %i chars, got %i)\\n\" % \\\n                              (expected_len, len(password)))\n        return 1", "response": "Get the password of correct length for this YubiHSM version."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets OTP from YubiKey.", "response": "def get_otp(hsm, args):\n    \"\"\" Get OTP from YubiKey. \"\"\"\n    if args.no_otp:\n        return None\n    if hsm.version.have_unlock():\n        if args.stdin:\n            otp = sys.stdin.readline()\n            while otp and otp[-1] == '\\n':\n                otp = otp[:-1]\n        else:\n            otp = raw_input('Enter admin YubiKey OTP (press enter to skip) : ')\n        if len(otp) == 44:\n            # YubiHSM admin OTP's always have a public_id length of 6 bytes\n            return otp\n        if otp:\n            sys.stderr.write(\"ERROR: Invalid YubiKey OTP\\n\")\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _as_mpl_axes(self):\n        proj = self.load(gpd.GeoDataFrame(), dict())\n        return proj._as_mpl_axes()", "response": "A method that returns a list of matplotlib axes that can be used to plot the data for the specified object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall load method with centerings filtered to keys in self. filter_.", "response": "def load(self, df, centerings):\n        \"\"\"Call `load` method with `centerings` filtered to keys in `self.filter_`.\"\"\"\n        return super().load(\n            df,\n            {key: value\n             for key, value in centerings.items()\n             if key in self.filter_}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gaussian_points(loc=(0, 0), scale=(10, 10), n=100):\n\n    arr = np.random.normal(loc, scale, (n, 2))\n    return gpd.GeoSeries([shapely.geometry.Point(x, y) for (x, y) in arr])", "response": "Generates and returns n normally distributed points centered at loc with scale x and y directionality."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an array of K - Means cluster classes for an array of shapely. geometry. Point objects.", "response": "def classify_clusters(points, n=10):\n    \"\"\"\n    Return an array of K-Means cluster classes for an array of `shapely.geometry.Point` objects.\n    \"\"\"\n    arr = [[p.x, p.y] for p in points.values]\n    clf = KMeans(n_clusters=n)\n    clf.fit(arr)\n    classes = clf.predict(arr)\n    return classes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an array of approximately n shapely. geometry. Polygon objects for an array of shapely. geometry. Point objects for an array of shapely. geometry. Point objects.", "response": "def gaussian_polygons(points, n=10):\n    \"\"\"\n    Returns an array of approximately `n` `shapely.geometry.Polygon` objects for an array of `shapely.geometry.Point`\n    objects.\n    \"\"\"\n    gdf = gpd.GeoDataFrame(data={'cluster_number': classify_clusters(points, n=n)}, geometry=points)\n    polygons = []\n    for i in range(n):\n        sel_points = gdf[gdf['cluster_number'] == i].geometry\n        polygons.append(shapely.geometry.MultiPoint([(p.x, p.y) for p in sel_points]).convex_hull)\n    polygons = [p for p in polygons if\n                (not isinstance(p, shapely.geometry.Point)) and (not isinstance(p, shapely.geometry.LineString))]\n    return gpd.GeoSeries(polygons)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gaussian_multi_polygons(points, n=10):\n    polygons = gaussian_polygons(points, n*2)\n    # Randomly stitch them together.\n    polygon_pairs = [shapely.geometry.MultiPolygon(list(pair)) for pair in np.array_split(polygons.values, n)]\n    return gpd.GeoSeries(polygon_pairs)", "response": "Returns an array of approximately n shapely. geometry. MultiPolygon objects for an array of approximately n shapely. geometry. Point objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an array of n uniformally distributed shapely. geometry. Point objects. Points are coordinates distributed equivalently across the Earth s surface.", "response": "def uniform_random_global_points(n=100):\n    \"\"\"\n    Returns an array of `n` uniformally distributed `shapely.geometry.Point` objects. Points are coordinates\n    distributed equivalently across the Earth's surface.\n    \"\"\"\n    xs = np.random.uniform(-180, 180, n)\n    ys = np.random.uniform(-90, 90, n)\n    return [shapely.geometry.Point(x, y) for x, y in zip(xs, ys)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an array of n uniformally randomly distributed shapely. geometry. Point objects.", "response": "def uniform_random_global_network(loc=2000, scale=250, n=100):\n    \"\"\"\n    Returns an array of `n` uniformally randomly distributed `shapely.geometry.Point` objects.\n    \"\"\"\n    arr = (np.random.normal(loc, scale, n)).astype(int)\n    return pd.DataFrame(data={'mock_variable': arr,\n                              'from': uniform_random_global_points(n),\n                              'to': uniform_random_global_points(n)})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flatten(items):\n    for x in items:\n        if isinstance(x, Iterable):\n            yield from flatten(x)\n        else:\n            yield x", "response": "Yields items from any nested iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the current QuadTree instance into four ways through the midpoint.", "response": "def split(self):\n        \"\"\"\n        Splits the current QuadTree instance four ways through the midpoint.\n\n        Returns\n        -------\n        A list of four \"sub\" QuadTree instances, corresponding with the first, second, third, and fourth quartiles,\n        respectively.\n        \"\"\"\n        # TODO: Investigate why a small number of entries are lost every time this method is run.\n        min_x, max_x, min_y, max_y = self.bounds\n        mid_x, mid_y = (min_x + max_x) / 2, (min_y + max_y) / 2\n        q1 = (min_x, mid_x, mid_y, max_y)\n        q2 = (min_x, mid_x, min_y, mid_y)\n        q3 = (mid_x, max_x, mid_y, max_y)\n        q4 = (mid_x, max_x, min_y, mid_y)\n        return [QuadTree(self.data, bounds=q1), QuadTree(self.data, bounds=q2), QuadTree(self.data, bounds=q3),\n                QuadTree(self.data, bounds=q4)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef partition(self, nmin, nmax):\n        if self.n < nmin:\n            return [self]\n        else:\n            ret = subpartition(self, nmin, nmax)\n            return flatten(ret)", "response": "This method returns a list of sub - QuadTree objects which are the smallest possible geospatial buckets given the current splitting rules containing at least nmin and nmax."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a pointplot of the data in a geographic projection.", "response": "def pointplot(df, projection=None,\n              hue=None, categorical=False, scheme=None, k=5, cmap='Set1', vmin=None, vmax=None,\n              scale=None, limits=(0.5, 2), scale_func=None,\n              legend=False, legend_values=None, legend_labels=None, legend_kwargs=None, legend_var=None,\n              figsize=(8, 6), extent=None, ax=None, **kwargs):\n    \"\"\"\n    Geospatial scatter plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    hue : None, Series, GeoSeries, iterable, or str, optional\n        Applies a colormap to the output points.\n    categorical : boolean, optional\n        Set to ``True`` if ``hue`` references a categorical variable, and ``False`` (the default) otherwise. Ignored\n        if ``hue`` is left unspecified.\n    scheme : None or {\"quantiles\"|\"equal_interval\"|\"fisher_jenks\"}, optional\n        Controls how the colormap bin edges are determined. Ignored if ``hue`` is left unspecified.\n    k : int or None, optional\n        Ignored if ``hue`` is left unspecified. Otherwise, if ``categorical`` is False, controls how many colors to\n        use (5 is the default). If set to ``None``, a continuous colormap will be used.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n        Ignored if ``hue`` is left unspecified.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum. Ignored\n        if ``hue`` is left unspecified.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum. Ignored\n        if ``hue`` is left unspecified.\n    scale : str or iterable, optional\n        Applies scaling to the output points. Defaults to None (no scaling).\n    limits : (min, max) tuple, optional\n        The minimum and maximum scale limits. Ignored if ``scale`` is left specified.\n    scale_func : ufunc, optional\n        The function used to scale point sizes. Defaults to a linear scale. For more information see `the Gallery demo\n        <examples/usa-city-elevations.html>`_.\n    legend : boolean, optional\n        Whether or not to include a legend. Ignored if neither a ``hue`` nor a ``scale`` is specified.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_var : \"hue\" or \"scale\", optional\n        If both ``hue`` and ``scale`` are specified, which variable to use in the legend.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying `scatter plot\n        <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n\n    The ``pointplot`` is a `geospatial scatter plot <https://en.wikipedia.org/wiki/Scatter_plot>`_ representing\n    each observation in your dataset with a single point. It is simple and easily interpretable plot that is nearly\n    universally understood, making it an ideal choice for showing simple pointwise relationships between\n    observations.\n\n    The expected input is a ``GeoDataFrame`` containing geometries of the ``shapely.geometry.Point`` type. A\n    bare-bones pointplot goes thusly:\n\n    .. code-block:: python\n\n        import geoplot as gplt\n        import geoplot.crs as gcrs\n        gplt.pointplot(points)\n\n    .. image:: ../figures/pointplot/pointplot-initial.png\n\n\n    The ``hue`` parameter accepts a data column and applies a colormap to the output. The ``legend`` parameter\n    toggles a legend.\n\n    .. code-block:: python\n\n        gplt.pointplot(cities, projection=gcrs.AlbersEqualArea(), hue='ELEV_IN_FT', legend=True)\n\n    .. image:: ../figures/pointplot/pointplot-legend.png\n\n    The ``pointplot`` binning methodology is controlled using by `scheme`` parameter. The default is ``quantile``,\n    which bins observations into classes of different sizes but the same numbers of observations. ``equal_interval``\n    will creates bins that are the same size, but potentially containing different numbers of observations.\n    The more complicated ``fisher_jenks`` scheme is an intermediate between the two.\n\n    .. code-block:: python\n\n        gplt.pointplot(cities, projection=gcrs.AlbersEqualArea(), hue='ELEV_IN_FT',\n                       legend=True, scheme='equal_interval')\n\n    .. image:: ../figures/pointplot/pointplot-scheme.png\n\n    Alternatively, your data may already be `categorical\n    <http://pandas.pydata.org/pandas-docs/stable/categorical.html>`_. In that case specify ``categorical=True`` instead.\n\n    .. code-block:: python\n\n        gplt.pointplot(collisions, projection=gcrs.AlbersEqualArea(), hue='BOROUGH',\n                       legend=True, categorical=True)\n\n    .. image:: ../figures/pointplot/pointplot-categorical.png\n\n    Keyword arguments can be passed to the legend using the ``legend_kwargs`` argument. These arguments will be\n    passed to the underlying ``matplotlib.legend.Legend`` instance (`ref\n    <http://matplotlib.org/api/legend_api.html#matplotlib.legend.Legend>`_). The ``loc`` and ``bbox_to_anchor``\n    parameters are particularly useful for positioning the legend. Other additional arguments will be passed to the\n    underlying ``matplotlib`` `scatter plot <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`_.\n\n    .. code-block:: python\n\n        gplt.pointplot(collisions[collisions['BOROUGH'].notnull()], projection=gcrs.AlbersEqualArea(),\n                       hue='BOROUGH', categorical=True,\n                       legend=True, legend_kwargs={'loc': 'upper left'},\n                       edgecolor='white', linewidth=0.5)\n\n    .. image:: ../figures/pointplot/pointplot-kwargs.png\n\n    Change the number of bins by specifying an alternative ``k`` value. Adjust the `colormap\n    <http://matplotlib.org/examples/color/colormaps_reference.html>`_ using the ``cmap`` parameter. To use a\n    continuous colormap, explicitly specify ``k=None``. Note that if ``legend=True``, a ``matplotlib``\n    `colorbar legend <http://matplotlib.org/api/colorbar_api.html>`_ will be used.\n\n    .. code-block:: python\n\n        gplt.pointplot(data, projection=gcrs.AlbersEqualArea(),\n                       hue='var', k=8,\n                       edgecolor='white', linewidth=0.5,\n                       legend=True, legend_kwargs={'bbox_to_anchor': (1.25, 1.0)})\n\n    .. image:: ../figures/pointplot/pointplot-k.png\n\n    ``scale`` provides an alternative or additional visual variable.\n\n    .. code-block:: python\n\n        gplt.pointplot(collisions, projection=gcrs.AlbersEqualArea(),\n                       scale='NUMBER OF PERSONS INJURED',\n                       legend=True, legend_kwargs={'loc': 'upper left'})\n\n    .. image:: ../figures/pointplot/pointplot-scale.png\n\n    The limits can be adjusted to fit your data using the ``limits`` parameter.\n\n    .. code-block:: python\n\n        gplt.pointplot(collisions, projection=gcrs.AlbersEqualArea(),\n                       scale='NUMBER OF PERSONS INJURED', limits=(0, 10),\n                       legend=True, legend_kwargs={'loc': 'upper left'})\n\n    .. image:: ../figures/pointplot/pointplot-limits.png\n\n    The default scaling function is linear: an observations at the midpoint of two others will be exactly midway\n    between them in size. To specify an alternative scaling function, use the ``scale_func`` parameter. This should\n    be a factory function of two variables which, when given the maximum and minimum of the dataset,\n    returns a scaling function which will be applied to the rest of the data. A demo is available in\n    the `example gallery <examples/usa-city-elevations.html>`_.\n\n    .. code-block:: python\n\n        def trivial_scale(minval, maxval):\n            def scalar(val):\n                return 2\n            return scalar\n\n        gplt.pointplot(collisions, projection=gcrs.AlbersEqualArea(),\n                       scale='NUMBER OF PERSONS INJURED', scale_func=trivial_scale,\n                       legend=True, legend_kwargs={'loc': 'upper left'})\n\n    .. image:: ../figures/pointplot/pointplot-scale-func.png\n\n    ``hue`` and ``scale`` can co-exist. In case more than one visual variable is used, control which one appears in\n    the legend using ``legend_var``.\n\n    .. code-block:: python\n\n        gplt.pointplot(collisions[collisions['BOROUGH'].notnull()],\n                       projection=gcrs.AlbersEqualArea(),\n                       hue='BOROUGH', categorical=True,\n                       scale='NUMBER OF PERSONS INJURED', limits=(0, 10),\n                       legend=True, legend_kwargs={'loc': 'upper left'},\n                       legend_var='scale')\n\n    .. image:: ../figures/pointplot/pointplot-legend-var.png\n\n    \"\"\"\n    # Initialize the figure, if one hasn't been initialized already.\n    fig = _init_figure(ax, figsize)\n\n    xs = np.array([p.x for p in df.geometry])\n    ys = np.array([p.y for p in df.geometry])\n\n    if projection:\n        # Properly set up the projection.\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n\n        # Set extent.\n        if extent:\n            ax.set_extent(extent)\n        else:\n            pass  # Default extent.\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Validate hue input.\n    hue = _validate_hue(df, hue)\n\n    # Set legend variable.\n    if legend_var is None:\n        if hue is not None:\n            legend_var = \"hue\"\n        elif scale is not None:\n            legend_var = \"scale\"\n\n    # Generate the coloring information, if needed. Follows one of two schemes, categorical or continuous,\n    # based on whether or not ``k`` is specified (``hue`` must be specified for either to work).\n    if k is not None:\n        # Categorical colormap code path.\n        categorical, k, scheme = _validate_buckets(categorical, k, scheme)\n\n        if hue is not None:\n            cmap, categories, hue_values = _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax)\n            colors = [cmap.to_rgba(v) for v in hue_values]\n\n            # Add a legend, if appropriate.\n            if legend and (legend_var != \"scale\" or scale is None):\n                _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs)\n        else:\n            if 'color' not in kwargs.keys():\n                colors = ['steelblue']*len(df)\n            else:\n                colors = [kwargs['color']]*len(df)\n                kwargs.pop('color')\n    elif k is None and hue is not None:\n        # Continuous colormap code path.\n        hue_values = hue\n        cmap = _continuous_colormap(hue_values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(v) for v in hue_values]\n\n        # Add a legend, if appropriate.\n        if legend and (legend_var != \"scale\" or scale is None):\n            _paint_colorbar_legend(ax, hue_values, cmap, legend_kwargs)\n\n    # Check if the ``scale`` parameter is filled, and use it to fill a ``values`` name.\n    if scale:\n        if isinstance(scale, str):\n            scalar_values = df[scale]\n        else:\n            scalar_values = scale\n\n        # Compute a scale function.\n        dmin, dmax = np.min(scalar_values), np.max(scalar_values)\n        if not scale_func:\n            dslope = (limits[1] - limits[0]) / (dmax - dmin)\n            if np.isinf(dslope):  # Edge case: if dmax, dmin are <=10**-30 or so, will overflow and eval to infinity.\n                raise ValueError(\"The data range provided to the 'scale' variable is too small for the default \"\n                                 \"scaling function. Normalize your data or provide a custom 'scale_func'.\")\n            dscale = lambda dval: limits[0] + dslope * (dval - dmin)\n        else:\n            dscale = scale_func(dmin, dmax)\n\n        # Apply the scale function.\n        scalar_multiples = np.array([dscale(d) for d in scalar_values])\n        sizes = scalar_multiples * 20\n\n        # When a scale is applied, large points will tend to obfuscate small ones. Bringing the smaller\n        # points to the front (by plotting them last) is a necessary intermediate step, which is what this bit of\n        # code does.\n        sorted_indices = np.array(sorted(enumerate(sizes), key=lambda tup: tup[1])[::-1])[:,0].astype(int)\n        xs = np.array(xs)[sorted_indices]\n        ys = np.array(ys)[sorted_indices]\n        sizes = np.array(sizes)[sorted_indices]\n        colors = np.array(colors)[sorted_indices]\n\n        # Draw a legend, if appropriate.\n        if legend and (legend_var == \"scale\" or hue is None):\n            _paint_carto_legend(ax, scalar_values, legend_values, legend_labels, dscale, legend_kwargs)\n    else:\n        sizes = kwargs.pop('s') if 's' in kwargs.keys() else 20\n\n    # Draw.\n    if projection:\n        ax.scatter(xs, ys, transform=ccrs.PlateCarree(), c=colors, s=sizes, **kwargs)\n    else:\n        ax.scatter(xs, ys, c=colors, s=sizes, **kwargs)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a polygon for a single entry in the system.", "response": "def polyplot(df, projection=None,\n             extent=None,\n             figsize=(8, 6), ax=None,\n             edgecolor='black',\n             facecolor='None', **kwargs):\n    \"\"\"\n    Trivial polygonal plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n        Defaults to (8, 6), the ``matplotlib`` default global.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Polygon patches\n        <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n\n    The polyplot can be used to draw simple, unembellished polygons. A trivial example can be created with just a\n    geometry and, optionally, a projection.\n\n    .. code-block:: python\n\n        import geoplot as gplt\n        import geoplot.crs as gcrs\n        gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea())\n\n\n    .. image:: ../figures/polyplot/polyplot-initial.png\n\n    However, note that ``polyplot`` is mainly intended to be used in concert with other plot types.\n\n    .. code-block:: python\n\n        ax = gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea())\n        gplt.pointplot(collisions[collisions['BOROUGH'].notnull()], projection=gcrs.AlbersEqualArea(),\n                       hue='BOROUGH', categorical=True,\n                       legend=True, edgecolor='white', linewidth=0.5, legend_kwargs={'loc': 'upper left'},\n                       ax=ax)\n\n\n    .. image:: ../figures/polyplot/polyplot-stacked.png\n\n    Additional keyword arguments are passed to the underlying ``matplotlib`` `Polygon patches\n    <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    .. code-block:: python\n\n        ax = gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea(),\n                           linewidth=0, facecolor='lightgray')\n\n\n    .. image:: ../figures/polyplot/polyplot-kwargs.png\n    \"\"\"\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    if projection:\n        # Properly set up the projection.\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Set extent.\n    extrema = _get_envelopes_min_maxes(df.geometry.envelope.exterior)\n    _set_extent(ax, projection, extent, extrema)\n\n    # Finally we draw the features.\n    if projection:\n        for geom in df.geometry:\n            features = ShapelyFeature([geom], ccrs.PlateCarree())\n            ax.add_feature(features, facecolor=facecolor, edgecolor=edgecolor, **kwargs)\n    else:\n        for geom in df.geometry:\n            try:  # Duck test for MultiPolygon.\n                for subgeom in geom:\n                    feature = descartes.PolygonPatch(subgeom, facecolor=facecolor, edgecolor=edgecolor, **kwargs)\n                    ax.add_patch(feature)\n            except (TypeError, AssertionError):  # Shapely Polygon.\n                feature = descartes.PolygonPatch(geom, facecolor=facecolor, edgecolor=edgecolor, **kwargs)\n                ax.add_patch(feature)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a choropleth plot for a given geographic projection.", "response": "def choropleth(df, projection=None,\n               hue=None,\n               scheme=None, k=5, cmap='Set1', categorical=False, vmin=None, vmax=None,\n               legend=False, legend_kwargs=None, legend_labels=None,\n               extent=None,\n               figsize=(8, 6), ax=None,\n               **kwargs):\n    \"\"\"\n    Area aggregation plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    hue : None, Series, GeoSeries, iterable, or str, optional\n        Applies a colormap to the output points.\n    categorical : boolean, optional\n        Set to ``True`` if ``hue`` references a categorical variable, and ``False`` (the default) otherwise. Ignored\n        if ``hue`` is left unspecified.\n    scheme : None or {\"quantiles\"|\"equal_interval\"|\"fisher_Jenks\"}, optional\n        Controls how the colormap bin edges are determined. Ignored if ``hue`` is left unspecified.\n    k : int or None, optional\n        Ignored if ``hue`` is left unspecified. Otherwise, if ``categorical`` is False, controls how many colors to\n        use (5 is the default). If set to ``None``, a continuous colormap will be used.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n        Ignored if ``hue`` is left unspecified.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum. Ignored\n        if ``hue`` is left unspecified.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum. Ignored\n        if ``hue`` is left unspecified.\n    legend : boolean, optional\n        Whether or not to include a legend. Ignored if neither a ``hue`` nor a ``scale`` is specified.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Polygon patches\n        <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n\n    A choropleth takes observations that have been aggregated on some meaningful polygonal level (e.g. census tract,\n    state, country, or continent) and displays the data to the reader using color. It is a well-known plot type,\n    and likeliest the most general-purpose and well-known of the specifically spatial plot types. It is especially\n    powerful when combined with meaningful or actionable aggregation areas; if no such aggregations exist,\n    or the aggregations you have access to are mostly incidental, its value is more limited.\n\n    The ``choropleth`` requires a series of enclosed areas consisting of ``shapely`` ``Polygon`` or ``MultiPolygon``\n    entities, and a set of data about them that you would like to express in color. A basic choropleth requires\n    geometry, a ``hue`` variable, and, optionally, a projection.\n\n    .. code-block:: python\n\n        import geoplot as gplt\n        import geoplot.crs as gcrs\n        gplt.choropleth(polydata, hue='latdep', projection=gcrs.PlateCarree())\n\n    .. image:: ../figures/choropleth/choropleth-initial.png\n\n    Change the colormap with the ``cmap`` parameter.\n\n    .. code-block:: python\n\n        gplt.choropleth(polydata, hue='latdep', projection=gcrs.PlateCarree(), cmap='Blues')\n\n    .. image:: ../figures/choropleth/choropleth-cmap.png\n\n    If your variable of interest is already `categorical\n    <http://pandas.pydata.org/pandas-docs/stable/categorical.html>`_, you can specify ``categorical=True`` to\n    use the labels in your dataset directly. To add a legend, specify ``legend``.\n\n    .. code-block:: python\n\n        gplt.choropleth(boroughs, projection=gcrs.AlbersEqualArea(), hue='BoroName',\n                        categorical=True, legend=True)\n\n    .. image:: ../figures/choropleth/choropleth-legend.png\n\n    Keyword arguments can be passed to the legend using the ``legend_kwargs`` argument. These arguments will be\n    passed to the underlying ``matplotlib.legend.Legend`` instance (`ref\n    <http://matplotlib.org/api/legend_api.html#matplotlib.legend.Legend>`_). The ``loc`` and ``bbox_to_anchor``\n    parameters are particularly useful for positioning the legend. Other additional arguments will be passed to the\n    underlying ``matplotlib`` `scatter plot <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`_.\n\n    .. code-block:: python\n\n        gplt.choropleth(boroughs, projection=gcrs.AlbersEqualArea(), hue='BoroName',\n                        categorical=True, legend=True, legend_kwargs={'loc': 'upper left'})\n\n    .. image:: ../figures/choropleth/choropleth-legend-kwargs.png\n\n    Additional arguments not in the method signature will be passed as keyword parameters to the underlying\n    `matplotlib Polygon patches <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    .. code-block:: python\n\n        gplt.choropleth(boroughs, projection=gcrs.AlbersEqualArea(), hue='BoroName', categorical=True,\n                        linewidth=0)\n\n    .. image:: ../figures/choropleth/choropleth-kwargs.png\n\n    Choropleths default to splitting the data into five buckets with approximately equal numbers of observations in\n    them. Change the number of buckets by specifying ``k``. Or, to use a continuous colormap, specify ``k=None``. In\n    this case a colorbar legend will be used.\n\n    .. code-block:: python\n\n        gplt.choropleth(polydata, hue='latdep', cmap='Blues', k=None, legend=True,\n                        projection=gcrs.PlateCarree())\n\n    .. image:: ../figures/choropleth/choropleth-k-none.png\n\n    The ``choropleth`` binning methodology is controlled using by `scheme`` parameter. The default is ``quantile``,\n    which bins observations into classes of different sizes but the same numbers of observations. ``equal_interval``\n    will creates bins that are the same size, but potentially containing different numbers of observations.\n    The more complicated ``fisher_jenks`` scheme is an intermediate between the two.\n\n    .. code-block:: python\n\n        gplt.choropleth(census_tracts, hue='mock_data', projection=gcrs.AlbersEqualArea(),\n                legend=True, edgecolor='white', linewidth=0.5, legend_kwargs={'loc': 'upper left'},\n                scheme='equal_interval')\n\n    .. image:: ../figures/choropleth/choropleth-scheme.png\n    \"\"\"\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    if projection:\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Set extent.\n    extrema = _get_envelopes_min_maxes(df.geometry.envelope.exterior)\n    _set_extent(ax, projection, extent, extrema)\n\n    # Format the data to be displayed for input.\n    hue = _validate_hue(df, hue)\n    if hue is None:\n        raise ValueError(\"No 'hue' specified.\")\n\n    # Generate the coloring information, if needed. Follows one of two schemes, categorical or continuous,\n    # based on whether or not ``k`` is specified (``hue`` must be specified for either to work).\n    if k is not None:\n        # Categorical colormap code path.\n\n        # Validate buckets.\n        categorical, k, scheme = _validate_buckets(categorical, k, scheme)\n\n        if hue is not None:\n            cmap, categories, hue_values = _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax)\n            colors = [cmap.to_rgba(v) for v in hue_values]\n\n            # Add a legend, if appropriate.\n            if legend:\n                _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs)\n        else:\n            colors = ['steelblue']*len(df)\n    elif k is None and hue is not None:\n        # Continuous colormap code path.\n        hue_values = hue\n        cmap = _continuous_colormap(hue_values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(v) for v in hue_values]\n\n        # Add a legend, if appropriate.\n        if legend:\n            _paint_colorbar_legend(ax, hue_values, cmap, legend_kwargs)\n\n    # Draw the features.\n    if projection:\n        for color, geom in zip(colors, df.geometry):\n            features = ShapelyFeature([geom], ccrs.PlateCarree())\n            ax.add_feature(features, facecolor=color, **kwargs)\n    else:\n        for color, geom in zip(colors, df.geometry):\n            try:  # Duck test for MultiPolygon.\n                for subgeom in geom:\n                    feature = descartes.PolygonPatch(subgeom, facecolor=color, **kwargs)\n                    ax.add_patch(feature)\n            except (TypeError, AssertionError):  # Shapely Polygon.\n                feature = descartes.PolygonPatch(geom, facecolor=color, **kwargs)\n                ax.add_patch(feature)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef aggplot(df, projection=None,\n            hue=None,\n            by=None,\n            geometry=None,\n            nmax=None, nmin=None, nsig=0,\n            agg=np.mean,\n            cmap='viridis', vmin=None, vmax=None,\n            legend=True, legend_kwargs=None,\n            extent=None,\n            figsize=(8, 6), ax=None,\n            **kwargs):\n    \"\"\"\n    Self-aggregating quadtree plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    hue : None, Series, GeoSeries, iterable, or str\n        Applies a colormap to the output shapes. Required.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n    by : iterable or str, optional\n        If specified, this data grouping will be used to aggregate points into `convex hulls\n        <https://en.wikipedia.org/wiki/Convex_hull>`_ or, if ``geometry`` is also specified, into polygons. If left\n        unspecified the data will be aggregated using a `quadtree <https://en.wikipedia.org/wiki/Quadtree>`_.\n    geometry : GeoDataFrame or GeoSeries, optional\n        A list of polygons to be used for spatial aggregation. Optional. See ``by``.\n    nmax : int or None, optional\n        Ignored if not plotting a quadtree. Otherwise, controls the maximum number of observations in a quadrangle.\n        If left unspecified, there is no maximum size.\n    nmin : int, optional\n        Ignored if not plotting a quadtree. Otherwise, controls the minimum number of observations in a quadrangle.\n        If left unspecified, there is no minimum size.\n    nsig : int, optional\n        Ignored if not plotting a quadtree. Otherwise, controls the minimum number of observations in a quadrangle\n        deemed significant. Insignificant quadrangles are removed from the plot. Defaults to 0 (empty patches).\n    agg : function, optional\n        The aggregation func used for the colormap. Defaults to ``np.mean``.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum.\n    legend : boolean, optional\n        Whether or not to include a legend.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Polygon patches\n        <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n    This plot type accepts any geometry, including mixtures of polygons and points, averages the value of a certain\n    data parameter at their centroids, and plots the result, using a colormap is the visual variable.\n\n    For the purposes of comparison, this library's ``choropleth`` function takes some sort of data as input,\n    polygons as geospatial context, and combines themselves into a colorful map. This is useful if, for example,\n    you have data on the amount of crimes committed per neighborhood, and you want to plot that.\n\n    But suppose your original dataset came in terms of individual observations - instead of \"n collisions happened\n    in this neighborhood\", you have \"one collision occured at this specific coordinate at this specific date\".\n    This is obviously more useful data - it can be made to do more things - but in order to generate the same map,\n    you will first have to do all of the work of geolocating your points to neighborhoods (not trivial),\n    then aggregating them (by, in this case, taking a count).\n\n    ``aggplot`` handles this work for you. It takes input in the form of observations, and outputs as useful as\n    possible a visualization of their \"regional\" statistics. What a \"region\" corresponds to depends on how much\n    geospatial information you can provide.\n\n    If you can't provide *any* geospatial context, ``aggplot`` will output what's known as a quadtree: it will break\n    your data down into recursive squares, and use them to aggregate the data. This is a very experimental format,\n    is very fiddly to make, and has not yet been optimized for speed; but it provides a useful baseline which\n    requires no additional work and can be used to expose interesting geospatial correlations right away. And,\n    if you have enough observations, it can be `a pretty good approximation\n    <../figures/aggplot/aggplot-initial.png>`_ (collisions in New York City pictured).\n\n    Our first few examples are of just such figures. A simple ``aggplot`` quadtree can be generated with just a\n    dataset, a data column of interest, and, optionally, a projection.\n\n    .. code-block:: python\n\n        import geoplot as gplt\n        import geoplot.crs as gcrs\n        gplt.aggplot(collisions, projection=gcrs.PlateCarree(), hue='LATDEP')\n\n    .. image:: ../figures/aggplot/aggplot-initial.png\n\n    To get the best output, you often need to tweak the ``nmin`` and ``nmax`` parameters, controlling the minimum and\n    maximum number of observations per box, respectively, yourself. In this case we'll also choose a different\n    `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_, using the ``cmap``\n    parameter.\n\n    ``aggplot`` will satisfy the ``nmax`` parameter before trying to satisfy ``nmin``, so you may result in spaces\n    without observations, or ones lacking a statistically significant number of observations. This is necessary in\n    order to break up \"spaces\" that the algorithm would otherwise end on. You can control the maximum number of\n    observations in the blank spaces using the ``nsig`` parameter.\n\n    .. code-block:: python\n\n        gplt.aggplot(collisions, nmin=20, nmax=500, nsig=5, projection=gcrs.PlateCarree(), hue='LATDEP', cmap='Reds')\n\n    .. image:: ../figures/aggplot/aggplot-quadtree-tuned.png\n\n    You'll have to play around with these parameters to get the clearest picture.\n\n    Usually, however, observations with a geospatial component will be provided with some form of spatial\n    categorization. In the case of our collisions example, this comes in the form of a postal zip code. With the\n    simple addition of this data column via the ``by`` parameter, our output changes radically, taking advantage of\n    the additional context we now have to sort and aggregate our observations by (hopefully) geospatially\n    meaningful, if still crude, grouped convex hulls.\n\n    .. code-block:: python\n\n\n        gplt.aggplot(collisions, projection=gcrs.PlateCarree(), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                     by='BOROUGH')\n\n    .. image:: ../figures/aggplot/aggplot-hulls.png\n\n    Finally, suppose you actually know exactly the geometries that you would like to aggregate by. Provide these in\n    the form of a ``geopandas`` ``GeoSeries``, one whose index matches the values in your ``by`` column (so\n    ``BROOKLYN`` matches ``BROOKLYN`` for example), to the ``geometry`` parameter. Your output will now be an\n    ordinary choropleth.\n\n    .. code-block:: python\n\n        gplt.aggplot(collisions, projection=gcrs.PlateCarree(), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                     by='BOROUGH', geometry=boroughs)\n\n    .. image:: ../figures/aggplot/aggplot-by.png\n\n    Observations will be aggregated by average, by default. In our example case, our plot shows that accidents in\n    Manhattan tend to result in significantly fewer injuries than accidents occuring in other boroughs. Specify an\n    alternative aggregation using the ``agg`` parameter.\n\n    .. code-block:: python\n\n        gplt.aggplot(collisions, projection=gcrs.PlateCarree(), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                 geometry=boroughs_2, by='BOROUGH', agg=len)\n\n    .. image:: ../figures/aggplot/aggplot-agg.png\n\n    ``legend`` toggles the legend. Additional keyword arguments for styling the `colorbar\n    <http://matplotlib.org/api/colorbar_api.html>`_ legend are passed using ``legend_kwargs``. Other additional keyword\n    arguments are passed to the underlying ``matplotlib`` `Polygon\n    <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_ instances.\n\n    .. code-block:: python\n\n        gplt.aggplot(collisions, projection=gcrs.PlateCarree(), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                     geometry=boroughs_2, by='BOROUGH', agg=len, linewidth=0,\n                     legend_kwargs={'orientation': 'horizontal'})\n\n    .. image:: ../figures/aggplot/aggplot-legend-kwargs.png\n    \"\"\"\n    fig = _init_figure(ax, figsize)\n\n    # Set up projection.\n    if projection:\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Up-convert input to a GeoDataFrame (necessary for quadtree comprehension).\n    df = gpd.GeoDataFrame(df, geometry=df.geometry)\n\n    # Validate hue.\n    if not isinstance(hue, str):\n        hue_col = hash(str(hue))\n        df[hue_col] = _validate_hue(df, hue)\n    else:\n        hue_col = hue\n\n    if geometry is not None and by is None:\n        raise NotImplementedError(\"Aggregation by geometry alone is not currently implemented and unlikely to be \"\n                                  \"implemented in the future - it is likely out-of-scope here due to the algorithmic \"\n                                  \"complexity involved.\")\n        # The user wants us to classify our data geometries by their location within the passed world geometries\n        # (\"sectors\"), aggregate a statistic based on that, and return a plot. Unfortunately this seems to be too\n        # hard for the moment. Two reasons:\n        # 1. The Shapely API for doing so is just about as consistent as can be, but still a little bit inconsistent.\n        #    In particular, it is not obvious what to do with invalid and self-intersecting geometric components passed\n        #    to the algorithm.\n        # 2. Point-in-polygon and, worse, polygon-in-polygon algorithms are extremely slow, to the point that almost\n        #    any optimizations that the user can make by doing classification \"by hand\" is worth it.\n        # There should perhaps be a separate library or ``geopandas`` function for doing this.\n\n    elif by is not None:\n\n        # Side-convert geometry for ease of use.\n        if geometry is not None:\n            # Downconvert GeoDataFrame to GeoSeries objects.\n            if isinstance(geometry, gpd.GeoDataFrame):\n                geometry = geometry.geometry\n\n        sectors = []\n        values = []\n\n        # The groupby operation does not take generators as inputs, so we duck test and convert them to lists.\n        if not isinstance(by, str):\n            try: len(by)\n            except TypeError: by = list(by)\n\n        for label, p in df.groupby(by):\n            if geometry is not None:\n                try:\n                    sector = geometry.loc[label]\n                except KeyError:\n                    raise KeyError(\"Data contains a '{0}' label which lacks a corresponding value in the provided \"\n                                   \"geometry.\".format(label))\n            else:\n                xs = [c.x for c in p.geometry]\n                ys = [c.y for c in p.geometry]\n                coords = list(zip(xs, ys))\n                sector = shapely.geometry.MultiPoint(coords).convex_hull\n\n            sectors.append(sector)\n            values.append(agg(p[hue_col]))\n\n        # Because we have to set the extent ourselves, we have to do some bookkeeping to keep track of the\n        # extrema of the hulls we are generating.\n        bxmin = bxmax = bymin = bymax = None\n        if not extent:\n            for sector in sectors:\n                if not isinstance(sector.envelope, shapely.geometry.Point):\n                    hxmin, hxmax, hymin, hymax = _get_envelopes_min_maxes(pd.Series(sector.envelope.exterior))\n                    if not bxmin or hxmin < bxmin:\n                        bxmin = hxmin\n                    if not bxmax or hxmax > bxmax:\n                        bxmax = hxmax\n                    if not bymin or hymin < bymin:\n                        bymin = hymin\n                    if not bymax or hymax > bymax:\n                        bymax = hymax\n\n        # By often creates overlapping polygons, to keep smaller polygons from being hidden by possibly overlapping\n        # larger ones we have to bring the smaller ones in front in the plotting order. This bit of code does that.\n        sorted_indices = np.array(sorted(enumerate(gpd.GeoSeries(sectors).area.values),\n                                         key=lambda tup: tup[1])[::-1])[:, 0].astype(int)\n        sectors = np.array(sectors)[sorted_indices]\n        values = np.array(values)[sorted_indices]\n\n        # Generate a colormap.\n        cmap = _continuous_colormap(values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(value) for value in values]\n\n        #  Draw.\n        for sector, color in zip(sectors, colors):\n            if projection:\n                features = ShapelyFeature([sector], ccrs.PlateCarree())\n                ax.add_feature(features, facecolor=color, **kwargs)\n            else:\n                try:  # Duck test for MultiPolygon.\n                    for subgeom in sector:\n                        feature = descartes.PolygonPatch(subgeom, facecolor=color, **kwargs)\n                        ax.add_patch(feature)\n                except (TypeError, AssertionError):  # Shapely Polygon.\n                    feature = descartes.PolygonPatch(sector, facecolor=color, **kwargs)\n                    ax.add_patch(feature)\n\n        # Set extent.\n        extrema = (bxmin, bxmax, bymin, bymax)\n        _set_extent(ax, projection, extent, extrema)\n\n    else:\n        # Set reasonable defaults for the n-params if appropriate.\n        nmax = nmax if nmax else len(df)\n        nmin = nmin if nmin else np.max([1, np.min([20, int(0.05 * len(df))])])\n\n        # Generate a quadtree.\n        quad = QuadTree(df)\n        bxmin, bxmax, bymin, bymax = quad.bounds\n\n        # Assert that nmin is not smaller than the largest number of co-located observations (otherwise the algorithm\n        # would continue running until the recursion limit).\n        max_coloc = np.max([len(l) for l in quad.agg.values()])\n        if max_coloc > nmin:\n            raise ValueError(\"nmin is set to {0}, but there is a coordinate containing {1} observations in the \"\n                             \"dataset.\".format(nmin, max_coloc))\n\n        # Run the partitions.\n        # partitions = quad.partition(nmin, nmax)\n        partitions = list(quad.partition(nmin, nmax))\n\n        # Generate colormap.\n        values = [agg(p.data[hue_col]) for p in partitions if p.n > nsig]\n        cmap = _continuous_colormap(values, cmap, vmin, vmax)\n\n        for p in partitions:\n            xmin, xmax, ymin, ymax = p.bounds\n            rect = shapely.geometry.Polygon([(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin)])\n            color = cmap.to_rgba(agg(p.data[hue_col])) if p.n > nsig else \"white\"\n            if projection:\n                feature = ShapelyFeature([rect], ccrs.PlateCarree())\n                ax.add_feature(feature, facecolor=color, **kwargs)\n            else:\n                feature = descartes.PolygonPatch(rect, facecolor=color, **kwargs)\n                ax.add_patch(feature)\n\n        # Set extent.\n        extrema = (bxmin, bxmax, bymin, bymax)\n        _set_extent(ax, projection, extent, extrema)\n\n    # Append a legend, if appropriate.\n    if legend:\n        _paint_colorbar_legend(ax, values, cmap, legend_kwargs)\n\n    return ax", "response": "This function will plot a single or multi - dimensional quadtree plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cartogram(df, projection=None,\n              scale=None, limits=(0.2, 1), scale_func=None, trace=True, trace_kwargs=None,\n              hue=None, categorical=False, scheme=None, k=5, cmap='viridis', vmin=None, vmax=None,\n              legend=False, legend_values=None, legend_labels=None, legend_kwargs=None, legend_var=\"scale\",\n              extent=None,\n              figsize=(8, 6), ax=None,\n              **kwargs):\n    \"\"\"\n    Self-scaling area plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    scale : str or iterable, optional\n        Applies scaling to the output points. Defaults to None (no scaling).\n    limits : (min, max) tuple, optional\n        The minimum and maximum scale limits. Ignored if ``scale`` is left specified.\n    scale_func : ufunc, optional\n        The function used to scale point sizes. Defaults to a linear scale. For more information see `the Gallery demo\n        <examples/usa-city-elevations.html>`_.\n    trace : boolean, optional\n        Whether or not to include a trace of the polygon's original outline in the plot result.\n    trace_kwargs : dict, optional\n        If ``trace`` is set to ``True``, this parameter can be used to adjust the properties of the trace outline. This\n        parameter is ignored if trace is ``False``.\n    hue : None, Series, GeoSeries, iterable, or str, optional\n        Applies a colormap to the output points.\n    categorical : boolean, optional\n        Set to ``True`` if ``hue`` references a categorical variable, and ``False`` (the default) otherwise. Ignored\n        if ``hue`` is left unspecified.\n    scheme : None or {\"quantiles\"|\"equal_interval\"|\"fisher_Jenks\"}, optional\n        Controls how the colormap bin edges are determined. Ignored if ``hue`` is left unspecified.\n    k : int or None, optional\n        Ignored if ``hue`` is left unspecified. Otherwise, if ``categorical`` is False, controls how many colors to\n        use (5 is the default). If set to ``None``, a continuous colormap will be used.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n        Ignored if ``hue`` is left unspecified.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum. Ignored\n        if ``hue`` is left unspecified.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum. Ignored\n        if ``hue`` is left unspecified.\n    legend : boolean, optional\n        Whether or not to include a legend. Ignored if neither a ``hue`` nor a ``scale`` is specified.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Polygon patches\n        <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n    A cartogram is a plot type which ingests a series of enclosed ``Polygon`` or ``MultiPolygon`` entities and spits\n    out a view of these shapes in which area is distorted according to the size of some parameter of interest.\n\n    A basic cartogram specifies data, a projection, and a ``scale`` parameter.\n\n    .. code-block:: python\n\n        import geoplot as gplt\n        import geoplot.crs as gcrs\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea())\n\n    .. image:: ../figures/cartogram/cartogram-initial.png\n\n    The gray outline can be turned off by specifying ``trace``, and a legend can be added by specifying ``legend``.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       trace=False, legend=True)\n\n    .. image:: ../figures/cartogram/cartogram-trace-legend.png\n\n    Keyword arguments can be passed to the legend using the ``legend_kwargs`` argument. These arguments will be\n    passed to the underlying ``matplotlib.legend.Legend`` instance (`ref\n    <http://matplotlib.org/api/legend_api.html#matplotlib.legend.Legend>`_). The ``loc`` and ``bbox_to_anchor``\n    parameters are particularly useful for positioning the legend. Other additional arguments will be passed to the\n    underlying ``matplotlib`` `scatter plot <http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter>`_.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       trace=False, legend=True, legend_kwargs={'loc': 'upper left'})\n\n    .. image:: ../figures/cartogram/cartogram-legend-kwargs.png\n\n    Additional arguments to ``cartogram`` will be interpreted as keyword arguments for the scaled polygons,\n    using `matplotlib Polygon patch\n    <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_ rules.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       edgecolor='darkgreen')\n\n    .. image:: ../figures/cartogram/cartogram-kwargs.png\n\n    Manipulate the outlines use the ``trace_kwargs`` argument, which accepts the same `matplotlib Polygon patch\n    <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_ parameters.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       trace_kwargs={'edgecolor': 'lightgreen'})\n\n    .. image:: ../figures/cartogram/cartogram-trace-kwargs.png\n\n    Adjust the level of scaling to apply using the ``limits`` parameter.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       limits=(0.5, 1))\n\n    .. image:: ../figures/cartogram/cartogram-limits.png\n\n    The default scaling function is linear: an observations at the midpoint of two others will be exactly midway\n    between them in size. To specify an alternative scaling function, use the ``scale_func`` parameter. This should\n    be a factory function of two variables which, when given the maximum and minimum of the dataset,\n    returns a scaling function which will be applied to the rest of the data. A demo is available in\n    the `example gallery <examples/usa-city-elevations.html>`_.\n\n    .. code-block:: python\n\n        def trivial_scale(minval, maxval): return lambda v: 2\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       limits=(0.5, 1), scale_func=trivial_scale)\n\n    .. image:: ../figures/cartogram/cartogram-scale-func.png\n\n    ``cartogram`` also provides the same ``hue`` visual variable parameters provided by e.g. ``pointplot``. For more\n    information on ``hue``-related arguments, see the related sections in the ``pointplot`` `documentation\n    <./pointplot.html>`_.\n\n    .. code-block:: python\n\n        gplt.cartogram(boroughs, scale='Population Density', projection=gcrs.AlbersEqualArea(),\n                       hue='Population Density', k=None, cmap='Blues')\n\n    .. image:: ../figures/cartogram/cartogram-hue.png\n    \"\"\"\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    # Load the projection.\n    if projection:\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n\n        # Clean up patches.\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Set extent.\n    extrema = _get_envelopes_min_maxes(df.geometry.envelope.exterior)\n    _set_extent(ax, projection, extent, extrema)\n\n    # Check that the ``scale`` parameter is filled, and use it to fill a ``values`` name.\n    if not scale:\n        raise ValueError(\"No scale parameter provided.\")\n    elif isinstance(scale, str):\n        values = df[scale]\n    else:\n        values = scale\n\n    # Compute a scale function.\n    dmin, dmax = np.min(values), np.max(values)\n    if not scale_func:\n        dslope = (limits[1] - limits[0]) / (dmax - dmin)\n        dscale = lambda dval: limits[0] + dslope * (dval - dmin)\n    else:\n        dscale = scale_func(dmin, dmax)\n\n    # Create a legend, if appropriate.\n    if legend:\n        _paint_carto_legend(ax, values, legend_values, legend_labels, dscale, legend_kwargs)\n\n    # Validate hue input.\n    hue = _validate_hue(df, hue)\n\n    # Generate the coloring information, if needed. Follows one of two schemes, categorical or continuous,\n    # based on whether or not ``k`` is specified (``hue`` must be specified for either to work).\n    if k is not None and hue is not None:\n        # Categorical colormap code path.\n        categorical, k, scheme = _validate_buckets(categorical, k, scheme)\n\n        if hue is not None:\n            cmap, categories, hue_values = _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax)\n            colors = [cmap.to_rgba(v) for v in hue_values]\n\n            # Add a legend, if appropriate.\n            if legend and (legend_var != \"scale\" or scale is None):\n                _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs)\n        else:\n            colors = ['None']*len(df)\n    elif k is None and hue is not None:\n        # Continuous colormap code path.\n        hue_values = hue\n        cmap = _continuous_colormap(hue_values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(v) for v in hue_values]\n\n        # Add a legend, if appropriate.\n        if legend and (legend_var != \"scale\" or scale is None):\n            _paint_colorbar_legend(ax, hue_values, cmap, legend_kwargs)\n    elif 'facecolor' in kwargs:\n        colors = [kwargs.pop('facecolor')]*len(df)\n    else:\n        colors = ['None']*len(df)\n\n    # Manipulate trace_kwargs.\n    if trace:\n        if trace_kwargs is None:\n            trace_kwargs = dict()\n        if 'edgecolor' not in trace_kwargs.keys():\n            trace_kwargs['edgecolor'] = 'lightgray'\n        if 'facecolor' not in trace_kwargs.keys():\n            trace_kwargs['facecolor'] = 'None'\n\n    # Draw traces first, if appropriate.\n    if trace:\n        if projection:\n            for polygon in df.geometry:\n                features = ShapelyFeature([polygon], ccrs.PlateCarree())\n                ax.add_feature(features, **trace_kwargs)\n        else:\n            for polygon in df.geometry:\n                try:  # Duck test for MultiPolygon.\n                    for subgeom in polygon:\n                        feature = descartes.PolygonPatch(subgeom, **trace_kwargs)\n                        ax.add_patch(feature)\n                except (TypeError, AssertionError):  # Shapely Polygon.\n                    feature = descartes.PolygonPatch(polygon, **trace_kwargs)\n                    ax.add_patch(feature)\n\n    # Finally, draw the scaled geometries.\n    for value, color, polygon in zip(values, colors, df.geometry):\n        scale_factor = dscale(value)\n        scaled_polygon = shapely.affinity.scale(polygon, xfact=scale_factor, yfact=scale_factor)\n        if projection:\n            features = ShapelyFeature([scaled_polygon], ccrs.PlateCarree())\n            ax.add_feature(features, facecolor=color, **kwargs)\n        else:\n            try:  # Duck test for MultiPolygon.\n                for subgeom in scaled_polygon:\n                    feature = descartes.PolygonPatch(subgeom, facecolor=color, **kwargs)\n                    ax.add_patch(feature)\n            except (TypeError, AssertionError):  # Shapely Polygon.\n                feature = descartes.PolygonPatch(scaled_polygon, facecolor=color, **kwargs)\n                ax.add_patch(feature)\n\n    return ax", "response": "This function plots a cartogram of the data in a single site."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a KDE - based kernel density estimate of the data in the specified location.", "response": "def kdeplot(df, projection=None,\n            extent=None,\n            figsize=(8, 6), ax=None,\n            clip=None,\n            **kwargs):\n    \"\"\"\n    Spatial kernel density estimate plot.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    clip : None or iterable or GeoSeries, optional\n        If specified, the ``kdeplot`` output will be clipped to the boundaries of this geometry.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``seaborn`` `kernel density estimate plot\n        <https://seaborn.pydata.org/generated/seaborn.kdeplot.html>`_.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n    `Kernel density estimate <https://en.wikipedia.org/wiki/Kernel_density_estimation>`_ is a flexible unsupervised\n    machine learning technique for non-parametrically estimating the distribution underlying input data. The KDE is a\n    great way of smoothing out random noise and estimating the  true shape of point data distributed in your space,\n    but it needs a moderately large number of observations to be reliable.\n\n    The ``geoplot`` ``kdeplot``, actually a thin wrapper on top of the ``seaborn`` ``kdeplot``, is an application of\n    this visualization technique to the geospatial setting.\n\n    A basic ``kdeplot`` specifies (pointwise) data and, optionally, a projection. To make the result more\n    interpretable, I also overlay the underlying borough geometry.\n\n    .. code-block:: python\n\n        ax = gplt.kdeplot(collisions, projection=gcrs.AlbersEqualArea())\n        gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea(), ax=ax)\n\n    .. image:: ../figures/kdeplot/kdeplot-overlay.png\n\n    Most of the rest of the parameters to ``kdeplot`` are parameters inherited from `the seaborn method by the same\n    name <http://seaborn.pydata.org/generated/seaborn.kdeplot.html#seaborn.kdeplot>`_, on which this plot type is\n    based. For example, specifying ``shade=True`` provides a filled KDE instead of a contour one:\n\n    .. code-block:: python\n\n        ax = gplt.kdeplot(collisions, projection=gcrs.AlbersEqualArea(),\n                          shade=True)\n        gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea(), ax=ax)\n\n    .. image:: ../figures/kdeplot/kdeplot-shade.png\n\n    Use ``n_levels`` to specify the number of contour levels.\n\n    .. code-block:: python\n\n        ax = gplt.kdeplot(collisions, projection=gcrs.AlbersEqualArea(),\n                          n_levels=30)\n        gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea(), ax=ax)\n\n    .. image:: ../figures/kdeplot/kdeplot-n-levels.png\n\n    Or specify ``cmap`` to change the colormap.\n\n    .. code-block:: python\n\n        ax = gplt.kdeplot(collisions, projection=gcrs.AlbersEqualArea(),\n             cmap='Purples')\n        gplt.polyplot(boroughs, projection=gcrs.AlbersEqualArea(), ax=ax)\n\n    .. image:: ../figures/kdeplot/kdeplot-cmap.png\n\n    Oftentimes given the geometry of the location, a \"regular\" continuous KDEPlot doesn't make sense. We can specify a\n    ``clip`` of iterable geometries, which will be used to trim the ``kdeplot``. Note that if you have set\n    ``shade=True`` as a parameter you may need to additionally specify ``shade_lowest=False`` to avoid inversion at\n    the edges of the plot.\n\n    .. code-block:: python\n\n        gplt.kdeplot(collisions, projection=gcrs.AlbersEqualArea(),\n                     shade=True, clip=boroughs)\n\n    .. image:: ../figures/kdeplot/kdeplot-clip.png\n\n    \"\"\"\n    import seaborn as sns  # Immediately fail if no seaborn.\n\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    # Necessary prior.\n    xs = np.array([p.x for p in df.geometry])\n    ys = np.array([p.y for p in df.geometry])\n\n    # Load the projection.\n    if projection:\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(xs),\n            'central_latitude': lambda df: np.mean(ys)\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Set extent.\n    extrema = np.min(xs), np.max(xs), np.min(ys), np.max(ys)\n    _set_extent(ax, projection, extent, extrema)\n\n    if projection:\n        if clip is None:\n            sns.kdeplot(pd.Series([p.x for p in df.geometry]), pd.Series([p.y for p in df.geometry]),\n                        transform=ccrs.PlateCarree(), ax=ax, **kwargs)\n        else:\n            sns.kdeplot(pd.Series([p.x for p in df.geometry]), pd.Series([p.y for p in df.geometry]),\n                        transform=ccrs.PlateCarree(), ax=ax, **kwargs)\n            clip_geom = _get_clip(ax.get_extent(crs=ccrs.PlateCarree()), clip)\n            feature = ShapelyFeature([clip_geom], ccrs.PlateCarree())\n            ax.add_feature(feature, facecolor=(1,1,1), linewidth=0, zorder=100)\n    else:\n        if clip is None:\n            sns.kdeplot(pd.Series([p.x for p in df.geometry]), pd.Series([p.y for p in df.geometry]), ax=ax, **kwargs)\n        else:\n            clip_geom = _get_clip(ax.get_xlim() + ax.get_ylim(), clip)\n            polyplot(gpd.GeoSeries(clip_geom),\n                     facecolor='white', linewidth=0, zorder=100, extent=ax.get_xlim() + ax.get_ylim(), ax=ax)\n            sns.kdeplot(pd.Series([p.x for p in df.geometry]), pd.Series([p.y for p in df.geometry]),\n                        ax=ax, **kwargs)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a Spatial Sankey or Flow Map.", "response": "def sankey(*args, projection=None,\n           start=None, end=None, path=None,\n           hue=None, categorical=False, scheme=None, k=5, cmap='viridis', vmin=None, vmax=None,\n           legend=False, legend_kwargs=None, legend_labels=None, legend_values=None, legend_var=None,\n           extent=None, figsize=(8, 6), ax=None,\n           scale=None, limits=(1, 5), scale_func=None,\n           **kwargs):\n    \"\"\"\n    Spatial Sankey or flow map.\n\n    Parameters\n    ----------\n    df : GeoDataFrame, optional.\n        The data being plotted. This parameter is optional - it is not needed if ``start`` and ``end`` (and ``hue``,\n        if provided) are iterables.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    start : str or iterable\n        A list of starting points. This parameter is required.\n    end : str or iterable\n        A list of ending points. This parameter is required.\n    path : geoplot.crs object instance or iterable, optional\n        Pass an iterable of paths to draw custom paths (see `this example\n        <https://residentmario.github.io/geoplot/examples/dc-street-network.html>`_), or a projection to draw\n        the shortest paths in that given projection. The default is ``Geodetic()``, which will connect points using\n        `great circle distance <https://en.wikipedia.org/wiki/Great-circle_distance>`_\u2014the true shortest\n        path on the surface of the Earth.\n    hue : None, Series, GeoSeries, iterable, or str, optional\n        Applies a colormap to the output points.\n    categorical : boolean, optional\n        Set to ``True`` if ``hue`` references a categorical variable, and ``False`` (the default) otherwise. Ignored\n        if ``hue`` is left unspecified.\n    scheme : None or {\"quantiles\"|\"equal_interval\"|\"fisher_jenks\"}, optional\n        Controls how the colormap bin edges are determined. Ignored if ``hue`` is left unspecified.\n    k : int or None, optional\n        Ignored if ``hue`` is left unspecified. Otherwise, if ``categorical`` is False, controls how many colors to\n        use (5 is the default). If set to ``None``, a continuous colormap will be used.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n        Ignored if ``hue`` is left unspecified.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum. Ignored\n        if ``hue`` is left unspecified.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum. Ignored\n        if ``hue`` is left unspecified.\n    scale : str or iterable, optional\n        Applies scaling to the output points. Defaults to None (no scaling).\n    limits : (min, max) tuple, optional\n        The minimum and maximum scale limits. Ignored if ``scale`` is left specified.\n    scale_func : ufunc, optional\n        The function used to scale point sizes. Defaults to a linear scale. For more information see `the Gallery demo\n        <examples/usa-city-elevations.html>`_.\n    legend : boolean, optional\n        Whether or not to include a legend. Ignored if neither a ``hue`` nor a ``scale`` is specified.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_var : \"hue\" or \"scale\", optional\n        If both ``hue`` and ``scale`` are specified, which variable to use in the legend.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Line2D\n        <https://matplotlib.org/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D>`_ instances.\n\n    Returns\n    -------\n    ``AxesSubplot`` or ``GeoAxesSubplot``\n        The plot axis\n\n    Examples\n    --------\n    A `Sankey diagram <https://en.wikipedia.org/wiki/Sankey_diagram>`_ is a simple visualization demonstrating flow\n    through a network. A Sankey diagram is useful when you wish to show the volume of things moving between points or\n    spaces: traffic load a road network, for example, or inter-airport travel volumes. The ``geoplot`` ``sankey``\n    adds spatial context to this plot type by laying out the points in meaningful locations: airport locations, say,\n    or road intersections.\n\n    A basic ``sankey`` specifies data, ``start`` points, ``end`` points, and, optionally, a projection. The ``df``\n    argument is optional; if geometries are provided as independent iterables it is ignored. We overlay world\n    geometry to aid interpretability.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(la_flights, start='start', end='end', projection=gcrs.PlateCarree())\n        ax.set_global(); ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-geospatial-context.png\n\n    The lines appear curved because they are `great circle <https://en.wikipedia.org/wiki/Great-circle_distance>`_\n    paths, which are the shortest routes between points on a sphere.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(la_flights, start='start', end='end', projection=gcrs.Orthographic())\n        ax.set_global(); ax.coastlines(); ax.outline_patch.set_visible(True)\n\n    .. image:: ../figures/sankey/sankey-greatest-circle-distance.png\n\n    To plot using a different distance metric pass a ``cartopy`` ``crs`` object (*not* a ``geoplot`` one) to the\n    ``path`` parameter.\n\n    .. code-block:: python\n\n        import cartopy.crs as ccrs\n        ax = gplt.sankey(la_flights, start='start', end='end', projection=gcrs.PlateCarree(), path=ccrs.PlateCarree())\n        ax.set_global(); ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-path-projection.png\n\n    If your data has custom paths, you can use those instead, via the ``path`` parameter.\n\n    .. code-block:: python\n\n        gplt.sankey(dc, path=dc.geometry, projection=gcrs.AlbersEqualArea(), scale='aadt')\n\n\n    .. image:: ../figures/sankey/sankey-path.png\n\n    ``hue`` parameterizes the color, and ``cmap`` controls the colormap. ``legend`` adds a a legend. Keyword\n    arguments can be passed to the legend using the ``legend_kwargs`` argument. These arguments will be\n    passed to the underlying ``matplotlib`` `Legend\n    <http://matplotlib.org/api/legend_api.html#matplotlib.legend.Legend>`_. The ``loc`` and ``bbox_to_anchor``\n    parameters are particularly useful for positioning the legend.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(network, projection=gcrs.PlateCarree(),\n                         start='from', end='to',\n                         hue='mock_variable', cmap='RdYlBu',\n                         legend=True, legend_kwargs={'bbox_to_anchor': (1.4, 1.0)})\n        ax.set_global()\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-legend-kwargs.png\n\n    Change the number of bins by specifying an alternative ``k`` value. To use a continuous colormap, explicitly\n    specify ``k=None``. You can change the binning sceme with ``scheme``. The default is ``quantile``, which bins\n    observations into classes of different sizes but the same numbers of observations. ``equal_interval`` will\n    creates bins that are the same size, but potentially containing different numbers of observations. The more\n    complicated ``fisher_jenks`` scheme is an intermediate between the two.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(network, projection=gcrs.PlateCarree(),\n                         start='from', end='to',\n                         hue='mock_variable', cmap='RdYlBu',\n                         legend=True, legend_kwargs={'bbox_to_anchor': (1.25, 1.0)},\n                         k=3, scheme='equal_interval')\n        ax.set_global()\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-scheme.png\n\n    If your variable of interest is already `categorical\n    <http://pandas.pydata.org/pandas-docs/stable/categorical.html>`_, specify ``categorical=True`` to\n    use the labels in your dataset directly.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(network, projection=gcrs.PlateCarree(),\n                         start='from', end='to',\n                         hue='above_meridian', cmap='RdYlBu',\n                         legend=True, legend_kwargs={'bbox_to_anchor': (1.2, 1.0)},\n                         categorical=True)\n        ax.set_global()\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-categorical.png\n\n    ``scale`` can be used to enable ``linewidth`` as a visual variable. Adjust the upper and lower bound with the\n    ``limits`` parameter.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(la_flights, projection=gcrs.PlateCarree(),\n                         extent=(-125.0011, -66.9326, 24.9493, 49.5904),\n                         start='start', end='end',\n                         scale='Passengers',\n                         limits=(0.1, 5),\n                         legend=True, legend_kwargs={'bbox_to_anchor': (1.1, 1.0)})\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-scale.png\n\n    The default scaling function is linear: an observations at the midpoint of two others will be exactly midway\n    between them in size. To specify an alternative scaling function, use the ``scale_func`` parameter. This should\n    be a factory function of two variables which, when given the maximum and minimum of the dataset,\n    returns a scaling function which will be applied to the rest of the data. A demo is available in\n    the `example gallery <examples/usa-city-elevations.html>`_.\n\n    .. code-block:: python\n\n        def trivial_scale(minval, maxval): return lambda v: 1\n        ax = gplt.sankey(la_flights, projection=gcrs.PlateCarree(),\n                         extent=(-125.0011, -66.9326, 24.9493, 49.5904),\n                         start='start', end='end',\n                         scale='Passengers', scale_func=trivial_scale,\n                         legend=True, legend_kwargs={'bbox_to_anchor': (1.1, 1.0)})\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-scale-func.png\n\n    ``hue`` and ``scale`` can co-exist. In case more than one visual variable is used, control which one appears in\n    the legend using ``legend_var``.\n\n    .. code-block:: python\n\n        ax = gplt.sankey(network, projection=gcrs.PlateCarree(),\n                 start='from', end='to',\n                 scale='mock_data',\n                 legend=True, legend_kwargs={'bbox_to_anchor': (1.1, 1.0)},\n                 hue='mock_data', legend_var=\"hue\")\n        ax.set_global()\n        ax.coastlines()\n\n    .. image:: ../figures/sankey/sankey-legend-var.png\n\n    \"\"\"\n    # Validate df.\n    if len(args) > 1:\n        raise ValueError(\"Invalid input.\")\n    elif len(args) == 1:\n        df = args[0]\n    else:\n        df = pd.DataFrame()\n        # df = None  # bind the local name here; initialize in a bit.\n\n    # Validate the rest of the input.\n    if ((start is None) or (end is None)) and not hasattr(path, \"__iter__\"):\n        raise ValueError(\"The 'start' and 'end' parameters must both be specified.\")\n    if (isinstance(start, str) or isinstance(end, str)) and df.empty:\n        raise ValueError(\"Invalid input.\")\n    if isinstance(start, str):\n        start = df[start]\n    elif start is not None:\n        start = gpd.GeoSeries(start)\n    if isinstance(end, str):\n        end = df[end]\n    elif end is not None:\n        end = gpd.GeoSeries(end)\n    if (start is not None) and (end is not None) and hasattr(path, \"__iter__\"):\n        raise ValueError(\"One of 'start' and 'end' OR 'path' must be specified, but they cannot be specified \"\n                         \"simultaneously.\")\n    if path is None:  # No path provided.\n        path = ccrs.Geodetic()\n        path_geoms = None\n    elif isinstance(path, str):  # Path is a column in the dataset.\n        path_geoms = df[path]\n    elif hasattr(path, \"__iter__\"):  # Path is an iterable.\n        path_geoms = gpd.GeoSeries(path)\n    else:  # Path is a cartopy.crs object.\n        path_geoms = None\n    if start is not None and end is not None:\n        points = pd.concat([start, end])\n    else:\n        points = None\n\n    # Set legend variable.\n    if legend_var is None:\n        if scale is not None:\n            legend_var = \"scale\"\n        elif hue is not None:\n            legend_var = \"hue\"\n\n    # After validating the inputs, we are in one of two modes:\n    # 1. Projective mode. In this case ``path_geoms`` is None, while ``points`` contains a concatenation of our\n    #    points (for use in initializing the plot extents). This case occurs when the user specifies ``start`` and\n    #    ``end``, and not ``path``. This is \"projective mode\" because it means that ``path`` will be a\n    #    projection---if one is not provided explicitly, the ``gcrs.Geodetic()`` projection.\n    # 2. Path mode. In this case ``path_geoms`` is an iterable of LineString entities to be plotted, while ``points``\n    #    is None. This occurs when the user specifies ``path``, and not ``start`` or ``end``. This is path mode\n    #    because we will need to plot exactly those paths!\n\n    # At this point we'll initialize the rest of the variables we need. The way that we initialize them is going to\n    # depend on which code path we are on. Additionally, we will initialize the `df` variable with a projection\n    # dummy, if it has not been initialized already. This `df` will only be used for figuring out the extent,\n    # and will be discarded afterwards!\n    #\n    # Variables we need to generate at this point, and why we need them:\n    # 1. (clong, clat) --- To pass this to the projection settings.\n    # 2. (xmin. xmax, ymin. ymax) --- To pass this to the extent settings.\n    # 3. n --- To pass this to the color array in case no ``color`` is specified.\n    if path_geoms is None and points is not None:\n        if df.empty:\n            df = gpd.GeoDataFrame(geometry=points)\n        xs = np.array([p.x for p in points])\n        ys = np.array([p.y for p in points])\n        xmin, xmax, ymin, ymax = np.min(xs), np.max(xs), np.min(ys), np.max(ys)\n        clong, clat = np.mean(xs), np.mean(ys)\n        n = int(len(points) / 2)\n    else:  # path_geoms is an iterable\n        path_geoms = gpd.GeoSeries(path_geoms)\n        xmin, xmax, ymin, ymax = _get_envelopes_min_maxes(path_geoms.envelope.exterior)\n        clong, clat = (xmin + xmax) / 2, (ymin + ymax) / 2\n        n = len(path_geoms)\n\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    # Load the projection.\n    if projection:\n        projection = projection.load(df, {\n            'central_longitude': lambda df: clong,\n            'central_latitude': lambda df: clat\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Set extent.\n    if projection:\n        if extent:\n            ax.set_extent(extent)\n        else:\n            ax.set_extent((xmin, xmax, ymin, ymax))\n    else:\n        if extent:\n            ax.set_xlim((extent[0], extent[1]))\n            ax.set_ylim((extent[2], extent[3]))\n        else:\n            ax.set_xlim((xmin, xmax))\n            ax.set_ylim((ymin, ymax))\n\n    # Generate the coloring information, if needed. Follows one of two schemes, categorical or continuous,\n    # based on whether or not ``k`` is specified (``hue`` must be specified for either to work).\n    if k is not None:\n        # Categorical colormap code path.\n        categorical, k, scheme = _validate_buckets(categorical, k, scheme)\n\n        hue = _validate_hue(df, hue)\n\n        if hue is not None:\n            cmap, categories, hue_values = _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax)\n            colors = [cmap.to_rgba(v) for v in hue_values]\n\n            # Add a legend, if appropriate.\n            if legend and (legend_var != \"scale\" or scale is None):\n                _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs)\n        else:\n            if 'color' not in kwargs.keys():\n                colors = ['steelblue'] * n\n            else:\n                colors = [kwargs['color']] * n\n                kwargs.pop('color')\n    elif k is None and hue is not None:\n        # Continuous colormap code path.\n        hue_values = hue\n        cmap = _continuous_colormap(hue_values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(v) for v in hue_values]\n\n        # Add a legend, if appropriate.\n        if legend and (legend_var != \"scale\" or scale is None):\n            _paint_colorbar_legend(ax, hue_values, cmap, legend_kwargs)\n\n    # Check if the ``scale`` parameter is filled, and use it to fill a ``values`` name.\n    if scale:\n        if isinstance(scale, str):\n            scalar_values = df[scale]\n        else:\n            scalar_values = scale\n\n        # Compute a scale function.\n        dmin, dmax = np.min(scalar_values), np.max(scalar_values)\n        if not scale_func:\n            dslope = (limits[1] - limits[0]) / (dmax - dmin)\n            dscale = lambda dval: limits[0] + dslope * (dval - dmin)\n        else:\n            dscale = scale_func(dmin, dmax)\n\n        # Apply the scale function.\n        scalar_multiples = np.array([dscale(d) for d in scalar_values])\n        widths = scalar_multiples * 1\n\n        # Draw a legend, if appropriate.\n        if legend and (legend_var == \"scale\"):\n            _paint_carto_legend(ax, scalar_values, legend_values, legend_labels, dscale, legend_kwargs)\n    else:\n        widths = [1] * n  # pyplot default\n\n    # Allow overwriting visual arguments.\n    if 'linestyle' in kwargs.keys():\n        linestyle = kwargs['linestyle']; kwargs.pop('linestyle')\n    else:\n        linestyle = '-'\n    if 'color' in kwargs.keys():\n        colors = [kwargs['color']]*n; kwargs.pop('color')\n    elif 'edgecolor' in kwargs.keys():  # plt.plot uses 'color', mpl.ax.add_feature uses 'edgecolor'. Support both.\n        colors = [kwargs['edgecolor']]*n; kwargs.pop('edgecolor')\n    if 'linewidth' in kwargs.keys():\n        widths = [kwargs['linewidth']]*n; kwargs.pop('linewidth')\n\n    if projection:\n        # Duck test plot. The first will work if a valid transformation is passed to ``path`` (e.g. we are in the\n        # ``start + ``end`` case), the second will work if ``path`` is an iterable (e.g. we are in the ``path`` case).\n        try:\n            for origin, destination, color, width in zip(start, end, colors, widths):\n                ax.plot([origin.x, destination.x], [origin.y, destination.y], transform=path,\n                        linestyle=linestyle, linewidth=width, color=color, **kwargs)\n        except TypeError:\n            for line, color, width in zip(path_geoms, colors, widths):\n                feature = ShapelyFeature([line], ccrs.PlateCarree())\n                ax.add_feature(feature, linestyle=linestyle, linewidth=width, edgecolor=color, facecolor='None',\n                **kwargs)\n    else:\n        try:\n            for origin, destination, color, width in zip(start, end, colors, widths):\n                ax.plot([origin.x, destination.x], [origin.y, destination.y],\n                        linestyle=linestyle, linewidth=width, color=color, **kwargs)\n        except TypeError:\n            for path, color, width in zip(path_geoms, colors, widths):\n                # We have to implement different methods for dealing with LineString and MultiLineString objects.\n                # This calls for, yep, another duck test.\n                try:  # LineString\n                    line = mpl.lines.Line2D([coord[0] for coord in path.coords],\n                                            [coord[1] for coord in path.coords],\n                                            linestyle=linestyle, linewidth=width, color=color, **kwargs)\n                    ax.add_line(line)\n                except NotImplementedError:  # MultiLineString\n                    for line in path:\n                        line = mpl.lines.Line2D([coord[0] for coord in line.coords],\n                                                [coord[1] for coord in line.coords],\n                                                linestyle=linestyle, linewidth=width, color=color, **kwargs)\n                        ax.add_line(line)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef voronoi(df, projection=None, edgecolor='black',\n            clip=None,\n            hue=None, scheme=None, k=5, cmap='viridis', categorical=False, vmin=None, vmax=None,\n            legend=False, legend_kwargs=None, legend_labels=None,\n            extent=None, figsize=(8, 6), ax=None,\n            **kwargs):\n    \"\"\"\n    Geospatial Voronoi diagram.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The data being plotted.\n    projection : geoplot.crs object instance, optional\n        A geographic projection. For more information refer to `the tutorial page on projections\n        <https://nbviewer.jupyter.org/github/ResidentMario/geoplot/blob/master/notebooks/tutorials/Projections.ipynb>`_.\n    hue : None, Series, GeoSeries, iterable, or str, optional\n        Applies a colormap to the output points.\n    categorical : boolean, optional\n        Set to ``True`` if ``hue`` references a categorical variable, and ``False`` (the default) otherwise. Ignored\n        if ``hue`` is left unspecified.\n    scheme : None or {\"quantiles\"|\"equal_interval\"|\"fisher_jenks\"}, optional\n        Controls how the colormap bin edges are determined. Ignored if ``hue`` is left unspecified.\n    k : int or None, optional\n        Ignored if ``hue`` is left unspecified. Otherwise, if ``categorical`` is False, controls how many colors to\n        use (5 is the default). If set to ``None``, a continuous colormap will be used.\n    cmap : matplotlib color, optional\n        The `matplotlib colormap <http://matplotlib.org/examples/color/colormaps_reference.html>`_ to be used.\n        Ignored if ``hue`` is left unspecified.\n    vmin : float, optional\n        Values below this level will be colored the same threshold value. Defaults to the dataset minimum. Ignored\n        if ``hue`` is left unspecified.\n    vmax : float, optional\n        Values above this level will be colored the same threshold value. Defaults to the dataset maximum. Ignored\n        if ``hue`` is left unspecified.\n    legend : boolean, optional\n        Whether or not to include a legend. Ignored if neither a ``hue`` nor a ``scale`` is specified.\n    legend_values : list, optional\n        The values to use in the legend. Defaults to equal intervals. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_labels : list, optional\n        The names to use in the legend. Defaults to the variable values. For more information see `the Gallery demo\n        <https://residentmario.github.io/geoplot/examples/largest-cities-usa.html>`_.\n    legend_kwargs : dict, optional\n        Keyword arguments to be passed to `the underlying legend <http://matplotlib.org/users/legend_guide.html>`_.\n    extent : None or (minx, maxx, miny, maxy), optional\n        Used to control plot x-axis and y-axis limits manually.\n    figsize : tuple, optional\n        An (x, y) tuple passed to ``matplotlib.figure`` which sets the size, in inches, of the resultant plot.\n    ax : AxesSubplot or GeoAxesSubplot instance, optional\n        A ``matplotlib.axes.AxesSubplot`` or ``cartopy.mpl.geoaxes.GeoAxesSubplot`` instance. Defaults to a new axis.\n    kwargs: dict, optional\n        Keyword arguments to be passed to the underlying ``matplotlib`` `Line2D objects\n        <http://matplotlib.org/api/lines_api.html#matplotlib.lines.Line2D>`_.\n\n    Returns\n    -------\n    AxesSubplot or GeoAxesSubplot instance\n        The axis object with the plot on it.\n\n    Examples\n    --------\n\n    The neighborhood closest to a point in space is known as its `Voronoi region\n    <https://en.wikipedia.org/wiki/Voronoi_diagram>`_. Every point in a dataset has a Voronoi region, which may be\n    either a closed polygon (for inliers) or open infinite region (for points on the edge of the distribution). A\n    Voronoi diagram works by dividing a space filled with points into such regions and plotting the result. Voronoi\n    plots allow efficient assessmelt of the *density* of points in different spaces, and when combined with a\n    colormap can be quite informative of overall trends in the dataset.\n\n    The ``geoplot`` ``voronoi`` is a spatially aware application of this technique. It compares well with the more\n    well-known ``choropleth``, which has the advantage of using meaningful regions, but the disadvantage of having\n    defined those regions beforehand. ``voronoi`` has fewer requirements and may perform better when the number of\n    observations is small. Compare also with the quadtree technique available in ``aggplot``.\n\n    A basic ``voronoi`` specified data and, optionally, a projection. We overlay geometry to aid interpretability.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000))\n        gplt.polyplot(boroughs, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-simple.png\n\n    ``hue`` parameterizes the color, and ``cmap`` controls the colormap.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000), hue='NUMBER OF PERSONS INJURED', cmap='Reds')\n        gplt.polyplot(boroughs, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-cmap.png\n\n    Add a ``clip`` of iterable geometries to trim the ``voronoi`` against local geography.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                          clip=boroughs.geometry)\n        gplt.polyplot(boroughs, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-clip.png\n\n    ``legend`` adds a a ``matplotlib`` `Legend\n    <http://matplotlib.org/api/legend_api.html#matplotlib.legend.Legend>`_. This can be tuned even further using the\n    ``legend_kwargs`` argument. Other keyword parameters are passed to the underlying ``matplotlib`` `Polygon patches\n    <http://matplotlib.org/api/patches_api.html#matplotlib.patches.Polygon>`_.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n                          clip=boroughs.geometry,\n                          legend=True, legend_kwargs={'loc': 'upper left'},\n                          linewidth=0.5, edgecolor='white',\n                         )\n        gplt.polyplot(boroughs, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-kwargs.png\n\n    Change the number of bins by specifying an alternative ``k`` value. To use a continuous colormap, explicitly\n    specify ``k=None``.  You can change the binning sceme with ``scheme``. The default is ``quantile``, which bins\n    observations into classes of different sizes but the same numbers of observations. ``equal_interval`` will\n    creates bins that are the same size, but potentially containing different numbers of observations. The more\n    complicated ``fisher_jenks`` scheme is an intermediate between the two.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000),\n                          hue='NUMBER OF PERSONS INJURED', cmap='Reds', k=5, scheme='fisher_jenks',\n                          clip=boroughs.geometry,\n                          legend=True, legend_kwargs={'loc': 'upper left'},\n                          linewidth=0.5, edgecolor='white',\n                         )\n        gplt.polyplot(boroughs, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-scheme.png\n\n    If your variable of interest is already `categorical\n    <http://pandas.pydata.org/pandas-docs/stable/categorical.html>`_, specify ``categorical=True`` to\n    use the labels in your dataset directly.\n\n    .. code-block:: python\n\n        ax = gplt.voronoi(injurious_collisions.head(1000), hue='NUMBER OF PERSONS INJURED', cmap='Reds',\n             edgecolor='white', clip=boroughs.geometry,\n             linewidth=0.5, categorical=True\n             )\n        gplt.polyplot(boroughs, linewidth=1, ax=ax)\n\n    .. image:: ../figures/voronoi/voronoi-multiparty.png\n    \"\"\"\n\n    # Initialize the figure.\n    fig = _init_figure(ax, figsize)\n\n    if projection:\n        # Properly set up the projection.\n        projection = projection.load(df, {\n            'central_longitude': lambda df: np.mean(np.array([p.x for p in df.geometry.centroid])),\n            'central_latitude': lambda df: np.mean(np.array([p.y for p in df.geometry.centroid]))\n        })\n\n        # Set up the axis.\n        if not ax:\n            ax = plt.subplot(111, projection=projection)\n\n    else:\n        if not ax:\n            ax = plt.gca()\n\n    # Clean up patches.\n    _lay_out_axes(ax, projection)\n\n    # Immediately return if input geometry is empty.\n    if len(df.geometry) == 0:\n        return ax\n\n    # Set extent.\n    xs, ys = [p.x for p in df.geometry.centroid], [p.y for p in df.geometry.centroid]\n    extrema = np.min(xs), np.max(xs), np.min(ys), np.max(ys)\n    _set_extent(ax, projection, extent, extrema)\n\n    # Validate hue input.\n    hue = _validate_hue(df, hue)\n\n    # Generate the coloring information, if needed. Follows one of two schemes, categorical or continuous,\n    # based on whether or not ``k`` is specified (``hue`` must be specified for either to work).\n    if k is not None:\n        # Categorical colormap code path.\n        categorical, k, scheme = _validate_buckets(categorical, k, scheme)\n\n        if hue is not None:\n            cmap, categories, hue_values = _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax)\n            colors = [cmap.to_rgba(v) for v in hue_values]\n\n        else:\n            colors = ['None']*len(df)\n\n    elif k is None and hue is not None:\n        # Continuous colormap code path.\n        hue_values = hue\n        cmap = _continuous_colormap(hue_values, cmap, vmin, vmax)\n        colors = [cmap.to_rgba(v) for v in hue_values]\n\n    elif 'facecolor' in kwargs:\n        colors = [kwargs.pop('facecolor')]*len(df)\n    else:\n        colors = ['None']*len(df)\n\n    # Finally we draw the features.\n    geoms = _build_voronoi_polygons(df)\n    if projection:\n        for color, geom in zip(colors, geoms):\n            features = ShapelyFeature([geom], ccrs.PlateCarree())\n            ax.add_feature(features, facecolor=color, edgecolor=edgecolor, **kwargs)\n\n        if clip is not None:\n            clip_geom = _get_clip(ax.get_extent(crs=ccrs.PlateCarree()), clip)\n            feature = ShapelyFeature([clip_geom], ccrs.PlateCarree())\n            ax.add_feature(feature, facecolor=(1,1,1), linewidth=0, zorder=100)\n\n    else:\n        for color, geom in zip(colors, geoms):\n            feature = descartes.PolygonPatch(geom, facecolor=color, edgecolor=edgecolor, **kwargs)\n            ax.add_patch(feature)\n\n        if clip is not None:\n            clip_geom = _get_clip(ax.get_xlim() + ax.get_ylim(), clip)\n            ax = polyplot(gpd.GeoSeries(clip_geom), facecolor='white', linewidth=0, zorder=100,\n                          extent=ax.get_xlim() + ax.get_ylim(), ax=ax)\n\n    # Add a legend, if appropriate.\n    if legend and k is not None:\n        _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs, figure=True)\n    elif legend and k is None and hue is not None:\n        _paint_colorbar_legend(ax, hue_values, cmap, legend_kwargs)\n\n    return ax", "response": "Plots a voronoi diagram of the data in a geographic projection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the matplotlib figure for the current object.", "response": "def _init_figure(ax, figsize):\n    \"\"\"\n    Initializes the ``matplotlib`` ``figure``, one of the first things that every plot must do. No figure is\n    initialized (and, consequentially, the ``figsize`` argument is ignored) if a pre-existing ``ax`` is passed to\n    the method. This is necessary for ``plt.savefig()`` to work.\n\n    Parameters\n    ----------\n    ax : None or cartopy GeoAxesSubplot instance\n        The current axis, if there is one.\n    figsize : (x_dim, y_dim) tuple\n        The dimension of the resultant plot.\n\n    Returns\n    -------\n    None or matplotlib.Figure instance\n        Returns either nothing or the underlying ``Figure`` instance, depending on whether or not one is initialized.\n    \"\"\"\n    if not ax:\n        fig = plt.figure(figsize=figsize)\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the xmin xmax ymin ymax for the inputted polygonal envelopes. Used for setting chart extent where appropriate.", "response": "def _get_envelopes_min_maxes(envelopes):\n    \"\"\"\n    Returns the extrema of the inputted polygonal envelopes. Used for setting chart extent where appropriate. Note\n    tha the ``Quadtree.bounds`` object property serves a similar role.\n\n    Parameters\n    ----------\n    envelopes : GeoSeries\n        The envelopes of the given geometries, as would be returned by e.g. ``data.geometry.envelope.exterior``.\n\n    Returns\n    -------\n    (xmin, xmax, ymin, ymax) : tuple\n        The data extrema.\n\n    \"\"\"\n    xmin = np.min(envelopes.map(lambda linearring: np.min([linearring.coords[1][0],\n                                                          linearring.coords[2][0],\n                                                          linearring.coords[3][0],\n                                                          linearring.coords[4][0]])))\n    xmax = np.max(envelopes.map(lambda linearring: np.max([linearring.coords[1][0],\n                                                          linearring.coords[2][0],\n                                                          linearring.coords[3][0],\n                                                          linearring.coords[4][0]])))\n    ymin = np.min(envelopes.map(lambda linearring: np.min([linearring.coords[1][1],\n                                                           linearring.coords[2][1],\n                                                           linearring.coords[3][1],\n                                                           linearring.coords[4][1]])))\n    ymax = np.max(envelopes.map(lambda linearring: np.max([linearring.coords[1][1],\n                                                           linearring.coords[2][1],\n                                                           linearring.coords[3][1],\n                                                           linearring.coords[4][1]])))\n    return xmin, xmax, ymin, ymax"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the centroid of an inputted geometry column.", "response": "def _get_envelopes_centroid(envelopes):\n    \"\"\"\n    Returns the centroid of an inputted geometry column. Not currently in use, as this is now handled by this\n    library's CRS wrapper directly. Light wrapper over ``_get_envelopes_min_maxes``.\n\n    Parameters\n    ----------\n    envelopes : GeoSeries\n        The envelopes of the given geometries, as would be returned by e.g. ``data.geometry.envelope``.\n\n    Returns\n    -------\n    (mean_x, mean_y) : tuple\n        The data centroid.\n    \"\"\"\n    xmin, xmax, ymin, ymax = _get_envelopes_min_maxes(envelopes)\n    return np.mean(xmin, xmax), np.mean(ymin, ymax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_extent(ax, projection, extent, extrema):\n    if extent:\n        xmin, xmax, ymin, ymax = extent\n        xmin, xmax, ymin, ymax = max(xmin, -180), min(xmax, 180), max(ymin, -90), min(ymax, 90)\n\n        if projection:  # Input ``extent`` into set_extent().\n            ax.set_extent((xmin, xmax, ymin, ymax), crs=ccrs.PlateCarree())\n        else:  # Input ``extent`` into set_ylim, set_xlim.\n            ax.set_xlim((xmin, xmax))\n            ax.set_ylim((ymin, ymax))\n\n    else:\n        xmin, xmax, ymin, ymax = extrema\n        xmin, xmax, ymin, ymax = max(xmin, -180), min(xmax, 180), max(ymin, -90), min(ymax, 90)\n\n        if projection:  # Input ``extrema`` into set_extent.\n            ax.set_extent((xmin, xmax, ymin, ymax), crs=ccrs.PlateCarree())\n        else:  # Input ``extrema`` into set_ylim, set_xlim.\n            ax.set_xlim((xmin, xmax))\n            ax.set_ylim((ymin, ymax))", "response": "Sets the plot extent."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _lay_out_axes(ax, projection):\n    if projection is not None:\n        try:\n            ax.background_patch.set_visible(False)\n            ax.outline_patch.set_visible(False)\n        except AttributeError:  # Testing...\n            pass\n    else:\n        plt.gca().axison = False", "response": "This function is used to set the axes that are used to visualize the content of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the hue parameter is present in the most plot types.", "response": "def _validate_hue(df, hue):\n    \"\"\"\n    The top-level ``hue`` parameter present in most plot types accepts a variety of input types. This method\n    condenses this variety into a single preferred format---an iterable---which is expected by all submethods working\n    with the data downstream of it.\n\n    Parameters\n    ----------\n    df : GeoDataFrame\n        The full data input, from which standardized ``hue`` information may need to be extracted.\n    hue : Series, GeoSeries, iterable, str\n        The data column whose entries are being discretely colorized, as (loosely) passed by the top-level ``hue``\n        variable.\n    required : boolean\n        Whether or not this parameter is required for the plot in question.\n\n    Returns\n    -------\n    hue : iterable\n        The ``hue`` parameter input as an iterable.\n    \"\"\"\n    if hue is None:\n        return None\n    elif isinstance(hue, str):\n        hue = df[hue]\n        return hue\n    else:\n        return gpd.GeoSeries(hue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a continuous colormap for the given hue and colormap.", "response": "def _continuous_colormap(hue, cmap, vmin, vmax):\n    \"\"\"\n    Creates a continuous colormap.\n\n    Parameters\n    ----------\n    hue : iterable\n        The data column whose entries are being discretely colorized. Note that although top-level plotter ``hue``\n        parameters ingest many argument signatures, not just iterables, they are all preprocessed to standardized\n        iterables before this method is called.\n    cmap : ``matplotlib.cm`` instance\n        The `matplotlib` colormap instance which will be used to colorize the geometries.\n    vmin : float\n        A strict floor on the value associated with the \"bottom\" of the colormap spectrum. Data column entries whose\n        value is below this level will all be colored by the same threshold value. The value for this variable is\n        meant to be inherited from the top-level variable of the same name.\n    vmax : float\n        A strict ceiling on the value associated with the \"top\" of the colormap spectrum. Data column entries whose\n        value is above this level will all be colored by the same threshold value. The value for this variable is\n        meant to be inherited from the top-level variable of the same name.\n\n    Returns\n    -------\n    cmap : ``mpl.cm.ScalarMappable`` instance\n        A normalized scalar version of the input ``cmap`` which has been fitted to the data and inputs.\n    \"\"\"\n    mn = min(hue) if vmin is None else vmin\n    mx = max(hue) if vmax is None else vmax\n    norm = mpl.colors.Normalize(vmin=mn, vmax=mx)\n    return mpl.cm.ScalarMappable(norm=norm, cmap=cmap)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a discrete colormap based on a given set of data values.", "response": "def _discrete_colorize(categorical, hue, scheme, k, cmap, vmin, vmax):\n    \"\"\"\n    Creates a discrete colormap, either using an already-categorical data variable or by bucketing a non-categorical\n    ordinal one. If a scheme is provided we compute a distribution for the given data. If one is not provided we\n    assume that the input data is categorical.\n\n    This code makes extensive use of ``geopandas`` choropleth facilities.\n\n    Parameters\n    ----------\n    categorical : boolean\n        Whether or not the input variable is already categorical.\n    hue : iterable\n        The data column whose entries are being discretely colorized. Note that although top-level plotter ``hue``\n        parameters ingest many argument signatures, not just iterables, they are all preprocessed to standardized\n        iterables before this method is called.\n    scheme : str\n        The mapclassify binning scheme to be used for splitting data values (or rather, the the string representation\n        thereof).\n    k : int\n        The number of bins which will be used. This parameter will be ignored if ``categorical`` is True. The default\n        value should be 5---this should be set before this method is called.\n    cmap : ``matplotlib.cm`` instance\n        The `matplotlib` colormap instance which will be used to colorize the geometries. This colormap\n        determines the spectrum; our algorithm determines the cuts.\n    vmin : float\n        A strict floor on the value associated with the \"bottom\" of the colormap spectrum. Data column entries whose\n        value is below this level will all be colored by the same threshold value.\n    vmax : float\n        A strict cealing on the value associated with the \"bottom\" of the colormap spectrum. Data column entries whose\n        value is above this level will all be colored by the same threshold value.\n\n    Returns\n    -------\n    (cmap, categories, values) : tuple\n        A tuple meant for assignment containing the values for various properties set by this method call.\n    \"\"\"\n    if not categorical:\n        binning = _mapclassify_choro(hue, scheme, k=k)\n        values = binning.yb\n        binedges = [binning.yb.min()] + binning.bins.tolist()\n        categories = ['{0:.2f} - {1:.2f}'.format(binedges[i], binedges[i + 1])\n                      for i in range(len(binedges) - 1)]\n    else:\n        categories = np.unique(hue)\n        if len(categories) > 10:\n            warnings.warn(\"Generating a colormap using a categorical column with over 10 individual categories. \"\n                          \"This is not recommended!\")\n        value_map = {v: i for i, v in enumerate(categories)}\n        values = [value_map[d] for d in hue]\n    cmap = _norm_cmap(values, cmap, mpl.colors.Normalize, mpl.cm, vmin=vmin, vmax=vmax)\n    return cmap, categories, values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _paint_hue_legend(ax, categories, cmap, legend_labels, legend_kwargs, figure=False):\n\n    # Paint patches.\n    patches = []\n    for value, cat in enumerate(categories):\n        patches.append(mpl.lines.Line2D([0], [0], linestyle=\"none\",\n                              marker=\"o\",\n                              markersize=10, markerfacecolor=cmap.to_rgba(value)))\n    # I can't initialize legend_kwargs as an empty dict() by default because of Python's argument mutability quirks.\n    # cf. http://docs.python-guide.org/en/latest/writing/gotchas/. Instead my default argument is None,\n    # but that doesn't unpack correctly, necessitating setting and passing an empty dict here. Awkward...\n    if not legend_kwargs: legend_kwargs = dict()\n\n    # If we are given labels use those, if we are not just use the categories.\n    target = ax.figure if figure else ax\n\n    if legend_labels:\n        target.legend(patches, legend_labels, numpoints=1, fancybox=True, **legend_kwargs)\n    else:\n        target.legend(patches, categories, numpoints=1, fancybox=True, **legend_kwargs)", "response": "Draws a legend on the given axes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _paint_carto_legend(ax, values, legend_values, legend_labels, scale_func, legend_kwargs):\n\n    # Set up the legend values.\n    if legend_values is not None:\n        display_values = legend_values\n    else:\n        display_values = np.linspace(np.max(values), np.min(values), num=5)\n    display_labels = legend_labels if (legend_labels is not None) else display_values\n\n    # Paint patches.\n    patches = []\n    for value in display_values:\n        patches.append(mpl.lines.Line2D([0], [0], linestyle='None',\n                       marker=\"o\",\n                       markersize=(20*scale_func(value))**(1/2),\n                       markerfacecolor='None'))\n    if legend_kwargs is None: legend_kwargs = dict()\n    ax.legend(patches, display_labels, numpoints=1, fancybox=True, **legend_kwargs)", "response": "Draws a legend on the carto axes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _paint_colorbar_legend(ax, values, cmap, legend_kwargs):\n    if legend_kwargs is None: legend_kwargs = dict()\n    cmap.set_array(values)\n    plt.gcf().colorbar(cmap, ax=ax, **legend_kwargs)", "response": "Draws a colorbar for the given colormap."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_voronoi_polygons(df):\n    from scipy.spatial import Voronoi\n    geom = np.array(df.geometry.map(lambda p: [p.x, p.y]).tolist())\n    vor = Voronoi(geom)\n\n    polygons = []\n\n    for idx_point, _ in enumerate(vor.points):\n        idx_point_region = vor.point_region[idx_point]\n        idxs_vertices = np.array(vor.regions[idx_point_region])\n\n        is_finite = not np.any(idxs_vertices == -1)\n\n        if is_finite:\n            # Easy case, the region is closed. Make a polygon out of the Voronoi ridge points.\n            idx_point_region = vor.point_region[idx_point]\n            idxs_vertices = np.array(vor.regions[idx_point_region])\n            region_vertices = vor.vertices[idxs_vertices]\n            region_poly = shapely.geometry.Polygon(region_vertices)\n\n            polygons.append(region_poly)\n\n        else:\n            # Hard case, the region is open. Project new edges out to the margins of the plot.\n            # See `scipy.spatial.voronoi_plot_2d` for the source of this calculation.\n            point_idx_ridges_idx = np.where((vor.ridge_points == idx_point).any(axis=1))[0]\n\n            # TODO: why does this happen?\n            if len(point_idx_ridges_idx) == 0:\n                continue\n\n            ptp_bound = vor.points.ptp(axis=0)\n            center = vor.points.mean(axis=0)\n\n            finite_segments = []\n            infinite_segments = []\n\n            pointwise_ridge_points = vor.ridge_points[point_idx_ridges_idx]\n            pointwise_ridge_vertices = np.asarray(vor.ridge_vertices)[point_idx_ridges_idx]\n\n            for pointidx, simplex in zip(pointwise_ridge_points, pointwise_ridge_vertices):\n                simplex = np.asarray(simplex)\n\n                if np.all(simplex >= 0):\n                    finite_segments.append(vor.vertices[simplex])\n\n                else:\n                    i = simplex[simplex >= 0][0]  # finite end Voronoi vertex\n\n                    t = vor.points[pointidx[1]] - vor.points[pointidx[0]]  # tangent\n                    t /= np.linalg.norm(t)\n                    n = np.array([-t[1], t[0]])  # normal\n\n                    midpoint = vor.points[pointidx].mean(axis=0)\n                    direction = np.sign(np.dot(midpoint - center, n)) * n\n                    far_point = vor.vertices[i] + direction * ptp_bound.max()\n\n                    infinite_segments.append(np.asarray([vor.vertices[i], far_point]))\n\n            finite_segments = finite_segments if finite_segments else np.zeros(shape=(0,2,2))\n            ls = np.vstack([np.asarray(infinite_segments), np.asarray(finite_segments)])\n\n            # We have to trivially sort the line segments into polygonal order. The algorithm that follows is\n            # inefficient, being O(n^2), but \"good enough\" for this use-case.\n            ls_sorted = []\n\n            while len(ls_sorted) < len(ls):\n                l1 = ls[0] if len(ls_sorted) == 0 else ls_sorted[-1]\n                matches = []\n\n                for l2 in [l for l in ls if not (l == l1).all()]:\n                    if np.any(l1 == l2):\n                        matches.append(l2)\n                    elif np.any(l1 == l2[::-1]):\n                        l2 = l2[::-1]\n                        matches.append(l2)\n\n                if len(ls_sorted) == 0:\n                    ls_sorted.append(l1)\n\n                for match in matches:\n                    # in list sytax this would be \"if match not in ls_sorted\"\n                    # in numpy things are more complicated...\n                    if not any((match == ls_sort).all() for ls_sort in ls_sorted):\n                        ls_sorted.append(match)\n                        break\n\n            # Build and return the final polygon.\n            polyline = np.vstack(ls_sorted)\n            geom = shapely.geometry.Polygon(polyline).convex_hull\n            polygons.append(geom)\n\n    return polygons", "response": "Builds a list of shapely. geometry. Polygon objects for each point in the given space and returns them."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _norm_cmap(values, cmap, normalize, cm, vmin=None, vmax=None):\n\n    mn = min(values) if vmin is None else vmin\n    mx = max(values) if vmax is None else vmax\n    norm = normalize(vmin=mn, vmax=mx)\n    n_cmap = cm.ScalarMappable(norm=norm, cmap=cmap)\n    return n_cmap", "response": "Normalize and set colormap."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version():\n    proc = tmux_cmd('-V')\n    if proc.stderr:\n        if proc.stderr[0] == 'tmux: unknown option -- V':\n            if sys.platform.startswith(\"openbsd\"):  # openbsd has no tmux -V\n                return LooseVersion('%s-openbsd' % TMUX_MAX_VERSION)\n            raise exc.LibTmuxException(\n                'libtmux supports tmux %s and greater. This system'\n                ' is running tmux 1.3 or earlier.' % TMUX_MIN_VERSION\n            )\n        raise exc.VersionTooLow(proc.stderr)\n\n    version = proc.stdout[0].split('tmux ')[1]\n\n    # Allow latest tmux HEAD\n    if version == 'master':\n        return LooseVersion('%s-master' % TMUX_MAX_VERSION)\n\n    version = re.sub(r'[a-z-]', '', version)\n\n    return LooseVersion(version)", "response": "Return tmux version.\n\n    If tmux is built from git master, the version returned will be the latest\n    version appended with -master, e.g. ``2.4-master``.\n\n    If using OpenBSD's base system tmux, the version will have ``-openbsd``\n    appended to the latest version, e.g. ``2.4-openbsd``.\n\n    Returns\n    -------\n    :class:`distutils.version.LooseVersion`\n        tmux version according to :func:`libtmux.common.which`'s tmux"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_minimum_version(raises=True):\n    if get_version() < LooseVersion(TMUX_MIN_VERSION):\n        if raises:\n            raise exc.VersionTooLow(\n                'libtmux only supports tmux %s and greater. This system'\n                ' has %s installed. Upgrade your tmux to use libtmux.'\n                % (TMUX_MIN_VERSION, get_version())\n            )\n        else:\n            return False\n    return True", "response": "Returns True if tmux meets minimum version requirement. Version > = minimum version."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef session_check_name(session_name):\n    if not session_name or len(session_name) == 0:\n        raise exc.BadSessionName(\"tmux session names may not be empty.\")\n    elif '.' in session_name:\n        raise exc.BadSessionName(\n            \"tmux session name \\\"%s\\\" may not contain periods.\", session_name\n        )\n    elif ':' in session_name:\n        raise exc.BadSessionName(\n            \"tmux session name \\\"%s\\\" may not contain colons.\", session_name\n        )", "response": "Checks tmux session name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising exception if error in option command found.", "response": "def handle_option_error(error):\n    \"\"\"Raises exception if error in option command found.\n\n    Purpose: As of tmux 2.4, there are now 3 different types of option errors:\n\n    - unknown option\n    - invalid option\n    - ambiguous option\n\n    Before 2.4, unknown option was the user.\n\n    All errors raised will have the base error of :exc:`exc.OptionError`. So to\n    catch any option error, use ``except exc.OptionError``.\n\n    Parameters\n    ----------\n    error : str\n        Error response from subprocess call.\n\n    Raises\n    ------\n    :exc:`exc.OptionError`, :exc:`exc.UnknownOption`, :exc:`exc.InvalidOption`,\n    :exc:`exc.AmbiguousOption`\n    \"\"\"\n    if 'unknown option' in error:\n        raise exc.UnknownOption(error)\n    elif 'invalid option' in error:\n        raise exc.InvalidOption(error)\n    elif 'ambiguous option' in error:\n        raise exc.AmbiguousOption(error)\n    else:\n        raise exc.OptionError(error)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the tmux environment variable name to value.", "response": "def set_environment(self, name, value):\n        \"\"\"\n        Set environment ``$ tmux set-environment <name> <value>``.\n\n        Parameters\n        ----------\n        name : str\n            the environment variable name. such as 'PATH'.\n        option : str\n            environment value.\n        \"\"\"\n        args = ['set-environment']\n        if self._add_option:\n            args += [self._add_option]\n\n        args += [name, value]\n\n        proc = self.cmd(*args)\n\n        if proc.stderr:\n            if isinstance(proc.stderr, list) and len(proc.stderr) == int(1):\n                proc.stderr = proc.stderr[0]\n            raise ValueError('tmux set-environment stderr: %s' % proc.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow environmental variables for the specified session or the value of a specific variable.", "response": "def show_environment(self, name=None):\n        \"\"\"Show environment ``$ tmux show-environment -t [session] <name>``.\n\n        Return dict of environment variables for the session or the value of a\n        specific variable if the name is specified.\n\n        Parameters\n        ----------\n        name : str\n            the environment variable name. such as 'PATH'.\n\n        Returns\n        -------\n        str or dict\n            environmental variables in dict, if no name, or str if name\n            entered.\n        \"\"\"\n        tmux_args = ['show-environment']\n        if self._add_option:\n            tmux_args += [self._add_option]\n        if name:\n            tmux_args += [name]\n        vars = self.cmd(*tmux_args).stdout\n        vars = [tuple(item.split('=', 1)) for item in vars]\n        vars_dict = {}\n        for t in vars:\n            if len(t) == 2:\n                vars_dict[t[0]] = t[1]\n            elif len(t) == 1:\n                vars_dict[t[0]] = True\n            else:\n                raise ValueError('unexpected variable %s', t)\n\n        if name:\n            return vars_dict.get(name)\n\n        return vars_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef where(self, attrs, first=False):\n\n        # from https://github.com/serkanyersen/underscore.py\n        def by(val, *args):\n            for key, value in attrs.items():\n                try:\n                    if attrs[key] != val[key]:\n                        return False\n                except KeyError:\n                    return False\n                return True\n\n        if first:\n            return list(filter(by, self.children))[0]\n        else:\n            return list(filter(by, self.children))", "response": "Returns a list of objects matching child objects properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_by_id(self, id):\n        for child in self.children:\n            if child[self.child_id_attribute] == id:\n                return child\n            else:\n                continue\n\n        return None", "response": "Return object based on child_id_attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends command to tmux with window_id as target.", "response": "def cmd(self, cmd, *args, **kwargs):\n        \"\"\"Return :meth:`Server.cmd` defaulting ``target_window`` as target.\n\n        Send command to tmux with :attr:`window_id` as ``target-window``.\n\n        Specifying ``('-t', 'custom-target')`` or ``('-tcustom_target')`` in\n        ``args`` will override using the object's ``window_id`` as target.\n\n        Returns\n        -------\n        :class:`Server.cmd`\n\n        Notes\n        -----\n        .. versionchanged:: 0.8\n\n            Renamed from ``.tmux`` to ``.cmd``.\n        \"\"\"\n        if not any(arg.startswith('-t') for arg in args):\n            args = ('-t', self.id) + args\n\n        return self.server.cmd(cmd, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_layout(self, layout=None):\n        cmd = ['select-layout', '-t%s:%s' % (self.get('session_id'), self.index)]\n\n        if layout:  # tmux allows select-layout without args\n            cmd.append(layout)\n\n        proc = self.cmd(*cmd)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)", "response": "Wrapper for tmux select - layout <layout."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap for tmux set - window - option", "response": "def set_window_option(self, option, value):\n        \"\"\"\n        Wrapper for ``$ tmux set-window-option <option> <value>``.\n\n        Parameters\n        ----------\n        option : str\n            option to set, e.g. 'aggressive-resize'\n        value : str\n            window option value. True/False will turn in 'on' and 'off',\n            also accepts string of 'on' or 'off' directly.\n\n        Raises\n        ------\n        :exc:`exc.OptionError`, :exc:`exc.UnknownOption`,\n        :exc:`exc.InvalidOption`, :exc:`exc.AmbiguousOption`\n        \"\"\"\n\n        self.server._update_windows()\n\n        if isinstance(value, bool) and value:\n            value = 'on'\n        elif isinstance(value, bool) and not value:\n            value = 'off'\n\n        cmd = self.cmd(\n            'set-window-option',\n            '-t%s:%s' % (self.get('session_id'), self.index),\n            # '-t%s' % self.id,\n            option,\n            value,\n        )\n\n        if isinstance(cmd.stderr, list) and len(cmd.stderr):\n            handle_option_error(cmd.stderr[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_window_options(self, option=None, g=False):\n\n        tmux_args = tuple()\n\n        if g:\n            tmux_args += ('-g',)\n\n        if option:\n            return self.show_window_option(option, g=g)\n        else:\n            tmux_args += ('show-window-options',)\n            cmd = self.cmd(*tmux_args).stdout\n\n        # The shlex.split function splits the args at spaces, while also\n        # retaining quoted sub-strings.\n        #   shlex.split('this is \"a test\"') => ['this', 'is', 'a test']\n        cmd = [tuple(shlex.split(item)) for item in cmd]\n\n        window_options = dict(cmd)\n\n        for key, value in window_options.items():\n            if value.isdigit():\n                window_options[key] = int(value)\n\n        return window_options", "response": "Returns a dict of options for the window."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the options for the current window.", "response": "def show_window_option(self, option, g=False):\n        \"\"\"\n        Return a list of options for the window.\n\n        todo: test and return True/False for on/off string\n\n        Parameters\n        ----------\n        option : str\n        g : bool, optional\n            Pass ``-g`` flag, global. Default False.\n\n        Returns\n        -------\n        str, int\n\n        Raises\n        ------\n        :exc:`exc.OptionError`, :exc:`exc.UnknownOption`,\n        :exc:`exc.InvalidOption`, :exc:`exc.AmbiguousOption`\n        \"\"\"\n\n        tmux_args = tuple()\n\n        if g:\n            tmux_args += ('-g',)\n\n        tmux_args += (option,)\n\n        cmd = self.cmd('show-window-options', *tmux_args)\n\n        if len(cmd.stderr):\n            handle_option_error(cmd.stderr[0])\n\n        if not len(cmd.stdout):\n            return None\n\n        option = [shlex.split(item) for item in cmd.stdout][0]\n\n        if option[1].isdigit():\n            option = (option[0], int(option[1]))\n\n        return option[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rename_window(self, new_name):\n\n        import shlex\n\n        lex = shlex.shlex(new_name)\n        lex.escape = ' '\n        lex.whitespace_split = False\n\n        try:\n            self.cmd('rename-window', new_name)\n            self['window_name'] = new_name\n        except Exception as e:\n            logger.error(e)\n\n        self.server._update_windows()\n\n        return self", "response": "Rename the window with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kill_window(self):\n\n        proc = self.cmd(\n            'kill-window',\n            # '-t:%s' % self.id\n            '-t%s:%s' % (self.get('session_id'), self.index),\n        )\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        self.server._update_windows()", "response": "Kill the current Window object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves the current window to another location.", "response": "def move_window(self, destination=\"\", session=None):\n        \"\"\"\n        Move the current :class:`Window` object ``$ tmux move-window``.\n\n        Parameters\n        ----------\n        destination : str, optional\n            the ``target window`` or index to move the window to, default:\n            empty string\n        session : str, optional\n            the ``target session`` or index to move the window to, default:\n            current session.\n        \"\"\"\n        session = session or self.get('session_id')\n        proc = self.cmd(\n            'move-window',\n            '-s%s:%s' % (self.get('session_id'), self.index),\n            '-t%s:%s' % (session, destination),\n        )\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        self.server._update_windows()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect window. Return self.", "response": "def select_window(self):\n        \"\"\"\n        Select window. Return ``self``.\n\n        To select a window object asynchrously. If a ``window`` object exists\n        and is no longer longer the current window, ``w.select_window()``\n        will make ``w`` the current window.\n\n        Returns\n        -------\n        :class:`Window`\n        \"\"\"\n        target = ('%s:%s' % (self.get('session_id'), self.index),)\n        return self.session.select_window(target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects a specific pane.", "response": "def select_pane(self, target_pane):\n        \"\"\"\n        Return selected :class:`Pane` through ``$ tmux select-pane``.\n\n        Parameters\n        ----------\n        target_pane : str\n            'target_pane', '-U' ,'-D', '-L', '-R', or '-l'.\n\n        Return\n        ------\n        :class:`Pane`\n        \"\"\"\n\n        if target_pane in ['-l', '-U', '-D', '-L', '-R']:\n            proc = self.cmd('select-pane', '-t%s' % self.id, target_pane)\n        else:\n            proc = self.cmd('select-pane', '-t%s' % target_pane)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        return self.attached_pane"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the window and return the created pane.", "response": "def split_window(\n        self, target=None, start_directory=None, attach=True, vertical=True, shell=None\n    ):\n        \"\"\"\n        Split window and return the created :class:`Pane`.\n\n        Used for splitting window and holding in a python object.\n\n        Parameters\n        ----------\n        attach : bool, optional\n            make new window the current window after creating it, default\n            True.\n        start_directory : str, optional\n            specifies the working directory in which the new window is created.\n        target : str\n            ``target_pane`` to split.\n        vertical : str\n            split vertically\n        shell : str, optional\n            execute a command on splitting the window.  The pane will close\n            when the command exits.\n\n            NOTE: When this command exits the pane will close.  This feature\n            is useful for long-running processes where the closing of the\n            window upon completion is desired.\n\n        Returns\n        -------\n        :class:`Pane`\n\n        Notes\n        -----\n\n        :term:`tmux(1)` will move window to the new pane if the\n        ``split-window`` target is off screen. tmux handles the ``-d`` the\n        same way as ``new-window`` and ``attach`` in\n        :class:`Session.new_window`.\n\n        By default, this will make the window the pane is created in\n        active. To remain on the same window and split the pane in another\n        target window, pass in ``attach=False``.\n        \"\"\"\n        pformats = [\n            'session_name',\n            'session_id',\n            'window_index',\n            'window_id',\n        ] + formats.PANE_FORMATS\n        tmux_formats = ['#{%s}\\t' % f for f in pformats]\n\n        # '-t%s' % self.attached_pane.get('pane_id'),\n        # 2013-10-18 LOOK AT THIS, rm'd it..\n        tmux_args = tuple()\n\n        if target:\n            tmux_args += ('-t%s' % target,)\n        else:\n            tmux_args += ('-t%s' % self.panes[0].get('pane_id'),)\n\n        if vertical:\n            tmux_args += ('-v',)\n        else:\n            tmux_args += ('-h',)\n\n        tmux_args += ('-P', '-F%s' % ''.join(tmux_formats))  # output\n\n        if start_directory:\n            # as of 2014-02-08 tmux 1.9-dev doesn't expand ~ in new-window -c.\n            start_directory = os.path.expanduser(start_directory)\n            tmux_args += ('-c%s' % start_directory,)\n\n        if not attach:\n            tmux_args += ('-d',)\n\n        if shell:\n            tmux_args += (shell,)\n\n        pane = self.cmd('split-window', *tmux_args)\n\n        # tmux < 1.7. This is added in 1.7.\n        if pane.stderr:\n            raise exc.LibTmuxException(pane.stderr)\n            if 'pane too small' in pane.stderr:\n                pass\n\n            raise exc.LibTmuxException(pane.stderr, self._info, self.panes)\n        else:\n            pane = pane.stdout[0]\n\n            pane = dict(zip(pformats, pane.split('\\t')))\n\n            # clear up empty dict\n            pane = dict((k, v) for k, v in pane.items() if v)\n\n        return Pane(window=self, **pane)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of attached Pane objects Returns ------- : class:`Pane| None", "response": "def attached_pane(self):\n        \"\"\"\n        Return the attached :class:`Pane`.\n\n        Returns\n        -------\n        :class:`Pane`\n        \"\"\"\n        for pane in self._panes:\n            if 'pane_active' in pane:\n                # for now pane_active is a unicode\n                if pane.get('pane_active') == '1':\n                    return Pane(window=self, **pane)\n                else:\n                    continue\n\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd(self, *args, **kwargs):\n\n        args = list(args)\n        if self.socket_name:\n            args.insert(0, '-L{0}'.format(self.socket_name))\n        if self.socket_path:\n            args.insert(0, '-S{0}'.format(self.socket_path))\n        if self.config_file:\n            args.insert(0, '-f{0}'.format(self.config_file))\n        if self.colors:\n            if self.colors == 256:\n                args.insert(0, '-2')\n            elif self.colors == 88:\n                args.insert(0, '-8')\n            else:\n                raise ValueError('Server.colors must equal 88 or 256')\n\n        return tmux_cmd(*args, **kwargs)", "response": "Execute tmux command and return output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of sessions in tmux - 1 format.", "response": "def _list_sessions(self):\n        \"\"\"\n        Return list of sessions in :py:obj:`dict` form.\n\n        Retrieved from ``$ tmux(1) list-sessions`` stdout.\n\n        The :py:obj:`list` is derived from ``stdout`` in\n        :class:`common.tmux_cmd` which wraps :py:class:`subprocess.Popen`.\n\n        Returns\n        -------\n        list of dict\n        \"\"\"\n\n        sformats = formats.SESSION_FORMATS\n        tmux_formats = ['#{%s}' % f for f in sformats]\n\n        tmux_args = ('-F%s' % '\\t'.join(tmux_formats),)  # output\n\n        proc = self.cmd('list-sessions', *tmux_args)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        sformats = formats.SESSION_FORMATS\n        tmux_formats = ['#{%s}' % format for format in sformats]\n        sessions = proc.stdout\n\n        # combine format keys with values returned from ``tmux list-sessions``\n        sessions = [dict(zip(sformats, session.split('\\t'))) for session in sessions]\n\n        # clear up empty dict\n        sessions = [\n            dict((k, v) for k, v in session.items() if v) for session in sessions\n        ]\n\n        return sessions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning list of windows in tmux - 1. 8 format.", "response": "def _list_windows(self):\n        \"\"\"\n        Return list of windows in :py:obj:`dict` form.\n\n        Retrieved from ``$ tmux(1) list-windows`` stdout.\n\n        The :py:obj:`list` is derived from ``stdout`` in\n        :class:`common.tmux_cmd` which wraps :py:class:`subprocess.Popen`.\n\n        Returns\n        -------\n        list of dict\n        \"\"\"\n\n        wformats = ['session_name', 'session_id'] + formats.WINDOW_FORMATS\n        tmux_formats = ['#{%s}' % format for format in wformats]\n\n        proc = self.cmd(\n            'list-windows',  # ``tmux list-windows``\n            '-a',\n            '-F%s' % '\\t'.join(tmux_formats),  # output\n        )\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        windows = proc.stdout\n\n        wformats = ['session_name', 'session_id'] + formats.WINDOW_FORMATS\n\n        # combine format keys with values returned from ``tmux list-windows``\n        windows = [dict(zip(wformats, window.split('\\t'))) for window in windows]\n\n        # clear up empty dict\n        windows = [dict((k, v) for k, v in window.items() if v) for window in windows]\n\n        # tmux < 1.8 doesn't have window_id, use window_name\n        for w in windows:\n            if 'window_id' not in w:\n                w['window_id'] = w['window_name']\n\n        if self._windows:\n            self._windows[:] = []\n\n        self._windows.extend(windows)\n\n        return self._windows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of panes in dict form.", "response": "def _list_panes(self):\n        \"\"\"\n        Return list of panes in :py:obj:`dict` form.\n\n        Retrieved from ``$ tmux(1) list-panes`` stdout.\n\n        The :py:obj:`list` is derived from ``stdout`` in\n        :class:`util.tmux_cmd` which wraps :py:class:`subprocess.Popen`.\n\n        Returns\n        -------\n        list\n        \"\"\"\n\n        pformats = [\n            'session_name',\n            'session_id',\n            'window_index',\n            'window_id',\n            'window_name',\n        ] + formats.PANE_FORMATS\n        tmux_formats = ['#{%s}\\t' % f for f in pformats]\n\n        proc = self.cmd('list-panes', '-a', '-F%s' % ''.join(tmux_formats))  # output\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        panes = proc.stdout\n\n        pformats = [\n            'session_name',\n            'session_id',\n            'window_index',\n            'window_id',\n            'window_name',\n        ] + formats.PANE_FORMATS\n\n        # combine format keys with values returned from ``tmux list-panes``\n        panes = [dict(zip(pformats, window.split('\\t'))) for window in panes]\n\n        # clear up empty dict\n        panes = [\n            dict(\n                (k, v) for k, v in window.items() if v or k == 'pane_current_path'\n            )  # preserve pane_current_path, in case it entered a new process\n            # where we may not get a cwd from.\n            for window in panes\n        ]\n\n        if self._panes:\n            self._panes[:] = []\n\n        self._panes.extend(panes)\n\n        return self._panes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attached_sessions(self):\n\n        sessions = self._sessions\n        attached_sessions = list()\n\n        for session in sessions:\n            if 'session_attached' in session:\n                # for now session_active is a unicode\n                if session.attached == '1':\n                    logger.debug('session %s attached', session.name)\n                    attached_sessions.append(session)\n                else:\n                    continue\n\n        return [Session(server=self, **s) for s in attached_sessions] or None", "response": "Return a list of active tmux sessions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if session exists.", "response": "def has_session(self, target_session, exact=True):\n        \"\"\"\n        Return True if session exists. ``$ tmux has-session``.\n\n        Parameters\n        ----------\n        target_session : str\n            session name\n        exact : bool\n            match the session name exactly. tmux uses fnmatch by default.\n            Internally prepends ``=`` to the session in ``$ tmux has-session``.\n            tmux 2.1 and up only.\n\n        Raises\n        ------\n        :exc:`exc.BadSessionName`\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        session_check_name(target_session)\n\n        if exact and has_gte_version('2.1'):\n            target_session = '={}'.format(target_session)\n\n        proc = self.cmd('has-session', '-t%s' % target_session)\n\n        if not proc.returncode:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nkilling the tmux session with tmux kill - session.", "response": "def kill_session(self, target_session=None):\n        \"\"\"\n        Kill the tmux session with ``$ tmux kill-session``, return ``self``.\n\n        Parameters\n        ----------\n        target_session : str, optional\n            target_session: str. note this accepts ``fnmatch(3)``. 'asdf' will\n            kill 'asdfasd'.\n\n        Returns\n        -------\n        :class:`Server`\n\n        Raises\n        ------\n        :exc:`exc.BadSessionName`\n        \"\"\"\n        session_check_name(target_session)\n\n        proc = self.cmd('kill-session', '-t%s' % target_session)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattaches a session to a tmux instance.", "response": "def attach_session(self, target_session=None):\n        \"\"\"``$ tmux attach-session`` aka alias: ``$ tmux attach``.\n\n        Parameters\n        ----------\n        target_session : str\n            name of the session. fnmatch(3) works.\n\n        Raises\n        ------\n        :exc:`exc.BadSessionName`\n        \"\"\"\n        session_check_name(target_session)\n\n        tmux_args = tuple()\n        if target_session:\n            tmux_args += ('-t%s' % target_session,)\n\n        proc = self.cmd('attach-session', *tmux_args)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_session(\n        self,\n        session_name=None,\n        kill_session=False,\n        attach=False,\n        start_directory=None,\n        window_name=None,\n        window_command=None,\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        Return :class:`Session` from  ``$ tmux new-session``.\n\n        Uses ``-P`` flag to print session info, ``-F`` for return formatting\n        returns new Session object.\n\n        ``$ tmux new-session -d`` will create the session in the background\n        ``$ tmux new-session -Ad`` will move to the session name if it already\n        exists. todo: make an option to handle this.\n\n        Parameters\n        ----------\n        session_name : str, optional\n            ::\n\n                $ tmux new-session -s <session_name>\n        attach : bool, optional\n            create session in the foreground. ``attach=False`` is equivalent\n            to::\n\n                $ tmux new-session -d\n\n        Other Parameters\n        ----------------\n        kill_session : bool, optional\n            Kill current session if ``$ tmux has-session``.\n            Useful for testing workspaces.\n        start_directory : str, optional\n            specifies the working directory in which the\n            new session is created.\n        window_name : str, optional\n            ::\n\n                $ tmux new-session -n <window_name>\n        window_command : str\n            execute a command on starting the session.  The window will close\n            when the command exits. NOTE: When this command exits the window\n            will close.  This feature is useful for long-running processes\n            where the closing of the window upon completion is desired.\n\n        Returns\n        -------\n        :class:`Session`\n\n        Raises\n        ------\n        :exc:`exc.BadSessionName`\n        \"\"\"\n        session_check_name(session_name)\n\n        if self.has_session(session_name):\n            if kill_session:\n                self.cmd('kill-session', '-t%s' % session_name)\n                logger.info('session %s exists. killed it.' % session_name)\n            else:\n                raise exc.TmuxSessionExists('Session named %s exists' % session_name)\n\n        logger.debug('creating session %s' % session_name)\n\n        sformats = formats.SESSION_FORMATS\n        tmux_formats = ['#{%s}' % f for f in sformats]\n\n        env = os.environ.get('TMUX')\n\n        if env:\n            del os.environ['TMUX']\n\n        tmux_args = (\n            '-s%s' % session_name,\n            '-P',\n            '-F%s' % '\\t'.join(tmux_formats),  # output\n        )\n\n        if not attach:\n            tmux_args += ('-d',)\n\n        if start_directory:\n            tmux_args += ('-c', start_directory)\n\n        if window_name:\n            tmux_args += ('-n', window_name)\n\n        # tmux 2.6 gives unattached sessions a tiny default area\n        # no need send in -x/-y if they're in a client already, though\n        if has_gte_version('2.6') and 'TMUX' not in os.environ:\n            tmux_args += ('-x', 800, '-y', 600)\n\n        if window_command:\n            tmux_args += (window_command,)\n\n        proc = self.cmd('new-session', *tmux_args)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        session = proc.stdout[0]\n\n        if env:\n            os.environ['TMUX'] = env\n\n        # combine format keys with values returned from ``tmux list-windows``\n        session = dict(zip(sformats, session.split('\\t')))\n\n        # clear up empty dict\n        session = dict((k, v) for k, v in session.items() if v)\n\n        session = Session(server=self, **session)\n\n        return session", "response": "Create a new session in the Tmux system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_keys(self, cmd, enter=True, suppress_history=True, literal=False):\n        prefix = ' ' if suppress_history else ''\n\n        if literal:\n            self.cmd('send-keys', '-l', prefix + cmd)\n        else:\n            self.cmd('send-keys', prefix + cmd)\n\n        if enter:\n            self.enter()", "response": "Send keys to the pane."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef display_message(self, cmd, get_text=False):\n        if get_text:\n            return self.cmd('display-message', '-p', cmd).stdout\n        else:\n            self.cmd('display-message', cmd)", "response": "Display a message in target - client status line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits window at pane and return newly created pane.", "response": "def split_window(self, attach=False, vertical=True, start_directory=None):\n        \"\"\"\n        Split window at pane and return newly created :class:`Pane`.\n\n        Parameters\n        ----------\n        attach : bool, optional\n            Attach / select pane after creation.\n        vertical : bool, optional\n            split vertically\n        start_directory : str, optional\n            specifies the working directory in which the new pane is created.\n\n        Returns\n        -------\n        :class:`Pane`\n        \"\"\"\n        return self.window.split_window(\n            target=self.get('pane_id'),\n            start_directory=start_directory,\n            attach=attach,\n            vertical=vertical,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize_pane(self, *args, **kwargs):\n\n        if 'height' in kwargs:\n            proc = self.cmd('resize-pane', '-y%s' % int(kwargs['height']))\n        elif 'width' in kwargs:\n            proc = self.cmd('resize-pane', '-x%s' % int(kwargs['width']))\n        else:\n            proc = self.cmd('resize-pane', args[0])\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        self.server._update_panes()\n        return self", "response": "Execute tmux resize - pane of pane and return self."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cmd(self, *args, **kwargs):\n        # if -t is not set in any arg yet\n        if not any('-t' in text_type(x) for x in args):\n            # insert -t immediately after 1st arg, as per tmux format\n            new_args = [args[0]]\n            new_args += ['-t', self.id]\n            new_args += args[1:]\n            args = new_args\n        return self.server.cmd(*args, **kwargs)", "response": "Return a command that will return the current state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the tmux attach - session aka alias.", "response": "def attach_session(self):\n        \"\"\"Return ``$ tmux attach-session`` aka alias: ``$ tmux attach``.\"\"\"\n        proc = self.cmd('attach-session', '-t%s' % self.id)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nkill the current session.", "response": "def kill_session(self):\n        \"\"\"``$ tmux kill-session``.\"\"\"\n\n        proc = self.cmd('kill-session', '-t%s' % self.id)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswitch client to this session.", "response": "def switch_client(self):\n        \"\"\"\n        Switch client to this session.\n\n        Raises\n        ------\n\n        :exc:`exc.LibTmuxException`\n        \"\"\"\n        proc = self.cmd('switch-client', '-t%s' % self.id)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenames the current session and return new session object.", "response": "def rename_session(self, new_name):\n        \"\"\"\n        Rename session and return new :class:`Session` object.\n\n        Parameters\n        ----------\n        new_name : str\n            new session name\n\n        Returns\n        -------\n        :class:`Session`\n\n        Raises\n        ------\n        :exc:`exc.BadSessionName`\n        \"\"\"\n        session_check_name(new_name)\n\n        proc = self.cmd('rename-session', new_name)\n\n        if proc.stderr:\n            if has_version('2.7') and 'no current client' in proc.stderr:\n                \"\"\"tmux 2.7 raises \"no current client\" warning on BSD systems.\n\n                Should be fixed next release:\n\n                - https://www.mail-archive.com/tech@openbsd.org/msg45186.html\n                - https://marc.info/?l=openbsd-cvs&m=152183263526828&w=2\n                \"\"\"\n                pass\n            else:\n                raise exc.LibTmuxException(proc.stderr)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_window(\n        self,\n        window_name=None,\n        start_directory=None,\n        attach=True,\n        window_index='',\n        window_shell=None,\n    ):\n        \"\"\"\n        Return :class:`Window` from ``$ tmux new-window``.\n\n        By default, this will make the window active. For the new window\n        to be created and not set to current, pass in ``attach=False``.\n\n        Parameters\n        ----------\n        window_name : str, optional\n        start_directory : str, optional\n            working directory in which the new window is created.\n        attach : bool, optional\n            make new window the current window after creating it, default True.\n        window_index : str\n            create the new window at the given index position. Default is empty\n            string which will create the window in the next available position.\n        window_shell : str\n            execute a command on starting the window.  The window will close\n            when the command exits.\n\n            .. note::\n                When this command exits the window will close.  This feature is\n                useful for long-running processes where the closing of the\n                window upon completion is desired.\n\n        Returns\n        -------\n        :class:`Window`\n        \"\"\"\n        wformats = ['session_name', 'session_id'] + formats.WINDOW_FORMATS\n        tmux_formats = ['#{%s}' % f for f in wformats]\n\n        window_args = tuple()\n\n        if not attach:\n            window_args += ('-d',)\n\n        window_args += ('-P',)\n\n        if start_directory:\n            # as of 2014-02-08 tmux 1.9-dev doesn't expand ~ in new-window -c.\n            start_directory = os.path.expanduser(start_directory)\n            window_args += ('-c%s' % start_directory,)\n\n        window_args += ('-F\"%s\"' % '\\t'.join(tmux_formats),)  # output\n        if window_name:\n            window_args += ('-n%s' % window_name,)\n\n        window_args += (\n            # empty string for window_index will use the first one available\n            '-t%s:%s'\n            % (self.id, window_index),\n        )\n\n        if window_shell:\n            window_args += (window_shell,)\n\n        proc = self.cmd('new-window', *window_args)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        window = proc.stdout[0]\n\n        window = dict(zip(wformats, window.split('\\t')))\n\n        # clear up empty dict\n        window = dict((k, v) for k, v in window.items() if v)\n        window = Window(session=self, **window)\n\n        self.server._update_windows()\n\n        return window", "response": "Create a new window from the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nkill the current window or the window at target_window.", "response": "def kill_window(self, target_window=None):\n        \"\"\"Close a tmux window, and all panes inside it, ``$ tmux kill-window``\n\n        Kill the current window or the window at ``target-window``. removing it\n        from any sessions to which it is linked.\n\n        Parameters\n        ----------\n        target_window : str, optional\n            window to kill\n        \"\"\"\n\n        if target_window:\n            if isinstance(target_window, int):\n                target = '-t%s:%d' % (self.name, target_window)\n            else:\n                target = '-t%s' % target_window\n\n        proc = self.cmd('kill-window', target)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        self.server._update_windows()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_windows(self):\n        windows = [w for w in self._windows if w['session_id'] == self._session_id]\n\n        return [Window(session=self, **window) for window in windows]", "response": "Return a list of : class:`Window` from the tmux1 session.\n        Returns\n        -------"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn active Window object.", "response": "def attached_window(self):\n        \"\"\"\n        Return active :class:`Window` object.\n\n        Returns\n        -------\n        :class:`Window`\n        \"\"\"\n        active_windows = []\n        for window in self._windows:\n            if 'window_active' in window:\n                # for now window_active is a unicode\n                if window.get('window_active') == '1':\n                    active_windows.append(Window(session=self, **window))\n                else:\n                    continue\n\n        if len(active_windows) == int(1):\n            return active_windows[0]\n        else:\n            raise exc.LibTmuxException(\n                'multiple active windows found. %s' % active_windows\n            )\n\n        if len(self._windows) == int(0):\n            raise exc.LibTmuxException('No Windows')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_window(self, target_window):\n\n        target = '-t%s' % target_window\n\n        proc = self.cmd('select-window', target)\n\n        if proc.stderr:\n            raise exc.LibTmuxException(proc.stderr)\n\n        return self.attached_window", "response": "Select the first available window in the specified target_window."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_option(self, option, value, _global=False):\n\n        if isinstance(value, bool) and value:\n            value = 'on'\n        elif isinstance(value, bool) and not value:\n            value = 'off'\n\n        tmux_args = tuple()\n\n        if _global:\n            tmux_args += ('-g',)\n\n        tmux_args += (option, value)\n\n        proc = self.cmd('set-option', *tmux_args)\n\n        if isinstance(proc.stderr, list) and len(proc.stderr):\n            handle_option_error(proc.stderr[0])", "response": "Set the value of an option in the current Tmux instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_options(self, option=None, _global=False):\n        tmux_args = tuple()\n\n        if _global:\n            tmux_args += ('-g',)\n\n        if option:\n            return self.show_option(option, _global=_global)\n        else:\n            tmux_args += ('show-options',)\n            session_options = self.cmd(*tmux_args).stdout\n\n        session_options = [tuple(item.split(' ')) for item in session_options]\n\n        session_options = dict(session_options)\n\n        for key, value in session_options.items():\n            if value.isdigit():\n                session_options[key] = int(value)\n\n        return session_options", "response": "Returns a dict of options for the current session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_option(self, option, _global=False):\n\n        tmux_args = tuple()\n\n        if _global:\n            tmux_args += ('-g',)\n\n        tmux_args += (option,)\n\n        cmd = self.cmd('show-options', *tmux_args)\n\n        if isinstance(cmd.stderr, list) and len(cmd.stderr):\n            handle_option_error(cmd.stderr[0])\n\n        if not len(cmd.stdout):\n            return None\n\n        option = [item.split(' ') for item in cmd.stdout][0]\n\n        if option[1].isdigit():\n            option = (option[0], int(option[1]))\n\n        return option[1]", "response": "Show the option for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef openpgp(ctx):\n    try:\n        ctx.obj['controller'] = OpgpController(ctx.obj['dev'].driver)\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            ctx.fail(\"The OpenPGP application can't be found on this \"\n                     'YubiKey.')\n        logger.debug('Failed to load OpenPGP Application', exc_info=e)\n        ctx.fail('Failed to load OpenPGP Application')", "response": "Manage OpenPGP Application.\n\n    Examples:\n\n    \\b\n      Set the retries for PIN, Reset Code and Admin PIN to 10:\n      $ ykman openpgp set-retries 10 10 10\n\n    \\b\n      Require touch to use the authentication key:\n      $ ykman openpgp touch aut on"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(ctx):\n    controller = ctx.obj['controller']\n    click.echo('OpenPGP version: %d.%d.%d' % controller.version)\n    retries = controller.get_remaining_pin_tries()\n    click.echo('PIN tries remaining: {}'.format(retries.pin))\n    click.echo('Reset code tries remaining: {}'.format(retries.reset))\n    click.echo('Admin PIN tries remaining: {}'.format(retries.admin))\n    click.echo()\n    click.echo('Touch policies')\n    click.echo(\n        'Signature key           {.name}'.format(\n            controller.get_touch(KEY_SLOT.SIGNATURE)))\n    click.echo(\n        'Encryption key          {.name}'.format(\n            controller.get_touch(KEY_SLOT.ENCRYPTION)))\n    click.echo(\n        'Authentication key      {.name}'.format(\n            controller.get_touch(KEY_SLOT.AUTHENTICATION)))", "response": "Display status of OpenPGP application."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset all OpenPGP data and all default PINs.", "response": "def reset(ctx):\n    \"\"\"\n    Reset OpenPGP application.\n\n    This action will wipe all OpenPGP data, and set all PINs to their default\n    values.\n    \"\"\"\n    click.echo(\"Resetting OpenPGP data, don't remove your YubiKey...\")\n    ctx.obj['controller'].reset()\n    click.echo('Success! All data has been cleared and default PINs are set.')\n    echo_default_pins()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef touch(ctx, key, policy, admin_pin, force):\n    controller = ctx.obj['controller']\n    old_policy = controller.get_touch(key)\n\n    if old_policy == TOUCH_MODE.FIXED:\n        ctx.fail('A FIXED policy cannot be changed!')\n\n    force or click.confirm('Set touch policy of {.name} key to {.name}?'.format(\n        key, policy), abort=True, err=True)\n    if admin_pin is None:\n        admin_pin = click.prompt('Enter admin PIN', hide_input=True, err=True)\n    controller.set_touch(key, policy, admin_pin.encode('utf8'))", "response": "Set touch policy for OpenPGP keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_pin_retries(ctx, pw_attempts, admin_pin, force):\n    controller = ctx.obj['controller']\n    resets_pins = controller.version < (4, 0, 0)\n    if resets_pins:\n        click.echo('WARNING: Setting PIN retries will reset the values for all '\n                   '3 PINs!')\n    force or click.confirm('Set PIN retry counters to: {} {} {}?'.format(\n        *pw_attempts), abort=True, err=True)\n    controller.set_pin_retries(*(pw_attempts + (admin_pin.encode('utf8'),)))\n    click.echo('PIN retries successfully set.')\n    if resets_pins:\n        click.echo('Default PINs are set.')\n        echo_default_pins()", "response": "Manage pin - retries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmanage PIV Application. Examples: \\b Generate an ECC P-256 private key and a self-signed certificate in slot 9a: $ ykman piv generate-key --algorithm ECCP256 9a pubkey.pem $ ykman piv generate-certificate --subject \"yubico\" 9a pubkey.pem \\b Change the PIN from 123456 to 654321: $ ykman piv change-pin --pin 123456 --new-pin 654321 \\b Reset all PIV data and restore default settings: $ ykman piv reset", "response": "def piv(ctx):\n    \"\"\"\n    Manage PIV Application.\n\n    Examples:\n\n    \\b\n      Generate an ECC P-256 private key and a self-signed certificate in\n      slot 9a:\n      $ ykman piv generate-key --algorithm ECCP256 9a pubkey.pem\n      $ ykman piv generate-certificate --subject \"yubico\" 9a pubkey.pem\n\n    \\b\n      Change the PIN from 123456 to 654321:\n      $ ykman piv change-pin --pin 123456 --new-pin 654321\n\n    \\b\n      Reset all PIV data and restore default settings:\n      $ ykman piv reset\n    \"\"\"\n    try:\n        ctx.obj['controller'] = PivController(ctx.obj['dev'].driver)\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            ctx.fail(\"The PIV application can't be found on this YubiKey.\")\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisplaying status of PIV application.", "response": "def info(ctx):\n    \"\"\"\n    Display status of PIV application.\n    \"\"\"\n    controller = ctx.obj['controller']\n    click.echo('PIV version: %d.%d.%d' % controller.version)\n\n    # Largest possible number of PIN tries to get back is 15\n    tries = controller.get_pin_tries()\n    tries = '15 or more.' if tries == 15 else tries\n    click.echo('PIN tries remaining: %s' % tries)\n    if controller.puk_blocked:\n        click.echo('PUK blocked.')\n    if controller.has_derived_key:\n        click.echo('Management key is derived from PIN.')\n    if controller.has_stored_key:\n        click.echo('Management key is stored on the YubiKey, protected by PIN.')\n    try:\n        chuid = b2a_hex(controller.get_data(OBJ.CHUID)).decode()\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            chuid = 'No data available.'\n    click.echo('CHUID:\\t' + chuid)\n\n    try:\n        ccc = b2a_hex(controller.get_data(OBJ.CAPABILITY)).decode()\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            ccc = 'No data available.'\n    click.echo('CCC: \\t' + ccc)\n\n    for (slot, cert) in controller.list_certificates().items():\n        click.echo('Slot %02x:' % slot)\n\n        try:\n            # Try to read out full DN, fallback to only CN.\n            # Support for DN was added in crytography 2.5\n            subject_dn = cert.subject.rfc4514_string()\n            issuer_dn = cert.issuer.rfc4514_string()\n            print_dn = True\n        except AttributeError:\n            print_dn = False\n            logger.debug('Failed to read DN, falling back to only CNs')\n            subject_cn = cert.subject.get_attributes_for_oid(x509.NameOID.COMMON_NAME)\n            subject_cn = subject_cn[0].value if subject_cn else 'None'\n            issuer_cn = cert.issuer.get_attributes_for_oid(x509.NameOID.COMMON_NAME)\n            issuer_cn = issuer_cn[0].value if issuer_cn else 'None'\n        except ValueError as e:\n            # Malformed certificates may throw ValueError\n            logger.debug('Failed parsing certificate', exc_info=e)\n            click.echo('\\tMalformed certificate: {}'.format(e))\n            continue\n\n        fingerprint = b2a_hex(cert.fingerprint(hashes.SHA256())).decode('ascii')\n        algo = ALGO.from_public_key(cert.public_key())\n        serial = cert.serial_number\n        not_before = cert.not_valid_before\n        not_after = cert.not_valid_after\n\n        # Print out everything\n        click.echo('\\tAlgorithm:\\t%s' % algo.name)\n        if print_dn:\n            click.echo('\\tSubject DN:\\t%s' % subject_dn)\n            click.echo('\\tIssuer DN:\\t%s' % issuer_dn)\n        else:\n            click.echo('\\tSubject CN:\\t%s' % subject_cn)\n            click.echo('\\tIssuer CN:\\t%s' % issuer_cn)\n        click.echo('\\tSerial:\\t\\t%s' % serial)\n        click.echo('\\tFingerprint:\\t%s' % fingerprint)\n        click.echo('\\tNot before:\\t%s' % not_before)\n        click.echo('\\tNot after:\\t%s' % not_after)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(ctx):\n\n    click.echo('Resetting PIV data...')\n    ctx.obj['controller'].reset()\n    click.echo(\n        'Success! All PIV data have been cleared from your YubiKey.')\n    click.echo('Your YubiKey now has the default PIN, PUK and Management Key:')\n    click.echo('\\tPIN:\\t123456')\n    click.echo('\\tPUK:\\t12345678')\n    click.echo(\n        '\\tManagement Key:\\t010203040506070801020304050607080102030405060708')", "response": "Reset all PIV data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an asymmetric key pair.", "response": "def generate_key(\n    ctx, slot, public_key_output, management_key, pin, algorithm,\n        format, pin_policy, touch_policy):\n    \"\"\"\n    Generate an asymmetric key pair.\n\n    The private key is generated on the YubiKey, and written to one of the\n    slots.\n\n    \\b\n    SLOT        PIV slot where private key should be stored.\n    PUBLIC-KEY  File containing the generated public key. Use '-' to use stdout.\n    \"\"\"\n\n    dev = ctx.obj['dev']\n    controller = ctx.obj['controller']\n\n    _ensure_authenticated(ctx, controller, pin, management_key)\n\n    algorithm_id = ALGO.from_string(algorithm)\n\n    if pin_policy:\n        pin_policy = PIN_POLICY.from_string(pin_policy)\n    if touch_policy:\n        touch_policy = TOUCH_POLICY.from_string(touch_policy)\n\n    _check_pin_policy(ctx, dev, controller, pin_policy)\n    _check_touch_policy(ctx, controller, touch_policy)\n\n    try:\n        public_key = controller.generate_key(\n            slot,\n            algorithm_id,\n            pin_policy,\n            touch_policy)\n    except UnsupportedAlgorithm:\n        ctx.fail('Algorithm {} is not supported by this '\n                 'YubiKey.'.format(algorithm))\n\n    key_encoding = format\n    public_key_output.write(public_key.public_bytes(\n            encoding=key_encoding,\n            format=serialization.PublicFormat.SubjectPublicKeyInfo))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_certificate(\n        ctx, slot, management_key, pin, cert, password, verify):\n    \"\"\"\n    Import a X.509 certificate.\n\n    Write a certificate to one of the slots on the YubiKey.\n\n    \\b\n    SLOT            PIV slot to import the certificate to.\n    CERTIFICATE     File containing the certificate. Use '-' to use stdin.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n\n    data = cert.read()\n\n    while True:\n        if password is not None:\n            password = password.encode()\n        try:\n            certs = parse_certificates(data, password)\n        except (ValueError, TypeError):\n            if password is None:\n                password = click.prompt(\n                    'Enter password to decrypt certificate',\n                    default='', hide_input=True,\n                    show_default=False,\n                    err=True)\n                continue\n            else:\n                password = None\n                click.echo('Wrong password.')\n            continue\n        break\n\n    if len(certs) > 1:\n        #  If multiple certs, only import leaf.\n        #  Leaf is the cert with a subject that is not an issuer in the chain.\n        leafs = get_leaf_certificates(certs)\n        cert_to_import = leafs[0]\n    else:\n        cert_to_import = certs[0]\n\n    def do_import(retry=True):\n        try:\n            controller.import_certificate(\n                slot, cert_to_import, verify=verify,\n                touch_callback=prompt_for_touch)\n\n        except KeypairMismatch:\n            ctx.fail('This certificate is not tied to the private key in the '\n                     '{} slot.'.format(slot.name))\n\n        except APDUError as e:\n            if e.sw == SW.SECURITY_CONDITION_NOT_SATISFIED and retry:\n                _verify_pin(ctx, controller, pin)\n                do_import(retry=False)\n            else:\n                raise\n\n    do_import()", "response": "Import a X. 509 certificate to one of the SLOTIAE SLOT."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_key(\n        ctx, slot, management_key, pin, private_key,\n        pin_policy, touch_policy, password):\n    \"\"\"\n    Import a private key.\n\n    Write a private key to one of the slots on the YubiKey.\n\n    \\b\n    SLOT        PIV slot to import the private key to.\n    PRIVATE-KEY File containing the private key. Use '-' to use stdin.\n    \"\"\"\n    dev = ctx.obj['dev']\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n\n    data = private_key.read()\n\n    while True:\n        if password is not None:\n            password = password.encode()\n        try:\n            private_key = parse_private_key(data, password)\n        except (ValueError, TypeError):\n            if password is None:\n                password = click.prompt(\n                    'Enter password to decrypt key',\n                    default='', hide_input=True,\n                    show_default=False,\n                    err=True)\n                continue\n            else:\n                password = None\n                click.echo('Wrong password.')\n            continue\n        break\n\n    if pin_policy:\n        pin_policy = PIN_POLICY.from_string(pin_policy)\n    if touch_policy:\n        touch_policy = TOUCH_POLICY.from_string(touch_policy)\n\n    _check_pin_policy(ctx, dev, controller, pin_policy)\n    _check_touch_policy(ctx, controller, touch_policy)\n    _check_key_size(ctx, controller, private_key)\n\n    controller.import_key(\n            slot,\n            private_key,\n            pin_policy,\n            touch_policy)", "response": "Imports a private key to one of the YubiKey s slot on the YubiKey."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export_certificate(ctx, slot, format, certificate):\n    controller = ctx.obj['controller']\n    try:\n        cert = controller.read_certificate(slot)\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            ctx.fail('No certificate found.')\n        else:\n            logger.error('Failed to read certificate from slot %s', slot,\n                         exc_info=e)\n    certificate.write(cert.public_bytes(encoding=format))", "response": "Export a X. 509 certificate from one of the YubiKey s slots."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates and set a CHUID on the YubiKey.", "response": "def set_chuid(ctx, management_key, pin):\n    \"\"\"\n    Generate and set a CHUID on the YubiKey.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n    controller.update_chuid()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate and set a CCC on the YubiKey.", "response": "def set_ccc(ctx, management_key, pin):\n    \"\"\"\n    Generate and set a CCC on the YubiKey.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n    controller.update_ccc()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the number of PIN and PUK retries for the current application.", "response": "def set_pin_retries(ctx, management_key, pin, pin_retries, puk_retries, force):\n    \"\"\"\n    Set the number of PIN and PUK retries.\n    NOTE: This will reset the PIN and PUK to their factory defaults.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _ensure_authenticated(\n        ctx, controller, pin, management_key, require_pin_and_key=True,\n        no_prompt=force)\n    click.echo('WARNING: This will reset the PIN and PUK to the factory '\n               'defaults!')\n    force or click.confirm('Set PIN and PUK retry counters to: {} {}?'.format(\n        pin_retries, puk_retries), abort=True, err=True)\n    try:\n        controller.set_pin_retries(pin_retries, puk_retries)\n        click.echo('Default PINs are set.')\n        click.echo('PIN:    123456')\n        click.echo('PUK:    12345678')\n    except Exception as e:\n        logger.error('Failed to set PIN retries', exc_info=e)\n        ctx.fail('Setting pin retries failed.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_certificate(\n        ctx, slot, management_key, pin, public_key, subject, valid_days):\n    \"\"\"\n    Generate a self-signed X.509 certificate.\n\n    A self-signed certificate is generated and written to one of the slots on\n    the YubiKey. A private key need to exist in the slot.\n\n    \\b\n    SLOT            PIV slot where private key is stored.\n    PUBLIC-KEY      File containing a public key. Use '-' to use stdin.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _ensure_authenticated(\n        ctx, controller, pin, management_key, require_pin_and_key=True)\n\n    data = public_key.read()\n    public_key = serialization.load_pem_public_key(\n        data, default_backend())\n\n    now = datetime.datetime.now()\n    valid_to = now + datetime.timedelta(days=valid_days)\n\n    try:\n        controller.generate_self_signed_certificate(\n            slot, public_key, subject, now, valid_to,\n            touch_callback=prompt_for_touch)\n\n    except APDUError as e:\n        logger.error('Failed to generate certificate for slot %s', slot,\n                     exc_info=e)\n        ctx.fail('Certificate generation failed.')", "response": "Generate a self - signed X.509 certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_certificate_signing_request(\n        ctx, slot, pin, public_key, csr_output, subject):\n    \"\"\"\n    Generate a Certificate Signing Request (CSR).\n\n    A private key need to exist in the slot.\n\n    \\b\n    SLOT        PIV slot where the private key is stored.\n    PUBLIC-KEY  File containing a public key. Use '-' to use stdin.\n    CSR         File to write CSR to. Use '-' to use stdout.\n    \"\"\"\n    controller = ctx.obj['controller']\n    _verify_pin(ctx, controller, pin)\n\n    data = public_key.read()\n    public_key = serialization.load_pem_public_key(\n        data, default_backend())\n\n    try:\n        csr = controller.generate_certificate_signing_request(\n            slot, public_key, subject, touch_callback=prompt_for_touch)\n    except APDUError:\n        ctx.fail('Certificate Signing Request generation failed.')\n\n    csr_output.write(csr.public_bytes(encoding=serialization.Encoding.PEM))", "response": "Generate a certificate signing request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_certificate(ctx, slot, management_key, pin):\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n    controller.delete_certificate(slot)", "response": "Delete a certificate from a slot on the YubiKey."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the PIN code.", "response": "def change_pin(ctx, pin, new_pin):\n    \"\"\"\n    Change the PIN code.\n\n    The PIN must be between 6 and 8 characters long, and supports any type of\n    alphanumeric characters. For cross-platform compatibility,\n    numeric digits are recommended.\n    \"\"\"\n\n    controller = ctx.obj['controller']\n\n    if not pin:\n        pin = _prompt_pin(ctx, prompt='Enter your current PIN')\n    if not new_pin:\n        new_pin = click.prompt(\n            'Enter your new PIN', default='', hide_input=True,\n            show_default=False, confirmation_prompt=True, err=True)\n\n    if not _valid_pin_length(pin):\n        ctx.fail('Current PIN must be between 6 and 8 characters long.')\n\n    if not _valid_pin_length(new_pin):\n        ctx.fail('New PIN must be between 6 and 8 characters long.')\n\n    try:\n        controller.change_pin(pin, new_pin)\n        click.echo('New PIN set.')\n\n    except AuthenticationBlocked as e:\n        logger.debug('PIN is blocked.', exc_info=e)\n        ctx.fail('PIN is blocked.')\n\n    except WrongPin as e:\n        logger.debug(\n            'Failed to change PIN, %d tries left', e.tries_left, exc_info=e)\n        ctx.fail('PIN change failed - %d tries left.' % e.tries_left)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change_puk(ctx, puk, new_puk):\n    controller = ctx.obj['controller']\n    if not puk:\n        puk = _prompt_pin(ctx, prompt='Enter your current PUK')\n    if not new_puk:\n        new_puk = click.prompt(\n            'Enter your new PUK', default='', hide_input=True,\n            show_default=False, confirmation_prompt=True,\n            err=True)\n\n    if not _valid_pin_length(puk):\n        ctx.fail('Current PUK must be between 6 and 8 characters long.')\n\n    if not _valid_pin_length(new_puk):\n        ctx.fail('New PUK must be between 6 and 8 characters long.')\n\n    try:\n        controller.change_puk(puk, new_puk)\n        click.echo('New PUK set.')\n\n    except AuthenticationBlocked as e:\n        logger.debug('PUK is blocked.', exc_info=e)\n        ctx.fail('PUK is blocked.')\n\n    except WrongPuk as e:\n        logger.debug(\n            'Failed to change PUK, %d tries left', e.tries_left, exc_info=e)\n        ctx.fail('PUK change failed - %d tries left.' % e.tries_left)", "response": "Change the PUK code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the management key.", "response": "def change_management_key(\n        ctx, management_key, pin, new_management_key, touch, protect, generate,\n        force):\n    \"\"\"\n    Change the management key.\n\n    Management functionality is guarded by a 24 byte management key.\n    This key is required for administrative tasks, such as generating key pairs.\n    A random key may be generated and stored on the YubiKey, protected by PIN.\n    \"\"\"\n    controller = ctx.obj['controller']\n\n    pin_verified = _ensure_authenticated(\n        ctx, controller, pin, management_key,\n        require_pin_and_key=protect,\n        mgm_key_prompt='Enter your current management key '\n                       '[blank to use default key]',\n        no_prompt=force)\n\n    if new_management_key and generate:\n        ctx.fail('Invalid options: --new-management-key conflicts with '\n                 '--generate')\n\n    # Touch not supported on NEO.\n    if touch and controller.version < (4, 0, 0):\n        ctx.fail('Require touch not supported on this YubiKey.')\n\n    # If an old stored key needs to be cleared, the PIN is needed.\n    if not pin_verified and controller.has_stored_key:\n        if pin:\n            _verify_pin(ctx, controller, pin, no_prompt=force)\n        elif not force:\n            click.confirm(\n                    'The current management key is stored on the YubiKey'\n                    ' and will not be cleared if no PIN is provided. Continue?',\n                    abort=True, err=True)\n\n    if not new_management_key and not protect:\n        if generate:\n            new_management_key = generate_random_management_key()\n\n            if not protect:\n                click.echo(\n                    'Generated management key: {}'.format(\n                        b2a_hex(new_management_key).decode('utf-8')))\n\n        elif force:\n            ctx.fail('New management key not given. Please remove the --force '\n                     'flag, or set the --generate flag or the '\n                     '--new-management-key option.')\n\n        else:\n            new_management_key = click.prompt(\n                'Enter your new management key',\n                hide_input=True, confirmation_prompt=True, err=True)\n\n    if new_management_key and type(new_management_key) is not bytes:\n        try:\n            new_management_key = a2b_hex(new_management_key)\n        except Exception:\n            ctx.fail('New management key has the wrong format.')\n\n    try:\n        controller.set_mgm_key(\n            new_management_key, touch=touch, store_on_device=protect)\n    except APDUError as e:\n        logger.error('Failed to change management key', exc_info=e)\n        ctx.fail('Changing the management key failed.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unblock_pin(ctx, puk, new_pin):\n    controller = ctx.obj['controller']\n    if not puk:\n        puk = click.prompt(\n            'Enter PUK', default='', show_default=False,\n            hide_input=True, err=True)\n    if not new_pin:\n        new_pin = click.prompt(\n            'Enter a new PIN', default='',\n            show_default=False, hide_input=True, err=True)\n    controller.unblock_pin(puk, new_pin)", "response": "Unblock the PIN using the PUK code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_object(ctx, pin, object_id):\n\n    controller = ctx.obj['controller']\n\n    def do_read_object(retry=True):\n        try:\n            click.echo(controller.get_data(object_id))\n        except APDUError as e:\n            if e.sw == SW.NOT_FOUND:\n                ctx.fail('No data found.')\n            elif e.sw == SW.SECURITY_CONDITION_NOT_SATISFIED:\n                _verify_pin(ctx, controller, pin)\n                do_read_object(retry=False)\n            else:\n                raise\n\n    do_read_object()", "response": "Read arbitrary PIV object by providing the object id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_object(ctx, pin, management_key, object_id, data):\n\n    controller = ctx.obj['controller']\n    _ensure_authenticated(ctx, controller, pin, management_key)\n\n    def do_write_object(retry=True):\n        try:\n            controller.put_data(object_id, data.read())\n        except APDUError as e:\n            logger.debug('Failed writing object', exc_info=e)\n            if e.sw == SW.INCORRECT_PARAMETERS:\n                ctx.fail('Something went wrong, is the object id valid?')\n            raise\n\n    do_write_object()", "response": "Write an arbitrary PIV object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmanages FIDO applications. Examples: \\b Reset the FIDO (FIDO2 and U2F) applications: $ ykman fido reset \\b Change the FIDO2 PIN from 123456 to 654321: $ ykman fido set-pin --pin 123456 --new-pin 654321", "response": "def fido(ctx):\n    \"\"\"\n    Manage FIDO applications.\n\n    Examples:\n\n    \\b\n      Reset the FIDO (FIDO2 and U2F) applications:\n      $ ykman fido reset\n\n    \\b\n      Change the FIDO2 PIN from 123456 to 654321:\n      $ ykman fido set-pin --pin 123456 --new-pin 654321\n\n    \"\"\"\n    dev = ctx.obj['dev']\n    if dev.is_fips:\n        try:\n            ctx.obj['controller'] = FipsU2fController(dev.driver)\n        except Exception as e:\n            logger.debug('Failed to load FipsU2fController', exc_info=e)\n            ctx.fail('Failed to load FIDO Application.')\n    else:\n        try:\n            ctx.obj['controller'] = Fido2Controller(dev.driver)\n        except Exception as e:\n            logger.debug('Failed to load Fido2Controller', exc_info=e)\n            ctx.fail('Failed to load FIDO 2 Application.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef info(ctx):\n    controller = ctx.obj['controller']\n\n    if controller.is_fips:\n        click.echo('FIPS Approved Mode: {}'.format(\n                'Yes' if controller.is_in_fips_mode else 'No'))\n    else:\n        if controller.has_pin:\n            try:\n                click.echo(\n                    'PIN is set, with {} tries left.'.format(\n                        controller.get_pin_retries()))\n            except CtapError as e:\n                if e.code == CtapError.ERR.PIN_BLOCKED:\n                    click.echo('PIN is blocked.')\n        else:\n            click.echo('PIN is not set.')", "response": "Display status of FIDO2 application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_pin(ctx, pin, new_pin, u2f):\n\n    controller = ctx.obj['controller']\n    is_fips = controller.is_fips\n\n    if is_fips and not u2f:\n        ctx.fail('This is a YubiKey FIPS. To set the U2F PIN, pass the --u2f '\n                 'option.')\n\n    if u2f and not is_fips:\n        ctx.fail('This is not a YubiKey FIPS, and therefore does not support a '\n                 'U2F PIN. To set the FIDO2 PIN, remove the --u2f option.')\n\n    def prompt_new_pin():\n        return click.prompt(\n                    'Enter your new PIN', default='', hide_input=True,\n                    show_default=False, confirmation_prompt=True, err=True)\n\n    def change_pin(pin, new_pin):\n        if pin is not None:\n            _fail_if_not_valid_pin(ctx, pin, is_fips)\n        _fail_if_not_valid_pin(ctx, new_pin, is_fips)\n        try:\n            if is_fips:\n                try:\n                    # Failing this with empty current PIN does not cost a retry\n                    controller.change_pin(old_pin=pin or '', new_pin=new_pin)\n                except ApduError as e:\n                    if e.code == SW.WRONG_LENGTH:\n                        pin = _prompt_current_pin()\n                        _fail_if_not_valid_pin(ctx, pin, is_fips)\n                        controller.change_pin(old_pin=pin, new_pin=new_pin)\n                    else:\n                        raise\n\n            else:\n                controller.change_pin(old_pin=pin, new_pin=new_pin)\n\n        except CtapError as e:\n            if e.code == CtapError.ERR.PIN_INVALID:\n                ctx.fail('Wrong PIN.')\n            if e.code == CtapError.ERR.PIN_AUTH_BLOCKED:\n                ctx.fail(\n                    'PIN authentication is currently blocked. '\n                    'Remove and re-insert the YubiKey.')\n            if e.code == CtapError.ERR.PIN_BLOCKED:\n                ctx.fail('PIN is blocked.')\n            if e.code == CtapError.ERR.PIN_POLICY_VIOLATION:\n                ctx.fail('New PIN is too long.')\n            logger.error('Failed to change PIN', exc_info=e)\n            ctx.fail('Failed to change PIN.')\n\n        except ApduError as e:\n            if e.code == SW.VERIFY_FAIL_NO_RETRY:\n                ctx.fail('Wrong PIN.')\n\n            if e.code == SW.AUTH_METHOD_BLOCKED:\n                ctx.fail('PIN is blocked.')\n\n            logger.error('Failed to change PIN', exc_info=e)\n            ctx.fail('Failed to change PIN.')\n\n    def set_pin(new_pin):\n        _fail_if_not_valid_pin(ctx, new_pin, is_fips)\n        try:\n            controller.set_pin(new_pin)\n        except CtapError as e:\n            if e.code == CtapError.ERR.PIN_POLICY_VIOLATION:\n                ctx.fail('PIN is too long.')\n            logger.error('Failed to set PIN', exc_info=e)\n            ctx.fail('Failed to set PIN')\n\n    if pin and not controller.has_pin:\n        ctx.fail('There is no current PIN set. Use --new-pin to set one.')\n\n    if controller.has_pin and pin is None and not is_fips:\n        pin = _prompt_current_pin()\n\n    if not new_pin:\n        new_pin = prompt_new_pin()\n\n    if controller.has_pin:\n        change_pin(pin, new_pin)\n    else:\n        set_pin(new_pin)", "response": "Set or change the PIN code for the YubiKey FIPS."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets all applications in the YubiKey.", "response": "def reset(ctx, force):\n    \"\"\"\n    Reset all FIDO applications.\n\n    This action will wipe all FIDO credentials, including FIDO U2F credentials,\n    on the YubiKey and remove the PIN code.\n\n    The reset must be triggered immediately after the YubiKey is\n    inserted, and requires a touch on the YubiKey.\n    \"\"\"\n\n    n_keys = len(list(get_descriptors()))\n    if n_keys > 1:\n        ctx.fail('Only one YubiKey can be connected to perform a reset.')\n\n    if not force:\n        if not click.confirm('WARNING! This will delete all FIDO credentials, '\n                             'including FIDO U2F credentials, and restore '\n                             'factory settings. Proceed?',\n                             err=True):\n            ctx.abort()\n\n    def prompt_re_insert_key():\n        click.echo('Remove and re-insert your YubiKey to perform the reset...')\n\n        removed = False\n        while True:\n            sleep(0.1)\n            n_keys = len(list(get_descriptors()))\n            if not n_keys:\n                removed = True\n            if removed and n_keys == 1:\n                return\n\n    def try_reset(controller_type):\n        if not force:\n            prompt_re_insert_key()\n            dev = list(get_descriptors())[0].open_device(TRANSPORT.FIDO)\n            controller = controller_type(dev.driver)\n            controller.reset(touch_callback=prompt_for_touch)\n        else:\n            controller = ctx.obj['controller']\n            controller.reset(touch_callback=prompt_for_touch)\n\n    if ctx.obj['dev'].is_fips:\n        if not force:\n            destroy_input = click.prompt(\n                'WARNING! This is a YubiKey FIPS device. This command will '\n                'also overwrite the U2F attestation key; this action cannot be '\n                'undone and this YubiKey will no longer be a FIPS compliant '\n                'device.\\n'\n                'To proceed, please enter the text \"OVERWRITE\"',\n                default='',\n                show_default=False,\n                err=True\n            )\n            if destroy_input != 'OVERWRITE':\n                ctx.fail('Reset aborted by user.')\n\n        try:\n            try_reset(FipsU2fController)\n\n        except ApduError as e:\n            if e.code == SW.COMMAND_NOT_ALLOWED:\n                ctx.fail(\n                    'Reset failed. Reset must be triggered within 5 seconds'\n                    ' after the YubiKey is inserted.')\n            else:\n                logger.error('Reset failed', exc_info=e)\n                ctx.fail('Reset failed.')\n\n        except Exception as e:\n            logger.error('Reset failed', exc_info=e)\n            ctx.fail('Reset failed.')\n\n    else:\n        try:\n            try_reset(Fido2Controller)\n        except CtapError as e:\n            if e.code == CtapError.ERR.ACTION_TIMEOUT:\n                ctx.fail(\n                    'Reset failed. You need to touch your'\n                    ' YubiKey to confirm the reset.')\n            elif e.code == CtapError.ERR.NOT_ALLOWED:\n                ctx.fail(\n                    'Reset failed. Reset must be triggered within 5 seconds'\n                    ' after the YubiKey is inserted.')\n            else:\n                logger.error(e)\n                ctx.fail('Reset failed.')\n        except Exception as e:\n            logger.error(e)\n            ctx.fail('Reset failed.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unlock(ctx, pin):\n\n    controller = ctx.obj['controller']\n    if not controller.is_fips:\n        ctx.fail('This is not a YubiKey FIPS, and therefore'\n                 ' does not support a U2F PIN.')\n\n    if pin is None:\n        pin = _prompt_current_pin('Enter your PIN')\n\n    _fail_if_not_valid_pin(ctx, pin, True)\n    try:\n        controller.verify_pin(pin)\n    except ApduError as e:\n        if e.code == SW.VERIFY_FAIL_NO_RETRY:\n            ctx.fail('Wrong PIN.')\n        if e.code == SW.AUTH_METHOD_BLOCKED:\n            ctx.fail('PIN is blocked.')\n        if e.code == SW.COMMAND_NOT_ALLOWED:\n            ctx.fail('PIN is not set.')\n\n        logger.error('PIN verification failed', exc_info=e)\n        ctx.fail('PIN verification failed.')", "response": "Unlock the YubiKey FIPS and allow U2F registration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_pin_tries(self):\n        # Verify without PIN gives number of tries left.\n        _, sw = self.send_cmd(INS.VERIFY, 0, PIN, check=None)\n        return tries_left(sw, self.version)", "response": "Returns the number of PIN retries left."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncommanding line interface for YubiKey list.", "response": "def cli(ctx, device, log_level, log_file, reader):\n    \"\"\"\n    Configure your YubiKey via the command line.\n\n    Examples:\n\n    \\b\n      List connected YubiKeys, only output serial number:\n      $ ykman list --serials\n\n    \\b\n      Show information about YubiKey with serial number 0123456:\n      $ ykman --device 0123456 info\n    \"\"\"\n    ctx.obj = YkmanContextObject()\n\n    if log_level:\n        ykman.logging_setup.setup(log_level, log_file=log_file)\n\n    if reader and device:\n        ctx.fail('--reader and --device options can\\'t be combined.')\n\n    subcmd = next(c for c in COMMANDS if c.name == ctx.invoked_subcommand)\n    if subcmd == list_keys:\n        if reader:\n            ctx.fail('--reader and list command can\\'t be combined.')\n        return\n\n    transports = getattr(subcmd, 'transports', TRANSPORT.usb_transports())\n    if transports:\n        def resolve_device():\n            if device is not None:\n                dev = _run_cmd_for_serial(ctx, subcmd.name, transports, device)\n            else:\n                dev = _run_cmd_for_single(ctx, subcmd.name, transports, reader)\n            ctx.call_on_close(dev.close)\n            return dev\n        ctx.obj.add_resolver('dev', resolve_device)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef otp(ctx, access_code):\n\n    ctx.obj['controller'] = OtpController(ctx.obj['dev'].driver)\n    if access_code is not None:\n        if access_code == '':\n            access_code = click.prompt(\n                'Enter access code', show_default=False, err=True)\n\n        try:\n            access_code = parse_access_code_hex(access_code)\n        except Exception as e:\n            ctx.fail('Failed to parse access code: ' + str(e))\n\n    ctx.obj['controller'].access_code = access_code", "response": "Manage the YubiKey OTP Application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef info(ctx):\n    dev = ctx.obj['dev']\n    controller = ctx.obj['controller']\n    slot1, slot2 = controller.slot_status\n\n    click.echo('Slot 1: {}'.format(slot1 and 'programmed' or 'empty'))\n    click.echo('Slot 2: {}'.format(slot2 and 'programmed' or 'empty'))\n\n    if dev.is_fips:\n        click.echo('FIPS Approved Mode: {}'.format(\n            'Yes' if controller.is_in_fips_mode else 'No'))", "response": "Display status of YubiKey Slots."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef swap(ctx):\n    controller = ctx.obj['controller']\n    click.echo('Swapping slots...')\n    try:\n        controller.swap_slots()\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)", "response": "Swaps the two slot configurations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ndef(ctx, slot, prefix):\n    dev = ctx.obj['dev']\n    controller = ctx.obj['controller']\n    if not dev.config.nfc_supported:\n        ctx.fail('NFC interface not available.')\n\n    if not controller.slot_status[slot - 1]:\n        ctx.fail('Slot {} is empty.'.format(slot))\n\n    try:\n        if prefix:\n            controller.configure_ndef_slot(slot, prefix)\n        else:\n            controller.configure_ndef_slot(slot)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)", "response": "Configure NDEF for a given slot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the configuration of a slot.", "response": "def delete(ctx, slot, force):\n    \"\"\"\n    Deletes the configuration of a slot.\n    \"\"\"\n    controller = ctx.obj['controller']\n    if not force and not controller.slot_status[slot - 1]:\n        ctx.fail('Not possible to delete an empty slot.')\n    force or click.confirm(\n        'Do you really want to delete'\n        ' the configuration of slot {}?'.format(slot), abort=True, err=True)\n    click.echo('Deleting the configuration of slot {}...'.format(slot))\n    try:\n        controller.zap_slot(slot)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef yubiotp(ctx, slot, public_id, private_id, key, no_enter, force,\n            serial_public_id, generate_private_id,\n            generate_key):\n    \"\"\"\n    Program a Yubico OTP credential.\n\n    \"\"\"\n\n    dev = ctx.obj['dev']\n    controller = ctx.obj['controller']\n\n    if public_id and serial_public_id:\n        ctx.fail('Invalid options: --public-id conflicts with '\n                 '--serial-public-id.')\n\n    if private_id and generate_private_id:\n        ctx.fail('Invalid options: --private-id conflicts with '\n                 '--generate-public-id.')\n\n    if key and generate_key:\n        ctx.fail('Invalid options: --key conflicts with --generate-key.')\n\n    if not public_id:\n        if serial_public_id:\n            if dev.serial is None:\n                ctx.fail('Serial number not set, public ID must be provided')\n            public_id = modhex_encode(\n                b'\\xff\\x00' + struct.pack(b'>I', dev.serial))\n            click.echo(\n                'Using YubiKey serial as public ID: {}'.format(public_id))\n        elif force:\n            ctx.fail(\n                'Public ID not given. Please remove the --force flag, or '\n                'add the --serial-public-id flag or --public-id option.')\n        else:\n            public_id = click.prompt('Enter public ID', err=True)\n\n    try:\n        public_id = modhex_decode(public_id)\n    except KeyError:\n        ctx.fail('Invalid public ID, must be modhex.')\n\n    if not private_id:\n        if generate_private_id:\n            private_id = os.urandom(6)\n            click.echo(\n                'Using a randomly generated private ID: {}'.format(\n                    b2a_hex(private_id).decode('ascii')))\n        elif force:\n            ctx.fail(\n                'Private ID not given. Please remove the --force flag, or '\n                'add the --generate-private-id flag or --private-id option.')\n        else:\n            private_id = click.prompt('Enter private ID', err=True)\n            private_id = a2b_hex(private_id)\n\n    if not key:\n        if generate_key:\n            key = os.urandom(16)\n            click.echo(\n                'Using a randomly generated secret key: {}'.format(\n                    b2a_hex(key).decode('ascii')))\n        elif force:\n            ctx.fail('Secret key not given. Please remove the --force flag, or '\n                     'add the --generate-key flag or --key option.')\n        else:\n            key = click.prompt('Enter secret key', err=True)\n            key = a2b_hex(key)\n\n    force or click.confirm('Program an OTP credential in slot {}?'.format(slot),\n                           abort=True, err=True)\n    try:\n        controller.program_otp(slot, key, public_id, private_id, not no_enter)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)", "response": "Generate a YubiKey OTP credential."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef static(\n        ctx, slot, password, generate, length,\n        keyboard_layout, no_enter, force):\n    \"\"\"\n    Configure a static password.\n\n    To avoid problems with different keyboard layouts, the following characters\n    are allowed by default: cbdefghijklnrtuv\n\n    Use the --keyboard-layout option to allow more characters based on\n    preferred keyboard layout.\n    \"\"\"\n\n    controller = ctx.obj['controller']\n    keyboard_layout = KEYBOARD_LAYOUT[keyboard_layout]\n\n    if password and len(password) > 38:\n        ctx.fail('Password too long (maximum length is 38 characters).')\n    if generate and not length:\n        ctx.fail('Provide a length for the generated password.')\n\n    if not password and not generate:\n        password = click.prompt('Enter a static password', err=True)\n    elif not password and generate:\n        password = generate_static_pw(length, keyboard_layout)\n\n    if not force:\n        _confirm_slot_overwrite(controller, slot)\n    try:\n        controller.program_static(\n            slot, password, not no_enter, keyboard_layout=keyboard_layout)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)", "response": "Configure a static password for a specific slot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chalresp(ctx, slot, key, totp, touch, force, generate):\n    controller = ctx.obj['controller']\n\n    if key:\n        if generate:\n            ctx.fail('Invalid options: --generate conflicts with KEY argument.')\n        elif totp:\n            key = parse_b32_key(key)\n        else:\n            key = parse_key(key)\n    else:\n        if force and not generate:\n            ctx.fail('No secret key given. Please remove the --force flag, '\n                     'set the KEY argument or set the --generate flag.')\n        elif totp:\n            while True:\n                key = click.prompt('Enter a secret key (base32)', err=True)\n                try:\n                    key = parse_b32_key(key)\n                    break\n                except Exception as e:\n                    click.echo(e)\n        else:\n            if generate:\n                key = os.urandom(20)\n                click.echo('Using a randomly generated key: {}'.format(\n                    b2a_hex(key).decode('ascii')))\n            else:\n                key = click.prompt('Enter a secret key', err=True)\n                key = parse_key(key)\n\n    cred_type = 'TOTP' if totp else 'challenge-response'\n    force or click.confirm('Program a {} credential in slot {}?'\n                           .format(cred_type, slot), abort=True, err=True)\n    try:\n        controller.program_chalresp(slot, key, touch)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)", "response": "Program a challenge - response credential."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates a challenge - response on a YubiKey slot.", "response": "def calculate(ctx, slot, challenge, totp, digits):\n    \"\"\"\n    Perform a challenge-response operation.\n\n    Send a challenge (in hex) to a YubiKey slot with a challenge-response\n    credential, and read the response. Supports output as a OATH-TOTP code.\n    \"\"\"\n    controller = ctx.obj['controller']\n    if not challenge and not totp:\n        ctx.fail('No challenge provided.')\n\n    # Check that slot is not empty\n    slot1, slot2 = controller.slot_status\n    if (slot == 1 and not slot1) or (slot == 2 and not slot2):\n        ctx.fail('Cannot perform challenge-response on an empty slot.')\n\n    # Timestamp challenge should be int\n    if challenge and totp:\n        try:\n            challenge = int(challenge)\n        except Exception as e:\n            logger.error('Error', exc_info=e)\n            ctx.fail('Timestamp challenge for TOTP must be an integer.')\n    try:\n        res = controller.calculate(\n            slot, challenge, totp=totp,\n            digits=int(digits), wait_for_touch=False)\n    except YkpersError as e:\n        # Touch is set\n        if e.errno == 11:\n            prompt_for_touch()\n            try:\n                res = controller.calculate(\n                    slot, challenge, totp=totp,\n                    digits=int(digits), wait_for_touch=True)\n            except YkpersError as e:\n                # Touch timed out\n                if e.errno == 4:\n                    ctx.fail('The YubiKey timed out.')\n                else:\n                    ctx.fail(e)\n        else:\n            ctx.fail('Failed to calculate challenge.')\n    click.echo(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprograms a HOTP credential in a resource.", "response": "def hotp(ctx, slot, key, digits, counter, no_enter, force):\n    \"\"\"\n    Program an HMAC-SHA1 OATH-HOTP credential.\n\n    \"\"\"\n    controller = ctx.obj['controller']\n    if not key:\n        while True:\n            key = click.prompt('Enter a secret key (base32)', err=True)\n            try:\n                key = parse_b32_key(key)\n                break\n            except Exception as e:\n                click.echo(e)\n\n    force or click.confirm(\n        'Program a HOTP credential in slot {}?'.format(slot), abort=True,\n        err=True)\n    try:\n        controller.program_hotp(\n            slot, key, counter, int(digits) == 8, not no_enter)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef settings(ctx, slot, new_access_code, delete_access_code, enter, pacing,\n             force):\n    \"\"\"\n    Update the settings for a slot.\n\n    Change the settings for a slot without changing the stored secret.\n    All settings not specified will be written with default values.\n    \"\"\"\n    controller = ctx.obj['controller']\n\n    if (new_access_code is not None) and delete_access_code:\n        ctx.fail('--new-access-code conflicts with --delete-access-code.')\n\n    if not controller.slot_status[slot - 1]:\n        ctx.fail('Not possible to update settings on an empty slot.')\n\n    if new_access_code is not None:\n        if new_access_code == '':\n            new_access_code = click.prompt(\n                'Enter new access code', show_default=False, err=True)\n\n        try:\n            new_access_code = parse_access_code_hex(new_access_code)\n        except Exception as e:\n            ctx.fail('Failed to parse access code: ' + str(e))\n\n    force or click.confirm(\n        'Update the settings for slot {}? '\n        'All existing settings will be overwritten.'.format(slot), abort=True,\n        err=True)\n    click.echo('Updating settings for slot {}...'.format(slot))\n\n    if pacing is not None:\n        pacing = int(pacing)\n\n    try:\n        controller.update_settings(slot, enter=enter, pacing=pacing)\n    except YkpersError as e:\n        _failed_to_write_msg(ctx, e)\n\n    if new_access_code:\n        try:\n            controller.set_access_code(slot, new_access_code)\n        except Exception as e:\n            logger.error('Failed to set access code', exc_info=e)\n            ctx.fail('Failed to set access code: ' + str(e))\n\n    if delete_access_code:\n        try:\n            controller.delete_access_code(slot)\n        except Exception as e:\n            logger.error('Failed to delete access code', exc_info=e)\n            ctx.fail('Failed to delete access code: ' + str(e))", "response": "Update the settings for a slot."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmanages connection modes of a YubiKey.", "response": "def mode(ctx, mode, touch_eject, autoeject_timeout, chalresp_timeout, force):\n    \"\"\"\n    Manage connection modes (USB Interfaces).\n\n    Get the current connection mode of the YubiKey, or set it to MODE.\n\n    MODE can be a string, such as \"OTP+FIDO+CCID\", or a shortened form: \"o+f+c\".\n    It can also be a mode number.\n\n    Examples:\n\n    \\b\n      Set the OTP and FIDO mode:\n      $ ykman mode OTP+FIDO\n\n    \\b\n      Set the CCID only mode and use touch to eject the smart card:\n      $ ykman mode CCID --touch-eject\n    \"\"\"\n    dev = ctx.obj['dev']\n    if autoeject_timeout:\n        touch_eject = True\n    autoeject = autoeject_timeout if touch_eject else None\n\n    if mode is not None:\n        if mode.transports != TRANSPORT.CCID:\n            autoeject = None\n            if touch_eject:\n                ctx.fail('--touch-eject can only be used when setting'\n                         ' CCID-only mode')\n\n        if not force:\n            if mode == dev.mode:\n                click.echo('Mode is already {}, nothing to do...'.format(mode))\n                ctx.exit()\n            elif not dev.has_mode(mode):\n                click.echo('Mode {} is not supported on this YubiKey!'\n                           .format(mode))\n                ctx.fail('Use --force to attempt to set it anyway.')\n            force or click.confirm('Set mode of YubiKey to {}?'.format(mode),\n                                   abort=True, err=True)\n\n        try:\n            dev.set_mode(mode, chalresp_timeout, autoeject)\n            if not dev.can_write_config:\n                click.echo(\n                    'Mode set! You must remove and re-insert your YubiKey '\n                    'for this change to take effect.')\n        except ModeSwitchError as e:\n            logger.debug('Failed to switch mode', exc_info=e)\n            click.echo('Failed to switch mode on the YubiKey. Make sure your '\n                       'YubiKey does not have an access code set.')\n\n    else:\n        click.echo('Current connection mode is: {}'.format(dev.mode))\n        supported = ', '.join(t.name for t in TRANSPORT\n                              .split(dev.config.usb_supported))\n        click.echo('Supported USB interfaces are: {}'.format(supported))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a cryptography private key and returns a cryptography private key object.", "response": "def parse_private_key(data, password):\n    \"\"\"\n    Identifies, decrypts and returns a cryptography private key object.\n    \"\"\"\n    # PEM\n    if is_pem(data):\n        if b'ENCRYPTED' in data:\n            if password is None:\n                raise TypeError('No password provided for encrypted key.')\n        try:\n            return serialization.load_pem_private_key(\n                data, password, backend=default_backend())\n        except ValueError:\n            # Cryptography raises ValueError if decryption fails.\n            raise\n        except Exception:\n            pass\n\n    # PKCS12\n    if is_pkcs12(data):\n        try:\n            p12 = crypto.load_pkcs12(data, password)\n            data = crypto.dump_privatekey(\n                crypto.FILETYPE_PEM, p12.get_privatekey())\n            return serialization.load_pem_private_key(\n                data, password=None, backend=default_backend())\n        except crypto.Error as e:\n            raise ValueError(e)\n\n    # DER\n    try:\n        return serialization.load_der_private_key(\n            data, password, backend=default_backend())\n    except Exception:\n        pass\n\n    # All parsing failed\n    raise ValueError('Could not parse private key.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the certificate data and returns list of cryptography x509 certificates.", "response": "def parse_certificates(data, password):\n    \"\"\"\n    Identifies, decrypts and returns list of cryptography x509 certificates.\n    \"\"\"\n\n    # PEM\n    if is_pem(data):\n        certs = []\n        for cert in data.split(PEM_IDENTIFIER):\n            try:\n                certs.append(\n                    x509.load_pem_x509_certificate(\n                        PEM_IDENTIFIER + cert, default_backend()))\n            except Exception:\n                pass\n        # Could be valid PEM but not certificates.\n        if len(certs) > 0:\n            return certs\n\n    # PKCS12\n    if is_pkcs12(data):\n        try:\n            p12 = crypto.load_pkcs12(data, password)\n            data = crypto.dump_certificate(\n                crypto.FILETYPE_PEM, p12.get_certificate())\n            return [x509.load_pem_x509_certificate(data, default_backend())]\n        except crypto.Error as e:\n            raise ValueError(e)\n\n    # DER\n    try:\n        return [x509.load_der_x509_certificate(data, default_backend())]\n    except Exception:\n        pass\n\n    raise ValueError('Could not parse certificate.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the leaf certificates from a list of certificates.", "response": "def get_leaf_certificates(certs):\n    \"\"\"\n    Extracts the leaf certificates from a list of certificates. Leaf\n    certificates are ones whose subject does not appear as issuer among the\n    others.\n    \"\"\"\n    issuers = [cert.issuer.get_attributes_for_oid(x509.NameOID.COMMON_NAME)\n               for cert in certs]\n    leafs = [cert for cert in certs\n             if (cert.subject.get_attributes_for_oid(x509.NameOID.COMMON_NAME)\n                 not in issuers)]\n    return leafs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_pkcs12(data):\n    if isinstance(data, bytes):\n        tlv = Tlv(data)\n        if tlv.tag == 0x30:\n            header = Tlv(tlv.value)\n            return header.tag == 0x02 and header.value == b'\\x03'\n        return False\n    else:\n        return False", "response": "Tries to identify a PKCS12 container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_lock_code(ctx, lock_code, new_lock_code, clear, generate, force):\n\n    dev = ctx.obj['dev']\n\n    def prompt_new_lock_code():\n        return prompt_lock_code(prompt='Enter your new lock code')\n\n    def prompt_current_lock_code():\n        return prompt_lock_code(prompt='Enter your current lock code')\n\n    def change_lock_code(lock_code, new_lock_code):\n        lock_code = _parse_lock_code(ctx, lock_code)\n        new_lock_code = _parse_lock_code(ctx, new_lock_code)\n        try:\n            dev.write_config(\n                device_config(\n                    config_lock=new_lock_code),\n                reboot=True,\n                lock_key=lock_code)\n        except Exception as e:\n            logger.error('Changing the lock code failed', exc_info=e)\n            ctx.fail('Failed to change the lock code. Wrong current code?')\n\n    def set_lock_code(new_lock_code):\n        new_lock_code = _parse_lock_code(ctx, new_lock_code)\n        try:\n            dev.write_config(\n                device_config(\n                    config_lock=new_lock_code),\n                reboot=True)\n        except Exception as e:\n            logger.error('Setting the lock code failed', exc_info=e)\n            ctx.fail('Failed to set the lock code.')\n\n    if generate and new_lock_code:\n        ctx.fail('Invalid options: --new-lock-code conflicts with --generate.')\n\n    if clear:\n        new_lock_code = CLEAR_LOCK_CODE\n\n    if generate:\n        new_lock_code = b2a_hex(os.urandom(16)).decode('utf-8')\n        click.echo(\n            'Using a randomly generated lock code: {}'.format(new_lock_code))\n        force or click.confirm(\n            'Lock configuration with this lock code?', abort=True, err=True)\n\n    if dev.config.configuration_locked:\n        if lock_code:\n            if new_lock_code:\n                change_lock_code(lock_code, new_lock_code)\n            else:\n                new_lock_code = prompt_new_lock_code()\n                change_lock_code(lock_code, new_lock_code)\n        else:\n            if new_lock_code:\n                lock_code = prompt_current_lock_code()\n                change_lock_code(lock_code, new_lock_code)\n            else:\n                lock_code = prompt_current_lock_code()\n                new_lock_code = prompt_new_lock_code()\n                change_lock_code(lock_code, new_lock_code)\n    else:\n        if lock_code:\n            ctx.fail(\n                'There is no current lock code set. '\n                'Use --new-lock-code to set one.')\n        else:\n            if new_lock_code:\n                set_lock_code(new_lock_code)\n            else:\n                new_lock_code = prompt_new_lock_code()\n                set_lock_code(new_lock_code)", "response": "Set or change the configuration lock code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef usb(\n        ctx, enable, disable, list, enable_all, touch_eject, no_touch_eject,\n        autoeject_timeout, chalresp_timeout, lock_code, force):\n    \"\"\"\n    Enable or disable applications over USB.\n    \"\"\"\n\n    def ensure_not_all_disabled(ctx, usb_enabled):\n        for app in APPLICATION:\n            if app & usb_enabled:\n                return\n        ctx.fail('Can not disable all applications over USB.')\n\n    if not (list or\n            enable_all or\n            enable or\n            disable or\n            touch_eject or\n            no_touch_eject or\n            autoeject_timeout or\n            chalresp_timeout):\n        ctx.fail('No configuration options chosen.')\n\n    enable = APPLICATION.__members__.keys() if enable_all else enable\n\n    _ensure_not_invalid_options(ctx, enable, disable)\n\n    if touch_eject and no_touch_eject:\n        ctx.fail('Invalid options.')\n\n    dev = ctx.obj['dev']\n\n    usb_supported = dev.config.usb_supported\n    usb_enabled = dev.config.usb_enabled\n    flags = dev.config.device_flags\n\n    if not usb_supported:\n        ctx.fail('USB interface not supported.')\n\n    if list:\n        _list_apps(ctx, usb_enabled)\n\n    if touch_eject:\n        flags |= FLAGS.MODE_FLAG_EJECT\n    if no_touch_eject:\n        flags &= ~FLAGS.MODE_FLAG_EJECT\n\n    for app in enable:\n        if APPLICATION[app] & usb_supported:\n            usb_enabled |= APPLICATION[app]\n        else:\n            ctx.fail('{} not supported over USB.'.format(app))\n    for app in disable:\n        if APPLICATION[app] & usb_supported:\n            usb_enabled &= ~APPLICATION[app]\n        else:\n            ctx.fail('{} not supported over USB.'.format(app))\n\n    ensure_not_all_disabled(ctx, usb_enabled)\n\n    f_confirm = '{}{}{}{}{}{}Configure USB interface?'.format(\n        'Enable {}.\\n'.format(\n            ', '.join(\n                [str(APPLICATION[app]) for app in enable])) if enable else '',\n        'Disable {}.\\n'.format(\n            ', '.join(\n                [str(APPLICATION[app]) for app in disable])) if disable else '',\n        'Set touch eject.\\n' if touch_eject else '',\n        'Disable touch eject.\\n' if no_touch_eject else '',\n        'Set autoeject timeout to {}.\\n'.format(\n            autoeject_timeout) if autoeject_timeout else '',\n        'Set challenge-response timeout to {}.\\n'.format(\n            chalresp_timeout) if chalresp_timeout else '')\n\n    is_locked = dev.config.configuration_locked\n\n    if force and is_locked and not lock_code:\n        ctx.fail('Configuration is locked - please supply the --lock-code '\n                 'option.')\n    if lock_code and not is_locked:\n        ctx.fail('Configuration is not locked - please remove the '\n                 '--lock-code option.')\n\n    force or click.confirm(f_confirm, abort=True, err=True)\n\n    if is_locked and not lock_code:\n        lock_code = prompt_lock_code()\n\n    if lock_code:\n        lock_code = _parse_lock_code(ctx, lock_code)\n\n    try:\n        dev.write_config(\n            device_config(\n                usb_enabled=usb_enabled,\n                flags=flags,\n                auto_eject_timeout=autoeject_timeout,\n                chalresp_timeout=chalresp_timeout),\n            reboot=True,\n            lock_key=lock_code)\n    except Exception as e:\n        logger.error('Failed to write config', exc_info=e)\n        ctx.fail('Failed to configure USB applications.')", "response": "Generate USB application list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables or disable applications over NFC.", "response": "def nfc(ctx, enable, disable, enable_all, disable_all, list, lock_code, force):\n    \"\"\"\n    Enable or disable applications over NFC.\n    \"\"\"\n\n    if not (list or enable_all or enable or disable_all or disable):\n        ctx.fail('No configuration options chosen.')\n\n    if enable_all:\n        enable = APPLICATION.__members__.keys()\n\n    if disable_all:\n        disable = APPLICATION.__members__.keys()\n\n    _ensure_not_invalid_options(ctx, enable, disable)\n\n    dev = ctx.obj['dev']\n    nfc_supported = dev.config.nfc_supported\n    nfc_enabled = dev.config.nfc_enabled\n\n    if not nfc_supported:\n        ctx.fail('NFC interface not available.')\n\n    if list:\n        _list_apps(ctx, nfc_enabled)\n\n    for app in enable:\n        if APPLICATION[app] & nfc_supported:\n            nfc_enabled |= APPLICATION[app]\n        else:\n            ctx.fail('{} not supported over NFC.'.format(app))\n    for app in disable:\n        if APPLICATION[app] & nfc_supported:\n            nfc_enabled &= ~APPLICATION[app]\n        else:\n            ctx.fail('{} not supported over NFC.'.format(app))\n\n    f_confirm = '{}{}Configure NFC interface?'.format(\n        'Enable {}.\\n'.format(\n            ', '.join(\n                [str(APPLICATION[app]) for app in enable])) if enable else '',\n        'Disable {}.\\n'.format(\n            ', '.join(\n                [str(APPLICATION[app]) for app in disable])) if disable else '')\n\n    is_locked = dev.config.configuration_locked\n\n    if force and is_locked and not lock_code:\n        ctx.fail('Configuration is locked - please supply the --lock-code '\n                 'option.')\n    if lock_code and not is_locked:\n        ctx.fail('Configuration is not locked - please remove the '\n                 '--lock-code option.')\n\n    force or click.confirm(f_confirm, abort=True, err=True)\n\n    if is_locked and not lock_code:\n        lock_code = prompt_lock_code()\n\n    if lock_code:\n        lock_code = _parse_lock_code(ctx, lock_code)\n\n    try:\n        dev.write_config(\n            device_config(\n                nfc_enabled=nfc_enabled),\n            reboot=True, lock_key=lock_code)\n    except Exception as e:\n        logger.error('Failed to write config', exc_info=e)\n        ctx.fail('Failed to configure NFC applications.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing information about the YubiKey.", "response": "def info(ctx, check_fips):\n    \"\"\"\n    Show general information.\n\n    Displays information about the attached YubiKey such as serial number,\n    firmware version, applications, etc.\n    \"\"\"\n    dev = ctx.obj['dev']\n\n    if dev.is_fips and check_fips:\n        fips_status = get_overall_fips_status(dev.serial, dev.config)\n\n    click.echo('Device type: {}'.format(dev.device_name))\n    click.echo('Serial number: {}'.format(\n        dev.serial or 'Not set or unreadable'))\n    if dev.version:\n        f_version = '.'.join(str(x) for x in dev.version)\n        click.echo('Firmware version: {}'.format(f_version))\n    else:\n        click.echo('Firmware version: Uncertain, re-run with only one '\n                   'YubiKey connected')\n\n    config = dev.config\n    if config.form_factor:\n        click.echo('Form factor: {!s}'.format(config.form_factor))\n    click.echo('Enabled USB interfaces: {}'.format(dev.mode))\n    if config.nfc_supported:\n        f_nfc = 'enabled' if config.nfc_enabled else 'disabled'\n        click.echo('NFC interface is {}.'.format(f_nfc))\n    if config.configuration_locked:\n        click.echo('Configured applications are protected by a lock code.')\n    click.echo()\n\n    print_app_status_table(config)\n\n    if dev.is_fips and check_fips:\n        click.echo()\n\n        click.echo('FIPS Approved Mode: {}'.format(\n            'Yes' if all(fips_status.values()) else 'No'))\n\n        status_keys = list(fips_status.keys())\n        status_keys.sort()\n        for status_key in status_keys:\n            click.echo('  {}: {}'.format(\n                status_key, 'Yes' if fips_status[status_key] else 'No'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oath(ctx, password):\n    try:\n        controller = OathController(ctx.obj['dev'].driver)\n        ctx.obj['controller'] = controller\n        ctx.obj['settings'] = Settings('oath')\n    except APDUError as e:\n        if e.sw == SW.NOT_FOUND:\n            ctx.fail(\"The OATH application can't be found on this YubiKey.\")\n        raise\n\n    if password:\n        ctx.obj['key'] = controller.derive_key(password)", "response": "Manage OATH Application.\n\n    Examples:\n\n    \\b\n      Generate codes for credentials starting with 'yubi':\n      $ ykman oath code yubi\n\n    \\b\n      Add a touch credential with the secret key f5up4ub3dw and the name yubico:\n      $ ykman oath add yubico f5up4ub3dw --touch\n\n    \\b\n      Set a password for the OATH application:\n      $ ykman oath set-password"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisplay status of OATH application.", "response": "def info(ctx):\n    \"\"\"\n    Display status of OATH application.\n    \"\"\"\n    controller = ctx.obj['controller']\n    version = controller.version\n    click.echo(\n        'OATH version: {}.{}.{}'.format(version[0], version[1], version[2]))\n    click.echo('Password protection ' +\n               ('enabled' if controller.locked else 'disabled'))\n\n    keys = ctx.obj['settings'].get('keys', {})\n    if controller.locked and controller.id in keys:\n        click.echo('The password for this YubiKey is remembered by ykman.')\n\n    if ctx.obj['dev'].is_fips:\n        click.echo('FIPS Approved Mode: {}'.format(\n            'Yes' if controller.is_in_fips_mode else 'No'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets all OATH data.", "response": "def reset(ctx):\n    \"\"\"\n    Reset all OATH data.\n\n    This action will wipe all credentials and reset factory settings for\n    the OATH application on the YubiKey.\n    \"\"\"\n\n    controller = ctx.obj['controller']\n    click.echo('Resetting OATH data...')\n    old_id = controller.id\n    controller.reset()\n\n    settings = ctx.obj['settings']\n    keys = settings.setdefault('keys', {})\n    if old_id in keys:\n        del keys[old_id]\n        settings.write()\n\n    click.echo(\n        'Success! All OATH credentials have been cleared from your YubiKey.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(ctx, secret, name, issuer, period, oath_type, digits, touch, algorithm,\n        counter, force):\n    \"\"\"\n    Add a new credential.\n\n    This will add a new credential to your YubiKey.\n    \"\"\"\n\n    oath_type = OATH_TYPE[oath_type]\n    algorithm = ALGO[algorithm]\n    digits = int(digits)\n\n    if not secret:\n        while True:\n            secret = click.prompt('Enter a secret key (base32)', err=True)\n            try:\n                secret = parse_b32_key(secret)\n                break\n            except Exception as e:\n                click.echo(e)\n\n    ensure_validated(ctx)\n\n    _add_cred(ctx, CredentialData(secret, issuer, name, oath_type, algorithm,\n                                  digits, period, counter, touch), force)", "response": "Add a new credential to the YubiKey."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uri(ctx, uri, touch, force):\n\n    if not uri:\n        while True:\n            uri = click.prompt('Enter an OATH URI', err=True)\n            try:\n                uri = CredentialData.from_uri(uri)\n                break\n            except Exception as e:\n                click.echo(e)\n\n    ensure_validated(ctx)\n    data = uri\n\n    # Steam is a special case where we allow the otpauth\n    # URI to contain a 'digits' value of '5'.\n    if data.digits == 5 and data.issuer == 'Steam':\n        data.digits = 6\n\n    data.touch = touch\n\n    _add_cred(ctx, data, force=force)", "response": "Add a new credential from a URI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all credentials stored on YubiKey.", "response": "def list(ctx, show_hidden, oath_type, period):\n    \"\"\"\n    List all credentials.\n\n    List all credentials stored on your YubiKey.\n    \"\"\"\n    ensure_validated(ctx)\n    controller = ctx.obj['controller']\n    creds = [cred\n             for cred in controller.list()\n             if show_hidden or not cred.is_hidden\n             ]\n    creds.sort()\n    for cred in creds:\n        click.echo(cred.printable_key, nl=False)\n        if oath_type:\n            click.echo(u', {}'.format(cred.oath_type.name), nl=False)\n        if period:\n            click.echo(', {}'.format(cred.period), nl=False)\n        click.echo()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates codes from credentials stored on YubiKey.", "response": "def code(ctx, show_hidden, query, single):\n    \"\"\"\n    Generate codes.\n\n    Generate codes from credentials stored on your YubiKey.\n    Provide a query string to match one or more specific credentials.\n    Touch and HOTP credentials require a single match to be triggered.\n    \"\"\"\n\n    ensure_validated(ctx)\n\n    controller = ctx.obj['controller']\n    creds = [(cr, c)\n             for (cr, c) in controller.calculate_all()\n             if show_hidden or not cr.is_hidden\n             ]\n\n    creds = _search(creds, query)\n\n    if len(creds) == 1:\n        cred, code = creds[0]\n        if cred.touch:\n            prompt_for_touch()\n        try:\n            if cred.oath_type == OATH_TYPE.HOTP:\n                # HOTP might require touch, we don't know.\n                # Assume yes after 500ms.\n                hotp_touch_timer = Timer(0.500, prompt_for_touch)\n                hotp_touch_timer.start()\n                creds = [(cred, controller.calculate(cred))]\n                hotp_touch_timer.cancel()\n            elif code is None:\n                creds = [(cred, controller.calculate(cred))]\n        except APDUError as e:\n            if e.sw == SW.SECURITY_CONDITION_NOT_SATISFIED:\n                ctx.fail('Touch credential timed out!')\n\n    elif single:\n        _error_multiple_hits(ctx, [cr for cr, c in creds])\n\n    if single:\n        click.echo(creds[0][1].value)\n    else:\n        creds.sort()\n\n        outputs = [\n            (\n                cr.printable_key,\n                c.value if c\n                else '[Touch Credential]' if cr.touch\n                else '[HOTP Credential]' if cr.oath_type == OATH_TYPE.HOTP\n                else ''\n            ) for (cr, c) in creds\n        ]\n\n        longest_name = max(len(n) for (n, c) in outputs) if outputs else 0\n        longest_code = max(len(c) for (n, c) in outputs) if outputs else 0\n        format_str = u'{:<%d}  {:>%d}' % (longest_name, longest_code)\n\n        for name, result in outputs:\n            click.echo(format_str.format(name, result))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a credential from your YubiKey.", "response": "def delete(ctx, query, force):\n    \"\"\"\n    Delete a credential.\n\n    Delete a credential from your YubiKey.\n    Provide a query string to match the credential to delete.\n    \"\"\"\n\n    ensure_validated(ctx)\n    controller = ctx.obj['controller']\n    creds = controller.list()\n    hits = _search(creds, query)\n    if len(hits) == 0:\n        click.echo('No matches, nothing to be done.')\n    elif len(hits) == 1:\n        cred = hits[0]\n        if force or (click.confirm(\n                u'Delete credential: {} ?'.format(cred.printable_key),\n                default=False, err=True\n        )):\n            controller.delete(cred)\n            click.echo(u'Deleted {}.'.format(cred.printable_key))\n        else:\n            click.echo('Deletion aborted by user.')\n\n    else:\n        _error_multiple_hits(ctx, hits)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchanges the password of the YubiKey.", "response": "def set_password(ctx, new_password, remember):\n    \"\"\"\n    Password protect the OATH credentials.\n\n    Allows you to set a password that will be required to access the OATH\n    credentials stored on your YubiKey.\n    \"\"\"\n    ensure_validated(ctx, prompt='Enter your current password')\n    if not new_password:\n        new_password = click.prompt(\n            'Enter your new password',\n            hide_input=True,\n            confirmation_prompt=True,\n            err=True)\n\n    controller = ctx.obj['controller']\n    settings = ctx.obj['settings']\n    keys = settings.setdefault('keys', {})\n    key = controller.set_password(new_password)\n    click.echo('Password updated.')\n    if remember:\n        keys[controller.id] = b2a_hex(key).decode()\n        settings.write()\n        click.echo('Password remembered')\n    elif controller.id in keys:\n        del keys[controller.id]\n        settings.write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremembers a password for a YubiKeys instance.", "response": "def remember_password(ctx, forget, clear_all):\n    \"\"\"\n    Manage local password storage.\n\n    Store your YubiKeys password on this computer to avoid having to enter it\n    on each use, or delete stored passwords.\n    \"\"\"\n    controller = ctx.obj['controller']\n    settings = ctx.obj['settings']\n    keys = settings.setdefault('keys', {})\n    if clear_all:\n        del settings['keys']\n        settings.write()\n        click.echo('All passwords have been cleared.')\n    elif forget:\n        if controller.id in keys:\n            del keys[controller.id]\n            settings.write()\n        click.echo('Password forgotten.')\n    else:\n        ensure_validated(ctx, remember=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new node from a list of intervals.", "response": "def from_intervals(cls, intervals):\n        \"\"\"\n        :rtype : Node\n        \"\"\"\n        if not intervals:\n            return None\n        node = Node()\n        node = node.init_from_sorted(sorted(intervals))\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_depth(self):\n        left_depth = self.left_node.compute_depth() if self.left_node else 0\n        right_depth = self.right_node.compute_depth() if self.right_node else 0\n        return 1 + max(left_depth, right_depth)", "response": "Recursively computes the depth of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrotates the node if necessary.", "response": "def rotate(self):\n        \"\"\"\n        Does rotating, if necessary, to balance this node, and\n        returns the new top node.\n        \"\"\"\n        self.refresh_balance()\n        if abs(self.balance) < 2:\n            return self\n        # balance > 0  is the heavy side\n        my_heavy = self.balance > 0\n        child_heavy = self[my_heavy].balance > 0\n        if my_heavy == child_heavy or self[my_heavy].balance == 0:\n            ## Heavy sides same\n            #    self     save\n            #  save   -> 1   self\n            # 1\n            #\n            ## Heavy side balanced\n            #    self     save         save\n            #  save   -> 1   self  -> 1  self.rot()\n            #  1  2         2\n            return self.srotate()\n        else:\n            return self.drotate()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef srotate(self):\n        #     self        save         save\n        #   save 3  ->   1   self  -> 1   self.rot()\n        #  1   2            2   3\n        #\n        #  self            save                save\n        # 3   save  ->  self  1    -> self.rot()   1\n        #    2   1     3   2\n\n        #assert(self.balance != 0)\n        heavy = self.balance > 0\n        light = not heavy\n        save = self[heavy]\n        #print(\"srotate: bal={},{}\".format(self.balance, save.balance))\n        #self.print_structure()\n        self[heavy] = save[light]   # 2\n        #assert(save[light])\n        save[light] = self.rotate()  # Needed to ensure the 2 and 3 are balanced under new subnode\n\n        # Some intervals may overlap both self.x_center and save.x_center\n        # Promote those to the new tip of the tree\n        promotees = [iv for iv in save[light].s_center if save.center_hit(iv)]\n        if promotees:\n            for iv in promotees:\n                save[light] = save[light].remove(iv)  # may trigger pruning\n            # TODO: Use Node.add() here, to simplify future balancing improvements.\n            # For now, this is the same as augmenting save.s_center, but that may\n            # change.\n            save.s_center.update(promotees)\n        save.refresh_balance()\n        return save", "response": "Single rotation. Assumes that balance is +-2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, interval):\n        if self.center_hit(interval):\n            self.s_center.add(interval)\n            return self\n        else:\n            direction = self.hit_branch(interval)\n            if not self[direction]:\n                self[direction] = Node.from_interval(interval)\n                self.refresh_balance()\n                return self\n            else:\n                self[direction] = self[direction].add(interval)\n                return self.rotate()", "response": "Adds an interval to the node. Returns self after adding the interval and balancing."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning self after removing the interval and balancing.", "response": "def remove(self, interval):\n        \"\"\"\n        Returns self after removing the interval and balancing.\n\n        If interval is not present, raise ValueError.\n        \"\"\"\n        # since this is a list, called methods can set this to [1],\n        # making it true\n        done = []\n        return self.remove_interval_helper(interval, done, should_raise_error=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn self after removing interval and balancing.", "response": "def discard(self, interval):\n        \"\"\"\n        Returns self after removing interval and balancing.\n\n        If interval is not present, do nothing.\n        \"\"\"\n        done = []\n        return self.remove_interval_helper(interval, done, should_raise_error=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_interval_helper(self, interval, done, should_raise_error):\n        #trace = interval.begin == 347 and interval.end == 353\n        #if trace: print('\\nRemoving from {} interval {}'.format(\n        #   self.x_center, interval))\n        if self.center_hit(interval):\n            #if trace: print('Hit at {}'.format(self.x_center))\n            if not should_raise_error and interval not in self.s_center:\n                done.append(1)\n                #if trace: print('Doing nothing.')\n                return self\n            try:\n                # raises error if interval not present - this is\n                # desired.\n                self.s_center.remove(interval)\n            except:\n                self.print_structure()\n                raise KeyError(interval)\n            if self.s_center:     # keep this node\n                done.append(1)    # no rebalancing necessary\n                #if trace: print('Removed, no rebalancing.')\n                return self\n\n            # If we reach here, no intervals are left in self.s_center.\n            # So, prune self.\n            return self.prune()\n        else:  # interval not in s_center\n            direction = self.hit_branch(interval)\n\n            if not self[direction]:\n                if should_raise_error:\n                    raise ValueError\n                done.append(1)\n                return self\n\n            #if trace:\n            #   print('Descending to {} branch'.format(\n            #       ['left', 'right'][direction]\n            #       ))\n            self[direction] = self[direction].remove_interval_helper(interval, done, should_raise_error)\n\n            # Clean up\n            if not done:\n                #if trace:\n                #    print('Rotating {}'.format(self.x_center))\n                #    self.print_structure()\n                return self.rotate()\n            return self", "response": "This method removes an interval from the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_overlap(self, point_list):\n        result = set()\n        for j in point_list:\n            self.search_point(j, result)\n        return result", "response": "Returns all intervals that overlap the point_list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_point(self, point, result):\n        for k in self.s_center:\n            if k.begin <= point < k.end:\n                result.add(k)\n        if point < self.x_center and self[0]:\n            return self[0].search_point(point, result)\n        elif point > self.x_center and self[1]:\n            return self[1].search_point(point, result)\n        return result", "response": "Searches the set of intervals that contain point."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prune(self):\n        if not self[0] or not self[1]:    # if I have an empty branch\n            direction = not self[0]       # graft the other branch here\n            #if trace:\n            #    print('Grafting {} branch'.format(\n            #       'right' if direction else 'left'))\n\n            result = self[direction]\n            #if result: result.verify()\n            return result\n        else:\n            # Replace the root node with the greatest predecessor.\n            heir, self[0] = self[0].pop_greatest_child()\n            #if trace:\n            #    print('Replacing {} with {}.'.format(\n            #        self.x_center, heir.x_center\n            #        ))\n            #    print('Removed greatest predecessor:')\n            #    self.print_structure()\n\n            #if self[0]: self[0].verify()\n            #if self[1]: self[1].verify()\n\n            # Set up the heir as the new root node\n            (heir[0], heir[1]) = (self[0], self[1])\n            #if trace: print('Setting up the heir:')\n            #if trace: heir.print_structure()\n\n            # popping the predecessor may have unbalanced this node;\n            # fix it\n            heir.refresh_balance()\n            heir = heir.rotate()\n            #heir.verify()\n            #if trace: print('Rotated the heir:')\n            #if trace: heir.print_structure()\n            return heir", "response": "Removes the root node from the tree and returns a new subtree with no empty s_centers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether this node or a child overlaps p.", "response": "def contains_point(self, p):\n        \"\"\"\n        Returns whether this node or a child overlaps p.\n        \"\"\"\n        for iv in self.s_center:\n            if iv.contains_point(p):\n                return True\n        branch = self[p > self.x_center]\n        return branch and branch.contains_point(p)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify(self, parents=set()):\n        assert(isinstance(self.s_center, set))\n\n        bal = self.balance\n        assert abs(bal) < 2, \\\n            \"Error: Rotation should have happened, but didn't! \\n{}\".format(\n                self.print_structure(tostring=True)\n            )\n        self.refresh_balance()\n        assert bal == self.balance, \\\n            \"Error: self.balance not set correctly! \\n{}\".format(\n                self.print_structure(tostring=True)\n            )\n\n        assert self.s_center, \\\n            \"Error: s_center is empty! \\n{}\".format(\n                self.print_structure(tostring=True)\n            )\n        for iv in self.s_center:\n            assert hasattr(iv, 'begin')\n            assert hasattr(iv, 'end')\n            assert iv.begin < iv.end\n            assert iv.overlaps(self.x_center)\n            for parent in sorted(parents):\n                assert not iv.contains_point(parent), \\\n                    \"Error: Overlaps ancestor ({})! \\n{}\\n\\n{}\".format(\n                        parent, iv, self.print_structure(tostring=True)\n                    )\n        if self[0]:\n            assert self[0].x_center < self.x_center, \\\n                \"Error: Out-of-order left child! {}\".format(self.x_center)\n            self[0].verify(parents.union([self.x_center]))\n        if self[1]:\n            assert self[1].x_center > self.x_center, \\\n                \"Error: Out-of-order right child! {}\".format(self.x_center)\n            self[1].verify(parents.union([self.x_center]))", "response": "This function checks that the invariants of the interval subtree contains all of the invariants of the interval s_center."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count_nodes(self):\n        count = 1\n        if self.left_node:\n            count += self.left_node.count_nodes()\n        if self.right_node:\n            count += self.right_node.count_nodes()\n        return count", "response": "Count the number of Nodes in this subtree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef depth_score(self, n, m):\n        if n == 0:\n            return 0.0\n\n        # dopt is the optimal maximum depth of the tree\n        dopt = 1 + int(floor(l2(m)))\n        f = 1 / float(1 + n - dopt)\n        return f * self.depth_score_helper(1, dopt)", "response": "Calculates the depth score of a tree entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef depth_score_helper(self, d, dopt):\n        # di is how may levels deeper than optimal d is\n        di = d - dopt\n        if di > 0:\n            count = di * len(self.s_center)\n        else:\n            count = 0\n        if self.right_node:\n            count += self.right_node.depth_score_helper(d + 1, dopt)\n        if self.left_node:\n            count += self.left_node.depth_score_helper(d + 1, dopt)\n        return count", "response": "Returns a weighted count of the number of Intervals deeper than dopt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_structure(self, indent=0, tostring=False):\n        nl = '\\n'\n        sp = indent * '    '\n\n        rlist = [str(self) + nl]\n        if self.s_center:\n            for iv in sorted(self.s_center):\n                rlist.append(sp + ' ' + repr(iv) + nl)\n        if self.left_node:\n            rlist.append(sp + '<:  ')  # no CR\n            rlist.append(self.left_node.print_structure(indent + 1, True))\n        if self.right_node:\n            rlist.append(sp + '>:  ')  # no CR\n            rlist.append(self.right_node.print_structure(indent + 1, True))\n        result = ''.join(rlist)\n        if tostring:\n            return result\n        else:\n            print(result)", "response": "Print the structure of the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the interval overlaps the given point or an Interval.", "response": "def overlaps(self, begin, end=None):\n        \"\"\"\n        Whether the interval overlaps the given point, range or Interval.\n        :param begin: beginning point of the range, or the point, or an Interval\n        :param end: end point of the range. Optional if not testing ranges.\n        :return: True or False\n        :rtype: bool\n        \"\"\"\n        if end is not None:\n            # An overlap means that some C exists that is inside both ranges:\n            #   begin <= C < end\n            # and \n            #   self.begin <= C < self.end\n            # See https://stackoverflow.com/questions/3269434/whats-the-most-efficient-way-to-test-two-integer-ranges-for-overlap/3269471#3269471\n            return begin < self.end and end > self.begin\n        try:\n            return self.overlaps(begin.begin, begin.end)\n        except:\n            return self.contains_point(begin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the size of the overlap between two point - like objects.", "response": "def overlap_size(self, begin, end=None):\n        \"\"\"\n        Return the overlap size between two intervals or a point\n        :param begin: beginning point of the range, or the point, or an Interval\n        :param end: end point of the range. Optional if not testing ranges.\n        :return: Return the overlap size, None if not overlap is found\n        :rtype: depends on the given input (e.g., int will be returned for int interval and timedelta for\n        datetime intervals)\n        \"\"\"\n        overlaps = self.overlaps(begin, end)\n        if not overlaps:\n            return 0\n\n        if end is not None:\n            # case end is given\n            i0 = max(self.begin, begin)\n            i1 = min(self.end, end)\n            return i1 - i0\n        # assume the type is interval, in other cases, an exception will be thrown\n        i0 = max(self.begin, begin.begin)\n        i1 = min(self.end, begin.end)\n        return i1 - i0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contains_interval(self, other):\n        return (\n            self.begin <= other.begin and\n            self.end >= other.end\n        )", "response": "Returns True if this Interval contains other False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the distance between two intervals or 0 if they touch or overlap.", "response": "def distance_to(self, other):\n        \"\"\"\n        Returns the size of the gap between intervals, or 0 \n        if they touch or overlap.\n        :param other: Interval or point\n        :return: distance\n        :rtype: Number\n        \"\"\"\n        if self.overlaps(other):\n            return 0\n        try:\n            if self.begin < other.begin:\n                return other.begin - self.end\n            else:\n                return self.begin - other.end\n        except:\n            if self.end <= other:\n                return other - self.end\n            else:\n                return self.begin - other"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise a ValueError if either self or other are null.", "response": "def _raise_if_null(self, other):\n        \"\"\"\n        :raises ValueError: if either self or other is a null Interval\n        \"\"\"\n        if self.is_null():\n            raise ValueError(\"Cannot compare null Intervals!\")\n        if hasattr(other, 'is_null') and other.is_null():\n            raise ValueError(\"Cannot compare null Intervals!\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if this interval extends higher than other.", "response": "def le(self, other):\n        \"\"\"\n        Less than or overlaps. Returns True if no part of this Interval\n        extends higher than other.\n        :raises ValueError: if either self or other is a null Interval\n        :param other: Interval or point\n        :return: True or False\n        :rtype: bool\n        \"\"\"\n        self._raise_if_null(other)\n        return self.end <= getattr(other, 'end', other)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gt(self, other):\n        self._raise_if_null(other)\n        if hasattr(other, 'end'):\n            return self.begin >= other.end\n        else:\n            return self.begin > other", "response": "Strictly greater than. Returns True if no part of this Interval or other extends lower than or into other."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ge(self, other):\n        self._raise_if_null(other)\n        return self.begin >= getattr(other, 'begin', other)", "response": "Returns True if this interval extends lower than other. Returns False if no part of this Interval or overlaps. Returns True if no part of this Interval or overlaps. Returns False if either self or other is a null Interval or other is a null Interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_fields(self):\n        if self.data is not None:\n            return self.begin, self.end, self.data\n        else:\n            return self.begin, self.end", "response": "Returns only the fields needed to reconstruct the Interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_tuples(cls, tups):\n        ivs = [Interval(*t) for t in tups]\n        return IntervalTree(ivs)", "response": "Create an IntervalTree from an iterable of 2 - or 3 - tuples containing the begin end and optionally data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_boundaries(self, interval):\n        begin = interval.begin\n        end = interval.end\n        if begin in self.boundary_table:\n            self.boundary_table[begin] += 1\n        else:\n            self.boundary_table[begin] = 1\n\n        if end in self.boundary_table:\n            self.boundary_table[end] += 1\n        else:\n            self.boundary_table[end] = 1", "response": "Adds the boundaries of the interval to the internal boundary table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _remove_boundaries(self, interval):\n        begin = interval.begin\n        end = interval.end\n        if self.boundary_table[begin] == 1:\n            del self.boundary_table[begin]\n        else:\n            self.boundary_table[begin] -= 1\n\n        if self.boundary_table[end] == 1:\n            del self.boundary_table[end]\n        else:\n            self.boundary_table[end] -= 1", "response": "Removes the boundaries of the interval from the boundary table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, interval):\n        if interval in self:\n            return\n\n        if interval.is_null():\n            raise ValueError(\n                \"IntervalTree: Null Interval objects not allowed in IntervalTree:\"\n                \" {0}\".format(interval)\n            )\n\n        if not self.top_node:\n            self.top_node = Node.from_interval(interval)\n        else:\n            self.top_node = self.top_node.add(interval)\n        self.all_intervals.add(interval)\n        self._add_boundaries(interval)", "response": "Adds an interval to the tree if not already present."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an interval to the set.", "response": "def addi(self, begin, end, data=None):\n        \"\"\"\n        Shortcut for add(Interval(begin, end, data)).\n\n        Completes in O(log n) time.\n        \"\"\"\n        return self.add(Interval(begin, end, data))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, interval):\n        #self.verify()\n        if interval not in self:\n            #print(self.all_intervals)\n            raise ValueError\n        self.top_node = self.top_node.remove(interval)\n        self.all_intervals.remove(interval)\n        self._remove_boundaries(interval)", "response": "Removes an interval from the tree if present. Raises ValueError."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef removei(self, begin, end, data=None):\n        return self.remove(Interval(begin, end, data))", "response": "Remove an interval from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove an interval from the tree if present. If not removes an interval from the tree if present. If not removes an interval from the tree if present.", "response": "def discard(self, interval):\n        \"\"\"\n        Removes an interval from the tree, if present. If not, does\n        nothing.\n\n        Completes in O(log n) time.\n        \"\"\"\n        if interval not in self:\n            return\n        self.all_intervals.discard(interval)\n        self.top_node = self.top_node.discard(interval)\n        self._remove_boundaries(interval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndiscards the given interval.", "response": "def discardi(self, begin, end, data=None):\n        \"\"\"\n        Shortcut for discard(Interval(begin, end, data)).\n\n        Completes in O(log n) time.\n        \"\"\"\n        return self.discard(Interval(begin, end, data))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef difference(self, other):\n        ivs = set()\n        for iv in self:\n            if iv not in other:\n                ivs.add(iv)\n        return IntervalTree(ivs)", "response": "Returns a new tree comprising all intervals in self but not in other."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new tree of all intervals common to both self and other.", "response": "def intersection(self, other):\n        \"\"\"\n        Returns a new tree of all intervals common to both self and\n        other.\n        \"\"\"\n        ivs = set()\n        shorter, longer = sorted([self, other], key=len)\n        for iv in shorter:\n            if iv in longer:\n                ivs.add(iv)\n        return IntervalTree(ivs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove intervals from self unless they also exist in other.", "response": "def intersection_update(self, other):\n        \"\"\"\n        Removes intervals from self unless they also exist in other.\n        \"\"\"\n        ivs = list(self)\n        for iv in ivs:\n            if iv not in other:\n                self.remove(iv)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tree with elements only in self or other but not both.", "response": "def symmetric_difference(self, other):\n        \"\"\"\n        Return a tree with elements only in self or other but not\n        both.\n        \"\"\"\n        if not isinstance(other, set): other = set(other)\n        me = set(self)\n        ivs = me.difference(other).union(other.difference(me))\n        return IntervalTree(ivs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating self with the set of intervals except those only in other.", "response": "def symmetric_difference_update(self, other):\n        \"\"\"\n        Throws out all intervals except those only in self or other,\n        not both.\n        \"\"\"\n        other = set(other)\n        ivs = list(self)\n        for iv in ivs:\n            if iv in other:\n                self.remove(iv)\n                other.remove(iv)\n        self.update(other)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_overlap(self, begin, end=None):\n        hitlist = self.at(begin) if end is None else self.overlap(begin, end)\n        for iv in hitlist:\n            self.remove(iv)", "response": "Removes all intervals overlapping the given point or range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_envelop(self, begin, end):\n        hitlist = self.envelop(begin, end)\n        for iv in hitlist:\n            self.remove(iv)", "response": "Removes all intervals completely enveloped in the given range."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chop(self, begin, end, datafunc=None):\n        insertions = set()\n        begin_hits = [iv for iv in self.at(begin) if iv.begin < begin]\n        end_hits = [iv for iv in self.at(end) if iv.end > end]\n\n        if datafunc:\n            for iv in begin_hits:\n                insertions.add(Interval(iv.begin, begin, datafunc(iv, True)))\n            for iv in end_hits:\n                insertions.add(Interval(end, iv.end, datafunc(iv, False)))\n        else:\n            for iv in begin_hits:\n                insertions.add(Interval(iv.begin, begin, iv.data))\n            for iv in end_hits:\n                insertions.add(Interval(end, iv.end, iv.data))\n\n        self.remove_envelop(begin, end)\n        self.difference_update(begin_hits)\n        self.difference_update(end_hits)\n        self.update(insertions)", "response": "Like remove_envelop but trims back Intervals hanging into\n        the chopped area so that nothing overlaps."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary mapping parent intervals to sets of all intervals overlapped by and contained in the parent.", "response": "def find_nested(self):\n        \"\"\"\n        Returns a dictionary mapping parent intervals to sets of\n        intervals overlapped by and contained in the parent.\n\n        Completes in O(n^2) time.\n        :rtype: dict of [Interval, set of Interval]\n        \"\"\"\n        result = {}\n\n        def add_if_nested():\n            if parent.contains_interval(child):\n                if parent not in result:\n                    result[parent] = set()\n                result[parent].add(child)\n\n        long_ivs = sorted(self.all_intervals, key=Interval.length, reverse=True)\n        for i, parent in enumerate(long_ivs):\n            for child in long_ivs[i + 1:]:\n                add_if_nested()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether some interval in the tree overlaps the given point or range.", "response": "def overlaps(self, begin, end=None):\n        \"\"\"\n        Returns whether some interval in the tree overlaps the given\n        point or range.\n\n        Completes in O(r*log n) time, where r is the size of the\n        search range.\n        :rtype: bool\n        \"\"\"\n        if end is not None:\n            return self.overlaps_range(begin, end)\n        elif isinstance(begin, Number):\n            return self.overlaps_point(begin)\n        else:\n            return self.overlaps_range(begin.begin, begin.end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if some interval in the tree overlaps p.", "response": "def overlaps_point(self, p):\n        \"\"\"\n        Returns whether some interval in the tree overlaps p.\n\n        Completes in O(log n) time.\n        :rtype: bool\n        \"\"\"\n        if self.is_empty():\n            return False\n        return bool(self.top_node.contains_point(p))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if some interval in the tree overlaps the given range.", "response": "def overlaps_range(self, begin, end):\n        \"\"\"\n        Returns whether some interval in the tree overlaps the given\n        range. Returns False if given a null interval over which to\n        test.\n\n        Completes in O(r*log n) time, where r is the range length and n\n        is the table size.\n        :rtype: bool\n        \"\"\"\n        if self.is_empty():\n            return False\n        elif begin >= end:\n            return False\n        elif self.overlaps_point(begin):\n            return True\n        return any(\n            self.overlaps_point(bound)\n            for bound in self.boundary_table\n            if begin < bound < end\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_overlaps(self):\n        if not self:\n            return\n        if len(self.boundary_table) == 2:\n            return\n\n        bounds = sorted(self.boundary_table)  # get bound locations\n\n        new_ivs = set()\n        for lbound, ubound in zip(bounds[:-1], bounds[1:]):\n            for iv in self[lbound]:\n                new_ivs.add(Interval(lbound, ubound, iv.data))\n\n        self.__init__(new_ivs)", "response": "Finds all intervals with overlapping ranges and splits them together the range boundaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_overlaps(self, data_reducer=None, data_initializer=None, strict=True):\n        if not self:\n            return\n\n        sorted_intervals = sorted(self.all_intervals)  # get sorted intervals\n        merged = []\n        # use mutable object to allow new_series() to modify it\n        current_reduced = [None]\n        higher = None  # iterating variable, which new_series() needs access to\n\n        def new_series():\n            if data_initializer is None:\n                current_reduced[0] = higher.data\n                merged.append(higher)\n                return\n            else:  # data_initializer is not None\n                current_reduced[0] = copy(data_initializer)\n                current_reduced[0] = data_reducer(current_reduced[0], higher.data)\n                merged.append(Interval(higher.begin, higher.end, current_reduced[0]))\n\n        for higher in sorted_intervals:\n            if merged:  # series already begun\n                lower = merged[-1]\n                if (higher.begin < lower.end or\n                    not strict and higher.begin == lower.end):  # should merge\n                    upper_bound = max(lower.end, higher.end)\n                    if data_reducer is not None:\n                        current_reduced[0] = data_reducer(current_reduced[0], higher.data)\n                    else:  # annihilate the data, since we don't know how to merge it\n                        current_reduced[0] = None\n                    merged[-1] = Interval(lower.begin, upper_bound, current_reduced[0])\n                else:\n                    new_series()\n            else:  # not merged; is first of Intervals to merge\n                new_series()\n\n        self.__init__(merged)", "response": "Merges all intervals with overlapping ranges and returns a new set of intervals."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef at(self, p):\n        root = self.top_node\n        if not root:\n            return set()\n        return root.search_point(p, set())", "response": "Returns the set of all intervals that contain p."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef envelop(self, begin, end=None):\n        root = self.top_node\n        if not root:\n            return set()\n        if end is None:\n            iv = begin\n            return self.envelop(iv.begin, iv.end)\n        elif begin >= end:\n            return set()\n        result = root.search_point(begin, set()) # bound_begin might be greater\n        boundary_table = self.boundary_table\n        bound_begin = boundary_table.bisect_left(begin)\n        bound_end = boundary_table.bisect_left(end)  # up to, but not including end\n        result.update(root.search_overlap(\n            # slice notation is slightly slower\n            boundary_table.keys()[index] for index in xrange(bound_begin, bound_end)\n        ))\n\n        # TODO: improve envelop() to use node info instead of less-efficient filtering\n        result = set(\n            iv for iv in result\n            if iv.begin >= begin and iv.end <= end\n        )\n        return result", "response": "Returns the set of intervals fully contained in the range [ begin end )."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the tree structure.", "response": "def print_structure(self, tostring=False):\n        \"\"\"\n        ## FOR DEBUGGING ONLY ##\n        Pretty-prints the structure of the tree.\n        If tostring is true, prints nothing and returns a string.\n        :rtype: None or str\n        \"\"\"\n        if self.top_node:\n            return self.top_node.print_structure(tostring=tostring)\n        else:\n            result = \"<empty IntervalTree>\"\n            if not tostring:\n                print(result)\n            else:\n                return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying that the invariants are held.", "response": "def verify(self):\n        \"\"\"\n        ## FOR DEBUGGING ONLY ##\n        Checks the table to ensure that the invariants are held.\n        \"\"\"\n        if self.all_intervals:\n            ## top_node.all_children() == self.all_intervals\n            try:\n                assert self.top_node.all_children() == self.all_intervals\n            except AssertionError as e:\n                print(\n                    'Error: the tree and the membership set are out of sync!'\n                )\n                tivs = set(self.top_node.all_children())\n                print('top_node.all_children() - all_intervals:')\n                try:\n                    pprint\n                except NameError:\n                    from pprint import pprint\n                pprint(tivs - self.all_intervals)\n                print('all_intervals - top_node.all_children():')\n                pprint(self.all_intervals - tivs)\n                raise e\n\n            ## All members are Intervals\n            for iv in self:\n                assert isinstance(iv, Interval), (\n                    \"Error: Only Interval objects allowed in IntervalTree:\"\n                    \" {0}\".format(iv)\n                )\n\n            ## No null intervals\n            for iv in self:\n                assert not iv.is_null(), (\n                    \"Error: Null Interval objects not allowed in IntervalTree:\"\n                    \" {0}\".format(iv)\n                )\n\n            ## Reconstruct boundary_table\n            bound_check = {}\n            for iv in self:\n                if iv.begin in bound_check:\n                    bound_check[iv.begin] += 1\n                else:\n                    bound_check[iv.begin] = 1\n                if iv.end in bound_check:\n                    bound_check[iv.end] += 1\n                else:\n                    bound_check[iv.end] = 1\n\n            ## Reconstructed boundary table (bound_check) ==? boundary_table\n            assert set(self.boundary_table.keys()) == set(bound_check.keys()),\\\n                'Error: boundary_table is out of sync with ' \\\n                'the intervals in the tree!'\n\n            # For efficiency reasons this should be iteritems in Py2, but we\n            # don't care much for efficiency in debug methods anyway.\n            for key, val in self.boundary_table.items():\n                assert bound_check[key] == val, \\\n                    'Error: boundary_table[{0}] should be {1},' \\\n                    ' but is {2}!'.format(\n                        key, bound_check[key], val)\n\n            ## Internal tree structure\n            self.top_node.verify(set())\n        else:\n            ## Verify empty tree\n            assert not self.boundary_table, \\\n                \"Error: boundary table should be empty!\"\n            assert self.top_node is None, \\\n                \"Error: top_node isn't None!\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef score(self, full_report=False):\n        if len(self) <= 2:\n            return 0.0\n\n        n = len(self)\n        m = self.top_node.count_nodes()\n\n        def s_center_score():\n            \"\"\"\n            Returns a normalized score, indicating roughly how many times\n            intervals share s_center with other intervals. Output is full-scale\n            from 0 to 1.\n            :rtype: float\n            \"\"\"\n            raw = n - m\n            maximum = n - 1\n            return raw / float(maximum)\n\n        report = {\n            \"depth\": self.top_node.depth_score(n, m),\n            \"s_center\": s_center_score(),\n        }\n        cumulative = max(report.values())\n        report[\"_cumulative\"] = cumulative\n        if full_report:\n            return report\n        return cumulative", "response": "Returns a score of the tree with the most common level of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef containsi(self, begin, end, data=None):\n        return Interval(begin, end, data) in self", "response": "Returns True if the tree contains the given interval."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bysize(words):\n    ret = {}\n    for w in words:\n        if len(w) not in ret:\n            ret[len(w)] = set()\n        ret[len(w)].add(w)\n    return ret", "response": "take a list of words and return a dict of sets sorted by word length"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_pl_si_lists(lst, plending, siendingsize, dojoinstem=True):\n    if siendingsize is not None:\n        siendingsize = -siendingsize\n    si_list = [w[:siendingsize] + plending for w in lst]\n    pl_bysize = bysize(lst)\n    si_bysize = bysize(si_list)\n    if dojoinstem:\n        stem = joinstem(siendingsize, lst)\n        return si_list, si_bysize, pl_bysize, stem\n    else:\n        return si_list, si_bysize, pl_bysize", "response": "This function takes a list of singular words and a list of pluralised words and returns a list of lists that are the pluralised words and the pluralised words by their size."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the noun plural of singular to plural.", "response": "def defnoun(self, singular, plural):\n        \"\"\"\n        Set the noun plural of singular to plural.\n\n        \"\"\"\n        self.checkpat(singular)\n        self.checkpatplural(plural)\n        self.pl_sb_user_defined.extend((singular, plural))\n        self.si_sb_user_defined.extend((plural, singular))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the verb plurals for s1 s2 and s3 to p1 p2 and p3 respectively.", "response": "def defverb(self, s1, p1, s2, p2, s3, p3):\n        \"\"\"\n        Set the verb plurals for s1, s2 and s3 to p1, p2 and p3 respectively.\n\n        Where 1, 2 and 3 represent the 1st, 2nd and 3rd person forms of the verb.\n\n        \"\"\"\n        self.checkpat(s1)\n        self.checkpat(s2)\n        self.checkpat(s3)\n        self.checkpatplural(p1)\n        self.checkpatplural(p2)\n        self.checkpatplural(p3)\n        self.pl_v_user_defined.extend((s1, p1, s2, p2, s3, p3))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defadj(self, singular, plural):\n        self.checkpat(singular)\n        self.checkpatplural(plural)\n        self.pl_adj_user_defined.extend((singular, plural))\n        return 1", "response": "Sets the adjective plural of singular to plural."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines the indefinate article as a for words matching pattern.", "response": "def defa(self, pattern):\n        \"\"\"\n        Define the indefinate article as 'a' for words matching pattern.\n\n        \"\"\"\n        self.checkpat(pattern)\n        self.A_a_user_defined.extend((pattern, \"a\"))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef defan(self, pattern):\n        self.checkpat(pattern)\n        self.A_a_user_defined.extend((pattern, \"an\"))\n        return 1", "response": "Define the indefinate article as an for words matching pattern."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checkpat(self, pattern):\n        if pattern is None:\n            return\n        try:\n            re.match(pattern, \"\")\n        except re.error:\n            print3(\"\\nBad user-defined singular pattern:\\n\\t%s\\n\" % pattern)\n            raise BadUserDefinedPatternError", "response": "check for errors in a regex pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef classical(self, **kwargs):\n        classical_mode = list(def_classical.keys())\n        if not kwargs:\n            self.classical_dict = all_classical.copy()\n            return\n        if \"all\" in kwargs:\n            if kwargs[\"all\"]:\n                self.classical_dict = all_classical.copy()\n            else:\n                self.classical_dict = no_classical.copy()\n\n        for k, v in list(kwargs.items()):\n            if k in classical_mode:\n                self.classical_dict[k] = v\n            else:\n                raise UnknownClassicalModeError", "response": "Turn classical mode on and off for various categories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the number of items in the cache.", "response": "def num(self, count=None, show=None):  # (;$count,$show)\n        \"\"\"\n        Set the number to be used in other method calls.\n\n        Returns count.\n\n        Set show to False to return '' instead.\n\n        \"\"\"\n        if count is not None:\n            try:\n                self.persistent_count = int(count)\n            except ValueError:\n                raise BadNumValueError\n            if (show is None) or show:\n                return str(count)\n        else:\n            self.persistent_count = None\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_value_from_ast(self, obj):\n        if isinstance(obj, ast.Num):\n            return obj.n\n        elif isinstance(obj, ast.Str):\n            return obj.s\n        elif isinstance(obj, ast.List):\n            return [self._get_value_from_ast(e) for e in obj.elts]\n        elif isinstance(obj, ast.Tuple):\n            return tuple([self._get_value_from_ast(e) for e in obj.elts])\n\n        # None, True and False are NameConstants in Py3.4 and above.\n        elif sys.version_info.major >= 3 and isinstance(obj, ast.NameConstant):\n            return obj.value\n\n        # For python versions below 3.4\n        elif isinstance(obj, ast.Name) and (obj.id in [\"True\", \"False\", \"None\"]):\n            return string_to_constant[obj.id]\n\n        # Probably passed a variable name.\n        # Or passed a single word without wrapping it in quotes as an argument\n        # ex: p.inflect(\"I plural(see)\") instead of p.inflect(\"I plural('see')\")\n        raise NameError(\"name '%s' is not defined\" % obj.id)", "response": "Returns the value of the ast object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the string to be substituted for the match.", "response": "def _string_to_substitute(self, mo, methods_dict):\n        \"\"\"\n        Return the string to be substituted for the match.\n        \"\"\"\n        matched_text, f_name = mo.groups()\n        # matched_text is the complete match string. e.g. plural_noun(cat)\n        # f_name is the function name. e.g. plural_noun\n\n        # Return matched_text if function name is not in methods_dict\n        if f_name not in methods_dict:\n            return matched_text\n\n        # Parse the matched text\n        a_tree = ast.parse(matched_text)\n\n        # get the args and kwargs from ast objects\n        args_list = [self._get_value_from_ast(a) for a in a_tree.body[0].value.args]\n        kwargs_list = {\n            kw.arg: self._get_value_from_ast(kw.value)\n            for kw in a_tree.body[0].value.keywords\n        }\n\n        # Call the corresponding function\n        return methods_dict[f_name](*args_list, **kwargs_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inflect(self, text):\n        save_persistent_count = self.persistent_count\n\n        # Dictionary of allowed methods\n        methods_dict = {\n            \"plural\": self.plural,\n            \"plural_adj\": self.plural_adj,\n            \"plural_noun\": self.plural_noun,\n            \"plural_verb\": self.plural_verb,\n            \"singular_noun\": self.singular_noun,\n            \"a\": self.a,\n            \"an\": self.a,\n            \"no\": self.no,\n            \"ordinal\": self.ordinal,\n            \"number_to_words\": self.number_to_words,\n            \"present_participle\": self.present_participle,\n            \"num\": self.num,\n        }\n\n        # Regular expression to find Python's function call syntax\n        functions_re = re.compile(r\"((\\w+)\\([^)]*\\)*)\", re.IGNORECASE)\n        output = functions_re.sub(\n            lambda mo: self._string_to_substitute(mo, methods_dict), text\n        )\n        self.persistent_count = save_persistent_count\n        return output", "response": "Perform inflections in a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plural(self, text, count=None):\n        pre, word, post = self.partition_word(text)\n        if not word:\n            return text\n        plural = self.postprocess(\n            word,\n            self._pl_special_adjective(word, count)\n            or self._pl_special_verb(word, count)\n            or self._plnoun(word, count),\n        )\n        return \"{}{}{}\".format(pre, plural, post)", "response": "Return the plural of text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the plural of text where text is a noun.", "response": "def plural_noun(self, text, count=None):\n        \"\"\"\n        Return the plural of text, where text is a noun.\n\n        If count supplied, then return text if count is one of:\n            1, a, an, one, each, every, this, that\n        otherwise return the plural.\n\n        Whitespace at the start and end is preserved.\n\n        \"\"\"\n        pre, word, post = self.partition_word(text)\n        if not word:\n            return text\n        plural = self.postprocess(word, self._plnoun(word, count))\n        return \"{}{}{}\".format(pre, plural, post)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plural_verb(self, text, count=None):\n        pre, word, post = self.partition_word(text)\n        if not word:\n            return text\n        plural = self.postprocess(\n            word,\n            self._pl_special_verb(word, count) or self._pl_general_verb(word, count),\n        )\n        return \"{}{}{}\".format(pre, plural, post)", "response": "Return the plural of text where text is a verb."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the plural of text where text is an adjective.", "response": "def plural_adj(self, text, count=None):\n        \"\"\"\n        Return the plural of text, where text is an adjective.\n\n        If count supplied, then return text if count is one of:\n            1, a, an, one, each, every, this, that\n        otherwise return the plural.\n\n        Whitespace at the start and end is preserved.\n\n        \"\"\"\n        pre, word, post = self.partition_word(text)\n        if not word:\n            return text\n        plural = self.postprocess(word, self._pl_special_adjective(word, count) or word)\n        return \"{}{}{}\".format(pre, plural, post)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compare(self, word1, word2):\n        return (\n            self._plequal(word1, word2, self.plural_noun)\n            or self._plequal(word1, word2, self.plural_verb)\n            or self._plequal(word1, word2, self.plural_adj)\n        )", "response": "compare word1 and word2 for equality regardless of plurality return True - if word1 and word2 are equal False - otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare_nouns(self, word1, word2):\n        return self._plequal(word1, word2, self.plural_noun)", "response": "compare word1 and word2 for equality regardless of plurality return values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompare word1 and word2 for equality regardless of plurality return values", "response": "def compare_verbs(self, word1, word2):\n        \"\"\"\n        compare word1 and word2 for equality regardless of plurality\n        word1 and word2 are to be treated as verbs\n\n        return values:\n        eq - the strings are equal\n        p:s - word1 is the plural of word2\n        s:p - word2 is the plural of word1\n        p:p - word1 and word2 are two different plural forms of the one word\n        False - otherwise\n\n        \"\"\"\n        return self._plequal(word1, word2, self.plural_verb)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare word1 and word2 for equality regardless of plurality return values", "response": "def compare_adjs(self, word1, word2):\n        \"\"\"\n        compare word1 and word2 for equality regardless of plurality\n        word1 and word2 are to be treated as adjectives\n\n        return values:\n        eq - the strings are equal\n        p:s - word1 is the plural of word2\n        s:p - word2 is the plural of word1\n        p:p - word1 and word2 are two different plural forms of the one word\n        False - otherwise\n\n        \"\"\"\n        return self._plequal(word1, word2, self.plural_adj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef singular_noun(self, text, count=None, gender=None):\n        pre, word, post = self.partition_word(text)\n        if not word:\n            return text\n        sing = self._sinoun(word, count=count, gender=gender)\n        if sing is not False:\n            plural = self.postprocess(\n                word, self._sinoun(word, count=count, gender=gender)\n            )\n            return \"{}{}{}\".format(pre, plural, post)\n        return False", "response": "Return the singular of text where text is a plural noun."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef a(self, text, count=1):\n        mo = re.search(r\"\\A(\\s*)(?:an?\\s+)?(.+?)(\\s*)\\Z\", text, re.IGNORECASE)\n        if mo:\n            word = mo.group(2)\n            if not word:\n                return text\n            pre = mo.group(1)\n            post = mo.group(3)\n            result = self._indef_article(word, count)\n            return \"{}{}{}\".format(pre, result, post)\n        return \"\"", "response": "Return the appropriate indefinite article followed by text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef no(self, text, count=None):\n        if count is None and self.persistent_count is not None:\n            count = self.persistent_count\n\n        if count is None:\n            count = 0\n        mo = re.search(r\"\\A(\\s*)(.+?)(\\s*)\\Z\", text)\n        pre = mo.group(1)\n        word = mo.group(2)\n        post = mo.group(3)\n\n        if str(count).lower() in pl_count_zero:\n            return \"{}no {}{}\".format(pre, self.plural(word, 0), post)\n        else:\n            return \"{}{} {}{}\".format(pre, count, self.plural(word, count), post)", "response": "Return the no or zero value of the plural of text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef present_participle(self, word):\n        plv = self.plural_verb(word, 2)\n\n        for pat, repl in (\n            (r\"ie$\", r\"y\"),\n            (r\"ue$\", r\"u\"),  # TODO: isn't ue$ -> u encompassed in the following rule?\n            (r\"([auy])e$\", r\"\\g<1>\"),\n            (r\"ski$\", r\"ski\"),\n            (r\"[^b]i$\", r\"\"),\n            (r\"^(are|were)$\", r\"be\"),\n            (r\"^(had)$\", r\"hav\"),\n            (r\"^(hoe)$\", r\"\\g<1>\"),\n            (r\"([^e])e$\", r\"\\g<1>\"),\n            (r\"er$\", r\"er\"),\n            (r\"([^aeiou][aeiouy]([bdgmnprst]))$\", r\"\\g<1>\\g<2>\"),\n        ):\n            (ans, num) = re.subn(pat, repl, plv)\n            if num:\n                return \"%sing\" % ans\n        return \"%sing\" % ans", "response": "Return the present participle for word."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ordinal(self, num):\n        if re.match(r\"\\d\", str(num)):\n            try:\n                num % 2\n                n = num\n            except TypeError:\n                if \".\" in str(num):\n                    try:\n                        # numbers after decimal,\n                        # so only need last one for ordinal\n                        n = int(num[-1])\n\n                    except ValueError:  # ends with '.', so need to use whole string\n                        n = int(num[:-1])\n                else:\n                    n = int(num)\n            try:\n                post = nth[n % 100]\n            except KeyError:\n                post = nth[n % 10]\n            return \"{}{}\".format(num, post)\n        else:\n            mo = re.search(r\"(%s)\\Z\" % ordinal_suff, num)\n            try:\n                post = ordinal[mo.group(1)]\n                return re.sub(r\"(%s)\\Z\" % ordinal_suff, post, num)\n            except AttributeError:\n                return \"%sth\" % num", "response": "Return the ordinal of num."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a number into a list of words.", "response": "def number_to_words(\n        self,\n        num,\n        wantlist=False,\n        group=0,\n        comma=\",\",\n        andword=\"and\",\n        zero=\"zero\",\n        one=\"one\",\n        decimal=\"point\",\n        threshold=None,\n    ):\n        \"\"\"\n        Return a number in words.\n\n        group = 1, 2 or 3 to group numbers before turning into words\n        comma: define comma\n        andword: word for 'and'. Can be set to ''.\n            e.g. \"one hundred and one\" vs \"one hundred one\"\n        zero: word for '0'\n        one: word for '1'\n        decimal: word for decimal point\n        threshold: numbers above threshold not turned into words\n\n        parameters not remembered from last call. Departure from Perl version.\n        \"\"\"\n        self.number_args = dict(andword=andword, zero=zero, one=one)\n        num = \"%s\" % num\n\n        # Handle \"stylistic\" conversions (up to a given threshold)...\n        if threshold is not None and float(num) > threshold:\n            spnum = num.split(\".\", 1)\n            while comma:\n                (spnum[0], n) = re.subn(r\"(\\d)(\\d{3}(?:,|\\Z))\", r\"\\1,\\2\", spnum[0])\n                if n == 0:\n                    break\n            try:\n                return \"{}.{}\".format(spnum[0], spnum[1])\n            except IndexError:\n                return \"%s\" % spnum[0]\n\n        if group < 0 or group > 3:\n            raise BadChunkingOptionError\n        nowhite = num.lstrip()\n        if nowhite[0] == \"+\":\n            sign = \"plus\"\n        elif nowhite[0] == \"-\":\n            sign = \"minus\"\n        else:\n            sign = \"\"\n\n        myord = num[-2:] in (\"st\", \"nd\", \"rd\", \"th\")\n        if myord:\n            num = num[:-2]\n        finalpoint = False\n        if decimal:\n            if group != 0:\n                chunks = num.split(\".\")\n            else:\n                chunks = num.split(\".\", 1)\n            if chunks[-1] == \"\":  # remove blank string if nothing after decimal\n                chunks = chunks[:-1]\n                finalpoint = True  # add 'point' to end of output\n        else:\n            chunks = [num]\n\n        first = 1\n        loopstart = 0\n\n        if chunks[0] == \"\":\n            first = 0\n            if len(chunks) > 1:\n                loopstart = 1\n\n        for i in range(loopstart, len(chunks)):\n            chunk = chunks[i]\n            # remove all non numeric \\D\n            chunk = re.sub(r\"\\D\", self.blankfn, chunk)\n            if chunk == \"\":\n                chunk = \"0\"\n\n            if group == 0 and (first == 0 or first == \"\"):\n                chunk = self.enword(chunk, 1)\n            else:\n                chunk = self.enword(chunk, group)\n\n            if chunk[-2:] == \", \":\n                chunk = chunk[:-2]\n            chunk = re.sub(r\"\\s+,\", self.commafn, chunk)\n\n            if group == 0 and first:\n                chunk = re.sub(r\", (\\S+)\\s+\\Z\", \" %s \\\\1\" % andword, chunk)\n            chunk = re.sub(r\"\\s+\", self.spacefn, chunk)\n            # chunk = re.sub(r\"(\\A\\s|\\s\\Z)\", self.blankfn, chunk)\n            chunk = chunk.strip()\n            if first:\n                first = \"\"\n            chunks[i] = chunk\n\n        numchunks = []\n        if first != 0:\n            numchunks = chunks[0].split(\"%s \" % comma)\n\n        if myord and numchunks:\n            # TODO: can this be just one re as it is in perl?\n            mo = re.search(r\"(%s)\\Z\" % ordinal_suff, numchunks[-1])\n            if mo:\n                numchunks[-1] = re.sub(\n                    r\"(%s)\\Z\" % ordinal_suff, ordinal[mo.group(1)], numchunks[-1]\n                )\n            else:\n                numchunks[-1] += \"th\"\n\n        for chunk in chunks[1:]:\n            numchunks.append(decimal)\n            numchunks.extend(chunk.split(\"%s \" % comma))\n\n        if finalpoint:\n            numchunks.append(decimal)\n\n        # wantlist: Perl list context. can explictly specify in Python\n        if wantlist:\n            if sign:\n                numchunks = [sign] + numchunks\n            return numchunks\n        elif group:\n            signout = \"%s \" % sign if sign else \"\"\n            return \"{}{}\".format(signout, \", \".join(numchunks))\n        else:\n            signout = \"%s \" % sign if sign else \"\"\n            num = \"{}{}\".format(signout, numchunks.pop(0))\n            if decimal is None:\n                first = True\n            else:\n                first = not num.endswith(decimal)\n            for nc in numchunks:\n                if nc == decimal:\n                    num += \" %s\" % nc\n                    first = 0\n                elif first:\n                    num += \"{} {}\".format(comma, nc)\n                else:\n                    num += \" %s\" % nc\n            return num"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef join(\n        self,\n        words,\n        sep=None,\n        sep_spaced=True,\n        final_sep=None,\n        conj=\"and\",\n        conj_spaced=True,\n    ):\n        \"\"\"\n        Join words into a list.\n\n        e.g. join(['ant', 'bee', 'fly']) returns 'ant, bee, and fly'\n\n        options:\n        conj: replacement for 'and'\n        sep: separator. default ',', unless ',' is in the list then ';'\n        final_sep: final separator. default ',', unless ',' is in the list then ';'\n        conj_spaced: boolean. Should conj have spaces around it\n\n        \"\"\"\n        if not words:\n            return \"\"\n        if len(words) == 1:\n            return words[0]\n\n        if conj_spaced:\n            if conj == \"\":\n                conj = \" \"\n            else:\n                conj = \" %s \" % conj\n\n        if len(words) == 2:\n            return \"{}{}{}\".format(words[0], conj, words[1])\n\n        if sep is None:\n            if \",\" in \"\".join(words):\n                sep = \";\"\n            else:\n                sep = \",\"\n        if final_sep is None:\n            final_sep = sep\n\n        final_sep = \"{}{}\".format(final_sep, conj)\n\n        if sep_spaced:\n            sep += \" \"\n\n        return \"{}{}{}\".format(sep.join(words[0:-1]), final_sep, words[-1])", "response": "Join the words into a list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _int(int_or_str: Any) -> int:\n    \"return an integer where a single character string may be expected\"\n    if isinstance(int_or_str, str):\n        return ord(int_or_str)\n    if isinstance(int_or_str, bytes):\n        return int_or_str[0]\n    return int(int_or_str)", "response": "return an integer where a single character string may be expected"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a cffi console.", "response": "def _console(console: Any) -> Any:\n    \"\"\"Return a cffi console.\"\"\"\n    try:\n        return console.console_c\n    except AttributeError:\n        warnings.warn(\n            (\n                \"Falsy console parameters are deprecated, \"\n                \"always use the root console instance returned by \"\n                \"console_init_root.\"\n            ),\n            DeprecationWarning,\n            stacklevel=3,\n        )\n        return ffi.NULL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new color from a cdata object.", "response": "def _new_from_cdata(cls, cdata: Any) -> \"Color\":\n        \"\"\"new in libtcod-cffi\"\"\"\n        return cls(cdata.r, cdata.g, cdata.b)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a bitmask in human readable form.", "response": "def _describe_bitmask(\n    bits: int, table: Dict[Any, str], default: str = \"0\"\n) -> str:\n    \"\"\"Returns a bitmask in human readable form.\n\n    This is a private function, used internally.\n\n    Args:\n        bits (int): The bitmask to be represented.\n        table (Dict[Any,str]): A reverse lookup table.\n        default (Any): A default return value when bits is 0.\n\n    Returns: str: A printable version of the bits variable.\n    \"\"\"\n    result = []\n    for bit, name in table.items():\n        if bit & bits:\n            result.append(name)\n    if not result:\n        return default\n    return \"|\".join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pixel_to_tile(x: float, y: float) -> Tuple[float, float]:\n    xy = tcod.ffi.new(\"double[2]\", (x, y))\n    tcod.lib.TCOD_sys_pixel_to_tile(xy, xy + 1)\n    return xy[0], xy[1]", "response": "Convert pixel coordinates to tile coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get() -> Iterator[Any]:\n    sdl_event = tcod.ffi.new(\"SDL_Event*\")\n    while tcod.lib.SDL_PollEvent(sdl_event):\n        if sdl_event.type in _SDL_TO_CLASS_TABLE:\n            yield _SDL_TO_CLASS_TABLE[sdl_event.type].from_sdl_event(sdl_event)\n        else:\n            yield Undefined.from_sdl_event(sdl_event)", "response": "Return an iterator for all pending events."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nblocking until events exist then return an event iterator.", "response": "def wait(timeout: Optional[float] = None) -> Iterator[Any]:\n    \"\"\"Block until events exist, then return an event iterator.\n\n    `timeout` is the maximum number of seconds to wait as a floating point\n    number with millisecond precision, or it can be None to wait forever.\n\n    Returns the same iterator as a call to :any:`tcod.event.get`.\n\n    Example::\n\n        for event in tcod.event.wait():\n            if event.type == \"QUIT\":\n                print(event)\n                raise SystemExit()\n            elif event.type == \"KEYDOWN\":\n                print(event)\n            elif event.type == \"MOUSEBUTTONDOWN\":\n                print(event)\n            elif event.type == \"MOUSEMOTION\":\n                print(event)\n            else:\n                print(event)\n    \"\"\"\n    if timeout is not None:\n        tcod.lib.SDL_WaitEventTimeout(tcod.ffi.NULL, int(timeout * 1000))\n    else:\n        tcod.lib.SDL_WaitEvent(tcod.ffi.NULL)\n    return get()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the current state of the mouse.", "response": "def get_mouse_state() -> MouseState:\n    \"\"\"Return the current state of the mouse.\n\n    .. addedversion:: 9.3\n    \"\"\"\n    xy = tcod.ffi.new(\"int[2]\")\n    buttons = tcod.lib.SDL_GetMouseState(xy, xy + 1)\n    x, y = _pixel_to_tile(*xy)\n    return MouseState((xy[0], xy[1]), (int(x), int(y)), buttons)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch an event to an ev_* method.", "response": "def dispatch(self, event: Any) -> None:\n        \"\"\"Send an event to an `ev_*` method.\n\n        `*` will be the events type converted to lower-case.\n\n        If `event.type` is an empty string or None then it will be ignored.\n        \"\"\"\n        if event.type:\n            getattr(self, \"ev_%s\" % (event.type.lower(),))(event)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a decorator which adds a warning to functions.", "response": "def deprecate(\n    message: str, category: Any = DeprecationWarning, stacklevel: int = 0\n) -> Callable[[F], F]:\n    \"\"\"Return a decorator which adds a warning to functions.\"\"\"\n\n    def decorator(func: F) -> F:\n        if not __debug__:\n            return func\n\n        @functools.wraps(func)\n        def wrapper(*args, **kargs):  # type: ignore\n            warnings.warn(message, category, stacklevel=stacklevel + 2)\n            return func(*args, **kargs)\n\n        return cast(F, wrapper)\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pending_deprecate(\n    message: str = \"This function may be deprecated in the future.\"\n    \" Consider raising an issue on GitHub if you need this feature.\",\n    category: Any = PendingDeprecationWarning,\n    stacklevel: int = 0,\n) -> Callable[[F], F]:\n    \"\"\"Like deprecate, but the default parameters are filled out for a generic\n    pending deprecation warning.\"\"\"\n    return deprecate(message, category, stacklevel)", "response": "A function decorator that returns a function that will be used to deprecate a pending deprecation warning."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_char(char):\n    if char is None:\n        return -1\n    if isinstance(char, _STRTYPES) and len(char) == 1:\n        return ord(char)\n    try:\n        return int(char) # allow all int-like objects\n    except:\n        raise TypeError('char single character string, integer, or None\\nReceived: ' + repr(char))", "response": "Prepares a single character for passing to ctypes calls returns a integer and returns the current character\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt fast string handing by decoding directly into an array.", "response": "def _format_str(string):\n    \"\"\"Attempt fast string handing by decoding directly into an array.\"\"\"\n    if isinstance(string, _STRTYPES):\n        if _IS_PYTHON3:\n            array = _array.array('I')\n            array.frombytes(string.encode(_utf32_codec))\n        else: # Python 2\n            if isinstance(string, unicode):\n                array = _array.array(b'I')\n                array.fromstring(string.encode(_utf32_codec))\n            else:\n                array = _array.array(b'B')\n                array.fromstring(string)\n        return array\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to get the width and height of a png image file", "response": "def _getImageSize(filename):\n    \"\"\"Try to get the width and height of a bmp of png image file\"\"\"\n    result = None\n    file = open(filename, 'rb')\n    if file.read(8) == b'\\x89PNG\\r\\n\\x1a\\n': # PNG\n        while 1:\n            length, = _struct.unpack('>i', file.read(4))\n            chunkID = file.read(4)\n            if chunkID == '': # EOF\n                break\n            if chunkID == b'IHDR':\n                # return width, height\n                result = _struct.unpack('>ii', file.read(8))\n                break\n            file.seek(4 + length, 1)\n        file.close()\n        return result\n    file.seek(0)\n    if file.read(8) == b'BM': # Bitmap\n        file.seek(18, 0) # skip to size data\n        result = _struct.unpack('<ii', file.read(8))\n    file.close()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the root console with the given width and height and return the root console.", "response": "def init(width, height, title=None, fullscreen=False, renderer='SDL'):\n    \"\"\"Start the main console with the given width and height and return the\n    root console.\n\n    Call the consoles drawing functions.  Then remember to use L{tdl.flush} to\n    make what's drawn visible on the console.\n\n    Args:\n        width (int): width of the root console (in tiles)\n        height (int): height of the root console (in tiles)\n        title (Optiona[Text]):\n            Text to display as the window title.\n\n            If left None it defaults to the running scripts filename.\n        fullscreen (bool): Can be set to True to start in fullscreen mode.\n        renderer (Text): Can be one of 'GLSL', 'OPENGL', or 'SDL'.\n\n        Due to way Python works you're unlikely to see much of an\n        improvement by using 'GLSL' over 'OPENGL' as most of the\n        time Python is slow interacting with the console and the\n        rendering itself is pretty fast even on 'SDL'.\n\n    Returns:\n        tdl.Console: The root console.\n\n            Only what is drawn on the root console is\n            what's visible after a call to :any:`tdl.flush`.\n            After the root console is garbage collected, the window made by\n            this function will close.\n\n    .. seealso::\n        :any:`Console` :any:`set_font`\n    \"\"\"\n    RENDERERS = {'GLSL': 0, 'OPENGL': 1, 'SDL': 2}\n    global _rootinitialized, _rootConsoleRef\n    if not _fontinitialized: # set the default font to the one that comes with tdl\n        set_font(_os.path.join(__path__[0], 'terminal8x8.png'),\n                 None, None, True, True)\n\n    if renderer.upper() not in RENDERERS:\n        raise TDLError('No such render type \"%s\", expected one of \"%s\"' % (renderer, '\", \"'.join(RENDERERS)))\n    renderer = RENDERERS[renderer.upper()]\n\n    # If a console already exists then make a clone to replace it\n    if _rootConsoleRef and _rootConsoleRef():\n        # unhook the root console, turning into a regular console and deleting\n        # the root console from libTCOD\n        _rootConsoleRef()._root_unhook()\n\n    if title is None: # use a default title\n        if _sys.argv:\n            # Use the script filename as the title.\n            title = _os.path.basename(_sys.argv[0])\n        else:\n            title = 'python-tdl'\n\n    _lib.TCOD_console_init_root(width, height, _encodeString(title), fullscreen, renderer)\n\n    #event.get() # flush the libtcod event queue to fix some issues\n    # issues may be fixed already\n\n    event._eventsflushed = False\n    _rootinitialized = True\n    rootconsole = Console._newConsole(_ffi.NULL)\n    _rootConsoleRef = _weakref.ref(rootconsole)\n\n    return rootconsole"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_font(path, columns=None, rows=None, columnFirst=False,\n             greyscale=False, altLayout=False):\n    \"\"\"Changes the font to be used for this session.\n    This should be called before :any:`tdl.init`\n\n    If the font specifies its size in its filename (i.e. font_NxN.png) then this\n    function can auto-detect the tileset formatting and the parameters columns\n    and rows can be left None.\n\n    While it's possible you can change the font mid program it can sometimes\n    break in rare circumstances.  So use caution when doing this.\n\n    Args:\n        path (Text): A file path to a `.bmp` or `.png` file.\n        columns (int):\n            Number of columns in the tileset.\n\n            Can be left None for auto-detection.\n        rows (int):\n            Number of rows in the tileset.\n\n            Can be left None for auto-detection.\n        columnFirst (bool):\n            Defines if the characer order goes along the rows or colomns.\n\n            It should be True if the charater codes 0-15 are in the\n            first column, and should be False if the characters 0-15\n            are in the first row.\n        greyscale (bool):\n            Creates an anti-aliased font from a greyscale bitmap.\n            Otherwise it uses the alpha channel for anti-aliasing.\n\n            Unless you actually need anti-aliasing from a font you\n            know uses a smooth greyscale channel you should leave\n            this on False.\n        altLayout (bool)\n            An alternative layout with space in the upper left corner.\n            The colomn parameter is ignored if this is True,\n            find examples of this layout in the `font/libtcod/`\n            directory included with the python-tdl source.\n\n    Raises:\n        TDLError: Will be raised if no file is found at path or if auto-\n                  detection fails.\n    \"\"\"\n    # put up some constants that are only used here\n    FONT_LAYOUT_ASCII_INCOL = 1\n    FONT_LAYOUT_ASCII_INROW = 2\n    FONT_TYPE_GREYSCALE = 4\n    FONT_LAYOUT_TCOD = 8\n    global _fontinitialized\n    _fontinitialized = True\n    flags = 0\n    if altLayout:\n        flags |= FONT_LAYOUT_TCOD\n    elif columnFirst:\n        flags |= FONT_LAYOUT_ASCII_INCOL\n    else:\n        flags |= FONT_LAYOUT_ASCII_INROW\n    if greyscale:\n        flags |= FONT_TYPE_GREYSCALE\n    if not _os.path.exists(path):\n        raise TDLError('Font %r not found.' % _os.path.abspath(path))\n    path = _os.path.abspath(path)\n\n    # and the rest is the auto-detect script\n    imgSize = _getImageSize(path) # try to find image size\n    if imgSize:\n        fontWidth, fontHeight = None, None\n        imgWidth, imgHeight = imgSize\n        # try to get font size from filename\n        match = _re.match('.*?([0-9]+)[xX]([0-9]+)', _os.path.basename(path))\n        if match:\n            fontWidth, fontHeight = match.groups()\n            fontWidth, fontHeight = int(fontWidth), int(fontHeight)\n\n            # estimate correct tileset size\n            estColumns, remC = divmod(imgWidth, fontWidth)\n            estRows, remR = divmod(imgHeight, fontHeight)\n            if remC or remR:\n                _warnings.warn(\"Font may be incorrectly formatted.\")\n\n            if not columns:\n                columns = estColumns\n            if not rows:\n                rows = estRows\n        else:\n            # filename doesn't contain NxN, but we can still estimate the fontWidth\n            # and fontHeight given number of columns and rows.\n            if columns and rows:\n                fontWidth, remC = divmod(imgWidth, columns)\n                fontHeight, remR = divmod(imgHeight, rows)\n                if remC or remR:\n                    _warnings.warn(\"Font may be incorrectly formatted.\")\n\n            # the font name excluded the fonts size\n            if not (columns and rows):\n                # no matched font size and no tileset is given\n                raise TDLError('%s has no font size in filename' % _os.path.basename(path))\n\n        if columns and rows:\n            # confirm user set options\n            if (fontWidth * columns != imgWidth or\n                fontHeight * rows != imgHeight):\n                _warnings.warn(\"set_font parameters are set as if the image size is (%d, %d) when the detected size is actually (%i, %i)\"\n                             % (fontWidth * columns, fontHeight * rows,\n                                imgWidth, imgHeight))\n    else:\n        _warnings.warn(\"%s is probably not an image.\" % _os.path.basename(path))\n\n    if not (columns and rows):\n        # didn't auto-detect\n        raise TDLError('Can not auto-detect the tileset of %s' % _os.path.basename(path))\n\n    _lib.TCOD_console_set_custom_font(_encodeString(path), flags, columns, rows)", "response": "Changes the font used for this session."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncaptures the screen and save it as a png file.", "response": "def screenshot(path=None):\n    \"\"\"Capture the screen and save it as a png file.\n\n    If path is None then the image will be placed in the current\n    folder with the names:\n    ``screenshot001.png, screenshot002.png, ...``\n\n    Args:\n        path (Optional[Text]): The file path to save the screenshot.\n    \"\"\"\n    if not _rootinitialized:\n        raise TDLError('Initialize first with tdl.init')\n    if isinstance(path, str):\n        _lib.TCOD_sys_save_screenshot(_encodeString(path))\n    elif path is None: # save to screenshot001.png, screenshot002.png, ...\n        filelist = _os.listdir('.')\n        n = 1\n        filename = 'screenshot%.3i.png' % n\n        while filename in filelist:\n            n += 1\n            filename = 'screenshot%.3i.png' % n\n        _lib.TCOD_sys_save_screenshot(_encodeString(filename))\n    else: # assume file like obj\n        #save to temp file and copy to file-like obj\n        tmpname = _os.tempnam()\n        _lib.TCOD_sys_save_screenshot(_encodeString(tmpname))\n        with tmpname as tmpfile:\n            path.write(tmpfile.read())\n        _os.remove(tmpname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _normalizePoint(self, x, y):\n        # cast to int, always faster than type checking\n        x = int(x)\n        y = int(y)\n\n        assert (-self.width <= x < self.width) and \\\n               (-self.height <= y < self.height), \\\n               ('(%i, %i) is an invalid postition on %s' % (x, y, self))\n\n        # handle negative indexes\n        return (x % self.width, y % self.height)", "response": "Check if a point is in bounds and make minor adjustments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _normalizeRect(self, x, y, width, height):\n        x, y = self._normalizePoint(x, y) # inherit _normalizePoint logic\n\n        assert width is None or isinstance(width, _INTTYPES), 'width must be an integer or None, got %s' % repr(width)\n        assert height is None or isinstance(height, _INTTYPES), 'height must be an integer or None, got %s' % repr(height)\n\n        # if width or height are None then extend them to the edge\n        if width is None:\n            width = self.width - x\n        elif width < 0: # handle negative numbers\n            width += self.width\n            width = max(0, width) # a 'too big' negative is clamped zero\n        if height is None:\n            height = self.height - y\n            height = max(0, height)\n        elif height < 0:\n            height += self.height\n\n        # reduce rect size to bounds\n        width = min(width, self.width - x)\n        height = min(height, self.height - y)\n\n        return x, y, width, height", "response": "Normalize the rectangle to be within bounds and make minor adjustments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the normalized the cursor position.", "response": "def _normalizeCursor(self, x, y):\n        \"\"\"return the normalized the cursor position.\"\"\"\n        width, height = self.get_size()\n        assert width != 0 and height != 0, 'can not print on a console with a width or height of zero'\n        while x >= width:\n            x -= width\n            y += 1\n        while y >= height:\n            if self._scrollMode == 'scroll':\n                y -= 1\n                self.scroll(0, -1)\n            elif self._scrollMode == 'error':\n                # reset the cursor on error\n                self._cursor = (0, 0)\n                raise TDLError('Cursor has reached the end of the console')\n        return (x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_colors(self, fg=None, bg=None):\n        if fg is not None:\n            self._fg = _format_color(fg, self._fg)\n        if bg is not None:\n            self._bg = _format_color(bg, self._bg)", "response": "Sets the colors to be used with the L { print_str and draw_* methods."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_str(self, string):\n        x, y = self._cursor\n        for char in string:\n            if char == '\\n': # line break\n                x = 0\n                y += 1\n                continue\n            if char == '\\r': # return\n                x = 0\n                continue\n            x, y = self._normalizeCursor(x, y)\n            self.draw_char(x, y, char, self._fg, self._bg)\n            x += 1\n        self._cursor = (x, y)", "response": "Print a string at the virtual cursor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, string):\n        # some 'basic' line buffer stuff.\n        # there must be an easier way to do this.  The textwrap module didn't\n        # help much.\n        x, y = self._normalizeCursor(*self._cursor)\n        width, height = self.get_size()\n        wrapper = _textwrap.TextWrapper(initial_indent=(' '*x), width=width)\n        writeLines = []\n        for line in string.split('\\n'):\n            if line:\n                writeLines += wrapper.wrap(line)\n                wrapper.initial_indent = ''\n            else:\n                writeLines.append([])\n\n        for line in writeLines:\n            x, y = self._normalizeCursor(x, y)\n            self.draw_str(x, y, line[x:], self._fg, self._bg)\n            y += 1\n            x = 0\n        y -= 1\n        self._cursor = (x, y)", "response": "This method writes out the text to the screen."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws a single character on the console.", "response": "def draw_char(self, x, y, char, fg=Ellipsis, bg=Ellipsis):\n        \"\"\"Draws a single character.\n\n        Args:\n            x (int): x-coordinate to draw on.\n            y (int): y-coordinate to draw on.\n            char (Optional[Union[int, Text]]): An integer, single character\n                string, or None.\n\n                You can set the char parameter as None if you only want to change\n                the colors of the tile.\n            fg (Optional[Union[Tuple[int, int, int], int, Ellipsis]])\n            bg (Optional[Union[Tuple[int, int, int], int, Ellipsis]])\n\n        Raises: AssertionError: Having x or y values that can't be placed\n            inside of the console will raise an AssertionError.\n            You can use always use ((x, y) in console) to\n            check if a tile is drawable.\n\n        .. seealso:: :any:`get_char`\n        \"\"\"\n        #x, y = self._normalizePoint(x, y)\n        _put_char_ex(self.console_c, x, y, _format_char(char),\n                     _format_color(fg, self._fg), _format_color(bg, self._bg), 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_str(self, x, y, string, fg=Ellipsis, bg=Ellipsis):\n\n        x, y = self._normalizePoint(x, y)\n        fg, bg = _format_color(fg, self._fg), _format_color(bg, self._bg)\n        width, height = self.get_size()\n        def _drawStrGen(x=x, y=y, string=string, width=width, height=height):\n            \"\"\"Generator for draw_str\n\n            Iterates over ((x, y), ch) data for _set_batch, raising an\n            error if the end of the console is reached.\n            \"\"\"\n            for char in _format_str(string):\n                if y == height:\n                    raise TDLError('End of console reached.')\n                yield((x, y), char)\n                x += 1 # advance cursor\n                if x == width: # line break\n                    x = 0\n                    y += 1\n        self._set_batch(_drawStrGen(), fg, bg)", "response": "Draws a string starting at x y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef draw_rect(self, x, y, width, height, string, fg=Ellipsis, bg=Ellipsis):\n        x, y, width, height = self._normalizeRect(x, y, width, height)\n        fg, bg = _format_color(fg, self._fg), _format_color(bg, self._bg)\n        char = _format_char(string)\n        # use itertools to make an x,y grid\n        # using ctypes here reduces type converstions later\n        #grid = _itertools.product((_ctypes.c_int(x) for x in range(x, x + width)),\n        #                          (_ctypes.c_int(y) for y in range(y, y + height)))\n        grid = _itertools.product((x for x in range(x, x + width)),\n                                  (y for y in range(y, y + height)))\n        # zip the single character in a batch variable\n        batch = zip(grid, _itertools.repeat(char, width * height))\n        self._set_batch(batch, fg, bg, nullChar=(char is None))", "response": "Draws a rectangle starting from x y width and height."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_frame(self, x, y, width, height, string, fg=Ellipsis, bg=Ellipsis):\n        x, y, width, height = self._normalizeRect(x, y, width, height)\n        fg, bg = _format_color(fg, self._fg), _format_color(bg, self._bg)\n        char = _format_char(string)\n        if width == 1 or height == 1: # it's just a single width line here\n            return self.draw_rect(x, y, width, height, char, fg, bg)\n\n        # draw sides of frame with draw_rect\n        self.draw_rect(x, y, 1, height, char, fg, bg)\n        self.draw_rect(x, y, width, 1, char, fg, bg)\n        self.draw_rect(x + width - 1, y, 1, height, char, fg, bg)\n        self.draw_rect(x, y + height - 1, width, 1, char, fg, bg)", "response": "Similar to draw_rect but only draws the outline of the rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blit(self, source, x=0, y=0, width=None, height=None, srcX=0, srcY=0,\n             fg_alpha=1.0, bg_alpha=1.0):\n        \"\"\"Blit another console or Window onto the current console.\n\n        By default it blits the entire source to the topleft corner.\n\n        Args:\n            source (Union[tdl.Console, tdl.Window]): The blitting source.\n                A console can blit to itself without any problems.\n            x (int): x-coordinate of this console to blit on.\n            y (int): y-coordinate of this console to blit on.\n            width (Optional[int]): Width of the rectangle.\n\n                Can be None to extend as far as possible to the\n                bottom right corner of the blit area or can be a negative\n                number to be sized reltive to the total size of the\n                B{destination} console.\n            height (Optional[int]): Height of the rectangle.\n            srcX (int):  x-coordinate of the source region to blit.\n            srcY (int):  y-coordinate of the source region to blit.\n            fg_alpha (float): The foreground alpha.\n        \"\"\"\n        assert isinstance(source, (Console, Window)), \"source muse be a Window or Console instance\"\n\n        # handle negative indexes and rects\n        # negative width and height will be set realtive to the destination\n        # and will also be clamped to the smallest Console\n        x, y, width, height = self._normalizeRect(x, y, width, height)\n        srcX, srcY, width, height = source._normalizeRect(srcX, srcY, width, height)\n\n        # translate source and self if any of them are Window instances\n        srcX, srcY = source._translate(srcX, srcY)\n        source = source.console\n        x, y = self._translate(x, y)\n        self = self.console\n\n        if self == source:\n            # if we are the same console then we need a third console to hold\n            # onto the data, otherwise it tries to copy into itself and\n            # starts destroying everything\n            tmp = Console(width, height)\n            _lib.TCOD_console_blit(source.console_c,\n                                   srcX, srcY, width, height,\n                                   tmp.console_c, 0, 0, fg_alpha, bg_alpha)\n            _lib.TCOD_console_blit(tmp.console_c, 0, 0, width, height,\n                                   self.console_c, x, y, fg_alpha, bg_alpha)\n        else:\n            _lib.TCOD_console_blit(source.console_c,\n                                   srcX, srcY, width, height,\n                                   self.console_c, x, y, fg_alpha, bg_alpha)", "response": "Blits another console or Window onto the current console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cursor(self):\n        x, y = self._cursor\n        width, height = self.parent.get_size()\n        while x >= width:\n            x -= width\n            y += 1\n        if y >= height and self.scrollMode == 'scroll':\n            y = height - 1\n        return x, y", "response": "Return the virtual cursor position."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove the virtual cursor.", "response": "def move(self, x, y):\n        \"\"\"Move the virtual cursor.\n\n        Args:\n            x (int): x-coordinate to place the cursor.\n            y (int): y-coordinate to place the cursor.\n\n        .. seealso:: :any:`get_cursor`, :any:`print_str`, :any:`write`\n        \"\"\"\n        self._cursor = self._normalizePoint(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscrolling the contents of the console in the given direction of x y.", "response": "def scroll(self, x, y):\n        \"\"\"Scroll the contents of the console in the direction of x,y.\n\n        Uncovered areas will be cleared to the default background color.\n        Does not move the virutal cursor.\n\n        Args:\n            x (int): Distance to scroll along the x-axis.\n            y (int): Distance to scroll along the y-axis.\n\n        Returns:\n            Iterator[Tuple[int, int]]: An iterator over the (x, y) coordinates\n            of any tile uncovered after scrolling.\n\n        .. seealso:: :any:`set_colors`\n        \"\"\"\n        assert isinstance(x, _INTTYPES), \"x must be an integer, got %s\" % repr(x)\n        assert isinstance(y, _INTTYPES), \"y must be an integer, got %s\" % repr(x)\n        def getSlide(x, length):\n            \"\"\"get the parameters needed to scroll the console in the given\n            direction with x\n            returns (x, length, srcx)\n            \"\"\"\n            if x > 0:\n                srcx = 0\n                length -= x\n            elif x < 0:\n                srcx = abs(x)\n                x = 0\n                length -= srcx\n            else:\n                srcx = 0\n            return x, length, srcx\n        def getCover(x, length):\n            \"\"\"return the (x, width) ranges of what is covered and uncovered\"\"\"\n            cover = (0, length) # everything covered\n            uncover = None  # nothing uncovered\n            if x > 0: # left side uncovered\n                cover = (x, length - x)\n                uncover = (0, x)\n            elif x < 0: # right side uncovered\n                x = abs(x)\n                cover = (0, length - x)\n                uncover = (length - x, x)\n            return cover, uncover\n\n        width, height = self.get_size()\n        if abs(x) >= width or abs(y) >= height:\n            return self.clear() # just clear the console normally\n\n        # get the ranges of the areas that will be uncovered\n        coverX, uncoverX = getCover(x, width)\n        coverY, uncoverY = getCover(y, height)\n        # so at this point we know that coverX and coverY makes a rect that\n        # encases the area that we end up blitting to.  uncoverX/Y makes a\n        # rect in the corner of the uncovered area.  So we need to combine\n        # the uncoverX/Y with coverY/X to make what's left of the uncovered\n        # area.  Explaining it makes it mush easier to do now.\n\n        # But first we need to blit.\n        x, width, srcx = getSlide(x, width)\n        y, height, srcy = getSlide(y, height)\n        self.blit(self, x, y, width, height, srcx, srcy)\n        if uncoverX: # clear sides (0x20 is space)\n            self.draw_rect(uncoverX[0], coverY[0], uncoverX[1], coverY[1],\n                           0x20, self._fg, self._bg)\n        if uncoverY: # clear top/bottom\n            self.draw_rect(coverX[0], uncoverY[0], coverX[1], uncoverY[1],\n                           0x20, self._fg, self._bg)\n        if uncoverX and uncoverY: # clear corner\n            self.draw_rect(uncoverX[0], uncoverY[0], uncoverX[1], uncoverY[1],\n                           0x20, self._fg, self._bg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _newConsole(cls, console):\n        self = cls.__new__(cls)\n        _BaseConsole.__init__(self)\n        self.console_c = console\n        self.console = self\n        self.width = _lib.TCOD_console_get_width(console)\n        self.height = _lib.TCOD_console_get_height(console)\n        return self", "response": "Make a Console instance from a console ctype"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _root_unhook(self):\n        global _rootinitialized, _rootConsoleRef\n        # do we recognise this as the root console?\n        # if not then assume the console has already been taken care of\n        if(_rootConsoleRef and _rootConsoleRef() is self):\n            # turn this console into a regular console\n            unhooked = _lib.TCOD_console_new(self.width, self.height)\n            _lib.TCOD_console_blit(self.console_c,\n                                   0, 0, self.width, self.height,\n                                   unhooked, 0, 0, 1, 1)\n            # delete root console from TDL and TCOD\n            _rootinitialized = False\n            _rootConsoleRef = None\n            _lib.TCOD_console_delete(self.console_c)\n            # this Console object is now a regular console\n            self.console_c = unhooked", "response": "Change this root console into a normal Console object and delete the root console from TDL and TCOD\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a character at the specified location.", "response": "def _set_char(self, x, y, char, fg=None, bg=None,\n                  bgblend=_lib.TCOD_BKGND_SET):\n        \"\"\"\n        Sets a character.\n        This is called often and is designed to be as fast as possible.\n\n        Because of the need for speed this function will do NO TYPE CHECKING\n        AT ALL, it's up to the drawing functions to use the functions:\n        _format_char and _format_color before passing to this.\"\"\"\n        # values are already formatted, honestly this function is redundant\n        return _put_char_ex(self.console_c, x, y, char, fg, bg, bgblend)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_batch(self, batch, fg, bg, bgblend=1, nullChar=False):\n        for (x, y), char in batch:\n            self._set_char(x, y, char, fg, bg, bgblend)", "response": "Set the items in the given batch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _translate(self, x, y):\n        # we add our position relative to our parent and then call then next parent up\n        return self.parent._translate((x + self.x), (y + self.y))", "response": "Convertion x and y to their position on the root Console"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls the callback function in libtcodpy style.", "response": "def _pycall_path_old(x1: int, y1: int, x2: int, y2: int, handle: Any) -> float:\n    \"\"\"libtcodpy style callback, needs to preserve the old userData issue.\"\"\"\n    func, userData = ffi.from_handle(handle)\n    return func(x1, y1, x2, y2, userData)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pycall_path_simple(\n    x1: int, y1: int, x2: int, y2: int, handle: Any\n) -> float:\n    \"\"\"Does less and should run faster, just calls the handle function.\"\"\"\n    return ffi.from_handle(handle)(x1, y1, x2, y2)", "response": "Does less and should run faster just calls the handle function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a properly cast PathCostArray callback.", "response": "def _get_pathcost_func(\n    name: str\n) -> Callable[[int, int, int, int, Any], float]:\n    \"\"\"Return a properly cast PathCostArray callback.\"\"\"\n    return ffi.cast(  # type: ignore\n        \"TCOD_path_func_t\", ffi.addressof(lib, name)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tcod_path_ffi(self) -> Tuple[Any, Any, Tuple[int, int]]:\n        return self._CALLBACK_P, ffi.new_handle(self._userdata), self.shape", "response": "Return ( C callback userdata handle shape )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of points to reach the goal point.", "response": "def get_path(\n        self, start_x: int, start_y: int, goal_x: int, goal_y: int\n    ) -> List[Tuple[int, int]]:\n        \"\"\"Return a list of (x, y) steps to reach the goal point, if possible.\n\n        Args:\n            start_x (int): Starting X position.\n            start_y (int): Starting Y position.\n            goal_x (int): Destination X position.\n            goal_y (int): Destination Y position.\n        Returns:\n            List[Tuple[int, int]]:\n                A list of points, or an empty list if there is no valid path.\n        \"\"\"\n        lib.TCOD_path_compute(self._path_c, start_x, start_y, goal_x, goal_y)\n        path = []\n        x = ffi.new(\"int[2]\")\n        y = x + 1\n        while lib.TCOD_path_walk(self._path_c, x, y, False):\n            path.append((x[0], y[0]))\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_goal(self, x: int, y: int) -> None:\n        lib.TCOD_dijkstra_compute(self._path_c, x, y)", "response": "Set the goal point and recompute the Dijkstra path - finder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_path(self, x: int, y: int) -> List[Tuple[int, int]]:\n        lib.TCOD_dijkstra_path_set(self._path_c, x, y)\n        path = []\n        pointer_x = ffi.new(\"int[2]\")\n        pointer_y = pointer_x + 1\n        while lib.TCOD_dijkstra_path_walk(self._path_c, pointer_x, pointer_y):\n            path.append((pointer_x[0], pointer_y[0]))\n        return path", "response": "Return a list of tuples that are the points at x y."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange character in position x y.", "response": "def change_cell(self, x, y, ch, fg, bg):\n        \"\"\"Change cell in position (x;y).\n        \"\"\"\n        self.console.draw_char(x, y, ch, fg, bg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits for an event and return it.", "response": "def poll_event(self):\n        \"\"\"Wait for an event and return it.\n\n           Returns a tuple: (type, unicode character, key, mod, width, height,\n           mousex, mousey).\n        \"\"\"\n        \"\"\"\n        cdef tb_event e\n        with self._poll_lock:\n            with nogil:\n                result = tb_poll_event(&e)\n        assert(result >= 0)\n        if e.ch:\n            uch = unichr(e.ch)\n        else:\n            uch = None\n        \"\"\"\n        for e in tdl.event.get():\n            # [ ] not all events are passed thru\n            self.e.type = e.type\n            if e.type == 'KEYDOWN':\n                self.e.key = e.key\n                return self.e.gettuple()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new instance encapsulating this cdata.", "response": "def _new_from_cdata(cls, cdata: Any) -> \"Random\":\n        \"\"\"Return a new instance encapsulating this cdata.\"\"\"\n        self = object.__new__(cls)  # type: \"Random\"\n        self.random_c = cdata\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef randint(self, low: int, high: int) -> int:\n        return int(lib.TCOD_random_get_i(self.random_c, low, high))", "response": "Return a random integer within the linear range low < = n < = high."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random floating number in the range low and high.", "response": "def uniform(self, low: float, high: float) -> float:\n        \"\"\"Return a random floating number in the range: low <= n <= high.\n\n        Args:\n            low (float): The lower bound of the random range.\n            high (float): The upper bound of the random range.\n\n        Returns:\n            float: A random float.\n        \"\"\"\n        return float(lib.TCOD_random_get_double(self.random_c, low, high))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random number using Gaussian distribution.", "response": "def guass(self, mu: float, sigma: float) -> float:\n        \"\"\"Return a random number using Gaussian distribution.\n\n        Args:\n            mu (float): The median returned value.\n            sigma (float): The standard deviation.\n\n        Returns:\n            float: A random float.\n        \"\"\"\n        return float(\n            lib.TCOD_random_get_gaussian_double(self.random_c, mu, sigma)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inverse_guass(self, mu: float, sigma: float) -> float:\n        return float(\n            lib.TCOD_random_get_gaussian_double_inv(self.random_c, mu, sigma)\n        )", "response": "Return a random Gaussian number using the Box - Muller transform."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_point(self, *position):\n        #array = self._array\n        #for d, pos in enumerate(position):\n        #    array[d] = pos\n        #array = self._cFloatArray(*position)\n        array = _ffi.new(self._arrayType, position)\n        if self._useOctaves:\n            return (self._noiseFunc(self._noise, array, self._octaves) + 1) * 0.5\n        return (self._noiseFunc(self._noise, array) + 1) * 0.5", "response": "Return the noise value at a specific position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the visible area of a field - of - view computation.", "response": "def compute_fov(\n    transparency: np.array,\n    x: int,\n    y: int,\n    radius: int = 0,\n    light_walls: bool = True,\n    algorithm: int = tcod.constants.FOV_RESTRICTIVE,\n) -> np.array:\n    \"\"\"Return the visible area of a field-of-view computation.\n\n    `transparency` is a 2 dimensional array where all non-zero values are\n    considered transparent.  The returned array will match the shape of this\n    array.\n\n    `x` and `y` are the 1st and 2nd coordinates of the origin point.  Areas\n    are visible when they can be seen from this point-of-view.\n\n    `radius` is the maximum view distance from `x`/`y`.  If this is zero then\n    the maximum distance is used.\n\n    If `light_walls` is True then visible obstacles will be returned, otherwise\n    only transparent areas will be.\n\n    `algorithm` is the field-of-view algorithm to run.  The default value is\n    `tcod.FOV_RESTRICTIVE`.\n    The options are:\n\n    * `tcod.FOV_BASIC`:\n      Simple ray-cast implementation.\n    * `tcod.FOV_DIAMOND`\n    * `tcod.FOV_SHADOW`:\n      Recursive shadow caster.\n    * `tcod.FOV_PERMISSIVE(n)`:\n      `n` starts at 0 (most restrictive) and goes up to 8 (most permissive.)\n    * `tcod.FOV_RESTRICTIVE`\n\n    .. versionadded:: 9.3\n\n    Example::\n\n        >>> explored = np.zeros((3, 5), dtype=bool, order=\"F\")\n        >>> transparency = np.ones((3, 5), dtype=bool, order=\"F\")\n        >>> transparency[:2, 2] = False\n        >>> transparency  # Transparent area.\n        array([[ True,  True, False,  True,  True],\n               [ True,  True, False,  True,  True],\n               [ True,  True,  True,  True,  True]]...)\n        >>> visible = tcod.map.compute_fov(transparency, 0, 0)\n        >>> visible  # Visible area.\n        array([[ True,  True,  True, False, False],\n               [ True,  True,  True, False, False],\n               [ True,  True,  True,  True, False]]...)\n        >>> explored |= visible  # Keep track of an explored area.\n    \"\"\"\n    if len(transparency.shape) != 2:\n        raise TypeError(\n            \"transparency must be an array of 2 dimensions\"\n            \" (shape is %r)\" % transparency.shape\n        )\n    map_ = Map(transparency.shape[1], transparency.shape[0])\n    map_.transparent[...] = transparency\n    map_.compute_fov(x, y, radius, light_walls, algorithm)\n    return map_.fov"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a field - of - view on the current instance.", "response": "def compute_fov(\n        self,\n        x: int,\n        y: int,\n        radius: int = 0,\n        light_walls: bool = True,\n        algorithm: int = tcod.constants.FOV_RESTRICTIVE,\n    ) -> None:\n        \"\"\"Compute a field-of-view on the current instance.\n\n        Args:\n            x (int): Point of view, x-coordinate.\n            y (int): Point of view, y-coordinate.\n            radius (int): Maximum view distance from the point of view.\n\n                A value of `0` will give an infinite distance.\n            light_walls (bool): Light up walls, or only the floor.\n            algorithm (int): Defaults to tcod.FOV_RESTRICTIVE\n\n        If you already have transparency in a NumPy array then you could use\n        :any:`tcod.map_compute_fov` instead.\n        \"\"\"\n        lib.TCOD_map_compute_fov(\n            self.map_c, x, y, radius, light_walls, algorithm\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_point(\n        self, x: float = 0, y: float = 0, z: float = 0, w: float = 0\n    ) -> float:\n        \"\"\"Return the noise value at the (x, y, z, w) point.\n\n        Args:\n            x (float): The position on the 1st axis.\n            y (float): The position on the 2nd axis.\n            z (float): The position on the 3rd axis.\n            w (float): The position on the 4th axis.\n        \"\"\"\n        return float(lib.NoiseGetSample(self._tdl_noise_c, (x, y, z, w)))", "response": "Return the noise value at the given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample_mgrid(self, mgrid: np.array) -> np.array:\n        mgrid = np.ascontiguousarray(mgrid, np.float32)\n        if mgrid.shape[0] != self.dimensions:\n            raise ValueError(\n                \"mgrid.shape[0] must equal self.dimensions, \"\n                \"%r[0] != %r\" % (mgrid.shape, self.dimensions)\n            )\n        out = np.ndarray(mgrid.shape[1:], np.float32)\n        if mgrid.shape[1:] != out.shape:\n            raise ValueError(\n                \"mgrid.shape[1:] must equal out.shape, \"\n                \"%r[1:] != %r\" % (mgrid.shape, out.shape)\n            )\n        lib.NoiseSampleMeshGrid(\n            self._tdl_noise_c,\n            out.size,\n            ffi.cast(\"float*\", mgrid.ctypes.data),\n            ffi.cast(\"float*\", out.ctypes.data),\n        )\n        return out", "response": "Sample a mesh - grid array and return the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsample an open mesh - grid array and return the result.", "response": "def sample_ogrid(self, ogrid: np.array) -> np.array:\n        \"\"\"Sample an open mesh-grid array and return the result.\n\n        Args\n            ogrid (Sequence[Sequence[float]]): An open mesh-grid.\n\n        Returns:\n            numpy.ndarray: An array of sampled points.\n\n                The ``shape`` is based on the lengths of the open mesh-grid\n                arrays.\n                The ``dtype`` is `numpy.float32`.\n        \"\"\"\n        if len(ogrid) != self.dimensions:\n            raise ValueError(\n                \"len(ogrid) must equal self.dimensions, \"\n                \"%r != %r\" % (len(ogrid), self.dimensions)\n            )\n        ogrids = [np.ascontiguousarray(array, np.float32) for array in ogrid]\n        out = np.ndarray([array.size for array in ogrids], np.float32)\n        lib.NoiseSampleOpenMeshGrid(\n            self._tdl_noise_c,\n            len(ogrids),\n            out.shape,\n            [ffi.cast(\"float*\", array.ctypes.data) for array in ogrids],\n            ffi.cast(\"float*\", out.ctypes.data),\n        )\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the key names of the TCODK_ and returns a dictionary mapping human readable key names to their keycodes", "response": "def _parseKeyNames(lib):\n    \"\"\"\n    returns a dictionary mapping of human readable key names to their keycodes\n    this parses constants with the names of K_* and makes code=name pairs\n    this is for KeyEvent.key variable and that enables things like:\n    if (event.key == 'PAGEUP'):\n    \"\"\"\n    _keyNames = {}\n    for attr in dir(lib): # from the modules variables\n        if attr[:6] == 'TCODK_': # get the K_* constants\n            _keyNames[getattr(lib, attr)] = attr[6:] # and make CODE=NAME pairs\n    return _keyNames"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess the events from libtcod into the global list _eventQueue.", "response": "def _processEvents():\n    \"\"\"Flushes the event queue from libtcod into the global list _eventQueue\"\"\"\n    global _mousel, _mousem, _mouser, _eventsflushed, _pushedEvents\n    _eventsflushed = True\n    events = _pushedEvents # get events from event.push\n    _pushedEvents = [] # then clear the pushed events queue\n\n    mouse = _ffi.new('TCOD_mouse_t *')\n    libkey = _ffi.new('TCOD_key_t *')\n    while 1:\n        libevent = _lib.TCOD_sys_check_for_event(_lib.TCOD_EVENT_ANY, libkey, mouse)\n        if not libevent: # no more events from libtcod\n            break\n\n        #if mouse.dx or mouse.dy:\n        if libevent & _lib.TCOD_EVENT_MOUSE_MOVE:\n            events.append(MouseMotion((mouse.x, mouse.y),\n                                      (mouse.cx, mouse.cy),\n                                      (mouse.dx, mouse.dy),\n                                      (mouse.dcx, mouse.dcy)))\n\n        mousepos = ((mouse.x, mouse.y), (mouse.cx, mouse.cy))\n\n        for oldstate, newstate, released, button in \\\n            zip((_mousel, _mousem, _mouser),\n                (mouse.lbutton, mouse.mbutton, mouse.rbutton),\n                (mouse.lbutton_pressed, mouse.mbutton_pressed,\n                 mouse.rbutton_pressed),\n                (1, 2, 3)):\n            if released:\n                if not oldstate:\n                    events.append(MouseDown(button, *mousepos))\n                events.append(MouseUp(button, *mousepos))\n                if newstate:\n                    events.append(MouseDown(button, *mousepos))\n            elif newstate and not oldstate:\n                events.append(MouseDown(button, *mousepos))\n\n        if mouse.wheel_up:\n            events.append(MouseDown(4, *mousepos))\n        if mouse.wheel_down:\n            events.append(MouseDown(5, *mousepos))\n\n        _mousel = mouse.lbutton\n        _mousem = mouse.mbutton\n        _mouser = mouse.rbutton\n\n        if libkey.vk == _lib.TCODK_NONE:\n            break\n        if libkey.pressed:\n            keyevent = KeyDown\n        else:\n            keyevent = KeyUp\n\n        events.append(\n            keyevent(\n                libkey.vk,\n                libkey.c.decode('ascii', errors='ignore'),\n                _ffi.string(libkey.text).decode('utf-8'),\n                libkey.shift,\n                libkey.lalt,\n                libkey.ralt,\n                libkey.lctrl,\n                libkey.rctrl,\n                libkey.lmeta,\n                libkey.rmeta,\n                )\n            )\n\n    if _lib.TCOD_console_is_window_closed():\n        events.append(Quit())\n\n    _eventQueue.extend(events)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait(timeout=None, flush=True):\n    if timeout is not None:\n        timeout = timeout + _time.clock() # timeout at this time\n    while True:\n        if _eventQueue:\n            return _eventQueue.pop(0)\n        if flush:\n            # a full 'round' of events need to be processed before flushing\n            _tdl.flush()\n        if timeout and _time.clock() >= timeout:\n            return None # return None on timeout\n        _time.sleep(0.001) # sleep 1ms\n        _processEvents()", "response": "Wait for an event."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key_wait():\n    while 1:\n        for event in get():\n            if event.type == 'KEYDOWN':\n                return event\n            if event.type == 'QUIT':\n                # convert QUIT into alt+F4\n                return KeyDown('F4', '', True, False, True, False, False)\n        _time.sleep(.001)", "response": "Waits until the user presses a key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        if getattr(self, '_App__running', False):\n            raise _tdl.TDLError('An App can not be run multiple times simultaneously')\n        self.__running = True\n        while self.__running:\n            self.runOnce()", "response": "Delegate control over to this App instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npump events to this App instance and then return.", "response": "def run_once(self):\n        \"\"\"Pump events to this App instance and then return.\n\n        This works in the way described in :any:`App.run` except it immediately\n        returns after the first :any:`update` call.\n\n        Having multiple :any:`App` instances and selectively calling runOnce on\n        them is a decent way to create a state machine.\n        \"\"\"\n        if not hasattr(self, '_App__prevTime'):\n            self.__prevTime = _time.clock() # initiate __prevTime\n        for event in get():\n            if event.type: # exclude custom events with a blank type variable\n                # call the ev_* methods\n                method = 'ev_%s' % event.type # ev_TYPE\n                getattr(self, method)(event)\n            if event.type == 'KEYDOWN':\n                # call the key_* methods\n                method = 'key_%s' % event.key # key_KEYNAME\n                if hasattr(self, method): # silently exclude undefined methods\n                    getattr(self, method)(event)\n        newTime = _time.clock()\n        self.update(newTime - self.__prevTime)\n        self.__prevTime = newTime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_truetype_font(\n    path: str, tile_width: int, tile_height: int\n) -> Tileset:\n    \"\"\"Return a new Tileset from a `.ttf` or `.otf` file.\n\n    Same as :any:`set_truetype_font`, but returns a :any:`Tileset` instead.\n    You can send this Tileset to :any:`set_default`.\n\n    This function is provisional.  The API may change.\n    \"\"\"\n    if not os.path.exists(path):\n        raise RuntimeError(\"File not found:\\n\\t%s\" % (os.path.realpath(path),))\n    return Tileset._claim(\n        lib.TCOD_load_truetype_font_(path.encode(), tile_width, tile_height)\n    )", "response": "Load a Tileset from a. ttf or. otf file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a default tileset from a. ttf or. otf file.", "response": "def set_truetype_font(path: str, tile_width: int, tile_height: int) -> None:\n    \"\"\"Set the default tileset from a `.ttf` or `.otf` file.\n\n    `path` is the file path for the font file.\n\n    `tile_width` and `tile_height` are the desired size of the tiles in the new\n    tileset.  The font will be scaled to fit the given `tile_height` and\n    `tile_width`.\n\n    This function will only affect the `SDL2` and `OPENGL2` renderers.\n\n    This function must be called before :any:`tcod.console_init_root`.  Once\n    the root console is setup you may call this funtion again to change the\n    font.  The tileset can be changed but the window will not be resized\n    automatically.\n\n    .. versionadded:: 9.2\n    \"\"\"\n    if not os.path.exists(path):\n        raise RuntimeError(\"File not found:\\n\\t%s\" % (os.path.realpath(path),))\n    lib.TCOD_tileset_load_truetype_(path.encode(), tile_width, tile_height)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _claim(cls, cdata: Any) -> \"Tileset\":\n        self = object.__new__(cls)  # type: Tileset\n        if cdata == ffi.NULL:\n            raise RuntimeError(\"Tileset initialized with nullptr.\")\n        self._tileset_p = ffi.gc(cdata, lib.TCOD_tileset_delete)\n        return self", "response": "Return a new Tileset that owns the provided TCOD_Tileset * object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a copy of a tile for the given codepoint.", "response": "def get_tile(self, codepoint: int) -> np.array:\n        \"\"\"Return a copy of a tile for the given codepoint.\n\n        If the tile does not exist yet then a blank array will be returned.\n\n        The tile will have a shape of (height, width, rgba) and a dtype of\n        uint8.  Note that most grey-scale tiles will only use the alpha\n        channel and will usually have a solid white color channel.\n        \"\"\"\n        tile = np.zeros(self.tile_shape + (4,), dtype=np.uint8)\n        lib.TCOD_tileset_get_tile_(\n            self._tileset_p,\n            codepoint,\n            ffi.cast(\"struct TCOD_ColorRGBA*\", tile.ctypes.data),\n        )\n        return tile"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading a tile into this array.", "response": "def set_tile(self, codepoint: int, tile: np.array) -> None:\n        \"\"\"Upload a tile into this array.\n\n        The tile can be in 32-bit color (height, width, rgba), or grey-scale\n        (height, width).  The tile should have a dtype of ``np.uint8``.\n\n        This data may need to be sent to graphics card memory, this is a slow\n        operation.\n        \"\"\"\n        tile = np.ascontiguousarray(tile, dtype=np.uint8)\n        if tile.shape == self.tile_shape:\n            full_tile = np.empty(self.tile_shape + (4,), dtype=np.uint8)\n            full_tile[:, :, :3] = 255\n            full_tile[:, :, 3] = tile\n            return self.set_tile(codepoint, full_tile)\n        required = self.tile_shape + (4,)\n        if tile.shape != required:\n            raise ValueError(\n                \"Tile shape must be %r or %r, got %r.\"\n                % (required, self.tile_shape, tile.shape)\n            )\n        lib.TCOD_tileset_set_tile_(\n            self._tileset_p,\n            codepoint,\n            ffi.cast(\"struct TCOD_ColorRGBA*\", tile.ctypes.data),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fix_header(filepath):\n    with open(filepath, \"r+\") as f:\n        current = f.read()\n        fixed = \"\\n\".join(line.strip() for line in current.split(\"\\n\"))\n        if current == fixed:\n            return\n        f.seek(0)\n        f.truncate()\n        f.write(fixed)", "response": "Removes leading whitespace from a MacOS header file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_sdl_attrs(prefix: str) -> Iterator[Tuple[str, Any]]:\n    from tcod._libtcod import lib\n\n    if prefix.startswith(\"SDL_\"):\n        name_starts_at = 4\n    elif prefix.startswith(\"SDL\"):\n        name_starts_at = 3\n    else:\n        name_starts_at = 0\n    for attr in dir(lib):\n        if attr.startswith(prefix):\n            yield attr[name_starts_at:], getattr(lib, attr)", "response": "Return names and values from tcod. lib."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name value pairs and the final dictionary string for the library attributes with prefix.", "response": "def parse_sdl_attrs(prefix: str, all_names: List[str]) -> Tuple[str, str]:\n    \"\"\"Return the name/value pairs, and the final dictionary string for the\n    library attributes with `prefix`.\n\n    Append matching names to the `all_names` list.\n    \"\"\"\n    names = []\n    lookup = []\n    for name, value in sorted(\n        find_sdl_attrs(prefix), key=lambda item: item[1]\n    ):\n        all_names.append(name)\n        names.append(\"%s = %s\" % (name, value))\n        lookup.append('%s: \"tcod.event.%s\"' % (value, name))\n    names = \"\\n\".join(names)\n    lookup = \"{\\n    %s,\\n}\" % (\",\\n    \".join(lookup),)\n    return names, lookup"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_library_constants():\n    from tcod._libtcod import lib, ffi\n    import tcod.color\n\n    with open(\"tcod/constants.py\", \"w\") as f:\n        all_names = []\n        f.write(CONSTANT_MODULE_HEADER)\n        for name in dir(lib):\n            value = getattr(lib, name)\n            if name[:5] == \"TCOD_\":\n                if name.isupper():  # const names\n                    f.write(\"%s = %r\\n\" % (name[5:], value))\n                    all_names.append(name[5:])\n            elif name.startswith(\"FOV\"):  # fov const names\n                f.write(\"%s = %r\\n\" % (name, value))\n                all_names.append(name)\n            elif name[:6] == \"TCODK_\":  # key name\n                f.write(\"KEY_%s = %r\\n\" % (name[6:], value))\n                all_names.append(\"KEY_%s\" % name[6:])\n\n        f.write(\"\\n# --- colors ---\\n\")\n        for name in dir(lib):\n            if name[:5] != \"TCOD_\":\n                continue\n            value = getattr(lib, name)\n            if not isinstance(value, ffi.CData):\n                continue\n            if ffi.typeof(value) != ffi.typeof(\"TCOD_color_t\"):\n                continue\n            color = tcod.color.Color._new_from_cdata(value)\n            f.write(\"%s = %r\\n\" % (name[5:], color))\n            all_names.append(name[5:])\n\n        all_names = \",\\n    \".join('\"%s\"' % name for name in all_names)\n        f.write(\"\\n__all__ = [\\n    %s,\\n]\\n\" % (all_names,))\n\n    with open(\"tcod/event_constants.py\", \"w\") as f:\n        all_names = []\n        f.write(EVENT_CONSTANT_MODULE_HEADER)\n        f.write(\"# --- SDL scancodes ---\\n\")\n        f.write(\n            \"%s\\n_REVERSE_SCANCODE_TABLE = %s\\n\"\n            % parse_sdl_attrs(\"SDL_SCANCODE\", all_names)\n        )\n\n        f.write(\"\\n# --- SDL keyboard symbols ---\\n\")\n        f.write(\n            \"%s\\n_REVERSE_SYM_TABLE = %s\\n\"\n            % parse_sdl_attrs(\"SDLK\", all_names)\n        )\n\n        f.write(\"\\n# --- SDL keyboard modifiers ---\\n\")\n        f.write(\n            \"%s\\n_REVERSE_MOD_TABLE = %s\\n\"\n            % parse_sdl_attrs(\"KMOD\", all_names)\n        )\n\n        f.write(\"\\n# --- SDL wheel ---\\n\")\n        f.write(\n            \"%s\\n_REVERSE_WHEEL_TABLE = %s\\n\"\n            % parse_sdl_attrs(\"SDL_MOUSEWHEEL\", all_names)\n        )\n        all_names = \",\\n    \".join('\"%s\"' % name for name in all_names)\n        f.write(\"\\n__all__ = [\\n    %s,\\n]\\n\" % (all_names,))", "response": "Write libtcod constants into the tcod. constants module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace enumerator expressions with '...' stubs.", "response": "def visit_EnumeratorList(self, node):\n        \"\"\"Replace enumerator expressions with '...' stubs.\"\"\"\n        for type, enum in node.children():\n            if enum.value is None:\n                pass\n            elif isinstance(enum.value, (c_ast.BinaryOp, c_ast.UnaryOp)):\n                enum.value = c_ast.Constant(\"int\", \"...\")\n            elif hasattr(enum.value, \"type\"):\n                enum.value = c_ast.Constant(enum.value.type, \"...\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bsp_new_with_size(x: int, y: int, w: int, h: int) -> tcod.bsp.BSP:\n    return Bsp(x, y, w, h)", "response": "Create a new BSP instance with the given rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bsp_split_once(\n    node: tcod.bsp.BSP, horizontal: bool, position: int\n) -> None:\n    \"\"\"\n    .. deprecated:: 2.0\n       Use :any:`BSP.split_once` instead.\n    \"\"\"\n    node.split_once(horizontal, position)", "response": "Split the BSP node at the given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit the node recursively.", "response": "def bsp_split_recursive(\n    node: tcod.bsp.BSP,\n    randomizer: Optional[tcod.random.Random],\n    nb: int,\n    minHSize: int,\n    minVSize: int,\n    maxHRatio: int,\n    maxVRatio: int,\n) -> None:\n    \"\"\"\n    .. deprecated:: 2.0\n       Use :any:`BSP.split_recursive` instead.\n    \"\"\"\n    node.split_recursive(\n        nb, minHSize, minVSize, maxHRatio, maxVRatio, randomizer\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bsp_resize(node: tcod.bsp.BSP, x: int, y: int, w: int, h: int) -> None:\n    node.x = x\n    node.y = y\n    node.width = w\n    node.height = h", "response": "Change the dimensions of a BSP node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first BSP in the tree.", "response": "def bsp_left(node: tcod.bsp.BSP) -> Optional[tcod.bsp.BSP]:\n    \"\"\"\n    .. deprecated:: 2.0\n       Use :any:`BSP.children` instead.\n    \"\"\"\n    return None if not node.children else node.children[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bsp_right(node: tcod.bsp.BSP) -> Optional[tcod.bsp.BSP]:\n    return None if not node.children else node.children[1]", "response": "Return the BSP node on the right side of the BSP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bsp_father(node: tcod.bsp.BSP) -> Optional[tcod.bsp.BSP]:\n    return node.parent", "response": "Return the first BSP that is father of the given node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bsp_contains(node: tcod.bsp.BSP, cx: int, cy: int) -> bool:\n    return node.contains(cx, cy)", "response": "Return true if the BSP contains the given cx and cy coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bsp_find_node(\n    node: tcod.bsp.BSP, cx: int, cy: int\n) -> Optional[tcod.bsp.BSP]:\n    \"\"\"\n    .. deprecated:: 2.0\n       Use :any:`BSP.find_node` instead.\n    \"\"\"\n    return node.find_node(cx, cy)", "response": "Return the BSP with the given cx and cy coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntraversing the BSP tree.", "response": "def _bsp_traverse(\n    node_iter: Iterable[tcod.bsp.BSP],\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any,\n) -> None:\n    \"\"\"pack callback into a handle for use with the callback\n    _pycall_bsp_callback\n    \"\"\"\n    for node in node_iter:\n        callback(node, userData)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bsp_traverse_pre_order(\n    node: tcod.bsp.BSP,\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any = 0,\n) -> None:\n    \"\"\"Traverse this nodes hierarchy with a callback.\n\n    .. deprecated:: 2.0\n       Use :any:`BSP.pre_order` instead.\n    \"\"\"\n    _bsp_traverse(node.pre_order(), callback, userData)", "response": "Traverse this node s pre - order with a callback."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntraverse this node s BSP hierarchy with a callback.", "response": "def bsp_traverse_in_order(\n    node: tcod.bsp.BSP,\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any = 0,\n) -> None:\n    \"\"\"Traverse this nodes hierarchy with a callback.\n\n    .. deprecated:: 2.0\n       Use :any:`BSP.in_order` instead.\n    \"\"\"\n    _bsp_traverse(node.in_order(), callback, userData)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bsp_traverse_post_order(\n    node: tcod.bsp.BSP,\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any = 0,\n) -> None:\n    \"\"\"Traverse this nodes hierarchy with a callback.\n\n    .. deprecated:: 2.0\n       Use :any:`BSP.post_order` instead.\n    \"\"\"\n    _bsp_traverse(node.post_order(), callback, userData)", "response": "Traverse this node s nodes hierarchy with a callback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraversing this node s hierarchy with a callback.", "response": "def bsp_traverse_level_order(\n    node: tcod.bsp.BSP,\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any = 0,\n) -> None:\n    \"\"\"Traverse this nodes hierarchy with a callback.\n\n    .. deprecated:: 2.0\n       Use :any:`BSP.level_order` instead.\n    \"\"\"\n    _bsp_traverse(node.level_order(), callback, userData)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntraverse this node s hierarchy with a callback.", "response": "def bsp_traverse_inverted_level_order(\n    node: tcod.bsp.BSP,\n    callback: Callable[[tcod.bsp.BSP, Any], None],\n    userData: Any = 0,\n) -> None:\n    \"\"\"Traverse this nodes hierarchy with a callback.\n\n    .. deprecated:: 2.0\n       Use :any:`BSP.inverted_level_order` instead.\n    \"\"\"\n    _bsp_traverse(node.inverted_level_order(), callback, userData)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef color_lerp(\n    c1: Tuple[int, int, int], c2: Tuple[int, int, int], a: float\n) -> Color:\n    \"\"\"Return the linear interpolation between two colors.\n\n    ``a`` is the interpolation value, with 0 returing ``c1``,\n    1 returning ``c2``, and 0.5 returing a color halfway between both.\n\n    Args:\n        c1 (Union[Tuple[int, int, int], Sequence[int]]):\n            The first color.  At a=0.\n        c2 (Union[Tuple[int, int, int], Sequence[int]]):\n            The second color.  At a=1.\n        a (float): The interpolation value,\n\n    Returns:\n        Color: The interpolated Color.\n    \"\"\"\n    return Color._new_from_cdata(lib.TCOD_color_lerp(c1, c2, a))", "response": "Return the linear interpolation between two colors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a color using hue saturation and value parameters.", "response": "def color_set_hsv(c: Color, h: float, s: float, v: float) -> None:\n    \"\"\"Set a color using: hue, saturation, and value parameters.\n\n    Does not return a new Color.  ``c`` is modified inplace.\n\n    Args:\n        c (Union[Color, List[Any]]): A Color instance, or a list of any kind.\n        h (float): Hue, from 0 to 360.\n        s (float): Saturation, from 0 to 1.\n        v (float): Value, from 0 to 1.\n    \"\"\"\n    new_color = ffi.new(\"TCOD_color_t*\")\n    lib.TCOD_color_set_HSV(new_color, h, s, v)\n    c[:] = new_color.r, new_color.g, new_color.b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef color_get_hsv(c: Tuple[int, int, int]) -> Tuple[float, float, float]:\n    hsv = ffi.new(\"float [3]\")\n    lib.TCOD_color_get_HSV(c, hsv, hsv + 1, hsv + 2)\n    return hsv[0], hsv[1], hsv[2]", "response": "Return the hue saturation and value of a color."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef color_scale_HSV(c: Color, scoef: float, vcoef: float) -> None:\n    color_p = ffi.new(\"TCOD_color_t*\")\n    color_p.r, color_p.g, color_p.b = c.r, c.g, c.b\n    lib.TCOD_color_scale_HSV(color_p, scoef, vcoef)\n    c[:] = color_p.r, color_p.g, color_p.b", "response": "Scale a color s saturation and value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef color_gen_map(\n    colors: Iterable[Tuple[int, int, int]], indexes: Iterable[int]\n) -> List[Color]:\n    \"\"\"Return a smoothly defined scale of colors.\n\n    If ``indexes`` is [0, 3, 9] for example, the first color from ``colors``\n    will be returned at 0, the 2nd will be at 3, and the 3rd will be at 9.\n    All in-betweens will be filled with a gradient.\n\n    Args:\n        colors (Iterable[Union[Tuple[int, int, int], Sequence[int]]]):\n            Array of colors to be sampled.\n        indexes (Iterable[int]): A list of indexes.\n\n    Returns:\n        List[Color]: A list of Color instances.\n\n    Example:\n        >>> tcod.color_gen_map([(0, 0, 0), (255, 128, 0)], [0, 5])\n        [Color(0, 0, 0), Color(51, 25, 0), Color(102, 51, 0), \\\nColor(153, 76, 0), Color(204, 102, 0), Color(255, 128, 0)]\n    \"\"\"\n    ccolors = ffi.new(\"TCOD_color_t[]\", colors)\n    cindexes = ffi.new(\"int[]\", indexes)\n    cres = ffi.new(\"TCOD_color_t[]\", max(indexes) + 1)\n    lib.TCOD_color_gen_map(cres, len(ccolors), ccolors, cindexes)\n    return [Color._new_from_cdata(cdata) for cdata in cres]", "response": "Return a smoothly defined scale of colors."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the root console.", "response": "def console_init_root(\n    w: int,\n    h: int,\n    title: Optional[str] = None,\n    fullscreen: bool = False,\n    renderer: Optional[int] = None,\n    order: str = \"C\",\n) -> tcod.console.Console:\n    \"\"\"Set up the primary display and return the root console.\n\n    `w` and `h` are the columns and rows of the new window (in tiles.)\n\n    `title` is an optional string to display on the windows title bar.\n\n    `fullscreen` determines if the window will start in fullscreen.  Fullscreen\n    mode is unreliable unless the renderer is set to `tcod.RENDERER_SDL2` or\n    `tcod.RENDERER_OPENGL2`.\n\n    `renderer` is the rendering back-end that libtcod will use.\n    If you don't know which to pick, then use `tcod.RENDERER_SDL2`.\n    Options are:\n\n    * `tcod.RENDERER_SDL`:\n      A deprecated software/SDL2 renderer.\n    * `tcod.RENDERER_OPENGL`:\n      A deprecated SDL2/OpenGL1 renderer.\n    * `tcod.RENDERER_GLSL`:\n      A deprecated SDL2/OpenGL2 renderer.\n    * `tcod.RENDERER_SDL2`:\n      The recommended SDL2 renderer.  Rendering is decided by SDL2 and can be\n      changed by using an SDL2 hint.\n    * `tcod.RENDERER_OPENGL2`:\n      An SDL2/OPENGL2 renderer.  Usually faster than regular SDL2.\n      Requires OpenGL 2.0 Core.\n\n    `order` will affect how the array attributes of the returned root console\n    are indexed.  `order='C'` is the default, but `order='F'` is recommended.\n\n    .. versionchanged:: 4.3\n        Added `order` parameter.\n        `title` parameter is now optional.\n\n    .. versionchanged:: 8.0\n        The default `renderer` is now automatic instead of always being\n        `RENDERER_SDL`.\n    \"\"\"\n    if title is None:\n        # Use the scripts filename as the title.\n        title = os.path.basename(sys.argv[0])\n    if renderer is None:\n        warnings.warn(\n            \"A renderer should be given, see the online documentation.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        renderer = tcod.constants.RENDERER_SDL\n    elif renderer in (\n        tcod.constants.RENDERER_SDL,\n        tcod.constants.RENDERER_OPENGL,\n        tcod.constants.RENDERER_GLSL,\n    ):\n        warnings.warn(\n            \"The SDL, OPENGL, and GLSL renderers are deprecated.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n    lib.TCOD_console_init_root(w, h, _bytes(title), fullscreen, renderer)\n    console = tcod.console.Console._get_root(order)\n    console.clear()\n    return console"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_set_custom_font(\n    fontFile: AnyStr,\n    flags: int = FONT_LAYOUT_ASCII_INCOL,\n    nb_char_horiz: int = 0,\n    nb_char_vertic: int = 0,\n) -> None:\n    \"\"\"Load the custom font file at `fontFile`.\n\n    Call this before function before calling :any:`tcod.console_init_root`.\n\n    Flags can be a mix of the following:\n\n    * tcod.FONT_LAYOUT_ASCII_INCOL:\n      Decode tileset raw in column-major order.\n    * tcod.FONT_LAYOUT_ASCII_INROW:\n      Decode tileset raw in row-major order.\n    * tcod.FONT_TYPE_GREYSCALE:\n      Force tileset to be read as greyscale.\n    * tcod.FONT_TYPE_GRAYSCALE\n    * tcod.FONT_LAYOUT_TCOD:\n      Unique layout used by libtcod.\n    * tcod.FONT_LAYOUT_CP437:\n      Decode a row-major Code Page 437 tileset into Unicode.\n\n    `nb_char_horiz` and `nb_char_vertic` are the columns and rows of the font\n    file respectfully.\n    \"\"\"\n    if not os.path.exists(fontFile):\n        raise RuntimeError(\n            \"File not found:\\n\\t%s\" % (os.path.realpath(fontFile),)\n        )\n    lib.TCOD_console_set_custom_font(\n        _bytes(fontFile), flags, nb_char_horiz, nb_char_vertic\n    )", "response": "Load the custom font at fontFile and set the layout used by libtcod."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the width of a console.", "response": "def console_get_width(con: tcod.console.Console) -> int:\n    \"\"\"Return the width of a console.\n\n    Args:\n        con (Console): Any Console instance.\n\n    Returns:\n        int: The width of a Console.\n\n    .. deprecated:: 2.0\n        Use `Console.width` instead.\n    \"\"\"\n    return int(lib.TCOD_console_get_width(_console(con)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_get_height(con: tcod.console.Console) -> int:\n    return int(lib.TCOD_console_get_height(_console(con)))", "response": "Return the height of a console."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps an ASCII character code to a new coordinates on the tile - set.", "response": "def console_map_ascii_code_to_font(\n    asciiCode: int, fontCharX: int, fontCharY: int\n) -> None:\n    \"\"\"Set a character code to new coordinates on the tile-set.\n\n    `asciiCode` must be within the bounds created during the initialization of\n    the loaded tile-set.  For example, you can't use 255 here unless you have a\n    256 tile tile-set loaded.  This applies to all functions in this group.\n\n    Args:\n        asciiCode (int): The character code to change.\n        fontCharX (int): The X tile coordinate on the loaded tileset.\n                         0 is the leftmost tile.\n        fontCharY (int): The Y tile coordinate on the loaded tileset.\n                         0 is the topmost tile.\n    \"\"\"\n    lib.TCOD_console_map_ascii_code_to_font(\n        _int(asciiCode), fontCharX, fontCharY\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef console_map_ascii_codes_to_font(\n    firstAsciiCode: int, nbCodes: int, fontCharX: int, fontCharY: int\n) -> None:\n    \"\"\"Remap a contiguous set of codes to a contiguous set of tiles.\n\n    Both the tile-set and character codes must be contiguous to use this\n    function.  If this is not the case you may want to use\n    :any:`console_map_ascii_code_to_font`.\n\n    Args:\n        firstAsciiCode (int): The starting character code.\n        nbCodes (int): The length of the contiguous set.\n        fontCharX (int): The starting X tile coordinate on the loaded tileset.\n                         0 is the leftmost tile.\n        fontCharY (int): The starting Y tile coordinate on the loaded tileset.\n                         0 is the topmost tile.\n\n    \"\"\"\n    lib.TCOD_console_map_ascii_codes_to_font(\n        _int(firstAsciiCode), nbCodes, fontCharX, fontCharY\n    )", "response": "Remap a contiguous set of characters to a contiguous set of tiles."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef console_set_default_background(\n    con: tcod.console.Console, col: Tuple[int, int, int]\n) -> None:\n    \"\"\"Change the default background color for a console.\n\n    Args:\n        con (Console): Any Console instance.\n        col (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.default_bg` instead.\n    \"\"\"\n    lib.TCOD_console_set_default_background(_console(con), col)", "response": "Change the default background color for a console."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_set_default_foreground(\n    con: tcod.console.Console, col: Tuple[int, int, int]\n) -> None:\n    \"\"\"Change the default foreground color for a console.\n\n    Args:\n        con (Console): Any Console instance.\n        col (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.default_fg` instead.\n    \"\"\"\n    lib.TCOD_console_set_default_foreground(_console(con), col)", "response": "Change the default foreground color for a console."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_put_char(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    c: Union[int, str],\n    flag: int = BKGND_DEFAULT,\n) -> None:\n    \"\"\"Draw the character c at x,y using the default colors and a blend mode.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        c (Union[int, AnyStr]): Character to draw, can be an integer or string.\n        flag (int): Blending mode to use, defaults to BKGND_DEFAULT.\n    \"\"\"\n    lib.TCOD_console_put_char(_console(con), x, y, _int(c), flag)", "response": "Draw the character c at x y using the default colors and a blend mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef console_put_char_ex(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    c: Union[int, str],\n    fore: Tuple[int, int, int],\n    back: Tuple[int, int, int],\n) -> None:\n    \"\"\"Draw the character c at x,y using the colors fore and back.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        c (Union[int, AnyStr]): Character to draw, can be an integer or string.\n        fore (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n        back (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n    \"\"\"\n    lib.TCOD_console_put_char_ex(_console(con), x, y, _int(c), fore, back)", "response": "Draw the character c at x y using the colors fore and back."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_set_char_background(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    col: Tuple[int, int, int],\n    flag: int = BKGND_SET,\n) -> None:\n    \"\"\"Change the background color of x,y to col using a blend mode.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        col (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n        flag (int): Blending mode to use, defaults to BKGND_SET.\n    \"\"\"\n    lib.TCOD_console_set_char_background(_console(con), x, y, col, flag)", "response": "Change the background color of x y to col using a blend mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchange the foreground color of x y to col.", "response": "def console_set_char_foreground(\n    con: tcod.console.Console, x: int, y: int, col: Tuple[int, int, int]\n) -> None:\n    \"\"\"Change the foreground color of x,y to col.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        col (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n\n    .. deprecated:: 8.4\n        Array access performs significantly faster than using this function.\n        See :any:`Console.fg`.\n    \"\"\"\n    lib.TCOD_console_set_char_foreground(_console(con), x, y, col)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_set_char(\n    con: tcod.console.Console, x: int, y: int, c: Union[int, str]\n) -> None:\n    \"\"\"Change the character at x,y to c, keeping the current colors.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        c (Union[int, AnyStr]): Character to draw, can be an integer or string.\n\n    .. deprecated:: 8.4\n        Array access performs significantly faster than using this function.\n        See :any:`Console.ch`.\n    \"\"\"\n    lib.TCOD_console_set_char(_console(con), x, y, _int(c))", "response": "Change the character at x y to c keeping the current colors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the default blend mode for this console.", "response": "def console_set_background_flag(con: tcod.console.Console, flag: int) -> None:\n    \"\"\"Change the default blend mode for this console.\n\n    Args:\n        con (Console): Any Console instance.\n        flag (int): Blend mode to use by default.\n\n    .. deprecated:: 8.5\n        Set :any:`Console.default_bg_blend` instead.\n    \"\"\"\n    lib.TCOD_console_set_background_flag(_console(con), flag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns this consoles current blend mode.", "response": "def console_get_background_flag(con: tcod.console.Console) -> int:\n    \"\"\"Return this consoles current blend mode.\n\n    Args:\n        con (Console): Any Console instance.\n\n    .. deprecated:: 8.5\n        Check :any:`Console.default_bg_blend` instead.\n    \"\"\"\n    return int(lib.TCOD_console_get_background_flag(_console(con)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef console_set_alignment(con: tcod.console.Console, alignment: int) -> None:\n    lib.TCOD_console_set_alignment(_console(con), alignment)", "response": "Change this consoles current alignment mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_get_alignment(con: tcod.console.Console) -> int:\n    return int(lib.TCOD_console_get_alignment(_console(con)))", "response": "Return this consoles current alignment mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting a color formatted string on a console.", "response": "def console_print(con: tcod.console.Console, x: int, y: int, fmt: str) -> None:\n    \"\"\"Print a color formatted string on a console.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n        fmt (AnyStr): A unicode or bytes string optionaly using color codes.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.print_` instead.\n    \"\"\"\n    lib.TCOD_console_printf(_console(con), x, y, _fmt(fmt))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a string on a console using blend mode and alignment mode.", "response": "def console_print_ex(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    flag: int,\n    alignment: int,\n    fmt: str,\n) -> None:\n    \"\"\"Print a string on a console using a blend mode and alignment mode.\n\n    Args:\n        con (Console): Any Console instance.\n        x (int): Character x position from the left.\n        y (int): Character y position from the top.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.print_` instead.\n    \"\"\"\n    lib.TCOD_console_printf_ex(_console(con), x, y, flag, alignment, _fmt(fmt))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint a string constrained to a rectangle.", "response": "def console_print_rect(\n    con: tcod.console.Console, x: int, y: int, w: int, h: int, fmt: str\n) -> int:\n    \"\"\"Print a string constrained to a rectangle.\n\n    If h > 0 and the bottom of the rectangle is reached,\n    the string is truncated. If h = 0,\n    the string is only truncated if it reaches the bottom of the console.\n\n\n\n    Returns:\n        int: The number of lines of text once word-wrapped.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.print_rect` instead.\n    \"\"\"\n    return int(\n        lib.TCOD_console_printf_rect(_console(con), x, y, w, h, _fmt(fmt))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef console_print_rect_ex(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    w: int,\n    h: int,\n    flag: int,\n    alignment: int,\n    fmt: str,\n) -> int:\n    \"\"\"Print a string constrained to a rectangle with blend and alignment.\n\n    Returns:\n        int: The number of lines of text once word-wrapped.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.print_rect` instead.\n    \"\"\"\n    return int(\n        lib.TCOD_console_printf_rect_ex(\n            _console(con), x, y, w, h, flag, alignment, _fmt(fmt)\n        )\n    )", "response": "Print a string constrained to a rectangle with blend and alignment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the height of this text once word - wrapped into this rectangle.", "response": "def console_get_height_rect(\n    con: tcod.console.Console, x: int, y: int, w: int, h: int, fmt: str\n) -> int:\n    \"\"\"Return the height of this text once word-wrapped into this rectangle.\n\n    Returns:\n        int: The number of lines of text once word-wrapped.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.get_height_rect` instead.\n    \"\"\"\n    return int(\n        lib.TCOD_console_get_height_rect_fmt(\n            _console(con), x, y, w, h, _fmt(fmt)\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_rect(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    w: int,\n    h: int,\n    clr: bool,\n    flag: int = BKGND_DEFAULT,\n) -> None:\n    \"\"\"Draw a the background color on a rect optionally clearing the text.\n\n    If clr is True the affected tiles are changed to space character.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.rect` instead.\n    \"\"\"\n    lib.TCOD_console_rect(_console(con), x, y, w, h, clr, flag)", "response": "Draw a background color on a rect optionally clearing the text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_hline(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    l: int,\n    flag: int = BKGND_DEFAULT,\n) -> None:\n    \"\"\"Draw a horizontal line on the console.\n\n    This always uses the character 196, the horizontal line character.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.hline` instead.\n    \"\"\"\n    lib.TCOD_console_hline(_console(con), x, y, l, flag)", "response": "Draw a horizontal line on the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_vline(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    l: int,\n    flag: int = BKGND_DEFAULT,\n) -> None:\n    \"\"\"Draw a vertical line on the console.\n\n    This always uses the character 179, the vertical line character.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.vline` instead.\n    \"\"\"\n    lib.TCOD_console_vline(_console(con), x, y, l, flag)", "response": "Draw a vertical line on the console."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_print_frame(\n    con: tcod.console.Console,\n    x: int,\n    y: int,\n    w: int,\n    h: int,\n    clear: bool = True,\n    flag: int = BKGND_DEFAULT,\n    fmt: str = \"\",\n) -> None:\n    \"\"\"Draw a framed rectangle with optinal text.\n\n    This uses the default background color and blend mode to fill the\n    rectangle and the default foreground to draw the outline.\n\n    `fmt` will be printed on the inside of the rectangle, word-wrapped.\n    If `fmt` is empty then no title will be drawn.\n\n    .. versionchanged:: 8.2\n        Now supports Unicode strings.\n\n    .. deprecated:: 8.5\n        Use :any:`Console.print_frame` instead.\n    \"\"\"\n    fmt = _fmt(fmt) if fmt else ffi.NULL\n    lib.TCOD_console_printf_frame(_console(con), x, y, w, h, clear, flag, fmt)", "response": "Draw a framed rectangle with optinal text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring :any:`color controls`. Args: con (int): :any:`Color control` constant to modify. fore (Union[Tuple[int, int, int], Sequence[int]]): An (r, g, b) sequence or Color instance. back (Union[Tuple[int, int, int], Sequence[int]]): An (r, g, b) sequence or Color instance.", "response": "def console_set_color_control(\n    con: int, fore: Tuple[int, int, int], back: Tuple[int, int, int]\n) -> None:\n    \"\"\"Configure :any:`color controls`.\n\n    Args:\n        con (int): :any:`Color control` constant to modify.\n        fore (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n        back (Union[Tuple[int, int, int], Sequence[int]]):\n            An (r, g, b) sequence or Color instance.\n    \"\"\"\n    lib.TCOD_console_set_color_control(con, fore, back)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef console_get_default_background(con: tcod.console.Console) -> Color:\n    return Color._new_from_cdata(\n        lib.TCOD_console_get_default_background(_console(con))\n    )", "response": "Return this consoles default background color."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_get_default_foreground(con: tcod.console.Console) -> Color:\n    return Color._new_from_cdata(\n        lib.TCOD_console_get_default_foreground(_console(con))\n    )", "response": "Return this consoles default foreground color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the background color at the x y of this console.", "response": "def console_get_char_background(\n    con: tcod.console.Console, x: int, y: int\n) -> Color:\n    \"\"\"Return the background color at the x,y of this console.\n\n    .. deprecated:: 8.4\n        Array access performs significantly faster than using this function.\n        See :any:`Console.bg`.\n    \"\"\"\n    return Color._new_from_cdata(\n        lib.TCOD_console_get_char_background(_console(con), x, y)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef console_get_char_foreground(\n    con: tcod.console.Console, x: int, y: int\n) -> Color:\n    \"\"\"Return the foreground color at the x,y of this console.\n\n    .. deprecated:: 8.4\n        Array access performs significantly faster than using this function.\n        See :any:`Console.fg`.\n    \"\"\"\n    return Color._new_from_cdata(\n        lib.TCOD_console_get_char_foreground(_console(con), x, y)\n    )", "response": "Return the foreground color at the x y of this console."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the character at the x y of this console.", "response": "def console_get_char(con: tcod.console.Console, x: int, y: int) -> int:\n    \"\"\"Return the character at the x,y of this console.\n\n    .. deprecated:: 8.4\n        Array access performs significantly faster than using this function.\n        See :any:`Console.ch`.\n    \"\"\"\n    return lib.TCOD_console_get_char(_console(con), x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_wait_for_keypress(flush: bool) -> Key:\n    key = Key()\n    lib.TCOD_console_wait_for_keypress_wrapper(key.key_p, flush)\n    return key", "response": "Block until the user presses a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a key that is pressed if flags is KEY_RELEASED.", "response": "def console_check_for_keypress(flags: int = KEY_RELEASED) -> Key:\n    \"\"\"\n    .. deprecated:: 9.3\n        Use the :any:`tcod.event.get` function to check for events.\n    \"\"\"\n    key = Key()\n    lib.TCOD_console_check_for_keypress_wrapper(key.key_p, flags)\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef console_new(w: int, h: int) -> tcod.console.Console:\n    return tcod.console.Console(w, h)", "response": "Return an offscreen console of size w h."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_from_file(filename: str) -> tcod.console.Console:\n    return tcod.console.Console._from_cdata(\n        lib.TCOD_console_from_file(filename.encode(\"utf-8\"))\n    )", "response": "Return a new console object from a filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef console_set_key_color(\n    con: tcod.console.Console, col: Tuple[int, int, int]\n) -> None:\n    \"\"\"Set a consoles blit transparent color.\n\n    .. deprecated:: 8.5\n        Pass the key color to :any:`tcod.console.Console.blit` instead of\n        calling this function.\n    \"\"\"\n    lib.TCOD_console_set_key_color(_console(con), col)\n    if hasattr(con, \"set_key_color\"):\n        con.set_key_color(col)", "response": "Change the key color of a consoles transparent color."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose the root console.", "response": "def console_delete(con: tcod.console.Console) -> None:\n    \"\"\"Closes the window if `con` is the root console.\n\n    libtcod objects are automatically garbage collected once they go out of\n    scope.\n\n    This function exists for backwards compatibility.\n\n    .. deprecated:: 9.3\n        This function is not needed for normal :any:`tcod.console.Console`'s.\n        The root console should be used in a with statement instead to ensure\n        that it closes.\n    \"\"\"\n    con = _console(con)\n    if con == ffi.NULL:\n        lib.TCOD_console_delete(con)\n        warnings.warn(\n            \"Instead of this call you should use a with statement to ensure\"\n            \" the root console closes, for example:\"\n            \"\\n    with tcod.console_init_root(...) as root_console:\"\n            \"\\n        ...\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n    else:\n        warnings.warn(\n            \"You no longer need to make this call, \"\n            \"Console's are deleted when they go out of scope.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_fill_foreground(\n    con: tcod.console.Console,\n    r: Sequence[int],\n    g: Sequence[int],\n    b: Sequence[int],\n) -> None:\n    \"\"\"Fill the foregound of a console with r,g,b.\n\n    Args:\n        con (Console): Any Console instance.\n        r (Sequence[int]): An array of integers with a length of width*height.\n        g (Sequence[int]): An array of integers with a length of width*height.\n        b (Sequence[int]): An array of integers with a length of width*height.\n\n    .. deprecated:: 8.4\n        You should assign to :any:`tcod.console.Console.fg` instead.\n    \"\"\"\n    if len(r) != len(g) or len(r) != len(b):\n        raise TypeError(\"R, G and B must all have the same size.\")\n    if (\n        isinstance(r, np.ndarray)\n        and isinstance(g, np.ndarray)\n        and isinstance(b, np.ndarray)\n    ):\n        # numpy arrays, use numpy's ctypes functions\n        r_ = np.ascontiguousarray(r, dtype=np.intc)\n        g_ = np.ascontiguousarray(g, dtype=np.intc)\n        b_ = np.ascontiguousarray(b, dtype=np.intc)\n        cr = ffi.cast(\"int *\", r_.ctypes.data)\n        cg = ffi.cast(\"int *\", g_.ctypes.data)\n        cb = ffi.cast(\"int *\", b_.ctypes.data)\n    else:\n        # otherwise convert using ffi arrays\n        cr = ffi.new(\"int[]\", r)\n        cg = ffi.new(\"int[]\", g)\n        cb = ffi.new(\"int[]\", b)\n\n    lib.TCOD_console_fill_foreground(_console(con), cr, cg, cb)", "response": "Fill the foreground of a console with r g b."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfill the character tiles of a console with an array.", "response": "def console_fill_char(con: tcod.console.Console, arr: Sequence[int]) -> None:\n    \"\"\"Fill the character tiles of a console with an array.\n\n    `arr` is an array of integers with a length of the consoles width and\n    height.\n\n    .. deprecated:: 8.4\n        You should assign to :any:`tcod.console.Console.ch` instead.\n    \"\"\"\n    if isinstance(arr, np.ndarray):\n        # numpy arrays, use numpy's ctypes functions\n        np_array = np.ascontiguousarray(arr, dtype=np.intc)\n        carr = ffi.cast(\"int *\", np_array.ctypes.data)\n    else:\n        # otherwise convert using the ffi module\n        carr = ffi.new(\"int[]\", arr)\n\n    lib.TCOD_console_fill_char(_console(con), carr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef console_load_asc(con: tcod.console.Console, filename: str) -> bool:\n    return bool(\n        lib.TCOD_console_load_asc(_console(con), filename.encode(\"utf-8\"))\n    )", "response": "Update a console from a non - delimited ASCII. asc file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef console_save_asc(con: tcod.console.Console, filename: str) -> bool:\n    return bool(\n        lib.TCOD_console_save_asc(_console(con), filename.encode(\"utf-8\"))\n    )", "response": "Save a console to a non - delimited ASCII. asc file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a console from an ASCII Paint. apf file.", "response": "def console_load_apf(con: tcod.console.Console, filename: str) -> bool:\n    \"\"\"Update a console from an ASCII Paint `.apf` file.\"\"\"\n    return bool(\n        lib.TCOD_console_load_apf(_console(con), filename.encode(\"utf-8\"))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef console_save_apf(con: tcod.console.Console, filename: str) -> bool:\n    return bool(\n        lib.TCOD_console_save_apf(_console(con), filename.encode(\"utf-8\"))\n    )", "response": "Save a console to an ASCII Paint. apf file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_load_xp(con: tcod.console.Console, filename: str) -> bool:\n    return bool(\n        lib.TCOD_console_load_xp(_console(con), filename.encode(\"utf-8\"))\n    )", "response": "Update a console from a REXPaint. xp file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef console_save_xp(\n    con: tcod.console.Console, filename: str, compress_level: int = 9\n) -> bool:\n    \"\"\"Save a console to a REXPaint `.xp` file.\"\"\"\n    return bool(\n        lib.TCOD_console_save_xp(\n            _console(con), filename.encode(\"utf-8\"), compress_level\n        )\n    )", "response": "Save a console to a REXPaint. xp file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_from_xp(filename: str) -> tcod.console.Console:\n    return tcod.console.Console._from_cdata(\n        lib.TCOD_console_from_xp(filename.encode(\"utf-8\"))\n    )", "response": "Return a single console from a REXPaint. xp file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef console_list_load_xp(\n    filename: str\n) -> Optional[List[tcod.console.Console]]:\n    \"\"\"Return a list of consoles from a REXPaint `.xp` file.\"\"\"\n    tcod_list = lib.TCOD_console_list_from_xp(filename.encode(\"utf-8\"))\n    if tcod_list == ffi.NULL:\n        return None\n    try:\n        python_list = []\n        lib.TCOD_list_reverse(tcod_list)\n        while not lib.TCOD_list_is_empty(tcod_list):\n            python_list.append(\n                tcod.console.Console._from_cdata(lib.TCOD_list_pop(tcod_list))\n            )\n        return python_list\n    finally:\n        lib.TCOD_list_delete(tcod_list)", "response": "Return a list of consoles from a REXPaint. xp file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef console_list_save_xp(\n    console_list: Sequence[tcod.console.Console],\n    filename: str,\n    compress_level: int = 9,\n) -> bool:\n    \"\"\"Save a list of consoles to a REXPaint `.xp` file.\"\"\"\n    tcod_list = lib.TCOD_list_new()\n    try:\n        for console in console_list:\n            lib.TCOD_list_push(tcod_list, _console(console))\n        return bool(\n            lib.TCOD_console_list_save_xp(\n                tcod_list, filename.encode(\"utf-8\"), compress_level\n            )\n        )\n    finally:\n        lib.TCOD_list_delete(tcod_list)", "response": "Save a list of consoles to a REXPaint. xp file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new AStar using the given Map.", "response": "def path_new_using_map(\n    m: tcod.map.Map, dcost: float = 1.41\n) -> tcod.path.AStar:\n    \"\"\"Return a new AStar using the given Map.\n\n    Args:\n        m (Map): A Map instance.\n        dcost (float): The path-finding cost of diagonal movement.\n                       Can be set to 0 to disable diagonal movement.\n    Returns:\n        AStar: A new AStar instance.\n    \"\"\"\n    return tcod.path.AStar(m, dcost)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new AStar using the given callable function.", "response": "def path_new_using_function(\n    w: int,\n    h: int,\n    func: Callable[[int, int, int, int, Any], float],\n    userData: Any = 0,\n    dcost: float = 1.41,\n) -> tcod.path.AStar:\n    \"\"\"Return a new AStar using the given callable function.\n\n    Args:\n        w (int): Clipping width.\n        h (int): Clipping height.\n        func (Callable[[int, int, int, int, Any], float]):\n        userData (Any):\n        dcost (float): A multiplier for the cost of diagonal movement.\n                       Can be set to 0 to disable diagonal movement.\n    Returns:\n        AStar: A new AStar instance.\n    \"\"\"\n    return tcod.path.AStar(\n        tcod.path._EdgeCostFunc((func, userData), (w, h)), dcost\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_compute(\n    p: tcod.path.AStar, ox: int, oy: int, dx: int, dy: int\n) -> bool:\n    \"\"\"Find a path from (ox, oy) to (dx, dy).  Return True if path is found.\n\n    Args:\n        p (AStar): An AStar instance.\n        ox (int): Starting x position.\n        oy (int): Starting y position.\n        dx (int): Destination x position.\n        dy (int): Destination y position.\n    Returns:\n        bool: True if a valid path was found.  Otherwise False.\n    \"\"\"\n    return bool(lib.TCOD_path_compute(p._path_c, ox, oy, dx, dy))", "response": "Compute a path from ox oy to dx dy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current origin position.", "response": "def path_get_origin(p: tcod.path.AStar) -> Tuple[int, int]:\n    \"\"\"Get the current origin position.\n\n    This point moves when :any:`path_walk` returns the next x,y step.\n\n    Args:\n        p (AStar): An AStar instance.\n    Returns:\n        Tuple[int, int]: An (x, y) point.\n    \"\"\"\n    x = ffi.new(\"int *\")\n    y = ffi.new(\"int *\")\n    lib.TCOD_path_get_origin(p._path_c, x, y)\n    return x[0], y[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the current destination position.", "response": "def path_get_destination(p: tcod.path.AStar) -> Tuple[int, int]:\n    \"\"\"Get the current destination position.\n\n    Args:\n        p (AStar): An AStar instance.\n    Returns:\n        Tuple[int, int]: An (x, y) point.\n    \"\"\"\n    x = ffi.new(\"int *\")\n    y = ffi.new(\"int *\")\n    lib.TCOD_path_get_destination(p._path_c, x, y)\n    return x[0], y[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path_size(p: tcod.path.AStar) -> int:\n    return int(lib.TCOD_path_size(p._path_c))", "response": "Return the current length of the computed path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the point on a path.", "response": "def path_get(p: tcod.path.AStar, idx: int) -> Tuple[int, int]:\n    \"\"\"Get a point on a path.\n\n    Args:\n        p (AStar): An AStar instance.\n        idx (int): Should be in range: 0 <= inx < :any:`path_size`\n    \"\"\"\n    x = ffi.new(\"int *\")\n    y = ffi.new(\"int *\")\n    lib.TCOD_path_get(p._path_c, idx, x, y)\n    return x[0], y[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path_is_empty(p: tcod.path.AStar) -> bool:\n    return bool(lib.TCOD_path_is_empty(p._path_c))", "response": "Return True if a path is empty."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk the path and return the next point in the AStar.", "response": "def path_walk(\n    p: tcod.path.AStar, recompute: bool\n) -> Union[Tuple[int, int], Tuple[None, None]]:\n    \"\"\"Return the next (x, y) point in a path, or (None, None) if it's empty.\n\n    When ``recompute`` is True and a previously valid path reaches a point\n    where it is now blocked, a new path will automatically be found.\n\n    Args:\n        p (AStar): An AStar instance.\n        recompute (bool): Recompute the path automatically.\n    Returns:\n        Union[Tuple[int, int], Tuple[None, None]]:\n            A single (x, y) point, or (None, None)\n    \"\"\"\n    x = ffi.new(\"int *\")\n    y = ffi.new(\"int *\")\n    if lib.TCOD_path_walk(p._path_c, x, y, recompute):\n        return x[0], y[0]\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _heightmap_cdata(array: np.ndarray) -> ffi.CData:\n    if array.flags[\"F_CONTIGUOUS\"]:\n        array = array.transpose()\n    if not array.flags[\"C_CONTIGUOUS\"]:\n        raise ValueError(\"array must be a contiguous segment.\")\n    if array.dtype != np.float32:\n        raise ValueError(\"array dtype must be float32, not %r\" % array.dtype)\n    width, height = array.shape\n    pointer = ffi.cast(\"float *\", array.ctypes.data)\n    return ffi.new(\"TCOD_heightmap_t *\", (width, height, pointer))", "response": "Return a new TCOD_heightmap_t instance using an array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef heightmap_new(w: int, h: int, order: str = \"C\") -> np.ndarray:\n    if order == \"C\":\n        return np.zeros((h, w), np.float32, order=\"C\")\n    elif order == \"F\":\n        return np.zeros((w, h), np.float32, order=\"F\")\n    else:\n        raise ValueError(\"Invalid order parameter, should be 'C' or 'F'.\")", "response": "Return a new NumPy array formatted for use with heightmap functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef heightmap_set_value(hm: np.ndarray, x: int, y: int, value: float) -> None:\n    if hm.flags[\"C_CONTIGUOUS\"]:\n        warnings.warn(\n            \"Assign to this heightmap with hm[i,j] = value\\n\"\n            \"consider using order='F'\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        hm[y, x] = value\n    elif hm.flags[\"F_CONTIGUOUS\"]:\n        warnings.warn(\n            \"Assign to this heightmap with hm[x,y] = value\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        hm[x, y] = value\n    else:\n        raise ValueError(\"This array is not contiguous.\")", "response": "Set the value of a point on a heightmap."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclamping all values on this heightmap between mi and ma.", "response": "def heightmap_clamp(hm: np.ndarray, mi: float, ma: float) -> None:\n    \"\"\"Clamp all values on this heightmap between ``mi`` and ``ma``\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        mi (float): The lower bound to clamp to.\n        ma (float): The upper bound to clamp to.\n\n    .. deprecated:: 2.0\n        Do ``hm.clip(mi, ma)`` instead.\n    \"\"\"\n    hm.clip(mi, ma)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnormalizing heightmap values between mi and ma.", "response": "def heightmap_normalize(\n    hm: np.ndarray, mi: float = 0.0, ma: float = 1.0\n) -> None:\n    \"\"\"Normalize heightmap values between ``mi`` and ``ma``.\n\n    Args:\n        mi (float): The lowest value after normalization.\n        ma (float): The highest value after normalization.\n    \"\"\"\n    lib.TCOD_heightmap_normalize(_heightmap_cdata(hm), mi, ma)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef heightmap_lerp_hm(\n    hm1: np.ndarray, hm2: np.ndarray, hm3: np.ndarray, coef: float\n) -> None:\n    \"\"\"Perform linear interpolation between two heightmaps storing the result\n    in ``hm3``.\n\n    This is the same as doing ``hm3[:] = hm1[:] + (hm2[:] - hm1[:]) * coef``\n\n    Args:\n        hm1 (numpy.ndarray): The first heightmap.\n        hm2 (numpy.ndarray): The second heightmap to add to the first.\n        hm3 (numpy.ndarray): A destination heightmap to store the result.\n        coef (float): The linear interpolation coefficient.\n    \"\"\"\n    lib.TCOD_heightmap_lerp_hm(\n        _heightmap_cdata(hm1),\n        _heightmap_cdata(hm2),\n        _heightmap_cdata(hm3),\n        coef,\n    )", "response": "Perform linear interpolation between two heightmaps storing the result in hm3."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds two heightmaps together and stores the result in hm3.", "response": "def heightmap_add_hm(\n    hm1: np.ndarray, hm2: np.ndarray, hm3: np.ndarray\n) -> None:\n    \"\"\"Add two heightmaps together and stores the result in ``hm3``.\n\n    Args:\n        hm1 (numpy.ndarray): The first heightmap.\n        hm2 (numpy.ndarray): The second heightmap to add to the first.\n        hm3 (numpy.ndarray): A destination heightmap to store the result.\n\n    .. deprecated:: 2.0\n        Do ``hm3[:] = hm1[:] + hm2[:]`` instead.\n    \"\"\"\n    hm3[:] = hm1[:] + hm2[:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef heightmap_multiply_hm(\n    hm1: np.ndarray, hm2: np.ndarray, hm3: np.ndarray\n) -> None:\n    \"\"\"Multiplies two heightmap's together and stores the result in ``hm3``.\n\n    Args:\n        hm1 (numpy.ndarray): The first heightmap.\n        hm2 (numpy.ndarray): The second heightmap to multiply with the first.\n        hm3 (numpy.ndarray): A destination heightmap to store the result.\n\n    .. deprecated:: 2.0\n        Do ``hm3[:] = hm1[:] * hm2[:]`` instead.\n        Alternatively you can do ``HeightMap(hm1.array[:] * hm2.array[:])``.\n    \"\"\"\n    hm3[:] = hm1[:] * hm2[:]", "response": "Multiplies two heightmaps together and stores the result in hm3."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a hill at given position.", "response": "def heightmap_add_hill(\n    hm: np.ndarray, x: float, y: float, radius: float, height: float\n) -> None:\n    \"\"\"Add a hill (a half spheroid) at given position.\n\n    If height == radius or -radius, the hill is a half-sphere.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        x (float): The x position at the center of the new hill.\n        y (float): The y position at the center of the new hill.\n        radius (float): The size of the new hill.\n        height (float): The height or depth of the new hill.\n    \"\"\"\n    lib.TCOD_heightmap_add_hill(_heightmap_cdata(hm), x, y, radius, height)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsimulate the effect of rain drops on the terrain.", "response": "def heightmap_rain_erosion(\n    hm: np.ndarray,\n    nbDrops: int,\n    erosionCoef: float,\n    sedimentationCoef: float,\n    rnd: Optional[tcod.random.Random] = None,\n) -> None:\n    \"\"\"Simulate the effect of rain drops on the terrain, resulting in erosion.\n\n    ``nbDrops`` should be at least hm.size.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        nbDrops (int): Number of rain drops to simulate.\n        erosionCoef (float): Amount of ground eroded on the drop's path.\n        sedimentationCoef (float): Amount of ground deposited when the drops\n                                   stops to flow.\n        rnd (Optional[Random]): A tcod.Random instance, or None.\n    \"\"\"\n    lib.TCOD_heightmap_rain_erosion(\n        _heightmap_cdata(hm),\n        nbDrops,\n        erosionCoef,\n        sedimentationCoef,\n        rnd.random_c if rnd else ffi.NULL,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef heightmap_kernel_transform(\n    hm: np.ndarray,\n    kernelsize: int,\n    dx: Sequence[int],\n    dy: Sequence[int],\n    weight: Sequence[float],\n    minLevel: float,\n    maxLevel: float,\n) -> None:\n    \"\"\"Apply a generic transformation on the map, so that each resulting cell\n    value is the weighted sum of several neighbour cells.\n\n    This can be used to smooth/sharpen the map.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        kernelsize (int): Should be set to the length of the parameters::\n                          dx, dy, and weight.\n        dx (Sequence[int]): A sequence of x coorinates.\n        dy (Sequence[int]): A sequence of y coorinates.\n        weight (Sequence[float]): A sequence of kernelSize cells weight.\n                                  The value of each neighbour cell is scaled by\n                                  its corresponding weight\n        minLevel (float): No transformation will apply to cells\n                          below this value.\n        maxLevel (float): No transformation will apply to cells\n                          above this value.\n\n    See examples below for a simple horizontal smoothing kernel :\n    replace value(x,y) with\n    0.33*value(x-1,y) + 0.33*value(x,y) + 0.33*value(x+1,y).\n    To do this, you need a kernel of size 3\n    (the sum involves 3 surrounding cells).\n    The dx,dy array will contain:\n\n    * dx=-1, dy=0 for cell (x-1, y)\n    * dx=1, dy=0 for cell (x+1, y)\n    * dx=0, dy=0 for cell (x, y)\n    * The weight array will contain 0.33 for each cell.\n\n    Example:\n        >>> import numpy as np\n        >>> heightmap = np.zeros((3, 3), dtype=np.float32)\n        >>> heightmap[:,1] = 1\n        >>> dx = [-1, 1, 0]\n        >>> dy = [0, 0, 0]\n        >>> weight = [0.33, 0.33, 0.33]\n        >>> tcod.heightmap_kernel_transform(heightmap, 3, dx, dy, weight,\n        ...                                 0.0, 1.0)\n    \"\"\"\n    cdx = ffi.new(\"int[]\", dx)\n    cdy = ffi.new(\"int[]\", dy)\n    cweight = ffi.new(\"float[]\", weight)\n    lib.TCOD_heightmap_kernel_transform(\n        _heightmap_cdata(hm), kernelsize, cdx, cdy, cweight, minLevel, maxLevel\n    )", "response": "This function transforms a kernel of the given kernels into a single kernel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef heightmap_add_voronoi(\n    hm: np.ndarray,\n    nbPoints: Any,\n    nbCoef: int,\n    coef: Sequence[float],\n    rnd: Optional[tcod.random.Random] = None,\n) -> None:\n    \"\"\"Add values from a Voronoi diagram to the heightmap.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        nbPoints (Any): Number of Voronoi sites.\n        nbCoef (int): The diagram value is calculated from the nbCoef\n                      closest sites.\n        coef (Sequence[float]): The distance to each site is scaled by the\n                                corresponding coef.\n                                Closest site : coef[0],\n                                second closest site : coef[1], ...\n        rnd (Optional[Random]): A Random instance, or None.\n    \"\"\"\n    nbPoints = len(coef)\n    ccoef = ffi.new(\"float[]\", coef)\n    lib.TCOD_heightmap_add_voronoi(\n        _heightmap_cdata(hm),\n        nbPoints,\n        nbCoef,\n        ccoef,\n        rnd.random_c if rnd else ffi.NULL,\n    )", "response": "Add values from a Voronoi diagram to the heightmap."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds FBM noise to the heightmap.", "response": "def heightmap_add_fbm(\n    hm: np.ndarray,\n    noise: tcod.noise.Noise,\n    mulx: float,\n    muly: float,\n    addx: float,\n    addy: float,\n    octaves: float,\n    delta: float,\n    scale: float,\n) -> None:\n    \"\"\"Add FBM noise to the heightmap.\n\n    The noise coordinate for each map cell is\n    `((x + addx) * mulx / width, (y + addy) * muly / height)`.\n\n    The value added to the heightmap is `delta + noise * scale`.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        noise (Noise): A Noise instance.\n        mulx (float): Scaling of each x coordinate.\n        muly (float): Scaling of each y coordinate.\n        addx (float): Translation of each x coordinate.\n        addy (float): Translation of each y coordinate.\n        octaves (float): Number of octaves in the FBM sum.\n        delta (float): The value added to all heightmap cells.\n        scale (float): The noise value is scaled with this parameter.\n\n    .. deprecated:: 8.1\n        An equivalent array of noise samples can be taken using a method such\n        as :any:`Noise.sample_ogrid`.\n    \"\"\"\n    noise = noise.noise_c if noise is not None else ffi.NULL\n    lib.TCOD_heightmap_add_fbm(\n        _heightmap_cdata(hm),\n        noise,\n        mulx,\n        muly,\n        addx,\n        addy,\n        octaves,\n        delta,\n        scale,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef heightmap_dig_bezier(\n    hm: np.ndarray,\n    px: Tuple[int, int, int, int],\n    py: Tuple[int, int, int, int],\n    startRadius: float,\n    startDepth: float,\n    endRadius: float,\n    endDepth: float,\n) -> None:\n    \"\"\"Carve a path along a cubic Bezier curve.\n\n    Both radius and depth can vary linearly along the path.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        px (Sequence[int]): The 4 `x` coordinates of the Bezier curve.\n        py (Sequence[int]): The 4 `y` coordinates of the Bezier curve.\n        startRadius (float): The starting radius size.\n        startDepth (float): The starting depth.\n        endRadius (float): The ending radius size.\n        endDepth (float): The ending depth.\n    \"\"\"\n    lib.TCOD_heightmap_dig_bezier(\n        _heightmap_cdata(hm),\n        px,\n        py,\n        startRadius,\n        startDepth,\n        endRadius,\n        endDepth,\n    )", "response": "Carve a path along a cubic Bezier curve."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value at x y in the specified heightmap.", "response": "def heightmap_get_interpolated_value(\n    hm: np.ndarray, x: float, y: float\n) -> float:\n    \"\"\"Return the interpolated height at non integer coordinates.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        x (float): A floating point x coordinate.\n        y (float): A floating point y coordinate.\n\n    Returns:\n        float: The value at ``x``, ``y``.\n    \"\"\"\n    return float(\n        lib.TCOD_heightmap_get_interpolated_value(_heightmap_cdata(hm), x, y)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the slope between 0 and pi at given coordinates.", "response": "def heightmap_get_slope(hm: np.ndarray, x: int, y: int) -> float:\n    \"\"\"Return the slope between 0 and (pi / 2) at given coordinates.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        x (int): The x coordinate.\n        y (int): The y coordinate.\n\n    Returns:\n        float: The steepness at ``x``, ``y``.  From 0 to (pi / 2)\n    \"\"\"\n    return float(lib.TCOD_heightmap_get_slope(_heightmap_cdata(hm), x, y))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the map normal at given coordinates.", "response": "def heightmap_get_normal(\n    hm: np.ndarray, x: float, y: float, waterLevel: float\n) -> Tuple[float, float, float]:\n    \"\"\"Return the map normal at given coordinates.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        x (float): The x coordinate.\n        y (float): The y coordinate.\n        waterLevel (float): The heightmap is considered flat below this value.\n\n    Returns:\n        Tuple[float, float, float]: An (x, y, z) vector normal.\n    \"\"\"\n    cn = ffi.new(\"float[3]\")\n    lib.TCOD_heightmap_get_normal(_heightmap_cdata(hm), x, y, cn, waterLevel)\n    return tuple(cn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of map cells which value is between mi and ma.", "response": "def heightmap_count_cells(hm: np.ndarray, mi: float, ma: float) -> int:\n    \"\"\"Return the number of map cells which value is between ``mi`` and ``ma``.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n        mi (float): The lower bound.\n        ma (float): The upper bound.\n\n    Returns:\n        int: The count of values which fall between ``mi`` and ``ma``.\n\n    .. deprecated:: 8.1\n        Can be replaced by an equivalent NumPy function such as:\n        ``numpy.count_nonzero((mi <= hm) & (hm < ma))``\n    \"\"\"\n    return int(lib.TCOD_heightmap_count_cells(_heightmap_cdata(hm), mi, ma))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef heightmap_has_land_on_border(hm: np.ndarray, waterlevel: float) -> bool:\n    return bool(\n        lib.TCOD_heightmap_has_land_on_border(_heightmap_cdata(hm), waterlevel)\n    )", "response": "Returns True if the map edges are below waterlevel False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the min and max values of this heightmap.", "response": "def heightmap_get_minmax(hm: np.ndarray) -> Tuple[float, float]:\n    \"\"\"Return the min and max values of this heightmap.\n\n    Args:\n        hm (numpy.ndarray): A numpy.ndarray formatted for heightmap functions.\n\n    Returns:\n        Tuple[float, float]: The (min, max) values.\n\n    .. deprecated:: 2.0\n        Use ``hm.min()`` or ``hm.max()`` instead.\n    \"\"\"\n    mi = ffi.new(\"float *\")\n    ma = ffi.new(\"float *\")\n    lib.TCOD_heightmap_get_minmax(_heightmap_cdata(hm), mi, ma)\n    return mi[0], ma[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads an image file into an Image instance and return it.", "response": "def image_load(filename: str) -> tcod.image.Image:\n    \"\"\"Load an image file into an Image instance and return it.\n\n    Args:\n        filename (AnyStr): Path to a .bmp or .png image file.\n    \"\"\"\n    return tcod.image.Image._from_cdata(\n        ffi.gc(lib.TCOD_image_load(_bytes(filename)), lib.TCOD_image_delete)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef image_from_console(console: tcod.console.Console) -> tcod.image.Image:\n    return tcod.image.Image._from_cdata(\n        ffi.gc(\n            lib.TCOD_image_from_console(_console(console)),\n            lib.TCOD_image_delete,\n        )\n    )", "response": "Return an Image with a Consoles pixel data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef line_init(xo: int, yo: int, xd: int, yd: int) -> None:\n    lib.TCOD_line_init(xo, yo, xd, yd)", "response": "Initilize a line whose points will be returned by line_step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef line(\n    xo: int, yo: int, xd: int, yd: int, py_callback: Callable[[int, int], bool]\n) -> bool:\n    \"\"\" Iterate over a line using a callback function.\n\n    Your callback function will take x and y parameters and return True to\n    continue iteration or False to stop iteration and return.\n\n    This function includes both the start and end points.\n\n    Args:\n        xo (int): X starting point.\n        yo (int): Y starting point.\n        xd (int): X destination point.\n        yd (int): Y destination point.\n        py_callback (Callable[[int, int], bool]):\n            A callback which takes x and y parameters and returns bool.\n\n    Returns:\n        bool: False if the callback cancels the line interation by\n              returning False or None, otherwise True.\n\n    .. deprecated:: 2.0\n       Use `line_iter` instead.\n    \"\"\"\n    for x, y in line_iter(xo, yo, xd, yd):\n        if not py_callback(x, y):\n            break\n    else:\n        return True\n    return False", "response": "Iterate over a line using a callback function."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator over the points in a line.", "response": "def line_iter(xo: int, yo: int, xd: int, yd: int) -> Iterator[Tuple[int, int]]:\n    \"\"\" returns an Iterable\n\n    This Iterable does not include the origin point.\n\n    Args:\n        xo (int): X starting point.\n        yo (int): Y starting point.\n        xd (int): X destination point.\n        yd (int): Y destination point.\n\n    Returns:\n        Iterable[Tuple[int,int]]: An Iterable of (x,y) points.\n    \"\"\"\n    data = ffi.new(\"TCOD_bresenham_data_t *\")\n    lib.TCOD_line_init_mt(xo, yo, xd, yd, data)\n    x = ffi.new(\"int *\")\n    y = ffi.new(\"int *\")\n    yield xo, yo\n    while not lib.TCOD_line_step_mt(x, y, data):\n        yield (x[0], y[0])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef line_where(\n    x1: int, y1: int, x2: int, y2: int, inclusive: bool = True\n) -> Tuple[np.array, np.array]:\n    \"\"\"Return a NumPy index array following a Bresenham line.\n\n    If `inclusive` is true then the start point is included in the result.\n\n    Example:\n        >>> where = tcod.line_where(1, 0, 3, 4)\n        >>> where\n        (array([1, 1, 2, 2, 3]...), array([0, 1, 2, 3, 4]...))\n        >>> array = np.zeros((5, 5), dtype=np.int32)\n        >>> array[where] = np.arange(len(where[0])) + 1\n        >>> array\n        array([[0, 0, 0, 0, 0],\n               [1, 2, 0, 0, 0],\n               [0, 0, 3, 4, 0],\n               [0, 0, 0, 0, 5],\n               [0, 0, 0, 0, 0]]...)\n\n    .. versionadded:: 4.6\n    \"\"\"\n    length = max(abs(x1 - x2), abs(y1 - y2)) + 1\n    array = np.ndarray((2, length), dtype=np.intc)\n    x = ffi.cast(\"int*\", array[0].ctypes.data)\n    y = ffi.cast(\"int*\", array[1].ctypes.data)\n    lib.LineWhere(x1, y1, x2, y2, x, y)\n    if not inclusive:\n        array = array[:, 1:]\n    return tuple(array)", "response": "Return a NumPy index array following a Bresenham line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_new(w: int, h: int) -> tcod.map.Map:\n    return tcod.map.Map(w, h)", "response": "Return a new map with a width and height."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map_copy(source: tcod.map.Map, dest: tcod.map.Map) -> None:\n    if source.width != dest.width or source.height != dest.height:\n        dest.__init__(  # type: ignore\n            source.width, source.height, source._order\n        )\n    dest._Map__buffer[:] = source._Map__buffer[:]", "response": "Copy map data from source to dest."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map_set_properties(\n    m: tcod.map.Map, x: int, y: int, isTrans: bool, isWalk: bool\n) -> None:\n    \"\"\"Set the properties of a single cell.\n\n    .. note::\n        This function is slow.\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.transparent` and :any:`tcod.map.Map.walkable`\n        arrays to set these properties.\n    \"\"\"\n    lib.TCOD_map_set_properties(m.map_c, x, y, isTrans, isWalk)", "response": "Set the properties of a single cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_clear(\n    m: tcod.map.Map, transparent: bool = False, walkable: bool = False\n) -> None:\n    \"\"\"Change all map cells to a specific value.\n\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.transparent` and :any:`tcod.map.Map.walkable`\n        arrays to set these properties.\n    \"\"\"\n    m.transparent[:] = transparent\n    m.walkable[:] = walkable", "response": "Clear the contents of the given map."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_compute_fov(\n    m: tcod.map.Map,\n    x: int,\n    y: int,\n    radius: int = 0,\n    light_walls: bool = True,\n    algo: int = FOV_RESTRICTIVE,\n) -> None:\n    \"\"\"Compute the field-of-view for a map instance.\n\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.compute_fov` instead.\n    \"\"\"\n    m.compute_fov(x, y, radius, light_walls, algo)", "response": "Compute the field - of - view for a map instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_is_in_fov(m: tcod.map.Map, x: int, y: int) -> bool:\n    return bool(lib.TCOD_map_is_in_fov(m.map_c, x, y))", "response": "Return True if the cell at x y is lit by the last field - of - view\n    algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if x y is transparent.", "response": "def map_is_transparent(m: tcod.map.Map, x: int, y: int) -> bool:\n    \"\"\"\n    .. note::\n        This function is slow.\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.transparent` to check this property.\n    \"\"\"\n    return bool(lib.TCOD_map_is_transparent(m.map_c, x, y))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if x y is in the map s walkable area.", "response": "def map_is_walkable(m: tcod.map.Map, x: int, y: int) -> bool:\n    \"\"\"\n    .. note::\n        This function is slow.\n    .. deprecated:: 4.5\n        Use :any:`tcod.map.Map.walkable` to check this property.\n    \"\"\"\n    return bool(lib.TCOD_map_is_walkable(m.map_c, x, y))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef noise_new(\n    dim: int,\n    h: float = NOISE_DEFAULT_HURST,\n    l: float = NOISE_DEFAULT_LACUNARITY,  # noqa: E741\n    random: Optional[tcod.random.Random] = None,\n) -> tcod.noise.Noise:\n    \"\"\"Return a new Noise instance.\n\n    Args:\n        dim (int): Number of dimensions.  From 1 to 4.\n        h (float): The hurst exponent.  Should be in the 0.0-1.0 range.\n        l (float): The noise lacunarity.\n        random (Optional[Random]): A Random instance, or None.\n\n    Returns:\n        Noise: The new Noise instance.\n    \"\"\"\n    return tcod.noise.Noise(dim, hurst=h, lacunarity=l, seed=random)", "response": "Return a new Noise instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a Noise object default noise algorithm.", "response": "def noise_set_type(n: tcod.noise.Noise, typ: int) -> None:\n    \"\"\"Set a Noise objects default noise algorithm.\n\n    Args:\n        typ (int): Any NOISE_* constant.\n    \"\"\"\n    n.algorithm = typ"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef noise_get(\n    n: tcod.noise.Noise, f: Sequence[float], typ: int = NOISE_DEFAULT\n) -> float:\n    \"\"\"Return the noise value sampled from the ``f`` coordinate.\n\n    ``f`` should be a tuple or list with a length matching\n    :any:`Noise.dimensions`.\n    If ``f`` is shoerter than :any:`Noise.dimensions` the missing coordinates\n    will be filled with zeros.\n\n    Args:\n        n (Noise): A Noise instance.\n        f (Sequence[float]): The point to sample the noise from.\n        typ (int): The noise algorithm to use.\n\n    Returns:\n        float: The sampled noise value.\n    \"\"\"\n    return float(lib.TCOD_noise_get_ex(n.noise_c, ffi.new(\"float[4]\", f), typ))", "response": "Return the noise value sampled from the f coordinate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the fractal Brownian motion sampled from the f coordinate.", "response": "def noise_get_fbm(\n    n: tcod.noise.Noise,\n    f: Sequence[float],\n    oc: float,\n    typ: int = NOISE_DEFAULT,\n) -> float:\n    \"\"\"Return the fractal Brownian motion sampled from the ``f`` coordinate.\n\n    Args:\n        n (Noise): A Noise instance.\n        f (Sequence[float]): The point to sample the noise from.\n        typ (int): The noise algorithm to use.\n        octaves (float): The level of level.  Should be more than 1.\n\n    Returns:\n        float: The sampled noise value.\n    \"\"\"\n    return float(\n        lib.TCOD_noise_get_fbm_ex(n.noise_c, ffi.new(\"float[4]\", f), oc, typ)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the turbulence noise sampled from the f coordinate.", "response": "def noise_get_turbulence(\n    n: tcod.noise.Noise,\n    f: Sequence[float],\n    oc: float,\n    typ: int = NOISE_DEFAULT,\n) -> float:\n    \"\"\"Return the turbulence noise sampled from the ``f`` coordinate.\n\n    Args:\n        n (Noise): A Noise instance.\n        f (Sequence[float]): The point to sample the noise from.\n        typ (int): The noise algorithm to use.\n        octaves (float): The level of level.  Should be more than 1.\n\n    Returns:\n        float: The sampled noise value.\n    \"\"\"\n    return float(\n        lib.TCOD_noise_get_turbulence_ex(\n            n.noise_c, ffi.new(\"float[4]\", f), oc, typ\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nunpacking a union from parser new_property.", "response": "def _unpack_union(type_: int, union: Any) -> Any:\n    \"\"\"\n        unpack items from parser new_property (value_converter)\n    \"\"\"\n    if type_ == lib.TCOD_TYPE_BOOL:\n        return bool(union.b)\n    elif type_ == lib.TCOD_TYPE_CHAR:\n        return union.c.decode(\"latin-1\")\n    elif type_ == lib.TCOD_TYPE_INT:\n        return union.i\n    elif type_ == lib.TCOD_TYPE_FLOAT:\n        return union.f\n    elif (\n        type_ == lib.TCOD_TYPE_STRING\n        or lib.TCOD_TYPE_VALUELIST15 >= type_ >= lib.TCOD_TYPE_VALUELIST00\n    ):\n        return _unpack_char_p(union.s)\n    elif type_ == lib.TCOD_TYPE_COLOR:\n        return Color._new_from_cdata(union.col)\n    elif type_ == lib.TCOD_TYPE_DICE:\n        return Dice(union.dice)\n    elif type_ & lib.TCOD_TYPE_LIST:\n        return _convert_TCODList(union.list, type_ & 0xFF)\n    else:\n        raise RuntimeError(\"Unknown libtcod type: %i\" % type_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the default Random instance.", "response": "def random_get_instance() -> tcod.random.Random:\n    \"\"\"Return the default Random instance.\n\n    Returns:\n        Random: A Random instance using the default random number generator.\n    \"\"\"\n    return tcod.random.Random._new_from_cdata(\n        ffi.cast(\"mersenne_data_t*\", lib.TCOD_random_get_instance())\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new Random instance using the given algorithm.", "response": "def random_new(algo: int = RNG_CMWC) -> tcod.random.Random:\n    \"\"\"Return a new Random instance.  Using ``algo``.\n\n    Args:\n        algo (int): The random number algorithm to use.\n\n    Returns:\n        Random: A new Random instance using the given algorithm.\n    \"\"\"\n    return tcod.random.Random(algo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new Random instance using the given seed and algorithm.", "response": "def random_new_from_seed(\n    seed: Hashable, algo: int = RNG_CMWC\n) -> tcod.random.Random:\n    \"\"\"Return a new Random instance.  Using the given ``seed`` and ``algo``.\n\n    Args:\n        seed (Hashable): The RNG seed.  Should be a 32-bit integer, but any\n                         hashable object is accepted.\n        algo (int): The random number algorithm to use.\n\n    Returns:\n        Random: A new Random instance using the given algorithm.\n    \"\"\"\n    return tcod.random.Random(algo, seed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges the distribution mode of a random number generator.", "response": "def random_set_distribution(\n    rnd: Optional[tcod.random.Random], dist: int\n) -> None:\n    \"\"\"Change the distribution mode of a random number generator.\n\n    Args:\n        rnd (Optional[Random]): A Random instance, or None to use the default.\n        dist (int): The distribution mode to use.  Should be DISTRIBUTION_*.\n    \"\"\"\n    lib.TCOD_random_set_distribution(rnd.random_c if rnd else ffi.NULL, dist)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_get_int(rnd: Optional[tcod.random.Random], mi: int, ma: int) -> int:\n    return int(\n        lib.TCOD_random_get_int(rnd.random_c if rnd else ffi.NULL, mi, ma)\n    )", "response": "Return a random integer in the range mi < = n < = ma."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_get_float(\n    rnd: Optional[tcod.random.Random], mi: float, ma: float\n) -> float:\n    \"\"\"Return a random float in the range: ``mi`` <= n <= ``ma``.\n\n    The result is affected by calls to :any:`random_set_distribution`.\n\n    Args:\n        rnd (Optional[Random]): A Random instance, or None to use the default.\n        low (float): The lower bound of the random range, inclusive.\n        high (float): The upper bound of the random range, inclusive.\n\n    Returns:\n        float: A random double precision float\n               in the range ``mi`` <= n <= ``ma``.\n    \"\"\"\n    return float(\n        lib.TCOD_random_get_double(rnd.random_c if rnd else ffi.NULL, mi, ma)\n    )", "response": "Return a random float in the range mi < = n < ma."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random weighted integer in the range mi < = n < = ma.", "response": "def random_get_int_mean(\n    rnd: Optional[tcod.random.Random], mi: int, ma: int, mean: int\n) -> int:\n    \"\"\"Return a random weighted integer in the range: ``mi`` <= n <= ``ma``.\n\n    The result is affacted by calls to :any:`random_set_distribution`.\n\n    Args:\n        rnd (Optional[Random]): A Random instance, or None to use the default.\n        low (int): The lower bound of the random range, inclusive.\n        high (int): The upper bound of the random range, inclusive.\n        mean (int): The mean return value.\n\n    Returns:\n        int: A random weighted integer in the range ``mi`` <= n <= ``ma``.\n    \"\"\"\n    return int(\n        lib.TCOD_random_get_int_mean(\n            rnd.random_c if rnd else ffi.NULL, mi, ma, mean\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_get_float_mean(\n    rnd: Optional[tcod.random.Random], mi: float, ma: float, mean: float\n) -> float:\n    \"\"\"Return a random weighted float in the range: ``mi`` <= n <= ``ma``.\n\n    The result is affacted by calls to :any:`random_set_distribution`.\n\n    Args:\n        rnd (Optional[Random]): A Random instance, or None to use the default.\n        low (float): The lower bound of the random range, inclusive.\n        high (float): The upper bound of the random range, inclusive.\n        mean (float): The mean return value.\n\n    Returns:\n        float: A random weighted double precision float\n               in the range ``mi`` <= n <= ``ma``.\n    \"\"\"\n    return float(\n        lib.TCOD_random_get_double_mean(\n            rnd.random_c if rnd else ffi.NULL, mi, ma, mean\n        )\n    )", "response": "Return a random weighted float in the range mi < = n < ma."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_save(rnd: Optional[tcod.random.Random]) -> tcod.random.Random:\n    return tcod.random.Random._new_from_cdata(\n        ffi.gc(\n            ffi.cast(\n                \"mersenne_data_t*\",\n                lib.TCOD_random_save(rnd.random_c if rnd else ffi.NULL),\n            ),\n            lib.TCOD_random_delete,\n        )\n    )", "response": "Return a copy of a random number generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrestores a random number generator from a backed up copy.", "response": "def random_restore(\n    rnd: Optional[tcod.random.Random], backup: tcod.random.Random\n) -> None:\n    \"\"\"Restore a random number generator from a backed up copy.\n\n    Args:\n        rnd (Optional[Random]): A Random instance, or None to use the default.\n        backup (Random): The Random instance which was used as a backup.\n\n    .. deprecated:: 8.4\n        You can use the standard library copy and pickle modules to save a\n        random state.\n    \"\"\"\n    lib.TCOD_random_restore(rnd.random_c if rnd else ffi.NULL, backup.random_c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sys_set_renderer(renderer: int) -> None:\n    lib.TCOD_sys_set_renderer(renderer)\n    if tcod.console._root_console is not None:\n        tcod.console.Console._get_root()", "response": "Change the current rendering mode to renderer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sys_save_screenshot(name: Optional[str] = None) -> None:\n    lib.TCOD_sys_save_screenshot(\n        _bytes(name) if name is not None else ffi.NULL\n    )", "response": "Save a screenshot to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sys_get_current_resolution() -> Tuple[int, int]:\n    w = ffi.new(\"int *\")\n    h = ffi.new(\"int *\")\n    lib.TCOD_sys_get_current_resolution(w, h)\n    return w[0], h[0]", "response": "Return the current resolution as ( width height )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sys_get_char_size() -> Tuple[int, int]:\n    w = ffi.new(\"int *\")\n    h = ffi.new(\"int *\")\n    lib.TCOD_sys_get_char_size(w, h)\n    return w[0], h[0]", "response": "Return the current font character size as ( width height )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sys_update_char(\n    asciiCode: int,\n    fontx: int,\n    fonty: int,\n    img: tcod.image.Image,\n    x: int,\n    y: int,\n) -> None:\n    \"\"\"Dynamically update the current font with img.\n\n    All cells using this asciiCode will be updated\n    at the next call to :any:`tcod.console_flush`.\n\n    Args:\n        asciiCode (int): Ascii code corresponding to the character to update.\n        fontx (int): Left coordinate of the character\n                     in the bitmap font (in tiles)\n        fonty (int): Top coordinate of the character\n                     in the bitmap font (in tiles)\n        img (Image): An image containing the new character bitmap.\n        x (int): Left pixel of the character in the image.\n        y (int): Top pixel of the character in the image.\n    \"\"\"\n    lib.TCOD_sys_update_char(_int(asciiCode), fontx, fonty, img, x, y)", "response": "Dynamically update the current font with the given character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a custom randering function with libtcod.", "response": "def sys_register_SDL_renderer(callback: Callable[[Any], None]) -> None:\n    \"\"\"Register a custom randering function with libtcod.\n\n    Note:\n        This callback will only be called by the SDL renderer.\n\n    The callack will receive a :any:`CData <ffi-cdata>` void* to an\n    SDL_Surface* struct.\n\n    The callback is called on every call to :any:`tcod.console_flush`.\n\n    Args:\n        callback Callable[[CData], None]:\n            A function which takes a single argument.\n    \"\"\"\n    with _PropagateException() as propagate:\n\n        @ffi.def_extern(onerror=propagate)  # type: ignore\n        def _pycall_sdl_hook(sdl_surface: Any) -> None:\n            callback(sdl_surface)\n\n        lib.TCOD_sys_register_SDL_renderer(lib._pycall_sdl_hook)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sys_check_for_event(\n    mask: int, k: Optional[Key], m: Optional[Mouse]\n) -> int:\n    \"\"\"Check for and return an event.\n\n    Args:\n        mask (int): :any:`Event types` to wait for.\n        k (Optional[Key]): A tcod.Key instance which might be updated with\n                           an event.  Can be None.\n        m (Optional[Mouse]): A tcod.Mouse instance which might be updated\n                             with an event.  Can be None.\n\n    .. deprecated:: 9.3\n        Use the :any:`tcod.event.get` function to check for events.\n    \"\"\"\n    return int(\n        lib.TCOD_sys_check_for_event(\n            mask, k.key_p if k else ffi.NULL, m.mouse_p if m else ffi.NULL\n        )\n    )", "response": "Check for and return an event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sys_wait_for_event(\n    mask: int, k: Optional[Key], m: Optional[Mouse], flush: bool\n) -> int:\n    \"\"\"Wait for an event then return.\n\n    If flush is True then the buffer will be cleared before waiting. Otherwise\n    each available event will be returned in the order they're recieved.\n\n    Args:\n        mask (int): :any:`Event types` to wait for.\n        k (Optional[Key]): A tcod.Key instance which might be updated with\n                           an event.  Can be None.\n        m (Optional[Mouse]): A tcod.Mouse instance which might be updated\n                             with an event.  Can be None.\n        flush (bool): Clear the event buffer before waiting.\n\n    .. deprecated:: 9.3\n        Use the :any:`tcod.event.wait` function to wait for events.\n    \"\"\"\n    return int(\n        lib.TCOD_sys_wait_for_event(\n            mask,\n            k.key_p if k else ffi.NULL,\n            m.mouse_p if m else ffi.NULL,\n            flush,\n        )\n    )", "response": "Wait for an event then return."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _atexit_verify() -> None:\n    if lib.TCOD_ctx.root:\n        warnings.warn(\n            \"The libtcod root console was implicitly deleted.\\n\"\n            \"Make sure the 'with' statement is used with the root console to\"\n            \" ensure that it closes properly.\",\n            ResourceWarning,\n            stacklevel=2,\n        )\n        lib.TCOD_console_delete(ffi.NULL)", "response": "Warns if the libtcod root console is implicitly deleted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(\n        self,\n        back_r: int = 0,\n        back_g: int = 0,\n        back_b: int = 0,\n        fore_r: int = 0,\n        fore_g: int = 0,\n        fore_b: int = 0,\n        char: str = \" \",\n    ) -> None:\n        \"\"\"Clears the console.  Values to fill it with are optional, defaults\n        to black with no characters.\n\n        Args:\n            back_r (int): Red background color, from 0 to 255.\n            back_g (int): Green background color, from 0 to 255.\n            back_b (int): Blue background color, from 0 to 255.\n            fore_r (int): Red foreground color, from 0 to 255.\n            fore_g (int): Green foreground color, from 0 to 255.\n            fore_b (int): Blue foreground color, from 0 to 255.\n            char (AnyStr): A single character str or bytes object.\n        \"\"\"\n        n = self.width * self.height\n        self.back_r = [back_r] * n\n        self.back_g = [back_g] * n\n        self.back_b = [back_b] * n\n        self.fore_r = [fore_r] * n\n        self.fore_g = [fore_g] * n\n        self.fore_b = [fore_b] * n\n        self.char = [ord(char)] * n", "response": "Clears the console.  Values to fill it with are optional, defaults\n        to black with no characters.\n\n        Args:\n            back_r (int): Red background color, from 0 to 255.\n            back_g (int): Green background color, from 0 to 255.\n            back_b (int): Blue background color, from 0 to 255.\n            fore_r (int): Red foreground color, from 0 to 255.\n            fore_g (int): Green foreground color, from 0 to 255.\n            fore_b (int): Blue foreground color, from 0 to 255.\n            char (AnyStr): A single character str or bytes object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self) -> \"ConsoleBuffer\":\n        other = ConsoleBuffer(0, 0)  # type: \"ConsoleBuffer\"\n        other.width = self.width\n        other.height = self.height\n        other.back_r = list(self.back_r)  # make explicit copies of all lists\n        other.back_g = list(self.back_g)\n        other.back_b = list(self.back_b)\n        other.fore_r = list(self.fore_r)\n        other.fore_g = list(self.fore_g)\n        other.fore_b = list(self.fore_b)\n        other.char = list(self.char)\n        return other", "response": "Returns a copy of this ConsoleBuffer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_fore(\n        self, x: int, y: int, r: int, g: int, b: int, char: str\n    ) -> None:\n        \"\"\"Set the character and foreground color of one cell.\n\n        Args:\n            x (int): X position to change.\n            y (int): Y position to change.\n            r (int): Red foreground color, from 0 to 255.\n            g (int): Green foreground color, from 0 to 255.\n            b (int): Blue foreground color, from 0 to 255.\n            char (AnyStr): A single character str or bytes object.\n        \"\"\"\n        i = self.width * y + x\n        self.fore_r[i] = r\n        self.fore_g[i] = g\n        self.fore_b[i] = b\n        self.char[i] = ord(char)", "response": "Set the character and foreground color of one cell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_back(self, x: int, y: int, r: int, g: int, b: int) -> None:\n        i = self.width * y + x\n        self.back_r[i] = r\n        self.back_g[i] = g\n        self.back_b[i] = b", "response": "Set the background color of one cell."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the background color foreground color and character of one cell.", "response": "def set(\n        self,\n        x: int,\n        y: int,\n        back_r: int,\n        back_g: int,\n        back_b: int,\n        fore_r: int,\n        fore_g: int,\n        fore_b: int,\n        char: str,\n    ) -> None:\n        \"\"\"Set the background color, foreground color and character of one cell.\n\n        Args:\n            x (int): X position to change.\n            y (int): Y position to change.\n            back_r (int): Red background color, from 0 to 255.\n            back_g (int): Green background color, from 0 to 255.\n            back_b (int): Blue background color, from 0 to 255.\n            fore_r (int): Red foreground color, from 0 to 255.\n            fore_g (int): Green foreground color, from 0 to 255.\n            fore_b (int): Blue foreground color, from 0 to 255.\n            char (AnyStr): A single character str or bytes object.\n        \"\"\"\n        i = self.width * y + x\n        self.back_r[i] = back_r\n        self.back_g[i] = back_g\n        self.back_b[i] = back_b\n        self.fore_r[i] = fore_r\n        self.fore_g[i] = fore_g\n        self.fore_b[i] = fore_b\n        self.char[i] = ord(char)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the contents of this console into another console.", "response": "def blit(\n        self,\n        dest: tcod.console.Console,\n        fill_fore: bool = True,\n        fill_back: bool = True,\n    ) -> None:\n        \"\"\"Use libtcod's \"fill\" functions to write the buffer to a console.\n\n        Args:\n            dest (Console): Console object to modify.\n            fill_fore (bool):\n                If True, fill the foreground color and characters.\n            fill_back (bool):\n                If True, fill the background color.\n        \"\"\"\n        if not dest:\n            dest = tcod.console.Console._from_cdata(ffi.NULL)\n        if dest.width != self.width or dest.height != self.height:\n            raise ValueError(\n                \"ConsoleBuffer.blit: \"\n                \"Destination console has an incorrect size.\"\n            )\n\n        if fill_back:\n            bg = dest.bg.ravel()\n            bg[0::3] = self.back_r\n            bg[1::3] = self.back_g\n            bg[2::3] = self.back_b\n\n        if fill_fore:\n            fg = dest.fg.ravel()\n            fg[0::3] = self.fore_r\n            fg[1::3] = self.fore_g\n            fg[2::3] = self.fore_b\n            dest.ch.ravel()[:] = self.char"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self, color: Tuple[int, int, int]) -> None:\n        lib.TCOD_image_clear(self.image_c, color)", "response": "Fill this entire Image with color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscaling this Image to the new width and height.", "response": "def scale(self, width: int, height: int) -> None:\n        \"\"\"Scale this Image to the new width and height.\n\n        Args:\n            width (int): The new width of the Image after scaling.\n            height (int): The new height of the Image after scaling.\n        \"\"\"\n        lib.TCOD_image_scale(self.image_c, width, height)\n        self.width, self.height = width, height"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a color to be transparent during blitting functions.", "response": "def set_key_color(self, color: Tuple[int, int, int]) -> None:\n        \"\"\"Set a color to be transparent during blitting functions.\n\n        Args:\n            color (Union[Tuple[int, int, int], Sequence[int]]):\n                An (r, g, b) sequence or Color instance.\n        \"\"\"\n        lib.TCOD_image_set_key_color(self.image_c, color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_alpha(self, x: int, y: int) -> int:\n        return lib.TCOD_image_get_alpha(self.image_c, x, y)", "response": "Get the Image alpha value at x y."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an Image from a Console.", "response": "def refresh_console(self, console: tcod.console.Console) -> None:\n        \"\"\"Update an Image created with :any:`tcod.image_from_console`.\n\n        The console used with this function should have the same width and\n        height as the Console given to :any:`tcod.image_from_console`.\n        The font width and height must also be the same as when\n        :any:`tcod.image_from_console` was called.\n\n        Args:\n            console (Console): A Console with a pixel width and height\n                               matching this Image.\n        \"\"\"\n        lib.TCOD_image_refresh_console(self.image_c, _console(console))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_size(self) -> Tuple[int, int]:\n        w = ffi.new(\"int *\")\n        h = ffi.new(\"int *\")\n        lib.TCOD_image_get_size(self.image_c, w, h)\n        return w[0], h[0]", "response": "Return the width and height of this Image."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the color of a pixel in this Image.", "response": "def get_pixel(self, x: int, y: int) -> Tuple[int, int, int]:\n        \"\"\"Get the color of a pixel in this Image.\n\n        Args:\n            x (int): X pixel of the Image.  Starting from the left at 0.\n            y (int): Y pixel of the Image.  Starting from the top at 0.\n\n        Returns:\n            Tuple[int, int, int]:\n                An (r, g, b) tuple containing the pixels color value.\n                Values are in a 0 to 255 range.\n        \"\"\"\n        color = lib.TCOD_image_get_pixel(self.image_c, x, y)\n        return color.r, color.g, color.b"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the average color of a rectangle in this Image.", "response": "def get_mipmap_pixel(\n        self, left: float, top: float, right: float, bottom: float\n    ) -> Tuple[int, int, int]:\n        \"\"\"Get the average color of a rectangle in this Image.\n\n        Parameters should stay within the following limits:\n        * 0 <= left < right < Image.width\n        * 0 <= top < bottom < Image.height\n\n        Args:\n            left (float): Left corner of the region.\n            top (float): Top corner of the region.\n            right (float): Right corner of the region.\n            bottom (float): Bottom corner of the region.\n\n        Returns:\n            Tuple[int, int, int]:\n                An (r, g, b) tuple containing the averaged color value.\n                Values are in a 0 to 255 range.\n        \"\"\"\n        color = lib.TCOD_image_get_mipmap_pixel(\n            self.image_c, left, top, right, bottom\n        )\n        return (color.r, color.g, color.b)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put_pixel(self, x: int, y: int, color: Tuple[int, int, int]) -> None:\n        lib.TCOD_image_put_pixel(self.image_c, x, y, color)", "response": "Change a pixel on this Image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef blit(\n        self,\n        console: tcod.console.Console,\n        x: float,\n        y: float,\n        bg_blend: int,\n        scale_x: float,\n        scale_y: float,\n        angle: float,\n    ) -> None:\n        \"\"\"Blit onto a Console using scaling and rotation.\n\n        Args:\n            console (Console): Blit destination Console.\n            x (float): Console X position for the center of the Image blit.\n            y (float): Console Y position for the center of the Image blit.\n                     The Image blit is centered on this position.\n            bg_blend (int): Background blending mode to use.\n            scale_x (float): Scaling along Image x axis.\n                             Set to 1 for no scaling.  Must be over 0.\n            scale_y (float): Scaling along Image y axis.\n                             Set to 1 for no scaling.  Must be over 0.\n            angle (float): Rotation angle in radians. (Clockwise?)\n        \"\"\"\n        lib.TCOD_image_blit(\n            self.image_c,\n            _console(console),\n            x,\n            y,\n            bg_blend,\n            scale_x,\n            scale_y,\n            angle,\n        )", "response": "Blit onto a Console using scaling and rotation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef blit_rect(\n        self,\n        console: tcod.console.Console,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        bg_blend: int,\n    ) -> None:\n        \"\"\"Blit onto a Console without scaling or rotation.\n\n        Args:\n            console (Console): Blit destination Console.\n            x (int): Console tile X position starting from the left at 0.\n            y (int): Console tile Y position starting from the top at 0.\n            width (int): Use -1 for Image width.\n            height (int): Use -1 for Image height.\n            bg_blend (int): Background blending mode to use.\n        \"\"\"\n        lib.TCOD_image_blit_rect(\n            self.image_c, _console(console), x, y, width, height, bg_blend\n        )", "response": "Blit onto a Console with scaling or rotation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_as(self, filename: str) -> None:\n        lib.TCOD_image_save(self.image_c, filename.encode(\"utf-8\"))", "response": "Save the Image to a 32 - bit. bmp or. png file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    WIDTH, HEIGHT = 120, 60\n    TITLE = None\n\n    with tcod.console_init_root(WIDTH, HEIGHT, TITLE, order=\"F\",\n                                renderer=tcod.RENDERER_SDL) as console:\n        tcod.sys_set_fps(24)\n        while True:\n            tcod.console_flush()\n            for event in tcod.event.wait():\n                print(event)\n                if event.type == \"QUIT\":\n                    raise SystemExit()\n                elif event.type == \"MOUSEMOTION\":\n                    console.ch[:, -1] = 0\n                    console.print_(0, HEIGHT - 1, str(event))\n                else:\n                    console.blit(console, 0, 0, 0, 1, WIDTH, HEIGHT - 2)\n                    console.ch[:, -3] = 0\n                    console.print_(0, HEIGHT - 3, str(event))", "response": "This is a simple example of how to use the console."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the changelog and return a tuple of the header and the list of changes.", "response": "def parse_changelog(args: Any) -> Tuple[str, str]:\n    \"\"\"Return an updated changelog and and the list of changes.\"\"\"\n    with open(\"CHANGELOG.rst\", \"r\") as file:\n        match = re.match(\n            pattern=r\"(.*?Unreleased\\n---+\\n)(.+?)(\\n*[^\\n]+\\n---+\\n.*)\",\n            string=file.read(),\n            flags=re.DOTALL,\n        )\n    assert match\n    header, changes, tail = match.groups()\n    tag = \"%s - %s\" % (args.tag, datetime.date.today().isoformat())\n\n    tagged = \"\\n%s\\n%s\\n%s\" % (tag, \"-\" * len(tag), changes)\n    if args.verbose:\n        print(tagged)\n\n    return \"\".join((header, tagged, tail)), changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits this partition into two sub - partitions.", "response": "def split_once(self, horizontal: bool, position: int) -> None:\n        \"\"\"Split this partition into 2 sub-partitions.\n\n        Args:\n            horizontal (bool):\n            position (int):\n        \"\"\"\n        cdata = self._as_cdata()\n        lib.TCOD_bsp_split_once(cdata, horizontal, position)\n        self._unpack_bsp_tree(cdata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndivide this object recursively.", "response": "def split_recursive(\n        self,\n        depth: int,\n        min_width: int,\n        min_height: int,\n        max_horizontal_ratio: float,\n        max_vertical_ratio: float,\n        seed: Optional[tcod.random.Random] = None,\n    ) -> None:\n        \"\"\"Divide this partition recursively.\n\n        Args:\n            depth (int): The maximum depth to divide this object recursively.\n            min_width (int): The minimum width of any individual partition.\n            min_height (int): The minimum height of any individual partition.\n            max_horizontal_ratio (float):\n                Prevent creating a horizontal ratio more extreme than this.\n            max_vertical_ratio (float):\n                Prevent creating a vertical ratio more extreme than this.\n            seed (Optional[tcod.random.Random]):\n                The random number generator to use.\n        \"\"\"\n        cdata = self._as_cdata()\n        lib.TCOD_bsp_split_recursive(\n            cdata,\n            seed or ffi.NULL,\n            depth,\n            min_width,\n            min_height,\n            max_horizontal_ratio,\n            max_vertical_ratio,\n        )\n        self._unpack_bsp_tree(cdata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef in_order(self) -> Iterator[\"BSP\"]:\n        if self.children:\n            yield from self.children[0].in_order()\n            yield self\n            yield from self.children[1].in_order()\n        else:\n            yield self", "response": "Iterate over this BSP s hierarchy in order."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef level_order(self) -> Iterator[\"BSP\"]:\n        next = [self]  # type: List['BSP']\n        while next:\n            level = next  # type: List['BSP']\n            next = []\n            yield from level\n            for node in level:\n                next.extend(node.children)", "response": "Iterate over this BSP s hierarchy in level order."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inverted_level_order(self) -> Iterator[\"BSP\"]:\n        levels = []  # type: List[List['BSP']]\n        next = [self]  # type: List['BSP']\n        while next:\n            levels.append(next)\n            level = next  # type: List['BSP']\n            next = []\n            for node in level:\n                next.extend(node.children)\n        while levels:\n            yield from levels.pop()", "response": "Iterate over this BSP s hierarchy in inverse level order."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if this node contains these coordinates.", "response": "def contains(self, x: int, y: int) -> bool:\n        \"\"\"Returns True if this node contains these coordinates.\n\n        Args:\n            x (int): X position to check.\n            y (int): Y position to check.\n\n        Returns:\n            bool: True if this node contains these coordinates.\n                  Otherwise False.\n        \"\"\"\n        return (\n            self.x <= x < self.x + self.width\n            and self.y <= y < self.y + self.height\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the deepest node which contains these coordinates.", "response": "def find_node(self, x: int, y: int) -> Optional[\"BSP\"]:\n        \"\"\"Return the deepest node which contains these coordinates.\n\n        Returns:\n            Optional[BSP]: BSP object or None.\n        \"\"\"\n        if not self.contains(x, y):\n            return None\n        for child in self.children:\n            found = child.find_node(x, y)  # type: Optional[\"BSP\"]\n            if found:\n                return found\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backport(func):\n    if not __debug__:\n        return func\n\n    @_functools.wraps(func)\n    def deprecated_function(*args, **kargs):\n        _warnings.warn('This function name is deprecated',\n                       DeprecationWarning, 2)\n        return func(*args, **kargs)\n    deprecated_function.__doc__ = None\n    return deprecated_function", "response": "Backport a function name into an old style for compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_fov_type(fov):\n    \"Return a FOV from a string\"\n    oldFOV = fov\n    fov = str(fov).upper()\n    if fov in _FOVTYPES:\n        return _FOVTYPES[fov]\n    if fov[:10] == 'PERMISSIVE' and fov[10].isdigit() and fov[10] != '9':\n        return 4 + int(fov[10])\n    raise _tdl.TDLError('No such fov option as %s' % oldFOV)", "response": "Return a FOV from a string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quick_fov(x, y, callback, fov='PERMISSIVE', radius=7.5, lightWalls=True,\n              sphere=True):\n    \"\"\"All field-of-view functionality in one call.\n\n    Before using this call be sure to make a function, lambda, or method that takes 2\n    positional parameters and returns True if light can pass through the tile or False\n    for light-blocking tiles and for indexes that are out of bounds of the\n    dungeon.\n\n    This function is 'quick' as in no hassle but can quickly become a very slow\n    function call if a large radius is used or the callback provided itself\n    isn't optimized.\n\n    Always check if the index is in bounds both in the callback and in the\n    returned values.  These values can go into the negatives as well.\n\n    Args:\n        x (int): x center of the field-of-view\n        y (int): y center of the field-of-view\n        callback (Callable[[int, int], bool]):\n\n            This should be a function that takes two positional arguments x,y\n            and returns True if the tile at that position is transparent\n            or False if the tile blocks light or is out of bounds.\n        fov (Text): The type of field-of-view to be used.\n\n            Available types are:\n            'BASIC', 'DIAMOND', 'SHADOW', 'RESTRICTIVE', 'PERMISSIVE',\n            'PERMISSIVE0', 'PERMISSIVE1', ..., 'PERMISSIVE8'\n        radius (float) Radius of the field-of-view.\n\n            When sphere is True a floating point can be used to fine-tune\n            the range.  Otherwise the radius is just rounded up.\n\n            Be careful as a large radius has an exponential affect on\n            how long this function takes.\n        lightWalls (bool): Include or exclude wall tiles in the field-of-view.\n        sphere (bool): True for a spherical field-of-view.\n            False for a square one.\n\n    Returns:\n        Set[Tuple[int, int]]: A set of (x, y) points that are within the\n            field-of-view.\n    \"\"\"\n    trueRadius = radius\n    radius = int(_math.ceil(radius))\n    mapSize = radius * 2 + 1\n    fov = _get_fov_type(fov)\n\n    setProp = _lib.TCOD_map_set_properties # make local\n    inFOV = _lib.TCOD_map_is_in_fov\n\n    tcodMap = _lib.TCOD_map_new(mapSize, mapSize)\n    try:\n        # pass no.1, write callback data to the tcodMap\n        for x_, y_ in _itertools.product(range(mapSize), range(mapSize)):\n            pos = (x_ + x - radius,\n                   y_ + y - radius)\n            transparent = bool(callback(*pos))\n            setProp(tcodMap, x_, y_, transparent, False)\n\n        # pass no.2, compute fov and build a list of points\n        _lib.TCOD_map_compute_fov(tcodMap, radius, radius, radius, lightWalls, fov)\n        touched = set() # points touched by field of view\n        for x_, y_ in _itertools.product(range(mapSize), range(mapSize)):\n            if sphere and _math.hypot(x_ - radius, y_ - radius) > trueRadius:\n                continue\n            if inFOV(tcodMap, x_, y_):\n                touched.add((x_ + x - radius, y_ + y - radius))\n    finally:\n        _lib.TCOD_map_delete(tcodMap)\n    return touched", "response": "This function is used to make a quick version of the field - of - view function. This function is used to make a quick version of the function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of points in a bresenham line.", "response": "def bresenham(x1, y1, x2, y2):\n    \"\"\"\n    Return a list of points in a bresenham line.\n\n    Implementation hastily copied from RogueBasin.\n\n    Returns:\n        List[Tuple[int, int]]: A list of (x, y) points,\n            including both the start and end-points.\n    \"\"\"\n    points = []\n    issteep = abs(y2-y1) > abs(x2-x1)\n    if issteep:\n        x1, y1 = y1, x1\n        x2, y2 = y2, x2\n    rev = False\n    if x1 > x2:\n        x1, x2 = x2, x1\n        y1, y2 = y2, y1\n        rev = True\n    deltax = x2 - x1\n    deltay = abs(y2-y1)\n    error = int(deltax / 2)\n    y = y1\n    ystep = None\n    if y1 < y2:\n        ystep = 1\n    else:\n        ystep = -1\n    for x in range(x1, x2 + 1):\n        if issteep:\n            points.append((y, x))\n        else:\n            points.append((x, y))\n        error -= deltay\n        if error < 0:\n            y += ystep\n            error += deltax\n    # Reverse the list if the coordinates were reversed\n    if rev:\n        points.reverse()\n    return points"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_fov(self, x, y, fov='PERMISSIVE', radius=None,\n                    light_walls=True, sphere=True, cumulative=False):\n        \"\"\"Compute the field-of-view of this Map and return an iterator of the\n        points touched.\n\n        Args:\n            x (int): Point of view, x-coordinate.\n            y (int): Point of view, y-coordinate.\n            fov (Text): The type of field-of-view to be used.\n\n                Available types are:\n                'BASIC', 'DIAMOND', 'SHADOW', 'RESTRICTIVE', 'PERMISSIVE',\n                'PERMISSIVE0', 'PERMISSIVE1', ..., 'PERMISSIVE8'\n            radius (Optional[int]): Maximum view distance from the point of\n                view.\n\n                A value of 0 will give an infinite distance.\n            light_walls (bool): Light up walls, or only the floor.\n            sphere (bool): If True the lit area will be round instead of\n                square.\n            cumulative (bool): If True the lit cells will accumulate instead\n                of being cleared before the computation.\n\n        Returns:\n            Iterator[Tuple[int, int]]: An iterator of (x, y) points of tiles\n                touched by the field-of-view.\n        \"\"\"\n        # refresh cdata\n        if radius is None: # infinite radius\n            radius = 0\n        if cumulative:\n            fov_copy = self.fov.copy()\n        lib.TCOD_map_compute_fov(\n            self.map_c, x, y, radius, light_walls, _get_fov_type(fov))\n        if cumulative:\n            self.fov[:] |= fov_copy\n        return zip(*np.where(self.fov))", "response": "Compute the field - of - view of this Map and return an iterator of the points touched by the field - of - view."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the shortest path between two points.", "response": "def compute_path(self, start_x, start_y, dest_x, dest_y,\n                     diagonal_cost=_math.sqrt(2)):\n        \"\"\"Get the shortest path between two points.\n\n        Args:\n            start_x (int): Starting x-position.\n            start_y (int): Starting y-position.\n            dest_x (int): Destination x-position.\n            dest_y (int): Destination y-position.\n            diagonal_cost (float): Multiplier for diagonal movement.\n\n                Can be set to zero to disable diagonal movement entirely.\n\n        Returns:\n            List[Tuple[int, int]]: The shortest list of points to the\n                destination position from the starting position.\n\n            The start point is not included in this list.\n        \"\"\"\n        return tcod.path.AStar(self, diagonal_cost).get_path(start_x, start_y,\n                                                             dest_x, dest_y)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_path(self, origX, origY, destX, destY):\n        return super(AStar, self).get_path(origX, origY, destX, destY)", "response": "Get the shortest path from origXY to destXY."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current version from a git tag or by reading tcod. version. py", "response": "def get_version():\n    \"\"\"Get the current version from a git tag, or by reading tcod/version.py\"\"\"\n    try:\n        tag = check_output(\n            [\"git\", \"describe\", \"--abbrev=0\"], universal_newlines=True\n        ).strip()\n        assert not tag.startswith(\"v\")\n        version = tag\n\n        # add .devNN if needed\n        log = check_output(\n            [\"git\", \"log\", \"%s..HEAD\" % tag, \"--oneline\"],\n            universal_newlines=True,\n        )\n        commits_since_tag = log.count(\"\\n\")\n        if commits_since_tag:\n            version += \".dev%i\" % commits_since_tag\n\n        # update tcod/version.py\n        open(\"tcod/version.py\", \"w\").write('__version__ = \"%s\"\\n' % version)\n        return version\n    except:\n        exec(open(\"tcod/version.py\").read(), globals())\n        return __version__"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting data files which will be included in the main tcod directory", "response": "def get_package_data():\n    \"\"\"get data files which will be included in the main tcod/ directory\"\"\"\n    BITSIZE, LINKAGE = platform.architecture()\n    files = [\n        \"py.typed\",\n        \"lib/LIBTCOD-CREDITS.txt\",\n        \"lib/LIBTCOD-LICENSE.txt\",\n        \"lib/README-SDL.txt\",\n    ]\n    if \"win32\" in sys.platform:\n        if BITSIZE == \"32bit\":\n            files += [\"x86/SDL2.dll\"]\n        else:\n            files += [\"x64/SDL2.dll\"]\n    if sys.platform == \"darwin\":\n        files += [\"SDL2.framework/Versions/A/SDL2\"]\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn this projects description.", "response": "def get_long_description():\n    \"\"\"Return this projects description.\"\"\"\n    with open(\"README.rst\", \"r\") as f:\n        readme = f.read()\n    with open(\"CHANGELOG.rst\", \"r\") as f:\n        changelog = f.read()\n        changelog = changelog.replace(\"\\nUnreleased\\n------------------\", \"\")\n    return \"\\n\".join([readme, changelog])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_height_rect(width: int, string: str) -> int:\n    string_ = string.encode(\"utf-8\")  # type: bytes\n    return int(lib.get_height_rect2(width, string_, len(string_)))", "response": "Return the number of lines which would be printed from these parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Console instance which wraps this TCOD_Console * object.", "response": "def _from_cdata(cls, cdata: Any, order: str = \"C\") -> \"Console\":\n        \"\"\"Return a Console instance which wraps this `TCOD_Console*` object.\n        \"\"\"\n        if isinstance(cdata, cls):\n            return cdata\n        self = object.__new__(cls)  # type: Console\n        self.console_c = cdata\n        self._init_setup_console_data(order)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a root console singleton with valid buffers.", "response": "def _get_root(cls, order: Optional[str] = None) -> \"Console\":\n        \"\"\"Return a root console singleton with valid buffers.\n\n        This function will also update an already active root console.\n        \"\"\"\n        global _root_console\n        if _root_console is None:\n            _root_console = object.__new__(cls)\n        self = _root_console  # type: Console\n        if order is not None:\n            self._order = order\n        self.console_c = ffi.NULL\n        self._init_setup_console_data(self._order)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_setup_console_data(self, order: str = \"C\") -> None:\n        global _root_console\n        self._key_color = None\n        if self.console_c == ffi.NULL:\n            _root_console = self\n            self._console_data = lib.TCOD_ctx.root\n        else:\n            self._console_data = ffi.cast(\n                \"struct TCOD_Console*\", self.console_c\n            )\n\n        self._tiles = np.frombuffer(\n            ffi.buffer(self._console_data.tiles[0 : self.width * self.height]),\n            dtype=self.DTYPE,\n        ).reshape((self.height, self.width))\n\n        self._order = tcod._internal.verify_order(order)", "response": "Setup numpy arrays over libtcod data buffers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tiles(self) -> np.array:\n        return self._tiles.T if self._order == \"F\" else self._tiles", "response": "An array of this consoles tile data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef default_fg(self) -> Tuple[int, int, int]:\n        color = self._console_data.fore\n        return color.r, color.g, color.b", "response": "The default foreground color."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising a warning for bad default values during a call to clear.", "response": "def __clear_warning(self, name: str, value: Tuple[int, int, int]) -> None:\n        \"\"\"Raise a warning for bad default values during calls to clear.\"\"\"\n        warnings.warn(\n            \"Clearing with the console default values is deprecated.\\n\"\n            \"Add %s=%r to this call.\" % (name, value),\n            DeprecationWarning,\n            stacklevel=3,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(  # type: ignore\n        self,\n        ch: int = ord(\" \"),\n        fg: Tuple[int, int, int] = ...,\n        bg: Tuple[int, int, int] = ...,\n    ) -> None:\n        \"\"\"Reset all values in this console to a single value.\n\n        `ch` is the character to clear the console with.  Defaults to the space\n        character.\n\n        `fg` and `bg` are the colors to clear the console with.  Defaults to\n        white-on-black if the console defaults are untouched.\n\n        .. note::\n            If `fg`/`bg` are not set, they will default to\n            :any:`default_fg`/:any:`default_bg`.\n            However, default values other than white-on-back are deprecated.\n\n        .. versionchanged:: 8.5\n            Added the `ch`, `fg`, and `bg` parameters.\n            Non-white-on-black default values are deprecated.\n        \"\"\"\n        if fg is ...:\n            fg = self.default_fg\n            if fg != (255, 255, 255):\n                self.__clear_warning(\"fg\", fg)\n        if bg is ...:\n            bg = self.default_bg\n            if bg != (0, 0, 0):\n                self.__clear_warning(\"bg\", bg)\n        self._tiles[...] = ch, (*fg, 255), (*bg, 255)", "response": "Clear all values in this console with a single value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_char(\n        self,\n        x: int,\n        y: int,\n        ch: int,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n    ) -> None:\n        \"\"\"Draw the character c at x,y using the default colors and a blend mode.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            ch (int): Character code to draw.  Must be in integer form.\n            bg_blend (int): Blending mode to use, defaults to BKGND_DEFAULT.\n        \"\"\"\n        lib.TCOD_console_put_char(self.console_c, x, y, ch, bg_blend)", "response": "Draw the character c at x y using the default colors and a blend mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __deprecate_defaults(\n        self,\n        new_func: str,\n        bg_blend: Any,\n        alignment: Any = ...,\n        clear: Any = ...,\n    ) -> None:\n        \"\"\"Return the parameters needed to recreate the current default state.\n        \"\"\"\n        if not __debug__:\n            return\n\n        fg = self.default_fg  # type: Any\n        bg = self.default_bg  # type: Any\n        if bg_blend == tcod.constants.BKGND_NONE:\n            bg = None\n        if bg_blend == tcod.constants.BKGND_DEFAULT:\n            bg_blend = self.default_bg_blend\n        else:\n            bg_blend = None\n        if bg_blend == tcod.constants.BKGND_NONE:\n            bg = None\n            bg_blend = None\n        if bg_blend == tcod.constants.BKGND_SET:\n            bg_blend = None\n        if alignment is None:\n            alignment = self.default_alignment\n            if alignment == tcod.constants.LEFT:\n                alignment = None\n        else:\n            alignment = None\n        if clear is not ...:\n            fg = None\n        params = []\n        if clear is True:\n            params.append('ch=ord(\" \")')\n        if clear is False:\n            params.append(\"ch=0\")\n        if fg is not None:\n            params.append(\"fg=%s\" % (fg,))\n        if bg is not None:\n            params.append(\"bg=%s\" % (bg,))\n        if bg_blend is not None:\n            params.append(\"bg_blend=%s\" % (self.__BG_BLEND_LOOKUP[bg_blend],))\n        if alignment is not None:\n            params.append(\n                \"alignment=%s\" % (self.__ALIGNMENT_LOOKUP[alignment],)\n            )\n        param_str = \", \".join(params)\n        if not param_str:\n            param_str = \".\"\n        else:\n            param_str = \" and add the following parameters:\\n%s\" % (param_str,)\n        warnings.warn(\n            \"Console functions using default values have been deprecated.\\n\"\n            \"Replace this method with `Console.%s`%s\" % (new_func, param_str),\n            DeprecationWarning,\n            stacklevel=3,\n        )", "response": "Deprecate the current state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a string on a console.", "response": "def print_(\n        self,\n        x: int,\n        y: int,\n        string: str,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n        alignment: Optional[int] = None,\n    ) -> None:\n        \"\"\"Print a color formatted string on a console.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            string (str): A Unicode string optionally using color codes.\n            bg_blend (int): Blending mode to use, defaults to BKGND_DEFAULT.\n            alignment (Optional[int]): Text alignment.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.print` instead, calling this function will print\n            a warning detailing which default values need to be made explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"print\", bg_blend, alignment)\n        alignment = self.default_alignment if alignment is None else alignment\n        lib.TCOD_console_printf_ex(\n            self.console_c, x, y, bg_blend, alignment, _fmt(string)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a string constrained to a rectangle.", "response": "def print_rect(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        string: str,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n        alignment: Optional[int] = None,\n    ) -> int:\n        \"\"\"Print a string constrained to a rectangle.\n\n        If h > 0 and the bottom of the rectangle is reached,\n        the string is truncated. If h = 0,\n        the string is only truncated if it reaches the bottom of the console.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            width (int): Maximum width to render the text.\n            height (int): Maximum lines to render the text.\n            string (str): A Unicode string.\n            bg_blend (int): Background blending flag.\n            alignment (Optional[int]): Alignment flag.\n\n        Returns:\n            int: The number of lines of text once word-wrapped.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.print_box` instead, calling this function will\n            print a warning detailing which default values need to be made\n            explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"print_box\", bg_blend, alignment)\n        alignment = self.default_alignment if alignment is None else alignment\n        return int(\n            lib.TCOD_console_printf_rect_ex(\n                self.console_c,\n                x,\n                y,\n                width,\n                height,\n                bg_blend,\n                alignment,\n                _fmt(string),\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_height_rect(\n        self, x: int, y: int, width: int, height: int, string: str\n    ) -> int:\n        \"\"\"Return the height of this text word-wrapped into this rectangle.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            width (int): Maximum width to render the text.\n            height (int): Maximum lines to render the text.\n            string (str): A Unicode string.\n\n        Returns:\n            int: The number of lines of text once word-wrapped.\n        \"\"\"\n        string_ = string.encode(\"utf-8\")\n        return int(\n            lib.get_height_rect(\n                self.console_c, x, y, width, height, string_, len(string_)\n            )\n        )", "response": "Return the height of this text word - wrapped into this rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rect(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        clear: bool,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n    ) -> None:\n        \"\"\"Draw a the background color on a rect optionally clearing the text.\n\n        If `clear` is True the affected tiles are changed to space character.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            width (int): Maximum width to render the text.\n            height (int): Maximum lines to render the text.\n            clear (bool): If True all text in the affected area will be\n                          removed.\n            bg_blend (int): Background blending flag.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.draw_rect` instead, calling this function will\n            print a warning detailing which default values need to be made\n            explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"draw_rect\", bg_blend, clear=bool(clear))\n        lib.TCOD_console_rect(\n            self.console_c, x, y, width, height, clear, bg_blend\n        )", "response": "Draw a background color on a rect."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hline(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n    ) -> None:\n        \"\"\"Draw a horizontal line on the console.\n\n        This always uses ord('\u2500'), the horizontal line character.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            width (int): The horizontal length of this line.\n            bg_blend (int): The background blending flag.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.draw_rect` instead, calling this function will\n            print a warning detailing which default values need to be made\n            explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"draw_rect\", bg_blend)\n        lib.TCOD_console_hline(self.console_c, x, y, width, bg_blend)", "response": "Draw a horizontal line on the console."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vline(\n        self,\n        x: int,\n        y: int,\n        height: int,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n    ) -> None:\n        \"\"\"Draw a vertical line on the console.\n\n        This always uses ord('\u2502'), the vertical line character.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            height (int): The horozontal length of this line.\n            bg_blend (int): The background blending flag.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.draw_rect` instead, calling this function will\n            print a warning detailing which default values need to be made\n            explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"draw_rect\", bg_blend)\n        lib.TCOD_console_vline(self.console_c, x, y, height, bg_blend)", "response": "Draw a vertical line on the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_frame(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        string: str = \"\",\n        clear: bool = True,\n        bg_blend: int = tcod.constants.BKGND_DEFAULT,\n    ) -> None:\n        \"\"\"Draw a framed rectangle with optional text.\n\n        This uses the default background color and blend mode to fill the\n        rectangle and the default foreground to draw the outline.\n\n        `string` will be printed on the inside of the rectangle, word-wrapped.\n        If `string` is empty then no title will be drawn.\n\n        Args:\n            x (int): The x coordinate from the left.\n            y (int): The y coordinate from the top.\n            width (int): The width if the frame.\n            height (int): The height of the frame.\n            string (str): A Unicode string to print.\n            clear (bool): If True all text in the affected area will be\n                          removed.\n            bg_blend (int): The background blending flag.\n\n        .. versionchanged:: 8.2\n            Now supports Unicode strings.\n\n        .. deprecated:: 8.5\n            Console methods which depend on console defaults have been\n            deprecated.\n            Use :any:`Console.draw_frame` instead, calling this function will\n            print a warning detailing which default values need to be made\n            explicit.\n        \"\"\"\n        self.__deprecate_defaults(\"draw_frame\", bg_blend)\n        string = _fmt(string) if string else ffi.NULL\n        lib.TCOD_console_printf_frame(\n            self.console_c, x, y, width, height, clear, bg_blend, string\n        )", "response": "Print a framed rectangle with optional text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef blit(\n        self,\n        dest: \"Console\",\n        dest_x: int = 0,\n        dest_y: int = 0,\n        src_x: int = 0,\n        src_y: int = 0,\n        width: int = 0,\n        height: int = 0,\n        fg_alpha: float = 1.0,\n        bg_alpha: float = 1.0,\n        key_color: Optional[Tuple[int, int, int]] = None,\n    ) -> None:\n        \"\"\"Blit from this console onto the ``dest`` console.\n\n        Args:\n            dest (Console): The destintaion console to blit onto.\n            dest_x (int): Leftmost coordinate of the destintaion console.\n            dest_y (int): Topmost coordinate of the destintaion console.\n            src_x (int): X coordinate from this console to blit, from the left.\n            src_y (int): Y coordinate from this console to blit, from the top.\n            width (int): The width of the region to blit.\n\n                If this is 0 the maximum possible width will be used.\n            height (int): The height of the region to blit.\n\n                If this is 0 the maximum possible height will be used.\n            fg_alpha (float): Foreground color alpha vaule.\n            bg_alpha (float): Background color alpha vaule.\n            key_color (Optional[Tuple[int, int, int]]):\n                None, or a (red, green, blue) tuple with values of 0-255.\n\n        .. versionchanged:: 4.0\n            Parameters were rearraged and made optional.\n\n            Previously they were:\n            `(x, y, width, height, dest, dest_x, dest_y, *)`\n        \"\"\"\n        # The old syntax is easy to detect and correct.\n        if hasattr(src_y, \"console_c\"):\n            (\n                src_x,  # type: ignore\n                src_y,\n                width,\n                height,\n                dest,  # type: ignore\n                dest_x,\n                dest_y,\n            ) = (dest, dest_x, dest_y, src_x, src_y, width, height)\n            warnings.warn(\n                \"Parameter names have been moved around, see documentation.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        key_color = key_color or self._key_color\n        if key_color:\n            key_color = ffi.new(\"TCOD_color_t*\", key_color)\n            lib.TCOD_console_blit_key_color(\n                self.console_c,\n                src_x,\n                src_y,\n                width,\n                height,\n                dest.console_c,\n                dest_x,\n                dest_y,\n                fg_alpha,\n                bg_alpha,\n                key_color,\n            )\n        else:\n            lib.TCOD_console_blit(\n                self.console_c,\n                src_x,\n                src_y,\n                width,\n                height,\n                dest.console_c,\n                dest_x,\n                dest_y,\n                fg_alpha,\n                bg_alpha,\n            )", "response": "Blits from this console onto the dest console."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a consoles blit transparent color.", "response": "def set_key_color(self, color: Optional[Tuple[int, int, int]]) -> None:\n        \"\"\"Set a consoles blit transparent color.\n\n        `color` is the (r, g, b) color, or None to disable key color.\n\n        .. deprecated:: 8.5\n            Pass the key color to :any:`Console.blit` instead of calling this\n            function.\n        \"\"\"\n        self._key_color = color"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print(\n        self,\n        x: int,\n        y: int,\n        string: str,\n        fg: Optional[Tuple[int, int, int]] = None,\n        bg: Optional[Tuple[int, int, int]] = None,\n        bg_blend: int = tcod.constants.BKGND_SET,\n        alignment: int = tcod.constants.LEFT,\n    ) -> None:\n        \"\"\"Print a string on a console with manual line breaks.\n\n        `x` and `y` are the starting tile, with ``0,0`` as the upper-left\n        corner of the console.  You can use negative numbers if you want to\n        start printing relative to the bottom-right corner, but this behavior\n        may change in future versions.\n\n        `string` is a Unicode string which may include color control\n        characters.  Strings which are too long will be truncated until the\n        next newline character ``\"\\\\n\"``.\n\n        `fg` and `bg` are the foreground text color and background tile color\n        respectfully.  This is a 3-item tuple with (r, g, b) color values from\n        0 to 255.  These parameters can also be set to `None` to leave the\n        colors unchanged.\n\n        `bg_blend` is the blend type used by libtcod.\n\n        `alignment` can be `tcod.LEFT`, `tcod.CENTER`, or `tcod.RIGHT`.\n\n        .. versionadded:: 8.5\n\n        .. versionchanged:: 9.0\n            `fg` and `bg` now default to `None` instead of white-on-black.\n        \"\"\"\n        x, y = self._pythonic_index(x, y)\n        string_ = string.encode(\"utf-8\")  # type: bytes\n        lib.console_print(\n            self.console_c,\n            x,\n            y,\n            string_,\n            len(string_),\n            (fg,) if fg is not None else ffi.NULL,\n            (bg,) if bg is not None else ffi.NULL,\n            bg_blend,\n            alignment,\n        )", "response": "Print a string on a console with manual line breaks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw a framed rectangle of the current console.", "response": "def draw_frame(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        title: str = \"\",\n        clear: bool = True,\n        fg: Optional[Tuple[int, int, int]] = None,\n        bg: Optional[Tuple[int, int, int]] = None,\n        bg_blend: int = tcod.constants.BKGND_SET,\n    ) -> None:\n        \"\"\"Draw a framed rectangle with an optional title.\n\n        `x` and `y` are the starting tile, with ``0,0`` as the upper-left\n        corner of the console.  You can use negative numbers if you want to\n        start printing relative to the bottom-right corner, but this behavior\n        may change in future versions.\n\n        `width` and `height` determine the size of the frame.\n\n        `title` is a Unicode string.\n\n        If `clear` is True than the region inside of the frame will be cleared.\n\n        `fg` and `bg` are the foreground text color and background tile color\n        respectfully.  This is a 3-item tuple with (r, g, b) color values from\n        0 to 255.  These parameters can also be set to `None` to leave the\n        colors unchanged.\n\n        `bg_blend` is the blend type used by libtcod.\n\n        .. versionadded:: 8.5\n\n        .. versionchanged:: 9.0\n            `fg` and `bg` now default to `None` instead of white-on-black.\n        \"\"\"\n        x, y = self._pythonic_index(x, y)\n        title_ = title.encode(\"utf-8\")  # type: bytes\n        lib.print_frame(\n            self.console_c,\n            x,\n            y,\n            width,\n            height,\n            title_,\n            len(title_),\n            (fg,) if fg is not None else ffi.NULL,\n            (bg,) if bg is not None else ffi.NULL,\n            bg_blend,\n            clear,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_rect(\n        self,\n        x: int,\n        y: int,\n        width: int,\n        height: int,\n        ch: int,\n        fg: Optional[Tuple[int, int, int]] = None,\n        bg: Optional[Tuple[int, int, int]] = None,\n        bg_blend: int = tcod.constants.BKGND_SET,\n    ) -> None:\n        \"\"\"Draw characters and colors over a rectangular region.\n\n        `x` and `y` are the starting tile, with ``0,0`` as the upper-left\n        corner of the console.  You can use negative numbers if you want to\n        start printing relative to the bottom-right corner, but this behavior\n        may change in future versions.\n\n        `width` and `height` determine the size of the rectangle.\n\n        `ch` is a Unicode integer.  You can use 0 to leave the current\n        characters unchanged.\n\n        `fg` and `bg` are the foreground text color and background tile color\n        respectfully.  This is a 3-item tuple with (r, g, b) color values from\n        0 to 255.  These parameters can also be set to `None` to leave the\n        colors unchanged.\n\n        `bg_blend` is the blend type used by libtcod.\n\n        .. versionadded:: 8.5\n\n        .. versionchanged:: 9.0\n            `fg` and `bg` now default to `None` instead of white-on-black.\n        \"\"\"\n        x, y = self._pythonic_index(x, y)\n        lib.draw_rect(\n            self.console_c,\n            x,\n            y,\n            width,\n            height,\n            ch,\n            (fg,) if fg is not None else ffi.NULL,\n            (bg,) if bg is not None else ffi.NULL,\n            bg_blend,\n        )", "response": "Draw the current color and characters of the current entry in the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sizeAdjust(self):\n        font_width, font_height = self.font_bbox[:2]\n        self.width = min(self.width, font_width)\n        self.height = min(self.height, font_height)\n        self.bbox[:2] = self.width, self.height\n\n        self.crop()", "response": "Adjust the size of the font to match the size of the glyph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blit(self, image, x, y):\n        # adjust the position with the local bbox\n        x += self.font_bbox[2] - self.bbox[2]\n        y += self.font_bbox[3] - self.bbox[3]\n        x += self.font_bbox[0] - self.bbox[0]\n        y += self.font_bbox[1] - self.bbox[1]\n        image[y:y+self.height, x:x+self.width] = self.bitmap * 255", "response": "blit to the image array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseBits(self, hexcode, width):\n        bitarray = []\n        for byte in hexcode[::-1]:\n            bits = int(byte, 16)\n            for x in range(4):\n                bitarray.append(bool((2 ** x) & bits))\n        bitarray = bitarray[::-1]\n        return enumerate(bitarray[:width])", "response": "enumerate over bits in a line of data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef memory_warning(config, context):\n    used = psutil.Process(os.getpid()).memory_info().rss / 1048576\n    limit = float(context.memory_limit_in_mb)\n    p = used / limit\n\n    memory_threshold = config.get('memory_warning_threshold')\n\n    if p >= memory_threshold:\n        config['raven_client'].captureMessage(\n            'Memory Usage Warning',\n            level='warning',\n            extra={\n                'MemoryLimitInMB': context.memory_limit_in_mb,\n                'MemoryUsedInMB': math.floor(used)\n            }\n        )\n    else:\n        # nothing to do check back later\n        Timer(.5, memory_warning, (config, context)).start()", "response": "Determines when memory usage is nearing it s max."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install_timers(config, context):\n    timers = []\n    if config.get('capture_timeout_warnings'):\n        timeout_threshold = config.get('timeout_warning_threshold')\n        # Schedule the warning at the user specified threshold given in percent.\n        # ie: 0.50 of 30000 ms = 15000ms\n        # Schedule the error a few milliseconds before the actual timeout happens.\n        time_remaining = context.get_remaining_time_in_millis() / 1000\n        timers.append(Timer(time_remaining * timeout_threshold, timeout_warning, (config, context)))\n        timers.append(Timer(max(time_remaining - .5, 0), timeout_error, [config]))\n\n    if config.get('capture_memory_warnings'):\n        # Schedule the memory watch dog interval. Warning will re-schedule itself if necessary.\n        timers.append(Timer(.5, memory_warning, (config, context)))\n\n    for t in timers:\n        t.start()\n\n    return timers", "response": "Create the timers as specified by the plugin configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, url, data, headers):\n        if not self.queue_url:\n            self.queue_url = self.sqs_client.get_queue_url(QueueName=self.sqs_name,\n                                                           QueueOwnerAWSAccountId=self.sqs_account)[\"QueueUrl\"]\n\n        payload = {\n            \"url\": url,\n            \"headers\": headers,\n            \"data\": base64.b64encode(data).decode(\"utf-8\")\n        }\n\n        try:\n            self.sqs_client.send_message(QueueUrl=self.queue_url,\n                                         MessageBody=json.dumps(payload))\n        except ClientError as e:\n            # TODO break circular dep for logging\n            print(data)  # not sure if this is the best way to get messages.\n            raise e", "response": "Sends a request to an SQS queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recurseforumcontents(parser, token):\n    bits = token.contents.split()\n    forums_contents_var = template.Variable(bits[1])\n\n    template_nodes = parser.parse(('endrecurseforumcontents',))\n    parser.delete_first_token()\n\n    return RecurseTreeForumVisibilityContentNode(template_nodes, forums_contents_var)", "response": "Renders the forums contents of the forums."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders the considered forum list.", "response": "def forum_list(context, forum_visibility_contents):\n    \"\"\" Renders the considered forum list.\n\n    This will render the given list of forums by respecting the order and the depth of each\n    forum in the forums tree.\n\n    Usage::\n\n        {% forum_list my_forums %}\n\n    \"\"\"\n    request = context.get('request')\n    tracking_handler = TrackingHandler(request=request)\n\n    data_dict = {\n        'forum_contents': forum_visibility_contents,\n        'unread_forums': tracking_handler.get_unread_forums_from_list(\n            request.user, forum_visibility_contents.forums),\n        'user': request.user,\n        'request': request,\n    }\n\n    root_level = forum_visibility_contents.root_level\n    if root_level is not None:\n        data_dict['root_level'] = root_level\n        data_dict['root_level_middle'] = root_level + 1\n        data_dict['root_level_sub'] = root_level + 2\n\n    return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the considered object.", "response": "def get_object(self, request, *args, **kwargs):\n        \"\"\" Handles the considered object. \"\"\"\n        forum_pk = kwargs.get('forum_pk', None)\n        descendants = kwargs.get('descendants', None)\n        self.user = request.user\n\n        if forum_pk:\n            forum = get_object_or_404(Forum, pk=forum_pk)\n            forums_qs = (\n                forum.get_descendants(include_self=True)\n                if descendants else Forum.objects.filter(pk=forum_pk)\n            )\n            self.forums = request.forum_permission_handler.get_readable_forums(\n                forums_qs, request.user,\n            )\n        else:\n            self.forums = request.forum_permission_handler.get_readable_forums(\n                Forum.objects.all(), request.user,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef items(self):\n        return Topic.objects.filter(forum__in=self.forums, approved=True).order_by('-last_post_on')", "response": "Returns the items to include into the feed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a link to a specific item of the feed.", "response": "def item_link(self, item):\n        \"\"\" Generates a link for a specific item of the feed. \"\"\"\n        return reverse_lazy(\n            'forum_conversation:topic',\n            kwargs={\n                'forum_slug': item.forum.slug,\n                'forum_pk': item.forum.pk,\n                'slug': item.slug,\n                'pk': item.id,\n            },\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef topic_pages_inline_list(topic):\n    data_dict = {\n        'topic': topic,\n    }\n\n    pages_number = ((topic.posts_count - 1) // machina_settings.TOPIC_POSTS_NUMBER_PER_PAGE) + 1\n    if pages_number > 5:\n        data_dict['first_pages'] = range(1, 5)\n        data_dict['last_page'] = pages_number\n    elif pages_number > 1:\n        data_dict['first_pages'] = range(1, pages_number + 1)\n\n    return data_dict", "response": "This will render an inline pagination for the posts related to the given topic."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of URLs associated with the admin abstraction.", "response": "def get_urls(self):\n        \"\"\" Returns the URLs associated with the admin abstraction. \"\"\"\n        urls = super().get_urls()\n        forum_admin_urls = [\n            url(\n                r'^(?P<forum_id>[0-9]+)/move-forum/(?P<direction>up|down)/$',\n                self.admin_site.admin_view(self.moveforum_view),\n                name='forum_forum_move',\n            ),\n            url(\n                r'^edit-global-permissions/$',\n                self.admin_site.admin_view(self.editpermissions_index_view),\n                name='forum_forum_editpermission_index',\n            ),\n            url(\n                r'^edit-global-permissions/user/(?P<user_id>[0-9]+)/$',\n                self.admin_site.admin_view(self.editpermissions_user_view),\n                name='forum_forum_editpermission_user',\n            ),\n            url(\n                r'^edit-global-permissions/user/anonymous/$',\n                self.admin_site.admin_view(self.editpermissions_anonymous_user_view),\n                name='forum_forum_editpermission_anonymous_user',\n            ),\n            url(\n                r'^edit-global-permissions/group/(?P<group_id>[0-9]+)/$',\n                self.admin_site.admin_view(self.editpermissions_group_view),\n                name='forum_forum_editpermission_group',\n            ),\n            url(\n                r'^(?P<forum_id>[0-9]+)/edit-permissions/$',\n                self.admin_site.admin_view(self.editpermissions_index_view),\n                name='forum_forum_editpermission_index',\n            ),\n            url(\n                r'^(?P<forum_id>[0-9]+)/edit-permissions/user/(?P<user_id>[0-9]+)/$',\n                self.admin_site.admin_view(self.editpermissions_user_view),\n                name='forum_forum_editpermission_user',\n            ),\n            url(\n                r'^(?P<forum_id>[0-9]+)/edit-permissions/user/anonymous/$',\n                self.admin_site.admin_view(self.editpermissions_anonymous_user_view),\n                name='forum_forum_editpermission_anonymous_user',\n            ),\n            url(\n                r'^(?P<forum_id>[0-9]+)/edit-permissions/group/(?P<group_id>[0-9]+)/$',\n                self.admin_site.admin_view(self.editpermissions_group_view),\n                name='forum_forum_editpermission_group',\n            ),\n        ]\n        return forum_admin_urls + urls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the context to provide to the template for permissions contents.", "response": "def get_forum_perms_base_context(self, request, obj=None):\n        \"\"\" Returns the context to provide to the template for permissions contents. \"\"\"\n        context = {\n            'adminform': {'model_admin': self},\n            'media': self.media,\n            'object': obj,\n            'app_label': self.model._meta.app_label,\n            'opts': self.model._meta,\n            'has_change_permission': self.has_change_permission(request, obj),\n        }\n        try:\n            context.update(self.admin_site.each_context(request))\n        except TypeError:  # pragma: no cover\n            # Django 1.7 compatibility\n            context.update(self.admin_site.each_context())\n        except AttributeError:  # pragma: no cover\n            pass\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef moveforum_view(self, request, forum_id, direction):\n        forum = get_object_or_404(Forum, pk=forum_id)\n\n        # Fetch the target\n        target, position = None, None\n        if direction == 'up':\n            target, position = forum.get_previous_sibling(), 'left'\n        elif direction == 'down':\n            target, position = forum.get_next_sibling(), 'right'\n\n        # Do the move\n        try:\n            assert target is not None\n            forum.move_to(target, position)\n        except (InvalidMove, AssertionError):\n            pass\n        self.message_user(request, _(\"'{}' forum successfully moved\").format(forum.name))\n        return HttpResponseRedirect(reverse('admin:forum_forum_changelist'))", "response": "Moves the given forum toward the requested direction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling the permissions edit view.", "response": "def editpermissions_index_view(self, request, forum_id=None):\n        \"\"\" Allows to select how to edit forum permissions.\n\n        The view displays a form to select a user or a group in order to edit its permissions for\n        the considered forum.\n\n        \"\"\"\n        forum = get_object_or_404(Forum, pk=forum_id) if forum_id \\\n            else None\n\n        # Set up the context\n        context = self.get_forum_perms_base_context(request, forum)\n        context['forum'] = forum\n        context['title'] = _('Forum permissions') if forum else _('Global forum permissions')\n\n        # Handles \"copy permission from\" form\n        permissions_copied = False\n        if forum and request.method == 'POST':\n            forum_form = PickForumForm(request.POST)\n            if forum_form.is_valid() and forum_form.cleaned_data['forum']:\n                self._copy_forum_permissions(forum_form.cleaned_data['forum'], forum)\n                self.message_user(request, _('Permissions successfully copied'))\n                permissions_copied = True\n            context['forum_form'] = forum_form\n        elif forum:\n            context['forum_form'] = PickForumForm()\n\n        # Handles user or group selection\n        if request.method == 'POST' and not permissions_copied:\n            user_form = PickUserForm(request.POST, admin_site=self.admin_site)\n            group_form = PickGroupForm(request.POST, admin_site=self.admin_site)\n\n            if user_form.is_valid() and group_form.is_valid():\n                user = user_form.cleaned_data.get('user', None) if user_form.cleaned_data else None\n                anonymous_user = (\n                    user_form.cleaned_data.get('anonymous_user', None)\n                    if user_form.cleaned_data else None\n                )\n                group = (\n                    group_form.cleaned_data.get('group', None)\n                    if group_form.cleaned_data else None\n                )\n\n                if not user and not anonymous_user and not group:\n                    user_form._errors[NON_FIELD_ERRORS] = user_form.error_class(\n                        [_('Choose either a user ID, a group ID or the anonymous user'), ])\n                elif user:\n                    # Redirect to user\n                    url_kwargs = (\n                        {'forum_id': forum.id, 'user_id': user.id}\n                        if forum else {'user_id': user.id}\n                    )\n                    return redirect(\n                        reverse('admin:forum_forum_editpermission_user', kwargs=url_kwargs),\n                    )\n                elif anonymous_user:\n                    # Redirect to anonymous user\n                    url_kwargs = {'forum_id': forum.id} if forum else {}\n                    return redirect(\n                        reverse(\n                            'admin:forum_forum_editpermission_anonymous_user',\n                            kwargs=url_kwargs,\n                        ),\n                    )\n                elif group:\n                    # Redirect to group\n                    url_kwargs = (\n                        {'forum_id': forum.id, 'group_id': group.id}\n                        if forum else {'group_id': group.id}\n                    )\n                    return redirect(\n                        reverse('admin:forum_forum_editpermission_group', kwargs=url_kwargs),\n                    )\n\n            context['user_errors'] = helpers.AdminErrorList(user_form, [])\n            context['group_errors'] = helpers.AdminErrorList(group_form, [])\n        else:\n            user_form = PickUserForm(admin_site=self.admin_site)\n            group_form = PickGroupForm(admin_site=self.admin_site)\n\n        context['user_form'] = user_form\n        context['group_form'] = group_form\n\n        return render(request, self.editpermissions_index_view_template_name, context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef editpermissions_user_view(self, request, user_id, forum_id=None):\n        user_model = get_user_model()\n        user = get_object_or_404(user_model, pk=user_id)\n        forum = get_object_or_404(Forum, pk=forum_id) if forum_id else None\n\n        # Set up the context\n        context = self.get_forum_perms_base_context(request, forum)\n        context['forum'] = forum\n        context['title'] = '{} - {}'.format(_('Forum permissions'), user)\n        context['form'] = self._get_permissions_form(\n            request, UserForumPermission, {'forum': forum, 'user': user},\n        )\n\n        return render(request, self.editpermissions_user_view_template_name, context)", "response": "Allows to edit user permissions for the considered forum."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef editpermissions_anonymous_user_view(self, request, forum_id=None):\n        forum = get_object_or_404(Forum, pk=forum_id) if forum_id else None\n\n        # Set up the context\n        context = self.get_forum_perms_base_context(request, forum)\n        context['forum'] = forum\n        context['title'] = '{} - {}'.format(_('Forum permissions'), _('Anonymous user'))\n        context['form'] = self._get_permissions_form(\n            request, UserForumPermission, {'forum': forum, 'anonymous_user': True},\n        )\n\n        return render(request, self.editpermissions_anonymous_user_view_template_name, context)", "response": "Allows to edit anonymous user permissions for the considered forum."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef editpermissions_group_view(self, request, group_id, forum_id=None):\n        group = get_object_or_404(Group, pk=group_id)\n        forum = get_object_or_404(Forum, pk=forum_id) if forum_id else None\n\n        # Set up the context\n        context = self.get_forum_perms_base_context(request, forum)\n        context['forum'] = forum\n        context['title'] = '{} - {}'.format(_('Forum permissions'), group)\n        context['form'] = self._get_permissions_form(\n            request, GroupForumPermission, {'forum': forum, 'group': group},\n        )\n\n        return render(request, self.editpermissions_group_view_template_name, context)", "response": "Allows to edit group permissions for the given considered forum."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_urlpatterns(self):\n        return [\n            path(\n                _('mark/forums/'),\n                self.mark_forums_read_view.as_view(),\n                name='mark_all_forums_read',\n            ),\n            path(\n                _('mark/forums/<int:pk>/'),\n                self.mark_forums_read_view.as_view(),\n                name='mark_subforums_read',\n            ),\n            path(\n                _('mark/forum/<int:pk>/topics/'),\n                self.mark_topics_read_view.as_view(),\n                name='mark_topics_read',\n            ),\n            path(\n                _('unread-topics/'),\n                self.unread_topics_view.as_view(),\n                name='unread_topics',\n            ),\n        ]", "response": "Returns the list of URL patterns managed by the considered factory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_form_count(self):\n        total_forms = super().total_form_count()\n        if not self.data and not self.files and self.initial_form_count() > 0:\n            total_forms -= self.extra\n        return total_forms", "response": "This rewrite of total_form_count allows to add an empty form to the formset only when no initial data is provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_classes(module_label, classnames):\n    app_label = module_label.split('.')[0]\n\n    app_module_path = _get_app_module_path(module_label)\n    if not app_module_path:\n        raise AppNotFoundError('No app found matching \\'{}\\''.format(module_label))\n\n    # Determines the full module path by appending the module label\n    # to the base package path of the considered application.\n    module_path = app_module_path\n    if '.' in app_module_path:\n        base_package = app_module_path.rsplit('.' + app_label, 1)[0]\n        module_path = '{}.{}'.format(base_package, module_label)\n\n    # Try to import this module from the related app that is specified\n    # in the Django settings.\n    local_imported_module = _import_module(module_path, classnames)\n\n    # If the module we tried to import is not located inside the machina\n    # vanilla apps, try to import it from the corresponding machina app.\n    machina_imported_module = None\n    if not app_module_path.startswith('machina.apps'):\n        machina_imported_module = _import_module(\n            '{}.{}'.format('machina.apps', module_label), classnames,\n        )\n\n    if local_imported_module is None and machina_imported_module is None:\n        raise AppNotFoundError('Error importing \\'{}\\''.format(module_path))\n\n    # Any local module is prioritized over the corresponding machina module\n    imported_modules = [\n        m for m in (local_imported_module, machina_imported_module) if m is not None\n    ]\n    return _pick_up_classes(imported_modules, classnames)", "response": "Imports a set of classes from a given module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to import the given Python module path and returns the module object.", "response": "def _import_module(module_path, classnames):\n    \"\"\" Tries to import the given Python module path. \"\"\"\n    try:\n        imported_module = __import__(module_path, fromlist=classnames)\n        return imported_module\n    except ImportError:\n        # In case of an ImportError, the module being loaded generally does not exist. But an\n        # ImportError can occur if the module being loaded exists and another import located inside\n        # it failed.\n        #\n        # In order to provide a meaningfull traceback, the execution information can be inspected in\n        # order to determine which case to consider. If the execution information provides more than\n        # a certain amount of frames, this means that an ImportError occured while loading the\n        # initial Python module.\n        __, __, exc_traceback = sys.exc_info()\n        frames = traceback.extract_tb(exc_traceback)\n        if len(frames) > 1:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pick_up_classes(modules, classnames):\n    klasses = []\n    for classname in classnames:\n        klass = None\n        for module in modules:\n            if hasattr(module, classname):\n                klass = getattr(module, classname)\n                break\n        if not klass:\n            raise ClassNotFoundError('Error fetching \\'{}\\' in {}'.format(\n                classname, str([module.__name__ for module in modules]))\n            )\n        klasses.append(klass)\n    return klasses", "response": "Given a list of class names to retrieve try to fetch them from the specified modules and returns the list of the fetched classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a module label return the module path of the application that is associated with that module label.", "response": "def _get_app_module_path(module_label):\n    \"\"\" Given a module label, loop over the apps specified in the INSTALLED_APPS to find the\n        corresponding application module path.\n    \"\"\"\n    app_name = module_label.rsplit('.', 1)[0]\n    for app in settings.INSTALLED_APPS:\n        if app.endswith('.' + app_name) or app == app_name:\n            return app\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_unread_forums(self, user):\n        return self.get_unread_forums_from_list(\n            user, self.perm_handler.get_readable_forums(Forum.objects.all(), user))", "response": "Returns the list of unread forums for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_unread_forums_from_list(self, user, forums):\n        unread_forums = []\n\n        # A user which is not authenticated will never see a forum as unread\n        if not user.is_authenticated:\n            return unread_forums\n\n        unread = ForumReadTrack.objects.get_unread_forums_from_list(forums, user)\n        unread_forums.extend(unread)\n\n        return unread_forums", "response": "Returns the list of unread forums for the given user from a given list of forums."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_unread_topics(self, topics, user):\n        unread_topics = []\n\n        # A user which is not authenticated will never see a topic as unread.\n        # If there are no topics to consider, we stop here.\n        if not user.is_authenticated or topics is None or not len(topics):\n            return unread_topics\n\n        # A topic can be unread if a track for itself exists with a mark time that\n        # is less important than its update date.\n        topic_ids = [topic.id for topic in topics]\n        topic_tracks = TopicReadTrack.objects.filter(topic__in=topic_ids, user=user)\n        tracked_topics = dict(topic_tracks.values_list('topic__pk', 'mark_time'))\n\n        if tracked_topics:\n            for topic in topics:\n                topic_last_modification_date = topic.last_post_on or topic.created\n                if (\n                    topic.id in tracked_topics.keys() and\n                    topic_last_modification_date > tracked_topics[topic.id]\n                ):\n                    unread_topics.append(topic)\n\n        # A topic can be unread if a track for its associated forum exists with\n        # a mark time that is less important than its creation or update date.\n        forum_ids = [topic.forum_id for topic in topics]\n        forum_tracks = ForumReadTrack.objects.filter(forum_id__in=forum_ids, user=user)\n        tracked_forums = dict(forum_tracks.values_list('forum__pk', 'mark_time'))\n\n        if tracked_forums:\n            for topic in topics:\n                topic_last_modification_date = topic.last_post_on or topic.created\n                if (\n                    (topic.forum_id in tracked_forums.keys() and topic.id not in tracked_topics) and\n                    topic_last_modification_date > tracked_forums[topic.forum_id]\n                ):\n                    unread_topics.append(topic)\n\n        # A topic can be unread if no tracks exists for it\n        for topic in topics:\n            if topic.forum_id not in tracked_forums and topic.id not in tracked_topics:\n                unread_topics.append(topic)\n\n        return list(set(unread_topics))", "response": "Returns a list of unread topics for the given user from a given set of topics."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmarking a list of forums as read.", "response": "def mark_forums_read(self, forums, user):\n        \"\"\" Marks a list of forums as read. \"\"\"\n        if not forums or not user.is_authenticated:\n            return\n\n        forums = sorted(forums, key=lambda f: f.level)\n\n        # Update all forum tracks to the current date for the considered forums\n        for forum in forums:\n            forum_track = ForumReadTrack.objects.get_or_create(forum=forum, user=user)[0]\n            forum_track.save()\n        # Delete all the unnecessary topic tracks\n        TopicReadTrack.objects.filter(topic__forum__in=forums, user=user).delete()\n        # Update parent forum tracks\n        self._update_parent_forum_tracks(forums[0], user)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mark_topic_read(self, topic, user):\n        if not user.is_authenticated:\n            return\n\n        forum = topic.forum\n        try:\n            forum_track = ForumReadTrack.objects.get(forum=forum, user=user)\n        except ForumReadTrack.DoesNotExist:\n            forum_track = None\n\n        if (\n            forum_track is None or\n            (topic.last_post_on and forum_track.mark_time < topic.last_post_on)\n        ):\n            topic_track, created = TopicReadTrack.objects.get_or_create(topic=topic, user=user)\n            if not created:\n                topic_track.save()  # mark_time filled\n\n            # If no other topic is unread inside the considered forum, the latter should also be\n            # marked as read.\n            unread_topics = (\n                forum.topics\n                .filter(\n                    Q(tracks__user=user, tracks__mark_time__lt=F('last_post_on')) |\n                    Q(\n                        forum__tracks__user=user, forum__tracks__mark_time__lt=F('last_post_on'),\n                        tracks__isnull=True,\n                    )\n                )\n                .exclude(id=topic.id)\n            )\n\n            forum_topic_tracks = TopicReadTrack.objects.filter(topic__forum=forum, user=user)\n            if (\n                not unread_topics.exists() and\n                (\n                    forum_track is not None or\n                    forum_topic_tracks.count() == forum.topics.filter(approved=True).count()\n                )\n            ):\n                # The topics that are marked as read inside the forum for the given user will be\n                # deleted while the forum track associated with the user must be created or updated.\n                # This is done only if there are as many topic tracks as approved topics in case\n                # the related forum has not beem previously marked as read.\n                TopicReadTrack.objects.filter(topic__forum=forum, user=user).delete()\n                forum_track, _ = ForumReadTrack.objects.get_or_create(forum=forum, user=user)\n                forum_track.save()\n\n                # Update parent forum tracks\n                self._update_parent_forum_tracks(forum, user)", "response": "Mark a topic as read."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urlpatterns(self):\n        return [\n            path(\n                _('profile/edit/'),\n                self.forum_profile_update_view.as_view(),\n                name='profile_update',\n            ),\n            path(\n                _('profile/<str:pk>/'),\n                self.forum_profile_detail_view.as_view(),\n                name='profile',\n            ),\n            path(\n                _('profile/<str:pk>/posts/'),\n                self.user_posts_list.as_view(),\n                name='user_posts',\n            ),\n            path(\n                _('subscriptions/'),\n                self.topic_subscription_list_view.as_view(),\n                name='user_subscriptions',\n            ),\n            path(\n                _('topic/<int:pk>/subscribe/'),\n                self.topic_subscribe_view.as_view(),\n                name='topic_subscribe',\n            ),\n            path(\n                _('topic/<int:pk>/unsubscribe/'),\n                self.topic_unsubscribe_view.as_view(),\n                name='topic_unsubscribe',\n            ),\n        ]", "response": "Returns the list of URL patterns managed by the considered factory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassign a permission to a user or group.", "response": "def assign_perm(perm, user_or_group, forum=None, has_perm=True):\n    \"\"\" Assigns a permission to a user (anonymous or not) or a group. \"\"\"\n    user, group = get_identity(user_or_group)\n    perm = ForumPermission.objects.get(codename=perm)\n    if user:\n        return UserForumPermission.objects.create(\n            forum=forum,\n            permission=perm,\n            user=user if not user.is_anonymous else None,\n            anonymous_user=user.is_anonymous,\n            has_perm=has_perm,\n        )\n    if group:\n        return GroupForumPermission.objects.create(\n            forum=forum, permission=perm, group=group, has_perm=has_perm,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a permission to a user or a group.", "response": "def remove_perm(perm, user_or_group, forum=None):\n    \"\"\" Remove a permission to a user (anonymous or not) or a group. \"\"\"\n    user, group = get_identity(user_or_group)\n    perm = ForumPermission.objects.get(codename=perm)\n    if user:\n        UserForumPermission.objects.filter(\n            forum=forum,\n            permission=perm,\n            user=user if not user.is_anonymous else None,\n            anonymous_user=user.is_anonymous,\n        ).delete()\n    if group:\n        GroupForumPermission.objects.filter(forum=forum, permission=perm, group=group).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple depending on the identity.", "response": "def get_identity(identity):\n    \"\"\" Returns a (user_obj, None) tuple or a (None, group_obj) tuple depending on the considered\n        instance.\n    \"\"\"\n    if isinstance(identity, AnonymousUser):\n        return identity, None\n\n    if isinstance(identity, get_user_model()):\n        return identity, None\n    elif isinstance(identity, Group):\n        return None, identity\n    else:  # pragma: no cover\n        raise NotUserNorGroup(\n            'User/AnonymousUser or Group instance is required '\n            '(got {})'.format(identity),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean(self):\n        super().clean()\n\n        if self.parent and self.parent.is_link:\n            raise ValidationError(_('A forum can not have a link forum as parent'))\n\n        if self.is_category and self.parent and self.parent.is_category:\n            raise ValidationError(_('A category can not have another category as parent'))\n\n        if self.is_link and not self.link:\n            raise ValidationError(_('A link forum must have a link associated with it'))", "response": "Validates the forum instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_image_upload_to(self, filename):\n        dummy, ext = os.path.splitext(filename)\n        return os.path.join(\n            machina_settings.FORUM_IMAGE_UPLOAD_TO,\n            '{id}{ext}'.format(id=str(uuid.uuid4()).replace('-', ''), ext=ext),\n        )", "response": "Returns the path to upload a new associated image to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the forum instance.", "response": "def save(self, *args, **kwargs):\n        \"\"\" Saves the forum instance. \"\"\"\n        # It is vital to track the changes of the parent associated with a forum in order to\n        # maintain counters up-to-date and to trigger other operations such as permissions updates.\n        old_instance = None\n        if self.pk:\n            old_instance = self.__class__._default_manager.get(pk=self.pk)\n\n        # Update the slug field\n        self.slug = slugify(force_text(self.name), allow_unicode=True)\n\n        # Do the save\n        super().save(*args, **kwargs)\n\n        # If any change has been made to the forum parent, trigger the update of the counters\n        if old_instance and old_instance.parent != self.parent:\n            self.update_trackers()\n            # Trigger the 'forum_moved' signal\n            signals.forum_moved.send(sender=self, previous_parent=old_instance.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the denormalized trackers associated with the forum instance.", "response": "def update_trackers(self):\n        \"\"\" Updates the denormalized trackers associated with the forum instance. \"\"\"\n        direct_approved_topics = self.topics.filter(approved=True).order_by('-last_post_on')\n\n        # Compute the direct topics count and the direct posts count.\n        self.direct_topics_count = direct_approved_topics.count()\n        self.direct_posts_count = direct_approved_topics.aggregate(\n            total_posts_count=Sum('posts_count'))['total_posts_count'] or 0\n\n        # Forces the forum's 'last_post' ID and 'last_post_on' date to the corresponding values\n        # associated with the topic with the latest post.\n        if direct_approved_topics.exists():\n            self.last_post_id = direct_approved_topics[0].last_post_id\n            self.last_post_on = direct_approved_topics[0].last_post_on\n        else:\n            self.last_post_id = None\n            self.last_post_on = None\n\n        # Any save of a forum triggered from the update_tracker process will not result in checking\n        # for a change of the forum's parent.\n        self._simple_save()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of URL patterns managed by the considered factory / application.", "response": "def get_urlpatterns(self):\n        \"\"\" Returns the URL patterns managed by the considered factory / application. \"\"\"\n        return [\n            url(r'', include(self.forum_urlpatterns_factory.urlpatterns)),\n            url(r'', include(self.conversation_urlpatterns_factory.urlpatterns)),\n            url(_(r'^feeds/'), include(self.feeds_urlpatterns_factory.urlpatterns)),\n            url(_(r'^member/'), include(self.member_urlpatterns_factory.urlpatterns)),\n            url(_(r'^moderation/'), include(self.moderation_urlpatterns_factory.urlpatterns)),\n            url(_(r'^search/'), include(self.search_urlpatterns_factory.urlpatterns)),\n            url(_(r'^tracking/'), include(self.tracking_urlpatterns_factory.urlpatterns)),\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_unread_topics(context, topics, user):\n    request = context.get('request', None)\n    return TrackingHandler(request=request).get_unread_topics(topics, user)", "response": "This will return a list of unread topics for the given user from a given set of topics."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resize_image(self, data, size):\n        from machina.core.compat import PILImage as Image\n        image = Image.open(BytesIO(data))\n\n        # Resize!\n        image.thumbnail(size, Image.ANTIALIAS)\n\n        string = BytesIO()\n        image.save(string, format='PNG')\n        return string.getvalue()", "response": "Resizes the given image to fit inside a box of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_backend(self):\n        try:\n            cache = caches[machina_settings.ATTACHMENT_CACHE_NAME]\n        except InvalidCacheBackendError:\n            raise ImproperlyConfigured(\n                'The attachment cache backend ({}) is not configured'.format(\n                    machina_settings.ATTACHMENT_CACHE_NAME,\n                ),\n            )\n        return cache", "response": "Returns the associated cache backend."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstoring the state of each file embedded in the request. FILES MultiValueDict instance.", "response": "def set(self, key, files):\n        \"\"\" Stores the state of each file embedded in the request.FILES MultiValueDict instance.\n\n        This instance is assumed to be passed as the 'files' argument. Each state stored in the\n        cache is a dictionary containing the following values:\n\n            name\n                The name of the uploaded file.\n            size\n                The size of the uploaded file.\n            content_type\n                The content type of the uploaded file.\n            content_length\n                The content length of the uploaded file.\n            charset\n                The charset of the uploaded file.\n            content\n                The content of the uploaded file.\n\n        \"\"\"\n        files_states = {}\n\n        for name, upload in files.items():\n            # Generates the state of the file\n            state = {\n                'name': upload.name,\n                'size': upload.size,\n                'content_type': upload.content_type,\n                'charset': upload.charset,\n                'content': upload.file.read(),\n            }\n            files_states[name] = state\n\n            # Go to the first byte in the file for future use\n            upload.file.seek(0)\n        self.backend.set(key, files_states)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregenerating a MultiValueDict instance containing the files related to all file states stored for the given key.", "response": "def get(self, key):\n        \"\"\" Regenerates a MultiValueDict instance containing the files related to all file states\n            stored for the given key.\n        \"\"\"\n        upload = None\n        files_states = self.backend.get(key)\n        files = MultiValueDict()\n        if files_states:\n            for name, state in files_states.items():\n                f = BytesIO()\n                f.write(state['content'])\n\n                # If the post is too large, we cannot use a\n                # InMemoryUploadedFile instance.\n                if state['size'] > settings.FILE_UPLOAD_MAX_MEMORY_SIZE:\n                    upload = TemporaryUploadedFile(\n                        state['name'],\n                        state['content_type'],\n                        state['size'],\n                        state['charset'],\n                    )\n                    upload.file = f\n                else:\n                    f = BytesIO()\n                    f.write(state['content'])\n                    upload = InMemoryUploadedFile(\n                        file=f,\n                        field_name=name,\n                        name=state['name'],\n                        content_type=state['content_type'],\n                        size=state['size'],\n                        charset=state['charset'],\n                    )\n                files[name] = upload\n\n                # Go to the first byte in the file for future use\n                upload.file.seek(0)\n\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters the given queryset in order to return a list of forums that can be seen and read by the specified user.", "response": "def forum_list_filter(self, qs, user):\n        \"\"\" Filters the given queryset in order to return a list of forums that can be seen and read\n            by the specified user (at least).\n        \"\"\"\n        # Any superuser should see all the forums\n        if user.is_superuser:\n            return qs\n\n        # Check whether the forums can be viewed by the given user\n        forums_to_hide = self._get_hidden_forum_ids(qs, user)\n\n        return qs.exclude(id__in=forums_to_hide)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a queryset of forums that can be read by the given user.", "response": "def get_readable_forums(self, forums, user):\n        \"\"\" Returns a queryset of forums that can be read by the considered user. \"\"\"\n        # Any superuser should be able to read all the forums.\n        if user.is_superuser:\n            return forums\n\n        # Fetches the forums that can be read by the given user.\n        readable_forums = self._get_forums_for_user(\n            user, ['can_read_forum', ], use_tree_hierarchy=True)\n        return forums.filter(id__in=[f.id for f in readable_forums]) \\\n            if isinstance(forums, (models.Manager, models.QuerySet)) \\\n            else list(filter(lambda f: f in readable_forums, forums))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether the user can add posts to a topic.", "response": "def can_add_post(self, topic, user):\n        \"\"\" Given a topic, checks whether the user can append posts to it. \"\"\"\n        can_add_post = self._perform_basic_permission_check(\n            topic.forum, user, 'can_reply_to_topics',\n        )\n        can_add_post &= (\n            not topic.is_locked or\n            self._perform_basic_permission_check(topic.forum, user, 'can_reply_to_locked_topics')\n        )\n        return can_add_post"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can_edit_post(self, post, user):\n        checker = self._get_checker(user)\n\n        # A user can edit a post if...\n        #     they are a superuser\n        #     they are the original poster of the forum post\n        #     they belong to the forum moderators\n        is_author = self._is_post_author(post, user)\n        can_edit = (\n            user.is_superuser or\n            (\n                is_author and checker.has_perm('can_edit_own_posts', post.topic.forum) and\n                not post.topic.is_locked\n            ) or\n            checker.has_perm('can_edit_posts', post.topic.forum)\n        )\n        return can_edit", "response": "Checks whether the user can edit the latter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the user can delete the latter.", "response": "def can_delete_post(self, post, user):\n        \"\"\"\n        Given a forum post, checks whether the user can delete the latter.\n        \"\"\"\n        checker = self._get_checker(user)\n\n        # A user can delete a post if...\n        #     they are a superuser\n        #     they are the original poster of the forum post\n        #     they belong to the forum moderators\n        is_author = self._is_post_author(post, user)\n        can_delete = (\n            user.is_superuser or\n            (is_author and checker.has_perm('can_delete_own_posts', post.topic.forum)) or\n            checker.has_perm('can_delete_posts', post.topic.forum)\n        )\n        return can_delete"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether the user can answer to a poll.", "response": "def can_vote_in_poll(self, poll, user):\n        \"\"\" Given a poll, checks whether the user can answer to it. \"\"\"\n        # First we have to check if the poll is curently open\n        if poll.duration:\n            poll_dtend = poll.created + dt.timedelta(days=poll.duration)\n            if poll_dtend < now():\n                return False\n\n        # Is this user allowed to vote in polls in the current forum?\n        can_vote = (\n            self._perform_basic_permission_check(poll.topic.forum, user, 'can_vote_in_polls') and\n            not poll.topic.is_locked\n        )\n\n        # Retrieve the user votes for the considered poll\n        user_votes = TopicPollVote.objects.filter(poll_option__poll=poll)\n        if user.is_anonymous:\n            forum_key = get_anonymous_user_forum_key(user)\n            if forum_key:\n                user_votes = user_votes.filter(anonymous_key=forum_key)\n            else:\n                # If the forum key of the anonymous user cannot be retrieved, the user should not be\n                # allowed to vote in the considered poll.\n                user_votes = user_votes.none()\n                can_vote = False\n        else:\n            user_votes = user_votes.filter(voter=user)\n\n        # If the user has already voted, they can vote again if the vote changes are allowed\n        if user_votes.exists() and can_vote:\n            can_vote = poll.user_changes\n\n        return can_vote"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether the user can add the topic to its subscription list.", "response": "def can_subscribe_to_topic(self, topic, user):\n        \"\"\" Given a topic, checks whether the user can add it to their subscription list. \"\"\"\n        # A user can subscribe to topics if they are authenticated and if they have the permission\n        # to read the related forum. Of course a user can subscribe only if they have not already\n        # subscribed to the considered topic.\n        return (\n            user.is_authenticated and\n            not topic.has_subscriber(user) and\n            self._perform_basic_permission_check(topic.forum, user, 'can_read_forum')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether the user can remove a topic from its subscription list.", "response": "def can_unsubscribe_from_topic(self, topic, user):\n        \"\"\" Given a topic, checks whether the user can remove it from their subscription list. \"\"\"\n        # A user can unsubscribe from topics if they are authenticated and if they have the\n        # permission to read the related forum. Of course a user can unsubscribe only if they are\n        #  already a subscriber of the considered topic.\n        return (\n            user.is_authenticated and\n            topic.has_subscriber(user) and\n            self._perform_basic_permission_check(topic.forum, user, 'can_read_forum')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_target_forums_for_moved_topics(self, user):\n        return [f for f in self._get_forums_for_user(user, ['can_move_topics', ]) if f.is_forum]", "response": "Returns a list of forums in which the considered user can add topics that have been\n            moved from another forum."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef can_update_topics_to_sticky_topics(self, forum, user):\n        return (\n            self._perform_basic_permission_check(forum, user, 'can_edit_posts') and\n            self._perform_basic_permission_check(forum, user, 'can_post_stickies')\n        )", "response": "Given a forum checks whether the user can change its topic types to sticky topics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a forum checks whether the user can change its topic types to announces.", "response": "def can_update_topics_to_announces(self, forum, user):\n        \"\"\" Given a forum, checks whether the user can change its topic types to announces. \"\"\"\n        return (\n            self._perform_basic_permission_check(forum, user, 'can_edit_posts') and\n            self._perform_basic_permission_check(forum, user, 'can_post_announcements')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_hidden_forum_ids(self, forums, user):\n        visible_forums = self._get_forums_for_user(\n            user, ['can_see_forum', 'can_read_forum', ], use_tree_hierarchy=True,\n        )\n        return forums.exclude(id__in=[f.id for f in visible_forums])", "response": "Given a set of forums and a user returns the list of forums that are not visible by the given user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all the forums that satisfy the given list of permission codenames.", "response": "def _get_forums_for_user(self, user, perm_codenames, use_tree_hierarchy=False):\n        \"\"\" Returns all the forums that satisfy the given list of permission codenames.\n\n        User and group forum permissions are used.\n\n        If the ``use_tree_hierarchy`` keyword argument is set the granted forums will be filtered so\n        that a forum which has an ancestor which is not in the granted forums set will not be\n        returned.\n        \"\"\"\n        granted_forums_cache_key = '{}__{}'.format(\n            ':'.join(perm_codenames), user.id if not user.is_anonymous else 'anonymous',\n        )\n\n        if granted_forums_cache_key in self._granted_forums_cache:\n            return self._granted_forums_cache[granted_forums_cache_key]\n\n        forums = self._get_all_forums()\n\n        # First check if the user is a superuser and if so, returns the forum queryset immediately.\n        if user.is_superuser:  # pragma: no cover\n            forum_objects = forums\n\n        else:\n            # Generates the appropriate queryset filter in order to handle both authenticated users\n            # and anonymous users.\n            user_kwargs_filter = {'anonymous_user': True} if user.is_anonymous else {'user': user}\n\n            # Get all the user permissions for the considered user.\n            user_perms = (\n                UserForumPermission.objects\n                .filter(**user_kwargs_filter)\n                .filter(permission__codename__in=perm_codenames)\n            )\n\n            # The first thing to do is to compute three lists of permissions: one containing only\n            # globally granted permissions, one containing granted permissions (these permissions\n            # are associated with specific forums) and one containing non granted permissions (the\n            # latest are also associated with specific forums).\n            globally_granted_user_perms = list(\n                filter(lambda p: p.has_perm and p.forum_id is None, user_perms)\n            )\n            per_forum_granted_user_perms = list(\n                filter(lambda p: p.has_perm and p.forum_id is not None, user_perms)\n            )\n            per_forum_nongranted_user_perms = list(\n                filter(lambda p: not p.has_perm and p.forum_id is not None, user_perms)\n            )\n\n            # Using the previous lists we are able to compute a list of forums ids for which\n            # permissions are explicitly not granted. It should be noted that any permission that is\n            # explicitely set for a user will not be considered as non granted if a \"non granted\"\n            # permission also exists. The explicitly granted permissions always win precedence.\n            granted_user_forum_ids = [p.forum_id for p in per_forum_granted_user_perms]\n            nongranted_forum_ids = [\n                p.forum_id for p in per_forum_nongranted_user_perms\n                if p.forum_id not in granted_user_forum_ids\n            ]\n\n            required_perm_codenames_count = len(perm_codenames)\n            initial_forum_ids = [f.id for f in forums]\n\n            # Now we build a dictionary allowing to associate each forum ID of the initial queryset\n            # with a set of permissions that are granted for the considered forum.\n            granted_permissions_per_forum = collections.defaultdict(set)\n            for perm in per_forum_granted_user_perms:\n                granted_permissions_per_forum[perm.forum_id].add(perm.permission_id)\n            for forum_id in initial_forum_ids:\n                granted_permissions_per_forum[forum_id].update(\n                    [perm.permission_id for perm in globally_granted_user_perms]\n                )\n\n            if not user.is_anonymous:\n                user_model = get_user_model()\n\n                # Get all the group permissions for the considered user.\n                group_perms = (\n                    GroupForumPermission.objects\n                    .filter(\n                        **{\n                            'group__{0}'.format(user_model.groups.field.related_query_name()): user\n                        }\n                    )\n                    .filter(permission__codename__in=perm_codenames)\n                )\n\n                # Again, we compute three lists of permissions. But this time we are considering\n                # group permissions. The first list contains only globally granted permissions. The\n                # second one contains only granted permissions that are associated with specific\n                # forums. The third list contains non granted permissions.\n                globally_granted_group_perms = list(\n                    filter(lambda p: p.has_perm and p.forum_id is None, group_perms)\n                )\n                per_forum_granted_group_perms = list(\n                    filter(lambda p: p.has_perm and p.forum_id is not None, group_perms)\n                )\n                per_forum_nongranted_group_perms = list(\n                    filter(lambda p: not p.has_perm and p.forum_id is not None, group_perms)\n                )\n\n                # Now we can update the list of forums ids for which permissions are explicitly not\n                # granted.\n                granted_group_forum_ids = [p.forum_id for p in per_forum_granted_group_perms]\n                nongranted_forum_ids += [\n                    p.forum_id for p in per_forum_nongranted_group_perms\n                    if p.forum_id not in granted_group_forum_ids\n                ]\n\n                # Now we will update our previous dictionary that associated each forum ID with a\n                # set of granted permissions (at the user level). We will update it with the new\n                # permissions we've computed for the user's groups.\n                for perm in per_forum_granted_group_perms:\n                    granted_permissions_per_forum[perm.forum_id].add(perm.permission_id)\n                for forum_id in initial_forum_ids:\n                    granted_permissions_per_forum[forum_id].update(\n                        [perm.permission_id for perm in globally_granted_group_perms]\n                    )\n\n            # We keep only the forum IDs for which the length of the set containing the granted\n            # permissions is equal to the number of initial permission codenames. The other forums\n            # have not all the required granted permissions, so we just throw them away.\n            for forum_id in list(granted_permissions_per_forum):\n                if len(granted_permissions_per_forum[forum_id]) < required_perm_codenames_count:\n                    del granted_permissions_per_forum[forum_id]\n\n            # Alright! It is now possible to filter the initial queryset using the forums associated\n            # with the granted permissions and the list of forums for which permissions are\n            # explicitly not granted.\n            forum_objects = [\n                f for f in forums\n                if f.id in granted_permissions_per_forum and f.id not in nongranted_forum_ids\n            ]\n\n            if (\n                not user.is_anonymous and\n                set(perm_codenames).issubset(\n                    set(machina_settings.DEFAULT_AUTHENTICATED_USER_FORUM_PERMISSIONS)\n                )\n            ):\n                forum_objects += [\n                    f for f in forums if f.id not in nongranted_forum_ids and f not in forum_objects\n                ]\n\n            if use_tree_hierarchy:\n                forum_objects = self._filter_granted_forums_using_tree(forum_objects)\n\n        self._granted_forums_cache[granted_forums_cache_key] = forum_objects\n        return forum_objects"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _perform_basic_permission_check(self, forum, user, permission):\n        checker = self._get_checker(user)\n\n        # The action is granted if...\n        #     the user is the superuser\n        #     the user has the permission to do so\n        check = (user.is_superuser or checker.has_perm(permission, forum))\n        return check", "response": "Perform a basic permission check on the given forum and user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_checker(self, user):\n        user_perm_checkers_cache_key = user.id if not user.is_anonymous else 'anonymous'\n\n        if user_perm_checkers_cache_key in self._user_perm_checkers_cache:\n            return self._user_perm_checkers_cache[user_perm_checkers_cache_key]\n\n        checker = ForumPermissionChecker(user)\n        self._user_perm_checkers_cache[user_perm_checkers_cache_key] = checker\n        return checker", "response": "Returns a ForumPermissionChecker instance for the given user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_queryset(self):\n        return ForumVisibilityContentTree.from_forums(\n            self.request.forum_permission_handler.forum_list_filter(\n                Forum.objects.all(), self.request.user,\n            ),\n        )", "response": "Returns the list of items for this view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super(IndexView, self).get_context_data(**kwargs)\n        visiblity_content_tree = context['forums']\n\n        # Computes some global values.\n        context['total_posts_count'] = sum(n.posts_count for n in visiblity_content_tree.top_nodes)\n        context['total_topics_count'] = sum(\n            n.topics_count for n in visiblity_content_tree.top_nodes\n        )\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the forum to consider.", "response": "def get_forum(self):\n        \"\"\" Returns the forum to consider. \"\"\"\n        if not hasattr(self, 'forum'):\n            self.forum = get_object_or_404(Forum, pk=self.kwargs['pk'])\n        return self.forum"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of items for this view.", "response": "def get_queryset(self):\n        \"\"\" Returns the list of items for this view. \"\"\"\n        self.forum = self.get_forum()\n        qs = (\n            self.forum.topics\n            .exclude(type=Topic.TOPIC_ANNOUNCE)\n            .exclude(approved=False)\n            .select_related('poster', 'last_post', 'last_post__poster')\n        )\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super(ForumView, self).get_context_data(**kwargs)\n\n        # Insert the considered forum into the context\n        context['forum'] = self.get_forum()\n\n        # Get the list of forums that have the current forum as parent\n        context['sub_forums'] = ForumVisibilityContentTree.from_forums(\n            self.request.forum_permission_handler.forum_list_filter(\n                context['forum'].get_descendants(), self.request.user,\n            ),\n        )\n\n        # The announces will be displayed on each page of the forum\n        context['announces'] = list(\n            self.get_forum()\n            .topics.select_related('poster', 'last_post', 'last_post__poster')\n            .filter(type=Topic.TOPIC_ANNOUNCE)\n        )\n\n        # Determines the topics that have not been read by the current user\n        context['unread_topics'] = TrackingHandler(self.request).get_unread_topics(\n            list(context[self.context_object_name]) + context['announces'], self.request.user,\n        )\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the signal associated with the view.", "response": "def send_signal(self, request, response, forum):\n        \"\"\" Sends the signal associated with the view. \"\"\"\n        self.view_signal.send(\n            sender=self, forum=forum, user=request.user, request=request, response=response,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_subscriber(self, user):\n        if not hasattr(self, '_subscribers'):\n            self._subscribers = list(self.subscribers.all())\n        return user in self._subscribers", "response": "Returns True if the given user is a subscriber of this topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the topic instance.", "response": "def clean(self):\n        \"\"\" Validates the topic instance. \"\"\"\n        super().clean()\n        if self.forum.is_category or self.forum.is_link:\n            raise ValidationError(\n                _('A topic can not be associated with a category or a link forum')\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the topic instance.", "response": "def save(self, *args, **kwargs):\n        \"\"\" Saves the topic instance. \"\"\"\n        # It is vital to track the changes of the forum associated with a topic in order to\n        # maintain counters up-to-date.\n        old_instance = None\n        if self.pk:\n            old_instance = self.__class__._default_manager.get(pk=self.pk)\n\n        # Update the slug field\n        self.slug = slugify(force_text(self.subject), allow_unicode=True)\n\n        # Do the save\n        super().save(*args, **kwargs)\n\n        # If any change has been made to the parent forum, trigger the update of the counters\n        if old_instance and old_instance.forum != self.forum:\n            self.update_trackers()\n            # The previous parent forum counters should also be updated\n            if old_instance.forum:\n                old_forum = old_instance.forum\n                old_forum.refresh_from_db()\n                old_forum.update_trackers()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the denormalized trackers associated with the topic instance.", "response": "def update_trackers(self):\n        \"\"\" Updates the denormalized trackers associated with the topic instance. \"\"\"\n        self.posts_count = self.posts.filter(approved=True).count()\n        first_post = self.posts.all().order_by('created').first()\n        last_post = self.posts.filter(approved=True).order_by('-created').first()\n        self.first_post = first_post\n        self.last_post = last_post\n        self.last_post_on = last_post.created if last_post else None\n        self._simple_save()\n        # Trigger the forum-level trackers update\n        self.forum.update_trackers()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the post is the first post of the topic.", "response": "def is_topic_head(self):\n        \"\"\" Returns ``True`` if the post is the first post of the topic. \"\"\"\n        return self.topic.first_post.id == self.id if self.topic.first_post else False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the post is the last post of the topic.", "response": "def is_topic_tail(self):\n        \"\"\" Returns ``True`` if the post is the last post of the topic. \"\"\"\n        return self.topic.last_post.id == self.id if self.topic.last_post else False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef position(self):\n        position = self.topic.posts.filter(Q(created__lt=self.created) | Q(id=self.id)).count()\n        return position", "response": "Returns the position of the post in the topic."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean(self):\n        super().clean()\n\n        # At least a poster (user) or a session key must be associated with\n        # the post.\n        if self.poster is None and self.anonymous_key is None:\n            raise ValidationError(\n                _('A user id or an anonymous key must be associated with a post.'),\n            )\n        if self.poster and self.anonymous_key:\n            raise ValidationError(\n                _('A user id or an anonymous key must be associated with a post, but not both.'),\n            )\n\n        if self.anonymous_key and not self.username:\n            raise ValidationError(_('A username must be specified if the poster is anonymous'))", "response": "Validates the post instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the post instance.", "response": "def save(self, *args, **kwargs):\n        \"\"\" Saves the post instance. \"\"\"\n        new_post = self.pk is None\n        super().save(*args, **kwargs)\n\n        # Ensures that the subject of the thread corresponds to the one associated\n        # with the first post. Do the same with the 'approved' flag.\n        if (new_post and self.topic.first_post is None) or self.is_topic_head:\n            if self.subject != self.topic.subject or self.approved != self.topic.approved:\n                self.topic.subject = self.subject\n                self.topic.approved = self.approved\n\n        # Trigger the topic-level trackers update\n        self.topic.update_trackers()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, using=None):\n        if self.is_alone:\n            # The default way of operating is to trigger the deletion of the associated topic\n            # only if the considered post is the only post embedded in the topic\n            self.topic.delete()\n        else:\n            super(AbstractPost, self).delete(using)\n            self.topic.update_trackers()", "response": "Deletes the post instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing a ForumVisibilityContentTree instance from a list of forums.", "response": "def from_forums(cls, forums):\n        \"\"\" Initializes a ``ForumVisibilityContentTree`` instance from a list of forums. \"\"\"\n        root_level = None\n        current_path = []\n        nodes = []\n\n        # Ensures forums last posts and related poster relations are \"followed\" for better\n        # performance (only if we're considering a queryset).\n        forums = (\n            forums.select_related('last_post', 'last_post__poster')\n            if isinstance(forums, QuerySet) else forums\n        )\n\n        for forum in forums:\n            level = forum.level\n\n            # Set the root level to the top node level at the first iteration.\n            if root_level is None:\n                root_level = level\n\n            # Initializes a visibility forum node associated with current forum instance.\n            vcontent_node = ForumVisibilityContentNode(forum)\n\n            # Computes a relative level associated to the node.\n            relative_level = level - root_level\n            vcontent_node.relative_level = relative_level\n\n            # All children nodes will be stored in an array attached to the current node.\n            vcontent_node.children = []\n\n            # Removes the forum that are not in the current branch.\n            while len(current_path) > relative_level:\n                current_path.pop(-1)\n\n            if level != root_level:\n                # Update the parent of the current forum.\n                parent_node = current_path[-1]\n                vcontent_node.parent = parent_node\n                parent_node.children.append(vcontent_node)\n\n            # Sets visible flag if applicable. The visible flag is used to determine whether a forum\n            # can be seen in a forum list or not. A forum can be seen if one of the following\n            # statements is true:\n            #\n            # * the forum is a direct child of the starting forum for the considered level\n            # * the forum have a parent which is a category and this category is a direct child of\n            #   the starting forum\n            # * the forum have its 'display_sub_forum_list' option set to True and have a parent\n            #   which is another forum. The latter is a direct child of the starting forum\n            # * the forum have its 'display_sub_forum_list' option set to True and have a parent\n            #   which is another forum. The later have a parent which is a category and this\n            #   category is a direct child of the starting forum\n            #\n            # If forums at the root level don't have parents, the visible forums are those that can\n            # be seen from the root of the forums tree.\n            vcontent_node.visible = (\n                (relative_level == 0) or\n                (forum.display_sub_forum_list and relative_level == 1) or\n                (forum.is_category and relative_level == 1) or\n                (\n                    relative_level == 2 and\n                    vcontent_node.parent.parent.obj.is_category and\n                    vcontent_node.parent.obj.is_forum\n                )\n            )\n\n            # Add the current forum to the end of the current branch and inserts the node inside the\n            # final node dictionary.\n            current_path.append(vcontent_node)\n            nodes.append(vcontent_node)\n\n        tree = cls(nodes=nodes)\n        for node in tree.nodes:\n            node.tree = tree\n\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the latest post associated with the node or one of its descendants.", "response": "def last_post(self):\n        \"\"\" Returns the latest post associated with the node or one of its descendants. \"\"\"\n        posts = [n.last_post for n in self.children if n.last_post is not None]\n        children_last_post = max(posts, key=lambda p: p.created) if posts else None\n        if children_last_post and self.obj.last_post_id:\n            return max(self.obj.last_post, children_last_post, key=lambda p: p.created)\n        return children_last_post or self.obj.last_post"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last_post_on(self):\n        dates = [n.last_post_on for n in self.children if n.last_post_on is not None]\n        children_last_post_on = max(dates) if dates else None\n        if children_last_post_on and self.obj.last_post_on:\n            return max(self.obj.last_post_on, children_last_post_on)\n        return children_last_post_on or self.obj.last_post_on", "response": "Returns the latest post date associated with the node or one of its descendants."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next_sibling(self):\n        if self.parent:\n            nodes = self.parent.children\n            index = nodes.index(self)\n            sibling = nodes[index + 1] if index < len(nodes) - 1 else None\n        else:\n            nodes = self.tree.nodes\n            index = nodes.index(self)\n            sibling = (\n                next((n for n in nodes[index + 1:] if n.level == self.level), None)\n                if index < len(nodes) - 1 else None\n            )\n        return sibling", "response": "Returns the next sibling of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef posts_count(self):\n        return self.obj.direct_posts_count + sum(n.posts_count for n in self.children)", "response": "Returns the number of posts associated with the current node and its descendants."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the previous sibling of the current node.", "response": "def previous_sibling(self):\n        \"\"\" Returns the previous sibling of the current node.\n\n        The previous sibling is searched in the parent node if we are not considering a top-level\n        node. Otherwise it is searched inside the list of nodes (which should be sorted by tree ID)\n        that is associated with the considered tree instance.\n        \"\"\"\n        if self.parent:\n            nodes = self.parent.children\n            index = nodes.index(self)\n            sibling = nodes[index - 1] if index > 0 else None\n        else:\n            nodes = self.tree.nodes\n            index = nodes.index(self)\n            sibling = (\n                next((n for n in reversed(nodes[:index]) if n.level == self.level), None)\n                if index > 0 else None\n            )\n        return sibling"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef topics_count(self):\n        return self.obj.direct_topics_count + sum(n.topics_count for n in self.children)", "response": "Returns the number of topics associated with the current node and its descendants."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urlpatterns(self):\n        return [\n            path(_('topics/'), self.latest_topics_feed(), name='latest_topics'),\n            path(\n                _('forum/<str:forum_slug>-<int:forum_pk>/topics/'),\n                self.latest_topics_feed(),\n                name='forum_latest_topics',\n            ),\n            path(\n                _('forum/<str:forum_slug>-<int:forum_pk>/topics/all/'),\n                self.latest_topics_feed(),\n                {'descendants': True},\n                name='forum_latest_topics_with_descendants',\n            ),\n        ]", "response": "Returns the list of URL patterns managed by the considered factory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_perm(self, perm, forum):\n        if not self.user.is_anonymous and not self.user.is_active:\n            # An inactive user cannot have permissions\n            return False\n        elif self.user and self.user.is_superuser:\n            # The superuser have all permissions\n            return True\n        return perm in self.get_perms(forum)", "response": "Checks if the considered user has given permission for the passed forum."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of permission codenames of all permissions for the given forum.", "response": "def get_perms(self, forum):\n        \"\"\" Returns the list of permission codenames of all permissions for the given forum. \"\"\"\n        # An inactive user has no permissions.\n        if not self.user.is_anonymous and not self.user.is_active:\n            return []\n\n        user_model = get_user_model()\n        user_groups_related_name = user_model.groups.field.related_query_name()\n\n        if forum.id not in self._forum_perms_cache:\n            if self.user and self.user.is_superuser:\n                # The superuser has all the permissions.\n                perms = list(ForumPermission.objects.values_list('codename', flat=True))\n            elif self.user:\n                default_auth_forum_perms = (\n                    machina_settings.DEFAULT_AUTHENTICATED_USER_FORUM_PERMISSIONS\n                )\n\n                user_kwargs_filter = (\n                    {'anonymous_user': True} if self.user.is_anonymous\n                    else {'user': self.user}\n                )\n\n                # Fetches the permissions of the considered user for the given forum.\n                user_perms = (\n                    UserForumPermission.objects.select_related()\n                    .filter(**user_kwargs_filter)\n                    .filter(Q(forum__isnull=True) | Q(forum=forum))\n                )\n\n                # Computes the list of permissions that are granted for all the forums.\n                globally_granted_user_perms = list(\n                    filter(lambda p: p.has_perm and p.forum_id is None, user_perms)\n                )\n                globally_granted_user_perms = [\n                    p.permission.codename for p in globally_granted_user_perms\n                ]\n\n                # Computes the list of permissions that are granted on a per-forum basis.\n                per_forum_granted_user_perms = list(\n                    filter(lambda p: p.has_perm and p.forum_id is not None, user_perms)\n                )\n                per_forum_granted_user_perms = [\n                    p.permission.codename for p in per_forum_granted_user_perms\n                ]\n\n                # Computes the list of permissions that are not granted on a per-forum basis.\n                per_forum_nongranted_user_perms = list(\n                    filter(lambda p: not p.has_perm and p.forum_id is not None, user_perms)\n                )\n                per_forum_nongranted_user_perms = [\n                    p.permission.codename for p in per_forum_nongranted_user_perms\n                ]\n\n                # If the considered user have no global permissions, the permissions defined by the\n                # DEFAULT_AUTHENTICATED_USER_FORUM_PERMISSIONS settings are used instead.\n                if self.user.is_authenticated and not globally_granted_user_perms:\n                    globally_granted_user_perms = default_auth_forum_perms\n\n                # Finally computes the list of permission codenames that are granted to the user for\n                # the considered forum.\n                granted_user_perms = [\n                    c for c in globally_granted_user_perms if\n                    c not in per_forum_nongranted_user_perms\n                ]\n                granted_user_perms += per_forum_granted_user_perms\n                granted_user_perms = set(granted_user_perms)\n\n                perms = granted_user_perms\n\n                # If the user is a registered user, we have to check the permissions of its groups\n                # in order to determine the additional permissions they could have.\n                if not self.user.is_anonymous:\n                    group_perms = (\n                        GroupForumPermission.objects.select_related()\n                        .filter(**{'group__{}'.format(user_groups_related_name): self.user})\n                        .filter(Q(forum__isnull=True) | Q(forum=forum))\n                    )\n\n                    globally_granted_group_perms = list(\n                        filter(lambda p: p.has_perm and p.forum_id is None, group_perms)\n                    )\n                    globally_granted_group_perms = [\n                        p.permission.codename for p in globally_granted_group_perms\n                    ]\n\n                    per_forum_granted_group_perms = list(\n                        filter(lambda p: p.has_perm and p.forum_id is not None, group_perms)\n                    )\n                    per_forum_granted_group_perms = [\n                        p.permission.codename for p in per_forum_granted_group_perms\n                    ]\n\n                    per_forum_nongranted_group_perms = list(\n                        filter(lambda p: not p.has_perm and p.forum_id is not None, group_perms)\n                    )\n                    per_forum_nongranted_group_perms = [\n                        p.permission.codename for p in per_forum_nongranted_group_perms\n                    ]\n\n                    granted_group_perms = [\n                        c for c in globally_granted_group_perms if\n                        c not in per_forum_nongranted_group_perms\n                    ]\n                    granted_group_perms += per_forum_granted_group_perms\n                    granted_group_perms = filter(\n                        lambda x: x not in per_forum_nongranted_user_perms, granted_group_perms\n                    )\n                    granted_group_perms = set(granted_group_perms)\n\n                    # Includes the permissions granted for the user' groups in the initial set of\n                    # permission codenames.\n                    perms |= granted_group_perms\n\n            self._forum_perms_cache[forum.id] = perms\n\n        return self._forum_perms_cache[forum.id]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the considered instances.", "response": "def save(self, commit=True, **kwargs):\n        \"\"\" Saves the considered instances. \"\"\"\n        if self.post:\n            for form in self.forms:\n                form.instance.post = self.post\n        super().save(commit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the URL patterns managed by the considered factory.", "response": "def get_urlpatterns(self):\n        \"\"\" Returns the URL patterns managed by the considered factory / application. \"\"\"\n        urlpatterns = super().get_urlpatterns()\n\n        conversation_urlpatterns = [\n            path(\n                _('topic/<str:slug>-<int:pk>/'),\n                self.topic_view.as_view(),\n                name='topic',\n            ),\n            path(_('topic/create/'), self.topic_create_view.as_view(), name='topic_create'),\n            path(\n                _('topic/<str:slug>-<int:pk>/update/'),\n                self.topic_update_view.as_view(),\n                name='topic_update',\n            ),\n            path(\n                _('topic/<str:topic_slug>-<int:topic_pk>/post/create/'),\n                self.post_create_view.as_view(),\n                name='post_create',\n            ),\n            path(\n                _('topic/<str:topic_slug>-<int:topic_pk>/<int:pk>/post/update/'),\n                self.post_update_view.as_view(),\n                name='post_update',\n            ),\n            path(\n                _('topic/<str:topic_slug>-<int:topic_pk>/<int:pk>/post/delete/'),\n                self.post_delete_view.as_view(),\n                name='post_delete',\n            ),\n        ]\n\n        urlpatterns += [\n            path(\n                _('forum/<str:forum_slug>-<int:forum_pk>/'),\n                include(conversation_urlpatterns),\n            ),\n        ]\n\n        return urlpatterns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_required_permissions(self, request):\n        perms = []\n\n        if not self.permission_required:\n            return perms\n\n        if isinstance(self.permission_required, string_types):\n            perms = [self.permission_required, ]\n        elif isinstance(self.permission_required, Iterable):\n            perms = [perm for perm in self.permission_required]\n        else:\n            raise ImproperlyConfigured(\n                '\\'PermissionRequiredMixin\\' requires \\'permission_required\\' '\n                'attribute to be set to \\'<app_label>.<permission codename>\\' but is set to {} '\n                'instead'.format(self.permission_required)\n            )\n        return perms", "response": "Returns the required permissions to access the considered object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform the permissions check for the given object.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permissions check.\n\n        Performs a permissions check in order to tell if the passed user can access the current view\n        for the given object. By default, this method checks whether the given user has all the\n        considered permissions in order to grant access. This behavior can be overridden in any\n        subclass.\n\n        \"\"\"\n        # Initializes a permission checker\n        checker = self.request.forum_permission_handler._get_checker(user)\n        # Check permissions\n        return all(checker.has_perm(perm, obj) for perm in perms)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_permissions(self, request):\n        obj = (\n            hasattr(self, 'get_controlled_object') and self.get_controlled_object() or\n            hasattr(self, 'get_object') and self.get_object() or getattr(self, 'object', None)\n        )\n        user = request.user\n\n        # Get the permissions to check\n        perms = self.get_required_permissions(self)\n\n        # Check permissions\n        has_permissions = self.perform_permissions_check(user, obj, perms)\n\n        if not has_permissions and not user.is_authenticated:\n            return HttpResponseRedirect('{}?{}={}'.format(\n                resolve_url(self.login_url),\n                self.redirect_field_name,\n                urlquote(request.get_full_path())\n            ))\n        elif not has_permissions:\n            raise PermissionDenied", "response": "Checks the permissions of the object and the user s permissions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndispatch an incoming request.", "response": "def dispatch(self, request, *args, **kwargs):\n        \"\"\" Dispatches an incoming request. \"\"\"\n        self.request = request\n        self.args = args\n        self.kwargs = kwargs\n        response = self.check_permissions(request)\n        if response:\n            return response\n        return super().dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_forum_redirects_counter(sender, forum, user, request, response, **kwargs):\n    if forum.is_link and forum.link_redirects:\n        forum.link_redirects_count = F('link_redirects_count') + 1\n        forum.save()", "response": "Updates the link redirects counter for a link forum."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_avatar_upload_to(self, filename):\n        dummy, ext = os.path.splitext(filename)\n        return os.path.join(\n            machina_settings.PROFILE_AVATAR_UPLOAD_TO,\n            '{id}{ext}'.format(id=str(uuid.uuid4()).replace('-', ''), ext=ext),\n        )", "response": "Returns the path to upload the associated avatar to."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_queryset(self):\n        qs = super().get_queryset()\n        qs = qs.filter(approved=True)\n        return qs", "response": "Returns all the approved topics or posts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef votes(self):\n        votes = []\n        for option in self.options.all():\n            votes += option.votes.all()\n        return votes", "response": "Returns all the votes related to this topic poll."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the considered instance.", "response": "def clean(self):\n        \"\"\" Validates the considered instance. \"\"\"\n        super().clean()\n\n        # At least a poster (user) or a session key must be associated with\n        # the vote instance.\n        if self.voter is None and self.anonymous_key is None:\n            raise ValidationError(_('A user id or an anonymous key must be used.'))\n        if self.voter and self.anonymous_key:\n            raise ValidationError(_('A user id or an anonymous key must be used, but not both.'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['top_level_forum'] = self.top_level_forum\n        context['top_level_forum_url'] = self.get_top_level_forum_url()\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the parent forum url for which forums are marked as read.", "response": "def get_top_level_forum_url(self):\n        \"\"\" Returns the parent forum from which forums are marked as read. \"\"\"\n        return (\n            reverse('forum:index') if self.top_level_forum is None else\n            reverse(\n                'forum:forum',\n                kwargs={'slug': self.top_level_forum.slug, 'pk': self.kwargs['pk']},\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark the considered forums as read.", "response": "def mark_as_read(self, request, pk):\n        \"\"\" Marks the considered forums as read. \"\"\"\n        if self.top_level_forum is not None:\n            forums = request.forum_permission_handler.get_readable_forums(\n                self.top_level_forum.get_descendants(include_self=True), request.user,\n            )\n        else:\n            forums = request.forum_permission_handler.get_readable_forums(\n                Forum.objects.all(), request.user,\n            )\n\n        # Marks forums as read\n        track_handler.mark_forums_read(forums, request.user)\n\n        if len(forums):\n            messages.success(request, self.success_message)\n\n        return HttpResponseRedirect(self.get_top_level_forum_url())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super().get_context_data(**kwargs)\n        context['forum_url'] = self.get_forum_url()\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_forum_url(self):\n        return reverse('forum:forum', kwargs={'slug': self.forum.slug, 'pk': self.forum.pk})", "response": "Returns the url of the forum whose topics will be marked read."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mark_topics_read(self, request, pk):\n        track_handler.mark_forums_read([self.forum, ], request.user)\n        messages.success(request, self.success_message)\n        return HttpResponseRedirect(self.get_forum_url())", "response": "Marks the forum topics as read."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of items for this view.", "response": "def get_queryset(self):\n        \"\"\" Returns the list of items for this view. \"\"\"\n        forums = self.request.forum_permission_handler.get_readable_forums(\n            Forum.objects.all(), self.request.user,\n        )\n        topics = Topic.objects.filter(forum__in=forums)\n        topics_pk = map(lambda t: t.pk, track_handler.get_unread_topics(topics, self.request.user))\n        return Topic.approved_objects.filter(pk__in=topics_pk).order_by('-last_post_on')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_model(app_label, model_name):\n    try:\n        return apps.get_model(app_label, model_name)\n    except AppRegistryNotReady:\n        if apps.apps_ready and not apps.models_ready:\n            # If the models module of the considered app has not been loaded yet,\n            # we try to import it manually in order to retrieve the model class.\n            # This trick is usefull in order to get the model class during the\n            # ``apps.populate()`` call and the execution of related methods of AppConfig\n            # instances (eg. ``ready``).\n\n            # Firts, the config of the consideration must be retrieved\n            app_config = apps.get_app_config(app_label)\n            # Then the models module is manually imported\n            import_module('%s.%s' % (app_config.name, MODELS_MODULE_NAME))\n            # Finally, tries to return the registered model class\n            return apps.get_registered_model(app_label, model_name)\n        else:\n            raise", "response": "Returns the corresponding model class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the given model is registered or not.", "response": "def is_model_registered(app_label, model_name):\n    \"\"\" Checks whether the given model is registered or not.\n\n    It is usefull to prevent Machina models for being registered if they are overridden by local\n    apps.\n\n    \"\"\"\n    try:\n        apps.get_registered_model(app_label, model_name)\n    except LookupError:\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef model_factory(abstract_class):\n    app_label = abstract_class.Meta.app_label\n    model_name = abstract_class.__name__.replace('Abstract', '')\n\n    if not is_model_registered(app_label, model_name):\n        return type(str(model_name), (abstract_class, ), {'__module__': __name__, })", "response": "Returns a class that inherits from this class only if it has not already been registered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the current instance.", "response": "def clean(self):\n        \"\"\" Validates the current instance. \"\"\"\n        super().clean()\n        if (\n            (self.user is None and not self.anonymous_user) or\n            (self.user and self.anonymous_user)\n        ):\n            raise ValidationError(\n                _('A permission should target either a user or an anonymous user'),\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_object_or_none(klass, *args, **kwargs):\n    queryset = _get_queryset(klass)\n    try:\n        return queryset.get(*args, **kwargs)\n    except:  # noqa: E722\n        return None", "response": "Calls get on a given model manager but returns None instead of the model s\n        DoesNotExist exception."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_to_response(self, context, **response_kwargs):\n        filename = os.path.basename(self.object.file.name)\n\n        # Try to guess the content type of the given file\n        content_type, _ = mimetypes.guess_type(self.object.file.name)\n        if not content_type:\n            content_type = 'text/plain'\n\n        response = HttpResponse(self.object.file, content_type=content_type)\n        response['Content-Disposition'] = 'attachment; filename={}'.format(filename)\n\n        return response", "response": "Generates the appropriate response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the user can download the files for the object.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permission check. \"\"\"\n        return self.request.forum_permission_handler.can_download_files(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of URL patterns managed by the considered factory.", "response": "def get_urlpatterns(self):\n        \"\"\" Returns the URL patterns managed by the considered factory / application. \"\"\"\n        return [\n            path('', self.index_view.as_view(), name='index'),\n            path(\n                _('forum/<str:slug>-<int:pk>/'),\n                self.forum_view.as_view(),\n                name='forum',\n            ),\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the keyword arguments to provide tp the associated form.", "response": "def get_form_kwargs(self):\n        \"\"\" Returns the keyword arguments to provide tp the associated form. \"\"\"\n        kwargs = super(ModelFormMixin, self).get_form_kwargs()\n        kwargs['poll'] = self.object\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef form_valid(self, form):\n        user_kwargs = (\n            {'voter': self.request.user}\n            if self.request.user.is_authenticated\n            else {'anonymous_key': self.request.user.forum_key}\n        )\n\n        if self.object.user_changes:\n            # If user changes are allowed for this poll, all the poll associated with the current\n            # user must be deleted.\n            TopicPollVote.objects.filter(poll_option__poll=self.object, **user_kwargs).delete()\n\n        options = form.cleaned_data['options']\n        for option in options:\n            TopicPollVote.objects.create(poll_option=option, **user_kwargs)\n\n        return HttpResponseRedirect(self.get_success_url())", "response": "Handles a valid poll form."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef form_invalid(self, form):\n        messages.error(self.request, form.errors[NON_FIELD_ERRORS])\n        return redirect(\n            reverse(\n                'forum_conversation:topic',\n                kwargs={\n                    'forum_slug': self.object.topic.forum.slug,\n                    'forum_pk': self.object.topic.forum.pk,\n                    'slug': self.object.topic.slug,\n                    'pk': self.object.topic.pk\n                },\n            ),\n        )", "response": "Handles an invalid form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the success URL to redirect the user to.", "response": "def get_success_url(self):\n        \"\"\" Returns the success URL to redirect the user to. \"\"\"\n        messages.success(self.request, _('Your vote has been cast.'))\n        return reverse(\n            'forum_conversation:topic',\n            kwargs={\n                'forum_slug': self.object.topic.forum.slug,\n                'forum_pk': self.object.topic.forum.pk,\n                'slug': self.object.topic.slug,\n                'pk': self.object.topic.pk,\n            },\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_vote_in_poll(obj, user)", "response": "Checks if the user has permission to vote in the poll."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_urlpatterns(self):\n        return [\n            path(\n                _('topic/<str:slug>-<int:pk>/lock/'),\n                self.topic_lock_view.as_view(),\n                name='topic_lock',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/unlock/'),\n                self.topic_unlock_view.as_view(),\n                name='topic_unlock',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/delete/'),\n                self.topic_delete_view.as_view(),\n                name='topic_delete',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/move/'),\n                self.topic_move_view.as_view(),\n                name='topic_move',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/change/topic/'),\n                self.topic_update_to_normal_topic_view.as_view(),\n                name='topic_update_to_post',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/change/sticky/'),\n                self.topic_update_to_sticky_topic_view.as_view(),\n                name='topic_update_to_sticky',\n            ),\n            path(\n                _('topic/<str:slug>-<int:pk>/change/announce/'),\n                self.topic_update_to_announce_view.as_view(),\n                name='topic_update_to_announce',\n            ),\n            path(_('queue/'), self.moderation_queue_list_view.as_view(), name='queue'),\n            path(\n                _('queue/<int:pk>/'),\n                self.moderation_queue_detail_view.as_view(),\n                name='queued_post',\n            ),\n            path(\n                _('queue/<int:pk>/approve/'),\n                self.post_approve_view.as_view(),\n                name='approve_queued_post',\n            ),\n            path(\n                _('queue/<int:pk>/disapprove/'),\n                self.post_disapprove_view.as_view(),\n                name='disapprove_queued_post',\n            ),\n        ]", "response": "Returns the URL patterns managed by the considered factory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_been_completed_by(poll, user):\n    user_votes = TopicPollVote.objects.filter(\n        poll_option__poll=poll)\n    if user.is_anonymous:\n        forum_key = get_anonymous_user_forum_key(user)\n        user_votes = user_votes.filter(anonymous_key=forum_key) if forum_key \\\n            else user_votes.none()\n    else:\n        user_votes = user_votes.filter(voter=user)\n    return user_votes.exists()", "response": "This will return a boolean indicating if the passed user has already voted in the given\n        poll."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_urlpatterns(self):\n        return [\n            path(\n                '',\n                search_view_factory(view_class=self.search_view, form_class=self.search_form),\n                name='search',\n            ),\n        ]", "response": "Returns the list of URL patterns managed by the considered factory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter a list of forums and return only those which are unread for the passed user.", "response": "def get_unread_forums_from_list(self, forums, user):\n        \"\"\" Filter a list of forums and return only those which are unread.\n\n        Given a list of forums find and returns the list of forums that are unread for the passed\n        user. If a forum is unread all of its ancestors are also unread and will be included in the\n        final list.\n        \"\"\"\n        unread_forums = []\n        visibility_contents = ForumVisibilityContentTree.from_forums(forums)\n        forum_ids_to_visibility_nodes = visibility_contents.as_dict\n\n        tracks = super().get_queryset().select_related('forum').filter(\n            user=user,\n            forum__in=forums)\n        tracked_forums = []\n\n        for track in tracks:\n            forum_last_post_on = forum_ids_to_visibility_nodes[track.forum_id].last_post_on\n            if (forum_last_post_on and track.mark_time < forum_last_post_on) \\\n                    and track.forum not in unread_forums:\n                unread_forums.extend(track.forum.get_ancestors(include_self=True))\n            tracked_forums.append(track.forum)\n\n        for forum in forums:\n            if forum not in tracked_forums and forum not in unread_forums \\\n                    and forum.direct_topics_count > 0:\n                unread_forums.extend(forum.get_ancestors(include_self=True))\n\n        return list(set(unread_forums))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef increase_posts_count(sender, instance, **kwargs):\n\n    if instance.poster is None:\n        # An anonymous post is considered. No profile can be updated in\n        # that case.\n        return\n\n    profile, dummy = ForumProfile.objects.get_or_create(user=instance.poster)\n    increase_posts_count = False\n\n    if instance.pk:\n        try:\n            old_instance = instance.__class__._default_manager.get(pk=instance.pk)\n        except ObjectDoesNotExist:  # pragma: no cover\n            # This should never happen (except with django loaddata command)\n            increase_posts_count = True\n            old_instance = None\n        if old_instance and old_instance.approved is False and instance.approved is True:\n            increase_posts_count = True\n    elif instance.approved:\n        increase_posts_count = True\n\n    if increase_posts_count:\n        profile.posts_count = F('posts_count') + 1\n        profile.save()", "response": "Increase the member s post count after a post save."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecreasing the member's post count after a post unaproval. This receiver handles the unaproval of a forum post: the posts count associated with the post's author is decreased.", "response": "def decrease_posts_count_after_post_unaproval(sender, instance, **kwargs):\n    \"\"\" Decreases the member's post count after a post unaproval.\n\n    This receiver handles the unaproval of a forum post: the posts count associated with the post's\n    author is decreased.\n    \"\"\"\n    if not instance.pk:\n        # Do not consider posts being created.\n        return\n\n    profile, dummy = ForumProfile.objects.get_or_create(user=instance.poster)\n\n    try:\n        old_instance = instance.__class__._default_manager.get(pk=instance.pk)\n    except ObjectDoesNotExist:  # pragma: no cover\n        # This should never happen (except with django loaddata command)\n        return\n\n    if old_instance and old_instance.approved is True and instance.approved is False:\n        profile.posts_count = F('posts_count') - 1\n        profile.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecrease the member's post count after a post deletion. This receiver handles the deletion of a forum post: the posts count related to the post's author is decreased.", "response": "def decrease_posts_count_after_post_deletion(sender, instance, **kwargs):\n    \"\"\" Decreases the member's post count after a post deletion.\n\n    This receiver handles the deletion of a forum post: the posts count related to the post's\n    author is decreased.\n    \"\"\"\n    if not instance.approved:\n        # If a post has not been approved, it has not been counted.\n        # So do not decrement count\n        return\n\n    try:\n        assert instance.poster_id is not None\n        poster = User.objects.get(pk=instance.poster_id)\n    except AssertionError:\n        # An anonymous post is considered. No profile can be updated in\n        # that case.\n        return\n    except ObjectDoesNotExist:  # pragma: no cover\n        # This can happen if a User instance is deleted. In that case the\n        # User instance is not available and the receiver should return.\n        return\n\n    profile, dummy = ForumProfile.objects.get_or_create(user=poster)\n    if profile.posts_count:\n        profile.posts_count = F('posts_count') - 1\n        profile.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lock(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        success_url = self.get_success_url()\n        self.object.status = Topic.TOPIC_LOCKED\n        self.object.save()\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(success_url)", "response": "Lock the considered topic and retirects the user to the success URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the success URL to redirect the user to.", "response": "def get_success_url(self):\n        \"\"\" Returns the success URL to redirect the user to. \"\"\"\n        return reverse(\n            'forum_conversation:topic',\n            kwargs={\n                'forum_slug': self.object.forum.slug,\n                'forum_pk': self.object.forum.pk,\n                'slug': self.object.slug,\n                'pk': self.object.pk,\n            },\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the user has permission to lock the topic.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permission check. \"\"\"\n        return self.request.forum_permission_handler.can_lock_topics(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nunlocks the considered topic and retirects the user to the success URL.", "response": "def unlock(self, request, *args, **kwargs):\n        \"\"\" Unlocks the considered topic and retirects the user to the success URL. \"\"\"\n        self.object = self.get_object()\n        success_url = self.get_success_url()\n        self.object.status = Topic.TOPIC_UNLOCKED\n        self.object.save()\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(success_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the success URL to redirect the user to.", "response": "def get_success_url(self):\n        \"\"\" Returns the success URL to redirect the user to. \"\"\"\n        messages.success(self.request, self.success_message)\n        return reverse(\n            'forum:forum', kwargs={'slug': self.object.forum.slug, 'pk': self.object.forum.pk},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_delete_topics(obj, user)", "response": "Checks if the user can delete the topic objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_valid(self, form):\n        # Move the topic\n        topic = self.object\n        old_forum = topic.forum\n        new_forum = form.cleaned_data['forum']\n        topic.forum = new_forum\n\n        # Eventually lock the topic\n        if form.cleaned_data['lock_topic']:\n            topic.status = Topic.TOPIC_LOCKED\n        else:\n            topic.status = Topic.TOPIC_MOVED\n\n        topic.save()\n        old_forum.save()\n\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(self.get_success_url())", "response": "Handles a valid form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the user can move the topic.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permissions check. \"\"\"\n        return self.request.forum_permission_handler.can_move_topics(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_type(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        success_url = self.get_success_url()\n        self.object.type = self.target_type\n        self.object.save()\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(success_url)", "response": "Updates the type of the considered topic and retirects the user to the success URL."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['question'] = self.question\n        topic = self.get_object()\n        context['forum'] = topic.forum\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_update_topics_to_normal_topics(obj, user)", "response": "Checks if the user can update topics to normal topics."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the user can update topics to sticky topics.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permissions check. \"\"\"\n        return self.request.forum_permission_handler.can_update_topics_to_sticky_topics(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the user has permission to update the topic list.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permissions check. \"\"\"\n        return self.request.forum_permission_handler.can_update_topics_to_announces(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of items for this view.", "response": "def get_queryset(self):\n        \"\"\" Returns the list of items for this view. \"\"\"\n        forums = self.request.forum_permission_handler.get_moderation_queue_forums(\n            self.request.user,\n        )\n        qs = super().get_queryset()\n        qs = qs.filter(topic__forum__in=forums, approved=False)\n        return qs.order_by('-created')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_access_moderation_queue(user)", "response": "Checks if the user can modify the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super().get_context_data(**kwargs)\n\n        post = self.object\n        topic = post.topic\n\n        # Handles the case when a poll is associated to the topic.\n        try:\n            if hasattr(topic, 'poll') and topic.poll.options.exists():\n                poll = topic.poll\n                context['poll'] = poll\n                context['poll_options'] = poll.options.all()\n        except ObjectDoesNotExist:  # pragma: no cover\n            pass\n\n        if not post.is_topic_head:\n            # Add the topic review\n            previous_posts = (\n                topic.posts\n                .filter(approved=True, created__lte=post.created)\n                .select_related('poster', 'updated_by')\n                .prefetch_related('attachments', 'poster__forum_profile')\n                .order_by('-created')\n            )\n            previous_posts = previous_posts[:machina_settings.TOPIC_REVIEW_POSTS_NUMBER]\n            context['previous_posts'] = previous_posts\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_approve_posts(obj, user)", "response": "Checks if the user has permission to approve posts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napproves the considered post and retirects the user to the success URL.", "response": "def approve(self, request, *args, **kwargs):\n        \"\"\" Approves the considered post and retirects the user to the success URL. \"\"\"\n        self.object = self.get_object()\n        success_url = self.get_success_url()\n        self.object.approved = True\n        self.object.save()\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(success_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disapprove(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        success_url = self.get_success_url()\n        self.object.delete()\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(success_url)", "response": "Disapproves the considered post and retirects the user to the success URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super().get_context_data(**kwargs)\n        context['poster'] = self.poster\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of items for this view.", "response": "def get_queryset(self):\n        \"\"\" Returns the list of items for this view. \"\"\"\n        # Determines the forums that can be accessed by the current user\n        forums = self.request.forum_permission_handler.get_readable_forums(\n            Forum.objects.all(), self.request.user,\n        )\n\n        # Returns the posts submitted by the considered user.\n        return (\n            Post.objects\n            .select_related('topic', 'topic__forum', 'poster')\n            .prefetch_related('poster__forum_profile')\n            .filter(poster=self.poster, topic__forum__in=forums)\n            .order_by('-created')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef poster(self):\n        user_model = get_user_model()\n        return get_object_or_404(user_model, pk=self.kwargs[self.user_pk_url_kwarg])", "response": "Returns the considered user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object(self, queryset=None):\n        user = super().get_object(queryset)\n        profile, dummy = ForumProfile.objects.get_or_create(user=user)\n        return profile", "response": "Returns the considered object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super().get_context_data(**kwargs)\n\n        # Computes the number of topics added by the considered member\n        context['topics_count'] = (\n            Topic.objects.filter(approved=True, poster=self.object.user).count()\n        )\n\n        # Fetches the recent posts added by the considered user\n        forums = self.request.forum_permission_handler.get_readable_forums(\n            Forum.objects.all(), self.request.user,\n        )\n        recent_posts = (\n            Post.approved_objects\n            .select_related('topic', 'topic__forum')\n            .filter(topic__forum__in=forums, poster=self.object.user)\n            .order_by('-created')\n        )\n        context['recent_posts'] = recent_posts[:machina_settings.PROFILE_RECENT_POSTS_NUMBER]\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the considered object.", "response": "def get_object(self, queryset=None):\n        \"\"\" Returns the considered object. \"\"\"\n        profile, dummy = ForumProfile.objects.get_or_create(user=self.request.user)\n        return profile"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef form_valid(self, form):\n        response = super().form_valid(form)\n        messages.success(self.request, self.success_message)\n        return response", "response": "Handles a valid form."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subscribe(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        self.object.subscribers.add(request.user)\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(self.get_success_url())", "response": "This action is performed by the object s subscribe method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['topic'] = self.object\n        context['forum'] = self.object.forum\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the user can subscribe to the topic.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permission check. \"\"\"\n        return self.request.forum_permission_handler.can_subscribe_to_topic(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unsubscribe(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        self.object.subscribers.remove(request.user)\n        messages.success(self.request, self.success_message)\n        return HttpResponseRedirect(self.get_success_url())", "response": "Removes the user from the list of subscribers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_unsubscribe_from_topic(obj, user)", "response": "Checks if the user can unsubscribe from the topic."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the views counter of the given topic.", "response": "def update_topic_counter(sender, topic, user, request, response, **kwargs):\n    \"\"\" Handles the update of the views counter associated with topics. \"\"\"\n    topic.__class__._default_manager.filter(id=topic.id).update(views_count=F('views_count') + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_topic(self):\n        if not hasattr(self, 'topic'):\n            self.topic = get_object_or_404(\n                Topic.objects.select_related('forum').all(), pk=self.kwargs['pk'],\n            )\n        return self.topic", "response": "Returns the topic to consider."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_queryset(self):\n        self.topic = self.get_topic()\n        qs = (\n            self.topic.posts\n            .all()\n            .exclude(approved=False)\n            .select_related('poster', 'updated_by')\n            .prefetch_related('attachments', 'poster__forum_profile')\n        )\n        return qs", "response": "Returns the list of items for this view."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n\n        # Insert the considered topic and the associated forum into the context\n        topic = self.get_topic()\n        context['topic'] = topic\n        context['forum'] = topic.forum\n\n        # Handles the case when a poll is associated to the topic\n        try:\n            if hasattr(topic, 'poll') and topic.poll.options.exists():\n                context['poll'] = topic.poll\n                context['poll_form'] = self.poll_form_class(poll=topic.poll)\n                context['view_results_action'] = self.request.GET.get('view_results', None)\n                context['change_vote_action'] = self.request.GET.get('change_vote', None)\n        except ObjectDoesNotExist:  # pragma: no cover\n            pass\n\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the attachment cache for the current view.", "response": "def init_attachment_cache(self):\n        \"\"\" Initializes the attachment cache for the current view. \"\"\"\n        if self.request.method == 'GET':\n            # Invalidates previous attachments\n            attachments_cache.delete(self.get_attachments_cache_key(self.request))\n            return\n\n        # Try to restore previous uploaded attachments if applicable\n        attachments_cache_key = self.get_attachments_cache_key(self.request)\n        restored_attachments_dict = attachments_cache.get(attachments_cache_key)\n        if restored_attachments_dict:\n            restored_attachments_dict.update(self.request.FILES)\n            self.request._files = restored_attachments_dict\n\n        # Updates the attachment cache if files are available\n        if self.request.FILES:\n            attachments_cache.set(attachments_cache_key, self.request.FILES)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_post_form_kwargs(self):\n        kwargs = {\n            'user': self.request.user,\n            'forum': self.get_forum(),\n            'topic': self.get_topic(),\n        }\n\n        post = self.get_post()\n        if post:\n            kwargs.update({'instance': post})\n\n        if self.request.method in ('POST', 'PUT'):\n            kwargs.update({\n                'data': self.request.POST,\n                'files': self.request.FILES,\n            })\n        return kwargs", "response": "Returns the keyword arguments for instantiating the post form."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an instance of the attachment formset class to be used in the view.", "response": "def get_attachment_formset(self, formset_class):\n        \"\"\" Returns an instance of the attachment formset to be used in the view. \"\"\"\n        if (\n            self.request.forum_permission_handler.can_attach_files(\n                self.get_forum(), self.request.user,\n            )\n        ):\n            return formset_class(**self.get_attachment_formset_kwargs())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the keyword arguments for instantiating the attachment formset.", "response": "def get_attachment_formset_kwargs(self):\n        \"\"\" Returns the keyword arguments for instantiating the attachment formset. \"\"\"\n        kwargs = {\n            'prefix': 'attachment',\n        }\n\n        if self.request.method in ('POST', 'PUT'):\n            kwargs.update({\n                'data': self.request.POST,\n                'files': self.request.FILES,\n            })\n        else:\n            post = self.get_post()\n            attachment_queryset = Attachment.objects.filter(post=post)\n            kwargs.update({\n                'queryset': attachment_queryset,\n            })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_context_data(self, **kwargs):\n        context = kwargs\n        if 'view' not in context:\n            context['view'] = self\n\n        # Insert the considered forum, topic and post into the context\n        context['forum'] = self.get_forum()\n        context['topic'] = self.get_topic()\n        context['post'] = self.get_post()\n\n        # Handles the preview of the attachments\n        if context['attachment_formset']:\n            if hasattr(self, 'attachment_preview') and self.attachment_preview:\n                context['attachment_preview'] = self.attachment_preview\n                attachments = []\n                # Computes the list of the attachment file names that should be attached\n                # to the forum post being created or updated\n                for form in context['attachment_formset'].forms:\n                    if (\n                        form['DELETE'].value() or\n                        (not form['file'].html_name in self.request._files and not form.instance.pk)\n                    ):\n                        continue\n                    attachments.append(\n                        (\n                            form,\n                            self.request._files[form['file'].html_name].name if not form.instance\n                            else form.instance.filename\n                        )\n                    )\n                context['attachment_file_previews'] = attachments\n\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_forum(self):\n        pk = self.kwargs.get(self.forum_pk_url_kwarg, None)\n        if not pk:  # pragma: no cover\n            # This should never happen\n            return\n        if not hasattr(self, '_forum'):\n            self._forum = get_object_or_404(Forum, pk=pk)\n        return self._forum", "response": "Returns the considered forum."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_topic(self):\n        pk = self.kwargs.get(self.topic_pk_url_kwarg, None)\n        if not pk:\n            return\n        if not hasattr(self, '_topic'):\n            self._topic = get_object_or_404(Topic, pk=pk)\n        return self._topic", "response": "Returns the considered topic if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the considered post if applicable.", "response": "def get_post(self):\n        \"\"\" Returns the considered post if applicable. \"\"\"\n        pk = self.kwargs.get(self.post_pk_url_kwarg, None)\n        if not pk:\n            return\n        if not hasattr(self, '_forum_post'):\n            self._forum_post = get_object_or_404(Post, pk=pk)\n        return self._forum_post"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef form_valid(self, post_form, attachment_formset, **kwargs):\n        save_attachment_formset = attachment_formset is not None \\\n            and not self.preview\n\n        if self.preview:\n            return self.render_to_response(\n                self.get_context_data(\n                    preview=True, post_form=post_form, attachment_formset=attachment_formset,\n                    **kwargs\n                ),\n            )\n\n        # This is not a preview ; the object is going to be saved\n        self.forum_post = post_form.save()\n\n        if save_attachment_formset:\n            attachment_formset.post = self.forum_post\n            attachment_formset.save()\n\n        messages.success(self.request, self.success_message)\n        if not self.forum_post.approved:\n            messages.warning(self.request, self.approval_required_message)\n\n        return HttpResponseRedirect(self.get_success_url())", "response": "Called if all forms are valid. Creates a Post instance along with associated attachments if required and redirects to the success page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_invalid(self, post_form, attachment_formset, **kwargs):\n        if (\n            attachment_formset and\n            not attachment_formset.is_valid() and\n            len(attachment_formset.errors)\n        ):\n            messages.error(self.request, self.attachment_formset_general_error_message)\n\n        return self.render_to_response(\n            self.get_context_data(\n                post_form=post_form, attachment_formset=attachment_formset, **kwargs\n            ),\n        )", "response": "Processes invalid forms.\n\n        Called if one of the forms is invalid. Re-renders the context data with the data-filled\n        forms and errors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_poll_option_formset(self, formset_class):\n        if self.request.forum_permission_handler.can_create_polls(\n            self.get_forum(), self.request.user,\n        ):\n            return formset_class(**self.get_poll_option_formset_kwargs())", "response": "Returns an instance of the poll option formset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_poll_option_formset_kwargs(self):\n        kwargs = {\n            'prefix': 'poll',\n        }\n\n        if self.request.method in ('POST', 'PUT'):\n            kwargs.update({\n                'data': self.request.POST,\n                'files': self.request.FILES,\n            })\n        else:\n            topic = self.get_topic()\n            poll_option_queryset = TopicPollOption.objects.filter(poll__topic=topic)\n            kwargs.update({\n                'queryset': poll_option_queryset,\n            })\n        return kwargs", "response": "Returns the keyword arguments for instantiating the poll option formset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n\n        # Handles the preview of the poll\n        if context['poll_option_formset']:\n            if hasattr(self, 'poll_preview') and self.poll_preview:\n                context['poll_preview'] = self.poll_preview\n                context['poll_options_previews'] = filter(\n                    lambda f: f['text'].value() and not f['DELETE'].value(),\n                    context['poll_option_formset'].forms,\n                )\n\n        return context", "response": "Returns the context data to provide to the template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_invalid(self, post_form, attachment_formset, poll_option_formset, **kwargs):\n        poll_errors = [k for k in post_form.errors.keys() if k.startswith('poll_')]\n        if (\n            poll_errors or\n            (\n                poll_option_formset and\n                not poll_option_formset.is_valid() and\n                len(post_form.cleaned_data['poll_question'])\n            )\n        ):\n            messages.error(self.request, self.poll_option_formset_general_error_message)\n\n        return super().form_invalid(\n            post_form, attachment_formset, poll_option_formset=poll_option_formset, **kwargs)", "response": "Checks if the poll option formset is valid and if so processes the invalid forms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_success_url(self):\n        if not self.forum_post.approved:\n            return reverse(\n                'forum:forum',\n                kwargs={\n                    'slug': self.forum_post.topic.forum.slug,\n                    'pk': self.forum_post.topic.forum.pk,\n                },\n            )\n        return reverse(\n            'forum_conversation:topic',\n            kwargs={\n                'forum_slug': self.forum_post.topic.forum.slug,\n                'forum_pk': self.forum_post.topic.forum.pk,\n                'slug': self.forum_post.topic.slug,\n                'pk': self.forum_post.topic.pk,\n            },\n        )", "response": "Returns the URL to redirect the user to upon valid form processing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the user can edit the object.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permission check. \"\"\"\n        return self.request.forum_permission_handler.can_edit_post(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the context data to provide to the template.", "response": "def get_context_data(self, **kwargs):\n        \"\"\" Returns the context data to provide to the template. \"\"\"\n        context = super().get_context_data(**kwargs)\n        topic = self.get_topic()\n\n        # Add the previous posts to the context\n        previous_posts = (\n            topic.posts.filter(approved=True)\n            .select_related('poster', 'updated_by')\n            .prefetch_related('attachments', 'poster__forum_profile')\n            .order_by('-created')\n        )\n        previous_posts = previous_posts[:machina_settings.TOPIC_REVIEW_POSTS_NUMBER]\n        context['previous_posts'] = previous_posts\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the URL to redirect the user to upon valid form processing.", "response": "def get_success_url(self):\n        \"\"\" Returns the URL to redirect the user to upon valid form processing. \"\"\"\n        return '{0}?post={1}#{1}'.format(\n            reverse(\n                'forum_conversation:topic',\n                kwargs={\n                    'forum_slug': self.forum_post.topic.forum.slug,\n                    'forum_pk': self.forum_post.topic.forum.pk,\n                    'slug': self.forum_post.topic.slug,\n                    'pk': self.forum_post.topic.pk,\n                },\n            ),\n            self.forum_post.pk,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the user can add the object.", "response": "def perform_permissions_check(self, user, obj, perms):\n        \"\"\" Performs the permission check. \"\"\"\n        return self.request.forum_permission_handler.can_add_post(obj, user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the URL to redirect the user to upon valid form processing.", "response": "def get_success_url(self):\n        \"\"\" Returns the URL to redirect the user to upon valid form processing. \"\"\"\n        messages.success(self.request, self.success_message)\n\n        if self.object.is_topic_head and self.object.is_topic_tail:\n            return reverse(\n                'forum:forum',\n                kwargs={\n                    'slug': self.object.topic.forum.slug, 'pk': self.object.topic.forum.pk,\n                },\n            )\n\n        return reverse(\n            'forum_conversation:topic',\n            kwargs={\n                'forum_slug': self.object.topic.forum.slug,\n                'forum_pk': self.object.topic.forum.pk,\n                'slug': self.object.topic.slug,\n                'pk': self.object.topic.pk,\n            },\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perform_permissions_check(self, user, obj, perms):\n        return self.request.forum_permission_handler.can_delete_post(obj, user)", "response": "Checks if the user can delete the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_exts(self,string):\n\n        # If the user hasn't disabled it, we will detect image extensions, such as .png, .jpg, etc.\n        # We'll remove them from the string before hashing.\n        # This ensures that /Bear.png and /Bear.bmp will send back the same image, in different formats.\n\n        if string.lower().endswith(('.png','.gif','.jpg','.bmp','.jpeg','.ppm','.datauri')):\n            format = string[string.rfind('.') +1 :len(string)]\n            if format.lower() == 'jpg':\n                    format = 'jpeg'\n            self.format = format\n            string = string[0:string.rfind('.')]\n        return string", "response": "Removes the extensions from the string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_hashes(self,count):\n        for i in range(0,count):\n             #Get 1/numblocks of the hash\n             blocksize = int(len(self.hexdigest) / count)\n             currentstart = (1 + i) * blocksize - blocksize\n             currentend = (1 +i) * blocksize\n             self.hasharray.append(int(self.hexdigest[currentstart:currentend],16))\n\n        # Workaround for adding more sets in 2019.\n        # We run out of blocks, because we use some for each set, whether it's called or not.\n        # I can't easily change this without invalidating every hash so far :/\n        # This shouldn't reduce the security since it should only draw from one set of these in practice.\n        self.hasharray = self.hasharray + self.hasharray", "response": "Create the hash array for the given count"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of files from each directory in path and choose one from each.", "response": "def _get_list_of_files(self,path):\n        \"\"\"\n        Go through each subdirectory of `path`, and choose one file from each to use in our hash.\n        Continue to increase self.iter, so we use a different 'slot' of randomness each time.\n        \"\"\"\n        chosen_files = []\n\n        # Get a list of all subdirectories\n        directories = []\n        for root, dirs, files in natsort.natsorted(os.walk(path, topdown=False)):\n            for name in dirs:\n                if name[:1] is not '.':\n                    directories.append(os.path.join(root, name))\n                    directories = natsort.natsorted(directories)\n\n        # Go through each directory in the list, and choose one file from each.\n        # Add this file to our master list of robotparts.\n        for directory in directories:\n            files_in_dir = []\n            for imagefile in natsort.natsorted(os.listdir(directory)):\n                files_in_dir.append(os.path.join(directory,imagefile))\n                files_in_dir = natsort.natsorted(files_in_dir)\n\n            # Use some of our hash bits to choose which file\n            element_in_list = self.hasharray[self.iter] % len(files_in_dir)\n            chosen_files.append(files_in_dir[element_in_list])\n            self.iter += 1\n\n        return chosen_files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassembling the robot image into a single entry.", "response": "def assemble(self,roboset=None,color=None,format=None,bgset=None,sizex=300,sizey=300):\n        \"\"\"\n        Build our Robot!\n        Returns the robot image itself.\n        \"\"\"\n\n        # Allow users to manually specify a robot 'set' that they like.\n        # Ensure that this is one of the allowed choices, or allow all\n        # If they don't set one, take the first entry from sets above.\n\n        if roboset == 'any':\n            roboset = self.sets[self.hasharray[1] % len(self.sets) ]\n        elif roboset in self.sets:\n            roboset = roboset\n        else:\n            roboset = self.sets[0]\n\n\n        # Only set1 is setup to be color-seletable. The others don't have enough pieces in various colors.\n        # This could/should probably be expanded at some point..\n        # Right now, this feature is almost never used. ( It was < 44 requests this year, out of 78M reqs )\n\n        if roboset == 'set1':\n            if color in self.colors:\n                roboset = 'set1/' + color\n            else:\n                randomcolor = self.colors[self.hasharray[0] % len(self.colors) ]\n                roboset = 'set1/' + randomcolor\n\n        # If they specified a background, ensure it's legal, then give it to them.\n        if bgset in self.bgsets:\n            bgset = bgset\n        elif bgset == 'any':\n            bgset = self.bgsets[ self.hasharray[2] % len(self.bgsets) ]\n\n        # If we set a format based on extension earlier, use that. Otherwise, PNG.\n        if format is None:\n            format = self.format\n\n        # Each directory in our set represents one piece of the Robot, such as the eyes, nose, mouth, etc.\n\n        # Each directory is named with two numbers - The number before the # is the sort order.\n        # This ensures that they always go in the same order when choosing pieces, regardless of OS.\n\n        # The second number is the order in which to apply the pieces.\n        # For instance, the head has to go down BEFORE the eyes, or the eyes would be hidden.\n\n        # First, we'll get a list of parts of our robot.\n\n\n        roboparts = self._get_list_of_files(self.resourcedir + 'sets/' + roboset)\n        # Now that we've sorted them by the first number, we need to sort each sub-category by the second.\n        roboparts.sort(key=lambda x: x.split(\"#\")[1])\n        if bgset is not None:\n                bglist = []\n                backgrounds = natsort.natsorted(os.listdir(self.resourcedir + 'backgrounds/' + bgset))\n                backgrounds.sort()\n                for ls in backgrounds:\n                        if not ls.startswith(\".\"):\n                                bglist.append(self.resourcedir + 'backgrounds/' + bgset + \"/\" + ls)\n                background = bglist[self.hasharray[3] % len(bglist)]\n\n        # Paste in each piece of the Robot.\n        roboimg = Image.open(roboparts[0])\n        roboimg = roboimg.resize((1024,1024))\n        for png in roboparts:\n                img = Image.open(png)\n                img = img.resize((1024,1024))\n                roboimg.paste(img,(0,0),img)\n\n        # If we're a BMP, flatten the image.\n        if format == 'bmp':\n                #Flatten bmps\n                r, g, b, a = roboimg.split()\n                roboimg = Image.merge(\"RGB\", (r, g, b))\n\n        if bgset is not None:\n                bg = Image.open(background)\n                bg = bg.resize((1024,1024))\n                bg.paste(roboimg,(0,0),roboimg)\n                roboimg = bg\n\n        self.img = roboimg.resize((sizex,sizey),Image.ANTIALIAS)\n        self.format = format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncollect all symbols from a list of modules.", "response": "def collect_members(module_to_name):\n  \"\"\"Collect all symbols from a list of modules.\n\n  Args:\n    module_to_name: Dictionary mapping modules to short names.\n\n  Returns:\n    Dictionary mapping name to (fullname, member) pairs.\n  \"\"\"\n  members = {}\n  for module, module_name in module_to_name.items():\n    all_names = getattr(module, \"__all__\", None)\n    for name, member in inspect.getmembers(module):\n      if ((inspect.isfunction(member) or inspect.isclass(member)) and\n          not _always_drop_symbol_re.match(name) and\n          (all_names is None or name in all_names)):\n        fullname = '%s.%s' % (module_name, name)\n        if name in members:\n          other_fullname, other_member = members[name]\n          if member is not other_member:\n            raise RuntimeError(\"Short name collision between %s and %s\" %\n                               (fullname, other_fullname))\n          if len(fullname) == len(other_fullname):\n            raise RuntimeError(\"Can't decide whether to use %s or %s for %s: \"\n                               \"both full names have length %d\" %\n                               (fullname, other_fullname, name, len(fullname)))\n          if len(fullname) > len(other_fullname):\n            continue  # Use the shorter full name\n        members[name] = fullname, member\n  return members"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning a full member name into an anchor.", "response": "def _get_anchor(module_to_name, fullname):\n  \"\"\"Turn a full member name into an anchor.\n\n  Args:\n    module_to_name: Dictionary mapping modules to short names.\n    fullname: Fully qualified name of symbol.\n\n  Returns:\n    HTML anchor string.  The longest module name prefix of fullname is\n    removed to make the anchor.\n\n  Raises:\n    ValueError: If fullname uses characters invalid in an anchor.\n  \"\"\"\n  if not _anchor_re.match(fullname):\n    raise ValueError(\"'%s' is not a valid anchor\" % fullname)\n  anchor = fullname\n  for module_name in module_to_name.values():\n    if fullname.startswith(module_name + \".\"):\n      rest = fullname[len(module_name)+1:]\n      # Use this prefix iff it is longer than any found before\n      if len(anchor) > len(rest):\n        anchor = rest\n  return anchor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a list of libraries to disk.", "response": "def write_libraries(dir, libraries):\n  \"\"\"Write a list of libraries to disk.\n\n  Args:\n    dir: Output directory.\n    libraries: List of (filename, library) pairs.\n  \"\"\"\n  files = [open(os.path.join(dir, k), \"w\") for k, _ in libraries]\n  # Document mentioned symbols for all libraries\n  for f, (_, v) in zip(files, libraries):\n    v.write_markdown_to_file(f)\n  # Document symbols that no library mentioned.  We do this after writing\n  # out all libraries so that earlier libraries know what later libraries\n  # documented.\n  for f, (_, v) in zip(files, libraries):\n    v.write_other_members(f)\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting this index to file f.", "response": "def write_markdown_to_file(self, f):\n    \"\"\"Writes this index to file `f`.\n\n    The output is formatted as an unordered list. Each list element\n    contains the title of the library, followed by a list of symbols\n    in that library hyperlinked to the corresponding anchor in that\n    library.\n\n    Args:\n      f: The output file.\n    \"\"\"\n    print(\"---\", file=f)\n    print(\"---\", file=f)\n    print(\"<!-- This file is machine generated: DO NOT EDIT! -->\", file=f)\n    print(\"\", file=f)\n    print(\"# TensorFlow Python reference documentation\", file=f)\n    print(\"\", file=f)\n    fullname_f = lambda name: self._members[name][0]\n    anchor_f = lambda name: _get_anchor(self._module_to_name, fullname_f(name))\n\n    for filename, library in self._filename_to_library_map:\n      sorted_names = sorted(library.mentioned, key=lambda x: (str.lower(x), x))\n      member_names = [n for n in sorted_names if n in self._members]\n      # TODO: This is a hack that should be removed as soon as the website code\n      # allows it.\n      full_filename = self._path_prefix + filename\n      links = [\"[`%s`](%s#%s)\" % (name, full_filename[:-3], anchor_f(name))\n               for name in member_names]\n      if links:\n        print(\"* **[%s](%s)**:\" % (library.title, full_filename[:-3]), file=f)\n        for link in links:\n          print(\"  * %s\" % link, file=f)\n        print(\"\", file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _should_include_member(self, name, member):\n    # Always exclude symbols matching _always_drop_symbol_re.\n    if _always_drop_symbol_re.match(name):\n      return False\n    # Finally, exclude any specifically-excluded symbols.\n    if name in self._exclude_symbols:\n      return False\n    return True", "response": "Returns True if this member should be included in the document False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_imported_modules(self, module):\n    for name, member in inspect.getmembers(module):\n      if inspect.ismodule(member):\n        yield name, member", "response": "Returns the list of modules imported from module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of class members to document in cls.", "response": "def get_class_members(self, cls_name, cls):\n    \"\"\"Returns the list of class members to document in `cls`.\n\n    This function filters the class member to ONLY return those\n    defined by the class.  It drops the inherited ones.\n\n    Args:\n      cls_name: Qualified name of `cls`.\n      cls: An inspect object of type 'class'.\n\n    Yields:\n      name, member tuples.\n    \"\"\"\n    for name, member in inspect.getmembers(cls):\n      # Only show methods and properties presently.  In Python 3,\n      # methods register as isfunction.\n      is_method = inspect.ismethod(member) or inspect.isfunction(member)\n      if not (is_method or isinstance(member, property)):\n        continue\n      if ((is_method and member.__name__ == \"__init__\")\n          or self._should_include_member(name, member)):\n        yield name, (\"%s.%s\" % (cls_name, name), member)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a function returns a string representing its args.", "response": "def _generate_signature_for_function(self, func):\n    \"\"\"Given a function, returns a string representing its args.\"\"\"\n    args_list = []\n    argspec = inspect.getargspec(func)\n    first_arg_with_default = (\n        len(argspec.args or []) - len(argspec.defaults or []))\n    for arg in argspec.args[:first_arg_with_default]:\n      if arg == \"self\":\n        # Python documentation typically skips `self` when printing method\n        # signatures.\n        continue\n      args_list.append(arg)\n\n    # TODO(mrry): This is a workaround for documenting signature of\n    # functions that have the @contextlib.contextmanager decorator.\n    # We should do something better.\n    if argspec.varargs == \"args\" and argspec.keywords == \"kwds\":\n      original_func = func.__closure__[0].cell_contents\n      return self._generate_signature_for_function(original_func)\n\n    if argspec.defaults:\n      for arg, default in zip(\n          argspec.args[first_arg_with_default:], argspec.defaults):\n        if callable(default):\n          args_list.append(\"%s=%s\" % (arg, default.__name__))\n        else:\n          args_list.append(\"%s=%r\" % (arg, default))\n    if argspec.varargs:\n      args_list.append(\"*\" + argspec.varargs)\n    if argspec.keywords:\n      args_list.append(\"**\" + argspec.keywords)\n    return \"(\" + \", \".join(args_list) + \")\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the minimum indent of the given docstring.", "response": "def _remove_docstring_indent(self, docstring):\n    \"\"\"Remove indenting.\n\n    We follow Python's convention and remove the minimum indent of the lines\n    after the first, see:\n    https://www.python.org/dev/peps/pep-0257/#handling-docstring-indentation\n    preserving relative indentation.\n\n    Args:\n      docstring: A docstring.\n\n    Returns:\n      A list of strings, one per line, with the minimum indent stripped.\n    \"\"\"\n    docstring = docstring or \"\"\n    lines = docstring.strip().split(\"\\n\")\n\n    min_indent = len(docstring)\n    for l in lines[1:]:\n      l = l.rstrip()\n      if l:\n        i = 0\n        while i < len(l) and l[i] == \" \":\n          i += 1\n        if i < min_indent: min_indent = i\n    for i in range(1, len(lines)):\n      l = lines[i].rstrip()\n      if len(l) >= min_indent:\n        l = l[min_indent:]\n      lines[i] = l\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _print_formatted_docstring(self, docstring, f):\n    lines = self._remove_docstring_indent(docstring)\n\n    # Output the lines, identifying \"Args\" and other section blocks.\n    i = 0\n\n    def _at_start_of_section():\n      \"\"\"Returns the header if lines[i] is at start of a docstring section.\"\"\"\n      l = lines[i]\n      match = _section_re.match(l)\n      if match and i + 1 < len(\n          lines) and lines[i + 1].startswith(\" \"):\n        return match.group(1)\n      else:\n        return None\n\n    while i < len(lines):\n      l = lines[i]\n\n      section_header = _at_start_of_section()\n      if section_header:\n        if i == 0 or lines[i-1]:\n          print(\"\", file=f)\n        # Use at least H4 to keep these out of the TOC.\n        print(\"##### \" + section_header + \":\", file=f)\n        print(\"\", file=f)\n        i += 1\n        outputting_list = False\n        while i < len(lines):\n          l = lines[i]\n          # A new section header terminates the section.\n          if _at_start_of_section():\n            break\n          match = _arg_re.match(l)\n          if match:\n            if not outputting_list:\n              # We need to start a list. In Markdown, a blank line needs to\n              # precede a list.\n              print(\"\", file=f)\n              outputting_list = True\n            suffix = l[len(match.group()):].lstrip()\n            print(\"*  <b>`\" + match.group(1) + \"`</b>: \" + suffix, file=f)\n          else:\n            # For lines that don't start with _arg_re, continue the list if it\n            # has enough indentation.\n            outputting_list &= l.startswith(\"   \")\n            print(l, file=f)\n          i += 1\n      else:\n        print(l, file=f)\n        i += 1", "response": "Formats the given docstring as Markdown and prints it to f."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the given function to f.", "response": "def _print_function(self, f, prefix, fullname, func):\n    \"\"\"Prints the given function to `f`.\"\"\"\n    heading = prefix + \" `\" + fullname\n    if not isinstance(func, property):\n      heading += self._generate_signature_for_function(func)\n    heading += \"` {#%s}\" % _get_anchor(self._module_to_name, fullname)\n    print(heading, file=f)\n    print(\"\", file=f)\n    self._print_formatted_docstring(inspect.getdoc(func), f)\n    print(\"\", file=f)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_member_markdown_to_file(self, f, prefix, name, member):\n    if (inspect.isfunction(member) or inspect.ismethod(member) or\n        isinstance(member, property)):\n      print(\"- - -\", file=f)\n      print(\"\", file=f)\n      self._print_function(f, prefix, name, member)\n      print(\"\", file=f)\n    elif inspect.isclass(member):\n      print(\"- - -\", file=f)\n      print(\"\", file=f)\n      print(\"%s `class %s` {#%s}\" % (prefix, name,\n                                     _get_anchor(self._module_to_name, name)),\n            file=f)\n      print(\"\", file=f)\n      self._write_class_markdown_to_file(f, name, member)\n      print(\"\", file=f)\n    else:\n      raise RuntimeError(\"Member %s has unknown type %s\" % (name, type(member)))", "response": "Print a member to f."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the class docstring to f.", "response": "def _write_class_markdown_to_file(self, f, name, cls):\n    \"\"\"Write the class doc to `f`.\n\n    Args:\n      f: File to write to.\n      prefix: Prefix for names.\n      cls: class object.\n      name: name to use.\n    \"\"\"\n    # Build the list of class methods to document.\n    methods = dict(self.get_class_members(name, cls))\n    # Used later to check if any methods were called out in the class\n    # docstring.\n    num_methods = len(methods)\n    try:\n      self._write_docstring_markdown_to_file(f, \"####\", inspect.getdoc(cls),\n                                             methods, {})\n    except ValueError as e:\n      raise ValueError(str(e) + \" in class `%s`\" % cls.__name__)\n\n    # If some methods were not described, describe them now if they are\n    # defined by the class itself (not inherited).  If NO methods were\n    # described, describe all methods.\n    #\n    # TODO(touts): when all methods have been categorized make it an error\n    # if some methods are not categorized.\n    any_method_called_out = (len(methods) != num_methods)\n    if any_method_called_out:\n      other_methods = {n: m for n, m in methods.items() if n in cls.__dict__}\n      if other_methods:\n        print(\"\\n#### Other Methods\", file=f)\n    else:\n      other_methods = methods\n    for name in sorted(other_methods):\n      self._write_member_markdown_to_file(f, \"####\", *other_methods[name])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints this library to file f.", "response": "def write_markdown_to_file(self, f):\n    \"\"\"Prints this library to file `f`.\n\n    Args:\n      f: File to write to.\n\n    Returns:\n      Dictionary of documented members.\n    \"\"\"\n    print(\"---\", file=f)\n    print(\"---\", file=f)\n    print(\"<!-- This file is machine generated: DO NOT EDIT! -->\", file=f)\n    print(\"\", file=f)\n    # TODO(touts): Do not insert these.  Let the doc writer put them in\n    # the module docstring explicitly.\n    print(\"#\", self._title, file=f)\n    if self._prefix:\n      print(self._prefix, file=f)\n    print(\"[TOC]\", file=f)\n    print(\"\", file=f)\n    if self._module is not None:\n      self._write_module_markdown_to_file(f, self._module)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the leftover members to f.", "response": "def write_other_members(self, f, catch_all=False):\n    \"\"\"Writes the leftover members to `f`.\n\n    Args:\n      f: File to write to.\n      catch_all: If true, document all missing symbols from any module.\n        Otherwise, document missing symbols from just this module.\n    \"\"\"\n    if catch_all:\n      names = self._members.items()\n    else:\n      names = inspect.getmembers(self._module)\n    leftovers = []\n    for name, _ in names:\n      if name in self._members and name not in self._documented:\n        leftovers.append(name)\n    if leftovers:\n      print(\"%s: undocumented members: %d\" % (self._title, len(leftovers)))\n      print(\"\\n## Other Functions and Classes\", file=f)\n      for name in sorted(leftovers):\n        print(\"  %s\" % name)\n        self._documented.add(name)\n        self._mentioned.add(name)\n        self._write_member_markdown_to_file(f, \"###\", *self._members[name])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assert_no_leftovers(self):\n    leftovers = []\n    for name in self._members.keys():\n      if name in self._members and name not in self._documented:\n        leftovers.append(name)\n    if leftovers:\n      raise RuntimeError(\"%s: undocumented members: %s\" %\n                         (self._title, \", \".join(leftovers)))", "response": "Generate an error if there are undocumented members."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart an HTTP server for exposing the metrics endpoint", "response": "def start_http_server(self, port, host='0.0.0.0', endpoint=None):\n        \"\"\"\n        Start an HTTP server for exposing the metrics, if the\n        `should_start_http_server` function says we should, otherwise just return.\n        Uses the implementation from `prometheus_client` rather than a Flask app.\n\n        :param port: the HTTP port to expose the metrics endpoint on\n        :param host: the HTTP host to listen on (default: `0.0.0.0`)\n        :param endpoint: **ignored**, the HTTP server will respond on any path\n        \"\"\"\n\n        if self.should_start_http_server():\n            pc_start_http_server(port, host, registry=self.registry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_endpoint(self, path, app=None):\n\n        if is_running_from_reloader() and not os.environ.get('DEBUG_METRICS'):\n            return\n\n        if app is None:\n            app = self.app or current_app\n\n        @app.route(path)\n        @self.do_not_track()\n        def prometheus_metrics():\n            # import these here so they don't clash with our own multiprocess module\n            from prometheus_client import multiprocess, CollectorRegistry\n\n            if 'prometheus_multiproc_dir' in os.environ:\n                registry = CollectorRegistry()\n            else:\n                registry = self.registry\n\n            if 'name[]' in request.args:\n                registry = registry.restricted_registry(request.args.getlist('name[]'))\n\n            if 'prometheus_multiproc_dir' in os.environ:\n                multiprocess.MultiProcessCollector(registry)\n\n            headers = {'Content-Type': CONTENT_TYPE_LATEST}\n            return generate_latest(registry), 200, headers", "response": "Register the metrics endpoint on the Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting an HTTP server for exposing the metrics.", "response": "def start_http_server(self, port, host='0.0.0.0', endpoint='/metrics'):\n        \"\"\"\n        Start an HTTP server for exposing the metrics.\n        This will be an individual Flask application,\n        not the one registered with this class.\n\n        :param port: the HTTP port to expose the metrics endpoint on\n        :param host: the HTTP host to listen on (default: `0.0.0.0`)\n        :param endpoint: the URL path to expose the endpoint on\n            (default: `/metrics`)\n        \"\"\"\n\n        if is_running_from_reloader():\n            return\n\n        app = Flask('prometheus-flask-exporter-%d' % port)\n        self.register_endpoint(endpoint, app)\n\n        def run_app():\n            app.run(host=host, port=port)\n\n        thread = threading.Thread(target=run_app)\n        thread.setDaemon(True)\n        thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports the default metrics for the current application.", "response": "def export_defaults(self, buckets=None, group_by='path',\n                        prefix='flask', app=None, **kwargs):\n        \"\"\"\n        Export the default metrics:\n            - HTTP request latencies\n            - Number of HTTP requests\n\n        :param buckets: the time buckets for request latencies\n            (will use the default when `None`)\n        :param group_by: group default HTTP metrics by\n            this request property, like `path`, `endpoint`, `rule`, etc.\n            (defaults to `path`)\n        :param prefix: prefix to start the default metrics names with\n            or `NO_PREFIX` (to skip prefix)\n        :param app: the Flask application\n        \"\"\"\n\n        if app is None:\n            app = self.app or current_app\n\n        if not prefix:\n            prefix = self._defaults_prefix or 'flask'\n\n        # use the default buckets from prometheus_client if not given here\n        buckets_as_kwargs = {}\n        if buckets is not None:\n            buckets_as_kwargs['buckets'] = buckets\n\n        if kwargs.get('group_by_endpoint') is True:\n            warnings.warn(\n                'The `group_by_endpoint` argument of '\n                '`PrometheusMetrics.export_defaults` is deprecated since 0.4.0, '\n                'please use the new `group_by` argument.', DeprecationWarning\n            )\n\n            duration_group = 'endpoint'\n\n        elif group_by:\n            duration_group = group_by\n\n        else:\n            duration_group = 'path'\n\n        if callable(duration_group):\n            duration_group_name = duration_group.__name__\n\n        else:\n            duration_group_name = duration_group\n\n        if prefix == NO_PREFIX:\n            prefix = \"\"\n        else:\n            prefix = prefix + \"_\"\n\n        histogram = Histogram(\n            '%shttp_request_duration_seconds' % prefix,\n            'Flask HTTP request duration in seconds',\n            ('method', duration_group_name, 'status'),\n            registry=self.registry,\n            **buckets_as_kwargs\n        )\n\n        counter = Counter(\n            '%shttp_request_total' % prefix,\n            'Total number of HTTP requests',\n            ('method', 'status'),\n            registry=self.registry\n        )\n\n        self.info(\n            '%sexporter_info' % prefix,\n            'Information about the Prometheus Flask exporter',\n            version=self.version\n        )\n\n        def before_request():\n            request.prom_start_time = default_timer()\n\n        def after_request(response):\n            if hasattr(request, 'prom_do_not_track'):\n                return response\n\n            if hasattr(request, 'prom_start_time'):\n                total_time = max(default_timer() - request.prom_start_time, 0)\n\n                if callable(duration_group):\n                    group = duration_group(request)\n                else:\n                    group = getattr(request, duration_group)\n\n                histogram.labels(\n                    request.method, group, response.status_code\n                ).observe(total_time)\n\n            counter.labels(request.method, response.status_code).inc()\n\n            return response\n\n        app.before_request(before_request)\n        app.after_request(after_request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a histogram with the given name description and labels.", "response": "def histogram(self, name, description, labels=None, **kwargs):\n        \"\"\"\n        Use a Histogram to track the execution time and invocation count\n        of the method.\n\n        :param name: the name of the metric\n        :param description: the description of the metric\n        :param labels: a dictionary of `{labelname: callable_or_value}` for labels\n        :param kwargs: additional keyword arguments for creating the Histogram\n        \"\"\"\n\n        return self._track(\n            Histogram,\n            lambda metric, time: metric.observe(time),\n            kwargs, name, description, labels,\n            registry=self.registry\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing a Summary to track the execution time and invocation count of the method.", "response": "def summary(self, name, description, labels=None, **kwargs):\n        \"\"\"\n        Use a Summary to track the execution time and invocation count\n        of the method.\n\n        :param name: the name of the metric\n        :param description: the description of the metric\n        :param labels: a dictionary of `{labelname: callable_or_value}` for labels\n        :param kwargs: additional keyword arguments for creating the Summary\n        \"\"\"\n\n        return self._track(\n            Summary,\n            lambda metric, time: metric.observe(time),\n            kwargs, name, description, labels,\n            registry=self.registry\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gauge(self, name, description, labels=None, **kwargs):\n\n        return self._track(\n            Gauge,\n            lambda metric, time: metric.dec(),\n            kwargs, name, description, labels,\n            registry=self.registry,\n            before=lambda metric: metric.inc()\n        )", "response": "Use a Gauge to track the number of invocations in progress for the method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing a Counter to track the total number of invocations of the method.", "response": "def counter(self, name, description, labels=None, **kwargs):\n        \"\"\"\n        Use a Counter to track the total number of invocations of the method.\n\n        :param name: the name of the metric\n        :param description: the description of the metric\n        :param labels: a dictionary of `{labelname: callable_or_value}` for labels\n        :param kwargs: additional keyword arguments for creating the Counter\n        \"\"\"\n\n        return self._track(\n            Counter,\n            lambda metric, time: metric.inc(),\n            kwargs, name, description, labels,\n            registry=self.registry\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreport any information as a Prometheus metric.", "response": "def info(self, name, description, labelnames=None, labelvalues=None, **labels):\n        \"\"\"\n        Report any information as a Prometheus metric.\n        This will create a `Gauge` with the initial value of 1.\n\n        The easiest way to use it is:\n\n            metrics = PrometheusMetrics(app)\n            metrics.info(\n                'app_info', 'Application info',\n                version='1.0', major=1, minor=0\n            )\n\n        If the order of the labels matters:\n\n            metrics = PrometheusMetrics(app)\n            metrics.info(\n                'app_info', 'Application info',\n                ('version', 'major', 'minor'),\n                ('1.0', 1, 0)\n            )\n\n        :param name: the name of the metric\n        :param description: the description of the metric\n        :param labelnames: the names of the labels\n        :param labelvalues: the values of the labels\n        :param labels: the names and values of the labels\n        :return: the newly created `Gauge` metric\n        \"\"\"\n\n        if labels and labelnames:\n            raise ValueError(\n                'Cannot have labels defined as `dict` '\n                'and collections of names and values'\n            )\n\n        if labelnames is None and labels:\n            labelnames = labels.keys()\n\n        elif labelnames and labelvalues:\n            for idx, label_name in enumerate(labelnames):\n                labels[label_name] = labelvalues[idx]\n\n        gauge = Gauge(\n            name, description, labelnames or tuple(),\n            registry=self.registry\n        )\n\n        if labels:\n            gauge = gauge.labels(**labels)\n\n        gauge.set(1)\n\n        return gauge"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shell_config_cmd(argv):\n    \"Prints the path for the current $SHELL helper file\"\n    shell = supported_shell()\n    if shell:\n        print(pew_site / 'shell_config' / ('init.' + shell))\n    else:\n        err('Completions and prompts are unavailable for %s' %\n            repr(os.environ.get('SHELL', '')))", "response": "Prints the path for the current $SHELL helper file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a command in the given virtual environment.", "response": "def inve(env, command, *args, **kwargs):\n    \"\"\"Run a command in the given virtual environment.\n\n    Pass additional keyword arguments to ``subprocess.check_call()``.\"\"\"\n    # we don't strictly need to restore the environment, since pew runs in\n    # its own process, but it feels like the right thing to do\n    with temp_environ():\n        os.environ['VIRTUAL_ENV'] = str(workon_home / env)\n        os.environ['PATH'] = compute_path(env)\n\n        unsetenv('PYTHONHOME')\n        unsetenv('__PYVENV_LAUNCHER__')\n\n        try:\n            return check_call([command] + list(args), shell=windows, **kwargs)\n            # need to have shell=True on windows, otherwise the PYTHONPATH\n            # won't inherit the PATH\n        except OSError as e:\n            if e.errno == 2:\n                err('Unable to find', command)\n                return 2\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new environment in the current working directory.", "response": "def new_cmd(argv):\n    \"\"\"Create a new environment, in $WORKON_HOME.\"\"\"\n    parser = mkvirtualenv_argparser()\n    parser.add_argument('-a', dest='project', help='Provide a full path to a \\\nproject directory to associate with the new environment.')\n\n    parser.add_argument('envname')\n    args, rest = parser.parse_known_args(argv)\n    project = expandpath(args.project) if args.project else None\n\n    mkvirtualenv(args.envname, args.python, args.packages, project,\n                 args.requirements, rest)\n    if args.activate:\n        shell(args.envname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef workon_cmd(argv):\n    parser = argparse.ArgumentParser(prog='pew workon')\n    parser.add_argument('envname', nargs='?')\n    parser.add_argument(\n        '-n', '--no-cd', action='store_true',\n        help=('Do not change working directory to project directory after '\n              'activating virtualenv.')\n    )\n    args = parser.parse_args(argv)\n\n    def list_and_exit():\n        lsvirtualenv(False)\n        sys.exit(0)\n\n    env = parse_envname([args.envname], list_and_exit)\n\n    # Check if the virtualenv has an associated project directory and in\n    # this case, use it as the current working directory.\n    project_dir = get_project_dir(env)\n    if project_dir is None or args.no_cd:\n        project_dir = os.getcwd()\n\n    return shell(env, cwd=project_dir)", "response": "List or change working virtual environments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_cmd(argv):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-d', dest='remove', action='store_true')\n    parser.add_argument('dirs', nargs='+')\n    args = parser.parse_args(argv)\n\n    extra_paths = sitepackages_dir() / '_virtualenv_path_extensions.pth'\n    new_paths = [os.path.abspath(d) + \"\\n\" for d in args.dirs]\n    if not extra_paths.exists():\n        with extra_paths.open('w') as extra:\n            extra.write('''import sys; sys.__plen = len(sys.path)\nimport sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new)\n            ''')\n\n    def rewrite(f):\n        with extra_paths.open('r+') as extra:\n            to_write = f(extra.readlines())\n            extra.seek(0)\n            extra.truncate()\n            extra.writelines(to_write)\n\n    if args.remove:\n        rewrite(lambda ls: [line for line in ls if line not in new_paths])\n    else:\n        rewrite(lambda lines: lines[0:1] + new_paths + lines[1:])", "response": "Add the specified directories to the currently active virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow the content of the site - packages directory of the current virtualenv.", "response": "def lssitepackages_cmd(argv):\n    \"\"\"Show the content of the site-packages directory of the current virtualenv.\"\"\"\n    site = sitepackages_dir()\n    print(*sorted(site.iterdir()), sep=os.linesep)\n    extra_paths = site / '_virtualenv_path_extensions.pth'\n    if extra_paths.exists():\n        print('from _virtualenv_path_extensions.pth:')\n        with extra_paths.open() as extra:\n            print(''.join(extra.readlines()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toggleglobalsitepackages_cmd(argv):\n    quiet = argv == ['-q']\n    site = sitepackages_dir()\n    ngsp_file = site.parent / 'no-global-site-packages.txt'\n    if ngsp_file.exists():\n        ngsp_file.unlink()\n        if not quiet:\n            print('Enabled global site-packages')\n    else:\n        with ngsp_file.open('w'):\n            if not quiet:\n                print('Disabled global site-packages')", "response": "Toggle the current virtualenv between having and not having access to the global site - packages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cp_cmd(argv):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('source')\n    parser.add_argument('target', nargs='?')\n    parser.add_argument('-d', '--dont-activate', action='store_false',\n                        default=True, dest='activate', help=\"After \\\n                        creation, continue with the existing shell (don't \\\n                        activate the new environment).\")\n\n    args = parser.parse_args(argv)\n    target_name = copy_virtualenv_project(args.source, args.target)\n    if args.activate:\n        shell(target_name)", "response": "Duplicate the named virtualenv to make a new one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the \\ virtualenv project up to be associated with the project.", "response": "def setproject_cmd(argv):\n    \"\"\"Given a virtualenv directory and a project directory, set the \\\n    virtualenv up to be associated with the project.\"\"\"\n    args = dict(enumerate(argv))\n    project = os.path.abspath(args.get(1, '.'))\n    env = args.get(0, os.environ.get('VIRTUAL_ENV'))\n    if not env:\n        sys.exit('pew setproject [virtualenv] [project_path]')\n    if not (workon_home / env).exists():\n        sys.exit(\"Environment '%s' doesn't exist.\" % env)\n    if not os.path.isdir(project):\n        sys.exit('pew setproject: %s does not exist' % project)\n    setvirtualenvproject(env, project)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getproject_cmd(argv):\n    # Parse command line arguments\n    parser = argparse.ArgumentParser(\n        description=\"Print an environment's project directory.\",\n    )\n    parser.add_argument(\n        'envname',\n        nargs='?',\n        default=os.environ.get('VIRTUAL_ENV'),\n        help=(\n            'The name of the environment to return the project directory '\n            'for.  If omitted, will use the currently active environment.'\n        ),\n    )\n    args = parser.parse_args(argv)\n    # Now, do the actual work\n    if not args.envname:\n        sys.exit('ERROR: no virtualenv active')\n    if not (workon_home / args.envname).exists():\n        sys.exit(\"ERROR: Environment '{0}' does not exist.\"\n                 .format(args.envname))\n    project_dir = get_project_dir(args.envname)\n    if project_dir is None:\n        sys.exit(\"ERROR: no project directory set for Environment '{0}'\"\n                 .format(args.envname))\n    print(project_dir)", "response": "Get a project directory for a virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new project directory and its associated virtualenv.", "response": "def mkproject_cmd(argv):\n    \"\"\"Create a new project directory and its associated virtualenv.\"\"\"\n    if '-l' in argv or '--list' in argv:\n        templates = [t.name[9:] for t in workon_home.glob(\"template_*\")]\n        print(\"Available project templates:\", *templates, sep='\\n')\n        return\n\n    parser = mkvirtualenv_argparser()\n    parser.add_argument('envname')\n    parser.add_argument(\n        '-t', action='append', default=[], dest='templates', help='Multiple \\\ntemplates may be selected.  They are applied in the order specified on the \\\ncommand line.')\n    parser.add_argument(\n        '-l', '--list', action='store_true', help='List available templates.')\n\n    args, rest = parser.parse_known_args(argv)\n\n    projects_home = Path(os.environ.get('PROJECT_HOME', '.'))\n    if not projects_home.exists():\n        sys.exit('ERROR: Projects directory %s does not exist. \\\nCreate it or set PROJECT_HOME to an existing directory.' % projects_home)\n\n    project = (projects_home / args.envname).absolute()\n    if project.exists():\n        sys.exit('Project %s already exists.' % args.envname)\n\n    mkvirtualenv(args.envname, args.python, args.packages, project.absolute(),\n                 args.requirements, rest)\n\n    project.mkdir()\n\n    for template_name in args.templates:\n        template = workon_home / (\"template_\" + template_name)\n        inve(args.envname, str(template), args.envname, str(project))\n    if args.activate:\n        shell(args.envname, cwd=str(project))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mktmpenv_cmd(argv):\n    parser = mkvirtualenv_argparser()\n    env = '.'\n    while (workon_home / env).exists():\n        env = hex(random.getrandbits(64))[2:-1]\n\n    args, rest = parser.parse_known_args(argv)\n\n    mkvirtualenv(env, args.python, args.packages, requirements=args.requirements,\n                 rest=rest)\n    print('This is a temporary environment. It will be deleted when you exit')\n    try:\n        if args.activate:\n            # only used for testing on windows\n            shell(env)\n    finally:\n        return rmvirtualenvs([env])", "response": "Create a temporary virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all installed packages from the current virtualenv.", "response": "def wipeenv_cmd(argv):\n    \"\"\"Remove all installed packages from the current (or supplied) env.\"\"\"\n    env = argv[0] if argv else os.environ.get('VIRTUAL_ENV')\n\n    if not env:\n        sys.exit('ERROR: no virtualenv active')\n    elif not (workon_home / env).exists():\n        sys.exit(\"ERROR: Environment '{0}' does not exist.\".format(env))\n    else:\n        env_pip = str(workon_home / env / env_bin_dir / 'pip')\n        all_pkgs = set(invoke(env_pip, 'freeze').out.splitlines())\n        pkgs = set(p for p in all_pkgs if len(p.split(\"==\")) == 2)\n        ignored = sorted(all_pkgs - pkgs)\n        pkgs = set(p.split(\"==\")[0] for p in pkgs)\n        to_remove = sorted(pkgs - set(['distribute', 'wsgiref']))\n        if to_remove:\n            print(\"Ignoring:\\n %s\" % \"\\n \".join(ignored))\n            print(\"Uninstalling packages:\\n %s\" % \"\\n \".join(to_remove))\n            return inve(env, 'pip', 'uninstall', '-y', *to_remove)\n        else:\n            print(\"Nothing to remove\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inall_cmd(argv):\n    envs = lsenvs()\n    errors = False\n    for env in envs:\n        print(\"\\n%s:\" % env)\n        try:\n            inve(env, *argv)\n        except CalledProcessError as e:\n            errors = True\n            err(e)\n    sys.exit(errors)", "response": "Run a command in each virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a command in the given virtualenv.", "response": "def in_cmd(argv):\n    \"\"\"Run a command in the given virtualenv.\"\"\"\n\n    if len(argv) == 1:\n        return workon_cmd(argv)\n\n    parse_envname(argv, lambda : sys.exit('You must provide a valid virtualenv to target'))\n\n    return inve(*argv)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to restore a broken virtualenv by reinstalling the same python version on top of it", "response": "def restore_cmd(argv):\n    \"\"\"Try to restore a broken virtualenv by reinstalling the same python version on top of it\"\"\"\n\n    if len(argv) < 1:\n        sys.exit('You must provide a valid virtualenv to target')\n\n    env = argv[0]\n    path = workon_home / env\n    py = path / env_bin_dir / ('python.exe' if windows else 'python')\n    exact_py = py.resolve().name\n\n    return check_call([sys.executable, \"-m\", \"virtualenv\", str(path.absolute()), \"--python=%s\" % exact_py])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dir_cmd(argv):\n    env = parse_envname(argv, lambda : sys.exit('You must provide a valid virtualenv to target'))\n    print(workon_home / env)", "response": "Print the path for the virtualenv directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing Pythonz to download and build the specified Python version", "response": "def install_cmd(argv):\n    '''Use Pythonz to download and build the specified Python version'''\n    installer = InstallCommand()\n    options, versions = installer.parser.parse_args(argv)\n    if len(versions) != 1:\n        installer.parser.print_help()\n        sys.exit(1)\n    else:\n        try:\n            actual_installer = PythonInstaller.get_installer(versions[0], options)\n            return actual_installer.install()\n        except AlreadyInstalledError as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef version_cmd(argv):\n    import pkg_resources\n\n    try:\n        __version__ = pkg_resources.get_distribution('pew').version\n    except pkg_resources.DistributionNotFound:\n        __version__ = 'unknown'\n        print('Setuptools has some issues here, failed to get our own package.', file=sys.stderr)\n\n    print(__version__)", "response": "Prints current pew version"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncommands - line tool to transform html style to inline css", "response": "def main(args):\n    \"\"\"Command-line tool to transform html style to inline css\n\n    Usage::\n\n        $ echo '<style>h1 { color:red; }</style><h1>Title</h1>' | \\\n        python -m premailer\n        <h1 style=\"color:red\"></h1>\n        $ cat newsletter.html | python -m premailer\n    \"\"\"\n\n    parser = argparse.ArgumentParser(usage=\"python -m premailer [options]\")\n\n    parser.add_argument(\n        \"-f\",\n        \"--file\",\n        nargs=\"?\",\n        type=argparse.FileType(\"r\"),\n        help=\"Specifies the input file.  The default is stdin.\",\n        default=sys.stdin,\n        dest=\"infile\",\n    )\n\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        nargs=\"?\",\n        type=argparse.FileType(\"w\"),\n        help=\"Specifies the output file.  The default is stdout.\",\n        default=sys.stdout,\n        dest=\"outfile\",\n    )\n\n    parser.add_argument(\"--base-url\", default=None, type=str, dest=\"base_url\")\n\n    parser.add_argument(\n        \"--remove-internal-links\",\n        default=True,\n        help=\"Remove links that start with a '#' like anchors.\",\n        dest=\"preserve_internal_links\",\n    )\n\n    parser.add_argument(\n        \"--exclude-pseudoclasses\",\n        default=False,\n        help=\"Pseudo classes like p:last-child', p:first-child, etc\",\n        action=\"store_true\",\n        dest=\"exclude_pseudoclasses\",\n    )\n\n    parser.add_argument(\n        \"--preserve-style-tags\",\n        default=False,\n        help=\"Do not delete <style></style> tags from the html document.\",\n        action=\"store_true\",\n        dest=\"keep_style_tags\",\n    )\n\n    parser.add_argument(\n        \"--remove-star-selectors\",\n        default=True,\n        help=\"All wildcard selectors like '* {color: black}' will be removed.\",\n        action=\"store_false\",\n        dest=\"include_star_selectors\",\n    )\n\n    parser.add_argument(\n        \"--remove-classes\",\n        default=False,\n        help=\"Remove all class attributes from all elements\",\n        action=\"store_true\",\n        dest=\"remove_classes\",\n    )\n\n    parser.add_argument(\n        \"--capitalize-float-margin\",\n        default=False,\n        help=\"Capitalize float and margin properties for outlook.com compat.\",\n        action=\"store_true\",\n        dest=\"capitalize_float_margin\",\n    )\n\n    parser.add_argument(\n        \"--strip-important\",\n        default=False,\n        help=\"Remove '!important' for all css declarations.\",\n        action=\"store_true\",\n        dest=\"strip_important\",\n    )\n\n    parser.add_argument(\n        \"--method\",\n        default=\"html\",\n        dest=\"method\",\n        help=\"The type of html to output. 'html' for HTML, 'xml' for XHTML.\",\n    )\n\n    parser.add_argument(\n        \"--base-path\",\n        default=None,\n        dest=\"base_path\",\n        help=\"The base path for all external stylsheets.\",\n    )\n\n    parser.add_argument(\n        \"--external-style\",\n        action=\"append\",\n        dest=\"external_styles\",\n        help=\"The path to an external stylesheet to be loaded.\",\n    )\n\n    parser.add_argument(\n        \"--css-text\",\n        action=\"append\",\n        dest=\"css_text\",\n        help=\"CSS text to be applied to the html.\",\n    )\n\n    parser.add_argument(\n        \"--disable-basic-attributes\",\n        dest=\"disable_basic_attributes\",\n        help=\"Disable provided basic attributes (comma separated)\",\n        default=[],\n    )\n\n    parser.add_argument(\n        \"--disable-validation\",\n        default=False,\n        action=\"store_true\",\n        dest=\"disable_validation\",\n        help=\"Disable CSSParser validation of attributes and values\",\n    )\n\n    parser.add_argument(\n        \"--pretty\",\n        default=False,\n        action=\"store_true\",\n        help=\"Pretty-print the outputted HTML.\",\n    )\n\n    parser.add_argument(\n        \"--encoding\", default=\"utf-8\", help=\"Output encoding. The default is utf-8\"\n    )\n\n    options = parser.parse_args(args)\n\n    if options.disable_basic_attributes:\n        options.disable_basic_attributes = options.disable_basic_attributes.split()\n\n    html = options.infile.read()\n    if hasattr(html, \"decode\"):  # Forgive me: Python 2 compatability\n        html = html.decode(\"utf-8\")\n\n    p = Premailer(\n        html=html,\n        base_url=options.base_url,\n        preserve_internal_links=options.preserve_internal_links,\n        exclude_pseudoclasses=options.exclude_pseudoclasses,\n        keep_style_tags=options.keep_style_tags,\n        include_star_selectors=options.include_star_selectors,\n        remove_classes=options.remove_classes,\n        strip_important=options.strip_important,\n        external_styles=options.external_styles,\n        css_text=options.css_text,\n        method=options.method,\n        base_path=options.base_path,\n        disable_basic_attributes=options.disable_basic_attributes,\n        disable_validation=options.disable_validation,\n    )\n    options.outfile.write(\n        p.transform(encoding=options.encoding, pretty_print=options.pretty)\n    )\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking css text and make it to list of tuple of key value.", "response": "def csstext_to_pairs(csstext):\n    \"\"\"\n    csstext_to_pairs takes css text and make it to list of\n    tuple of key,value.\n    \"\"\"\n    # The lock is required to avoid ``cssutils`` concurrency\n    # issues documented in issue #65\n    with csstext_to_pairs._lock:\n        return sorted(\n            [\n                (prop.name.strip(), format_value(prop))\n                for prop in cssutils.parseStyle(csstext)\n            ],\n            key=itemgetter(0),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes every property in a string!important.", "response": "def make_important(bulk):\n    \"\"\"makes every property in a string !important.\n    \"\"\"\n    return \";\".join(\n        \"%s !important\" % p if not p.endswith(\"!important\") else p\n        for p in bulk.split(\";\")\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring that root contains a <head > element and returns it.", "response": "def get_or_create_head(root):\n    \"\"\"Ensures that `root` contains a <head> element and returns it.\n    \"\"\"\n    head = _create_cssselector(\"head\")(root)\n    if not head:\n        head = etree.Element(\"head\")\n        body = _create_cssselector(\"body\")(root)[0]\n        body.getparent().insert(0, head)\n        return head\n    else:\n        return head[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncapitalizing float and margin CSS property names", "response": "def capitalize_float_margin(css_body):\n    \"\"\"Capitalize float and margin CSS property names\n    \"\"\"\n\n    def _capitalize_property(match):\n        return \"{0}:{1}{2}\".format(\n            match.group(\"property\").capitalize(),\n            match.group(\"value\"),\n            match.group(\"terminator\"),\n        )\n\n    return _lowercase_margin_float_rule.sub(_capitalize_property, css_body)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_style_rules(self, css_body, ruleset_index):\n\n        def format_css_property(prop):\n            if self.strip_important or prop.priority != \"important\":\n                return \"{0}:{1}\".format(prop.name, prop.value)\n            else:\n                return \"{0}:{1} !important\".format(prop.name, prop.value)\n\n        def join_css_properties(properties):\n            \"\"\" Accepts a list of cssutils Property objects and returns\n            a semicolon delimitted string like 'color: red; font-size: 12px'\n            \"\"\"\n            return \";\".join(format_css_property(prop) for prop in properties)\n\n        leftover = []\n        rules = []\n        # empty string\n        if not css_body:\n            return rules, leftover\n        sheet = self._parse_css_string(css_body, validate=not self.disable_validation)\n        for rule in sheet:\n            # handle media rule\n            if rule.type == rule.MEDIA_RULE:\n                leftover.append(rule)\n                continue\n            # only proceed for things we recognize\n            if rule.type != rule.STYLE_RULE:\n                continue\n\n            # normal means it doesn't have \"!important\"\n            normal_properties = [\n                prop\n                for prop in rule.style.getProperties()\n                if prop.priority != \"important\"\n            ]\n            important_properties = [\n                prop\n                for prop in rule.style.getProperties()\n                if prop.priority == \"important\"\n            ]\n\n            # Create three strings that we can use to add to the `rules`\n            # list later as ready blocks of css.\n            bulk_normal = join_css_properties(normal_properties)\n            bulk_important = join_css_properties(important_properties)\n            bulk_all = join_css_properties(normal_properties + important_properties)\n\n            selectors = (\n                x.strip()\n                for x in rule.selectorText.split(\",\")\n                if x.strip() and not x.strip().startswith(\"@\")\n            )\n            for selector in selectors:\n                if (\n                    \":\" in selector\n                    and self.exclude_pseudoclasses\n                    and \":\" + selector.split(\":\", 1)[1] not in FILTER_PSEUDOSELECTORS\n                ):\n                    # a pseudoclass\n                    leftover.append((selector, bulk_all))\n                    continue\n                elif \"*\" in selector and not self.include_star_selectors:\n                    continue\n                elif selector.startswith(\":\"):\n                    continue\n\n                # Crudely calculate specificity\n                id_count = selector.count(\"#\")\n                class_count = selector.count(\".\")\n                element_count = len(_element_selector_regex.findall(selector))\n\n                # Within one rule individual properties have different\n                # priority depending on !important.\n                # So we split each rule into two: one that includes all\n                # the !important declarations and another that doesn't.\n                for is_important, bulk in ((1, bulk_important), (0, bulk_normal)):\n                    if not bulk:\n                        # don't bother adding empty css rules\n                        continue\n                    specificity = (\n                        is_important,\n                        id_count,\n                        class_count,\n                        element_count,\n                        ruleset_index,\n                        len(rules),  # this is the rule's index number\n                    )\n                    rules.append((specificity, selector, bulk))\n\n        return rules, leftover", "response": "Parses the CSS body of a style rule and returns a list of rules that will be used to apply to this doc and a list of rules that will be used to apply to this doc."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform(self, html=None, pretty_print=True, **kwargs):\n        if html is not None and self.html is not None:\n            raise TypeError(\"Can't pass html argument twice\")\n        elif html is None and self.html is None:\n            raise TypeError(\"must pass html as first argument\")\n        elif html is None:\n            html = self.html\n        if hasattr(html, \"getroottree\"):\n            # skip the next bit\n            root = html.getroottree()\n            page = root\n            tree = root\n        else:\n            if self.method == \"xml\":\n                parser = etree.XMLParser(ns_clean=False, resolve_entities=False)\n            else:\n                parser = etree.HTMLParser()\n            stripped = html.strip()\n            tree = etree.fromstring(stripped, parser).getroottree()\n            page = tree.getroot()\n            # lxml inserts a doctype if none exists, so only include it in\n            # the root if it was in the original html.\n            root = tree if stripped.startswith(tree.docinfo.doctype) else page\n\n        assert page is not None\n\n        if self.disable_leftover_css:\n            head = None\n        else:\n            head = get_or_create_head(tree)\n        #\n        # style selectors\n        #\n\n        rules = []\n        index = 0\n\n        cssselector = [\"style\"]\n        if self.allow_network:\n            cssselector.append(\"link[rel~=stylesheet]\")\n        for element in _create_cssselector(\",\".join(cssselector))(page):\n            # If we have a media attribute whose value is anything other than\n            # 'all' or 'screen', ignore the ruleset.\n            media = element.attrib.get(\"media\")\n            if media and media not in (\"all\", \"screen\"):\n                continue\n\n            data_attribute = element.attrib.get(self.attribute_name)\n            if data_attribute:\n                if data_attribute == \"ignore\":\n                    del element.attrib[self.attribute_name]\n                    continue\n                else:\n                    warnings.warn(\n                        \"Unrecognized %s attribute (%r)\"\n                        % (self.attribute_name, data_attribute)\n                    )\n\n            is_style = element.tag == \"style\"\n            if is_style:\n                css_body = element.text\n            else:\n                href = element.attrib.get(\"href\")\n                css_body = self._load_external(href)\n\n            these_rules, these_leftover = self._parse_style_rules(css_body, index)\n\n            index += 1\n            rules.extend(these_rules)\n            parent_of_element = element.getparent()\n            if these_leftover or self.keep_style_tags:\n                if is_style:\n                    style = element\n                else:\n                    style = etree.Element(\"style\")\n                    style.attrib[\"type\"] = \"text/css\"\n                if self.keep_style_tags:\n                    style.text = css_body\n                else:\n                    style.text = self._css_rules_to_string(these_leftover)\n                if self.method == \"xml\":\n                    style.text = etree.CDATA(style.text)\n\n                if not is_style:\n                    element.addprevious(style)\n                    parent_of_element.remove(element)\n\n            elif not self.keep_style_tags or not is_style:\n                parent_of_element.remove(element)\n\n        # external style files\n        if self.external_styles and self.allow_network:\n            for stylefile in self.external_styles:\n                css_body = self._load_external(stylefile)\n                self._process_css_text(css_body, index, rules, head)\n                index += 1\n\n        # css text\n        if self.css_text:\n            for css_body in self.css_text:\n                self._process_css_text(css_body, index, rules, head)\n                index += 1\n\n        # rules is a tuple of (specificity, selector, styles), where\n        # specificity is a tuple ordered such that more specific\n        # rules sort larger.\n        rules.sort(key=operator.itemgetter(0))\n\n        # collecting all elements that we need to apply rules on\n        # id is unique for the lifetime of the object\n        # and lxml should give us the same everytime during this run\n        # item id -> {item: item, classes: [], style: []}\n        elements = {}\n        for _, selector, style in rules:\n            new_selector = selector\n            class_ = \"\"\n            if \":\" in selector:\n                new_selector, class_ = re.split(\":\", selector, 1)\n                class_ = \":%s\" % class_\n            # Keep filter-type selectors untouched.\n            if class_ in FILTER_PSEUDOSELECTORS or class_.startswith(\":nth-child\"):\n                class_ = \"\"\n            else:\n                selector = new_selector\n\n            assert selector\n            sel = _create_cssselector(selector)\n            items = sel(page)\n            if len(items):\n                # same so process it first\n                processed_style = csstext_to_pairs(style)\n\n                for item in items:\n                    item_id = id(item)\n                    if item_id not in elements:\n                        elements[item_id] = {\"item\": item, \"classes\": [], \"style\": []}\n\n                    elements[item_id][\"style\"].append(processed_style)\n                    elements[item_id][\"classes\"].append(class_)\n\n        # Now apply inline style\n        # merge style only once for each element\n        # crucial when you have a lot of pseudo/classes\n        # and a long list of elements\n        for _, element in elements.items():\n            final_style = merge_styles(\n                element[\"item\"].attrib.get(\"style\", \"\"),\n                element[\"style\"],\n                element[\"classes\"],\n                remove_unset_properties=self.remove_unset_properties,\n            )\n            if final_style:\n                # final style could be empty string because of\n                # remove_unset_properties\n                element[\"item\"].attrib[\"style\"] = final_style\n            self._style_to_basic_html_attributes(\n                element[\"item\"], final_style, force=True\n            )\n\n        if self.remove_classes:\n            # now we can delete all 'class' attributes\n            for item in page.xpath(\"//@class\"):\n                parent = item.getparent()\n                del parent.attrib[\"class\"]\n\n        # Capitalize Margin properties\n        # To fix weird outlook bug\n        # https://www.emailonacid.com/blog/article/email-development/outlook.com-does-support-margins\n        if self.capitalize_float_margin:\n            for item in page.xpath(\"//@style\"):\n                mangled = capitalize_float_margin(item)\n                item.getparent().attrib[\"style\"] = mangled\n\n        # Add align attributes to images if they have a CSS float value of\n        # right or left. Outlook (both on desktop and on the web) are bad at\n        # understanding floats, but they do understand the HTML align attrib.\n        if self.align_floating_images:\n            for item in page.xpath(\"//img[@style]\"):\n                image_css = cssutils.parseStyle(item.attrib[\"style\"])\n                if image_css.float == \"right\":\n                    item.attrib[\"align\"] = \"right\"\n                elif image_css.float == \"left\":\n                    item.attrib[\"align\"] = \"left\"\n\n        #\n        # URLs\n        #\n        if self.base_url and not self.disable_link_rewrites:\n            if not urlparse(self.base_url).scheme:\n                raise ValueError(\"Base URL must have a scheme\")\n            for attr in (\"href\", \"src\"):\n                for item in page.xpath(\"//@%s\" % attr):\n                    parent = item.getparent()\n                    url = parent.attrib[attr]\n                    if (\n                        attr == \"href\"\n                        and self.preserve_internal_links\n                        and url.startswith(\"#\")\n                    ):\n                        continue\n                    if (\n                        attr == \"src\"\n                        and self.preserve_inline_attachments\n                        and url.startswith(\"cid:\")\n                    ):\n                        continue\n                    if attr == \"href\" and url.startswith(\"tel:\"):\n                        continue\n                    parent.attrib[attr] = urljoin(self.base_url, url)\n\n        if hasattr(html, \"getroottree\"):\n            return root\n        else:\n            kwargs.setdefault(\"method\", self.method)\n            kwargs.setdefault(\"pretty_print\", pretty_print)\n            kwargs.setdefault(\"encoding\", \"utf-8\")  # As Ken Thompson intended\n            out = etree.tostring(root, **kwargs).decode(kwargs[\"encoding\"])\n            if self.method == \"xml\":\n                out = _cdata_regex.sub(\n                    lambda m: \"/*<![CDATA[*/%s/*]]>*/\" % m.group(1), out\n                )\n            if self.strip_important:\n                out = _importants.sub(\"\", out)\n            return out", "response": "change the html and return it with CSS turned into style\n            attributes. pretty_print is False if the output is not pretty - printed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads an external stylesheet from a remote url or local path", "response": "def _load_external(self, url):\n        \"\"\"loads an external stylesheet from a remote url or local path\n        \"\"\"\n        if url.startswith(\"//\"):\n            # then we have to rely on the base_url\n            if self.base_url and \"https://\" in self.base_url:\n                url = \"https:\" + url\n            else:\n                url = \"http:\" + url\n\n        if url.startswith(\"http://\") or url.startswith(\"https://\"):\n            css_body = self._load_external_url(url)\n        else:\n            stylefile = url\n            if not os.path.isabs(stylefile):\n                stylefile = os.path.abspath(\n                    os.path.join(self.base_path or \"\", stylefile)\n                )\n            if os.path.exists(stylefile):\n                with codecs.open(stylefile, encoding=\"utf-8\") as f:\n                    css_body = f.read()\n            elif self.base_url:\n                url = urljoin(self.base_url, url)\n                return self._load_external(url)\n            else:\n                raise ExternalNotFoundError(stylefile)\n\n        return css_body"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn some of that into HTML attributes.", "response": "def _style_to_basic_html_attributes(self, element, style_content, force=False):\n        \"\"\"given an element and styles like\n        'background-color:red; font-family:Arial' turn some of that into HTML\n        attributes. like 'bgcolor', etc.\n\n        Note, the style_content can contain pseudoclasses like:\n        '{color:red; border:1px solid green} :visited{border:1px solid green}'\n        \"\"\"\n        if style_content.count(\"}\") and style_content.count(\"{\") == style_content.count(\n            \"}\"\n        ):\n            style_content = style_content.split(\"}\")[0][1:]\n\n        attributes = OrderedDict()\n        for key, value in [\n            x.split(\":\") for x in style_content.split(\";\") if len(x.split(\":\")) == 2\n        ]:\n            key = key.strip()\n\n            if key == \"text-align\":\n                attributes[\"align\"] = value.strip()\n            elif key == \"vertical-align\":\n                attributes[\"valign\"] = value.strip()\n            elif key == \"background-color\" and \"transparent\" not in value.lower():\n                # Only add the 'bgcolor' attribute if the value does not\n                # contain the word \"transparent\"; before we add it possibly\n                # correct the 3-digit color code to its 6-digit equivalent\n                # (\"abc\" to \"aabbcc\") so IBM Notes copes.\n                attributes[\"bgcolor\"] = self.six_color(value.strip())\n            elif key == \"width\" or key == \"height\":\n                value = value.strip()\n                if value.endswith(\"px\"):\n                    value = value[:-2]\n                attributes[key] = value\n\n        for key, value in attributes.items():\n            if (\n                key in element.attrib\n                and not force\n                or key in self.disable_basic_attributes\n            ):\n                # already set, don't dare to overwrite\n                continue\n            element.attrib[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _css_rules_to_string(self, rules):\n        lines = []\n        for item in rules:\n            if isinstance(item, tuple):\n                k, v = item\n                lines.append(\"%s {%s}\" % (k, make_important(v)))\n            # media rule\n            else:\n                for rule in item.cssRules:\n                    if isinstance(\n                        rule,\n                        (\n                            cssutils.css.csscomment.CSSComment,\n                            cssutils.css.cssunknownrule.CSSUnknownRule,\n                        ),\n                    ):\n                        continue\n                    for key in rule.style.keys():\n                        rule.style[key] = (\n                            rule.style.getPropertyValue(key, False),\n                            \"!important\",\n                        )\n                lines.append(item.cssText)\n        return \"\\n\".join(lines)", "response": "given a list of css rules returns a css string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_css_text(self, css_text, index, rules, head):\n        these_rules, these_leftover = self._parse_style_rules(css_text, index)\n        rules.extend(these_rules)\n        if head is not None and (these_leftover or self.keep_style_tags):\n            style = etree.Element(\"style\")\n            style.attrib[\"type\"] = \"text/css\"\n            if self.keep_style_tags:\n                style.text = css_text\n            else:\n                style.text = self._css_rules_to_string(these_leftover)\n            head.append(style)", "response": "processes the given css_text by adding rules that can be\n        in -lined to the given list and adding any that cannot\n        be in -lined to the given head element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_request(self, num_pending, ports, request_blocking=False):\n        '''port is the open port at the worker, num_pending is the num_pending of stack.\n        A non-zero num_pending means that the worker is pending on something while\n        looking for new job, so the worker should not be killed.\n        '''\n        if any(port in self._step_requests for port in ports):\n            # if the port is available\n            port = [x for x in ports if x in self._step_requests][0]\n            self._worker_backend_socket.send_pyobj(\n                self._step_requests.pop(port))\n            self._n_processed += 1\n            self.report(f'Step {port} processed')\n            # port should be in claimed ports\n            self._claimed_ports.remove(port)\n            if ports[0] in self._last_pending_time:\n                self._last_pending_time.pop(ports[0])\n        elif any(port in self._claimed_ports for port in ports):\n            # the port is claimed, but the real message is not yet available\n            self._worker_backend_socket.send_pyobj({})\n            self.report(f'pending with claimed {ports}')\n        elif any(port in self._blocking_ports for port in ports):\n            # in block list but appear to be idle, kill it\n            self._max_workers -= 1\n            env.logger.debug(\n                f'Reduce maximum number of workers to {self._max_workers} after completion of a blocking subworkflow.'\n            )\n            for port in ports:\n                if port in self._blocking_ports:\n                    self._blocking_ports.remove(port)\n                if port in self._available_ports:\n                    self._available_ports.remove(port)\n            self._worker_backend_socket.send_pyobj(None)\n            self._num_workers -= 1\n            self.report(f'Blocking worker {ports} killed')\n        elif self._substep_requests:\n            # port is not claimed, free to use for substep worker\n            msg = self._substep_requests.pop()\n            self._worker_backend_socket.send_pyobj(msg)\n            self._n_processed += 1\n            self.report(f'Substep processed with {ports[0]}')\n            # port can however be in available ports\n            for port in ports:\n                if port in self._available_ports:\n                    self._available_ports.remove(port)\n                if port in self._last_pending_time:\n                    self._last_pending_time.pop(port)\n        elif request_blocking:\n            self._worker_backend_socket.send_pyobj({})\n            return ports[0]\n        elif num_pending == 0 and ports[\n                0] in self._last_pending_time and time.time(\n                ) - self._last_pending_time[ports[0]] > 5:\n            # kill the worker\n            for port in ports:\n                if port in self._available_ports:\n                    self._available_ports.remove(port)\n            self._worker_backend_socket.send_pyobj(None)\n            self._num_workers -= 1\n            self.report(f'Kill standing {ports}')\n            self._last_pending_time.pop(ports[0])\n        else:\n            if num_pending == 0 and ports[0] not in self._last_pending_time:\n                self._last_pending_time[ports[0]] = time.time()\n            self._available_ports.add(ports[0])\n            self._worker_backend_socket.send_pyobj({})\n            ports = tuple(ports)\n            if (ports, num_pending) not in self._last_pending_msg or time.time(\n            ) - self._last_pending_msg[(ports, num_pending)] > 1.0:\n                self.report(\n                    f'pending with port {ports} at num_pending {num_pending}')\n                self._last_pending_msg[(ports, num_pending)] = time.time()", "response": "Process a request from the worker and process it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nkilling workers that have been pending for a while and check if all workers are alive.", "response": "def check_workers(self):\n        '''Kill workers that have been pending for a while and check if all workers\n        are alive. '''\n        if time.time() - self._worker_alive_time > 5:\n            self._worker_alive_time = time.time()\n            # join processes if they are now gone, it should not do anything bad\n            # if the process is still running\n            [worker.join() for worker in self._workers if not worker.is_alive()]\n            self._workers = [\n                worker for worker in self._workers if worker.is_alive()\n            ]\n            if len(self._workers) < self._num_workers:\n                raise ProcessKilled('One of the workers has been killed.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling the named version of the module using command pip install if necessary.", "response": "def _install(self, name, autoinstall):\n        '''Check existence of Python module and install it using command\n        pip install if necessary.'''\n        import importlib\n        import pkg_resources\n        spam_spec = importlib.util.find_spec(name)\n        reinstall = False\n        if spam_spec is not None:\n            if self._version:\n                mod = importlib.__import__(name)\n                if hasattr(mod, '__version__'):\n                    ver = mod.__version__\n                else:\n                    try:\n                        ver = pkg_resources.get_distribution(name).version\n                    except Exception as e:\n                        env.logger.debug(\n                            f'Failed to get version of {name}: {e}')\n                env.logger.debug(\n                    f'Comparing exiting version {ver} against requested version {self._version}'\n                )\n                if self._version.startswith(\n                        '==') and pkg_resources.parse_version(\n                            ver) == pkg_resources.parse_version(\n                                self._version[2:]):\n                    pass\n                elif self._version.startswith(\n                        '<=') and pkg_resources.parse_version(\n                            ver) <= pkg_resources.parse_version(\n                                self._version[2:]):\n                    pass\n                elif self._version.startswith(\n                        '<') and not self._version.startswith(\n                            '<=') and pkg_resources.parse_version(\n                                ver) < pkg_resources.parse_version(\n                                    self._version[1:]):\n                    pass\n                elif self._version.startswith(\n                        '>=') and pkg_resources.parse_version(\n                            ver) >= pkg_resources.parse_version(\n                                self._version[2:]):\n                    pass\n                # the case of >\n                elif self._version.startswith(\n                        '>') and not self._version.startswith(\n                            '>=') and pkg_resources.parse_version(\n                                ver) > pkg_resources.parse_version(\n                                    self._version[1:]):\n                    pass\n                elif self._version.startswith(\n                        '!=') and pkg_resources.parse_version(\n                            ver) != pkg_resources.parse_version(\n                                self._version[2:]):\n                    pass\n                elif self._version[0] not in (\n                        '=', '>', '<', '!') and pkg_resources.parse_version(\n                            ver) == pkg_resources.parse_version(self._version):\n                    pass\n                else:\n                    env.logger.warning(\n                        f'Version {ver} of installed {name} does not match specified version {self._version}.'\n                    )\n                    reinstall = True\n        if spam_spec and not reinstall:\n            return True\n        if not autoinstall:\n            return False\n        # try to install it?\n        import subprocess\n        cmd = ['pip', 'install'] + ([] if self._version else ['-U']) + [\n            self._module + (self._version if self._version else '')\n            if self._autoinstall is True else self._autoinstall\n        ]\n        env.logger.info(\n            f'Installing python module {name} with command {\" \".join(cmd)}')\n        ret = subprocess.call(cmd)\n        if reinstall:\n            import sys\n            importlib.reload(sys.modules[name])\n        # try to check version\n        return ret == 0 and self._install(name, False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a single or master task and return a dictionary of the result.", "response": "def execute_task(task_id,\n                 verbosity=None,\n                 runmode='run',\n                 sigmode=None,\n                 monitor_interval=5,\n                 resource_monitor_interval=60):\n    '''Execute single or master task, return a dictionary'''\n    tf = TaskFile(task_id)\n\n    # this will automatically create a pulse file\n    tf.status = 'running'\n    # write result file\n    try:\n        signal.signal(signal.SIGTERM, signal_handler)\n        res = _execute_task(task_id, verbosity, runmode, sigmode,\n                            monitor_interval, resource_monitor_interval)\n    except KeyboardInterrupt:\n        tf.status = 'aborted'\n        raise\n    except ProcessKilled:\n        tf.status = 'aborted'\n        raise ProcessKilled('task interrupted')\n    finally:\n        signal.signal(signal.SIGTERM, signal.SIG_DFL)\n\n    if res['ret_code'] != 0 and 'exception' in res:\n        with open(\n                os.path.join(\n                    os.path.expanduser('~'), '.sos', 'tasks', task_id + '.err'),\n                'a') as err:\n            err.write(f'Task {task_id} exits with code {res[\"ret_code\"]}')\n\n    if res.get('skipped', False):\n        # a special mode for skipped to set running time to zero\n        tf.status = 'skipped'\n    else:\n        tf.add_outputs()\n        sig = res.get('signature', {})\n        res.pop('signature', None)\n        tf.add_result(res)\n        if sig:\n            tf.add_signature(sig)\n        # **after** result file is created, remove other files\n        #\n        # NOTE: if the pulse is not removed. When another sos process checkes\n        # the task is started very quickly so the task has satus 'pending',\n        # the task might be considered already running.\n        tf.status = 'completed' if res['ret_code'] == 0 else 'failed'\n\n    return res['ret_code']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _execute_sub_tasks(task_id, params, sig_content, verbosity, runmode,\n                       sigmode, monitor_interval, resource_monitor_interval,\n                       master_runtime):\n    '''If this is a master task, execute as individual tasks'''\n    m = ProcessMonitor(\n        task_id,\n        monitor_interval=monitor_interval,\n        resource_monitor_interval=resource_monitor_interval,\n        max_walltime=params.sos_dict['_runtime'].get('max_walltime', None),\n        max_mem=params.sos_dict['_runtime'].get('max_mem', None),\n        max_procs=params.sos_dict['_runtime'].get('max_procs', None),\n        sos_dict=params.sos_dict)\n    m.start()\n\n    env.logger.info(f'{task_id} ``started``')\n\n    master_out = os.path.join(\n        os.path.expanduser('~'), '.sos', 'tasks', task_id + '.out')\n    master_err = os.path.join(\n        os.path.expanduser('~'), '.sos', 'tasks', task_id + '.err')\n    # if this is a master task, calling each sub task\n    with open(master_out, 'wb') as out, open(master_err, 'wb') as err:\n\n        def copy_out_and_err(result):\n            tid = result['task']\n            out.write(\n                f'{tid}: {\"completed\" if result[\"ret_code\"] == 0 else \"failed\"}\\n'\n                .encode())\n            if 'output' in result:\n                out.write(f'output: {result[\"output\"]}\\n'.encode())\n            sub_out = os.path.join(\n                os.path.expanduser('~'), '.sos', 'tasks', tid + '.out')\n            if os.path.isfile(sub_out):\n                with open(sub_out, 'rb') as sout:\n                    out.write(sout.read())\n                try:\n                    os.remove(sub_out)\n                except Exception as e:\n                    env.logger.warning(f'Failed to remove {sub_out}: {e}')\n\n            sub_err = os.path.join(\n                os.path.expanduser('~'), '.sos', 'tasks', tid + '.err')\n            if 'exception' in result:\n                err.write(str(result['exception']).encode())\n            err.write(\n                f'{tid}: {\"completed\" if result[\"ret_code\"] == 0 else \"failed\"}\\n'\n                .encode())\n            if os.path.isfile(sub_err):\n                with open(sub_err, 'rb') as serr:\n                    err.write(serr.read())\n                try:\n                    os.remove(sub_err)\n                except Exception as e:\n                    env.logger.warning(f'Failed to remove {sub_err}: {e}')\n\n            # remove other files as well\n            try:\n                remove_task_files(tid, ['.out', '.err'])\n            except Exception as e:\n                env.logger.debug(f'Failed to remove files {tid}: {e}')\n\n        if params.num_workers > 1:\n            from multiprocessing.pool import Pool\n            p = Pool(params.num_workers)\n            results = []\n            for tid, tdef in params.task_stack:\n                if hasattr(params, 'common_dict'):\n                    tdef.sos_dict.update(params.common_dict)\n                results.append(\n                    p.apply_async(\n                        _execute_task, ((tid, tdef, {\n                            tid: sig_content.get(tid, {})\n                        }), verbosity, runmode, sigmode, None, None, {\n                            x: master_runtime.get(x, {})\n                            for x in ('_runtime', tid)\n                        }),\n                        callback=copy_out_and_err))\n            for idx, r in enumerate(results):\n                results[idx] = r.get()\n            p.close()\n            p.join()\n            # we wait for all results to be ready to return or raise\n            # but we only raise exception for one of the subtasks\n            # for res in results:\n            #     if 'exception' in res:\n            #         failed = [x.get(\"task\", \"\")\n            #                   for x in results if \"exception\" in x]\n            #         env.logger.error(\n            #             f'{task_id} ``failed`` due to failure of subtask{\"s\" if len(failed) > 1 else \"\"} {\", \".join(failed)}')\n            #         return {'ret_code': 1, 'exception': res['exception'], 'task': task_id}\n        else:\n            results = []\n            for tid, tdef in params.task_stack:\n                if hasattr(params, 'common_dict'):\n                    tdef.sos_dict.update(params.common_dict)\n                # no monitor process for subtasks\n                res = _execute_task(\n                    (tid, tdef, {\n                        tid: sig_content.get(tid, {})\n                    }),\n                    verbosity=verbosity,\n                    runmode=runmode,\n                    sigmode=sigmode,\n                    monitor_interval=None,\n                    resource_monitor_interval=None,\n                    master_runtime={\n                        x: master_runtime.get(x, {}) for x in ('_runtime', tid)\n                    })\n                try:\n                    copy_out_and_err(res)\n                except Exception as e:\n                    env.logger.warning(\n                        f'Failed to copy result of subtask {tid}: {e}')\n                results.append(res)\n            # for res in results:\n            #     if 'exception' in res:\n            #         failed = [x.get(\"task\", \"\")\n            #                   for x in results if \"exception\" in x]\n            #         env.logger.error(\n            #             f'{task_id} ``failed`` due to failure of subtask{\"s\" if len(failed) > 1 else \"\"} {\", \".join(failed)}')\n            #         return {'ret_code': 1, 'exception': res['exception'], 'task': task_id}\n    #\n    # now we collect result\n    all_res = {\n        'ret_code': 0,\n        'output': None,\n        'subtasks': {},\n        'shared': {},\n        'skipped': 0,\n        'signature': {}\n    }\n    for tid, x in zip(params.task_stack, results):\n        all_res['subtasks'][tid[0]] = x\n\n        if 'exception' in x:\n            all_res['exception'] = x['exception']\n            all_res['ret_code'] += 1\n            continue\n        all_res['ret_code'] += x['ret_code']\n        if all_res['output'] is None:\n            all_res['output'] = copy.deepcopy(x['output'])\n        else:\n            try:\n                all_res['output'].extend(x['output'], keep_groups=True)\n            except Exception as e:\n                env.logger.warning(\n                    f\"Failed to extend output {all_res['output']} with {x['output']}\"\n                )\n        all_res['shared'].update(x['shared'])\n        # does not care if one or all subtasks are executed or skipped.\n        all_res['skipped'] += x.get('skipped', 0)\n        if 'signature' in x:\n            all_res['signature'].update(x['signature'])\n\n    if all_res['ret_code'] != 0:\n        if all_res['ret_code'] == len(results):\n            env.logger.info(f'All {len(results)} tasks in {task_id} ``failed``')\n        else:\n            env.logger.info(\n                f'{all_res[\"ret_code\"]} of {len(results)} tasks in {task_id} ``failed``'\n            )\n        # if some failed, some skipped, not skipped\n        if 'skipped' in all_res:\n            all_res.pop('skipped')\n    elif all_res['skipped']:\n        if all_res['skipped'] == len(results):\n            env.logger.info(\n                f'All {len(results)} tasks in {task_id} ``ignored`` or skipped')\n        else:\n            # if only partial skip, we still save signature and result etc\n            env.logger.info(\n                f'{all_res[\"skipped\"]} of {len(results)} tasks in {task_id} ``ignored`` or skipped'\n            )\n            all_res.pop('skipped')\n    else:\n        env.logger.info(f'All {len(results)} tasks in {task_id} ``completed``')\n    return all_res", "response": "Execute all sub - tasks of the task_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting md5 of a piece of text", "response": "def textMD5(text):\n    '''Get md5 of a piece of text'''\n    m = hash_md5()\n    if isinstance(text, str):\n        m.update(text.encode())\n    else:\n        m.update(text)\n    return m.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objectMD5(obj):\n    '''Get md5 of an object'''\n    if hasattr(obj, 'target_name'):\n        return obj.target_name()\n    try:\n        return textMD5(pickle.dumps(obj))\n    except:\n        return ''", "response": "Get md5 of an object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the MD5 of a file.", "response": "def fileMD5(filename, partial=True):\n    '''Calculate partial MD5, basically the first and last 8M\n    of the file for large files. This should signicicantly reduce\n    the time spent on the creation and comparison of file signature\n    when dealing with large bioinformat ics datasets. '''\n    filesize = os.path.getsize(filename)\n    # calculate md5 for specified file\n    md5 = hash_md5()\n    block_size = 2**20  # buffer of 1M\n    try:\n        # 2**24 = 16M\n        if (not partial) or filesize < 2**24:\n            with open(filename, 'rb') as f:\n                while True:\n                    data = f.read(block_size)\n                    if not data:\n                        break\n                    md5.update(data)\n        else:\n            count = 16\n            # otherwise, use the first and last 8M\n            with open(filename, 'rb') as f:\n                while True:\n                    data = f.read(block_size)\n                    count -= 1\n                    if count == 8:\n                        # 2**23 = 8M\n                        f.seek(-2**23, 2)\n                    if not data or count == 0:\n                        break\n                    md5.update(data)\n    except IOError as e:\n        sys.exit(f'Failed to read {filename}: {e}')\n    return md5.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if file matches its signature", "response": "def validate(self, sig=None):\n        '''Check if file matches its signature'''\n        if sig is not None:\n            sig_mtime, sig_size, sig_md5 = sig\n        else:\n            try:\n                with open(self.sig_file()) as sig:\n                    sig_mtime, sig_size, sig_md5 = sig.read().strip().split()\n            except:\n                return False\n        if not self.exists():\n            if (self + '.zapped').is_file():\n                with open(self + '.zapped') as sig:\n                    line = sig.readline()\n                    return sig_md5 == line.strip().rsplit('\\t', 3)[-1]\n            else:\n                return False\n        if sig_mtime == os.path.getmtime(self) and sig_size == os.path.getsize(\n                self):\n            return True\n        return fileMD5(self) == sig_md5"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites signature to sig store", "response": "def write_sig(self):\n        '''Write signature to sig store'''\n        if not self._md5:\n            self._md5 = fileMD5(self)\n        with open(self.sig_file(), 'w') as sig:\n            sig.write(\n                f'{os.path.getmtime(self)}\\t{os.path.getsize(self)}\\t{self._md5}'\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving targets of certain type from the set of target sets.", "response": "def remove_targets(self, type, kept=None):\n        '''Remove targets of certain type'''\n        if kept is None:\n            kept = [\n                i for i, x in enumerate(self._targets)\n                if not isinstance(x, type)\n            ]\n        if len(kept) == len(self._targets):\n            return self\n        self._targets = [self._targets[x] for x in kept]\n        self._labels = [self._labels[x] for x in kept]\n        if not self._groups:\n            return self\n        index_map = {\n            o_idx: n_idx\n            for n_idx, o_idx in zip(range(len(self._targets)), kept)\n        }\n        kept = set(kept)\n        for idx, grp in enumerate(self._groups):\n            self._groups[idx] = _sos_group(\n                [index_map[x] for x in grp._indexes if x in kept],\n                [y for x, y in zip(grp._indexes, grp._labels) if x in kept\n                ]).set(**grp._dict)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles input option paired_with", "response": "def _handle_paired_with(self, paired_with):\n        '''Handle input option paired_with'''\n        if paired_with is None or not paired_with:\n            var_name = []\n            var_value = []\n        elif isinstance(paired_with, str):\n            var_name = ['_' + paired_with]\n            if paired_with not in env.sos_dict:\n                raise ValueError(f'Variable {paired_with} does not exist.')\n            var_value = [env.sos_dict[paired_with]]\n        elif isinstance(paired_with, dict):\n            var_name = []\n            var_value = []\n            for k, v in paired_with.items():\n                var_name.append(k)\n                var_value.append(v)\n        elif isinstance(paired_with, Iterable):\n            try:\n                var_name = ['_' + x for x in paired_with]\n            except Exception:\n                raise ValueError(\n                    f'Invalud value for option paired_with {paired_with}')\n            var_value = []\n            for vn in var_name:\n                if vn[1:] not in env.sos_dict:\n                    raise ValueError(f'Variable {vn[1:]} does not exist.')\n                var_value.append(env.sos_dict[vn[1:]])\n        else:\n            raise ValueError(\n                f'Unacceptable value for parameter paired_with: {paired_with}')\n        #\n        for vn, vv in zip(var_name, var_value):\n            # set paired with values to step_input\n            self.paired_with(vn, vv)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_group_with(self, group_with):\n        '''Handle input option group_with'''\n        if group_with is None or not group_with:\n            var_name = []\n            var_value = []\n        elif isinstance(group_with, str):\n            var_name = ['_' + group_with]\n            if group_with not in env.sos_dict:\n                raise ValueError(f'Variable {group_with} does not exist.')\n            var_value = [env.sos_dict[group_with]]\n        elif isinstance(group_with, dict):\n            var_name = []\n            var_value = []\n            for k, v in group_with.items():\n                var_name.append(k)\n                var_value.append(v)\n        elif isinstance(group_with, Iterable):\n            try:\n                var_name = ['_' + x for x in group_with]\n            except Exception:\n                raise ValueError(\n                    f'Invalud value for option group_with {group_with}')\n            var_value = []\n            for vn in var_name:\n                if vn[1:] not in env.sos_dict:\n                    raise ValueError(f'Variable {vn[1:]} does not exist.')\n                var_value.append(env.sos_dict[vn[1:]])\n        else:\n            raise ValueError(\n                f'Unacceptable value for parameter group_with: {group_with}')\n        #\n        for vn, vv in zip(var_name, var_value):\n            self.group_with(vn, vv)", "response": "Handle input option group_with"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle input option pattern", "response": "def _handle_extract_pattern(self, pattern):\n        '''Handle input option pattern'''\n        if pattern is None or not pattern:\n            patterns = []\n        elif isinstance(pattern, str):\n            patterns = [pattern]\n        elif isinstance(pattern, Iterable):\n            patterns = pattern\n        else:\n            raise ValueError(\n                f'Unacceptable value for parameter pattern: {pattern}')\n        #\n        for pattern in patterns:\n            res = extract_pattern(pattern, self._targets)\n            self.set(**res)\n            # also make k, v pair with _input\n            self._handle_paired_with({'_' + x: y for x, y in res.items()})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if ofiles and ifiles match signatures recorded in md5file", "response": "def validate(self, signature):\n        '''Check if ofiles and ifiles match signatures recorded in md5file'''\n        if not signature:\n            return 'Empty signature'\n        sig_files = self.input_files._targets + self.output_files._targets + \\\n            self.dependent_files._targets\n        for x in sig_files:\n            if not x.target_exists('any'):\n                return f'Missing target {x}'\n        #\n\n        files_checked = {x.target_name(): False for x in sig_files}\n        res = {'input': [], 'output': [], 'depends': [], 'vars': {}}\n        cur_type = 'input'\n        # old signature\n        if 'init_context' in signature:\n            for key, value in signature['init_context'].items():\n                if key not in env.sos_dict:\n                    return f'Variable {key} not in running environment'\n                try:\n                    if env.sos_dict[key] != value:\n                        return f'Context variable {key} value mismatch: {short_repr(value)} saved, {short_repr(env.sos_dict[key])} current'\n                except Exception as e:\n                    env.logger.debug(\n                        f\"Variable {key} of type {type(value).__name__} cannot be compared: {e}\"\n                    )\n        elif 'init_context_sig' in signature:\n            for key, value in signature['init_context_sig'].items():\n                if key not in env.sos_dict:\n                    return f'Variable {key} not in running environment'\n                try:\n                    if objectMD5(env.sos_dict[key]) != value:\n                        return f'ID of context variable {key} ({objectMD5(env.sos_dict[key])}) mismatch: {short_repr(env.sos_dict[key])} does not match id {value}'\n                except Exception as e:\n                    env.logger.debug(f\"Variable {key} cannot be compared: {e}\")\n\n        res['vars'].update(signature['end_context'])\n        #\n        for cur_type in ['input', 'output', 'depends']:\n            for f, m in signature[cur_type].items():\n                try:\n                    if '(' in f and ')' in f:\n                        # this part is hard, because this can be a customized target.\n                        target_type = f.split('(')[0]\n                        target_class = None\n                        if target_type in globals():\n                            target_class = eval(target_type)\n                        else:\n                            # check registry\n                            for entrypoint in pkg_resources.iter_entry_points(\n                                    group='sos_targets'):\n                                if entrypoint.name.strip() == target_type:\n                                    target_class = entrypoint.load()\n                                    break\n                        if target_class is None:\n                            raise ValueError(\n                                f'Failed to identify target class {target_type}'\n                            )\n                        # parameter of class?\n                        freal = eval(f, {target_type: target_class})\n                    else:\n                        freal = file_target(f)\n                    if not freal.validate(m):\n                        return f'Target {f} does not exist or does not match saved signature {m}'\n                    res[cur_type].append(freal.target_name(\n                    ) if isinstance(freal, file_target) else freal)\n                    files_checked[freal.target_name()] = True\n                except Exception as e:\n                    env.logger.debug(f'Wrong md5 in signature: {e}')\n        #\n        if not all(files_checked.values()):\n            return f'No MD5 signature for {\", \".join(x for x,y in files_checked.items() if not y)}'\n        if 'input_obj' in signature:\n            # for new style signature, the entire objects are kept\n            res['input'] = signature['input_obj']\n            res['depends'] = signature['depends_obj']\n            res['output'] = signature['output_obj']\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite signature file with signature of script input output dependent files.", "response": "def write(self):\n        '''Write signature file with signature of script, input, output and dependent files.\n        Because local input and output files can only be determined after the execution\n        of workflow. They are not part of the construction.\n        '''\n        if not self.output_files.valid():\n            raise ValueError(\n                f'Cannot write signature with undetermined output {self.output_files}'\n            )\n        else:\n            if 'TARGET' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                env.log_to_file(\n                    'TARGET',\n                    f'write signature {self.sig_id} with output {self.output_files}'\n                )\n        ret = super(RuntimeInfo, self).write()\n        if ret is False:\n            env.logger.debug(f'Failed to write signature {self.sig_id}')\n            return ret\n        send_message_to_controller(['step_sig', self.sig_id, ret])\n        send_message_to_controller([\n            'workflow_sig', 'tracked_files', self.sig_id,\n            repr({\n                'input_files': [\n                    str(f.resolve())\n                    for f in self.input_files\n                    if isinstance(f, file_target)\n                ],\n                'dependent_files': [\n                    str(f.resolve())\n                    for f in self.dependent_files\n                    if isinstance(f, file_target)\n                ],\n                'output_files': [\n                    str(f.resolve())\n                    for f in self.output_files\n                    if isinstance(f, file_target)\n                ]\n            })\n        ])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if ofiles and ifiles match signatures recorded in md5file", "response": "def validate(self):\n        '''Check if ofiles and ifiles match signatures recorded in md5file'''\n        if 'TARGET' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('TARGET', f'Validating {self.sig_id}')\n        #\n        # file not exist?\n        sig_files = self.input_files._targets + self.output_files._targets + \\\n            self.dependent_files._targets\n        for x in sig_files:\n            if not x.target_exists('any'):\n                return f'Missing target {x}'\n        #\n        sig = request_answer_from_controller(['step_sig', 'get', self.sig_id])\n        if not sig:\n            return f\"No signature found for {self.sig_id}\"\n        return super(RuntimeInfo, self).validate(sig)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves file targets in _output when a step fails to complete", "response": "def clear_output(output=None):\n    '''\n    Remove file targets in `_output` when a step fails to complete\n    '''\n    for target in env.sos_dict['_output'] if output is None else output:\n        if isinstance(target, file_target) and target.exists():\n            try:\n                target.unlink()\n            except Exception as e:\n                env.logger.warning(f'Failed to remove {target}: {e}')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the current sos_dict and execute global statements and inject global variables", "response": "def prepare_env(gdef='', gvars={}, extra_vars={}, host='localhost'):\n    '''clear current sos_dict, execute global_def (definitions and imports),\n    and inject global variables'''\n    env.sos_dict.clear()\n\n    if not gdef and not gvars:\n        # SoS Notebook calls prepare_env without global statement from a\n        # particular\n        gdef, gvars = analyze_global_statements('')\n\n    if gdef:\n        exec(compile(gdef, filename=\"<ast>\", mode=\"exec\"), env.sos_dict._dict)\n\n    env.sos_dict.quick_update(gvars)\n    env.sos_dict.quick_update(extra_vars)\n    if 'CONFIG' not in env.sos_dict:\n        # if this is in sos notebook\n        load_config_files()\n    if 'hosts' not in env.sos_dict[\n            'CONFIG'] and 'localhost' not in env.sos_dict['CONFIG']:\n        env.sos_dict['CONFIG']['localhost'] = 'localhost'\n        env.sos_dict['CONFIG']['hosts'] = {\n            'localhost': {\n                'paths': {},\n                'address': 'localhost'\n            }\n        }\n    # expose `paths` of localhost\n    if host == 'localhost':\n        if 'localhost' in env.sos_dict['CONFIG']:\n            if 'hosts' not in env.sos_dict['CONFIG'] or env.sos_dict['CONFIG'][\n                    'localhost'] not in env.sos_dict['CONFIG']['hosts']:\n                env.logger.warning(\n                    f\"Localhost {env.sos_dict['CONFIG']['localhost']} is not defined in CONFIG['hosts']\"\n                )\n                env.sos_dict['CONFIG']['hosts'][env.sos_dict['CONFIG']\n                                                ['localhost']] = {\n                                                    'paths': {},\n                                                    'address': 'localhost'\n                                                }\n            env.sos_dict.set('__host__', env.sos_dict['CONFIG']['localhost'])\n        else:\n            if 'hosts' in env.sos_dict['CONFIG']:\n                if 'localhost' not in env.sos_dict['CONFIG']['hosts']:\n                    env.logger.warning('locahost is not defined in \"hosts\".')\n                    env.sos_dict['CONFIG']['hosts']['localhost'] = {\n                        'paths': {},\n                        'address': 'localhost'\n                    }\n            elif 'paths' not in env.sos_dict['CONFIG']['hosts']['localhost']:\n                env.sos_dict['CONFIG']['hosts']['localhost']['paths'] = {}\n            env.sos_dict.set('__host__', 'localhost')\n    else:\n        if 'hosts' not in env.sos_dict['CONFIG'] or host not in env.sos_dict[\n                'CONFIG']['hosts']:\n            raise RuntimeError(\n                f\"Remote host {host} is not defined in CONFIG['hosts']. Available ones are {env.sos_dict['CONFIG']['hosts'].keys()}\"\n            )\n        env.sos_dict.set('__host__', host)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_dangling_targets(self,\n                                 dag: SoS_DAG,\n                                 targets: Optional[sos_targets] = None) -> int:\n        '''Feed dangling targets with their dependncies from auxiliary steps,\n        optionally add other targets'''\n        resolved = 0\n        while True:\n            added_node = 0\n            # first resolve missing\n            dangling_targets = dag.dangling(targets)[0]\n            if dangling_targets:\n                env.log_to_file(\n                    'EXECUTOR',\n                    f'Resolving {dangling_targets} objects from {dag.number_of_nodes()} nodes'\n                )\n            # find matching steps\n            # check auxiliary steps and see if any steps provides it\n            remaining_targets = dangling_targets\n            while remaining_targets:\n                target = remaining_targets.pop()\n                mo = self.match(target)\n                if not mo:\n                    #\n                    # if no step produces the target, it is possible that it is an indexed step\n                    # so the execution of its previous steps would solves the dependency\n                    #\n                    # find all the nodes that depends on target\n                    nodes = dag._all_depends_files[target]\n                    for node in nodes:\n                        # if this is an index step... simply let it depends on previous steps\n                        if node._node_index is not None:\n                            indexed = [\n                                x for x in dag.nodes()\n                                if x._node_index is not None and\n                                x._node_index < node._node_index and\n                                not x._output_targets.valid()\n                            ]\n                            indexed.sort(key=lambda x: x._node_index)\n                            if not indexed:\n                                raise RuntimeError(\n                                    f'No step to generate target {target}{dag.steps_depending_on(target, self.workflow)}'\n                                )\n                            if isinstance(target, sos_step) and not any(\n                                    self.workflow.section_by_id(x._step_uuid)\n                                    .match(target.target_name())\n                                    for x in indexed):\n                                raise RuntimeError(\n                                    f'No step to generate target {target}{dag.steps_depending_on(target, self.workflow)}'\n                                )\n                            # now, if it is not a sos_step, but its previous steps have already been executed and still\n                            # could not satisfy the requirement..., we should generate an error\n                            if not any(\n                                    x._status is None or\n                                    x._status.endswith('pending')\n                                    for x in indexed):\n                                # all previous status has been failed or completed...\n                                raise RuntimeError(\n                                    f'Previous step{\" has\" if len(indexed) == 1 else \"s have\"} not generated target {target}{dag.steps_depending_on(target, self.workflow)}'\n                                )\n                            if node._input_targets.valid():\n                                node._input_targets = sos_targets([])\n                            if node._depends_targets.valid():\n                                node._depends_targets = sos_targets([])\n                        else:\n                            raise RuntimeError(\n                                f'No step to generate target {target}{dag.steps_depending_on(target, self.workflow)}'\n                            )\n                    if nodes:\n                        resolved += 1\n                    # cannot resolve, but the step is numerically indexed so we just wait\n                    continue\n                if len(mo) > 1:\n                    # sos_step('a') could match to step a_1, a_2, etc, in this case we are adding a subworkflow\n                    if isinstance(target, sos_step):\n                        # create a new forward_workflow that is different from the master one\n                        # get the step names\n                        sections = sorted(mo, key=lambda x: x.step_name())\n                        # this is only useful for executing auxiliary steps and\n                        # might interfere with the step analysis\n                        env.sos_dict.pop('__default_output__', None)\n                        env.log_to_file(\n                            'DAG',\n                            f'Adding {len(sections)} steps to resolve target {target}'\n                        )\n\n                        n_added = self.add_forward_workflow(\n                            dag, sections, satisfies=target)\n\n                        added_node += n_added\n                        resolved += 1\n                        # dag.show_nodes()\n                        continue\n                    else:\n                        raise RuntimeError(\n                            f'Multiple steps {\", \".join(x.step_name() for x in mo)} to generate target {target}'\n                        )\n                #\n                # m0[0] can be a tuple\n                #   section, context\n                # or just a section\n                #   section\n                if isinstance(mo[0], tuple):\n                    # for auxiliary, we need to set input and output, here\n                    # now, if the step does not provide any alternative (e.g. no variable generated\n                    # from patten), we should specify all output as output of step. Otherwise the\n                    # step will be created for multiple outputs. issue #243\n                    if mo[0][1]:\n                        env.sos_dict['__default_output__'] = sos_targets(target)\n                    else:\n                        env.sos_dict['__default_output__'] = sos_targets(\n                            mo[0][0].options['provides'])\n                    n_added, _ = self.add_backward_step(\n                        dag,\n                        section=mo[0][0],\n                        context=mo[0][1] if isinstance(mo[0][1], dict) else {},\n                        target=target)\n                else:\n                    env.sos_dict['__default_output__'] = sos_targets(target)\n                    n_added, _ = self.add_backward_step(\n                        dag, section=mo[0], context={}, target=target)\n\n                added_node += n_added\n                resolved += n_added\n                # this could be made more efficient by removing step output directly\n                # but it is inefficient to remove elements from list\n                remaining_targets = dag.dangling(remaining_targets)[0]\n\n            # for existing targets that are not in DAG\n            traced = [x for x in targets if x.traced]\n            if not env.config['trace_existing'] and not traced:\n                if added_node == 0:\n                    break\n                else:\n                    continue\n\n            existing_targets = set(dag.dangling(\n                targets)[1]) if env.config['trace_existing'] else traced\n\n            remaining_targets = existing_targets\n            while remaining_targets:\n                target = remaining_targets.pop()\n                # now we need to build DAG for existing...\n                mo = self.match(target)\n                if not mo:\n                    # this is ok, this is just an existing target, no one is designed to\n                    # generate it.\n                    continue\n                if len(mo) > 1:\n                    # this is not ok.\n                    raise RuntimeError(\n                        f'Multiple steps {\", \".join(x.step_name() for x in mo)} to generate target {target}'\n                    )\n\n                if isinstance(mo[0], tuple):\n                    # for auxiliary, we need to set input and output, here\n                    # now, if the step does not provide any alternative (e.g. no variable generated\n                    # from patten), we should specify all output as output of step. Otherwise the\n                    # step will be created for multiple outputs. issue #243\n                    if mo[0][1]:\n                        env.sos_dict['__default_output__'] = sos_targets(target)\n                    else:\n                        env.sos_dict['__default_output__'] = sos_targets(\n                            mo[0][0].options['provides'])\n                    n_added, resolved_output = self.add_backward_step(\n                        dag,\n                        section=mo[0][0],\n                        context=mo[0][1] if isinstance(mo[0][1], dict) else {},\n                        target=target)\n                else:\n                    env.sos_dict['__default_output__'] = sos_targets(target)\n                    n_added, resolved_output = self.add_backward_step(\n                        dag, section=mo[0], context={}, target=target)\n\n                added_node += n_added\n                resolved += n_added\n\n                # adding one step can resolve many targets #1199\n                if len(resolved_output) > 1:\n                    remaining_targets -= set(resolved_output.targets)\n                    # set(dag.dangling(remaining_targets)[1])\n\n            if added_node == 0:\n                break\n        return resolved", "response": "Feed dangling targets with their dependncies from auxiliary steps and optionally add other targets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_forward_workflow(self, dag, sections, satisfies=None):\n        '''Add a forward-workflow, return number of nodes added\n        '''\n        dag.new_forward_workflow()\n\n        if 'DAG' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file(\n                'DAG', f'Adding mini-workflow with {len(sections)} sections')\n        default_input: sos_targets = sos_targets([])\n        for idx, section in enumerate(sections):\n            #\n            res = analyze_section(section, default_input=default_input)\n\n            environ_vars = res['environ_vars']\n            signature_vars = res['signature_vars']\n            changed_vars = res['changed_vars']\n            # parameters, if used in the step, should be considered environmental\n            environ_vars |= env.parameter_vars & signature_vars\n\n            # add shared to targets\n            if res['changed_vars']:\n                if 'provides' in section.options:\n                    if isinstance(section.options['provides'], str):\n                        section.options.set('provides',\n                                            [section.options['provides']])\n                else:\n                    section.options.set('provides', [])\n                #\n                section.options.set(\n                    'provides', section.options['provides'] +\n                    [sos_variable(var) for var in changed_vars])\n\n            context = {\n                '__signature_vars__': signature_vars,\n                '__environ_vars__': environ_vars,\n                '__changed_vars__': changed_vars,\n                '__dynamic_depends__': res['dynamic_depends'],\n                '__dynamic_input__': res['dynamic_input']\n            }\n\n            # for nested workflow, the input is specified by sos_run, not None.\n            if idx == 0:\n                context['__step_output__'] = env.sos_dict['__step_output__']\n            # can be the only step\n            if idx == len(sections) - 1 and satisfies is not None:\n                res['step_output'].extend(satisfies)\n\n            dag.add_step(\n                section.uuid,\n                section.step_name(),\n                idx,\n                res['step_input'],\n                res['step_depends'],\n                res['step_output'],\n                context=context)\n            default_input = res['step_output']\n        return len(sections)", "response": "Add a forward - workflow to the DAG."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize_dag(self,\n                       targets: Optional[List[str]] = [],\n                       nested: bool = False) -> SoS_DAG:\n        '''Create a DAG by analyzing sections statically.'''\n        self.reset_dict()\n\n        dag = SoS_DAG(name=self.md5)\n        targets = sos_targets(targets)\n\n        self.add_forward_workflow(dag, self.workflow.sections)\n        #\n        if self.resolve_dangling_targets(dag, targets) == 0:\n            if targets:\n                raise UnknownTarget(f'No step to generate target {targets}.')\n        # now, there should be no dangling targets, let us connect nodes\n        dag.build()\n\n        # dag.show_nodes()\n        # trim the DAG if targets are specified\n        if targets:\n            dag = dag.subgraph_from(targets)\n        # check error\n        cycle = dag.circular_dependencies()\n        if cycle:\n            raise RuntimeError(\n                f'Circular dependency detected {cycle}. It is likely a later step produces input of a previous step.'\n            )\n        dag.save(env.config['output_dag'])\n        return dag", "response": "Create a DAG by analyzing sections statically."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef short_repr(obj, noneAsNA=False):\n    '''Return a short representation of obj for clarity.'''\n    if obj is None:\n        return 'unspecified' if noneAsNA else 'None'\n    elif isinstance(obj, str) and len(obj) > 80:\n        return '{}...{}'.format(obj[:60].replace('\\n', '\\\\n'),\n                                obj[-20:].replace('\\n', '\\\\n'))\n    elif isinstance(obj, (str, int, float, bool)):\n        return repr(obj)\n    elif hasattr(obj, '__short_repr__'):\n        return obj.__short_repr__()\n    elif isinstance(obj, Sequence):  # should be a list or tuple\n        if len(obj) == 0:\n            return '[]'\n        elif len(obj) == 1:\n            return f'{short_repr(obj[0])}'\n        elif len(obj) == 2:\n            return f'{short_repr(obj[0])}, {short_repr(obj[1])}'\n        else:\n            return f'{short_repr(obj[0])}, {short_repr(obj[1])}, ... ({len(obj)} items)'\n    elif isinstance(obj, dict):\n        if not obj:\n            return ''\n        elif len(obj) == 1:\n            first_key = list(obj.keys())[0]\n            return f'{short_repr(first_key)!r}:{short_repr(obj[first_key])!r}'\n        else:\n            first_key = list(obj.keys())[0]\n            return f'{short_repr(first_key)}:{short_repr(obj[first_key])}, ... ({len(obj)} items)'\n    elif isinstance(obj, KeysView):\n        if not obj:\n            return ''\n        elif len(obj) == 1:\n            return short_repr(next(iter(obj)))\n        else:\n            return f'{short_repr(next(iter(obj)))}, ... ({len(obj)} items)'\n    #elif hasattr(obj, 'target_name'):\n    #    return obj.target_name()\n    else:\n        ret = str(obj)\n        if len(ret) > 40:\n            return f'{repr(obj)[:35]}...'\n        else:\n            return ret", "response": "Return a short representation of obj for clarity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dehtml(text):\n    '''Remove HTML tag in input text and format the texts\n    accordingly. '''\n    try:\n        parser = _DeHTMLParser()\n        parser.feed(text)\n        parser.close()\n        return parser.text()\n    except Exception as e:\n        env.logger.warning(f'Failed to dehtml text: {e}')\n        return text", "response": "Remove HTML tag in input text and format the texts\n    accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef natural_keys(text):\n    '''\n    alist.sort(key=natural_keys) sorts in human order\n    http://nedbatchelder.com/blog/200712/human_sorting.html\n    (See Toothy's implementation in the comments)\n    '''\n    return [int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', text)]", "response": "Sort the text in natural order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_merge(dct, merge_dct):\n    for k, v in merge_dct.items():\n        if (k in dct and isinstance(dct[k], dict) and isinstance(v, dict)):\n            dict_merge(dct[k], v)\n        else:\n            dct[k] = v", "response": "Recursive dict merge. Inspired by dict. update."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing command line arguments and set values to parameters section.", "response": "def sos_handle_parameter_(key, defvalue):\n    '''Parse command line arguments and set values to parameters section.\n    NOTE: parmeters will not be handled if it is already defined in\n    the environment. This makes the parameters variable.\n    '''\n    env.parameter_vars.add(key)\n    # if no argument is provided\n    if not env.config['workflow_args'] and not env.config['workflow_vars']:\n        if isinstance(defvalue, type):\n            raise ArgumentError(\n                f'Argument {key} of type {defvalue.__name__} is required')\n        else:\n            return defvalue\n    #\n    if env.config['workflow_vars']:\n        if key in env.config['workflow_vars']:\n            return env.config['workflow_vars'][key]\n\n    parser = argparse.ArgumentParser(allow_abbrev=False)\n    # thre is a possibility that users specify --cut-off instead of --cut_off for parameter\n    # cut_off. It owuld be nice to allow both.\n    #\n    # Argparse would produce cut_off for both definition of --cut-off and --cut_off, however\n    # you can only use the matching input...\n    from .targets import path, paths, sos_targets, file_target\n    ret_type = None\n\n    if isinstance(defvalue, type) or defvalue is None:\n        if defvalue == bool:\n            feature_parser = parser.add_mutually_exclusive_group(required=True)\n            feature_parser.add_argument(\n                f'--{key}', dest=key, action='store_true')\n            feature_parser.add_argument(\n                f'--no-{key}', dest=key, action='store_false')\n            if '_' in key:\n                feature_parser.add_argument(\n                    f'--{key.replace(\"_\", \"-\")}', dest=key, action='store_true')\n                feature_parser.add_argument(\n                    f'--no-{key.replace(\"_\", \"-\")}',\n                    dest=key,\n                    action='store_false')\n        else:\n            if defvalue is None:\n                defvalue = str\n            if defvalue in (sos_targets, paths):\n                ret_type = defvalue\n            # if only a type is specified, it is a required document of required type\n            if '_' in key:\n                feature_parser = parser.add_mutually_exclusive_group(\n                    required=True)\n                feature_parser.add_argument(\n                    f'--{key}',\n                    dest=key,\n                    type=str if hasattr(defvalue, '__iter__') and\n                    defvalue not in (file_target, path) else defvalue,\n                    help='',\n                    nargs='+' if defvalue not in (str, file_target) and\n                    hasattr(defvalue, '__iter__') else '?')\n                feature_parser.add_argument(\n                    f'--{key.replace(\"_\", \"-\")}',\n                    dest=key,\n                    type=str if hasattr(defvalue, '__iter__') and\n                    defvalue not in (file_target, path) else defvalue,\n                    help='',\n                    nargs='+' if defvalue not in (str, file_target) and\n                    hasattr(defvalue, '__iter__') else '?')\n            else:\n                parser.add_argument(\n                    f'--{key}',\n                    dest=key,\n                    type=str if hasattr(defvalue, '__iter__') and\n                    defvalue not in (file_target, path) else defvalue,\n                    help='',\n                    required=True,\n                    nargs='+' if defvalue not in (str, file_target, path) and\n                    hasattr(defvalue, '__iter__') else '?')\n    else:\n        if isinstance(defvalue, bool):\n            feature_parser = parser.add_mutually_exclusive_group(required=False)\n            feature_parser.add_argument(\n                f'--{key}', dest=key, action='store_true')\n            feature_parser.add_argument(\n                f'--no-{key}', dest=key, action='store_false')\n            if '_' in key:\n                feature_parser.add_argument(\n                    f'--{key.replace(\"_\", \"-\")}', dest=key, action='store_true')\n                feature_parser.add_argument(\n                    f'--no-{key.replace(\"_\", \"-\")}',\n                    dest=key,\n                    action='store_false')\n            feature_parser.set_defaults(**{key: defvalue})\n        else:\n            if isinstance(defvalue, (file_target, path)):\n                deftype = type(defvalue)\n            elif isinstance(defvalue, paths):\n                deftype = path\n                ret_type = type(defvalue)\n            elif isinstance(defvalue, sos_targets):\n                deftype = file_target\n                ret_type = type(defvalue)\n            elif isinstance(defvalue, str):\n                deftype = str\n            elif isinstance(defvalue, Sequence):\n                if len(defvalue) > 0:\n                    deftype = type(defvalue[0])\n                else:\n                    deftype = str\n            else:\n                deftype = type(defvalue)\n\n            if '_' in key:\n                feature_parser = parser.add_mutually_exclusive_group(\n                    required=False)\n                feature_parser.add_argument(\n                    f'--{key}',\n                    dest=key,\n                    type=deftype,\n                    nargs='*' if isinstance(defvalue, Sequence) and\n                    not isinstance(defvalue, str) else '?',\n                    default=defvalue)\n                feature_parser.add_argument(\n                    f'--{key.replace(\"_\", \"-\")}',\n                    dest=key,\n                    type=deftype,\n                    nargs='*' if isinstance(defvalue, Sequence) and\n                    not isinstance(defvalue, str) else '?',\n                    default=defvalue)\n            else:\n                parser.add_argument(\n                    f'--{key}',\n                    dest=key,\n                    type=deftype,\n                    nargs='*' if isinstance(defvalue, Sequence) and\n                    not isinstance(defvalue, str) else '?',\n                    default=defvalue)\n    #\n    parser.error = _parse_error\n    parsed, _ = parser.parse_known_args(env.config['workflow_args'])\n    return ret_type(vars(parsed)[key]) if ret_type else vars(parsed)[key]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a n lines from a file and returns the last n lines.", "response": "def tail_of_file(filename, n, ansi2html=False):\n    \"\"\"Reads a n lines from f with an offset of offset lines. \"\"\"\n    avg_line_length = 74\n    to_read = n\n\n    with open(filename) as f:\n        while 1:\n            try:\n                f.seek(-(avg_line_length * to_read), 2)\n            except IOError:\n                # woops.  apparently file is smaller than what we want\n                # to step back, go to the beginning instead\n                f.seek(0)\n            pos = f.tell()\n            lines = f.read().splitlines()\n            if len(lines) >= to_read or pos == 0:\n                if ansi2html:\n                    return convertAnsi2html('\\n'.join(lines[-to_read:]))\n                return '\\n'.join(lines[-to_read:]) + '\\n'\n            avg_line_length *= 1.3"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample_lines(lines, n):\n    '''Draw a sample of n lines from filename, largely evenly.'''\n    if len(lines) <= n:\n        return ''.join(lines)\n    else:\n        m = len(lines)\n        return ''.join([lines[x * m // n + m // (2 * n)] for x in range(n)])", "response": "Draw a sample of n lines from filename largely evenly."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nredefine update to trigger logging message", "response": "def update(self, obj):\n        '''Redefine update to trigger logging message'''\n        self._dict.update(obj)\n        for k, v in obj.items():\n            # if k.isupper():\n            #    self._check_readonly(k, v)\n            if env.verbosity > 2:\n                self._log(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls a Cran or BioC package.", "response": "def _install(self, name, version, repos):\n        '''Check existence and version match of R library.\n        cran and bioc packages are unique yet might overlap with github.\n        Therefore if the input name is {repo}/{pkg} the package will be\n        installed from github if not available, else from cran or bioc\n        '''\n        from sos.pattern import glob_wildcards\n        import tempfile\n        import subprocess\n\n        output_file = tempfile.NamedTemporaryFile(\n            mode='w+t', suffix='.txt', delete=False).name\n        script_file = tempfile.NamedTemporaryFile(\n            mode='w+t', suffix='.R', delete=False).name\n        #\n        package_loaded = 'suppressMessages(require(package, character.only=TRUE, quietly=TRUE))'\n        version_satisfied = 'TRUE'\n        for opt in ('==', '>=', '>', '<=', '<', '!='):\n            if opt in name:\n                if version is not None:\n                    raise ValueError(\n                        f\"Specifying 'version=' option in addition to '{name}' is not allowed\"\n                    )\n                name, version = [x.strip() for x in name.split(opt, 1)]\n                if ',' in version:\n                    raise ValueError(\n                        f'SoS does not yet support multiple version comparisons. {version} provided'\n                    )\n                version = (opt + version,)\n                break\n        if version is not None:\n            version = list(version)\n            operators = []\n            for idx, value in enumerate(version):\n                value = str(value)\n                if value.startswith('>='):\n                    operators.append('>=')\n                    version[idx] = value[2:]\n                elif value.startswith('>'):\n                    operators.append('>')\n                    version[idx] = value[1:]\n                elif value.startswith('<='):\n                    operators.append('<=')\n                    version[idx] = value[2:]\n                elif value.startswith('<'):\n                    operators.append('<')\n                    version[idx] = value[1:]\n                elif value.startswith('=='):\n                    operators.append('==')\n                    version[idx] = value[2:]\n                elif value.startswith('!='):\n                    operators.append('!=')\n                    version[idx] = value[2:]\n                else:\n                    operators.append('==')\n            # check version and mark version mismatch\n            # if current version satisfies any of the\n            # requirement the check program quits\n            version_satisfied = '||'.join([\n                f'(cur_version {y} {repr(x)})'\n                for x, y in zip(version, operators)\n            ])\n        #\n        if len(glob_wildcards('{repo}@{pkg}', [name])['repo']):\n            # package is from github\n            self._install('remotes', None, repos)\n            install_script = f'''\n            options(warn=-1)\n            package_repo <-strsplit(\"{name}\", split=\"@\")[[1]][2]\n            package <-strsplit(\"{name}\", split=\"@\")[[1]][1]\n            if ({package_loaded}) cur_version <- packageVersion(package) else cur_version <- NULL\n            if (!is.null(cur_version) && {version_satisfied}) {{\n                write(paste(package, cur_version, \"AVAILABLE\"), file={repr(output_file)})\n            }} else if ({\"TRUE\" if self._autoinstall else \"FALSE\"}) {{\n                remotes::install_github(package_repo, force = TRUE)\n                if ({package_loaded}) cur_version <- packageVersion(package) else cur_version <- NULL\n                # if it still does not exist, write the package name to output\n                if (!is.null(cur_version)) {{\n                    if ({version_satisfied}) write(paste(package, cur_version, \"INSTALLED\"), file={repr(output_file)})\n                    else write(paste(package, cur_version, \"VERSION_MISMATCH\"), file={repr(output_file)})\n                }} else {{\n                    write(paste(package, \"NA\", \"MISSING\"), file={repr(output_file)})\n                    quit(\"no\")\n                }}\n            }} else {{\n                if (!is.null(cur_version)) write(paste(package, cur_version, \"VERSION_MISMATCH\"), file={repr(output_file)}) else write(paste(package, cur_version, \"UNAVAILABLE\"), file={repr(output_file)})\n            }}\n            '''\n        else:\n            # package is from cran or bioc\n            install_script = f'''\n            options(warn=-1)\n            package <- \"{name}\"\n            if ({package_loaded}) cur_version <- packageVersion(package) else cur_version <- NULL\n            if (!is.null(cur_version) && {version_satisfied}) {{\n                write(paste(package, cur_version, \"AVAILABLE\"), file={repr(output_file)})\n            }} else if ({\"TRUE\" if self._autoinstall else \"FALSE\"}) {{\n                install.packages(package, repos=\"{repos}\", quiet=FALSE)\n                # if the package still does not exist\n                if (!{package_loaded}) {{\n                    source(\"http://bioconductor.org/biocLite.R\")\n                    biocLite(package, suppressUpdates=TRUE, suppressAutoUpdate=TRUE, ask=FALSE)\n                }}\n                if ({package_loaded}) cur_version <- packageVersion(package) else cur_version <- NULL\n                # if it still does not exist, write the package name to output\n                if (!is.null(cur_version)) {{\n                    if ({version_satisfied}) write(paste(package, cur_version, \"INSTALLED\"), file={repr(output_file)}) else write(paste(package, cur_version, \"VERSION_MISMATCH\"), file={repr(output_file)})\n                }} else {{\n                    write(paste(package, \"NA\", \"MISSING\"), file={repr(output_file)})\n                    quit(\"no\")\n                }}\n            }} else {{\n                if (!is.null(cur_version)) write(paste(package, cur_version, \"VERSION_MISMATCH\"), file={repr(output_file)}) else write(paste(package, cur_version, \"UNAVAILABLE\"), file={repr(output_file)})\n            }}\n            '''\n        # temporarily change the run mode to run to execute script\n        try:\n            with open(script_file, 'w') as sfile:\n                sfile.write(install_script)\n            #\n            p = subprocess.Popen(\n                ['Rscript', '--default-packages=utils', script_file])\n            ret = p.wait()\n            if ret != 0:\n                env.logger.warning(\n                    f'Failed to detect or install R library {name}')\n                return False\n        except Exception as e:\n            env.logger.error(f'Failed to execute script: {e}')\n            return False\n        finally:\n            os.remove(script_file)\n\n        ret_val = False\n        with open(output_file) as tmp:\n            for line in tmp:\n                lib, cur_version, status = line.split(' ', 2)\n                if status.strip() == \"MISSING\":\n                    env.logger.warning(\n                        f'R library {lib} is not available and cannot be installed.'\n                    )\n                elif status.strip() == \"UNAVAILABLE\":\n                    env.logger.warning(f'R library {lib} is not available.')\n                elif status.strip() == 'AVAILABLE':\n                    env.logger.debug(\n                        f'R library {lib} ({cur_version}) is available')\n                    ret_val = True\n                elif status.strip() == 'INSTALLED':\n                    env.logger.debug(\n                        f'R library {lib} ({cur_version}) has been installed')\n                    ret_val = True\n                elif status.strip() == 'VERSION_MISMATCH':\n                    env.logger.warning(\n                        f'R library {lib} ({cur_version}) does not satisfy version requirement ({\"/\".join(version)})!'\n                    )\n                else:\n                    raise RuntimeError(f'This should not happen: {line}')\n        try:\n            os.remove(output_file)\n        except Exception:\n            pass\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a substep with specific input etc.", "response": "def execute_substep(stmt,\n                    global_def,\n                    global_vars,\n                    task='',\n                    task_params='',\n                    proc_vars={},\n                    shared_vars=[],\n                    config={}):\n    '''Execute a substep with specific input etc\n\n    Substep executed by this function should be self-contained. It can contain\n    tasks (which will be sent to the master process) but not nested workflows.\n\n    The executor checks step signatures and might skip the substep if it has\n    been executed and the signature matches.\n\n    The executor accepts connections to the controller, and a socket using\n    which the results will be returned. However, the calling process should\n    take care of the connection and disconnection of controller sockets and\n    this function only takes care of the connection and disconnection of\n    result socket.\n\n    stmt:\n        Main statement of the substep\n\n    global_def:\n        Global definitions, might define functions useful to the substep\n\n    task:\n        External task\n\n    proc_vars:\n        Environmental variables, signature variables etc\n\n    shared_vars:\n        Variables that should be returned after the execution\n\n    config:\n        Runmode, signature mode, verbosity, etc.\n\n    The return value should be a dictionary with the following keys:\n\n    index: index of the substep within the step\n    ret_code: (all) return code, 0 for successful\n    sig_skipped: (optional) return if the step is skipped due to signature\n    shared: (optional) shared variable as specified by 'shared_vars'\n    stdout: (optional) if in interactive mode\n    stderr: (optional) if in interactive mode\n    exception: (optional) if an exception occures\n    '''\n    assert not env.zmq_context.closed\n    assert 'workflow_id' in proc_vars\n    assert 'step_id' in proc_vars\n    assert '_input' in proc_vars\n    assert '_output' in proc_vars\n    assert '_depends' in proc_vars\n    assert 'step_output' in proc_vars\n    assert '_index' in proc_vars\n    assert 'result_push_socket' in config[\"sockets\"]\n\n    # this should not happen but check nevertheless\n    if env.result_socket_port is not None and env.result_socket_port != config[\n            \"sockets\"][\"result_push_socket\"]:\n        close_socket(env.result_socket)\n        env.result_socket = None\n\n    if env.result_socket is None:\n        env.result_socket = create_socket(env.zmq_context, zmq.PUSH)\n        env.result_socket_port = config[\"sockets\"][\"result_push_socket\"]\n        env.result_socket.connect(f'tcp://127.0.0.1:{env.result_socket_port}')\n\n    res = _execute_substep(\n        stmt=stmt,\n        global_def=global_def,\n        global_vars=global_vars,\n        task=task,\n        task_params=task_params,\n        proc_vars=proc_vars,\n        shared_vars=shared_vars,\n        config=config)\n    env.result_socket.send_pyobj(res)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting files related to workflows related to current directory", "response": "def files(self):\n        '''Listing files related to workflows related to current directory'''\n        try:\n            cur = self.conn.cursor()\n            cur.execute(\n                'SELECT id, item FROM workflows WHERE entry_type = \"tracked_files\"'\n            )\n            return [(x[0], eval(x[1])) for x in cur.fetchall()]\n        except sqlite3.DatabaseError as e:\n            env.logger.warning(\n                f'Failed to get files from signature database: {e}')\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npatching Spyder to make it work with sos files and sos kernel", "response": "def patch_spyder2(verbose=False):\n    '''Patch spyder to make it work with sos files and sos kernel '''\n    try:\n        # patch spyderlib/config.py for file extension\n        from spyderlib import config\n        src_file = config.__file__\n        spyderlib_dir = os.path.dirname(src_file)\n        if verbose:\n            print('Patching {}'.format(src_file))\n        with open(src_file, encoding='utf-8') as src:\n            content = src.read()\n        with open(src_file, 'w', encoding='utf-8') as src:\n            src.write(content.replace('''\n    (_(\"Cython/Pyrex files\"), ('.pyx', '.pxd', '.pxi')),\n    (_(\"C files\"), ('.c', '.h')),''', '''\n    (_(\"Cython/Pyrex files\"), ('.pyx', '.pxd', '.pxi')),\n    (_(\"SoS files\"), ('.sos', )),\n    (_(\"C files\"), ('.c', '.h')),'''))\n        #\n        # patch spyderlib/cli_options.py to add command line option --kernel\n        src_file = os.path.join(spyderlib_dir, 'cli_options.py')\n        if verbose:\n            print('Patching {}'.format(src_file))\n        with open(src_file, encoding='utf-8') as src:\n            content = src.read()\n        with open(src_file, 'w', encoding='utf-8') as src:\n            src.write(content.replace('''with Python profiling)\")\n    options, args = parser.parse_args()''',\n            '''with Python profiling)\")\n    parser.add_option('--kernel', help=\"Jupyter kernel to start.\")\n    options, args = parser.parse_args()'''))\n        #\n        # patch spyderlib.utils.sourcecode.py,\n        src_file = os.path.join(spyderlib_dir, 'utils', 'sourcecode.py')\n        if verbose:\n            print('Patching {}'.format(src_file))\n        with open(src_file, encoding='utf-8') as src:\n            content = src.read()\n        with open(src_file, 'w', encoding='utf-8') as src:\n            src.write(content.replace(\n                \"'Python': ('py', 'pyw', 'python', 'ipy')\",\n                \"'Python': ('py', 'pyw', 'python', 'ipy', 'sos')\")\n                .replace(\n                '''CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[')}''',\n                '''CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[', '%cell')}''')\n            )\n        #\n        # patch spyderlib/spyder.py\n        src_file = os.path.join(spyderlib_dir, 'spyder.py')\n        if verbose:\n            print('Patching {}'.format(src_file))\n        with open(src_file, encoding='utf-8') as src:\n            content = src.read()\n        with open(src_file, 'w', encoding='utf-8') as src:\n            src.write(content.replace(\n            '''\n    app.exec_()\n''',\n            r'''\n    try:\n        if options.kernel == 'sos':\n            cfg_file = os.path.expanduser('~/.ipython/profile_default/ipython_config.py')\n            has_cfg = os.path.isfile(cfg_file)\n            if has_cfg and not os.path.isfile(cfg_file + '.sos_bak'):\n                os.rename(cfg_file, cfg_file + '.sos_bak')\n            with open(cfg_file, 'w') as cfg:\n                cfg.write(\"c.IPKernelApp.kernel_class =  'sos_notebook.kernel.SoS_Kernel'\\n\")\n        app.exec_()\n    finally:\n        if options.kernel == 'sos':\n            os.remove(cfg_file)\n            if os.path.isfile(cfg_file + '.sos_bak'):\n                os.rename(cfg_file + '.sos_bak', cfg_file)\n'''))\n        #\n        print('\\nSpyder is successfully patched to accept .sos format and sos kernel.')\n        print('Use ')\n        print()\n        print('    $ spyder --kernel sos')\n        print()\n        print('to start spyder with sos kernel')\n    except Exception as e:\n        sys.exit('Failed to patch spyder: {}'.format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npatching Spyder to make it work with sos files and sos kernels and sos kernels", "response": "def patch_spyder3(verbose=False):\n    '''Patch spyder to make it work with sos files and sos kernel '''\n    try:\n        # patch spyder/config/utils.py for file extension\n        from spyder.config import utils\n        src_file = utils.__file__\n        spyder_dir = os.path.dirname(os.path.dirname(src_file))\n        patch_file(src_file,\n        '''\n    (_(\"Cython/Pyrex files\"), ('.pyx', '.pxd', '.pxi')),\n    (_(\"C files\"), ('.c', '.h')),''',\n        '''\n    (_(\"Cython/Pyrex files\"), ('.pyx', '.pxd', '.pxi')),\n    (_(\"SoS files\"), ('.sos', )),\n    (_(\"C files\"), ('.c', '.h')),''',\n            verbose=verbose)\n        #\n        # patch spyder/app/cli_options.py to add command line option --kernel\n        patch_file(os.path.join(spyder_dir, 'app', 'cli_options.py'),\n            '''help=\"String to show in the main window title\")\n    options, args = parser.parse_args()''',\n            '''help=\"String to show in the main window title\")\n    parser.add_option('--kernel', help=\"Jupyter kernel to start.\")\n    options, args = parser.parse_args()''',\n            verbose=verbose)\n        #\n        # patch spyder/utils/sourcecode.py,\n        patch_file(os.path.join(spyder_dir, 'utils', 'sourcecode.py'),\n                \"'Python': ('py', 'pyw', 'python', 'ipy')\",\n                \"'Python': ('py', 'pyw', 'python', 'ipy', 'sos')\",\n            verbose=verbose)\n        patch_file(os.path.join(spyder_dir, 'utils', 'sourcecode.py'),\n                '''CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[')}''',\n                '''CELL_LANGUAGES = {'Python': ('#%%', '# %%', '# <codecell>', '# In[', '%cell')}''',\n            verbose=verbose)\n        #\n        # patch spyder/app/mainwindow.py\n        patch_file(os.path.join(spyder_dir, 'app', 'mainwindow.py'),\n            '''\n    app.exec_()\n''',\n            r'''\n    try:\n        if options.kernel == 'sos':\n            cfg_file = os.path.expanduser('~/.ipython/profile_default/ipython_config.py')\n            has_cfg = os.path.isfile(cfg_file)\n            if has_cfg and not os.path.isfile(cfg_file + '.sos_bak'):\n                os.rename(cfg_file, cfg_file + '.sos_bak')\n            with open(cfg_file, 'w') as cfg:\n                cfg.write(\"c.IPKernelApp.kernel_class =  'sos_notebook.spyder_kernel.SoS_SpyderKernel'\\n\")\n        app.exec_()\n    finally:\n        if options.kernel == 'sos':\n            os.remove(cfg_file)\n            if os.path.isfile(cfg_file + '.sos_bak'):\n                os.rename(cfg_file + '.sos_bak', cfg_file)\n''',\n            verbose=verbose)\n        #\n        print('\\nSpyder is successfully patched to accept .sos format and sos kernel.')\n        print('Use ')\n        print()\n        print('    $ spyder --kernel sos')\n        print()\n        print('to start spyder with sos kernel')\n    except Exception as e:\n        sys.exit('Failed to patch spyder: {}'.format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_executable(self):\n        '''Find an executable node, which means nodes that has not been completed\n        and has no input dependency.'''\n        if 'DAG' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('DAG', 'find_executable')\n        for node in self.nodes():\n            # if it has not been executed\n            if node._status is None:\n                with_dependency = False\n                for edge in self.in_edges(node):\n                    if edge[0]._status != 'completed':\n                        with_dependency = True\n                        break\n                if not with_dependency:\n                    return node\n        # if no node could be found, let use try pending ones\n        pending_jobs = [\n            x for x in self.nodes() if x._status == 'signature_pending'\n        ]\n        if pending_jobs:\n            try:\n                notifier = ActivityNotifier(\n                    f'Waiting for {len(pending_jobs)} pending job{\"s: e.g.\" if len(pending_jobs) > 1 else \":\"} output {short_repr(pending_jobs[0]._signature[0])} with signature file {pending_jobs[0]._signature[1] + \"_\"}. You can manually remove this lock file if you are certain that no other process is working on the output.'\n                )\n                while True:\n                    for node in pending_jobs:\n                        # if it has not been executed\n                        lock = fasteners.InterProcessLock(node._signature[1] +\n                                                          '_')\n                        if lock.acquire(blocking=False):\n                            lock.release()\n                            node._status = None\n                            return node\n                    time.sleep(0.1)\n            except Exception as e:\n                env.logger.error(e)\n            finally:\n                notifier.stop()\n        return None", "response": "Find an executable node which means nodes that have not been completed\n        and has no input dependency."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dangling(self, targets: sos_targets):\n        '''returns\n        1. missing targets, which are missing from the DAG or from the provided targets\n        2. existing targets of provided target list, not in DAG\n        '''\n        existing = []\n        missing = []\n        if env.config['trace_existing']:\n            for x in self._all_depends_files.keys():\n                if x not in self._all_output_files:\n                    if x.target_exists():\n                        existing.append(x)\n                    else:\n                        missing.append(x)\n        else:\n            missing = [\n                x for x in self._all_depends_files.keys()\n                if x not in self._all_output_files and not x.target_exists()\n            ]\n        for x in targets:\n            if x not in self._all_output_files:\n                if x.target_exists('target'):\n                    existing.append(x)\n                else:\n                    missing.append(x)\n        return missing, existing", "response": "returns a list of missing targets which are missing from the DAG or from the provided targets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrimming DAG to keep only nodes that produce targets", "response": "def subgraph_from(self, targets: sos_targets):\n        '''Trim DAG to keep only nodes that produce targets'''\n        if 'DAG' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('DAG', 'create subgraph')\n        # first, find all nodes with targets\n        subnodes = []\n        for node in self.nodes():\n            if node._output_targets.valid() and any(\n                    x in node._output_targets for x in targets):\n                subnodes.append(node)\n        #\n        ancestors = set()\n        for node in subnodes:\n            ancestors |= nx.ancestors(self, node)\n        return SoS_DAG(nx.subgraph(self, subnodes + list(ancestors)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build(self):\n        '''Connect nodes according to status of targets'''\n        # right now we do not worry about status of nodes\n        # connecting the output to the input of other nodes\n        #\n        # NOTE: This is implemented in the least efficient way just for\n        # testing. It has to be re-implemented.\n        #\n        # refer to http://stackoverflow.com/questions/33494376/networkx-add-edges-to-graph-from-node-attributes\n        #\n        # several cases triggers dependency.\n        if 'DAG' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('DAG', 'build DAG')\n        for wf in range(self._forward_workflow_id + 1):\n            indexed = [x for x in self.nodes() if x._wf_index == wf]\n            indexed.sort(key=lambda x: x._node_index)\n\n            for idx, node in enumerate(indexed):\n                # 1. if a node changes context (using option alias), all later steps\n                # has to rely on it.\n                if node._context['__changed_vars__']:\n                    for later_node in indexed[idx + 1:]:\n                        if node._context['__changed_vars__'] & (\n                                later_node._context['__signature_vars__']\n                                | later_node._context['__environ_vars__']):\n                            self.add_edge(node, later_node)\n\n                # 2. if the input of a step is undetermined, it has to be executed\n                # after all its previous steps.\n                if not node._input_targets.valid() and idx > 0:\n                    # if there is some input specified, it does not use default\n                    # input, so the relationship can be further looked before\n                    if node._input_targets.undetermined():\n                        # if the input is dynamic, has to rely on previous step...\n                        if 'dynamic' in node._context['__environ_vars__']:\n                            self.add_edge(indexed[idx - 1], node)\n                        else:\n                            # otherwise let us look back.\n                            for prev_node in indexed[idx - 1::-1]:\n                                if node._context[\n                                        '__environ_vars__'] & prev_node._context[\n                                            '__changed_vars__']:\n                                    self.add_edge(prev_node, node)\n                    else:\n                        self.add_edge(indexed[idx - 1], node)\n        #\n        # 3. if the input of a step depends on the output of another step\n        for target, in_node in self._all_depends_files.items():\n            if target not in self._all_output_files:\n                continue\n            # it is possible that multiple nodes satisfy the same target\n            out_node = self._all_output_files[target]\n            for i in in_node:\n                for j in out_node:\n                    if j != i:\n                        self.add_edge(j, i)\n        self.mark_dirty()", "response": "Connect nodes according to status of targets and connect edges to the output of other nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef monitor_tasks(self, tasks=None, status=None, age=None):\n        '''Start monitoring specified or all tasks'''\n        self.engine_ready.wait()\n        if not tasks:\n            tasks = self.task_status.keys()\n        else:\n            tasks = [x for x in tasks if x in self.task_status]\n\n        # we only monitor running tasks\n        with threading.Lock():\n            for task in tasks:\n                if self.task_status[task] in (\n                        'submitted',\n                        'running') and task not in self.running_tasks:\n                    # these tasks will be actively monitored\n                    self.running_tasks.append(task)\n        #\n        if age is not None:\n            age = expand_time(age, default_unit='d')\n        return sorted([\n            (x, self.task_status[x], self.task_info[x].get(\n                'data', (time.time(), None, None)))\n            for x in tasks\n            if (status is None or self.task_status[x] in status) and\n            (age is None or (\n                (age > 0 and time.time() -\n                 self.task_info[x].get('date',\n                                       (time.time(), None, None))[0] > age) or\n                (age < 0 and time.time() -\n                 self.task_info[x].get('date',\n                                       (time.time(), None, None))[0] < -age)))\n        ],\n                      key=lambda x: -x[2][0])", "response": "Start monitoring specified or all tasks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubmit tasks by interpolating a shell script defined in job_template", "response": "def _submit_task_with_template(self, task_ids):\n        '''Submit tasks by interpolating a shell script defined in job_template'''\n        runtime = self.config\n        runtime.update({\n            'workdir': os.getcwd(),\n            'cur_dir': os.getcwd(),  # for backward compatibility\n            'verbosity': env.verbosity,\n            'sig_mode': env.config.get('sig_mode', 'default'),\n            'run_mode': env.config.get('run_mode', 'run'),\n            'home_dir': os.path.expanduser('~')\n        })\n        if '_runtime' in env.sos_dict:\n            runtime.update({\n                x: env.sos_dict['_runtime'][x]\n                for x in ('nodes', 'cores', 'workdir', 'mem', 'walltime')\n                if x in env.sos_dict['_runtime']\n            })\n        if 'nodes' not in runtime:\n            runtime['nodes'] = 1\n        if 'cores' not in runtime:\n            runtime['cores'] = 1\n\n        # let us first prepare a task file\n        job_text = ''\n        for task_id in task_ids:\n            runtime['task'] = task_id\n            try:\n                job_text += cfg_interpolate(self.job_template, runtime)\n                job_text += '\\n'\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to generate job file for task {task_id}: {e}')\n\n        filename = task_ids[0] + ('.sh' if len(task_ids) == 1 else\n                                  f'-{task_ids[-1]}.sh')\n        # now we need to write a job file\n        job_file = os.path.join(\n            os.path.expanduser('~'), '.sos', 'tasks', filename)\n        # do not translate newline under windows because the script will be executed\n        # under linux/mac\n        with open(job_file, 'w', newline='') as job:\n            job.write(job_text)\n\n        # then copy the job file to remote host if necessary\n        self.agent.send_task_file(job_file)\n\n        try:\n            cmd = f'bash ~/.sos/tasks/{filename}'\n            self.agent.run_command(cmd, wait_for_task=self.wait_for_task)\n        except Exception as e:\n            raise RuntimeError(f'Failed to submit task {task_ids}: {e}')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if statement is a type hint or not.", "response": "def is_type_hint(stmt: str) -> bool:\n    '''Try to differentiate\n\n    var: type = value\n\n    with\n\n    action: input = whatever\n\n    '''\n    if stmt.count('=') > 1:\n        return False\n\n    if ':' not in stmt:\n        return False\n\n    #\n    # action:\n    if not stmt.split(':')[1].strip():\n        return False\n\n    #\n    # action: int\n    #\n    # or\n    #\n    # input: variable\n    #\n    if '=' not in stmt:\n        action, par = [x.strip() for x in stmt.split(':', 1)]\n    else:\n        # one parameter?\n        #\n        # action: input={'a': b}\n        #\n        action, par = [x.strip() for x in stmt.split('=', 1)[0].split(':', 1)]\n\n    if action in SOS_DIRECTIVES:\n        return False\n    if par in SOS_ACTION_OPTIONS:\n        return False\n\n    # if par is something like List[Any], or 'classname'\n    if not par.isidentifier():\n        return True\n\n    # if action is a builtin function, such as sort, it cannot be\n    # a variable assignment.\n    if action in dir(builtins):\n        return False\n\n    # if action is registered\n    global _action_list\n    if _action_list is None:\n        import pkg_resources\n        _action_list = [\n            x.name for x in pkg_resources.iter_entry_points(group='sos_actions')\n        ]\n    if action in _action_list:\n        return False\n\n    # if par is something like List, Tuple, str\n    if par in dir(typing) or par in dir(builtins):\n        return True\n\n    # if not quite sure???\n    env.logger.debug(\n        f\"Failed to tell if '{stmt}' is an assignment with type hint or function in script format. Assuming type hint.\"\n    )\n    # regular function written in this format?\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef indented_script(self) -> bool:\n        ''' check self._script and see if it is indented '''\n        # get all leading space, tab and newline\n        leading = INDENTED.match(self._script)\n        return 0 if leading is None else len(leading.group(2))", "response": "check self. _script and see if it is indented"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef category(self) -> Optional[str]:\n        '''Determine the category of existing statement'''\n        if self.statements:\n            if self.statements[-1][0] == ':':\n                # a hack. ... to avoid calling isValid recursively\n                def validDirective():\n                    if not self.values:\n                        return True\n                    if self.values[-1].strip().endswith(','):\n                        return False\n                    try:\n                        compile(\n                            'func(' + ''.join(self.values) + ')',\n                            filename='<string>',\n                            mode='eval')\n                    except Exception:\n                        return False\n                    return True\n\n                if validDirective() and self._action is not None:\n                    return 'script'\n                return 'directive'\n            return 'statements'\n        return None", "response": "Determine the category of existing statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextends the current directive expression or script", "response": "def extend(self, line: str) -> None:\n        '''Extend the current directive, expression or script'''\n        if self.category() == 'directive':\n            self.add_directive(None, line)\n        elif self.category() == 'script':\n            self._script += line\n        else:\n            self.add_statement(line)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new directive to the list of statements and values.", "response": "def add_directive(self,\n                      key: Optional[str],\n                      value: str,\n                      lineno: Optional[int] = None,\n                      comment: str = '') -> None:\n        '''Assignments are items with ':' type '''\n        if key is None:\n            # continuation of multi-line directive\n            self.statements[-1][2] += value\n            self.values.append(value)\n            if self._action is not None:\n                self._action_options += value\n        else:\n            # new directive, the comment before it are used\n            self.statements.append([':', key, value, comment])\n            self.values = [value]\n        if lineno:\n            self.lineno = lineno"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a script to the log", "response": "def add_script(self, key: str, value: str,\n                   lineno: Optional[int] = None) -> None:\n        '''script starts with key: value'''\n        # we need a fake directive here because the : directive can be multi-line and\n        # we need to borrow the syntax checking of directives here.\n        self.statements.append([':', '__script__', ''])\n        self.values = [value]\n        self._action = key\n        self._action_options = value\n        if lineno:\n            self.lineno = lineno"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a statement to the log.", "response": "def add_statement(self, line: str, lineno: Optional[int] = None) -> None:\n        '''statements are regular python statements'''\n        # there can be only one statement block\n        if self.category() != 'statements':\n            self.values = [line]\n        else:\n            self.values.append(line)\n        if self.statements and self.statements[-1][0] == '!':\n            self.statements[-1][-1] += line\n        else:\n            self.statements.append(['!', line])\n        if lineno:\n            self.lineno = lineno"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap_script(self) -> None:\n        '''convert action: script to task: action(script)'''\n        if self._action is None:\n            return\n        # _action options can contain both runtime option and action options\n        opt = self._action_options.strip()\n        if self.statements[-1][0] != ':' or self.statements[-1][\n                1] != '__script__':\n            raise RuntimeError('Failed to parse script')\n        # under window, the lines will be ended with \\r\\n, which will cause\n        # trouble with textwrap.dedent.\n        self._script = '\\n'.join(self._script.splitlines()) + '\\n'\n        # dedent, which will not remove empty line, so _scrit will always ends with \\n.\n        self._script = textwrap.dedent(self._script)\n        # let us look for 'expand=\"\"' in options\n        if 'expand' in opt:\n            sigil, opt = extract_option_from_arg_list(opt, 'expand', None)\n            if sigil is None or sigil is False:\n                # no expansion\n                self._script = repr(self._script)\n            elif sigil is True:\n                self._script = as_fstring(self._script)\n            else:\n                self._script = as_fstring(replace_sigil(self._script, sigil))\n        else:\n            # verbatim script, use repr is enough\n            self._script = repr(self._script)\n        self.statements[-1] = [\n            '!',\n            f'{self._action}({self._script}{(\", \" + opt) if opt else \"\"})\\n'\n        ]\n        self.values = []\n        self._action = None\n        self._action_options = None\n        self._script = ''", "response": "wrap the script in a new line and return the new entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tokens(self) -> str:\n        '''Get tokens after input statement'''\n\n        def _get_tokens(statement):\n            return [\n                x[1]\n                for x in generate_tokens(StringIO(statement).readline)\n                if x[1] not in ('', '\\n')\n            ]\n\n        tokens: List = []\n        for statement in self.statements:\n            tokens.extend(\n                _get_tokens(statement[2] if statement[0] ==\n                            ':' else statement[1]))\n\n        if self.task:\n            tokens.extend(_get_tokens(self.task))\n\n        return ' '.join(tokens)", "response": "Get tokens after input statement"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finalize(self) -> None:\n        ''' split statement and task by last directive '''\n        self.wrap_script()\n        if not self.statements:\n            self.task = ''\n            return\n        # handle tasks\n        input_directive = [\n            idx for idx, statement in enumerate(self.statements)\n            if statement[0] == ':' and statement[1] == 'input'\n        ]\n        task_directive = [\n            idx for idx, statement in enumerate(self.statements)\n            if statement[0] == ':' and statement[1] == 'task'\n        ]\n        if len(task_directive) > 1:\n            raise ValueError('Only one task statement is allowed in a step')\n        # handle parameter\n        for idx, statement in enumerate(self.statements):\n            if statement[0] == ':' and statement[1] == 'parameter':\n                if task_directive and task_directive[0] < idx:\n                    raise ValueError(\n                        'Parameter statement is not allowed in tasks.')\n                if '=' not in statement[2]:\n                    if ':' in statement[2]:\n                        if not is_type_hint(statement[2]):\n                            raise ValueError(\n                                f'Invalid type trait in parameter specification {statement[2]}'\n                            )\n                        name, value = statement[2].split(':')\n                    else:\n                        name = statement[2]\n                        value = 'str'\n                else:\n                    name, value = statement[2].split('=', 1)\n                    # ignore type trait if a default value is specified\n                    name = name.split(':')[0]\n                name = name.strip()\n                if name.startswith('_'):\n                    raise ValueError(\n                        f'Invalid parameter name {name}: names with leading underscore is not allowed.'\n                    )\n                if not value.strip():\n                    raise ValueError(\n                        f'{self.step_name()}: Invalid parameter definition: {statement[2]}'\n                    )\n                # there is a possibility that value contains # so  sos_handle_parameter(name, val # aaa) will fail\n                self.statements[idx] = [\n                    '!',\n                    f'#begin_parameter {name}\\n{name} = sos_handle_parameter_({name.strip()!r}, {value}\\n) #end_parameter {name}\\n',\n                    statement[2].strip()\n                ]\n                self.parameters[name] = (value, statement[3])\n                if input_directive and input_directive[0] < idx:\n                    self.substep_parameters.add(name)\n        # handle tasks\n        if not task_directive:\n            self.task = ''\n        else:\n            start_task = task_directive[0] + 1\n            # convert statement to task\n            self.task = ''\n            for statement in self.statements[start_task:]:\n                if statement[0] == ':':\n                    if statement[1] in ('input', 'output', 'depends'):\n                        raise ValueError(\n                            f'{self.step_name()}: Step task should be defined as the last item in a SoS step'\n                        )\n                    elif statement[1] == 'task':\n                        raise ValueError(\n                            f'{self.step_name()}: Only one task is allowed for a step'\n                        )\n                    elif statement[1] == 'parameter':\n                        raise ValueError(\n                            f'{self.step_name()}: Parameters should be defined before step task'\n                        )\n                    # ignore ...\n                    self.task += '\\n'\n                else:\n                    self.task += statement[1]\n            self.task_params = self.statements[task_directive[0]][2]\n            self.statements = self.statements[:task_directive[0]]\n        # merge multiple statments at the end\n        if len(self.statements) > 1 and self.statements[-1][0] == '!':\n            starting = len(self.statements) - 1\n            for idx in range(starting - 1, -1, -1):\n                if self.statements[idx][0] == '!':\n                    starting = idx\n                else:\n                    break\n            # merge\n            for idx in range(starting + 1, len(self.statements)):\n                self.statements[starting][1] += self.statements[idx][1]\n            # remove the rest of the statements\n            self.statements = self.statements[:starting + 1]\n        #\n        # auto provides #859\n        if not any(opt in self.options for opt in ('provides', 'shared')) and \\\n                len([x for x in self.statements if x[0] == ':' and x[1] == 'output']) == 1:\n            output_stmt = [\n                x for x in self.statements if x[0] == ':' and x[1] == 'output'\n            ][0][2]\n            output_names = get_names_of_kwargs(output_stmt)\n            self.options['namedprovides'] = repr(output_names)", "response": "This method is called by the base class to finalize the processing of the command line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noutput for command sos show", "response": "def show(self):\n        '''Output for command sos show'''\n        textWidth = max(60, shutil.get_terminal_size((80, 20)).columns)\n        text = f'  {self.step_name() + \":\":<21} ' + self.comment\n        print('\\n'.join(\n            textwrap.wrap(\n                text,\n                width=textWidth,\n                initial_indent='',\n                subsequent_indent=' ' * 24)))\n        local_parameters = {\n            x: y\n            for x, y in self.parameters.items()\n            if x not in self.global_parameters\n        }\n        if local_parameters:\n            print('    Workflow Options:')\n        for name, (value, comment) in local_parameters.items():\n            par_str = f'      {format_par(name, value)}'\n            print(par_str)\n            if comment:\n                print('\\n'.join(\n                    textwrap.wrap(\n                        comment,\n                        width=textWidth,\n                        initial_indent=' ' * 24,\n                        subsequent_indent=' ' * 24)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nappending another workflow to existing one to created a combined workflow", "response": "def extend(self, workflow: 'SoS_Workflow') -> None:\n        '''Append another workflow to existing one to created a combined workflow'''\n        # all sections are simply appended ...\n        # but we will need to make sure that the new workflow is\n        # executed after the previous one.\n        if not workflow.sections:\n            return\n        if not self.sections:\n            self.sections = workflow.sections\n            return\n        section = workflow.sections[0]\n        depends_idx = [\n            idx for idx, stmt in enumerate(section.statements)\n            if stmt[0] == ':' and stmt[1] == 'depends'\n        ]\n        if not depends_idx:\n            section.statements.insert(0, [\n                ':', 'depends', f\"sos_step('{self.sections[-1].step_name()}')\"\n            ])\n        else:\n            section.statements[depends_idx[0]][2] = section.statements[depends_idx[0]][2].strip() + \\\n                (\", \" if section.statements[depends_idx[0]][2].strip() else \"\") + \\\n                f\"sos_step('{self.sections[-1].step_name()}')\\n\"\n        self.sections.extend(workflow.sections)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a comment line to the last comment line.", "response": "def add_comment(self, line: str) -> None:\n        '''Keeping track of \"last comment\" for section and parameter '''\n        # the rule is like\n        #\n        # # comment line  --> add to last comment\n        # blank line --> clears last comment\n        # [ ] --> use last comment\n        # parameter: --> use last comment\n        # All others: clear last comment\n        self._last_comment += (' ' if self._last_comment else '') + \\\n            line.lstrip('#').strip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a workflow with name_step + name_step specified in wf_name", "response": "def workflow(self,\n                 workflow_name: Optional[str] = None,\n                 use_default: bool = True) -> SoS_Workflow:\n        '''Return a workflow with name_step+name_step specified in wf_name\n        This function might be called recursively because of nested\n        workflow.'''\n        if workflow_name is None and not use_default:\n            return SoS_Workflow(self.content, '', '', self.sections,\n                                self.global_stmts)\n        allowed_steps = None\n        if not workflow_name:\n            wf_name = ''\n        else:\n            # if consists of multiple workflows\n            if '+' in workflow_name:\n                wfs = []\n                for wf in workflow_name.split('+'):\n                    if not SOS_SUBWORKFLOW.match(wf):\n                        raise ValueError(\n                            f'Incorrect workflow name {workflow_name}')\n                    # if this is a combined workflow, extra_section might be specied.\n                    wfs.append(self.workflow(wf))\n                combined_wf = wfs[0]\n                for wf in wfs[1:]:\n                    combined_wf.extend(wf)\n                combined_wf.name = workflow_name\n                return combined_wf\n            # if a single workflow\n            # workflow_10:15 etc\n            mo = SOS_SUBWORKFLOW.match(workflow_name)\n            if not mo:\n                raise ValueError(f'Incorrect workflow name {workflow_name}')\n            wf_name, allowed_steps = mo.group('name', 'steps')\n        # check source\n        if not wf_name:\n            if len(self.workflows) == 1:\n                wf_name = list(self.workflows)[0]\n            elif self.default_workflow:\n                wf_name = self.default_workflow\n            elif 'default' in self.workflows or '' in self.workflows:\n                wf_name = 'default'\n            else:\n                raise ValueError(\n                    'Name of workflow should be specified because '\n                    'the script defines more than one pipelines without a default one. '\n                    'Available pipelines are: {}.'.format(', '.join(\n                        self.workflows)))\n        elif wf_name not in self.workflows and wf_name != 'default':\n            raise ValueError(\n                f'Workflow {wf_name} is undefined. Available workflows are: {\", \".join(self.workflows)}'\n            )\n\n        return SoS_Workflow(self.content, wf_name, allowed_steps, self.sections,\n                            self.global_stmts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_help(self, script_name: str):\n        '''print a help message from the script'''\n        textWidth = max(60, shutil.get_terminal_size((80, 20)).columns)\n\n        if len(script_name) > 20:\n            print(f'usage: sos run {script_name}')\n            print(\n                '               [workflow_name | -t targets] [options] [workflow_options]'\n            )\n        else:\n            print(\n                f'usage: sos run {script_name} [workflow_name | -t targets] [options] [workflow_options]'\n            )\n        print(\n            '  workflow_name:        Single or combined workflows defined in this script'\n        )\n        print('  targets:              One or more targets to generate')\n        print(\n            '  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)'\n        )\n        print(\n            '  workflow_options:     Double-hyphen workflow-specific parameters'\n        )\n        description = [x.lstrip('# ').strip() for x in self.description]\n        description = textwrap.dedent('\\n'.join(description)).strip()\n        if description:\n            print('\\n' + description)\n        #\n        print('\\nWorkflows:')\n        print('  ' + '\\n  '.join(self.workflows))\n        #\n        global_parameters = {}\n        for section in self.sections:\n            global_parameters.update(section.global_parameters)\n        if global_parameters:\n            print('\\nGlobal Workflow Options:')\n            for name, (value, comment) in global_parameters.items():\n                par_str = f'  {format_par(name, value)}'\n                print(par_str)\n                if comment:\n                    print('\\n'.join(\n                        textwrap.wrap(\n                            comment,\n                            width=textWidth,\n                            initial_indent=' ' * 24,\n                            subsequent_indent=' ' * 24)))\n        #\n        print('\\nSections')\n        for section in self.sections:\n            section.show()", "response": "print a help message from the script"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate(text, global_dict=None, local_dict=None):\n    '''Evaluate expressions in `text` '''\n    # step 1, make it a f-string (add quotation marks and f\n    # step 2, evaluate as a string\n    try:\n        return eval(as_fstring(text), global_dict, local_dict)\n    except Exception as e:\n        raise ValueError(f'Failed to interpolate {text}: {e}')", "response": "Evaluate expressions in text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget names but ignore variables names to the left hand side", "response": "def get_accessed(node):\n    '''Get names, but ignore variables names to the left hand side\n    That is to say, in case of\n       a = b + 1\n    we consider b as \"being accessed\", while a is not.\n    '''\n    if isinstance(node, ast.Assign):\n        return get_accessed(node.value)\n    elif isinstance(node, ast.Name):\n        return {node.id}\n    names = set()\n    if isinstance(node, list):\n        for x in node:\n            names |= get_accessed(x)\n    else:\n        for x in ast.iter_child_nodes(node):\n            names |= get_accessed(x)\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a Python statement and analyze the symbols used. The result will be used to determine what variables a step depends upon.", "response": "def accessed_vars(statement: str, mode: str = 'exec') -> Set[str]:\n    '''Parse a Python statement and analyze the symbols used. The result\n    will be used to determine what variables a step depends upon.'''\n    try:\n        if mode == 'exec':\n            return get_accessed(ast.parse(statement, '<string>', 'exec'))\n        else:\n            res = get_accessed(\n                ast.parse('__NULL__(' + statement + ')', '<string>', 'eval'))\n            res.remove('__NULL__')\n            return res\n    except:\n        raise RuntimeError(\n            f'Failed to parse statement: {statement} in {mode} mode')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget names but ignore variables names to the left hand side", "response": "def get_used_in_func(node):\n    '''Get names, but ignore variables names to the left hand side\n    That is to say, in case of\n       a = b + 1\n    we consider b as \"being accessed\", while a is not.\n    '''\n    if isinstance(node, ast.FunctionDef):\n        return {node.name: get_accessed(node.body)}\n    names = {}\n    for node in ast.iter_child_nodes(node):\n        names.update(get_used_in_func(node))\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Python statement and analyze the symbols used.", "response": "def used_in_func(statement: str, filename: str = '<string>',\n                 mode: str = 'exec'):\n    '''Parse a Python statement and analyze the symbols used. The result\n    will be used to determine what variables a step depends upon.'''\n    try:\n        return get_used_in_func(ast.parse(statement, filename, mode))\n    except Exception as e:\n        raise RuntimeError(f'Failed to parse statement: {statement} {e}')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SoS_eval(expr: str, extra_dict: dict = {}) -> Any:\n    '''Evaluate an expression with sos dict.'''\n    return eval(expr, env.sos_dict.dict(), extra_dict)", "response": "Evaluate an expression with sos dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_output_files(value, *args, **kwargs):\n    '''Process output files (perhaps a pattern) to determine input files.\n    '''\n    if any(isinstance(x, dynamic) for x in args) or any(\n            isinstance(y, dynamic) for y in kwargs.values()):\n        return sos_targets(_undetermined=value)\n    else:\n        return sos_targets(\n            *args,\n            **kwargs,\n            _undetermined=False,\n            _source=env.sos_dict['step_name'])", "response": "Expand the output files of the current process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_input_args(self, ifiles: sos_targets, **kwargs):\n        if ifiles.unspecified():\n            env.sos_dict.set('step_input', sos_targets([]))\n            env.sos_dict.set('_input', sos_targets([]))\n            env.sos_dict.set('step_output', sos_targets())\n            return [sos_targets([])], [{}]\n\n        assert isinstance(ifiles, sos_targets)\n\n        if env.sos_dict.get('__dynamic_input__', False):\n            runner = self.verify_dynamic_targets(\n                [x for x in ifiles if isinstance(x, file_target)])\n            try:\n                yreq = next(runner)\n                while True:\n                    yres = yield yreq\n                    yreq = runner.send(yres)\n            except StopIteration as e:\n                pass\n\n        # input file is the filtered files\n        env.sos_dict.set('step_input', ifiles)\n        env.sos_dict.set('_input', ifiles)\n\n        if ifiles._num_groups() == 0:\n            ifiles._group('all')\n        #\n        return ifiles.groups", "response": "This function handles the input and all its parameters and returns the list of patterns and the set of variables that need to be set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        '''Execute a single step and return results. The result for batch mode is the\n        input, output etc returned as alias, and for interactive mode is the return value\n        of the last expression. '''\n        # return value of the last executed statement\n        self.last_res = None\n        self.start_time = time.time()\n        self.completed = defaultdict(int)\n        #\n        # prepare environments, namely variables that can be used by the step\n        #\n        # * step_name:  name of the step, can be used by step process to determine\n        #               actions dynamically.\n        env.sos_dict.set('step_name', self.step.step_name())\n        env.sos_dict.set('__last_step__', self.step.last_step)\n        self.log('start')\n        env.sos_dict.set(\n            'step_id',\n            textMD5(\n                f'{env.sos_dict[\"workflow_id\"]} {env.sos_dict[\"step_name\"]} {self.step.md5}'\n            ))\n        env.sos_dict.set('master_id', env.config['master_id'])\n        # used by nested workflow\n        env.sos_dict.set('__step_context__', self.step.context)\n\n        env.sos_dict.set('_runtime', {})\n        # * input:      input files, which should be __step_output__ if it is defined, or\n        #               None otherwise.\n        # * _input:     first batch of input, which should be input if no input statement is used\n        # * output:     None at first, can be redefined by output statement\n        # * _output:    None at first, can be redefined by output statement\n        # * depends:    None at first, can be redefined by depends statement\n        # * _depends:   None at first, can be redefined by depends statement\n        #\n        if '__step_output__' not in env.sos_dict or env.sos_dict[\n                '__step_output__'].unspecified():\n            env.sos_dict.set('step_input', sos_targets([]))\n        else:\n            env.sos_dict.set(\n                'step_input',\n                env.sos_dict['__step_output__']._remove_empty_groups())\n        # input can be Undetermined from undetermined output from last step\n        env.sos_dict.set('_input', copy.deepcopy(env.sos_dict['step_input']))\n\n        if '__default_output__' in env.sos_dict:\n            # if step is triggered by sos_step, it should not be considered as\n            # output of the step. #981\n            env.sos_dict.set(\n                '__default_output__',\n                sos_targets([\n                    x for x in env.sos_dict['__default_output__']._targets\n                    if not isinstance(x, sos_step)\n                ]))\n            env.sos_dict.set('step_output',\n                             copy.deepcopy(env.sos_dict['__default_output__']))\n            env.sos_dict.set('_output',\n                             copy.deepcopy(env.sos_dict['__default_output__']))\n        else:\n            env.sos_dict.set('step_output', sos_targets([]))\n            # output is said to be unspecified until output: is used\n            env.sos_dict.set('_output', sos_targets(_undetermined=True))\n\n        env.sos_dict.set('step_depends', sos_targets([]))\n        env.sos_dict.set('_depends', sos_targets([]))\n        # _index is needed for pre-input action's active option and for debug output of scripts\n        env.sos_dict.set('_index', 0)\n\n        if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file(\n                'STEP',\n                f'Executing step {env.sos_dict[\"step_name\"]} with step_input {env.sos_dict[\"step_input\"]} and step_output {env.sos_dict[\"step_output\"]}'\n            )\n\n        if self.step.task_params:\n            try:\n                task_queue = get_value_of_param(\n                    'queue',\n                    self.step.task_params,\n                    extra_dict=env.sos_dict.dict())\n                if task_queue:\n                    env.sos_dict['_runtime']['queue'] = task_queue[0]\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to determine value of parameter queue of {self.step.task_params}: {e}'\n                )\n            # check concurrent #1134\n            try:\n                task_concurrency = get_value_of_param(\n                    'concurrent',\n                    self.step.task_params,\n                    extra_dict=env.sos_dict.dict())\n                if task_concurrency:\n                    env.sos_dict['_runtime']['concurrent'] = task_concurrency[0]\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to determine value of parameter queue of {self.step.task_params}: {e}'\n                )\n        if (env.config['default_queue'] in ('None', 'none', None) and\n            'queue' not in env.sos_dict['_runtime']) or \\\n            ('queue' in env.sos_dict['_runtime'] and\n            env.sos_dict['_runtime']['queue'] in ('none', 'None', None)):\n            # remove task statement\n            if len(self.step.statements\n                  ) >= 1 and self.step.statements[-1][0] == '!':\n                self.step.statements[-1][1] += '\\n' + self.step.task\n            else:\n                self.step.statements.append(['!', self.step.task])\n            self.step.task = None\n        elif 'queue' not in env.sos_dict[\n                '_runtime'] or not env.sos_dict['_runtime']['queue']:\n            if env.config['default_queue']:\n                env.sos_dict['_runtime']['queue'] = env.config['default_queue']\n            else:\n                env.sos_dict['_runtime']['queue'] = 'localhost'\n\n        # look for input statement.\n        input_statement_idx = [\n            idx for idx, x in enumerate(self.step.statements)\n            if x[0] == ':' and x[1] == 'input'\n        ]\n        if not input_statement_idx:\n            input_statement_idx = None\n        elif len(input_statement_idx) == 1:\n            input_statement_idx = input_statement_idx[0]\n        else:\n            raise ValueError(\n                f'More than one step input are specified in step {self.step.step_name()}'\n            )\n\n        # if shared is true, we have to disable concurrent because we\n        # do not yet return anything from shared.\n        self.concurrent_substep = 'shared' not in self.step.options and \\\n            ('concurrent' not in env.sos_dict['_runtime'] or env.sos_dict['_runtime']['concurrent'] is True)\n        if input_statement_idx is not None:\n            # execute before input stuff\n            for statement in self.step.statements[:input_statement_idx]:\n                if statement[0] == ':':\n                    # wait for all dependent targets to be resolved to be resolved\n                    key, value = statement[1:3]\n                    if key != 'depends':\n                        raise ValueError(\n                            f'Step input should be specified before {key}')\n                    while True:\n                        try:\n                            args, kwargs = SoS_eval(\n                                f'__null_func__({value})',\n                                extra_dict={\n                                    '__null_func__': __null_func__,\n                                    'output_from': __output_from__,\n                                    'named_output': __named_output__,\n                                    'traced': __traced__\n                                })\n                            dfiles = expand_depends_files(*args)\n                            # dfiles can be Undetermined\n                            runner = self.process_depends_args(dfiles, **kwargs)\n                            try:\n                                yreq = next(runner)\n                                while True:\n                                    yres = yield yreq\n                                    yreq = runner.send(yres)\n                            except StopIteration as e:\n                                pass\n                        except (UnknownTarget, RemovedTarget) as e:\n                            runner = self.handle_unknown_target(e)\n                            try:\n                                yreq = next(runner)\n                                while True:\n                                    yres = yield yreq\n                                    yreq = runner.send(yres)\n                            except StopIteration as e:\n                                pass\n                            continue\n                        except UnavailableLock:\n                            raise\n                        except Exception as e:\n                            raise RuntimeError(\n                                f'Failed to process step {key} ({value.strip()}): {e}'\n                            )\n                        break\n                else:\n                    try:\n                        self.execute(statement[1])\n                    except StopInputGroup as e:\n                        # stop before substeps, because there is no output statement before it\n                        # we do not have to worry about keep_output\n                        if e.message:\n                            env.logger.info(e.message)\n                        return self.collect_result()\n            # input statement\n            stmt = self.step.statements[input_statement_idx][2]\n            self.log('input statement', stmt)\n            while True:\n                # wait for all targets to be resovled\n                try:\n                    args, kwargs = SoS_eval(\n                        f\"__null_func__({stmt})\",\n                        extra_dict={\n                            '__null_func__': __null_func__,\n                            'output_from': __output_from__,\n                            'named_output': __named_output__,\n                            'traced': __traced__\n                        })\n                    # Files will be expanded differently with different running modes\n                    input_files: sos_targets = expand_input_files(\n                        *args, **{\n                            k: v\n                            for k, v in kwargs.items()\n                            if k not in SOS_INPUT_OPTIONS\n                        })\n                    runner = self.process_input_args(\n                        input_files, **{\n                            k: v\n                            for k, v in kwargs.items()\n                            if k in SOS_INPUT_OPTIONS\n                        })\n                    try:\n                        yreq = next(runner)\n                        while True:\n                            yres = yield yreq\n                            yreq = runner.send(yres)\n                    except StopIteration as e:\n                        self._substeps = e.value\n                    #\n                    if 'concurrent' in kwargs and kwargs['concurrent'] is False:\n                        self.concurrent_substep = False\n                except (UnknownTarget, RemovedTarget) as e:\n                    runner = self.handle_unknown_target(e)\n                    try:\n                        yreq = next(runner)\n                        while True:\n                            yres = yield yreq\n                            yreq = runner.send(yres)\n                    except StopIteration as e:\n                        pass\n                    continue\n                except UnavailableLock:\n                    raise\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to process input statement {stmt}: {e}')\n                break\n\n            input_statement_idx += 1\n        elif env.sos_dict['step_input'].groups:\n            # if default has groups...\n            # default case\n            self._substeps = env.sos_dict['step_input'].groups\n            # assuming everything starts from 0 is after input\n            input_statement_idx = 0\n        else:\n            # default case\n            self._substeps = [env.sos_dict['step_input']]\n            # assuming everything starts from 0 is after input\n            input_statement_idx = 0\n\n        self.proc_results = []\n        self.vars_to_be_shared = set()\n        if 'shared' in self.step.options:\n            self.vars_to_be_shared = parse_shared_vars(\n                self.step.options['shared'])\n        self.vars_to_be_shared = sorted([\n            x[5:] if x.startswith('step_') else x\n            for x in self.vars_to_be_shared\n            if x not in ('step_', 'step_input', 'step_output', 'step_depends')\n        ])\n        self.shared_vars = [{} for x in self._substeps]\n        # run steps after input statement, which will be run multiple times for each input\n        # group.\n        env.sos_dict.set('__num_groups__', len(self._substeps))\n\n        # determine if a single index or the whole step should be skipped\n        skip_index = False\n        # signatures of each index, which can remain to be None if no output\n        # is defined.\n        self.output_groups = [sos_targets([]) for x in self._substeps]\n        self.depends_groups = [sos_targets([]) for x in self._substeps]\n\n        # used to prevent overlapping output from substeps\n        self._all_outputs = set()\n        self._subworkflow_results = []\n\n        if any('sos_run' in x[1] for x in self.step.statements[input_statement_idx:]) and \\\n            'shared' not in self.step.options and not self.step.task and \\\n            self.step.statements[-1][0] == '!' and \\\n            (len(self.step.statements) == 1 or self.step.statements[-2][0] == ':') and \\\n            is_sos_run_the_only_last_stmt(self.step.statements[-1][1]):\n            env.sos_dict.set('__concurrent_subworkflow__', True)\n\n        if self.concurrent_substep:\n            if len(self._substeps) <= 1 or env.config['run_mode'] == 'dryrun':\n                self.concurrent_substep = False\n            elif len([\n                    x for x in self.step.statements[input_statement_idx:]\n                    if x[0] != ':'\n            ]) > 1:\n                self.concurrent_substep = False\n                env.logger.debug(\n                    'Substeps are executed sequentially because of existence of directives between statements.'\n                )\n            elif any('sos_run' in x[1]\n                     for x in self.step.statements[input_statement_idx:]):\n                self.concurrent_substep = False\n                env.logger.debug(\n                    'Substeps are executed sequentially because of existence of multiple nested workflow.'\n                )\n            else:\n                self.prepare_substep()\n\n        try:\n            self.completed['__substep_skipped__'] = 0\n            self.completed['__substep_completed__'] = len(self._substeps)\n            self._completed_concurrent_substeps = 0\n            # pending signatures are signatures for steps with external tasks\n            pending_signatures = [None for x in self._substeps]\n\n            for idx, g in enumerate(self._substeps):\n                # other variables\n                #\n                _vars = {}\n                # now, let us expose target level variables as lists\n                if len(g) > 1:\n                    names = set.union(\n                        *[set(x._dict.keys()) for x in g._targets])\n                elif len(g) == 1:\n                    names = set(g._targets[0]._dict.keys())\n                else:\n                    names = set()\n                for name in names:\n                    _vars[name] = [x.get(name) for x in g._targets]\n                # then we expose all group level variables\n                _vars.update(g._dict)\n                _vars.update(env.sos_dict['step_input']._dict)\n                env.sos_dict.update(_vars)\n\n                env.sos_dict.set('_input', copy.deepcopy(g))\n                # set vars to _input\n                #env.sos_dict['_input'].set(**v)\n\n                self.log('_input')\n                env.sos_dict.set('_index', idx)\n\n                # in interactive mode, because sos_dict are always shared\n                # execution of a substep, especially when it calls a nested\n                # workflow, would change step_name, __step_context__ etc, and\n                # we will have to reset these variables to make sure the next\n                # substep would execute normally. Batch mode is immune to this\n                # problem because nested workflows are executed in their own\n                # process/context etc\n                if env.config['run_mode'] == 'interactive':\n                    env.sos_dict.set('step_name', self.step.step_name())\n                    env.sos_dict.set(\n                        'step_id',\n                        hash((env.sos_dict[\"workflow_id\"],\n                              env.sos_dict[\"step_name\"], self.step.md5)))\n                    # used by nested workflow\n                    env.sos_dict.set('__step_context__', self.step.context)\n                #\n                pre_statement = []\n                if not any(st[0] == ':' and st[1] == 'output' for st in self.step.statements[input_statement_idx:]) and \\\n                        '__default_output__' in env.sos_dict:\n                    pre_statement = [[':', 'output', '_output']]\n\n                # if there is no statement, no task, claim success\n                post_statement = []\n                if not any(\n                        st[0] == '!'\n                        for st in self.step.statements[input_statement_idx:]):\n                    if self.step.task:\n                        # if there is only task, we insert a fake statement so that it can be executed by the executor\n                        post_statement = [['!', '']]\n                    else:\n                        # complete case: no step, no statement\n                        send_message_to_controller([\n                            'progress', 'substep_completed',\n                            env.sos_dict['step_id']\n                        ])\n\n                all_statements = pre_statement + self.step.statements[\n                    input_statement_idx:] + post_statement\n                is_input_verified = True\n                for statement_idx, statement in enumerate(all_statements):\n                    is_last_runblock = statement_idx == len(all_statements) - 1\n\n                    # if input is undertermined, we can only process output:\n                    if not g.valid() and statement[0] != ':':\n                        raise RuntimeError('Undetermined input encountered')\n                    if statement[0] == ':':\n                        key, value = statement[1:3]\n                        # output, depends, and process can be processed multiple times\n                        while True:\n                            # loop for all unresolved targets to be resolved\n                            try:\n                                args, kwargs = SoS_eval(\n                                    f'__null_func__({value})',\n                                    extra_dict={\n                                        '__null_func__': __null_func__,\n                                        'output_from': __output_from__,\n                                        'named_output': __named_output__,\n                                        'traced': __traced__\n                                    })\n                                # dynamic output or dependent files\n                                if key == 'output':\n                                    # if output is defined, its default value needs to be cleared\n                                    if idx == 0:\n                                        env.sos_dict.set(\n                                            'step_output', sos_targets())\n                                    ofiles: sos_targets = expand_output_files(\n                                        value, *args, **{\n                                            k: v\n                                            for k, v in kwargs.items()\n                                            if k not in SOS_OUTPUT_OPTIONS\n                                        })\n                                    if g.valid() and ofiles.valid():\n                                        if any(\n                                                x in g._targets\n                                                for x in ofiles\n                                                if not isinstance(x, sos_step)):\n                                            raise RuntimeError(\n                                                f'Overlapping input and output files: {\", \".join(repr(x) for x in ofiles if x in g)}'\n                                            )\n\n                                    # set variable _output and output\n                                    self.process_output_args(\n                                        ofiles, **{\n                                            k: v\n                                            for k, v in kwargs.items()\n                                            if k in SOS_OUTPUT_OPTIONS\n                                        })\n                                    self.output_groups[idx] = env.sos_dict[\n                                        '_output']\n                                elif key == 'depends':\n                                    try:\n                                        dfiles = expand_depends_files(*args)\n                                        # dfiles can be Undetermined\n                                        runner = self.process_depends_args(\n                                            dfiles, **kwargs)\n                                        try:\n                                            yreq = next(runner)\n                                            while True:\n                                                yres = yield yreq\n                                                yreq = runner.send(yres)\n                                        except StopIteration as e:\n                                            pass\n                                        self.depends_groups[idx] = env.sos_dict[\n                                            '_depends']\n                                        self.log('_depends')\n                                    except Exception as e:\n                                        #env.logger.info(e)\n                                        raise\n                                else:\n                                    raise RuntimeError(\n                                        f'Unrecognized directive {key}')\n                                # everything is ok, break\n                                break\n                            except (UnknownTarget, RemovedTarget) as e:\n                                runner = self.handle_unknown_target(e)\n                                try:\n                                    yreq = next(runner)\n                                    while True:\n                                        yres = yield yreq\n                                        yreq = runner.send(yres)\n                                except StopIteration as e:\n                                    pass\n                                continue\n                            except UnavailableLock:\n                                raise\n                            except Exception as e:\n                                # if input is Undertermined, it is possible that output cannot be processed\n                                # due to that, and we just return\n                                if not g.valid():\n                                    env.logger.debug(e)\n                                    return self.collect_result()\n                                raise RuntimeError(\n                                    f'Failed to process step {key} ({value.strip()}): {e}'\n                                )\n                    elif is_last_runblock:\n                        try:\n                            if self.concurrent_substep:\n                                if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                                    env.log_to_file(\n                                        'STEP',\n                                        f'Execute substep {env.sos_dict[\"step_name\"]} {idx} concurrently with {self._completed_concurrent_substeps} completed'\n                                    )\n\n                                # the ignatures are supposed to be written by substep worker, however\n                                # the substep worker might send tasks back to the step worker and\n                                # we should write the signatures after the tasks are completed\n                                if env.config['sig_mode'] != 'ignore' and not env.sos_dict['_output'].unspecified() \\\n                                    and self.step.task:\n                                    pending_signatures[idx] = RuntimeInfo(\n                                        statementMD5(\n                                            [statement[1], self.step.task]),\n                                        env.sos_dict['_input'],\n                                        env.sos_dict['_output'],\n                                        env.sos_dict['_depends'],\n                                        env.sos_dict['__signature_vars__'],\n                                        shared_vars=self.vars_to_be_shared)\n                                #\n                                # step_output: needed only when it is undetermined\n                                # step_input: not needed\n                                # _input, _output, _depends, _index: needed\n                                # step_name: for debug scripts\n                                # step_id, workflow_id: for reporting to controller\n                                # '__signature_vars__' to be used for signature creation\n                                #\n                                # __step_context__ is not needed because substep\n                                # executor does not support nested workflow\n\n                                proc_vars = env.sos_dict['__signature_vars__'] \\\n                                    | {'_input', '_output', '_depends', '_index',\n                                     'step_output', 'step_name',\n                                      '_runtime', 'step_id', 'workflow_id', '__num_groups__',\n                                      '__signature_vars__'}\n                                self.proc_results.append({})\n                                self.submit_substep(\n                                    dict(\n                                        stmt=statement[1],\n                                        global_def=self.step.global_def,\n                                        #1225: the step might contain large variables from global section, but\n                                        # we do not have to sent them if they are not used in substeps.\n                                        global_vars={\n                                            x: y\n                                            for x, y in\n                                            self.step.global_vars.items()\n                                            if x in\n                                            env.sos_dict['__signature_vars__']\n                                        },\n                                        task=self.step.task,\n                                        task_params=self.step.task_params,\n                                        proc_vars=env.sos_dict\n                                        .clone_selected_vars(proc_vars),\n                                        shared_vars=self.vars_to_be_shared,\n                                        config=env.config))\n                                # we check if the previous task has been completed and process them\n                                # because further steps might need to be done\n                                try:\n                                    runner = self.process_returned_substep_result(\n                                        wait=False)\n                                    yreq = next(runner)\n                                    while True:\n                                        yres = yield yreq\n                                        yreq = runner.send(yres)\n                                except StopIteration:\n                                    pass\n                            else:\n                                if env.config[\n                                        'sig_mode'] == 'ignore' or env.sos_dict[\n                                            '_output'].unspecified():\n                                    if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                                        env.log_to_file(\n                                            'STEP',\n                                            f'Execute substep {env.sos_dict[\"step_name\"]} without signature'\n                                        )\n                                    try:\n                                        if is_input_verified:\n                                            verify_input()\n                                            is_input_verified = False\n                                        if env.sos_dict.get(\n                                                '__concurrent_subworkflow__',\n                                                False):\n                                            self._subworkflow_results.append(\n                                                self.execute(\n                                                    statement[1],\n                                                    return_result=True))\n                                        else:\n                                            self.execute(statement[1])\n                                    finally:\n                                        if not self.step.task:\n                                            # if no task, this step is __completed\n                                            # complete case: local skip without task\n                                            send_message_to_controller([\n                                                'progress', 'substep_completed',\n                                                env.sos_dict['step_id']\n                                            ])\n                                    if 'shared' in self.step.options:\n                                        try:\n                                            self.shared_vars[\n                                                env.sos_dict['_index']].update({\n                                                    x: env.sos_dict[x]\n                                                    for x in\n                                                    self.vars_to_be_shared\n                                                    if x in env.sos_dict\n                                                })\n                                        except Exception as e:\n                                            raise ValueError(\n                                                f'Missing shared variable {e}.')\n                                else:\n                                    sig = RuntimeInfo(\n                                        statementMD5(\n                                            [statement[1], self.step.task]),\n                                        env.sos_dict['_input'],\n                                        env.sos_dict['_output'],\n                                        env.sos_dict['_depends'],\n                                        env.sos_dict['__signature_vars__'],\n                                        shared_vars=self.vars_to_be_shared)\n                                    if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                                        env.log_to_file(\n                                            'STEP',\n                                            f'Execute substep {env.sos_dict[\"step_name\"]} with signature {sig.sig_id}'\n                                        )\n                                    # if singaure match, we skip the substep even  if\n                                    # there are tasks.\n                                    matched = validate_step_sig(sig)\n                                    skip_index = bool(matched)\n                                    if matched:\n                                        if env.sos_dict[\n                                                'step_output'].undetermined():\n                                            self.output_groups[env.sos_dict[\n                                                '_index']] = matched[\"output\"]\n                                        if 'vars' in matched:\n                                            self.shared_vars[\n                                                env.sos_dict['_index']].update(\n                                                    matched[\"vars\"])\n                                        # complete case: local skip without task\n                                        send_message_to_controller([\n                                            'progress', 'substep_ignored',\n                                            env.sos_dict['step_id']\n                                        ])\n                                        # do not execute the rest of the statement\n                                        break\n                                    else:\n                                        sig.lock()\n                                        try:\n                                            if is_input_verified:\n                                                verify_input()\n                                                is_input_verified = False\n                                            if env.sos_dict.get(\n                                                    '__concurrent_subworkflow__',\n                                                    False):\n                                                self._subworkflow_results.append(\n                                                    self.execute(\n                                                        statement[1],\n                                                        return_result=True))\n                                            else:\n                                                self.execute(statement[1])\n                                            if 'shared' in self.step.options:\n                                                try:\n                                                    self.shared_vars[\n                                                        env.sos_dict[\n                                                            '_index']].update({\n                                                                x:\n                                                                env.sos_dict[x]\n                                                                for x in self.\n                                                                vars_to_be_shared\n                                                                if x in\n                                                                env.sos_dict\n                                                            })\n                                                except Exception as e:\n                                                    raise ValueError(\n                                                        f'Missing shared variable {e}.'\n                                                    )\n                                        finally:\n                                            # if this is the end of substep, save the signature\n                                            # otherwise we need to wait for the completion\n                                            # of the task.\n                                            if not self.step.task:\n                                                if env.sos_dict[\n                                                        'step_output'].undetermined(\n                                                        ):\n                                                    output = reevaluate_output()\n                                                    self.output_groups[\n                                                        env.sos_dict[\n                                                            '_index']] = output\n                                                    sig.set_output(output)\n                                                sig.write()\n                                                # complete case : local execution without task\n                                                send_message_to_controller([\n                                                    'progress',\n                                                    'substep_completed',\n                                                    env.sos_dict['step_id']\n                                                ])\n                                            else:\n                                                pending_signatures[idx] = sig\n                                            sig.release()\n                        except StopInputGroup as e:\n                            if not e.keep_output:\n                                clear_output()\n                                self.output_groups[idx] = sos_targets([])\n                            if e.message:\n                                env.logger.info(e.message)\n                            skip_index = True\n                            break\n                        except Exception as e:\n                            clear_output()\n                            raise\n                    else:\n                        # if it is not the last statement group (e.g. statements before :output)\n                        # we execute locally without anything like signature\n                        if is_input_verified:\n                            verify_input()\n                            is_input_verified = False\n                        try:\n                            self.execute(statement[1])\n                        except StopInputGroup as e:\n                            if not e.keep_output:\n                                clear_output()\n                                self.output_groups[idx] = sos_targets([])\n                            if e.message:\n                                env.logger.info(e.message)\n                            skip_index = True\n                            break\n                        except Exception as e:\n                            clear_output()\n                            raise\n                # if there is no statement , but there are tasks, we should\n                # check signature here.\n                if not any(x[0] == '!' for x in self.step.statements[input_statement_idx:]) and self.step.task and not self.concurrent_substep \\\n                    and env.config['sig_mode'] != 'ignore' and not env.sos_dict['_output'].unspecified():\n                    sig = RuntimeInfo(\n                        statementMD5([self.step.task]),\n                        env.sos_dict['_input'],\n                        env.sos_dict['_output'],\n                        env.sos_dict['_depends'],\n                        env.sos_dict['__signature_vars__'],\n                        shared_vars=self.vars_to_be_shared)\n                    if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                        env.log_to_file(\n                            'STEP',\n                            f'Check task-only step {env.sos_dict[\"step_name\"]} with signature {sig.sig_id}'\n                        )\n                    matched = validate_step_sig(sig)\n                    skip_index = bool(matched)\n                    if matched:\n                        if env.sos_dict['step_output'].undetermined():\n                            self.output_groups[\n                                env.sos_dict['_index']] = matched[\"output\"]\n                        self.shared_vars[env.sos_dict['_index']].update(\n                            matched[\"vars\"])\n                        # complete case: step with task ignored\n                        send_message_to_controller([\n                            'progress', 'substep_ignored',\n                            env.sos_dict['step_id']\n                        ])\n                    pending_signatures[idx] = sig\n\n                # if this index is skipped, go directly to the next one\n                if skip_index:\n                    self.completed['__substep_skipped__'] += 1\n                    self.completed['__substep_completed__'] -= 1\n                    skip_index = False\n                    continue\n\n                # if concurrent input group, tasks are handled in substep\n                if self.concurrent_substep or not self.step.task:\n                    continue\n\n                if env.config[\n                        'run_mode'] == 'dryrun' and env.sos_dict['_index'] != 0:\n                    continue\n\n                # check if the task is active\n                if 'active' in env.sos_dict['_runtime']:\n                    active = env.sos_dict['_runtime']['active']\n                    if active is True:\n                        pass\n                    elif active is False:\n                        continue\n                    elif isinstance(active, int):\n                        if active >= 0 and env.sos_dict['_index'] != active:\n                            continue\n                        if active < 0 and env.sos_dict[\n                                '_index'] != active + env.sos_dict[\n                                    '__num_groups__']:\n                            continue\n                    elif isinstance(active, Sequence):\n                        allowed_index = list([\n                            x if x >= 0 else env.sos_dict['__num_groups__'] + x\n                            for x in active\n                        ])\n                        if env.sos_dict['_index'] not in allowed_index:\n                            continue\n                    elif isinstance(active, slice):\n                        allowed_index = list(\n                            range(env.sos_dict['__num_groups__']))[active]\n                        if env.sos_dict['_index'] not in allowed_index:\n                            continue\n                    else:\n                        raise RuntimeError(\n                            f'Unacceptable value for option active: {active}')\n\n                #\n                self.log('task')\n                try:\n                    task_id, taskdef, task_vars = create_task(\n                        self.step.global_def, self.step.global_vars,\n                        self.step.task, self.step.task_params)\n                    task = self.submit_task({\n                        'index': env.sos_dict['_index'],\n                        'task_id': task_id,\n                        'task_def': taskdef,\n                        'task_vars': task_vars\n                    })\n                    self.proc_results.append(task)\n                except Exception as e:\n                    # FIXME: cannot catch exception from subprocesses\n                    if env.verbosity > 2:\n                        sys.stderr.write(get_traceback())\n                    raise RuntimeError(\n                        f'Failed to execute process\\n\"{short_repr(self.step.task)}\"\\n{e}'\n                    )\n                #\n                # if not concurrent, we have to wait for the completion of the task\n                if 'concurrent' in env.sos_dict['_runtime'] and env.sos_dict[\n                        '_runtime']['concurrent'] is False:\n                    # in this case the steps must be executed not concurrently\n                    runner = self.wait_for_results(all_submitted=False)\n                    try:\n                        yreq = next(runner)\n                        while True:\n                            yres = yield yreq\n                            yreq = runner.send(yres)\n                    except StopIteration:\n                        pass\n                #\n                # endfor loop for each input group\n                #\n            if self._subworkflow_results:\n                try:\n                    runner = self.wait_for_subworkflows(\n                        self._subworkflow_results)\n                    yreq = next(runner)\n                    while True:\n                        yres = yield yreq\n                        yreq = runner.send(yres)\n                except StopIteration:\n                    pass\n                env.sos_dict.pop('__concurrent_subworkflow__')\n\n            runner = self.wait_for_results(all_submitted=True)\n            try:\n                yreq = next(runner)\n                while True:\n                    yres = yield yreq\n                    yreq = runner.send(yres)\n            except StopIteration:\n                pass\n\n            for idx, res in enumerate(self.proc_results):\n                if 'sig_skipped' in res:\n                    self.completed['__substep_skipped__'] += 1\n                    self.completed['__substep_completed__'] -= 1\n                if 'output' in res:\n                    self.output_groups[idx] = res[\"output\"]\n\n            # check results\n            for proc_result in [\n                    x for x in self.proc_results if x['ret_code'] == 0\n            ]:\n                if 'stdout' in proc_result and proc_result['stdout']:\n                    sys.stdout.write(proc_result['stdout'])\n                if 'stderr' in proc_result and proc_result['stderr']:\n                    sys.stderr.write(proc_result['stderr'])\n\n            # now that output is settled, we can write remaining signatures\n            for idx, res in enumerate(self.proc_results):\n                if pending_signatures[idx] is not None and res[\n                        'ret_code'] == 0 and not 'sig_skipped' in res:\n                    pending_signatures[idx].write()\n                if res['ret_code'] != 0 and 'output' in res:\n                    clear_output(output=res['output'])\n\n            for proc_result in [\n                    x for x in self.proc_results if x['ret_code'] != 0\n            ]:\n                if 'stdout' in proc_result and proc_result['stdout']:\n                    sys.stdout.write(proc_result['stdout'])\n                if 'stderr' in proc_result and proc_result['stderr']:\n                    sys.stderr.write(proc_result['stderr'])\n                if 'exception' in proc_result:\n                    excp = proc_result['exception']\n                    if isinstance(excp, StopInputGroup):\n                        if excp.message:\n                            env.logger.info(excp.message)\n                        self.output_groups[proc_result['index']] = sos_targets(\n                            [])\n                    #elif isinstance(e, RemovedTarget):\n                    #\n                    # in theory, we should be able to handled removed target from here\n                    # by rerunning the substep, but we it is too much work for this\n                    # corner case. Let us simply rerunt he entire step.\n                    else:\n                        raise excp\n                else:\n                    raise RuntimeError(\n                        f\"Substep failed with return code {proc_result['ret_code']}\"\n                    )\n\n            # if output is Undetermined, re-evalulate it\n            # finalize output from output_groups because some output might be skipped\n            # this is the final version of the output but we do maintain output\n            # during the execution of step, for compatibility.\n            env.sos_dict.set('step_output',\n                             sos_targets([])._add_groups(self.output_groups))\n            env.sos_dict.set('step_depends',\n                             sos_targets([])._add_groups(self.depends_groups))\n\n            # if there exists an option shared, the variable would be treated as\n            # provides=sos_variable(), and then as step_output\n            if 'shared' in self.step.options:\n                self.shared_vars = evaluate_shared(self.shared_vars,\n                                                   self.step.options['shared'])\n                env.sos_dict.quick_update(self.shared_vars)\n            self.log('output')\n            self.verify_output()\n            substeps = self.completed['__substep_completed__'] + \\\n                self.completed['__substep_skipped__']\n            self.completed['__step_completed__'] = self.completed[\n                '__substep_completed__'] / substeps\n            self.completed['__step_skipped__'] = self.completed[\n                '__substep_skipped__'] / substeps\n            if self.completed['__step_completed__'].is_integer():\n                self.completed['__step_completed__'] = int(\n                    self.completed['__step_completed__'])\n            if self.completed['__step_skipped__'].is_integer():\n                self.completed['__step_skipped__'] = int(\n                    self.completed['__step_skipped__'])\n\n            def file_only(targets):\n                if not isinstance(targets, sos_targets):\n                    env.logger.warning(\n                        f\"Unexpected input or output target for reporting. Empty list returned: {targets}\"\n                    )\n                    return []\n                return [(str(x), x.size())\n                        for x in targets._targets\n                        if isinstance(x, file_target)]\n\n            step_info = {\n                'step_id': self.step.md5,\n                'start_time': self.start_time,\n                'stepname': self.step.step_name(True),\n                'substeps': len(self._substeps),\n                'input': file_only(env.sos_dict['step_input']),\n                'output': file_only(env.sos_dict['step_output']),\n                'completed': dict(self.completed),\n                'end_time': time.time()\n            }\n            send_message_to_controller([\n                'workflow_sig', 'step', env.sos_dict[\"workflow_id\"],\n                repr(step_info)\n            ])\n            return self.collect_result()\n        finally:\n            if self.concurrent_substep:\n                close_socket(self.result_pull_socket, 'substep collector')", "response": "Execute a single step and return results."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for results from subworkflows", "response": "def wait_for_subworkflows(self, workflow_results):\n        '''Wait for results from subworkflows'''\n        wf_ids = sum([x['pending_workflows'] for x in workflow_results], [])\n        for wf_id in wf_ids:\n            # here we did not check if workflow ids match\n            yield self.socket\n            res = self.socket.recv_pyobj()\n            if res is None:\n                sys.exit(0)\n            elif isinstance(res, Exception):\n                raise res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Rmarkdown(script=None,\n              input=None,\n              output=None,\n              args='{input:r}, output_file={output:ar}',\n              **kwargs):\n    '''Convert input file to output using Rmarkdown\n\n    The input can be specified in three ways:\n\n    1. instant script, which is assumed to be in md format\n\n    Rmarkdown:   output='report.html'\n      script\n\n    2. one or more input files. The format is determined by extension of input file\n\n    Rmarkdown(input, output='report.html')\n\n    3. input file specified by command line option `-r` .\n    Rmarkdown(output='report.html')\n\n    If no output is specified, it is assumed to be in html format\n    and is written to standard output.\n\n    You can specify more options using the args parameter of the action. The default value\n    of args is `${input!r} --output ${output!ar}'\n    '''\n    if not R_library('rmarkdown').target_exists():\n        raise RuntimeError('Library rmarkdown does not exist')\n\n    input = sos_targets(collect_input(script, input))\n\n    output = sos_targets(output)\n    if len(output) == 0:\n        write_to_stdout = True\n        output = sos_targets(\n            tempfile.NamedTemporaryFile(\n                mode='w+t', suffix='.html', delete=False).name)\n    else:\n        write_to_stdout = False\n    #\n    ret = 1\n    try:\n        #   render(input, output_format = NULL, output_file = NULL, output_dir = NULL,\n        #        output_options = NULL, intermediates_dir = NULL,\n        #        runtime = c(\"auto\", \"static\", \"shiny\"),\n        #        clean = TRUE, params = NULL, knit_meta = NULL, envir = parent.frame(),\n        #        run_Rmarkdown = TRUE, quiet = FALSE, encoding = getOption(\"encoding\"))\n        cmd = interpolate(f'Rscript -e \"rmarkdown::render({args})\"', {\n            'input': input,\n            'output': output\n        })\n        if 'ACTION' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('ACTION', f'Running command \"{cmd}\"')\n        if env.config['run_mode'] == 'interactive':\n            # need to catch output and send to python output, which will in trun be hijacked by SoS notebook\n            p = subprocess.Popen(\n                cmd, shell=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n            #pid = p.pid\n            out, err = p.communicate()\n            sys.stdout.write(out.decode())\n            sys.stderr.write(err.decode())\n            ret = p.returncode\n        else:\n            p = subprocess.Popen(cmd, shell=True)\n            #pid = p.pid\n            ret = p.wait()\n    except Exception as e:\n        env.logger.error(e)\n    if ret != 0:\n        temp_file = os.path.join('.sos', f'{\"Rmarkdown\"}_{os.getpid()}.md')\n        shutil.copyfile(str(input), temp_file)\n        cmd = interpolate(f'Rscript -e \"rmarkdown::render({args})\"', {\n            'input': input,\n            'output': sos_targets(temp_file)\n        })\n        raise RuntimeError(\n            f'Failed to execute script. Please use command \\n\"{cmd}\"\\nunder {os.getcwd()} to test it.'\n        )\n    if write_to_stdout:\n        with open(str(output[0])) as out:\n            sys.stdout.write(out.read())\n    else:\n        env.logger.info(f'Report saved to {output}')", "response": "Convert input file to output using Rmarkdown"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef total_memory(self, image='ubuntu'):\n        '''Get the available ram fo the docker machine in Kb'''\n        try:\n            ret = subprocess.check_output(\n                f'''docker run -t {image} cat /proc/meminfo  | grep MemTotal''',\n                shell=True,\n                stdin=subprocess.DEVNULL)\n            # ret: MemTotal:       30208916 kB\n            self.tot_mem = int(ret.split()[1])\n        except Exception:\n            # some system does not have cat or grep\n            self.tot_mem = None\n        return self.tot_mem", "response": "Get the available ram fo the docker machine in Kb"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sos_run(workflow=None,\n            targets=None,\n            shared=None,\n            args=None,\n            source=None,\n            **kwargs):\n    '''Execute a workflow from the current SoS script or a specified source\n    (in .sos or .ipynb format), with _input as the initial input of workflow.'''\n    if '__std_out__' in env.sos_dict and '__std_err__' in env.sos_dict:\n        raise RuntimeError(\n            'Executing nested workflow (action sos_run) in tasks is not supported.'\n        )\n\n    if isinstance(workflow, str):\n        workflows = [workflow]\n    elif isinstance(workflow, Sequence):\n        workflows = list(workflow)\n    elif workflow is not None:\n        raise ValueError(\n            'workflow has to be None, a workflow name, or a list of workflow names'\n        )\n\n    if source is None:\n        script = SoS_Script(env.sos_dict['__step_context__'].content,\n                            env.sos_dict['__step_context__'].filename)\n        wfs = [script.workflow(wf, use_default=not targets) for wf in workflows]\n    else:\n        # reading workflow from another file\n        script = SoS_Script(filename=source)\n        wfs = [script.workflow(wf, use_default=not targets) for wf in workflows]\n    # if wf contains the current step or one of the previous one, this constitute\n    # recusive nested workflow and should not be allowed\n    all_parameters = set()\n    for wf in wfs:\n        all_parameters |= set(wf.parameters())\n        if env.sos_dict['step_name'] in [\n                f'{x.name}_{x.index}' for x in wf.sections\n        ]:\n            raise RuntimeError(\n                f'Nested workflow {workflow} contains the current step {env.sos_dict[\"step_name\"]}'\n            )\n\n    # args can be specified both as a dictionary or keyword arguments\n    if args is None:\n        args = kwargs\n    else:\n        args.update(kwargs)\n\n    for key in args.keys():\n        if key not in all_parameters and key not in SOS_ACTION_OPTIONS:\n            raise ValueError(\n                f'No parameter {key} is defined for workflow {workflow}')\n\n    if shared is None:\n        shared = []\n    elif isinstance(shared, str):\n        shared = [shared]\n\n    # for nested workflow, _input would becomes the input of workflow.\n    env.sos_dict.set('__step_output__',\n                     copy.deepcopy(env.sos_dict.get('_input', None)))\n    shared.append('__step_output__')\n    try:\n        my_name = env.sos_dict['step_name']\n        args_output = ', '.join(f'{x}={short_repr(y)}' for x, y in args.items()\n                                if not x.startswith('__'))\n        if 'ACTION' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file(\n                'ACTION',\n                'Executing workflow ``{}`` with input ``{}`` and {}'.format(\n                    workflow,\n                    short_repr(env.sos_dict.get('_input', None), True),\n                    'no args' if not args_output else args_output))\n\n        if not hasattr(env, '__socket__'):\n            raise RuntimeError(\n                'sos_run function cannot be executed in scratch cell.')\n        # tell the master process to receive a workflow\n        # really send the workflow\n        shared = {\n            x: (env.sos_dict[x] if x in env.sos_dict else None) for x in shared\n        }\n\n        wf_ids = [str(uuid.uuid4()) for wf in wfs]\n\n        blocking = not env.sos_dict.get('__concurrent_subworkflow__', False)\n        env.__socket__.send_pyobj([\n            'workflow', wf_ids, wfs, targets, args, shared, env.config, blocking\n        ])\n\n        if not blocking:\n            return {'pending_workflows': wf_ids}\n        res = {}\n        for wf in wfs:\n            wf_res = env.__socket__.recv_pyobj()\n            res.update(wf_res)\n            if wf_res is None:\n                sys.exit(0)\n            elif isinstance(wf_res, Exception):\n                raise wf_res\n            else:\n                env.sos_dict.quick_update(wf_res['shared'])\n        return res\n    finally:\n        # restore step_name in case the subworkflow re-defines it\n        env.sos_dict.set('step_name', my_name)", "response": "Execute a workflow from the current SoS script or a specified source file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting specified script using specified interpreter.", "response": "def script(script, interpreter='', suffix='', args='', **kwargs):\n    '''Execute specified script using specified interpreter. This action accepts common\n    action arguments such as input, active, workdir, docker_image and args. In particular,\n    content of one or more files specified by option input would be prepended before\n    the specified script.'''\n    return SoS_ExecuteScript(script, interpreter, suffix, args).run(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naborting the execution of the current step or loop and yield an warning message msg if expr is False", "response": "def stop_if(expr, msg='', no_output=False):\n    '''Abort the execution of the current step or loop and yield\n    an warning message `msg` if `expr` is False '''\n    if expr:\n        raise StopInputGroup(msg=msg, keep_output=not no_output)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads files from specified URL which should be space tab or newline separated URLs.", "response": "def download(URLs, dest_dir='.', dest_file=None, decompress=False, max_jobs=5):\n    '''Download files from specified URL, which should be space, tab or\n    newline separated URLs. The files will be downloaded to specified\n    destination. If `filename.md5` files are downloaded, they are used to\n    validate downloaded `filename`. Unless otherwise specified, compressed\n    files are decompressed. If `max_jobs` is given, a maximum of `max_jobs`\n    concurrent download jobs will be used for each domain. This restriction\n    applies to domain names and will be applied to multiple download\n    instances.\n    '''\n    if env.config['run_mode'] == 'dryrun':\n        print(f'HINT: download\\n{URLs}\\n')\n        return None\n    if isinstance(URLs, str):\n        urls = [x.strip() for x in URLs.split() if x.strip()]\n    else:\n        urls = list(URLs)\n\n    if not urls:\n        env.logger.debug(f'No download URL specified: {URLs}')\n        return\n    #\n    if dest_file is not None and len(urls) != 1:\n        raise RuntimeError(\n            'Only one URL is allowed if a destination file is specified.')\n    #\n    if dest_file is None:\n        filenames = []\n        for idx, url in enumerate(urls):\n            token = urllib.parse.urlparse(url)\n            # if no scheme or netloc, the URL is not acceptable\n            if not all([\n                    getattr(token, qualifying_attr)\n                    for qualifying_attr in ('scheme', 'netloc')\n            ]):\n                raise ValueError(f'Invalid URL {url}')\n            filename = os.path.split(token.path)[-1]\n            if not filename:\n                raise ValueError(f'Cannot determine destination file for {url}')\n            filenames.append(os.path.join(dest_dir, filename))\n    else:\n        token = urllib.parse.urlparse(urls[0])\n        if not all([\n                getattr(token, qualifying_attr)\n                for qualifying_attr in ('scheme', 'netloc')\n        ]):\n            raise ValueError(f'Invalid URL {url}')\n        filenames = [dest_file]\n    #\n    succ = [(False, None) for x in urls]\n    with ProcessPoolExecutor(max_workers=max_jobs) as executor:\n        for idx, (url, filename) in enumerate(zip(urls, filenames)):\n            # if there is alot, start download\n            succ[idx] = executor.submit(downloadURL, url, filename, decompress,\n                                        idx)\n    succ = [x.result() for x in succ]\n\n    # for su, url in zip(succ, urls):\n    #    if not su:\n    #        env.logger.warning('Failed to download {}'.format(url))\n    failed = [y for x, y in zip(succ, urls) if not x]\n    if failed:\n        if len(urls) == 1:\n            raise RuntimeError('Failed to download {urls[0]}')\n        else:\n            raise RuntimeError(\n                f'Failed to download {failed[0]} ({len(failed)} out of {len(urls)})'\n            )\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(script, args='', **kwargs):\n    '''Execute specified script using bash. This action accepts common action arguments such as\n    input, active, workdir, docker_image and args. In particular, content of one or more files\n    specified by option input would be prepended before the specified script.'''\n    if sys.platform == 'win32':\n        # in the case there is no interpreter, we put the script\n        # at first (this is the case for windows)\n        # and we donot add default args.\n        interpreter = ''\n    else:\n        # if there is a shebang line, we ...\n        if not script.startswith('#!'):\n            interpreter = '/bin/bash'\n            if not args:\n                args = '-ev {filename:q}'\n        else:\n            # execute script directly\n            interpreter = ''\n    return SoS_ExecuteScript(script, interpreter, '', args).run(**kwargs)", "response": "Execute specified script using bash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef report(script=None, input=None, output=None, **kwargs):\n    '''Write script to an output file specified by `output`, which can be\n    a filename to which the content of the script will be written,\n    any object with a \"write\" attribute (e.g. a file handle) for which the \"write\"\n    function will be called with the content. If output is unspecified, the content\n    will be written to standard output or appended to a file specified with command\n    line option `-r`. '''\n    if env.config['run_mode'] == 'dryrun':\n        if '__std_out__' in env.sos_dict:\n            with open(env.sos_dict['__std_out__'], 'a') as so:\n                so.write(f'HINT: report:\\n{\"\" if script is None else script}\\n')\n                if input is not None:\n                    for ifile in input:\n                        so.write(f'  from file: {ifile}\\n')\n        else:\n            print(f'HINT: report:\\n{\"\" if script is None else script}')\n            if input is not None:\n                for ifile in input:\n                    print(f'  from file: {ifile}')\n        return\n    file_handle = None\n    if isinstance(output, str):\n        if not output or output == '-':\n            writer = sys.stdout.write\n        elif output.startswith('>>'):\n            file_handle = open(os.path.expanduser(output[2:]), 'a')\n            writer = file_handle.write\n        else:\n            file_handle = open(os.path.expanduser(output), 'w')\n            writer = file_handle.write\n    elif isinstance(output, (path, file_target)):\n        file_handle = open(os.path.expanduser(str(output)), 'w')\n        writer = file_handle.write\n    elif isinstance(output, (paths, sos_targets)):\n        if len(output) != 1:\n            raise ValueError(f'More than one output is specified {output}')\n        if not isinstance(output[0], (file_target, path)):\n            raise ValueError(\n                f'Action report can only output to file target or standard output'\n            )\n        file_handle = open(os.path.expanduser(str(output[0])), 'w')\n        writer = file_handle.write\n    elif hasattr(output, 'write'):\n        writer = output.write\n    elif output is None or output == '':\n        writer = sys.stdout.write\n    else:\n        raise ValueError(f'Invalid output {output}.')\n\n    # file lock to prevent race condition\n    with TimeoutInterProcessLock(os.path.join(env.temp_dir, 'report_lock')):\n        if isinstance(script, str) and script.strip():\n            writer(script.rstrip() + '\\n\\n')\n        if input is not None:\n            if isinstance(input, (str, file_target)):\n                if 'ACTION' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n                    env.log_to_file('ACTION', f'Loading report from {input}')\n                with open(input) as ifile:\n                    writer(ifile.read().rstrip() + '\\n\\n')\n            elif isinstance(input, Sequence):\n                for ifile in input:\n                    try:\n                        env.logger.debug(f'Loading report from {ifile}')\n                        with open(ifile) as itmp:\n                            writer(itmp.read().rstrip() + '\\n\\n')\n                    except Exception as e:\n                        raise ValueError(\n                            f'Failed to read input file {ifile}: {e}')\n            else:\n                raise ValueError('Unknown input file for action report')\n    #\n    if file_handle:\n        file_handle.close()", "response": "Write script to an output file specified by output which can be used to write the content of the script to the file specified by input."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts input file to output using pandoc.", "response": "def pandoc(script=None,\n           input=None,\n           output=None,\n           args='{input:q} --output {output:q}',\n           **kwargs):\n    '''Convert input file to output using pandoc\n\n    The input can be specified in three ways:\n\n    1. instant script, which is assumed to be in md format\n\n    pandoc:   output='report.html'\n      script\n\n    2. one or more input files. The format is determined by extension of input file\n\n    pandoc(input, output='report.html')\n\n    3. input file specified by command line option `-r` .\n    pandoc(output='report.html')\n\n    If no output is specified, it is assumed to be in html format\n    and is written to standard output.\n\n    You can specify more options such as \"from\" and \"to\" by customizing\n    the args parameter of the action. The default value of args is\n    `{input:q} --output {output:q}'\n    '''\n    #\n    #     # this is output format\n    #     pandoc [OPTIONS] [FILES]\n    # Input formats:  commonmark, docbook, docx, epub, haddock, html, json*, latex,\n    #                 markdown, markdown_github, markdown_mmd, markdown_phpextra,\n    #                 markdown_strict, mediawiki, native, odt, opml, org, rst, t2t,\n    #                 textile, twiki\n    #                 [ *only Pandoc's JSON version of native AST]\n    # Output formats: asciidoc, beamer, commonmark, context, docbook, docx, dokuwiki,\n    #                 dzslides, epub, epub3, fb2, haddock, html, html5, icml, json*,\n    #                 latex, man, markdown, markdown_github, markdown_mmd,\n    #                 markdown_phpextra, markdown_strict, mediawiki, native, odt,\n    #                 opendocument, opml, org, pdf**, plain, revealjs, rst, rtf, s5,\n    #                 slideous, slidy, tei, texinfo, textile\n    #                 [**for pdf output, use latex or beamer and -o FILENAME.pdf]\n    # Options:\n    #   -f FORMAT, -r FORMAT  --from=FORMAT, --read=FORMAT\n    #   -t FORMAT, -w FORMAT  --to=FORMAT, --write=FORMAT\n    #   -o FILENAME           --output=FILENAME\n    #                         --data-dir=DIRECTORY\n    #   -R                    --parse-raw\n    #   -S                    --smart\n    #\n    # IGNORED\n    #\n    if not executable('pandoc').target_exists():\n        raise RuntimeError('pandoc not found')\n\n    input = sos_targets(collect_input(script, input))\n\n    output = sos_targets(output)\n    if len(output) == 0:\n        write_to_stdout = True\n        output = sos_targets(\n            tempfile.NamedTemporaryFile(\n                mode='w+t', suffix='.html', delete=False).name)\n    else:\n        write_to_stdout = False\n    #\n    ret = 1\n    try:\n        p = None\n        cmd = interpolate(f'pandoc {args}', {'input': input, 'output': output})\n        if 'ACTION' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file('ACTION', f'Running command \"{cmd}\"')\n        if env.config['run_mode'] == 'interactive':\n            # need to catch output and send to python output, which will in trun be hijacked by SoS notebook\n            from .utils import pexpect_run\n            ret = pexpect_run(cmd)\n        else:\n            p = subprocess.Popen(cmd, shell=True)\n            ret = p.wait()\n    except Exception as e:\n        env.logger.error(e)\n    if ret != 0:\n        temp_file = os.path.join('.sos', f'pandoc_{os.getpid()}.md')\n        shutil.copyfile(input, temp_file)\n        cmd = interpolate(f'pandoc {args}', {\n            'input': sos_targets(temp_file),\n            'output': sos_targets(output)\n        })\n        raise RuntimeError(\n            f'Failed to execute script. Please use command \\n{cmd}\\nunder {os.getcwd()} to test it.'\n        )\n    if write_to_stdout:\n        with open(output[0].fullname()) as out:\n            sys.stdout.write(out.read())\n    else:\n        env.logger.info(f'Report saved to {output}')\n    try:\n        os.remove(input)\n    except Exception:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_changed_vars(section: SoS_Step):\n    '''changed vars are variables that are \"shared\" and therefore \"provides\"\n    to others '''\n    if 'shared' not in section.options:\n        return set()\n\n    changed_vars = set()\n    svars = section.options['shared']\n    if isinstance(svars, str):\n        changed_vars.add(svars)\n        svars = {svars: svars}\n    elif isinstance(svars, Sequence):\n        for item in svars:\n            if isinstance(item, str):\n                changed_vars.add(item)\n            elif isinstance(item, Mapping):\n                changed_vars |= set(item.keys())\n            else:\n                raise ValueError(\n                    f'Option shared should be a string, a mapping of expression, or list of string or mappings. {svars} provided'\n                )\n    elif isinstance(svars, Mapping):\n        changed_vars |= set(svars.keys())\n    else:\n        raise ValueError(\n            f'Option shared should be a string, a mapping of expression, or list of string or mappings. {svars} provided'\n        )\n    return changed_vars", "response": "Returns a set of variables that are shared and therefore provides a\n    to others"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_used_vars(section):\n    '''Get variables which are variables used by input statement and statements before it'''\n    all_used_vars = set()\n    for statement in section.statements:\n        if statement[0] == '=':\n            all_used_vars |= accessed_vars('='.join(statement[1:3]))\n        elif statement[0] == '!':\n            all_used_vars |= accessed_vars(statement[1])\n        elif statement[0] == ':':\n            all_used_vars |= accessed_vars(statement[2], mode='eval')\n            if statement[1] != 'input':\n                continue\n            if 'paired_with' in statement[2]:\n                try:\n                    pws = get_names_of_param(\n                        'paired_with',\n                        statement[2],\n                        extra_dict=env.sos_dict.dict())\n                    all_used_vars |= set(pws)\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to parse parameter paired_with: {e}')\n            if 'group_with' in statement[2]:\n                try:\n                    pws = get_names_of_param(\n                        'group_with',\n                        statement[2],\n                        extra_dict=env.sos_dict.dict())\n                    all_used_vars |= set(pws)\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to parse parameter group_with: {e}')\n            if 'for_each' in statement[2]:\n                try:\n                    pws = get_names_of_param(\n                        'for_each',\n                        statement[2],\n                        extra_dict=env.sos_dict.dict())\n                    for pw in pws:\n                        all_used_vars |= set(pw.split(','))\n                except Exception as e:\n                    raise ValueError(f'Failed to parse parameter for_each: {e}')\n    if section.task:\n        all_used_vars |= accessed_vars(section.task)\n\n    # now we have a list of global variables that are actually used in the functions\n    # this is specifically designed to handle the last case in #1225\n    func_with_vars = [\n        y for x, y in used_in_func(section.global_stmts).items()\n        if x in all_used_vars\n    ]\n    return set.union(all_used_vars, *func_with_vars)", "response": "Get variables which are variables used by input statement and statements before it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting signature variables which are variables that will be passed to step signatures", "response": "def get_signature_vars(section):\n    '''Get signature variables which are variables that will be\n    saved with step signatures'''\n\n    # signature vars should contain parameters defined in global section\n    # #1155\n    signature_vars = set(\n        section.parameters.keys()\n        & accessed_vars(strip_param_defs(section.global_stmts)))\n\n    input_idx = find_statement(section, 'input')\n    after_input_idx = 0 if input_idx is None else input_idx + 1\n\n    for statement in section.statements[after_input_idx:]:\n        if statement[0] == '=':\n            signature_vars |= accessed_vars('='.join(statement[1:3]))\n        elif statement[0] == '!':\n            signature_vars |= accessed_vars(statement[1])\n    # finally, tasks..\n    if section.task:\n        signature_vars |= accessed_vars(section.task)\n\n    return {x for x in signature_vars if not x.startswith('__')}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting sos_step from statement", "response": "def get_sos_step_steps(stmt):\n    '''\n    Extract sos_step(x) from statement\n    '''\n    opt_values = get_param_of_function(\n        'sos_step', stmt, extra_dict=env.sos_dict.dict())\n    for value in opt_values:\n        if len(value) != 1:\n            raise ValueError('sos_step only accept one and only one parameter')\n    return [x[0] for x in opt_values]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting output_from from the steps section of the grammar", "response": "def get_output_from_steps(stmt, last_step):\n    '''\n    Extract output_from(1), output_from('step_1'), and output_from([1, 2])\n    to determine dependent steps\n    '''\n    opt_values = get_param_of_function(\n        'output_from', stmt, extra_dict=env.sos_dict.dict())\n\n    def step_name(val):\n        if isinstance(val, str):\n            return val\n        elif isinstance(val, int):\n            if val == -1:\n                if last_step is None:\n                    # there is a case where a regular step is checked as auxiliary step.\n                    # we will postpone the decision later because the step might not be\n                    # used as such\n                    return None\n                return last_step\n            if '_' in env.sos_dict['step_name']:\n                return f\"{env.sos_dict['step_name'].rsplit('_',1)[0]}_{val}\"\n            else:\n                return str(val)\n        else:\n            raise ValueError(f'Invalid value {val} for output_from() function')\n\n    res = []\n    for value in opt_values:\n        if len(value) == 1:\n            # regular argument\n            value = value[0]\n        elif value[0] == 'steps':\n            value = value[1]\n        elif value[0] in SOS_TARGETS_OPTIONS:\n            continue\n        else:\n            raise ValueError(\n                f'Unacceptable keyword argument {value[0]} for function output_from'\n            )\n        if isinstance(value, (int, str)):\n            res.append(step_name(value))\n        elif isinstance(value, Sequence):\n            res.extend([step_name(x) for x in value])\n        else:\n            raise ValueError(f'Invalid value for input option from {value}')\n    return [x for x in res if x is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nanalyze a section for how it uses input and output what variables it uses and input and output etc.", "response": "def analyze_section(section: SoS_Step,\n                    default_input: Optional[sos_targets] = None,\n                    default_output: Optional[sos_targets] = None,\n                    context={},\n                    vars_and_output_only: bool = False) -> Dict[str, Any]:\n    '''Analyze a section for how it uses input and output, what variables\n    it uses, and input, output, etc.'''\n    # analysis_key = (section.md5, section.step_name(),\n    #     default_input.target_name() if hasattr(default_input, 'target_name') else '',\n    #     default_output.target_name() if hasattr(default_output, 'target_name') else '', vars_and_output_only)\n    #if analysis_key in analysis_cache:\n    #    return analysis_cache[analysis_key]\n\n    # use a fresh env for analysis\n    new_env, old_env = env.request_new()\n    try:\n        prepare_env(section.global_def, section.global_vars, context)\n\n        env.sos_dict.set('step_name', section.step_name())\n        env.sos_dict.set('__null_func__', __null_func__)\n        if 'STEP' in env.config['SOS_DEBUG'] or 'ALL' in env.config['SOS_DEBUG']:\n            env.log_to_file(\n                'STEP',\n                f'Analyzing {section.step_name()} {\"(output only)\" if vars_and_output_only else \"\"}'\n            )\n\n        res = {\n            'step_name': section.step_name(),\n            'step_output': get_step_output(section, default_output),\n            # variables starting with __ are internals...\n            'environ_vars': get_environ_vars(section),\n            'signature_vars': get_signature_vars(section),\n            'changed_vars': get_changed_vars(section)\n        }\n        if not vars_and_output_only:\n            inps = get_step_input(section, default_input)\n            res['step_input'] = inps[0]\n            res['dynamic_input'] = inps[1]\n            deps = get_step_depends(section)\n            res['step_depends'] = deps[0]\n            res['dynamic_depends'] = deps[1]\n    # analysis_cache[analysis_key] = res\n    finally:\n        # restore env\n        env.restore_to_old(new_env, old_env)\n\n    # #1225\n    # The global section can contain a lot of variables, some of which can be large. Here we\n    # found all variables that will be used in the step, including ones used in substep (signature_vars)\n    # and ones that will be used in input statement etc.\n    section.global_vars = {\n        x: y\n        for x, y in section.global_vars.items()\n        if x in get_all_used_vars(section)\n    }\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef script_to_html(script_file, html_file, args=None, unknown_args=None):\n    '''\n    Convert sos file to html format with syntax highlighting, and\n    either save the output either to a HTML file or view it in a broaser.\n    This converter accepts additional parameters --style or pygments\n    styles, --linenos for displaying linenumbers, and a parameter --raw\n    to embed a URL to the raw sos file.\n    '''\n    from jinja2 import Environment, PackageLoader, select_autoescape\n    environment = Environment(\n        loader=PackageLoader('sos', 'templates'),\n        autoescape=select_autoescape(['html', 'xml']))\n    template = environment.get_template(\n        args.template if args and hasattr(args, 'template') and args.template\n        else 'sos_script.tpl')\n\n    with open(script_file) as script:\n        content = script.read()\n    # for backward compatibility\n    if args and hasattr(args, 'raw'):\n        args.url = args.raw\n    context = {\n        'filename': script_file,\n        'basename': os.path.basename(script_file),\n        'script': content,\n        'sos_version': __version__,\n        'linenos': args.linenos if args and hasattr(args, 'linenos') else True,\n        'url': args.url if args and hasattr(args, 'url') else '',\n        'theme': args.style if args and hasattr(args, 'style') else 'default',\n    }\n    html_content = template.render(context)\n    if html_file is None:\n        if args and args.view:\n            # write to a temp file\n            import tempfile\n            html_file = tempfile.NamedTemporaryFile(\n                delete=False, suffix='.html').name\n            with open(html_file, 'w') as out:\n                out.write(html_content)\n        else:\n            sys.stdout.write(html_content)\n    else:\n        with open(html_file, 'w') as out:\n            out.write(html_content)\n        env.logger.info(f'SoS script saved to {html_file}')\n        #\n    if args and args.view:\n        import webbrowser\n        url = f'file://{os.path.abspath(html_file)}'\n        env.logger.info(f'Viewing {url} in a browser')\n        webbrowser.open(url, new=2)\n        # in case the html file is temporary, give the browser sometime to load it\n        time.sleep(2)", "response": "Convert a script file to html format with syntax highlighting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract workflow from a notebook file or notebook JSON instance", "response": "def extract_workflow(notebook):\n    '''Extract workflow from a notebook file or notebook JSON instance'''\n    if isinstance(notebook, str):\n        nb = nbformat.read(notebook, nbformat.NO_CONVERT)\n    else:\n        nb = notebook\n    cells = nb.cells\n    content = '#!/usr/bin/env sos-runner\\n#fileformat=SOS1.0\\n\\n'\n    for cell in cells:\n        if cell.cell_type != \"code\":\n            continue\n        # Non-sos code cells are also ignored\n        if 'kernel' in cell.metadata and cell.metadata['kernel'] not in ('sos',\n                                                                         'SoS',\n                                                                         None):\n            continue\n        lines = cell.source.split('\\n')\n        valid_cell = False\n        for idx, line in enumerate(lines):\n            if valid_cell or (line.startswith('%include') or\n                              line.startswith('%from')):\n                content += line + '\\n'\n            elif SOS_SECTION_HEADER.match(line):\n                valid_cell = True\n                # look retrospectively for comments\n                c = idx - 1\n                comment = ''\n                while c >= 0 and lines[c].startswith('#'):\n                    comment = lines[c] + '\\n' + comment\n                    c -= 1\n                content += comment + line + '\\n'\n        if valid_cell:\n            content += '\\n'\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new IPython kernel", "response": "def new_ipy(s=''):\n    \"\"\"Create a new IPython kernel (optionally with extra arguments)\n\n    XXX: Allow passing of profile information here\n\n    Examples\n    --------\n\n        new_ipy()\n\n    \"\"\"\n    # Modified by Bo Peng.\n    # This package has been deprecated. Need to import from ipykernel\n    from jupyter_client.manager import KernelManager\n    km = KernelManager()\n    km.start_kernel()\n    return km_from_string(km.connection_file)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef km_from_string(s=''):\n    try:\n        import IPython\n    except ImportError:\n        raise ImportError(\"Could not find IPython. \" + _install_instructions)\n    # Modified by BoPeng\n    #\n    #from IPython.config.loader import KeyValueConfigLoader\n    from traitlets.config.loader import KeyValueConfigLoader\n    try:\n        # Updated by Bo Peng for module names\n        from jupyter_client.manager import  KernelManager\n        from jupyter_client import find_connection_file\n    except ImportError:\n        #  IPython < 1.0\n        from IPython.zmq.blockingkernelmanager import BlockingKernelManager as KernelManager\n        from IPython.zmq.kernelapp import kernel_aliases\n        try:\n            from IPython.lib.kernel import find_connection_file\n        except ImportError:\n            # < 0.12, no find_connection_file\n            pass\n\n    global km, kc, send\n\n    s = s.replace('--existing', '')\n    if 'connection_file' in KernelManager.class_trait_names():\n        # 0.12 uses files instead of a collection of ports\n        # include default IPython search path\n        # filefind also allows for absolute paths, in which case the search\n        # is ignored\n        try:\n            # XXX: the following approach will be brittle, depending on what\n            # connection strings will end up looking like in the future, and\n            # whether or not they are allowed to have spaces. I'll have to sync\n            # up with the IPython team to address these issues -pi\n            if '--profile' in s:\n                k,p = s.split('--profile')\n                k = k.lstrip().rstrip() # kernel part of the string\n                p = p.lstrip().rstrip() # profile part of the string\n                fullpath = find_connection_file(k,p)\n            else:\n                fullpath = find_connection_file(s.lstrip().rstrip())\n        except IOError as e:\n            echo(\":IPython \" + s + \" failed\", \"Info\")\n            echo(\"^-- failed '\" + s + \"' not found\", \"Error\")\n            return\n        km = KernelManager(connection_file = fullpath)\n        km.load_connection_file()\n    else:\n        if s == '':\n            echo(\":IPython 0.11 requires the full connection string\")\n            return\n        loader = KeyValueConfigLoader(s.split(), aliases=kernel_aliases)\n        cfg = loader.load_config()['KernelApp']\n        try:\n            km = KernelManager(\n                shell_address=(ip, cfg['shell_port']),\n                sub_address=(ip, cfg['iopub_port']),\n                stdin_address=(ip, cfg['stdin_port']),\n                hb_address=(ip, cfg['hb_port']))\n        except KeyError as e:\n            echo(\":IPython \" +s + \" failed\", \"Info\")\n            echo(\"^-- failed --\"+e.message.replace('_port','')+\" not specified\", \"Error\")\n            return\n\n    try:\n        kc = km.client()\n    except AttributeError:\n        # 0.13\n        kc = km\n    kc.start_channels()\n\n    try:\n        send = kc.execute\n    except AttributeError:\n        # < 3.0\n        send = kc.shell_channel.execute\n\n    #XXX: backwards compatibility for IPython < 0.13\n    try:\n        import inspect\n        sc = kc.shell_channel\n        num_oinfo_args = len(inspect.getargspec(sc.object_info).args)\n        if num_oinfo_args == 2:\n            # patch the object_info method which used to only take one argument\n            klass = sc.__class__\n            klass._oinfo_orig = klass.object_info\n            klass.object_info = lambda s,x,y: s._oinfo_orig(x)\n    except Exception:\n        pass\n\n    #XXX: backwards compatibility for IPython < 1.0\n    if not hasattr(kc, 'iopub_channel'):\n        kc.iopub_channel = kc.sub_channel\n\n    # now that we're connect to an ipython kernel, activate completion\n    # machinery, but do so only for the local buffer if the user added the\n    # following line the vimrc:\n    #   let g:ipy_completefunc = 'local'\n    vim.command(\"\"\"\n        if g:ipy_completefunc == 'global'\n            set completefunc=CompleteIPython\n        elseif g:ipy_completefunc == 'local'\n            setl completefunc=CompleteIPython\n        endif\n        \"\"\")\n    # also activate GUI doc balloons if in gvim\n    vim.command(\"\"\"\n        if has('balloon_eval')\n            set bexpr=IPythonBalloonExpr()\n        endif\n        \"\"\")\n    set_pid()\n    return km", "response": "create kernel manager from string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if vim - ipython shell is currently open False otherwise", "response": "def vim_ipython_is_open():\n    \"\"\"\n    Helper function to let us know if the vim-ipython shell is currently\n    visible\n    \"\"\"\n    for w in vim.windows:\n        if w.buffer.name is not None and w.buffer.name.endswith(\"vim-ipython\"):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving HTML tags in input text and format the texts accordingly.", "response": "def dehtml(text):\n    '''Remove HTML tag in input text and format the texts\n    accordingly. '''\n    # added by BoPeng to handle html output from kernel\n    #\n    # Do not understand why, but I cannot define the class outside of the\n    # function.\n    try:\n        # python 2\n        from HTMLParser import HTMLParser\n    except ImportError:\n        # python 3\n        from html.parser import HTMLParser\n    # added by BoPeng to handle html output from kernel\n    class _DeHTMLParser(HTMLParser):\n        '''This parser analyzes input text, removes HTML tags such as\n        <p>, <br>, <ul>, <li> etc and returns properly formatted texts.\n        '''\n        def __init__(self):\n            HTMLParser.__init__(self)\n            self.__text = []\n\n        def handle_data(self, data):\n            text = data.strip()\n            if len(text) > 0:\n                text = re.sub('[ \\t\\r\\n]+', ' ', text)\n                self.__text.append(text + ' ')\n\n        def handle_starttag(self, tag, attrs):\n            if tag == 'p':\n                self.__text.append('\\n\\n\\n\\n')\n            elif tag == 'br':\n                self.__text.append('\\n\\n')\n            elif tag == 'ul':\n                self.__text.append('')\n            elif tag == 'li':\n                self.__text.append('\\n\\n  * ')\n\n        def handle_endtag(self, tag):\n            if tag == 'ul':\n                self.__text.append('\\n\\n')\n            if tag == 'li':\n                self.__text.append('\\n\\n')\n\n        def handle_startendtag(self, tag, attrs):\n            if tag == 'br':\n                self.__text.append('\\n\\n')\n\n        def text(self):\n            return ''.join(self.__text).strip()\n\n    try:\n        parser = _DeHTMLParser()\n        parser.feed(text)\n        parser.close()\n        return parser.text()\n    except Exception as e:\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the internal buffer with the current messages from the iopub channel.", "response": "def update_subchannel_msgs(debug=False, force=False):\n    \"\"\"\n    Grab any pending messages and place them inside the vim-ipython shell.\n    This function will do nothing if the vim-ipython shell is not visible,\n    unless force=True argument is passed.\n    \"\"\"\n    if kc is None or (not vim_ipython_is_open() and not force):\n        return False\n    msgs = kc.iopub_channel.get_msgs()\n    b = vim.current.buffer\n    startedin_vimipython = vim.eval('@%')=='vim-ipython'\n    if not startedin_vimipython:\n        # switch to preview window\n        vim.command(\n            \"try\"\n            \"|silent! wincmd P\"\n            \"|catch /^Vim\\%((\\a\\+)\\)\\=:E441/\"\n            \"|silent pedit +set\\ ma vim-ipython\"\n            \"|silent! wincmd P\"\n            \"|endtry\")\n        # if the current window is called 'vim-ipython'\n        if vim.eval('@%')=='vim-ipython':\n            # set the preview window height to the current height\n            vim.command(\"set pvh=\" + vim.eval('winheight(0)'))\n        else:\n            # close preview window, it was something other than 'vim-ipython'\n            vim.command(\"pcl\")\n            vim.command(\"silent pedit +set\\ ma vim-ipython\")\n            vim.command(\"wincmd P\") #switch to preview window\n            # subchannel window quick quit key 'q'\n            vim.command('nnoremap <buffer> q :q<CR>')\n            vim.command(\"set bufhidden=hide buftype=nofile ft=python\")\n            vim.command(\"setlocal nobuflisted\") # don't come up in buffer lists\n            vim.command(\"setlocal nonumber\") # no line numbers, we have in/out nums\n            vim.command(\"setlocal noswapfile\") # no swap file (so no complaints cross-instance)\n            # make shift-enter and control-enter in insert mode behave same as in ipython notebook\n            # shift-enter send the current line, control-enter send the line\n            # but keeps it around for further editing.\n            vim.command(\"inoremap <buffer> <s-Enter> <esc>dd:python run_command('''<C-r>\\\"''')<CR>i\")\n            # pkddA: paste, go up one line which is blank after run_command,\n            # delete it, and then back to insert mode\n            vim.command(\"inoremap <buffer> <c-Enter> <esc>dd:python run_command('''<C-r>\\\"''')<CR>pkddA\")\n            # ctrl-C gets sent to the IPython process as a signal on POSIX\n            vim.command(\"noremap <buffer> \u0003 :IPythonInterrupt<cr>\")\n\n    #syntax highlighting for python prompt\n    # QtConsole In[] is blue, but I prefer the oldschool green\n    # since it makes the vim-ipython 'shell' look like the holidays!\n    colors = status_prompt_colors\n    vim.command(\"hi IPyPromptIn ctermfg=%s guifg=%s\" % (colors['in_ctermfg'], colors['in_guifg']))\n    vim.command(\"hi IPyPromptOut ctermfg=%s guifg=%s\" % (colors['out_ctermfg'], colors['out_guifg']))\n    vim.command(\"hi IPyPromptOut2 ctermfg=%s guifg=%s\" % (colors['out2_ctermfg'], colors['out2_guifg']))\n    in_expression = vim_regex_escape(status_prompt_in % {'line': 999}).replace('999', '[ 0-9]*')\n    vim.command(\"syn match IPyPromptIn /^%s/\" % in_expression)\n    out_expression = vim_regex_escape(status_prompt_out % {'line': 999}).replace('999', '[ 0-9]*')\n    vim.command(\"syn match IPyPromptOut /^%s/\" % out_expression)\n    vim.command(\"syn match IPyPromptOut2 /^\\\\.\\\\.\\\\.* /\")\n    b = vim.current.buffer\n    update_occured = False\n    for m in msgs:\n        s = ''\n        if 'msg_type' not in m['header']:\n            # debug information\n            #echo('skipping a message on sub_channel','WarningMsg')\n            #echo(str(m))\n            continue\n        header = m['header']['msg_type']\n        if header == 'status':\n            continue\n        elif header == 'stream':\n            # TODO: alllow for distinguishing between stdout and stderr (using\n            # custom syntax markers in the vim-ipython buffer perhaps), or by\n            # also echoing the message to the status bar\n            try:\n                s = strip_color_escapes(m['content']['data'])\n            except KeyError:    # changed in IPython 3.0.0\n                s = strip_color_escapes(m['content']['text'])\n        elif header == 'pyout' or header == 'execute_result':\n            s = status_prompt_out % {'line': m['content']['execution_count']}\n            s += m['content']['data']['text/plain']\n        elif header == 'display_data':\n            # TODO: handle other display data types (HMTL? images?)\n            # Modified by BoPeng\n            if 'text/plain' in m['content']['data']:\n                s += m['content']['data']['text/plain']\n            elif 'text/markdown' in m['content']['data']:\n                s += m['content']['data']['text/markdown']\n            elif 'text/html' in m['content']['data']:\n                s += dehtml(m['content']['data']['text/html'])\n        elif header == 'pyin' or header == 'execute_input':\n            # TODO: the next line allows us to resend a line to ipython if\n            # %doctest_mode is on. In the future, IPython will send the\n            # execution_count on subchannel, so this will need to be updated\n            # once that happens\n            line_number = m['content'].get('execution_count', 0)\n            prompt = status_prompt_in % {'line': line_number}\n            s = prompt\n            # add a continuation line (with trailing spaces if the prompt has them)\n            dots = '.' * len(prompt.rstrip())\n            dots += prompt[len(prompt.rstrip()):]\n            s += m['content']['code'].rstrip().replace('\\n', '\\n' + dots)\n        elif header == 'pyerr' or header == 'error':\n            c = m['content']\n            s = \"\\n\".join(map(strip_color_escapes,c['traceback']))\n            s += c['ename'] + \":\" + c['evalue']\n\n        if s.find('\\n') == -1:\n            # somewhat ugly unicode workaround from\n            # http://vim.1045645.n5.nabble.com/Limitations-of-vim-python-interface-with-respect-to-character-encodings-td1223881.html\n            if isinstance(s,unicode):\n                s=s.encode(vim_encoding)\n            b.append(s)\n        else:\n            try:\n                b.append(s.splitlines())\n            except Exception:\n                b.append([l.encode(vim_encoding) for l in s.splitlines()])\n        update_occured = True\n    # make a newline so we can just start typing there\n    if status_blank_lines:\n        if b[-1] != '':\n            b.append([''])\n    if update_occured or force:\n        vim.command('normal! G') # go to the end of the file\n    if not startedin_vimipython:\n        vim.command('normal! \u0017p') # go back to where you were\n    return update_occured"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the prompt or message if msg_id is None print the message if show_execution_count is True", "response": "def print_prompt(prompt,msg_id=None):\n    \"\"\"Print In[] or In[42] style messages\"\"\"\n    global show_execution_count\n    if show_execution_count and msg_id:\n        # wait to get message back from kernel\n        try:\n            child = get_child_msg(msg_id)\n            count = child['content']['execution_count']\n            echo(\"In[%d]: %s\" %(count,prompt))\n        except Empty:\n            echo(\"In[]: %s (no reply from IPython kernel)\" % prompt)\n    else:\n        echo(\"In[]: %s\" % prompt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_pid():\n    global pid\n    lines = '\\n'.join(['import os', '_pid = os.getpid()'])\n\n    try:\n        msg_id = send(lines, silent=True, user_variables=['_pid'])\n    except TypeError: # change in IPython 3.0+\n        msg_id = send(lines, silent=True, user_expressions={'_pid':'_pid'})\n\n    # wait to get message back from kernel\n    try:\n        child = get_child_msg(msg_id)\n    except Empty:\n        echo(\"no reply from IPython kernel\")\n        return\n    try:\n        pid = int(child['content']['user_variables']['_pid'])\n    except TypeError: # change in IPython 1.0.dev moved this out\n        pid = int(child['content']['user_variables']['_pid']['data']['text/plain'])\n    except KeyError:    # change in IPython 3.0+\n        pid = int(\n            child['content']['user_expressions']['_pid']['data']['text/plain'])\n    except KeyError: # change in IPython 1.0.dev moved this out\n        echo(\"Could not get PID information, kernel not running Python?\")\n    return pid", "response": "Explicitly ask the ipython kernel for its pid"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interrupt_kernel_hack(signal_to_send=None):\n    global pid\n    import signal\n    import os\n    if pid is None:\n        # Avoid errors if we couldn't get pid originally,\n        # by trying to obtain it now\n        pid = set_pid()\n\n        if pid is None:\n            echo(\"cannot get kernel PID, Ctrl-C will not be supported\")\n            return\n    if not signal_to_send:\n        signal_to_send = signal.SIGINT\n\n    echo(\"KeyboardInterrupt (sent to ipython: pid \" +\n        \"%i with signal %s)\" % (pid, signal_to_send),\"Operator\")\n    try:\n        os.kill(pid, int(signal_to_send))\n    except OSError:\n        echo(\"unable to kill pid %d\" % pid)\n        pid = None", "response": "This is a hack to send a keyboard interrupt to the remote kernel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_adc(self, adc_number):\n        assert 0 <= adc_number <= 7, 'ADC number must be a value of 0-7!'\n        # Build a single channel read command.\n        # For example channel zero = 0b11000000\n        command = 0b11 << 6                  # Start bit, single channel read\n        command |= (adc_number & 0x07) << 3  # Channel number (in 3 bits)\n        # Note the bottom 3 bits of command are 0, this is to account for the\n        # extra clock to do the conversion, and the low null bit returned at\n        # the start of the response.\n        resp = self._spi.transfer([command, 0x0, 0x0])\n        # Parse out the 10 bits of response data and return it.\n        result = (resp[0] & 0x01) << 9\n        result |= (resp[1] & 0xFF) << 1\n        result |= (resp[2] & 0x80) >> 7\n        return result & 0x3FF", "response": "Read the current value of the specified ADC channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_adc_difference(self, differential):\n        assert 0 <= differential <= 7, 'Differential number must be a value of 0-7!'\n        # Build a difference channel read command.\n        command = 0b10 << 6                  # Start bit, differential read\n        command |= (differential & 0x07) << 3  # Channel number (in 3 bits)\n        # Note the bottom 3 bits of command are 0, this is to account for the\n        # extra clock to do the conversion, and the low null bit returned at\n        # the start of the response.\n        resp = self._spi.transfer([command, 0x0, 0x0])\n        # Parse out the 10 bits of response data and return it.\n        result = (resp[0] & 0x01) << 9\n        result |= (resp[1] & 0xFF) << 1\n        result |= (resp[2] & 0x80) >> 7\n        return result & 0x3FF", "response": "Read the difference between two ADC channel names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fetchBlock(self):\n        # make sure that another block request is not standing\n        if self._blockRequestInProgress :\n           # need to wait here before returning... (TODO)\n           return\n\n        # make sure another block request has not completed meanwhile\n        if self._standbyBlock is not None: \n           return\n\n        self._blockRequestInProgress = True\n        fetchReq = TFetchResultsReq(operationHandle=self.operationHandle,\n                                    orientation=TFetchOrientation.FETCH_NEXT,\n                                    maxRows=self.arraysize)\n        self._standbyBlock = self._fetch([],fetchReq)\n        self._blockRequestInProgress = False\n        return", "response": "internal use only. fetchBlock - fetch a block of rows from the server and put in standby block."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches a single record from the database", "response": "def fetchone(self):\n        \"\"\" fetch a single row. a lock object is used to assure that a single \n\t record will be fetched and all housekeeping done properly in a \n\t multithreaded environment.\n         as getting a block is currently synchronous, this also protects \n\t against multiple block requests (but does not protect against \n\t explicit calls to to _fetchBlock())\n        \"\"\"\n        self._cursorLock.acquire()\n\n        # if there are available records in current block, \n\t# return one and advance counter\n        if self._currentBlock is not None and self._currentRecordNum < len(self._currentBlock):\n           x = self._currentRecordNum\n           self._currentRecordNum += 1\n           self._cursorLock.release()\n           return self._currentBlock[x]\n\n        # if no standby block is waiting, fetch a block\n        if self._standbyBlock is None:\n           # TODO - make sure exceptions due to problems in getting the block \n\t   # of records from the server are handled properly\n           self._fetchBlock()\n\n        # if we still do not have a standby block (or it is empty), \n\t# return None - no more data is available\n        if self._standbyBlock is None or len(self._standbyBlock)==0:\n           self._cursorLock.release()\n           return None\n\n        #  move the standby to current\n        self._currentBlock = self._standbyBlock \n        self._standbyBlock = None\n        self._currentRecordNum = 1\n\n        # return the first record\n        self._cursorLock.release()\n        return self._currentBlock[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetchmany(self,size=-1):\n        self._cursorLock.acquire()\n\n        # default value (or just checking that someone did not put a ridiculous size)\n        if size < 0 or size > self.MAX_BLOCK_SIZE:\n           size = self.arraysize\n        recs = []\n        for i in range(0,size):\n            recs.append(self.fetchone())\n\n        self._cursorLock.release()\n        return recs", "response": "fetchmany returns a sequential set of records."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the remainder of records from the query.", "response": "def fetchall(self):\n        \"\"\" returns the remainder of records from the query. This is \n\t guaranteed by locking, so that no other thread can grab a few records \n\t while the set is fetched. This has the side effect that other threads \n\t may have to wait for an arbitrary long time until this query is done \n\t before they can return (obviously with None).\n        \"\"\"\n        self._cursorLock.acquire()\n\n        recs = []\n        while True:\n            rec = self.fetchone()\n            if rec is None:\n               break\n            recs.append(rec)\n\n        self._cursorLock.release()\n        return recs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, f):\n        '''parse a JSON stream.\n        :type f: file\n        :param f: stream to parse JSON from\n        :type context: ctypes.POINTER\n        :raises YajlError: When invalid JSON in input stream found\n        '''\n        self._listener.parse_start()\n\n        while len(f):\n            data = f.read(self._buffer_size).encode('utf-8')\n            status = yajl.yajl_parse(self._handler, data, len(data))\n            self._listener.parse_buf()\n            if status != OK.value:\n                if status == CLIENT_CANCELLED.value:\n                    if self._exc_info:\n                        exc_info = self._exc_info\n                        raise exc_info[0](exc_info[1]).with_traceback(exc_info[2])\n                    else:\n                        raise YajlError(\"Client probably cancelled callback\")\n                else:\n                    yajl.yajl_get_error.restype = c_char_p\n                    error = yajl.yajl_get_error(self._handler, 1, data, len(data))\n                    raise YajlError(error)\n            if not data: return", "response": "Parse a JSON stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_number(self, ctx, value):\n        ''' Since this is defined both integer and double callbacks are useless '''\n        value = int(value) if value.isdigit() else float(value)\n        top = self._stack[-1]\n        if top is JSONCompositeType.OBJECT:\n            self.fire(JSONStreamer.VALUE_EVENT, value)\n        elif top is JSONCompositeType.ARRAY:\n            self.fire(JSONStreamer.ELEMENT_EVENT, value)\n        else:\n            raise RuntimeError('Invalid json-streamer state')", "response": "When a number is received from the JSON stream we need to fire the appropriate events."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef consume(self, data):\n        if not self._started:\n            self.fire(JSONStreamer.DOC_START_EVENT)\n            self._started = True\n        self._file_like.write(data)\n        try:\n            self._parser.parse(self._file_like)\n        except YajlError as ye:\n            raise JSONStreamerException(ye.value)", "response": "Takes input that must be parsed\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        self.fire(JSONStreamer.DOC_END_EVENT)\n        self._stack = None\n        self._parser.close()", "response": "Closes the streamer which causes a DOC_END_EVENT to be fired and frees up memory used by yajl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consume(self, data):\n        try:\n            self._streamer.consume(data)\n        except YajlError as ye:\n            print(ye.value)\n            raise JSONStreamerException(ye.value)", "response": "Takes input that must be parsed\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the next size characters from the buffer and returns it.", "response": "def read(self, size:int=None):\n        \"\"\"\n        :param size: number of characters to read from the buffer\n        :return: string that has been read from the buffer\n        \"\"\"\n        if size:\n            result = self._buffer[0:size]\n            self._buffer = self._buffer[size:]\n            return result\n        else:\n            result = self._buffer\n            self._buffer = ''\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the value of a dzn statement.", "response": "def parse_value(val, var_type=None, enums=None, rebase_arrays=True):\n    \"\"\"Parses the value of a dzn statement.\n\n    Parameters\n    ----------\n    val : str\n        A value in dzn format.\n    var_type : dict\n        The dictionary of variable type as returned by the command ``minizinc\n        --model-types-only``. Default is ``None``, in which case the type of the\n        variable is inferred from its value. To parse an enum value as a Python\n        enum type its ``var_type`` is required, otherwise the value is simply\n        returned as a string.\n    enums : dict of IntEnum\n        A dictionary containing Python enums, with their respective names as\n        keys. These enums are available to the parser to convert enum values\n        into corresponding values of their respective enum types. Enum values\n        can only be parsed if also the ``var_type`` of the variable is\n        available.\n    rebase_arrays : bool\n        If the parsed value is an array and ``rebase_arrays`` is ``True``,\n        return it as zero-based lists. If ``rebase_arrays`` is ``False``,\n        instead, return it as a dictionary, preserving the original index-set.\n\n    Returns\n    -------\n    object\n        The parsed object. The type of the object depends on the dzn value.\n    \"\"\"\n\n    if not var_type:\n        p_val = _parse_array(\n            val, rebase_arrays=rebase_arrays, enums=enums, raise_errors=False\n        )\n        if p_val is not None:\n            return p_val\n        return _parse_val(val, enums=enums)\n\n    if 'dims' in var_type:\n        return _parse_array(\n            val, rebase_arrays=rebase_arrays, var_type=var_type, enums=enums\n        )\n\n    return _parse_val(val, var_type=var_type, enums=enums)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a dzn string or file into a dictionary of variable assignments.", "response": "def dzn2dict(dzn, *, rebase_arrays=True, types=None, return_enums=False):\n    \"\"\"Parses a dzn string or file into a dictionary of variable assignments.\n\n    Parameters\n    ----------\n    dzn : str\n        A dzn content string or a path to a dzn file.\n    rebase_arrays : bool\n        Whether to return arrays as zero-based lists or to return them as\n        dictionaries, preserving the original index-sets.\n    types : dict\n        Dictionary of variable types. Types can either be dictionaries, as\n        returned by the ``minizinc --model-types-only``, or strings containing a\n        type in dzn format. If the type is a string, it can either be the name\n        of an enum type or one of the following: ``bool``, ``int``, ``float``,\n        ``enum``, ``set of <type>``, ``array[<index_sets>] of <type>``. The\n        default value for ``var_types`` is ``None``, in which case the type of\n        most dzn assignments will be inferred automatically from the value. Enum\n        values can only be parsed if their respective types are available.\n    return_enums : bool\n        Whether to return the parsed enum types included in the dzn content.\n\n    Returns\n    -------\n    dict\n        A dictionary containing the variable assignments parsed from the\n        input file or string.\n    \"\"\"\n    dzn_ext = os.path.splitext(dzn)[1]\n    if dzn_ext == '.dzn':\n        with open(dzn) as f:\n            dzn = f.read()\n\n    var_types = None\n    if types:\n        var_types = {}\n        for var, var_type in types.items():\n            if isinstance(var_type, str):\n                var_types[var] = _to_var_type(var, var_type)\n            elif isinstance(var_type, dict):\n                var_types[var] = var_type\n            else:\n                err = 'Type of variable {} must be a string or a dict.'\n                raise ValueError(err.format(var))\n\n    enum_types = None\n    if var_types:\n        enum_types = []\n        for var, var_type in var_types.items():\n            if 'enum_type' in var_type and var_type['enum_type'] == var:\n                enum_types.append(var)\n\n    var_list = []\n    dzn = _comm_p.sub('\\n', dzn)\n    stmts = _stmt_p.findall(dzn)\n    for stmt in stmts:\n        var_m = _var_p.match(stmt)\n        if var_m:\n            var = var_m.group('var')\n            val = var_m.group('val')\n            var_list.append((var, val))\n        else:\n            raise ValueError(\n                'Unsupported parsing for statement:\\n{}'.format(repr(stmt))\n            )\n\n    enums = None\n    if enum_types:\n        enums = {}\n        remaining = []\n        while len(var_list) > 0:\n            var, val = var_list.pop(0)\n            if var in enum_types:\n                enum = None\n                enum_m = _enum_p.match(val)\n                if enum_m:\n                    vals = enum_m.group('vals').strip()\n                    if vals:\n                        enum_vals = _parse_enum_vals(vals.split(','))\n                        enum = IntEnum(\n                            var, {v: i + 1 for i, v in enumerate(enum_vals)}\n                        )\n                if enum is None:\n                    raise ValueError(\n                        'Cannot parse enum type \\'{} = {}\\'.'.format(var, val)\n                    )\n                enums[var] = enum\n            else:\n                remaining.append((var, val))\n        var_list = remaining\n\n    assign = {}\n    for var, val in var_list:\n        var_type = None\n        if var_types:\n            var_type = var_types.get(var, None)\n        assign[var] = parse_value(\n            val, var_type=var_type, enums=enums, rebase_arrays=rebase_arrays\n        )\n\n    if return_enums and enums:\n        assign.update(enums)\n\n    return assign"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef args(\n        self, all_solutions=False, num_solutions=None, free_search=False,\n        parallel=None, seed=None, **kwargs\n    ):\n        \"\"\"Returns a list of command line arguments for the specified options.\n\n        If the solver parser is able to parse statistics, this function should\n        always add options to display statistics.\n\n        Parameters\n        ----------\n        all_solutions : bool\n            Whether all the solutions must be returned (default is False).\n        num_solutions : int\n            The maximum number of solutions to be returned (only used in\n            satisfation problems).\n        free_search : bool\n            Whether the solver should be instructed to perform a free search.\n        parallel : int\n            The number of parallel threads the solver should use.\n        seed : int\n            The random number generator seed to pass to the solver.\n        \"\"\"\n        args = ['-s', '-v']\n        if all_solutions:\n            args.append('-a')\n        if num_solutions is not None:\n            args += ['-n', num_solutions]\n        if free_search:\n            args.append('-f')\n        if parallel is not None:\n            args += ['-p', parallel]\n        if seed is not None:\n            args += ['-r', seed]\n        return args", "response": "Returns a list of command line arguments for the specified options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable or disables debugging messages on the standard output.", "response": "def debug(dbg=True):\n    \"\"\"Enables or disables debugging messages on the standard output.\"\"\"\n    global _debug_handler\n    if dbg and _debug_handler is None:\n        _debug_handler = logging.StreamHandler()\n        logger.addHandler(_debug_handler)\n        logger.setLevel(logging.DEBUG)\n    elif not dbg and _debug_handler is not None:\n        logger.removeHandler(_debug_handler)\n        _debug_handler = None\n        logger.setLevel(logging.WARNING)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning an external process.", "response": "def run_process(*args, input=None):\n    \"\"\"Run an external process.\n\n    Parameters\n    ----------\n    *args : list of str\n        The arguments to pass to the external process. The first argument should\n        be the executable to call.\n    input : str or bytes\n        The input stream to supply to the extenal process.\n\n    Return\n    ------\n        Object wrapping the executed process.\n    \"\"\"\n    shell = os.name == 'nt'\n    start_time = _time()\n    cp = subprocess.run(\n        args, input=input, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        shell=shell, bufsize=1, universal_newlines=True\n    )\n    end_time = _time()\n    return CompletedProcessWrapper(cp, start_time, end_time)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef minizinc_version():\n    vs = _run_minizinc('--version')\n    m = re.findall('version ([\\d\\.]+)', vs)\n    if not m:\n        raise RuntimeError('MiniZinc executable not found.')\n    return m[0]", "response": "Returns the version of the found minizinc executable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_model(model, output_file=None, output_dir=None, output_prefix='pymzn'):\n    if output_file:\n        mzn_file = output_file\n        output_file = open(output_file, 'w+', buffering=1)\n    else:\n        output_prefix += '_'\n        output_file = NamedTemporaryFile(\n            dir=output_dir, prefix=output_prefix, suffix='.mzn', delete=False,\n            mode='w+', buffering=1\n        )\n        mzn_file = output_file.name\n\n    output_file.write(model)\n    output_file.close()\n\n    logger.info('Generated file {}'.format(mzn_file))\n    return mzn_file", "response": "Save a minizinc model to a temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming instance checking on a given model + data.", "response": "def check_instance(\n    mzn, *dzn_files, data=None, include=None, stdlib_dir=None, globals_dir=None,\n    allow_multiple_assignments=False\n):\n    \"\"\"Perform instance checking on a model + data.\n\n    This function calls the command ``minizinc --instance-check-only`` to check\n    for consistency of the given model + data.\n\n    Parameters\n    ----------\n    mzn : str\n        The minizinc model. This can be either the path to the ``.mzn`` file or\n        the content of the model itself.\n    *dzn_files\n        A list of paths to dzn files to attach to the minizinc execution,\n        provided as positional arguments; by default no data file is attached.\n    data : dict\n        Additional data as a list of strings containing dzn variables\n        assignments.\n    include : str or list\n        One or more additional paths to search for included ``.mzn`` files.\n    stdlib_dir : str\n        The path to the MiniZinc standard library. Provide it only if it is\n        different from the default one.\n    globals_dir : str\n        The path to the MiniZinc globals directory. Provide it only if it is\n        different from the default one.\n    allow_multiple_assignments : bool\n        Whether to allow multiple assignments of variables. Sometimes is\n        convenient to simply let the data file override the value already\n        assigned in the minizinc file. Default is ``False``.\n\n    Raises\n    ------\n        ``MiniZincError`` if instance checking fails.\n    \"\"\"\n\n    args = ['--instance-check-only']\n    args += _flattening_args(\n        mzn, *dzn_files, data=data, include=include, stdlib_dir=stdlib_dir,\n        globals_dir=globals_dir,\n        allow_multiple_assignments=allow_multiple_assignments\n    )\n\n    input = mzn if args[-1] == '-' else None\n    proc = _run_minizinc_proc(*args, input=input)\n\n    if proc.stderr_data:\n        raise MiniZincError(\n            mzn if input is None else '\\n' + mzn + '\\n', args, proc.stderr_data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms model checking on a given minizinc model.", "response": "def check_model(\n    mzn, *, include=None, stdlib_dir=None, globals_dir=None\n):\n    \"\"\"Perform model checking on a given model.\n\n    This function calls the command ``minizinc --model-check-only`` to check\n    for consistency of the given model.\n\n    Parameters\n    ----------\n    mzn : str\n        The minizinc model. This can be either the path to the ``.mzn`` file or\n        the content of the model itself.\n    include : str or list\n        One or more additional paths to search for included ``.mzn`` files.\n    stdlib_dir : str\n        The path to the MiniZinc standard library. Provide it only if it is\n        different from the default one.\n    globals_dir : str\n        The path to the MiniZinc globals directory. Provide it only if it is\n        different from the default one.\n\n    Raises\n    ------\n        ``MiniZincError`` if model checking fails.\n    \"\"\"\n\n    args = ['--model-check-only']\n    args += _flattening_args(\n        mzn, include=include, stdlib_dir=stdlib_dir, globals_dir=globals_dir\n    )\n\n    input = mzn if args[-1] == '-' else None\n    proc = _run_minizinc_proc(*args, input=input)\n\n    if proc.stderr_data:\n        raise MiniZincError(\n            mzn if input is None else '\\n' + mzn + '\\n', args, proc.stderr_data\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef minizinc(\n    mzn, *dzn_files, args=None, data=None, include=None, stdlib_dir=None,\n    globals_dir=None, declare_enums=True, allow_multiple_assignments=False,\n    keep=False, output_vars=None, output_base=None, output_mode='dict',\n    solver=None, timeout=None, two_pass=None, pre_passes=None,\n    output_objective=False, non_unique=False, all_solutions=False,\n    num_solutions=None, free_search=False, parallel=None, seed=None,\n    rebase_arrays=True, keep_solutions=True, return_enums=False, **kwargs\n):\n    \"\"\"Implements the workflow for solving a CSP problem encoded with MiniZinc.\n\n    Parameters\n    ----------\n    mzn : str\n        The minizinc model. This can be either the path to the ``.mzn`` file or\n        the content of the model itself.\n    *dzn_files\n        A list of paths to dzn files to attach to the minizinc execution,\n        provided as positional arguments; by default no data file is attached.\n    args : dict\n        Arguments for the template engine.\n    data : dict\n        Additional data as a dictionary of variables assignments to supply to\n        the minizinc executable. The dictionary is automatically converted to\n        dzn format by the ``pymzn.dict2dzn`` function.\n    include : str or list\n        One or more additional paths to search for included ``.mzn`` files.\n    stdlib_dir : str\n        The path to the MiniZinc standard library. Provide it only if it is\n        different from the default one.\n    globals_dir : str\n        The path to the MiniZinc globals directory. Provide it only if it is\n        different from the default one.\n    declare_enums : bool\n        Whether to declare enum types when converting inline data into dzn\n        format. If the enum types are declared elsewhere this option should be\n        False. Default is ``True``.\n    allow_multiple_assignments : bool\n        Whether to allow multiple assignments of variables. Sometimes is\n        convenient to simply let the data file override the value already\n        assigned in the minizinc file. Default is ``False``.\n    keep : bool\n        Whether to keep the generated ``.mzn``, ``.dzn``, ``.fzn`` and ``.ozn``\n        files or not. If False, the generated files are created as temporary\n        files which will be deleted right after the problem is solved. Though\n        files generated by PyMzn are not intended to be kept, this property can\n        be used for debugging purpose. Note that in case of error the files are\n        not deleted even if this parameter is ``False``. Default is ``False``.\n    output_vars : list of str\n        A list of output variables. These variables will be the ones included in\n        the output dictionary. Only available if ``ouptut_mode='dict'``.\n    output_base : str\n        Output directory for the files generated by PyMzn. The default\n        (``None``) is the temporary directory of your OS (if ``keep=False``) or\n        the current working directory (if ``keep=True``).\n    output_mode : {'dict', 'item', 'dzn', 'json', 'raw'}\n        The desired output format. The default is ``'dict'`` which returns a\n        stream of solutions decoded as python dictionaries. The ``'item'``\n        format outputs a stream of strings as returned by the ``solns2out``\n        tool, formatted according to the output statement of the MiniZinc model.\n        The ``'dzn'`` and ``'json'`` formats output a stream of strings\n        formatted in dzn of json respectively. The ``'raw'`` format, instead\n        returns the whole solution stream, without parsing.\n    solver : Solver\n        The ``Solver`` instance to use. The default solver is ``gecode``.\n    timeout : int\n        The timeout in seconds for the flattening + solving process.\n    two_pass : bool or int\n        If ``two_pass`` is True, then it is equivalent to the ``--two-pass``\n        option for the ``minizinc`` executable. If ``two_pass`` is an integer\n        ``<n>``, instead, it is equivalent to the ``-O<n>`` option for the\n        ``minizinc`` executable.\n    pre_passes : int\n        Equivalent to the ``--pre-passes`` option for the ``minizinc``\n        executable.\n    output_objective : bool\n        Equivalent to the ``--output-objective`` option for the ``minizinc``\n        executable. Adds a field ``_objective`` to all solutions.\n    non_unique : bool\n        Equivalent to the ``--non-unique`` option for the ``minizinc``\n        executable.\n    all_solutions : bool\n        Whether all the solutions must be returned. This option might not work\n        if the solver does not support it. Default is ``False``.\n    num_solutions : int\n        The upper bound on the number of solutions to be returned. This option\n        might not work if the solver does not support it. Default is ``1``.\n    free_search : bool\n        If ``True``, instruct the solver to perform free search.\n    parallel : int\n        The number of parallel threads the solver can utilize for the solving.\n    seed : int\n        The random number generator seed to pass to the solver.\n    rebase_arrays : bool\n        Whether to \"rebase\" parsed arrays (see the `Dzn files\n        <http://paolodragone.com/pymzn/reference/dzn>`__ section). Default is\n        True.\n    keep_solutions : bool\n        Whether to store the solutions in memory after solving is done. If\n        ``keep_solutions`` is ``False``, the returned solution stream can only\n        be iterated once and cannot be addressed as a list.\n    return_enums : bool\n        Wheter to return enum types along with the variable assignments in the\n        solutions. Only used if ``output_mode='dict'``. Default is ``False``.\n    **kwargs\n        Additional arguments to pass to the solver, provided as additional\n        keyword arguments to this function. Check the solver documentation for\n        the available arguments.\n\n    Returns\n    -------\n    Solutions or str\n        If ``output_mode`` is not ``'raw'``, returns a list-like object\n        containing the solutions found by the solver. The format of the solution\n        depends on the specified ``output_mode``. If ``keep_solutions=False``,\n        the returned object cannot be addressed as a list and can only be\n        iterated once. If ``output_mode='raw'``, the function returns the whole\n        solution stream as a single string.\n    \"\"\"\n\n    mzn_file, dzn_files, data_file, data, keep, _output_mode, types = \\\n        _minizinc_preliminaries(\n            mzn, *dzn_files, args=args, data=data, include=include,\n            stdlib_dir=stdlib_dir, globals_dir=globals_dir,\n            output_vars=output_vars, keep=keep, output_base=output_base,\n            output_mode=output_mode, declare_enums=declare_enums,\n            allow_multiple_assignments=allow_multiple_assignments\n        )\n\n    if not solver:\n        solver = config.get('solver', gecode)\n\n    solver_args = {**kwargs, **config.get('solver_args', {})}\n\n    proc = solve(\n        solver, mzn_file, *dzn_files, data=data, include=include,\n        stdlib_dir=stdlib_dir, globals_dir=globals_dir,\n        output_mode=_output_mode, timeout=timeout, two_pass=two_pass,\n        pre_passes=pre_passes, output_objective=output_objective,\n        non_unique=non_unique, all_solutions=all_solutions,\n        num_solutions=num_solutions, free_search=free_search, parallel=parallel,\n        seed=seed, allow_multiple_assignments=allow_multiple_assignments,\n        **solver_args\n    )\n\n    if not keep:\n        _cleanup([mzn_file, data_file])\n\n    if output_mode == 'raw':\n        return proc.stdout_data\n\n    parser = SolutionParser(\n        solver, output_mode=output_mode, rebase_arrays=rebase_arrays,\n        types=types, keep_solutions=keep_solutions, return_enums=return_enums\n    )\n    solns = parser.parse(proc)\n    return solns", "response": "Implements the workflow for solving a CSP problem encoded with MiniZinc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solve(\n    solver, mzn, *dzn_files, data=None, include=None, stdlib_dir=None,\n    globals_dir=None, allow_multiple_assignments=False, output_mode='item',\n    timeout=None, two_pass=None, pre_passes=None, output_objective=False,\n    non_unique=False, all_solutions=False, num_solutions=None,\n    free_search=False, parallel=None, seed=None, **kwargs\n):\n    \"\"\"Flatten and solve a MiniZinc program.\n\n    Parameters\n    ----------\n    solver : Solver\n        The ``Solver`` instance to use.\n    mzn : str\n        The path to the minizinc model file.\n    *dzn_files\n        A list of paths to dzn files to attach to the minizinc execution,\n        provided as positional arguments; by default no data file is attached.\n    data : list of str\n        Additional data as a list of strings containing dzn variables\n        assignments.\n    include : str or list\n        One or more additional paths to search for included ``.mzn`` files.\n    stdlib_dir : str\n        The path to the MiniZinc standard library. Provide it only if it is\n        different from the default one.\n    globals_dir : str\n        The path to the MiniZinc globals directory. Provide it only if it is\n        different from the default one.\n    allow_multiple_assignments : bool\n        Whether to allow multiple assignments of variables. Sometimes is\n        convenient to simply let the data file override the value already\n        assigned in the minizinc file. Default is ``False``.\n    output_mode : {'item', 'dzn', 'json'}\n        The desired output format. The default is ``'item'`` which outputs a\n        stream of strings as returned by the ``solns2out`` tool, formatted\n        according to the output statement of the MiniZinc model. The ``'dzn'``\n        and ``'json'`` formats output a stream of strings formatted in dzn and\n        json respectively.\n    timeout : int\n        The timeout in seconds for the flattening + solving process.\n    two_pass : bool or int\n        If ``two_pass`` is True, then it is equivalent to the ``--two-pass``\n        option for the ``minizinc`` executable. If ``two_pass`` is an integer\n        ``<n>``, instead, it is equivalent to the ``-O<n>`` option for the\n        ``minizinc`` executable.\n    pre_passes : int\n        Equivalent to the ``--pre-passes`` option for the ``minizinc``\n        executable.\n    output_objective : bool\n        Equivalent to the ``--output-objective`` option for the ``minizinc``\n        executable. Adds a field ``_objective`` to all solutions.\n    non_unique : bool\n        Equivalent to the ``--non-unique`` option for the ``minizinc``\n        executable.\n    all_solutions : bool\n        Whether all the solutions must be returned. This option might not work\n        if the solver does not support it. Default is ``False``.\n    num_solutions : int\n        The upper bound on the number of solutions to be returned. This option\n        might not work if the solver does not support it. Default is ``1``.\n    free_search : bool\n        If True, instruct the solver to perform free search.\n    parallel : int\n        The number of parallel threads the solver can utilize for the solving.\n    seed : int\n        The random number generator seed to pass to the solver.\n    **kwargs\n        Additional arguments to pass to the solver, provided as additional\n        keyword arguments to this function. Check the solver documentation for\n        the available arguments.\n\n    Returns\n    -------\n        Object wrapping the executed process.\n    \"\"\"\n\n    args = _solve_args(\n        solver, timeout=timeout, two_pass=two_pass, pre_passes=pre_passes,\n        output_objective=output_objective, non_unique=non_unique,\n        all_solutions=all_solutions, num_solutions=num_solutions,\n        free_search=free_search, parallel=parallel, seed=seed, **kwargs\n    )\n\n    args += _flattening_args(\n        mzn, *dzn_files, data=data, stdlib_dir=stdlib_dir,\n        globals_dir=globals_dir, output_mode=output_mode, include=include,\n        allow_multiple_assignments=allow_multiple_assignments\n    )\n\n    input = mzn if args[-1] == '-' else None\n\n    t0 = _time()\n\n    try:\n        proc = _run_minizinc_proc(*args, input=input)\n    except RuntimeError as err:\n        raise MiniZincError(mzn_file, args) from err\n\n    solve_time = _time() - t0\n    logger.info('Solving completed in {:>3.2f} sec'.format(solve_time))\n\n    return proc", "response": "Flatten and solve a MiniZinc program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nflatten a MiniZinc model into a FlatZinc model.", "response": "def mzn2fzn(\n    mzn, *dzn_files, args=None, data=None, include=None, stdlib_dir=None,\n    globals_dir=None, declare_enums=True, allow_multiple_assignments=False,\n    keep=False, output_vars=None, output_base=None, output_mode='item',\n    no_ozn=False\n):\n    \"\"\"Flatten a MiniZinc model into a FlatZinc one.\n\n    This function is equivalent to the command ``minizinc --compile``.\n\n    Parameters\n    ----------\n    mzn : str\n        The minizinc model. This can be either the path to the ``.mzn`` file or\n        the content of the model itself.\n    *dzn_files\n        A list of paths to dzn files to attach to the minizinc execution,\n        provided as positional arguments; by default no data file is attached.\n    args : dict\n        Arguments for the template engine.\n    data : dict\n        Additional data as a dictionary of variables assignments to supply to\n        the minizinc executable. The dictionary is automatically converted to\n        dzn format by the ``pymzn.dict2dzn`` function.\n    include : str or list\n        One or more additional paths to search for included ``.mzn`` files.\n    stdlib_dir : str\n        The path to the MiniZinc standard library. Provide it only if it is\n        different from the default one.\n    globals_dir : str\n        The path to the MiniZinc globals directory. Provide it only if it is\n        different from the default one.\n    declare_enums : bool\n        Whether to declare enum types when converting inline data into dzn\n        format. If the enum types are declared elsewhere this option should be\n        False. Default is ``True``.\n    allow_multiple_assignments : bool\n        Whether to allow multiple assignments of variables. Sometimes is\n        convenient to simply let the data file override the value already\n        assigned in the minizinc file. Default is ``False``.\n    keep : bool\n        Whether to keep the generated ``.mzn``, ``.dzn``, ``.fzn`` and ``.ozn``\n        files or not. If False, the generated files are created as temporary\n        files which will be deleted right after the problem is solved. Though\n        files generated by PyMzn are not intended to be kept, this property can\n        be used for debugging purpose. Note that in case of error the files are\n        not deleted even if this parameter is ``False``. Default is ``False``.\n    output_vars : list of str\n        A list of output variables. These variables will be the ones included in\n        the output dictionary. Only available if ``ouptut_mode='dict'``.\n    output_base : str\n        Output directory for the files generated by PyMzn. The default\n        (``None``) is the temporary directory of your OS (if ``keep=False``) or\n        the current working directory (if ``keep=True``).\n    output_mode : {'dict', 'item', 'dzn', 'json', 'raw'}\n        The desired output format. The default is ``'dict'`` which returns a\n        stream of solutions decoded as python dictionaries. The ``'item'``\n        format outputs a stream of strings as returned by the ``solns2out``\n        tool, formatted according to the output statement of the MiniZinc model.\n        The ``'dzn'`` and ``'json'`` formats output a stream of strings\n        formatted in dzn and json respectively. The ``'raw'`` format, instead\n        returns the whole solution stream, without parsing.\n    no_ozn : bool\n        If ``True``, the ozn file is not produced, ``False`` otherwise.\n\n    Returns\n    -------\n    tuple (str, str)\n        The paths to the generated fzn and ozn files. If ``no_ozn=True``, the\n        second argument is ``None``.\n    \"\"\"\n\n    mzn_file, dzn_files, data_file, data, keep, _output_mode, types = \\\n        _minizinc_preliminaries(\n            mzn, *dzn_files, args=args, data=data, include=include,\n            stdlib_dir=stdlib_dir, globals_dir=globals_dir,\n            output_vars=output_vars, keep=keep, output_base=output_base,\n            output_mode=output_mode, declare_enums=declare_enums,\n            allow_multiple_assignments=allow_multiple_assignments\n        )\n\n    args = ['--compile']\n    args += _flattening_args(\n        mzn_file, *dzn_files, data=data, stdlib_dir=stdlib_dir,\n        globals_dir=globals_dir, output_mode=output_mode, include=include,\n        no_ozn=no_ozn, output_base=output_base,\n        allow_multiple_assignments=allow_multiple_assignments\n    )\n\n    t0 = _time()\n    _run_minizinc(*args)\n    flattening_time = _time() - t0\n    logger.info('Flattening completed in {:>3.2f} sec'.format(flattening_time))\n\n    if not keep:\n        with contextlib.suppress(FileNotFoundError):\n            if data_file:\n                os.remove(data_file)\n                logger.info('Deleted file: {}'.format(data_file))\n\n    if output_base:\n        mzn_base = output_base\n    else:\n        mzn_base = os.path.splitext(mzn_file)[0]\n\n    fzn_file = '.'.join([mzn_base, 'fzn'])\n    fzn_file = fzn_file if os.path.isfile(fzn_file) else None\n    ozn_file = '.'.join([mzn_base, 'ozn'])\n    ozn_file = ozn_file if os.path.isfile(ozn_file) else None\n\n    if fzn_file:\n        logger.info('Generated file: {}'.format(fzn_file))\n    if ozn_file:\n        logger.info('Generated file: {}'.format(ozn_file))\n\n    return fzn_file, ozn_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the solution stream", "response": "def print(self, output_file=sys.stdout, log=False):\n        \"\"\"Print the solution stream\"\"\"\n\n        for soln in iter(self):\n            print(soln, file=output_file)\n            print(SOLN_SEP, file=output_file)\n\n        if self.status == 0:\n            print(SEARCH_COMPLETE, file=output_file)\n\n        if (self.status == 1 and self._n_solns == 0) or self.status >= 2:\n            print({\n                Status.INCOMPLETE : ERROR,\n                Status.UNKNOWN: UNKNOWN,\n                Status.UNSATISFIABLE: UNSATISFIABLE,\n                Status.UNBOUNDED: UNBOUNDED,\n                Status.UNSATorUNBOUNDED: UNSATorUNBOUNDED,\n                Status.ERROR: ERROR\n            }[self.status], file=output_file)\n\n            if self.stderr:\n                print(self.stderr.strip(), file=sys.stderr)\n\n        elif log:\n            print(str(self.log), file=output_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(self):\n        try:\n            import yaml\n            cfg_file = self._cfg_file()\n            cfg_dir, __ = os.path.split(cfg_file)\n            os.makedirs(cfg_dir, exist_ok=True)\n            with open(cfg_file, 'w') as f:\n                yaml.dump(self, f)\n        except ImportError as err:\n            raise RuntimeError(\n                'Cannot dump the configuration settings to file. You need to '\n                'install the necessary dependencies (pyyaml, appdirs).'\n            ) from err", "response": "Writes the changes to the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discretize(value, factor=100):\n    if not isinstance(value, Iterable):\n        return int(value * factor)\n    int_value = list(deepcopy(value))\n    for i in range(len(int_value)):\n        int_value[i] = int(int_value[i] * factor)\n    return int_value", "response": "Discretize the given value pre - multiplying by the given factor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering a template string", "response": "def from_string(source, args=None):\n    \"\"\"Renders a template string\"\"\"\n    if _has_jinja:\n        logger.info('Precompiling model with arguments: {}'.format(args))\n        return _jenv.from_string(source).render(args or {})\n    if args:\n        raise RuntimeError(_except_text)\n    return source"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_package(package_name, package_path='templates', encoding='utf-8'):\n    if not _has_jinja:\n        raise RuntimeError(_except_text)\n    _jload.add_loader(PackageLoader(package_name, package_path, encoding))", "response": "Adds the given package to the template search routine"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_path(searchpath, encoding='utf-8', followlinks=False):\n    if not _has_jinja:\n        raise RuntimeError(_except_text)\n    _jload.add_loader(FileSystemLoader(searchpath, encoding, followlinks))", "response": "Adds the given path to the template search routine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef val2dzn(val, wrap=True):\n    if _is_value(val):\n        dzn_val = _dzn_val(val)\n    elif _is_set(val):\n        dzn_val = _dzn_set(val)\n    elif _is_array_type(val):\n        dzn_val =_dzn_array_nd(val)\n    else:\n        raise TypeError(\n            'Unsupported serialization of value: {}'.format(repr(val))\n        )\n\n    if wrap:\n        wrapper = _get_wrapper()\n        dzn_val = wrapper.fill(dzn_val)\n\n    return dzn_val", "response": "Serializes a value into its dzn representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dzn statement declaring and assigning the given value.", "response": "def stmt2dzn(name, val, declare=True, assign=True, wrap=True):\n    \"\"\"Returns a dzn statement declaring and assigning the given value.\n\n    Parameters\n    ----------\n    val\n        The value to serialize.\n    declare : bool\n        Whether to include the declaration of the variable in the statement or\n        just the assignment.\n    assign : bool\n        Wheter to include the assignment of the value in the statement or just\n        the declaration.\n    wrap : bool\n        Whether to wrap the serialized value.\n\n    Returns\n    -------\n    str\n        The serialized dzn representation of the value.\n    \"\"\"\n    if not (declare or assign):\n        raise ValueError(\n            'The statement must be a declaration or an assignment.'\n        )\n\n    stmt = []\n    if declare:\n        val_type = _dzn_type(val)\n        stmt.append('{}: '.format(val_type))\n    stmt.append(name)\n    if assign:\n        val_str = val2dzn(val, wrap=wrap)\n        stmt.append(' = {}'.format(val_str))\n    stmt.append(';')\n    return ''.join(stmt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stmt2enum(enum_type, declare=True, assign=True, wrap=True):\n\n    if not (declare or assign):\n        raise ValueError(\n            'The statement must be a declaration or an assignment.'\n        )\n\n    stmt = []\n    if declare:\n        stmt.append('enum ')\n    stmt.append(enum_type.__name__)\n    if assign:\n        val_str = []\n        for v in list(enum_type):\n            val_str.append(v.name)\n        val_str = ''.join(['{', ','.join(val_str), '}'])\n\n        if wrap:\n            wrapper = _get_wrapper()\n            val_str = wrapper.fill(val_str)\n\n        stmt.append(' = {}'.format(val_str))\n    stmt.append(';')\n    return ''.join(stmt)", "response": "Returns a dzn enum declaration from an enum type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dict2dzn(\n    objs, declare=False, assign=True, declare_enums=True, wrap=True, fout=None\n):\n    \"\"\"Serializes the objects in input and produces a list of strings encoding\n    them into dzn format. Optionally, the produced dzn is written on a file.\n\n    Supported types of objects include: ``str``, ``int``, ``float``, ``set``,\n    ``list`` or ``dict``. List and dict are serialized into dzn\n    (multi-dimensional) arrays. The key-set of a dict is used as index-set of\n    dzn arrays. The index-set of a list is implicitly set to ``1 .. len(list)``.\n\n    Parameters\n    ----------\n    objs : dict\n        A dictionary containing the objects to serialize, the keys are the names\n        of the variables.\n    declare : bool\n        Whether to include the declaration of the variable in the statements or\n        just the assignment. Default is ``False``.\n    assign : bool\n        Whether to include assignment of the value in the statements or just the\n        declaration.\n    declare_enums : bool\n        Whether to declare the enums found as types of the objects to serialize.\n        Default is ``True``.\n    wrap : bool\n        Whether to wrap the serialized values.\n    fout : str\n        Path to the output file, if None no output file is written.\n\n    Returns\n    -------\n    list\n        List of strings containing the dzn-encoded objects.\n    \"\"\"\n    log = logging.getLogger(__name__)\n\n    vals = []\n    enums = set()\n    for key, val in objs.items():\n        if _is_enum(val) and declare_enums:\n            enum_type = type(val)\n            enum_name = enum_type.__name__\n            if enum_name not in enums:\n                enum_stmt = stmt2enum(\n                    enum_type, declare=declare, assign=assign, wrap=wrap\n                )\n                vals.append(enum_stmt)\n                enums.add(enum_name)\n        stmt = stmt2dzn(key, val, declare=declare, assign=assign, wrap=wrap)\n        vals.append(stmt)\n\n    if fout:\n        log.debug('Writing file: {}'.format(fout))\n        with open(fout, 'w') as f:\n            for val in vals:\n                f.write('{}\\n\\n'.format(val))\n    return vals", "response": "Serializes the objects in input and produces a list of strings encoding them into dzn format. Optionally the produced dzn is written on a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rebase_array(d, recursive=False):\n    arr = []\n    min_val, max_val = _extremes(d.keys())\n    for idx in range(min_val, max_val + 1):\n        v = d[idx]\n        if recursive and _is_dict(v):\n            v = rebase_array(v)\n        arr.append(v)\n    return arr", "response": "Transform an indexed dictionary into a multi - dimensional list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self, lock_name, timeout=900):\n        # Try Redis first\n        try:\n            try:\n                lock = self.cache.lock\n            except AttributeError:\n                try:\n                    # Possibly using old Django-Redis\n                    lock = self.cache.client.lock\n                except AttributeError:\n                    # Possibly using Werkzeug + Redis\n                    lock = self.cache._client.lock\n            have_lock = False\n            lock = lock(lock_name, timeout=timeout)\n            try:\n                have_lock = lock.acquire(blocking=True)\n                if have_lock:\n                    yield\n            finally:\n                if have_lock:\n                    lock.release()\n        except AttributeError:\n            # No lock method on the cache, so fall back to add\n            have_lock = False\n            try:\n                while not have_lock:\n                    have_lock = self.cache.add(lock_name, 'locked', timeout)\n                if have_lock:\n                    yield\n            finally:\n                if have_lock:\n                    self.cache.delete(lock_name)", "response": "A generator that yields the next available lock for the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to call self. apply_async or return an EagerResult.", "response": "def async_or_eager(self, **options):\n        \"\"\"\n        Attempt to call self.apply_async, or if that fails because of a problem\n        with the broker, run the task eagerly and return an EagerResult.\n        \"\"\"\n        args = options.pop(\"args\", None)\n        kwargs = options.pop(\"kwargs\", None)\n        possible_broker_errors = self._get_possible_broker_errors_tuple()\n        try:\n            return self.apply_async(args, kwargs, **options)\n        except possible_broker_errors:\n            return self.apply(args, kwargs, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef async_or_fail(self, **options):\n        args = options.pop(\"args\", None)\n        kwargs = options.pop(\"kwargs\", None)\n        possible_broker_errors = self._get_possible_broker_errors_tuple()\n        try:\n            return self.apply_async(args, kwargs, **options)\n        except possible_broker_errors as e:\n            return self.simulate_async_error(e)", "response": "A simple wrapper around apply_async that does not fail with an exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping async_or_eager with a convenience signiture like delay", "response": "def delay_or_eager(self, *args, **kwargs):\n        \"\"\"\n        Wrap async_or_eager with a convenience signiture like delay\n        \"\"\"\n        return self.async_or_eager(args=args, kwargs=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delay_or_run(self, *args, **kwargs):\n        warnings.warn(\n            \"delay_or_run is deprecated. Please use delay_or_eager\",\n            DeprecationWarning,\n        )\n        possible_broker_errors = self._get_possible_broker_errors_tuple()\n        try:\n            result = self.apply_async(args=args, kwargs=kwargs)\n            required_fallback = False\n        except possible_broker_errors:\n            result = self().run(*args, **kwargs)\n            required_fallback = True\n        return result, required_fallback", "response": "Attempt to call self. delay or self. run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delay_or_fail(self, *args, **kwargs):\n        return self.async_or_fail(args=args, kwargs=kwargs)", "response": "Wrap async_or_fail with a convenience signiture like delay\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simulate_async_error(self, exception):\n        task_id = gen_unique_id()\n        async_result = self.AsyncResult(task_id)\n        einfo = ExceptionInfo(sys.exc_info())\n\n        async_result.backend.mark_as_failure(\n            task_id,\n            exception,\n            traceback=einfo.traceback,\n        )\n\n        return async_result", "response": "Simulate an asynchronous exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_async(self, args, kwargs, **options):\n        self._validate_required_class_vars()\n\n        cache_key = self._get_cache_key(**kwargs)\n\n        # Check for an already-computed and cached result\n        task_id = self.cache.get(cache_key)  # Check for the cached result\n        if task_id:\n            # We've already built this result, just latch on to the task that\n            # did the work\n            logging.info(\n                'Found existing cached and completed task: %s', task_id)\n            return self.AsyncResult(task_id)\n\n        # Check for an in-progress equivalent task to avoid duplicating work\n        task_id = self.cache.get('herd:%s' % cache_key)\n        if task_id:\n            logging.info('Found existing in-progress task: %s', task_id)\n            return self.AsyncResult(task_id)\n\n        # It's not cached and it's not already running. Use an atomic lock to\n        # start the task, ensuring there isn't a race condition that could\n        # result in multiple identical tasks being fired at once.\n        with self.cache.lock('lock:%s' % cache_key):\n            task_meta = super(JobtasticTask, self).apply_async(\n                args,\n                kwargs,\n                **options\n            )\n            logging.info('Current status: %s', task_meta.status)\n            if task_meta.status in (PROGRESS, PENDING):\n                self.cache.set(\n                    'herd:%s' % cache_key,\n                    task_meta.task_id,\n                    timeout=self.herd_avoidance_timeout)\n                logging.info(\n                    'Setting herd-avoidance cache for task: %s', cache_key)\n        return task_meta", "response": "This method is called by the Task class to create a singleton queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calc_progress(self, completed_count, total_count):\n        self.logger.debug(\n            \"calc_progress(%s, %s)\",\n            completed_count,\n            total_count,\n        )\n        current_time = time.time()\n\n        time_spent = current_time - self.start_time\n        self.logger.debug(\"Progress time spent: %s\", time_spent)\n\n        if total_count == 0:\n            return 100, 1\n\n        completion_fraction = completed_count / total_count\n        if completion_fraction == 0:\n            completion_fraction = 1\n\n        total_time = 0\n        total_time = time_spent / completion_fraction\n        time_remaining = total_time - time_spent\n\n        completion_display = completion_fraction * 100\n        if completion_display == 100:\n            return 100, 1  # 1 second to finish up\n\n        return completion_display, time_remaining", "response": "Calculate the percentage of complete and remaining time based on the current number of items completed and total number of items total."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_progress(\n        self,\n        completed_count,\n        total_count,\n        update_frequency=1,\n    ):\n        \"\"\"\n        Update the task backend with both an estimated percentage complete and\n        number of seconds remaining until completion.\n\n        ``completed_count`` Number of task \"units\" that have been completed out\n        of ``total_count`` total \"units.\"\n        ``update_frequency`` Only actually store the updated progress in the\n        background at most every ``N`` ``completed_count``.\n        \"\"\"\n        if completed_count - self._last_update_count < update_frequency:\n            # We've updated the progress too recently. Don't stress out the\n            # result backend\n            return\n        # Store progress for display\n        progress_percent, time_remaining = self.calc_progress(\n            completed_count, total_count)\n        self.logger.debug(\n            \"Updating progress: %s percent, %s remaining\",\n            progress_percent,\n            time_remaining)\n        if self.request.id:\n            self._last_update_count = completed_count\n            self.update_state(None, PROGRESS, {\n                \"progress_percent\": progress_percent,\n                \"time_remaining\": time_remaining,\n            })", "response": "Update the task backend with both an estimated percentage complete and number of seconds remaining until completion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_required_class_vars(self):\n        required_members = (\n            'significant_kwargs',\n            'herd_avoidance_timeout',\n        )\n        for required_member in required_members:\n            if not hasattr(self, required_member):\n                raise Exception(\n                    \"JobtasticTask's must define a %s\" % required_member)", "response": "Ensure that this subclass has defined all of the required class - level variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when a task is completed.", "response": "def on_success(self, retval, task_id, args, kwargs):\n        \"\"\"\n        Store results in the backend even if we're always eager. This ensures\n        the `delay_or_run` calls always at least have results.\n        \"\"\"\n        if self.request.is_eager:\n            # Store the result because celery wouldn't otherwise\n            self.update_state(task_id, SUCCESS, retval)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the cache to use for thundering herd protection etc.", "response": "def _get_cache(self):\n        \"\"\"\n        Return the cache to use for thundering herd protection, etc.\n        \"\"\"\n        if not self._cache:\n            self._cache = get_cache(self.app)\n        return self._cache"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_cache_key(self, **kwargs):\n        m = md5()\n        for significant_kwarg in self.significant_kwargs:\n            key, to_str = significant_kwarg\n            try:\n                m.update(to_str(kwargs[key]))\n            except (TypeError, UnicodeEncodeError):\n                # Python 3.x strings aren't accepted by hash.update().\n                # String should be byte-encoded first.\n                m.update(to_str(kwargs[key]).encode('utf-8'))\n\n        if hasattr(self, 'cache_prefix'):\n            cache_prefix = self.cache_prefix\n        else:\n            cache_prefix = '%s.%s' % (self.__module__, self.__name__)\n        return '%s:%s' % (cache_prefix, m.hexdigest())", "response": "Returns a cache key for the current task."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a valid cache for the current application.", "response": "def get_cache(app):\n    \"\"\"\n    Attempt to find a valid cache from the Celery configuration\n\n    If the setting is a valid cache, just use it.\n    Otherwise, if Django is installed, then:\n        If the setting is a valid Django cache entry, then use that.\n        If the setting is empty use the default cache\n    Otherwise, if Werkzeug is installed, then:\n        If the setting is a valid Celery Memcache or Redis Backend, then use\n            that.\n        If the setting is empty and the default Celery Result Backend is\n            Memcache or Redis, then use that\n    Otherwise fail\n    \"\"\"\n    jobtastic_cache_setting = app.conf.get('JOBTASTIC_CACHE')\n    if isinstance(jobtastic_cache_setting, BaseCache):\n        return jobtastic_cache_setting\n\n    if 'Django' in CACHES:\n        if jobtastic_cache_setting:\n            try:\n                return WrappedCache(get_django_cache(jobtastic_cache_setting))\n            except InvalidCacheBackendError:\n                pass\n        else:\n            return WrappedCache(get_django_cache('default'))\n\n    if 'Werkzeug' in CACHES:\n        if jobtastic_cache_setting:\n            backend, url = get_backend_by_url(jobtastic_cache_setting)\n            backend = backend(app=app, url=url)\n        else:\n            backend = app.backend\n\n        if isinstance(backend, CacheBackend):\n            return WrappedCache(MemcachedCache(backend.client))\n        elif isinstance(backend, RedisBackend):\n            return WrappedCache(RedisCache(backend.client))\n\n    # Give up\n    raise RuntimeError('Cannot find a suitable cache for Jobtastic')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting specific columns from DataFrame.", "response": "def select(*args):\n  \"\"\"Select specific columns from DataFrame. \n\n  Output will be DplyFrame type. Order of columns will be the same as input into\n  select.\n\n  >>> diamonds >> select(X.color, X.carat) >> head(3)\n  Out:\n    color  carat\n  0     E   0.23\n  1     E   0.21\n  2     E   0.23\n\n  Grouping variables are implied in selection.\n  >>> df >> group_by(X.a, X.b) >> select(X.c)\n  returns a dataframe like `df[[X.a, X.b, X.c]]` with the variables appearing in\n  grouped order before the selected column(s), unless a grouped variable is\n  explicitly selected\n\n  >>> df >> group_by(X.a, X.b) >> select(X.c, X.b)\n  returns a dataframe like `df[[X.a, X.c, X.b]]`\n  \"\"\"\n  def select_columns(df, args):\n    columns = [column._name for column in args]\n    if df._grouped_on:\n      for col in df._grouped_on[::-1]:\n        if col not in columns:\n          columns.insert(0, col)\n    return columns\n  return lambda df: df[select_columns(df, args)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef arrange(*args):\n  names = [column._name for column in args]\n  def f(df):\n    sortby_df = df >> mutate(*args)\n    index = sortby_df.sort_values([str(arg) for arg in args]).index\n    return df.loc[index]\n  return f", "response": "Sort DataFrame by the input column arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename(**kwargs):\n  def rename_columns(df):\n    column_assignments = {old_name_later._name: new_name\n                          for new_name, old_name_later in kwargs.items()}\n    return df.rename(columns=column_assignments)\n  return rename_columns", "response": "Rename one or more columns leaving other columns unchanged\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transmute(*args, **kwargs):\n  mutate_dateframe_fn = mutate(*args, **dict(kwargs))\n  column_names_args = [str(arg) for arg in args]\n  column_names_kwargs = [name for name, _\n                         in _dict_to_possibly_ordered_tuples(kwargs)]\n  column_names = column_names_args + column_names_kwargs\n  return lambda df: mutate_dateframe_fn(df)[column_names]", "response": "Same as select but allows mutation in column definitions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_join_cols(by_entry):\n  left_cols = []\n  right_cols = []\n  for col in by_entry:\n    if isinstance(col, str):\n      left_cols.append(col)\n      right_cols.append(col)\n    else:\n      left_cols.append(col[0])\n      right_cols.append(col[1])\n  return left_cols, right_cols", "response": "helper function used for joins\n returns left and right join list for join function\n"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mutating_join(*args, **kwargs):\n  # candidate for improvement\n  left = args[0]\n  right = args[1]\n  if 'by' in kwargs:\n    left_cols, right_cols = get_join_cols(kwargs['by'])\n  else:\n    left_cols, right_cols = None, None\n  if 'suffixes' in kwargs:\n    dsuffixes = kwargs['suffixes']\n  else:\n    dsuffixes = ('_x', '_y')\n  if left._grouped_on:\n    outDf = (DplyFrame((left >> ungroup())\n                       .merge(right, how=kwargs['how'], left_on=left_cols, \n                              right_on=right_cols, suffixes=dsuffixes))\n             .regroup(left._grouped_on))\n  else:\n    outDf = DplyFrame(left.merge(right, how=kwargs['how'], left_on=left_cols, \n                                 right_on=right_cols, suffixes=dsuffixes))\n  return outDf", "response": "generic function for mutating dplyr - style joins\n  generic function for mutating dplyr - style joins\n ethernet"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntemplates chart support function", "response": "def _chart_support(self, name, data, caller, **kwargs):\n        \"template chart support function\"\n        id = 'chart-%s' % next(self.id)\n        name = self._chart_class_name(name)\n        options = dict(self.environment.options)\n        options.update(name=name, id=id)\n\n        # jinja2 prepends 'l_' or 'l_{{ n }}'(ver>=2.9) to keys\n        if jinja2.__version__ >= '2.9':\n            kwargs = dict((k[4:], v) for (k, v) in kwargs.items())\n        else:\n            kwargs = dict((k[2:], v) for (k, v) in kwargs.items())\n\n        if self._library is None:\n            self._library = self.load_library()\n        id = kwargs.get('id', '')\n        library = self._library.get(id, {})\n\n        # apply options from a tag\n        library.update(kwargs.get('library', {}))\n        # apply options from chartkick.json\n        kwargs.update(library=library)\n\n        options.update(kwargs)\n        return CHART_HTML.format(data=data, options=json.dumps(kwargs),\n                                 **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef js():\n    \"returns home directory of js\"\n    return os.path.join(os.path.dirname(os.path.abspath(__file__)), 'js')", "response": "returns home directory of js"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses chart tag options", "response": "def parse_options(source):\n    \"\"\"parses chart tag options\"\"\"\n    options = {}\n    tokens = [t.strip() for t in source.split('=')]\n\n    name = tokens[0]\n    for token in tokens[1:-1]:\n        value, next_name = token.rsplit(' ', 1)\n        options[name.strip()] = value\n        name = next_name\n    options[name.strip()] = tokens[-1].strip()\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self):\n        return RigidTransform(np.copy(self.rotation), np.copy(self.translation), self.from_frame, self.to_frame)", "response": "Returns a deep copy of the RigidTransform."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the given rotation matrix is valid.", "response": "def _check_valid_rotation(self, rotation):\n        \"\"\"Checks that the given rotation matrix is valid.\n        \"\"\"\n        if not isinstance(rotation, np.ndarray) or not np.issubdtype(rotation.dtype, np.number):\n            raise ValueError('Rotation must be specified as numeric numpy array')\n\n        if len(rotation.shape) != 2 or rotation.shape[0] != 3 or rotation.shape[1] != 3:\n            raise ValueError('Rotation must be specified as a 3x3 ndarray')\n\n        if np.abs(np.linalg.det(rotation) - 1.0) > 1e-3:\n            raise ValueError('Illegal rotation. Must have determinant == 1.0')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_valid_translation(self, translation):\n        if not isinstance(translation, np.ndarray) or not np.issubdtype(translation.dtype, np.number):\n            raise ValueError('Translation must be specified as numeric numpy array')\n\n        t = translation.squeeze()\n        if len(t.shape) != 1 or t.shape[0] != 3:\n            raise ValueError('Translation must be specified as a 3-vector, 3x1 ndarray, or 1x3 ndarray')", "response": "Checks that the translation vector is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef euler_angles(self):\n        q_wxyz = self.quaternion\n        q_xyzw = np.roll(q_wxyz, -1)\n        return transformations.euler_from_quaternion(q_xyzw)", "response": "The three euler angles for the rotation of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quaternion(self):\n        q_xyzw = transformations.quaternion_from_matrix(self.matrix)\n        q_wxyz = np.roll(q_xyzw, 1)\n        return q_wxyz", "response": "A numpy. ndarray of float of float representing the quaternion vector in wxyz layout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dual_quaternion(self):\n        qr = self.quaternion\n        qd = np.append([0], self.translation / 2.)\n        return DualQuaternion(qr, qd)", "response": "Returns the dual quaternion corresponding to this\n        transform."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef axis_angle(self):\n        qw, qx, qy, qz = self.quaternion\n        theta = 2 * np.arccos(qw)\n        omega = np.array([1,0,0])\n        if theta > 0:\n            rx = qx / np.sqrt(1.0 - qw**2)\n            ry = qy / np.sqrt(1.0 - qw**2)\n            rz = qz / np.sqrt(1.0 - qw**2)\n            omega = np.array([rx, ry, rz])\n        return theta * omega", "response": "Returns the axis - angle representation of the rotation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the euler angle of the resource", "response": "def euler(self):\n        \"\"\"TODO DEPRECATE THIS?\"\"\"\n        e_xyz = transformations.euler_from_matrix(self.rotation, 'sxyz')\n        return np.array([180.0 / np.pi * a for a in e_xyz])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef matrix(self):\n        return np.r_[np.c_[self._rotation, self._translation], [[0,0,0,1]]]", "response": "Returns the canonical 4x4 matrix representation of this transform."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the rigid transform as a geometry_msg. Pose.", "response": "def pose_msg(self):\n        \"\"\":obj:`geometry_msgs.msg.Pose` The rigid transform as a geometry_msg pose.\n        \"\"\"\n        pose = msg.Pose()\n        pose.orientation.w = float(self.quaternion[0])\n        pose.orientation.x = float(self.quaternion[1])\n        pose.orientation.y = float(self.quaternion[2])\n        pose.orientation.z = float(self.quaternion[3])\n        pose.position.x = float(self.translation[0])\n        pose.position.y = float(self.translation[1])\n        pose.position.z = float(self.translation[2])\n        return pose"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninterpolate this rigid transform with another rigid transform.", "response": "def interpolate_with(self, other_tf, t):\n        \"\"\"Interpolate with another rigid transformation.\n\n        Parameters\n        ----------\n        other_tf : :obj:`RigidTransform`\n            The transform to interpolate with.\n\n        t : float\n            The interpolation step in [0,1], where 0 favors this RigidTransform.\n\n        Returns\n        -------\n        :obj:`RigidTransform`\n            The interpolated RigidTransform.\n\n        Raises\n        ------\n        ValueError\n            If t isn't in [0,1].\n        \"\"\"\n        if t < 0 or t > 1:\n            raise ValueError('Must interpolate between 0 and 1')\n\n        interp_translation = (1.0 - t) * self.translation + t * other_tf.translation\n        interp_rotation = transformations.quaternion_slerp(self.quaternion, other_tf.quaternion, t)\n        interp_tf = RigidTransform(rotation=interp_rotation, translation=interp_translation,\n                                  from_frame = self.from_frame, to_frame = self.to_frame)\n        return interp_tf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a trajectory of poses linearly interpolated from this tf to target tf.", "response": "def linear_trajectory_to(self, target_tf, traj_len):\n        \"\"\"Creates a trajectory of poses linearly interpolated from this tf to a target tf.\n\n        Parameters\n        ----------\n        target_tf : :obj:`RigidTransform`\n            The RigidTransform to interpolate to.\n        traj_len : int\n            The number of RigidTransforms in the returned trajectory.\n\n        Returns\n        -------\n        :obj:`list` of :obj:`RigidTransform`\n            A list of interpolated transforms from this transform to the target.\n        \"\"\"\n        if traj_len < 0:\n            raise ValueError('Traj len must at least 0')\n        delta_t = 1.0 / (traj_len + 1)\n        t = 0.0\n        traj = []\n        while t < 1.0:\n            traj.append(self.interpolate_with(target_tf, t))\n            t += delta_t\n        traj.append(target_tf)\n        return traj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying the rigid transformation to a set of 3D points.", "response": "def apply(self, points):\n        \"\"\"Applies the rigid transformation to a set of 3D objects.\n\n        Parameters\n        ----------\n        points : :obj:`BagOfPoints`\n            A set of objects to transform. Could be any subclass of BagOfPoints.\n\n        Returns\n        -------\n        :obj:`BagOfPoints`\n            A transformed set of objects of the same type as the input.\n\n        Raises\n        ------\n        ValueError\n            If the input is not a Bag of 3D points or if the points are not in\n            this transform's from_frame.\n        \"\"\"\n        if not isinstance(points, BagOfPoints):\n            raise ValueError('Rigid transformations can only be applied to bags of points')\n        if points.dim != 3:\n            raise ValueError('Rigid transformations can only be applied to 3-dimensional points')\n        if points.frame != self._from_frame:\n            raise ValueError('Cannot transform points in frame %s with rigid transformation from frame %s to frame %s' %(points.frame, self._from_frame, self._to_frame))\n\n        if isinstance(points, BagOfVectors):\n            # rotation only\n            x = points.data\n            x_tf = self.rotation.dot(x)\n        else:\n            # extract numpy data, homogenize, and transform\n            x = points.data\n            if len(x.shape) == 1:\n                x = x[:,np.newaxis]\n            x_homog = np.r_[x, np.ones([1, points.num_points])]\n            x_homog_tf = self.matrix.dot(x_homog)\n            x_tf = x_homog_tf[0:3,:]\n\n        # output in BagOfPoints format\n        if isinstance(points, PointCloud):\n            return PointCloud(x_tf, frame=self._to_frame)\n        elif isinstance(points, Point):\n            return Point(x_tf, frame=self._to_frame)\n        elif isinstance(points, Direction):\n            return Direction(x_tf, frame=self._to_frame)\n        elif isinstance(points, NormalCloud):\n            return NormalCloud(x_tf, frame=self._to_frame)\n        raise ValueError('Type %s not yet supported' %(type(points)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dot(self, other_tf):\n        if other_tf.to_frame != self.from_frame:\n            raise ValueError('To frame of right hand side ({0}) must match from frame of left hand side ({1})'.format(other_tf.to_frame, self.from_frame))\n\n        pose_tf = self.matrix.dot(other_tf.matrix)\n        rotation, translation = RigidTransform.rotation_and_translation_from_matrix(pose_tf)\n\n        if isinstance(other_tf, SimilarityTransform):\n            return SimilarityTransform(self.rotation, self.translation, scale=1.0,\n                                       from_frame=self.from_frame,\n                                       to_frame=self.to_frame) * other_tf\n        return RigidTransform(rotation, translation,\n                              from_frame=other_tf.from_frame,\n                              to_frame=self.to_frame)", "response": "Compose this rigid transform with another rigid transform."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake the inverse of the rigid transform.", "response": "def inverse(self):\n        \"\"\"Take the inverse of the rigid transform.\n\n        Returns\n        -------\n        :obj:`RigidTransform`\n            The inverse of this RigidTransform.\n        \"\"\"\n        inv_rotation = self.rotation.T\n        inv_translation = np.dot(-self.rotation.T, self.translation)\n        return RigidTransform(inv_rotation, inv_translation,\n                              from_frame=self._to_frame,\n                              to_frame=self._from_frame)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, filename):\n        file_root, file_ext = os.path.splitext(filename)\n        if file_ext.lower() != TF_EXTENSION:\n            raise ValueError('Extension %s not supported for RigidTransform. Must be stored with extension %s' %(file_ext, TF_EXTENSION))\n\n        f = open(filename, 'w')\n        f.write('%s\\n' %(self._from_frame))\n        f.write('%s\\n' %(self._to_frame))\n        f.write('%f %f %f\\n' %(self._translation[0], self._translation[1], self._translation[2]))\n        f.write('%f %f %f\\n' %(self._rotation[0, 0], self._rotation[0, 1], self._rotation[0, 2]))\n        f.write('%f %f %f\\n' %(self._rotation[1, 0], self._rotation[1, 1], self._rotation[1, 2]))\n        f.write('%f %f %f\\n' %(self._rotation[2, 0], self._rotation[2, 1], self._rotation[2, 2]))\n        f.close()", "response": "Save the RigidTransform to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_frames(self, from_frame, to_frame='world'):\n        return RigidTransform(self.rotation, self.translation, from_frame, to_frame)", "response": "Return a shallow copy of this rigid transform with just the frames\n            changed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef publish_to_ros(self, mode='transform', service_name='rigid_transforms/rigid_transform_publisher', namespace=None):\n        if namespace == None:\n            service_name = rospy.get_namespace() + service_name\n        else:\n            service_name = namespace + service_name\n        \n        rospy.wait_for_service(service_name, timeout = 10)\n        publisher = rospy.ServiceProxy(service_name, RigidTransformPublisher)\n        \n        trans = self.translation\n        rot = self.quaternion\n        \n        publisher(trans[0], trans[1], trans[2], rot[0], rot[1], rot[2], rot[3], self.from_frame, self.to_frame, mode)", "response": "Publishes a RigidTransform to the ROS."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_from_ros(self, service_name='rigid_transforms/rigid_transform_publisher', namespace=None):\n        if namespace == None:\n            service_name = rospy.get_namespace() + service_name\n        else:\n            service_name = namespace + service_name\n            \n        rospy.wait_for_service(service_name, timeout = 10)\n        publisher = rospy.ServiceProxy(service_name, RigidTransformPublisher)\n        \n        publisher(0, 0, 0, 0, 0, 0, 0, self.from_frame, self.to_frame, 'delete')", "response": "Removes the transform from the ROS publisher."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a ROS quaternion vector to an autolab_core quaternion vector.", "response": "def ros_q_to_core_q(q_ros):\n        \"\"\"Converts a ROS quaternion vector to an autolab_core quaternion vector.\"\"\"\n        q_core = np.array([q_ros[3], q_ros[0], q_ros[1], q_ros[2]])\n        return q_core"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef core_q_to_ros_q(q_core):\n        q_ros = np.array([q_core[1], q_core[2], q_core[3], q_core[0]])\n        return q_ros", "response": "Converts a ROS quaternion vector to an autolab_core quaternion vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a RigidTransform from a ROS pose message.", "response": "def from_ros_pose_msg(pose_msg,\n                          from_frame='unassigned',\n                          to_frame='world'):\n        \"\"\"Creates a RigidTransform from a ROS pose msg. \n        \n        Parameters\n        ----------\n        pose_msg : :obj:`geometry_msgs.msg.Pose`\n            ROS pose message\n        \"\"\"\n        quaternion = np.array([pose_msg.orientation.w,\n                               pose_msg.orientation.x,\n                               pose_msg.orientation.y,\n                               pose_msg.orientation.z])\n        position = np.array([pose_msg.position.x,\n                             pose_msg.position.y,\n                             pose_msg.position.z])\n        pose = RigidTransform(rotation=quaternion,\n                              translation=position,\n                              from_frame=from_frame,\n                              to_frame=to_frame)\n        return pose"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a rigid transform from a ROS frame.", "response": "def rigid_transform_from_ros(from_frame, to_frame, service_name='rigid_transforms/rigid_transform_listener', namespace=None):\n        \"\"\"Gets transform from ROS as a rigid transform\n        \n        Requires ROS rigid_transform_publisher service to be running. Assuming autolab_core is installed as a catkin package,\n        this can be done with: roslaunch autolab_core rigid_transforms.launch\n        \n        Parameters\n        ----------\n        from_frame : :obj:`str`\n        to_frame : :obj:`str`\n        service_name : string, optional\n            RigidTransformListener service to interface with. If the RigidTransformListener services are started through\n            rigid_transforms.launch it will be called rigid_transform_listener\n        namespace : string, optional\n            Namespace to prepend to transform_listener_service. If None, current namespace is prepended.\n        \n        Raises\n        ------\n        rospy.ServiceException\n            If service call to rigid_transform_listener fails\n        \"\"\"\n        if namespace == None:\n            service_name = rospy.get_namespace() + service_name\n        else:\n            service_name = namespace + service_name\n        \n        rospy.wait_for_service(service_name, timeout = 10)\n        listener = rospy.ServiceProxy(service_name, RigidTransformListener)\n        \n        ret = listener(from_frame, to_frame)\n        \n        quat = np.asarray([ret.w_rot, ret.x_rot, ret.y_rot, ret.z_rot])\n        trans = np.asarray([ret.x_trans, ret.y_trans, ret.z_trans])\n        \n        rot = RigidTransform.rotation_from_quaternion(quat)\n        \n        return RigidTransform(rotation=rot, translation=trans, from_frame=from_frame, to_frame=to_frame)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert quaternion array to rotation matrix.", "response": "def rotation_from_quaternion(q_wxyz):\n        \"\"\"Convert quaternion array to rotation matrix.\n\n        Parameters\n        ----------\n        q_wxyz : :obj:`numpy.ndarray` of float\n            A quaternion in wxyz order.\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float\n            A 3x3 rotation matrix made from the quaternion.\n        \"\"\"\n        q_xyzw = np.array([q_wxyz[1], q_wxyz[2], q_wxyz[3], q_wxyz[0]])\n        R = transformations.quaternion_matrix(q_xyzw)[:3,:3]\n        return R"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef quaternion_from_axis_angle(v):\n        theta = np.linalg.norm(v)\n        if theta > 0:\n            v = v / np.linalg.norm(v)\n        ax, ay, az = v    \n        qx = ax * np.sin(0.5 * theta)\n        qy = ay * np.sin(0.5 * theta)\n        qz = az * np.sin(0.5 * theta)        \n        qw = np.cos(0.5 * theta)\n        q = np.array([qw, qx, qy, qz])\n        return q", "response": "Convert axis - angle representation to a quaternion vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform_from_dual_quaternion(dq, from_frame='unassigned', to_frame='world'):\n        quaternion = dq.qr\n        translation = 2 * dq.qd[1:]\n        return RigidTransform(rotation=quaternion, translation=translation, from_frame=from_frame, to_frame=to_frame)", "response": "Create a RigidTransform from a DualQuaternion."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rotation_from_axis_and_origin(axis, origin, angle, to_frame='world'):\n        axis_hat = np.array([[0, -axis[2], axis[1]],\n                             [axis[2], 0, -axis[0]],\n                             [-axis[1], axis[0], 0]])\n        # Rodrigues Formula\n        R = RigidTransform(\n            np.eye(3) + np.sin(angle) * axis_hat + (1 - np.cos(angle)) * axis_hat.dot(axis_hat),\n            from_frame=to_frame,\n            to_frame=to_frame\n        )\n\n        return RigidTransform(translation=origin, from_frame=to_frame, to_frame=to_frame) \\\n            .dot(R) \\\n            .dot(RigidTransform(translation=-origin, from_frame=to_frame, to_frame=to_frame))", "response": "Returns a rotation matrix around some arbitrary axis about the point origin and the angle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef x_axis_rotation(theta):\n        R = np.array([[1, 0, 0,],\n                      [0, np.cos(theta), -np.sin(theta)],\n                      [0, np.sin(theta), np.cos(theta)]])\n        return R", "response": "Generates a 3x3 rotation matrix for a rotation of angletheta about the x axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a 3x3 rotation matrix for a rotation of angletheta about the y axis.", "response": "def y_axis_rotation(theta):\n        \"\"\"Generates a 3x3 rotation matrix for a rotation of angle\n        theta about the y axis.\n\n        Parameters\n        ----------\n        theta : float\n            amount to rotate, in radians\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float\n            A random 3x3 rotation matrix.\n        \"\"\"\n        R = np.array([[np.cos(theta), 0, np.sin(theta)],\n                      [0, 1, 0],\n                      [-np.sin(theta), 0, np.cos(theta)]])\n        return R"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef z_axis_rotation(theta):\n        R = np.array([[np.cos(theta), -np.sin(theta), 0],\n                      [np.sin(theta), np.cos(theta), 0],\n                      [0, 0, 1]])\n        return R", "response": "Generates a 3x3 rotation matrix for a rotation of angletheta about the z axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random 3x3 rotation matrix with SVD.", "response": "def random_rotation():\n        \"\"\"Generates a random 3x3 rotation matrix with SVD.\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float\n            A random 3x3 rotation matrix.\n        \"\"\"\n        rand_seed = np.random.rand(3, 3)\n        U, S, V = np.linalg.svd(rand_seed)\n        return U"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotation_from_axes(x_axis, y_axis, z_axis):\n        return np.hstack((x_axis[:,np.newaxis], y_axis[:,np.newaxis], z_axis[:,np.newaxis]))", "response": "Convert specification of axis in source frame to a rotation matrix from source frame to target frame."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sph_coords_to_pose(theta, psi):\n        # rotate about the z and y axes individually\n        rot_z = RigidTransform.z_axis_rotation(theta)\n        rot_y = RigidTransform.y_axis_rotation(psi)\n        R = rot_y.dot(rot_z)\n        return RigidTransform(rotation=R)", "response": "Convert spherical coordinates to a pose."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate(T0, T1, t):\n        if T0.to_frame != T1.to_frame:\n            raise ValueError('Cannot interpolate between 2 transforms with different to frames! Got T1 {0} and T2 {1}'.format(T0.to_frame, T1.to_frame))\n        dq0 = T0.dual_quaternion\n        dq1 = T1.dual_quaternion\n\n        dqt = DualQuaternion.interpolate(dq0, dq1, t)\n        from_frame = \"{0}_{1}_{2}\".format(T0.from_frame, T1.from_frame, t)\n        return RigidTransform.transform_from_dual_quaternion(dqt, from_frame, T0.to_frame)", "response": "Return an interpolation of two RigidTransforms."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(filename):\n        file_root, file_ext = os.path.splitext(filename)\n        if file_ext.lower() != TF_EXTENSION:\n            raise ValueError('Extension %s not supported for RigidTransform. Can only load extension %s' %(file_ext, TF_EXTENSION))\n\n        f = open(filename, 'r')\n        lines = list(f)\n        from_frame = lines[0][:-1]\n        to_frame = lines[1][:-1]\n\n        t = np.zeros(3)\n        t_tokens = lines[2][:-1].split()\n        t[0] = float(t_tokens[0])\n        t[1] = float(t_tokens[1])\n        t[2] = float(t_tokens[2])\n\n        R = np.zeros([3,3])\n        r_tokens = lines[3][:-1].split()\n        R[0, 0] = float(r_tokens[0])\n        R[0, 1] = float(r_tokens[1])\n        R[0, 2] = float(r_tokens[2])\n\n        r_tokens = lines[4][:-1].split()\n        R[1, 0] = float(r_tokens[0])\n        R[1, 1] = float(r_tokens[1])\n        R[1, 2] = float(r_tokens[2])\n\n        r_tokens = lines[5][:-1].split()\n        R[2, 0] = float(r_tokens[0])\n        R[2, 1] = float(r_tokens[1])\n        R[2, 2] = float(r_tokens[2])\n        f.close()\n        return RigidTransform(rotation=R, translation=t,\n                              from_frame=from_frame,\n                              to_frame=to_frame)", "response": "Loads a RigidTransform from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomposes this simliarity transform with another.", "response": "def dot(self, other_tf):\n        \"\"\"Compose this simliarity transform with another.\n\n        This transform is on the left-hand side of the composition.\n\n        Parameters\n        ----------\n        other_tf : :obj:`SimilarityTransform`\n            The other SimilarityTransform to compose with this one.\n\n        Returns\n        -------\n        :obj:`SimilarityTransform`\n            A SimilarityTransform that represents the composition.\n\n        Raises\n        ------\n        ValueError\n            If the to_frame of other_tf is not identical to this transform's\n            from_frame.\n        \"\"\"\n        if other_tf.to_frame != self.from_frame:\n            raise ValueError('To frame of right hand side ({0}) must match from frame of left hand side ({1})'.format(other_tf.to_frame, self.from_frame))\n        if not isinstance(other_tf, RigidTransform):\n            raise ValueError('Can only compose with other RigidTransform classes')\n\n        other_scale = 1.0\n        if isinstance(other_tf, SimilarityTransform):\n            other_scale = other_tf.scale\n\n        rotation = self.rotation.dot(other_tf.rotation)\n        translation = self.translation + self.scale * self.rotation.dot(other_tf.translation)\n        scale = self.scale * other_scale\n        return SimilarityTransform(rotation, translation, scale,\n                                   from_frame=other_tf.from_frame,\n                                   to_frame=self.to_frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes the inverse of the similarity transform. Returns ------- SimilarityTransform The inverse of this SimilarityTransform.", "response": "def inverse(self):\n        \"\"\"Take the inverse of the similarity transform.\n\n        Returns\n        -------\n        :obj:`SimilarityTransform`\n            The inverse of this SimilarityTransform.\n        \"\"\"\n        inv_rot = np.linalg.inv(self.rotation)\n        inv_scale = 1.0 / self.scale\n        inv_trans = -inv_scale * inv_rot.dot(self.translation)\n        return SimilarityTransform(inv_rot, inv_trans, inv_scale,\n                                   from_frame=self._to_frame,\n                                   to_frame=self._from_frame)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the data array to the preferred dim x #points structure.", "response": "def _preprocess_data(self, data):\n        \"\"\"Converts the data array to the preferred dim x #points structure.\n\n        Parameters\n        ----------\n        data : :obj:`numpy.ndarray` of float\n            The data to process.\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float\n            The same data array, but reshapes lists to be dim x 1.\n        \"\"\"\n        if len(data.shape) == 1: \n            data = data[:,np.newaxis]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, filename):\n        file_root, file_ext = os.path.splitext(filename)\n        if file_ext == '.npy':\n            np.save(filename, self._data)\n        elif file_ext == '.npz':\n            np.savez_compressed(filename, self._data)\n        else:\n            raise ValueError('Extension %s not supported for point saves.' %(file_ext))", "response": "Saves the current state of the object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads data from a file.", "response": "def load_data(filename):\n        \"\"\"Loads data from a file.\n\n        Parameters\n        ----------\n        filename : :obj:`str`\n            The file to load the collection from.\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float\n            The data read from the file.\n\n        Raises\n        ------\n        ValueError\n            If the file extension is not .npy or .npz.\n        \"\"\"\n        file_root, file_ext = os.path.splitext(filename)\n        data = None\n        if file_ext == '.npy':\n            data = np.load(filename)\n        elif file_ext == '.npz':\n            data = np.load(filename)['arr_0']\n        else:\n            raise ValueError('Extension %s not supported for point reads' %(file_ext))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Point from data saved in a file.", "response": "def open(filename, frame='unspecified'):\n        \"\"\"Create a Point from data saved in a file.\n\n        Parameters\n        ----------\n        filename : :obj:`str`\n            The file to load data from.\n\n        frame : :obj:`str`\n            The frame to apply to the created point.\n\n        Returns\n        -------\n        :obj:`Point`\n            A point created from the data in the file.\n        \"\"\"\n        data = BagOfPoints.load_data(filename)\n        return Point(data, frame)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the incoming data is a Nx1 array.", "response": "def _check_valid_data(self, data):\n        \"\"\"Checks that the incoming data is a Nx1 ndarray.\n\n        Parameters\n        ----------\n        data : :obj:`numpy.ndarray`\n            The data to verify.\n\n        Raises\n        ------\n        ValueError\n            If the data is not of the correct shape or if the vector is not\n            normed.\n        \"\"\"\n        if len(data.shape) == 2 and data.shape[1] != 1:\n            raise ValueError('Can only initialize Direction from a single Nx1 array') \n        if np.abs(np.linalg.norm(data) - 1.0) > 1e-4:\n            raise ValueError('Direction data must have norm=1.0')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an orthogonal basis to this direction.", "response": "def orthogonal_basis(self):\n        \"\"\"Return an orthogonal basis to this direction.\n\n        Note\n        ----\n            Only implemented in 3D.\n\n        Returns\n        -------\n        :obj:`tuple` of :obj:`Direction`\n            The pair of normalized Direction vectors that form a basis of\n            this direction's orthogonal complement.\n\n        Raises\n        ------\n        NotImplementedError\n            If the vector is not 3D\n        \"\"\"\n        if self.dim == 3:\n            x_arr = np.array([-self.data[1], self.data[0], 0])\n            if np.linalg.norm(x_arr) == 0:\n                x_arr = np.array([self.data[2], 0, 0])\n            x_arr = x_arr / np.linalg.norm(x_arr)\n            y_arr = np.cross(self.data, x_arr)\n            return Direction(x_arr, frame=self.frame), Direction(y_arr, frame=self.frame)\n        raise NotImplementedError('Orthogonal basis only supported for 3 dimensions')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Direction from data saved in a file.", "response": "def open(filename, frame='unspecified'):\n        \"\"\"Create a Direction from data saved in a file.\n\n        Parameters\n        ----------\n        filename : :obj:`str`\n            The file to load data from.\n\n        frame : :obj:`str`\n            The frame to apply to the created Direction.\n\n        Returns\n        -------\n        :obj:`Direction`\n            A Direction created from the data in the file.\n        \"\"\"\n        data = BagOfPoints.load_data(filename)\n        return Direction(data, frame)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a point cloud into two along this plane.", "response": "def split_points(self, point_cloud):\n        \"\"\"Split a point cloud into two along this plane.\n\n        Parameters\n        ----------\n        point_cloud : :obj:`PointCloud`\n            The PointCloud to divide in two.\n\n        Returns\n        -------\n        :obj:`tuple` of :obj:`PointCloud`\n            Two new PointCloud objects. The first contains points above the\n            plane, and the second contains points below the plane.\n\n        Raises\n        ------\n        ValueError\n            If the input is not a PointCloud.\n        \"\"\"\n        if not isinstance(point_cloud, PointCloud):\n            raise ValueError('Can only split point clouds')\n        # compute indices above and below\n        above_plane = point_cloud._data - np.tile(self._x0.data, [1, point_cloud.num_points]).T.dot(self._n) > 0\n        above_plane = point_cloud.z_coords > 0 & above_plane\n        below_plane = point_cloud._data - np.tile(self._x0.data, [1, point_cloud.num_points]).T.dot(self._n) <= 0\n        below_plane = point_cloud.z_coords > 0 & below_plane\n\n        # split data\n        above_data = point_cloud.data[:, above_plane]\n        below_data = point_cloud.data[:, below_plane]\n        return PointCloud(above_data, point_cloud.frame), PointCloud(below_data, point_cloud.frame)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the average point in the point cloud.", "response": "def mean(self):\n        \"\"\"Returns the average point in the cloud.\n\n        Returns\n        -------\n        :obj:`Point`\n            The mean point in the PointCloud.\n        \"\"\"\n        mean_point_data = np.mean(self._data, axis=1)\n        return Point(mean_point_data, self._frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a subsampled version of the PointCloud with N samples.", "response": "def subsample(self, rate, random=False):\n        \"\"\"Returns a subsampled version of the PointCloud.\n\n        Parameters\n        ----------\n        rate : int\n            Only every rate-th element of the PointCloud is returned.\n\n        Returns\n        -------\n        :obj:`PointCloud`\n            A subsampled point cloud with N / rate total samples.\n\n        Raises\n        ------\n        ValueError\n            If rate is not a positive integer.\n        \"\"\"\n        if type(rate) != int and rate < 1:\n            raise ValueError('Can only subsample with strictly positive integer rate')\n        indices = np.arange(self.num_points)\n        if random:\n            np.random.shuffle(indices)\n        subsample_inds = indices[::rate]\n        subsampled_data = self._data[:,subsample_inds]\n        return PointCloud(subsampled_data, self._frame), subsample_inds"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a PointCloud containing only points within the given Box.", "response": "def box_mask(self, box):\n        \"\"\"Return a PointCloud containing only points within the given Box.\n\n        Parameters\n        ----------\n        box : :obj:`Box`\n            A box whose boundaries are used to filter points.\n\n        Returns\n        -------\n        :obj:`PointCloud`\n            A filtered PointCloud whose points are all in the given box.\n        :obj:`numpy.ndarray`\n            Array of indices of the segmented points in the original cloud\n\n        Raises\n        ------\n        ValueError\n            If the input is not a box in the same frame as the PointCloud.\n        \"\"\"\n        if not isinstance(box, Box):\n            raise ValueError('Must provide Box object')\n        if box.frame != self.frame:\n            raise ValueError('Box must be in same frame as PointCloud')\n        all_points = self.data.T\n        cond1 = np.all(box.min_pt <= all_points, axis=1)\n        cond2 = np.all(all_points <= box.max_pt, axis=1)\n        valid_point_indices = np.where(np.logical_and(cond1, cond2))[0]\n        valid_points = all_points[valid_point_indices]\n\n        return PointCloud(valid_points.T, self.frame), valid_point_indices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit a plane to the point cloud using least squares.", "response": "def best_fit_plane(self):\n        \"\"\"Fits a plane to the point cloud using least squares.\n\n        Returns\n        -------\n        :obj:`tuple` of :obj:`numpy.ndarray` of float\n            A normal vector to and point in the fitted plane.\n        \"\"\"\n        X = np.c_[self.x_coords, self.y_coords, np.ones(self.num_points)]\n        y = self.z_coords\n        A = X.T.dot(X)\n        b = X.T.dot(y)\n        w = np.linalg.inv(A).dot(b)\n        n = np.array([w[0], w[1], -1])\n        n = n / np.linalg.norm(n)\n        n = Direction(n, self._frame)\n        x0 = self.mean()\n        return n, x0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving points with a zero in the z - axis. Note that this is a no - op.", "response": "def remove_zero_points(self):\n        \"\"\"Removes points with a zero in the z-axis.\n\n        Note\n        ----\n        This returns nothing and updates the PointCloud in-place.\n        \"\"\"\n        points_of_interest = np.where(self.z_coords != 0.0)[0]\n        self._data = self.data[:, points_of_interest]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving infinite points from the PointCloud.", "response": "def remove_infinite_points(self):\n        \"\"\"Removes infinite points.\n\n        Note\n        ----\n        This returns nothing and updates the PointCloud in-place.\n        \"\"\"\n        points_of_interest = np.where(np.all(np.isfinite(self.data), axis=0))[0]\n        self._data = self.data[:, points_of_interest]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(filename, frame='unspecified'):\n        data = BagOfPoints.load_data(filename)\n        return PointCloud(data, frame)", "response": "Create a PointCloud from data saved in a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subsample(self, rate):\n        if type(rate) != int and rate < 1:\n            raise ValueError('Can only subsample with strictly positive integer rate')\n        subsample_inds = np.arange(self.num_points)[::rate]\n        subsampled_data = self._data[:,subsample_inds]\n        return NormalCloud(subsampled_data, self._frame)", "response": "Returns a subsampled version of the NormalCloud with the given rate."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove normal vectors with a zero magnitude. Note ---- This returns nothing and updates the NormalCloud in - place.", "response": "def remove_zero_normals(self):\n        \"\"\"Removes normal vectors with a zero magnitude.\n\n        Note\n        ----\n        This returns nothing and updates the NormalCloud in-place.\n        \"\"\"\n        points_of_interest = np.where(np.linalg.norm(self._data, axis=0) != 0.0)[0]\n        self._data = self._data[:, points_of_interest]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_nan_normals(self):\n        points_of_interest = np.where(np.isfinite(np.linalg.norm(self._data, axis=0)))[0]\n        self._data = self._data[:, points_of_interest]", "response": "Removes normal vectors with nan magnitude. Note\n        ---- This returns nothing and updates the NormalCloud in - place."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(filename, frame='unspecified'):\n        data = BagOfPoints.load_data(filename)\n        return NormalCloud(data, frame)", "response": "Create a NormalCloud from data saved in a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the incoming data is a 2 x elements ndarray of ints.", "response": "def _check_valid_data(self, data):\n        \"\"\"Checks that the incoming data is a 2 x #elements ndarray of ints.\n\n        Parameters\n        ----------\n        data : :obj:`numpy.ndarray`\n            The data to verify.\n\n        Raises\n        ------\n        ValueError\n            If the data is not of the correct shape or type.\n        \"\"\"\n        if data.dtype.type != np.int8 and data.dtype.type != np.int16 \\\n                and data.dtype.type != np.int32 and data.dtype.type != np.int64 \\\n                and data.dtype.type != np.uint8 and data.dtype.type != np.uint16 \\\n                and data.dtype.type != np.uint32 and data.dtype.type != np.uint64:\n            raise ValueError('Must initialize image coords with a numpy int ndarray')\n        if data.shape[0] != 2:\n            raise ValueError('Illegal data array passed to image coords. Must have 2 coordinates')\n        if len(data.shape) > 2:\n            raise ValueError('Illegal data array passed to point cloud. Must have 1 or 2 dimensions')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an ImageCoords from data saved in a file.", "response": "def open(filename, frame='unspecified'):\n        \"\"\"Create an ImageCoords from data saved in a file.\n\n        Parameters\n        ----------\n        filename : :obj:`str`\n            The file to load data from.\n\n        frame : :obj:`str`\n            The frame to apply to the created ImageCoords.\n\n        Returns\n        -------\n        :obj:`ImageCoords`\n            An ImageCoords created from the data in the file.\n        \"\"\"\n        data = BagOfPoints.load_data(filename)\n        return ImageCoords(data, frame)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(filename, frame='unspecified'):\n        data = BagOfPoints.load_data(filename)\n        return RgbCloud(data, frame)", "response": "Create a RgbCloud from data saved in a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all elements where the norms and points are zero. Note that this is not a problem.", "response": "def remove_zero_points(self):\n        \"\"\"Remove all elements where the norms and points are zero.\n\n        Note\n        ----\n        This returns nothing and updates the NormalCloud in-place.\n        \"\"\"\n        points_of_interest = np.where((np.linalg.norm(self.point_cloud.data, axis=0) != 0.0)  &\n                                      (np.linalg.norm(self.normal_cloud.data, axis=0) != 0.0) &\n                                      (np.isfinite(self.normal_cloud.data[0,:])))[0]\n        self.point_cloud._data = self.point_cloud.data[:, points_of_interest]\n        self.normal_cloud._data = self.normal_cloud.data[:, points_of_interest]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_experiment_ref(experiment_tag, n=10):\n        experiment_id = gen_experiment_id(n=n)\n        return '{0}_{1}'.format(experiment_tag, experiment_id)", "response": "Generate a random string for naming."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the datapoint to the tensor.", "response": "def add(self, datapoint):\n        \"\"\" Adds the datapoint to the tensor if room is available. \"\"\"\n        if not self.is_full:\n            self.set_datapoint(self.cur_index, datapoint)\n            self.cur_index += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_batch(self, datapoints):\n        num_datapoints_to_add = datapoints.shape[0]\n        end_index = self.cur_index + num_datapoints_to_add\n        if end_index <= self.num_datapoints:\n            self.data[self.cur_index:end_index,...] = datapoints\n            self.cur_index = end_index", "response": "Adds a batch of datapoints to the tensor if room is available."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the datapoint at the given index.", "response": "def datapoint(self, ind):\n        \"\"\" Returns the datapoint at the given index. \"\"\"\n        if self.height is None:\n            return self.data[ind]\n        return self.data[ind, ...].copy()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the datapoint at the given index.", "response": "def set_datapoint(self, ind, datapoint):\n        \"\"\" Sets the value of the datapoint at the given index. \"\"\"\n        if ind >= self.num_datapoints:\n            raise ValueError('Index %d out of bounds! Tensor has %d datapoints' %(ind, self.num_datapoints))\n        self.data[ind, ...] = np.array(datapoint).astype(self.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a slice of datapoints", "response": "def data_slice(self, slice_ind):\n        \"\"\" Returns a slice of datapoints \"\"\"\n        if self.height is None:\n            return self.data[slice_ind]\n        return self.data[slice_ind, ...]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving a tensor to disk.", "response": "def save(self, filename, compressed=True):\n        \"\"\" Save a tensor to disk. \"\"\"\n        # check for data\n        if not self.has_data:\n            return False\n\n        # read ext and save accordingly\n        _, file_ext = os.path.splitext(filename)\n        if compressed:\n            if file_ext != COMPRESSED_TENSOR_EXT:\n                raise ValueError('Can only save compressed tensor with %s extension' %(COMPRESSED_TENSOR_EXT))\n            np.savez_compressed(filename,\n                                self.data[:self.cur_index,...])\n        else:\n            if file_ext != TENSOR_EXT:\n                raise ValueError('Can only save tensor with .npy extension')\n            np.save(filename, self.data[:self.cur_index,...])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(filename, compressed=True, prealloc=None):\n        # switch load based on file ext\n        _, file_ext = os.path.splitext(filename)\n        if compressed:\n            if file_ext != COMPRESSED_TENSOR_EXT:\n                raise ValueError('Can only load compressed tensor with %s extension' %(COMPRESSED_TENSOR_EXT))\n            data = np.load(filename)['arr_0']\n        else:\n            if file_ext != TENSOR_EXT:\n                raise ValueError('Can only load tensor with .npy extension')\n            data = np.load(filename)\n            \n        # fill prealloc tensor\n        if prealloc is not None:\n            prealloc.reset()\n            prealloc.add_batch(data)\n            return prealloc\n            \n        # init new tensor\n        tensor = Tensor(data.shape, data.dtype, data=data)\n        return tensor", "response": "Loads a tensor from disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef datapoint_indices_for_tensor(self, tensor_index):\n        if tensor_index >= self._num_tensors:\n            raise ValueError('Tensor index %d is greater than the number of tensors (%d)' %(tensor_index, self._num_tensors))\n        return self._file_num_to_indices[tensor_index]", "response": "Returns the indices for all datapoints in the given tensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the index of the tensor containing the referenced datapoint.", "response": "def tensor_index(self, datapoint_index):\n        \"\"\" Returns the index of the tensor containing the referenced datapoint. \"\"\"\n        if datapoint_index >= self._num_datapoints:\n            raise ValueError('Datapoint index %d is greater than the number of datapoints (%d)' %(datapoint_index, self._num_datapoints))\n        return self._index_to_file_num[datapoint_index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_tensor_filename(self, field_name, file_num, compressed=True):\n        file_ext = TENSOR_EXT\n        if compressed:\n            file_ext = COMPRESSED_TENSOR_EXT\n        filename = os.path.join(self.filename, 'tensors', '%s_%05d%s' %(field_name, file_num, file_ext))\n        return filename", "response": "Generate a filename for a tensor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_split(self, split_name):\n        if os.path.exists(os.path.join(self.split_dir, split_name)):\n            return True\n        return False", "response": "Checks whether or not the split with the given name exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _allocate_tensors(self):\n        # init tensors dict\n        self._tensors = {}\n\n        # allocate tensor for each data field\n        for field_name, field_spec in self._config['fields'].items():\n            # parse attributes\n            field_dtype = np.dtype(field_spec['dtype'])\n            \n            # parse shape\n            field_shape = [self._datapoints_per_file]\n            if 'height' in field_spec.keys():\n                field_shape.append(field_spec['height'])\n                if 'width' in field_spec.keys():\n                    field_shape.append(field_spec['width'])\n                    if 'channels' in field_spec.keys():\n                        field_shape.append(field_spec['channels'])\n                        \n            # create tensor\n            self._tensors[field_name] = Tensor(field_shape, field_dtype)", "response": "Allocates the tensors in the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, datapoint):\n        # check access level\n        if self._access_mode == READ_ONLY_ACCESS:\n            raise ValueError('Cannot add datapoints with read-only access')\n\n        # read tensor datapoint ind\n        tensor_ind = self._num_datapoints // self._datapoints_per_file\n\n        # check datapoint fields\n        for field_name in datapoint.keys():\n            if field_name not in self.field_names:\n                raise ValueError('Field %s not specified in dataset' %(field_name))\n        \n        # store data in tensor\n        cur_num_tensors = self._num_tensors\n        new_num_tensors = cur_num_tensors\n        for field_name in self.field_names:\n            if tensor_ind < cur_num_tensors:\n                # load tensor if it was previously allocated\n                self._tensors[field_name] = self.tensor(field_name, tensor_ind)\n            else:\n                # clear tensor if this is a new tensor\n                self._tensors[field_name].reset()\n                self._tensor_cache_file_num[field_name] = tensor_ind\n                new_num_tensors = cur_num_tensors + 1\n                self._has_unsaved_data = True\n            self._tensors[field_name].add(datapoint[field_name])\n            cur_size = self._tensors[field_name].size\n\n        # update num tensors\n        if new_num_tensors > cur_num_tensors:\n            self._num_tensors = new_num_tensors\n\n        # update file indices\n        self._index_to_file_num[self._num_datapoints] = tensor_ind\n        self._file_num_to_indices[tensor_ind] = tensor_ind * self._datapoints_per_file + np.arange(cur_size)\n\n        # save if tensors are full\n        field_name = self.field_names[0]\n        if self._tensors[field_name].is_full:\n            # save next tensors to file\n            logging.info('Dataset %s: Writing tensor %d to disk' %(self.filename, tensor_ind))\n            self.write()\n\n        # increment num datapoints\n        self._num_datapoints += 1", "response": "Adds a datapoint to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef datapoint(self, ind, field_names=None):\n        # flush if necessary\n        if self._has_unsaved_data:\n            self.flush()\n\n        # check valid input\n        if ind >= self._num_datapoints:\n            raise ValueError('Index %d larger than the number of datapoints in the dataset (%d)' %(ind, self._num_datapoints))\n\n        # load the field names\n        if field_names is None:\n            field_names = self.field_names\n        \n        # return the datapoint\n        datapoint = TensorDatapoint(field_names)\n        file_num = self._index_to_file_num[ind]\n        for field_name in field_names:\n            tensor = self.tensor(field_name, file_num)\n            tensor_index = ind % self._datapoints_per_file\n            datapoint[field_name] = tensor.datapoint(tensor_index)\n        return datapoint", "response": "Loads a tensor datapoint for a given global index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the tensor for a given field and tensor index.", "response": "def tensor(self, field_name, tensor_ind):\n        \"\"\" Returns the tensor for a given field and tensor index.\n\n        Parameters\n        ----------\n        field_name : str\n            the name of the field to load\n        tensor_index : int\n            the index of the tensor\n\n        Returns\n        -------\n        :obj:`Tensor`\n            the desired tensor\n        \"\"\"\n        if tensor_ind == self._tensor_cache_file_num[field_name]:\n            return self._tensors[field_name]\n        filename = self.generate_tensor_filename(field_name, tensor_ind, compressed=True)\n        Tensor.load(filename, compressed=True,\n                    prealloc=self._tensors[field_name])\n        self._tensor_cache_file_num[field_name] = tensor_ind\n        return self._tensors[field_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes the last N datapoints from the dataset.", "response": "def delete_last(self, num_to_delete=1):\n        \"\"\" Deletes the last N datapoints from the dataset.\n\n        Parameters\n        ----------\n        num_to_delete : int\n            the number of datapoints to remove from the end of the dataset\n        \"\"\"\n        # check access level\n        if self._access_mode == READ_ONLY_ACCESS:\n            raise ValueError('Cannot delete datapoints with read-only access')\n\n        # check num to delete\n        if num_to_delete > self._num_datapoints:\n            raise ValueError('Cannot remove more than the number of datapoints in the dataset')\n\n        # compute indices\n        last_datapoint_ind = self._num_datapoints - 1\n        last_tensor_ind = last_datapoint_ind // self._datapoints_per_file\n        new_last_datapoint_ind = self._num_datapoints - 1 - num_to_delete\n        new_num_datapoints = new_last_datapoint_ind + 1\n\n        new_last_datapoint_ind = max(new_last_datapoint_ind, 0)\n        new_last_tensor_ind = new_last_datapoint_ind // self._datapoints_per_file\n\n        # delete all but the last tensor\n        delete_tensor_ind = range(new_last_tensor_ind+1, last_tensor_ind+1) \n        for tensor_ind in delete_tensor_ind:\n            for field_name in self.field_names:\n                filename = self.generate_tensor_filename(field_name, tensor_ind)\n                os.remove(filename)\n\n        # update last tensor\n        dataset_empty = False\n        target_tensor_size = new_num_datapoints % self._datapoints_per_file\n        if target_tensor_size == 0:\n            if new_num_datapoints > 0:\n                target_tensor_size = self._datapoints_per_file\n            else:\n                dataset_empty = True\n\n        for field_name in self.field_names:\n            new_last_tensor = self.tensor(field_name, new_last_tensor_ind)\n            while new_last_tensor.size > target_tensor_size:\n                new_last_tensor.delete_last()\n            filename = self.generate_tensor_filename(field_name, new_last_tensor_ind)\n            new_last_tensor.save(filename, compressed=True)\n            if not new_last_tensor.has_data:\n                os.remove(filename)\n                new_last_tensor.reset()\n        \n        # update num datapoints            \n        if self._num_datapoints - 1 - num_to_delete >= 0:\n            self._num_datapoints = new_num_datapoints\n        else:\n            self._num_datapoints = 0\n\n        # handle deleted tensor\n        self._num_tensors = new_last_tensor_ind + 1\n        if dataset_empty:\n            self._num_tensors = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_metadata(self, key, value):\n        self._metadata[key] = value\n\n        # write the current metadata to file\n        json.dump(self._metadata, open(self.metadata_filename, 'w'),\n                  indent=JSON_INDENT,\n                  sort_keys=True)", "response": "Adds metadata to the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting all tensors to the next file number.", "response": "def write(self):\n        \"\"\" Writes all tensors to the next file number. \"\"\"\n        # write the next file for all fields\n        for field_name in self.field_names:\n            filename = self.generate_tensor_filename(field_name, self._num_tensors-1)\n            self._tensors[field_name].save(filename, compressed=True)\n\n        # write the current metadata to file\n        json.dump(self._metadata, open(self.metadata_filename, 'w'),\n                  indent=JSON_INDENT,\n                  sort_keys=True)\n\n        # update\n        self._has_unsaved_data = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a tensor dataset.", "response": "def open(dataset_dir, access_mode=READ_ONLY_ACCESS):\n        \"\"\" Opens a tensor dataset. \"\"\"\n        # check access mode\n        if access_mode == WRITE_ACCESS:\n            raise ValueError('Cannot open a dataset with write-only access')\n\n        # read config\n        try:\n            # json load\n            config_filename = os.path.join(dataset_dir, 'config.json')\n            config = json.load(open(config_filename, 'r'))\n        except:\n            # YAML load\n            config_filename = os.path.join(dataset_dir, 'config.yaml')\n            config = YamlConfig(config_filename)\n\n        # open dataset\n        dataset = TensorDataset(dataset_dir, config, access_mode=access_mode)\n        return dataset"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split(self, split_name):\n        if not self.has_split(split_name):\n            raise ValueError('Split %s does not exist!' %(split_name))\n        metadata_filename = self.split_metadata_filename(split_name)\n        train_filename = self.train_indices_filename(split_name)\n        val_filename = self.val_indices_filename(split_name)        \n\n        metadata = json.load(open(metadata_filename, 'r'))\n        train_indices = np.load(train_filename)['arr_0']\n        val_indices = np.load(val_filename)['arr_0']\n        return train_indices, val_indices, metadata", "response": "Return the training and validation indices for the requested split."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit the dataset into train and test according to the given attribute.", "response": "def make_split(self, split_name, val_indices=None, train_pct=0.8, field_name=None):\n        \"\"\" Splits the dataset into train and test according\n        to the given attribute.\n        The split is saved with the dataset for future access.\n\n        Parameters\n        ----------\n        split_name : str\n            name of the split (for future accesses)\n        val_indices : \n            indices of the validation datapoints (overrides other variables if not None) \n        train_pct : float\n            percent of data to use for training\n        field_name : str\n            name of the field to use in splitting (None for raw indices)\n\n        Returns\n        -------\n        :obj:`numpy.ndarray`\n            array of training indices in the global dataset\n        :obj:`numpy.ndarray`\n            array of validation indices in the global dataset\n        \"\"\"\n        # check train percentage\n        if train_pct < 0 or train_pct > 1:\n            raise ValueError('Train pct must be a float between 0 and 1')\n\n        # check existence\n        if self.has_split(split_name):\n            raise ValueError('Cannot create split %s - it already exists! To overwrite, delete split with TensorDataset.delete_split(split_name)' %(split_name))\n\n        # perform splitting\n        if val_indices is not None:\n            all_indices = np.arange(self.num_datapoints)\n            train_indices = np.setdiff1d(all_indices, val_indices)\n        elif field_name is None:\n            # split on indices\n            indices = np.arange(self.num_datapoints)\n            num_train = int(train_pct * self.num_datapoints)\n            np.random.shuffle(indices)\n            train_indices = indices[:num_train]\n            val_indices = indices[num_train:]\n            field_name = 'index'\n        elif field_name == 'split':\n            # split on binary values\n            train_indices = []\n            val_indices = []\n            for i in range(self.num_datapoints):\n                datapoint = self.datapoint(i, field_names=['split'])\n                split = datapoint['split']\n                if split == TRAIN_ID:\n                    train_indices.append(i)\n                else:\n                    val_indices.append(i)\n            train_indices = np.array(train_indices)\n            val_indices = np.array(val_indices)\n        else:\n            # split on field name\n\n            # check valid field\n            if field_name not in self.config['fields'].keys():\n                raise ValueError('Field %d not in dataset!' %(field_name))\n            if 'height' in self.config['fields'][field_name].keys():\n                raise ValueError('Can only split on scalar fields!')\n\n            # find unique values\n            values = []\n            for i in range(self.num_datapoints):\n                datapoint = self.datapoint(i, field_names=[field_name])\n                values.append(datapoint[field_name])\n            unique_values = np.unique(values)\n            num_unique = unique_values.shape[0]\n            num_train = int(train_pct * num_unique)\n\n            # split\n            np.random.shuffle(unique_values)\n            train_values = unique_values[:num_train]\n            val_values = unique_values[num_train:]\n\n            # aggregate indices\n            train_indices = []\n            val_indices = []\n            for i in range(self.num_datatpoints):\n                datapoint = self.datapoint(i, field_names=[field_name])\n                if datapoint[field_name] in train_values:\n                    train_indices.append(i)\n                else:\n                    val_indices.append(i)\n            train_indices = np.array(train_indices)\n            val_indices = np.array(val_indices)                    \n                \n        # sort indices\n        train_indices.sort()\n        val_indices.sort()\n\n        # save to disk\n        if not os.path.exists(self.split_dir):\n            os.mkdir(self.split_dir)\n        split_dir = os.path.join(self.split_dir, split_name)\n        os.mkdir(split_dir)\n        train_filename = self.train_indices_filename(split_name)\n        val_filename = self.val_indices_filename(split_name)        \n        np.savez_compressed(train_filename, train_indices)\n        np.savez_compressed(val_filename, val_indices)\n        metadata_filename = self.split_metadata_filename(split_name)\n        metadata = {\n            'field_name': field_name,\n            'train_pct': train_pct\n        }\n        json.dump(metadata, open(metadata_filename, 'w'),\n                  indent=JSON_INDENT,\n                  sort_keys=True)\n        return train_indices, val_indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a split of the dataset.", "response": "def delete_split(self, split_name):\n        \"\"\" Delete a split of the dataset.\n\n        Parameters\n        ----------\n        split_name : str\n            name of the split to delete\n        \"\"\"\n        if self.has_split(split_name):\n            shutil.rmtree(os.path.join(self.split_dir, split_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a yaml configuration file from the given filename.", "response": "def _load_config(self, filename):\n        \"\"\"Loads a yaml configuration file from the given filename.\n\n        Parameters\n        ----------\n        filename : :obj:`str`\n            The filename of the .yaml file that contains the configuration.\n        \"\"\"\n        # Read entire file for metadata\n        fh = open(filename, 'r')\n        self.file_contents = fh.read()\n\n        # Replace !include directives with content\n        config_dir = os.path.split(filename)[0]\n        include_re = re.compile('^(.*)!include\\s+(.*)$', re.MULTILINE)\n\n        def recursive_load(matchobj, path):\n            first_spacing = matchobj.group(1)\n            other_spacing = first_spacing.replace('-', ' ')\n            fname = os.path.join(path, matchobj.group(2))\n            new_path, _ = os.path.split(fname)\n            new_path = os.path.realpath(new_path)\n            text = ''\n            with open(fname) as f:\n                text = f.read()\n            text = first_spacing + text\n            text = text.replace('\\n', '\\n{}'.format(other_spacing), text.count('\\n') - 1)\n            return re.sub(include_re, lambda m : recursive_load(m, new_path), text)\n\n#        def include_repl(matchobj):\n#            first_spacing = matchobj.group(1)\n#            other_spacing = first_spacing.replace('-', ' ')\n#            fname = os.path.join(config_dir, matchobj.group(2))\n#            text = ''\n#            with open(fname) as f:\n#                text = f.read()\n#            text = first_spacing + text\n#            text = text.replace('\\n', '\\n{}'.format(other_spacing), text.count('\\n') - 1)\n#            return text\n\n        self.file_contents = re.sub(include_re, lambda m : recursive_load(m, config_dir), self.file_contents)\n        # Read in dictionary\n        self.config = self.__ordered_load(self.file_contents)\n\n        # Convert functions of other params to true expressions\n        for k in self.config.keys():\n            self.config[k] = YamlConfig.__convert_key(self.config[k])\n\n        fh.close()\n\n        # Load core configuration\n        return self.config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __convert_key(expression):\n        if type(expression) is str and len(expression) > 2 and expression[1] == '!':\n            expression = eval(expression[2:-1])\n        return expression", "response": "Converts keys in YAML that reference other keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a matplotlib table object with relevant data.", "response": "def make_summary_table(train_result, val_result, plot=True, save_dir=None, prepend=\"\", save=False):\n        \"\"\"\n        Makes a matplotlib table object with relevant data.\n        Thanks to Lucas Manuelli for the contribution.\n\n        Parameters\n        ----------\n        train_result: ClassificationResult\n            result on train split\n\n        val_result: ClassificationResult\n            result on validation split\n\n        save_dir: str\n            path pointing to where to save results\n\n        Returns\n        -------\n        dict\n            dict with stored values, can be saved to a yaml file\n\n        :obj:`matplotlibt.pyplot.fig`\n            a figure containing the table\n        \"\"\"\n        table_key_list = ['error_rate', 'recall_at_99_precision', 'average_precision', 'precision', 'recall']\n        num_fields = len(table_key_list)\n        \n        import matplotlib.pyplot as plt\n        ax = plt.subplot(111, frame_on=False)\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n        \n        data = np.zeros([num_fields, 2])\n        data_dict = dict()\n\n        names = ['train', 'validation']\n        for name, result in zip(names, [train_result, val_result]):\n            data_dict[name] = {}\n            data_dict[name]['error_rate'] = result.error_rate\n            data_dict[name]['average_precision'] = result.ap_score * 100\n            data_dict[name]['precision'] = result.precision * 100\n            data_dict[name]['recall'] = result.recall * 100\n\n            precision_array, recall_array, _ = result.precision_recall_curve()\n            recall_at_99_precision = recall_array[np.argmax(precision_array > 0.99)] * 100  # to put it in percentage terms\n            data_dict[name]['recall_at_99_precision'] = recall_at_99_precision\n                        \n            for i, key in enumerate(table_key_list):\n                data_dict[name][key] = float(\"{0:.2f}\".format(data_dict[name][key]))\n                j = names.index(name)\n                data[i, j] = data_dict[name][key]\n\n        table = plt.table(cellText=data, rowLabels=table_key_list, colLabels=names)\n\n        fig = plt.gcf()\n        fig.subplots_adjust(bottom=0.15)\n        \n        if plot:\n            plt.show()\n\n        # save the results\n        if save_dir is not None and save:\n            fig_filename = os.path.join(save_dir, prepend + 'summary.png')\n            yaml_filename = os.path.join(save_dir, prepend + 'summary.yaml')\n            \n            yaml.dump(data_dict, open(yaml_filename, 'w'), default_flow_style=False)\n            fig.savefig(fig_filename, bbox_inches=\"tight\")\n            \n        return data_dict, fig"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the app score of the current state of the current state of the app curve.", "response": "def app_score(self):\n        \"\"\" Computes the area under the app curve. \"\"\"\n        # compute curve\n        precisions, pct_pred_pos, taus = self.precision_pct_pred_pos_curve(interval=False)\n\n        # compute area\n        app = 0\n        total = 0\n        for k in range(len(precisions)-1):\n            # read cur data\n            cur_prec = precisions[k]\n            cur_pp = pct_pred_pos[k]\n            cur_tau = taus[k]\n\n            # read next data\n            next_prec = precisions[k+1]\n            next_pp = pct_pred_pos[k+1]\n            next_tau = taus[k+1]\n            \n            # approximate with rectangles\n            mid_prec = (cur_prec + next_prec) / 2.0\n            width_pp = np.abs(next_pp - cur_pp)\n            app += mid_prec * width_pp\n            total += width_pp\n\n        return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the relationship between probability threshold and classification accuracy.", "response": "def accuracy_curve(self, delta_tau=0.01):\n        \"\"\" Computes the relationship between probability threshold\n        and classification accuracy. \"\"\"\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        scores = []\n        taus = []\n        tau = 0\n        for k in range(len(sorted_labels)):\n            # compute new accuracy\n            self.threshold = tau\n            scores.append(self.accuracy)\n            taus.append(tau)\n\n            # update threshold\n            tau = sorted_probs[k]\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        scores.append(self.accuracy)\n        taus.append(tau)\n\n        self.threshold = orig_thresh\n        return scores, taus"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef precision_curve(self, delta_tau=0.01):\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        scores = []\n        taus = []\n        tau = 0\n        for k in range(len(sorted_labels)):\n            # compute new accuracy\n            self.threshold = tau\n            scores.append(self.precision)\n            taus.append(tau)\n\n            # update threshold\n            tau = sorted_probs[k]\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        scores.append(1.0)\n        taus.append(tau)\n\n        self.threshold = orig_thresh\n        return scores, taus", "response": "Compute the relationship between probability threshold\n            and classification precision."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the relationship between probability threshold and classification precision.", "response": "def recall_curve(self, delta_tau=0.01):\n        \"\"\" Computes the relationship between probability threshold\n        and classification precision. \"\"\"\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        scores = []\n        taus = []\n        tau = 0\n        for k in range(len(sorted_labels)):\n            # compute new accuracy\n            self.threshold = tau\n            scores.append(self.recall)\n            taus.append(tau)\n\n            # update threshold\n            tau = sorted_probs[k]\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        scores.append(1.0)\n        taus.append(tau)\n\n        self.threshold = orig_thresh\n        return scores, taus"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef f1_curve(self, delta_tau=0.01):\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        scores = []\n        taus = []\n        tau = 0\n        for k in range(len(sorted_labels)):\n            # compute new accuracy\n            self.threshold = tau\n            scores.append(self.f1_score)\n            taus.append(tau)\n\n            # update threshold\n            tau = sorted_probs[k]\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        scores.append(self.f1_score)\n        taus.append(tau)\n\n        self.threshold = orig_thresh\n        return scores, taus", "response": "Computes the relationship between probability threshold\n        and classification F1 score."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the relationship between probability threshold and classification phi coefficient.", "response": "def phi_coef_curve(self, delta_tau=0.01):\n        \"\"\" Computes the relationship between probability threshold\n        and classification phi coefficient. \"\"\"\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        scores = []\n        taus = []\n        tau = 0\n        for k in range(len(sorted_labels)):\n            # compute new accuracy\n            self.threshold = tau\n            scores.append(self.phi_coef)\n            taus.append(tau)\n\n            # update threshold\n            tau = sorted_probs[k]\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        scores.append(self.phi_coef)\n        taus.append(tau)\n\n        self.threshold = orig_thresh\n        return scores, taus"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the relationship between precision and pct - pred positively classified datapoints.", "response": "def precision_pct_pred_pos_curve(self, interval=False, delta_tau=0.001):\n        \"\"\" Computes the relationship between precision\n        and the percent of positively classified datapoints . \"\"\"\n        # compute thresholds based on the sorted probabilities\n        orig_thresh = self.threshold\n        sorted_labels, sorted_probs = self.sorted_values\n\n        precisions = []\n        pct_pred_pos = []\n        taus = []\n        tau = 0\n        if not interval:\n            for k in range(len(sorted_labels)):\n                # compute new accuracy\n                self.threshold = tau\n                precisions.append(self.precision)\n                pct_pred_pos.append(self.pct_pred_pos)\n                taus.append(tau)\n                \n                # update threshold\n                tau = sorted_probs[k]\n\n        else:\n            while tau < 1.0:\n                # compute new accuracy\n                self.threshold = tau\n                precisions.append(self.precision)\n                pct_pred_pos.append(self.pct_pred_pos)\n                taus.append(tau)\n                \n                # update threshold\n                tau += delta_tau\n\n        # add last datapoint\n        tau = 1.0\n        self.threshold = tau\n        precisions.append(self.precision)\n        pct_pred_pos.append(self.pct_pred_pos)\n        taus.append(tau)\n\n        precisions.append(1.0)\n        pct_pred_pos.append(0.0)\n        taus.append(1.0 + 1e-12)\n\n        self.threshold = orig_thresh\n        return precisions, pct_pred_pos, taus"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random string with only alphabetic characters.", "response": "def gen_experiment_id(n=10):\n    \"\"\"Generate a random string with n characters.\n\n    Parameters\n    ----------\n    n : int\n        The length of the string to be generated.\n\n    Returns\n    -------\n    :obj:`str`\n        A string with only alphabetic characters. \n    \"\"\"\n    chrs = 'abcdefghijklmnopqrstuvwxyz'\n    inds = np.random.randint(0,len(chrs), size=n)\n    return ''.join([chrs[i] for i in inds])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef histogram(values, num_bins, bounds, normalized=True, plot=False, color='b'):\n    hist, bins = np.histogram(values, bins=num_bins, range=bounds)\n    width = (bins[1] - bins[0])\n    if normalized:\n        if np.sum(hist) > 0:\n            hist = hist.astype(np.float32) / np.sum(hist)\n    if plot:\n        import matplotlib.pyplot as plt\n        plt.bar(bins[:-1], hist, width=width, color=color)    \n    return hist, bins", "response": "Generates a histogram plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef skew(xi):\n    S = np.array([[0, -xi[2], xi[1]],\n                  [xi[2], 0, -xi[0]],\n                  [-xi[1], xi[0], 0]])\n    return S", "response": "Return the skew - symmetric cross - product matrix that can be used to calculate the same result\n    as xi x v."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deskew(S):\n    x = np.zeros(3)\n    x[0] = S[2,1]\n    x[1] = S[0,2]\n    x[2] = S[1,0]\n    return x", "response": "Converts a skew - symmetric cross - product matrix to its corresponding\n    vector. Only works for 3x3 matrices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reverse_dictionary(d):\n    rev_d = {}\n    [rev_d.update({v:k}) for k, v in d.items()]\n    return rev_d", "response": "Returns a new dictionary with the keys and values swapped."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filenames(directory, tag='', sorted=False, recursive=False):\n    if recursive:\n        f = [os.path.join(directory, f) for directory, _, filename in os.walk(directory) for f in filename if f.find(tag) > -1] \n    else:\n        f = [os.path.join(directory, f) for f in os.listdir(directory) if f.find(tag) > -1]\n    if sorted:\n        f.sort()\n    return f", "response": "Reads in all filenames from a directory that contain a specified substring."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sph2cart(r, az, elev):\n    x = r * np.cos(az) * np.sin(elev)\n    y = r * np.sin(az) * np.sin(elev)\n    z = r * np.cos(elev)\n    return x, y, z", "response": "Convert spherical to cartesian coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cart2sph(x, y, z):\n    r = np.sqrt(x**2 + y**2 + z**2)\n    if x > 0 and y > 0:\n        az = np.arctan(y / x)\n    elif x > 0 and y < 0:\n        az = 2*np.pi - np.arctan(-y / x)\n    elif x < 0 and y > 0:\n        az = np.pi - np.arctan(-y / x)    \n    elif x < 0 and y < 0:\n        az = np.pi + np.arctan(y / x)    \n    elif x == 0 and y > 0:\n        az = np.pi / 2\n    elif x == 0 and y < 0:\n        az = 3 * np.pi / 2\n    elif y == 0 and x > 0:\n        az = 0\n    elif y == 0 and x < 0:\n        az = np.pi\n    elev = np.arccos(z / r)\n    return r, az, elev", "response": "Convert cartesian coordinates to spherical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keyboard_input(message, yesno=False):\n    # add space for readability\n    message += ' '\n\n    # add yes or no to message\n    if yesno:\n        message += '[y/n] '\n\n    # ask human\n    human_input = input(message)\n    if yesno:\n        while human_input.lower() != 'n' and human_input.lower() != 'y':\n            logging.info('Did not understand input. Please answer \\'y\\' or \\'n\\'')\n            human_input = input(message)\n    return human_input", "response": "Get keyboard input by a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conjugate(self):\n        qr_c_xyzw = quaternion_conjugate(self._qr)\n        qd_c_xyzw = quaternion_conjugate(self._qd)\n\n        qr_c_wxyz = np.roll(qr_c_xyzw, 1)\n        qd_c_wxyz = np.roll(qd_c_xyzw, 1)\n        return DualQuaternion(qr_c_wxyz, qd_c_wxyz)", "response": "Returns the conjugate of this quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the normalized vectors for qr and qd respectively.", "response": "def norm(self):\n        \"\"\":obj:`tuple` of :obj:`numpy.ndarray`: The normalized vectors for qr and qd, respectively.\n        \"\"\"\n        qr_c = quaternion_conjugate(self._qr)\n        qd_c = quaternion_conjugate(self._qd)\n\n        qr_norm = np.linalg.norm(quaternion_multiply(self._qr, qr_c))\n        qd_norm = np.linalg.norm(quaternion_multiply(self._qr, qd_c) + quaternion_multiply(self._qd, qr_c))\n\n        return (qr_norm, qd_norm)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalized(self):\n        qr = self.qr /1./ np.linalg.norm(self.qr)\n        return DualQuaternion(qr, self.qd, True)", "response": "Returns a new DualQuaternion object with qr normalized."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the interpolation of two DualQuaternions.", "response": "def interpolate(dq0, dq1, t):\n        \"\"\"Return the interpolation of two DualQuaternions.\n\n        This uses the Dual Quaternion Linear Blending Method as described by Matthew Smith's\n        'Applications of Dual Quaternions in Three Dimensional Transformation and Interpolation'\n        https://www.cosc.canterbury.ac.nz/research/reports/HonsReps/2013/hons_1305.pdf\n\n        Parameters\n        ----------\n        dq0 : :obj:`DualQuaternion`\n            The first DualQuaternion.\n\n        dq1 : :obj:`DualQuaternion`\n            The second DualQuaternion.\n\n        t : float\n            The interpolation step in [0,1]. When t=0, this returns dq0, and\n            when t=1, this returns dq1.\n\n        Returns\n        -------\n        :obj:`DualQuaternion`\n            The interpolated DualQuaternion.\n\n        Raises\n        ------\n        ValueError\n            If t isn't in [0,1].\n        \"\"\"\n        if not 0 <= t <= 1:\n            raise ValueError(\"Interpolation step must be between 0 and 1! Got {0}\".format(t))\n\n        dqt = dq0 * (1-t) + dq1 * t\n        return dqt.normalized"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _save(self):\n        # if not first time saving, copy .csv to a backup\n        if os.path.isfile(self._full_filename):\n            shutil.copyfile(self._full_filename, self._full_backup_filename)\n\n        # write to csv\n        with open(self._full_filename, 'w') as file:\n            writer = csv.DictWriter(file, fieldnames=self._headers)\n            writer.writeheader()\n            for row in self._table:\n                writer.writerow(row)", "response": "Save the model to a. csv file\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, data):\n        row = {key:self._default_entry for key in self._headers}\n        row['_uid'] = self._get_new_uid()\n\n        for key, val in data.items():\n            if key in ('_uid', '_default'):\n                logging.warn(\"Cannot manually set columns _uid or _default of a row! Given data: {0}\".format(data))\n                continue\n            if not isinstance(val, CSVModel._KNOWN_TYPES_MAP[self._headers_types[key]]):\n                raise Exception('Data type mismatch for column {0}. Expected: {1}, got: {2}'.format(key,\n                                                        CSVModel._KNOWN_TYPES_MAP[self._headers_types[key]], type(val)))\n            row[key] = val\n\n        self._table.append(row)\n        self._save()\n        return row['_uid']", "response": "Insert a new row into the. csv file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a row with the given data.", "response": "def update_by_uid(self, uid, data):\n        \"\"\"Update a row with the given data.\n\n        Parameters\n        ----------\n        uid : int\n            The UID of the row to update.\n\n        data : :obj:`dict`\n            A dictionary mapping keys (header strings) to values.\n\n        Raises\n        ------\n        Exception\n            If the value for a given header is not of the appropriate type.\n        \"\"\"\n        row = self._table[uid+1]\n        for key, val in data.items():\n            if key == '_uid' or key == '_default':\n                continue\n            if key not in self._headers:\n                logging.warn(\"Unknown column name: {0}\".format(key))\n                continue\n            if not isinstance(val, CSVModel._KNOWN_TYPES_MAP[self._headers_types[key]]):\n                raise Exception('Data type mismatch for column {0}. Expected: {1}, got: {2}'.format(key,\n                                                        CSVModel._KNOWN_TYPES_MAP[self._headers_types[key]], type(val)))\n            row[key] = val\n        self._save()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_col(self, col_name, filter = lambda _ : True):\n        if col_name not in self._headers:\n            raise ValueError(\"{} not found! Model has headers: {}\".format(col_name, self._headers))\n        col = []\n        for i in range(self.num_rows):\n            row = self._table[i + 1]\n            val = row[col_name]\n            if filter(val):\n                col.append(val)\n\n        return col", "response": "Return all values in the column corresponding to col_name that satisfies filter which is the value of the column s type and returns True or False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first or last row that satisfies the given col value constraints or None if no such row exists.", "response": "def get_by_cols(self, cols, direction=1):\n        \"\"\"Return the first or last row that satisfies the given col value constraints,\n        or None if no row contains the given value.\n\n        Parameters\n        ----------\n        cols: :obj:'dict'\n            Dictionary of col values for a specific row.\n        direction: int, optional\n            Either 1 or -1. 1 means find the first row, -1 means find the last row.\n\n        Returns\n        -------\n        :obj:`dict`\n            A dictionary mapping keys (header strings) to values, which\n            represents a row of the table. This row contains the given value in\n            the specified column.\n        \"\"\"\n        if direction == 1:\n            iterator = range(self.num_rows)\n        elif direction == -1:\n            iterator = range(self.num_rows-1, -1, -1)\n        else:\n            raise ValueError(\"Direction can only be 1 (first) or -1 (last). Got: {0}\".format(direction))\n\n        for i in iterator:\n            row = self._table[i+1]\n\n            all_sat = True\n            for key, val in cols.items():\n                if row[key] != val:\n                    all_sat = False\n                    break\n\n            if all_sat:\n                return row.copy()\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all rows where the cols match the elements given in the matching_dict.", "response": "def get_rows_by_cols(self, matching_dict):\n        \"\"\"Return all rows where the cols match the elements given in the matching_dict\n\n        Parameters\n        ----------\n        matching_dict: :obj:'dict'\n            Desired dictionary of col values.\n\n        Returns\n        -------\n        :obj:`list`\n            A list of rows that satisfy the matching_dict\n        \"\"\"\n        result = []\n        for i in range(self.num_rows):\n            row = self._table[i+1]\n            matching = True\n            for key, val in matching_dict.items():\n                if row[key] != val:\n                    matching = False\n                    break\n\n            if matching:\n                result.append(row)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next row in the CSV for iteration", "response": "def next(self):\n        \"\"\" Returns the next row in the CSV, for iteration \"\"\"\n        if self._cur_row >= len(self._table):\n            raise StopIteration\n        data = self._table[self._cur_row].copy()\n        self._cur_row += 1\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(full_filename):\n        with open(full_filename, 'r') as file:\n            reader = csv.DictReader(file)\n            headers = reader.fieldnames\n            if '_uid' not in headers or '_default' not in headers:\n                raise Exception(\"Malformed CSVModel file!\")\n\n            all_rows = [row for row in reader]\n            types = all_rows[0]\n            table = [types]\n            default_entry = table[0]['_default']\n\n            for i in range(1, len(all_rows)):\n                raw_row = all_rows[i]\n                row = {}\n                for column_name in headers:\n                    if raw_row[column_name] != default_entry and column_name != '':\n                        if types[column_name] == 'bool':\n                            row[column_name] = CSVModel._str_to_bool(raw_row[column_name])\n                        else:\n                            try:\n                                row[column_name] = CSVModel._KNOWN_TYPES_MAP[types[column_name]](raw_row[column_name])\n                            except:\n                                logging.error('{}, {}, {}'.format(column_name, types[column_name], raw_row[column_name]))\n                                row[column_name] = CSVModel._KNOWN_TYPES_MAP[types[column_name]](bool(raw_row[column_name]))\n                    else:\n                        row[column_name] = default_entry\n                table.append(row)\n\n        if len(table) == 1:\n            next_valid_uid = 0\n        else:\n            next_valid_uid = int(table[-1]['_uid']) + 1\n\n        headers_init = headers[1:-1]\n        types_init = [types[column_name] for column_name in headers_init]\n        headers_types_list = zip(headers_init, types_init)\n\n        csv_model = CSVModel(full_filename, headers_types_list, default_entry=default_entry)\n        csv_model._uid = next_valid_uid\n        csv_model._table = table\n        csv_model._save()\n        return csv_model", "response": "Loads a. csv file into a CSVModel."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a. csv file into a CSVModel if the file does not exist or create a new CSVModel with the given filename if it does not exist.", "response": "def get_or_create(full_filename, headers_types=None, default_entry=''):\n        \"\"\"Load a .csv file into a CSVModel if the file exists, or create\n        a new CSVModel with the given filename if the file does not exist.\n\n        Parameters\n        ----------\n        full_filename : :obj:`str`\n            The file path to a .csv file.\n\n        headers_types : :obj:`list` of :obj:`tuple` of :obj:`str`, :obj:`str`\n            A list of tuples, where the first element in each tuple is the\n            string header for a column and the second element is that column's\n            data type as a string.\n\n        default_entry : :obj:`str`\n            The default entry for cells in the CSV.\n\n        Returns\n        -------\n        :obj:`CSVModel`\n            The CSVModel initialized with the data in the given file, or a new\n            CSVModel tied to the filename if the file doesn't currently exist.\n        \"\"\"\n        # convert dictionaries to list\n        if isinstance(headers_types, dict):\n            headers_types_list = [(k,v) for k,v in headers_types.items()]\n            headers_types = headers_types_list\n\n        if os.path.isfile(full_filename):\n            return CSVModel.load(full_filename)\n        else:\n            return CSVModel(full_filename, headers_types, default_entry=default_entry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rotation_matrix(angle, direction, point=None):\n    sina = math.sin(angle)\n    cosa = math.cos(angle)\n    direction = unit_vector(direction[:3])\n    # rotation matrix around unit vector\n    R = numpy.array(((cosa, 0.0,  0.0),\n                     (0.0,  cosa, 0.0),\n                     (0.0,  0.0,  cosa)), dtype=numpy.float64)\n    R += numpy.outer(direction, direction) * (1.0 - cosa)\n    direction *= sina\n    R += numpy.array((( 0.0,         -direction[2],  direction[1]),\n                      ( direction[2], 0.0,          -direction[0]),\n                      (-direction[1], direction[0],  0.0)),\n                     dtype=numpy.float64)\n    M = numpy.identity(4)\n    M[:3, :3] = R\n    if point is not None:\n        # rotation not around origin\n        point = numpy.array(point[:3], dtype=numpy.float64, copy=False)\n        M[:3, 3] = point - numpy.dot(R, point)\n    return M", "response": "Return matrix to rotate about axis defined by point and direction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns matrix to scale by factor around origin in direction.", "response": "def scale_matrix(factor, origin=None, direction=None):\n    \"\"\"Return matrix to scale by factor around origin in direction.\n\n    Use factor -1 for point symmetry.\n\n    >>> v = (numpy.random.rand(4, 5) - 0.5) * 20.0\n    >>> v[3] = 1.0\n    >>> S = scale_matrix(-1.234)\n    >>> numpy.allclose(numpy.dot(S, v)[:3], -1.234*v[:3])\n    True\n    >>> factor = random.random() * 10 - 5\n    >>> origin = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> S = scale_matrix(factor, origin)\n    >>> S = scale_matrix(factor, origin, direct)\n\n    \"\"\"\n    if direction is None:\n        # uniform scaling\n        M = numpy.array(((factor, 0.0,    0.0,    0.0),\n                         (0.0,    factor, 0.0,    0.0),\n                         (0.0,    0.0,    factor, 0.0),\n                         (0.0,    0.0,    0.0,    1.0)), dtype=numpy.float64)\n        if origin is not None:\n            M[:3, 3] = origin[:3]\n            M[:3, 3] *= 1.0 - factor\n    else:\n        # nonuniform scaling\n        direction = unit_vector(direction[:3])\n        factor = 1.0 - factor\n        M = numpy.identity(4)\n        M[:3, :3] -= factor * numpy.outer(direction, direction)\n        if origin is not None:\n            M[:3, 3] = (factor * numpy.dot(origin[:3], direction)) * direction\n    return M"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns matrix to project onto plane defined by point and normal.", "response": "def projection_matrix(point, normal, direction=None,\n                      perspective=None, pseudo=False):\n    \"\"\"Return matrix to project onto plane defined by point and normal.\n\n    Using either perspective point, projection direction, or none of both.\n\n    If pseudo is True, perspective projections will preserve relative depth\n    such that Perspective = dot(Orthogonal, PseudoPerspective).\n\n    >>> P = projection_matrix((0, 0, 0), (1, 0, 0))\n    >>> numpy.allclose(P[1:, 1:], numpy.identity(4)[1:, 1:])\n    True\n    >>> point = numpy.random.random(3) - 0.5\n    >>> normal = numpy.random.random(3) - 0.5\n    >>> direct = numpy.random.random(3) - 0.5\n    >>> persp = numpy.random.random(3) - 0.5\n    >>> P0 = projection_matrix(point, normal)\n    >>> P1 = projection_matrix(point, normal, direction=direct)\n    >>> P2 = projection_matrix(point, normal, perspective=persp)\n    >>> P3 = projection_matrix(point, normal, perspective=persp, pseudo=True)\n    >>> is_same_transform(P2, numpy.dot(P0, P3))\n    True\n    >>> P = projection_matrix((3, 0, 0), (1, 1, 0), (1, 0, 0))\n    >>> v0 = (numpy.random.rand(4, 5) - 0.5) * 20.0\n    >>> v0[3] = 1.0\n    >>> v1 = numpy.dot(P, v0)\n    >>> numpy.allclose(v1[1], v0[1])\n    True\n    >>> numpy.allclose(v1[0], 3.0-v1[1])\n    True\n\n    \"\"\"\n    M = numpy.identity(4)\n    point = numpy.array(point[:3], dtype=numpy.float64, copy=False)\n    normal = unit_vector(normal[:3])\n    if perspective is not None:\n        # perspective projection\n        perspective = numpy.array(perspective[:3], dtype=numpy.float64,\n                                  copy=False)\n        M[0, 0] = M[1, 1] = M[2, 2] = numpy.dot(perspective-point, normal)\n        M[:3, :3] -= numpy.outer(perspective, normal)\n        if pseudo:\n            # preserve relative depth\n            M[:3, :3] -= numpy.outer(normal, normal)\n            M[:3, 3] = numpy.dot(point, normal) * (perspective+normal)\n        else:\n            M[:3, 3] = numpy.dot(point, normal) * perspective\n        M[3, :3] = -normal\n        M[3, 3] = numpy.dot(perspective, normal)\n    elif direction is not None:\n        # parallel projection\n        direction = numpy.array(direction[:3], dtype=numpy.float64, copy=False)\n        scale = numpy.dot(direction, normal)\n        M[:3, :3] -= numpy.outer(direction, normal) / scale\n        M[:3, 3] = direction * (numpy.dot(point, normal) / scale)\n    else:\n        # orthogonal projection\n        M[:3, :3] -= numpy.outer(normal, normal)\n        M[:3, 3] = numpy.dot(point, normal) * normal\n    return M"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef projection_from_matrix(matrix, pseudo=False):\n    M = numpy.array(matrix, dtype=numpy.float64, copy=False)\n    M33 = M[:3, :3]\n    l, V = numpy.linalg.eig(M)\n    i = numpy.where(abs(numpy.real(l) - 1.0) < 1e-8)[0]\n    if not pseudo and len(i):\n        # point: any eigenvector corresponding to eigenvalue 1\n        point = numpy.real(V[:, i[-1]]).squeeze()\n        point /= point[3]\n        # direction: unit eigenvector corresponding to eigenvalue 0\n        l, V = numpy.linalg.eig(M33)\n        i = numpy.where(abs(numpy.real(l)) < 1e-8)[0]\n        if not len(i):\n            raise ValueError(\"no eigenvector corresponding to eigenvalue 0\")\n        direction = numpy.real(V[:, i[0]]).squeeze()\n        direction /= vector_norm(direction)\n        # normal: unit eigenvector of M33.T corresponding to eigenvalue 0\n        l, V = numpy.linalg.eig(M33.T)\n        i = numpy.where(abs(numpy.real(l)) < 1e-8)[0]\n        if len(i):\n            # parallel projection\n            normal = numpy.real(V[:, i[0]]).squeeze()\n            normal /= vector_norm(normal)\n            return point, normal, direction, None, False\n        else:\n            # orthogonal projection, where normal equals direction vector\n            return point, direction, None, None, False\n    else:\n        # perspective projection\n        i = numpy.where(abs(numpy.real(l)) > 1e-8)[0]\n        if not len(i):\n            raise ValueError(\n                \"no eigenvector not corresponding to eigenvalue 0\")\n        point = numpy.real(V[:, i[-1]]).squeeze()\n        point /= point[3]\n        normal = - M[3, :3]\n        perspective = M[:3, 3] / numpy.dot(point[:3], normal)\n        if pseudo:\n            perspective -= normal\n        return point, normal, None, perspective, pseudo", "response": "Return projection plane and perspective point from projection matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef superimposition_matrix(v0, v1, scaling=False, usesvd=True):\n    v0 = numpy.array(v0, dtype=numpy.float64, copy=False)[:3]\n    v1 = numpy.array(v1, dtype=numpy.float64, copy=False)[:3]\n\n    if v0.shape != v1.shape or v0.shape[1] < 3:\n        raise ValueError(\"Vector sets are of wrong shape or type.\")\n\n    # move centroids to origin\n    t0 = numpy.mean(v0, axis=1)\n    t1 = numpy.mean(v1, axis=1)\n    v0 = v0 - t0.reshape(3, 1)\n    v1 = v1 - t1.reshape(3, 1)\n\n    if usesvd:\n        # Singular Value Decomposition of covariance matrix\n        u, s, vh = numpy.linalg.svd(numpy.dot(v1, v0.T))\n        # rotation matrix from SVD orthonormal bases\n        R = numpy.dot(u, vh)\n        if numpy.linalg.det(R) < 0.0:\n            # R does not constitute right handed system\n            R -= numpy.outer(u[:, 2], vh[2, :]*2.0)\n            s[-1] *= -1.0\n        # homogeneous transformation matrix\n        M = numpy.identity(4)\n        M[:3, :3] = R\n    else:\n        # compute symmetric matrix N\n        xx, yy, zz = numpy.sum(v0 * v1, axis=1)\n        xy, yz, zx = numpy.sum(v0 * numpy.roll(v1, -1, axis=0), axis=1)\n        xz, yx, zy = numpy.sum(v0 * numpy.roll(v1, -2, axis=0), axis=1)\n        N = ((xx+yy+zz, yz-zy,    zx-xz,    xy-yx),\n             (yz-zy,    xx-yy-zz, xy+yx,    zx+xz),\n             (zx-xz,    xy+yx,   -xx+yy-zz, yz+zy),\n             (xy-yx,    zx+xz,    yz+zy,   -xx-yy+zz))\n        # quaternion: eigenvector corresponding to most positive eigenvalue\n        l, V = numpy.linalg.eig(N)\n        q = V[:, numpy.argmax(l)]\n        q /= vector_norm(q) # unit quaternion\n        q = numpy.roll(q, -1) # move w component to end\n        # homogeneous transformation matrix\n        M = quaternion_matrix(q)\n\n    # scale: ratio of rms deviations from centroid\n    if scaling:\n        v0 *= v0\n        v1 *= v1\n        M[:3, :3] *= math.sqrt(numpy.sum(v1) / numpy.sum(v0))\n\n    # translation\n    M[:3, 3] = t1\n    T = numpy.identity(4)\n    T[:3, 3] = -t0\n    M = numpy.dot(M, T)\n    return M", "response": "Return matrix to transform given vector set into second vector set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning quaternion about axis.", "response": "def quaternion_about_axis(angle, axis):\n    \"\"\"Return quaternion for rotation about axis.\n\n    >>> q = quaternion_about_axis(0.123, (1, 0, 0))\n    >>> numpy.allclose(q, [0.06146124, 0, 0, 0.99810947])\n    True\n\n    \"\"\"\n    quaternion = numpy.zeros((4, ), dtype=numpy.float64)\n    quaternion[:3] = axis[:3]\n    qlen = vector_norm(quaternion)\n    if qlen > _EPS:\n        quaternion *= math.sin(angle/2.0) / qlen\n    quaternion[3] = math.cos(angle/2.0)\n    return quaternion"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning quaternion from rotation matrix.", "response": "def quaternion_from_matrix(matrix):\n    \"\"\"Return quaternion from rotation matrix.\n\n    >>> R = rotation_matrix(0.123, (1, 2, 3))\n    >>> q = quaternion_from_matrix(R)\n    >>> numpy.allclose(q, [0.0164262, 0.0328524, 0.0492786, 0.9981095])\n    True\n\n    \"\"\"\n    q = numpy.empty((4, ), dtype=numpy.float64)\n    M = numpy.array(matrix, dtype=numpy.float64, copy=False)[:4, :4]\n    t = numpy.trace(M)\n    if t > M[3, 3]:\n        q[3] = t\n        q[2] = M[1, 0] - M[0, 1]\n        q[1] = M[0, 2] - M[2, 0]\n        q[0] = M[2, 1] - M[1, 2]\n    else:\n        i, j, k = 0, 1, 2\n        if M[1, 1] > M[0, 0]:\n            i, j, k = 1, 2, 0\n        if M[2, 2] > M[i, i]:\n            i, j, k = 2, 0, 1\n        t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n        q[i] = t\n        q[j] = M[i, j] + M[j, i]\n        q[k] = M[k, i] + M[i, k]\n        q[3] = M[k, j] - M[j, k]\n    q *= 0.5 / math.sqrt(t * M[3, 3])\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning conjugate of quaternion.", "response": "def quaternion_conjugate(quaternion):\n    \"\"\"Return conjugate of quaternion.\n\n    >>> q0 = random_quaternion()\n    >>> q1 = quaternion_conjugate(q0)\n    >>> q1[3] == q0[3] and all(q1[:3] == -q0[:3])\n    True\n\n    \"\"\"\n    return numpy.array((-quaternion[0], -quaternion[1],\n                        -quaternion[2], quaternion[3]), dtype=numpy.float64)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_quaternion(rand=None):\n    if rand is None:\n        rand = numpy.random.rand(3)\n    else:\n        assert len(rand) == 3\n    r1 = numpy.sqrt(1.0 - rand[0])\n    r2 = numpy.sqrt(rand[0])\n    pi2 = math.pi * 2.0\n    t1 = pi2 * rand[1]\n    t2 = pi2 * rand[2]\n    return numpy.array((numpy.sin(t1)*r1,\n                        numpy.cos(t1)*r1,\n                        numpy.sin(t2)*r2,\n                        numpy.cos(t2)*r2), dtype=numpy.float64)", "response": "Return uniform random unit quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arcball_map_to_sphere(point, center, radius):\n    v = numpy.array(((point[0] - center[0]) / radius,\n                     (center[1] - point[1]) / radius,\n                     0.0), dtype=numpy.float64)\n    n = v[0]*v[0] + v[1]*v[1]\n    if n > 1.0:\n        v /= math.sqrt(n) # position outside of sphere\n    else:\n        v[2] = math.sqrt(1.0 - n)\n    return v", "response": "Return unit sphere coordinates from arcball window coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning ndarray normalized by length i. e. eucledian norm along axis.", "response": "def unit_vector(data, axis=None, out=None):\n    \"\"\"Return ndarray normalized by length, i.e. eucledian norm, along axis.\n\n    >>> v0 = numpy.random.random(3)\n    >>> v1 = unit_vector(v0)\n    >>> numpy.allclose(v1, v0 / numpy.linalg.norm(v0))\n    True\n    >>> v0 = numpy.random.rand(5, 4, 3)\n    >>> v1 = unit_vector(v0, axis=-1)\n    >>> v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=2)), 2)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> v1 = unit_vector(v0, axis=1)\n    >>> v2 = v0 / numpy.expand_dims(numpy.sqrt(numpy.sum(v0*v0, axis=1)), 1)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> v1 = numpy.empty((5, 4, 3), dtype=numpy.float64)\n    >>> unit_vector(v0, axis=1, out=v1)\n    >>> numpy.allclose(v1, v2)\n    True\n    >>> list(unit_vector([]))\n    []\n    >>> list(unit_vector([1.0]))\n    [1.0]\n\n    \"\"\"\n    if out is None:\n        data = numpy.array(data, dtype=numpy.float64, copy=True)\n        if data.ndim == 1:\n            data /= math.sqrt(numpy.dot(data, data))\n            return data\n    else:\n        if out is not data:\n            out[:] = numpy.array(data, copy=False)\n        data = out\n    length = numpy.atleast_1d(numpy.sum(data*data, axis))\n    numpy.sqrt(length, length)\n    if axis is not None:\n        length = numpy.expand_dims(length, axis)\n    data /= length\n    if out is None:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concatenate_matrices(*matrices):\n    M = numpy.identity(4)\n    for i in matrices:\n        M = numpy.dot(M, i)\n    return M", "response": "Return concatenation of series of transformation matrices."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry import all public attributes from module into global namespace.", "response": "def _import_module(module_name, warn=True, prefix='_py_', ignore='_'):\n    \"\"\"Try import all public attributes from module into global namespace.\n\n    Existing attributes with name clashes are renamed with prefix.\n    Attributes starting with underscore are ignored by default.\n\n    Return True on successful import.\n\n    \"\"\"\n    try:\n        module = __import__(module_name)\n    except ImportError:\n        if warn:\n            warnings.warn(\"Failed to import module \" + module_name)\n    else:\n        for attr in dir(module):\n            if ignore and attr.startswith(ignore):\n                continue\n            if prefix:\n                if attr in globals():\n                    globals()[prefix + attr] = globals()[attr]\n                elif warn:\n                    warnings.warn(\"No Python implementation of \" + attr)\n            globals()[attr] = getattr(module, attr)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_numpy_obj_hook(dct):\n    if isinstance(dct, dict) and '__ndarray__' in dct:\n        data = np.asarray(dct['__ndarray__'], dtype=dct['dtype'])\n        return data.reshape(dct['shape'])\n    return dct", "response": "Decodes a previously encoded numpy ndarray with proper shape and dtype."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(*args, **kwargs):\n    kwargs.update(dict(cls=NumpyEncoder,\n                       sort_keys=True,\n                       indent=4,\n                       separators=(',', ': ')))\n    return _json.dump(*args, **kwargs)", "response": "Dump a numpy. ndarray to file stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an numpy. ndarray from a file stream.", "response": "def load(*args, **kwargs):\n    \"\"\"Load an numpy.ndarray from a file stream.\n\n    This works exactly like the usual `json.load()` function,\n    but it uses our custom deserializer.\n    \"\"\"\n    kwargs.update(dict(object_hook=json_numpy_obj_hook))\n    return _json.load(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return dict(__ndarray__=obj.tolist(),\n                        dtype=str(obj.dtype),\n                        shape=obj.shape)\n        # Let the base class default method raise the TypeError\n        return _json.JSONEncoder(self, obj)", "response": "Converts an ndarray into a dictionary for efficient serialization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_dataset_statistics(dataset_path,\n                               output_path,\n                               config):\n    \"\"\"\n    Compute the statistics of fields of a TensorDataset\n\n    Parameters\n    ----------\n    dataset_path : str\n        path to the dataset\n    output_dir : str\n        where to save the data\n    config : :obj:`YamlConfig`\n        parameters for the analysis\n    \"\"\"\n    # parse config\n    analysis_fields = config['analysis_fields']\n    num_percentiles = config['num_percentiles']\n    thresholds = config['thresholds']\n    log_rate = config['log_rate']\n\n    num_bins = config['num_bins']\n    font_size = config['font_size']\n    line_width = config['line_width']\n    dpi = config['dpi']\n    \n    # create dataset for the aggregated results\n    dataset = TensorDataset.open(dataset_path)\n    num_datapoints = dataset.num_datapoints\n\n    # allocate buffers\n    analysis_data = {}\n    for field in analysis_fields:\n        analysis_data[field] = []\n\n    # loop through dataset\n    for i in range(num_datapoints):\n        if i % log_rate == 0:\n            logging.info('Reading datapoint %d of %d' %(i+1, num_datapoints))\n\n        # read datapoint\n        datapoint = dataset.datapoint(i, analysis_fields)\n        for key, value in datapoint.iteritems():\n            analysis_data[key].append(value)\n\n    # create output CSV\n    stats_headers = {\n        'name': 'str',\n        'mean': 'float',\n        'median': 'float',\n        'std': 'float'\n    }    \n    for i in range(num_percentiles):\n        pctile = int((100.0 / num_percentiles) * i)\n        field = '%d_pctile' %(pctile)\n        stats_headers[field] = 'float'\n    for t in thresholds:\n        field = 'pct_above_%.3f' %(t)\n        stats_headers[field] = 'float'\n    \n    # analyze statistics\n    for field, data in analysis_data.iteritems():\n        # init arrays\n        data = np.array(data)\n\n        # init filename\n        stats_filename = os.path.join(output_path, '%s_stats.json' %(field))\n        if os.path.exists(stats_filename):\n            logging.warning('Statistics file %s exists!' %(stats_filename))\n        \n        # stats\n        mean = np.mean(data)\n        median = np.median(data)\n        std = np.std(data)\n        stats = {\n            'name': str(field),\n            'mean': float(mean),\n            'median': float(median),\n            'std': float(std),\n        }\n        for i in range(num_percentiles):\n            pctile = int((100.0 / num_percentiles) * i)\n            pctile_field = '%d_pctile' %(pctile)\n            stats[pctile_field] = float(np.percentile(data, pctile))\n        for t in thresholds:\n            t_field = 'pct_above_%.3f' %(t)\n            stats[t_field] = float(np.mean(1 * (data > t)))\n        json.dump(stats,\n                  open(stats_filename, 'w'),\n                  indent=2,\n                  sort_keys=True)\n                  \n        # histogram\n        num_unique = np.unique(data).shape[0]\n        nb = min(num_bins, data.shape[0], num_unique)\n        bounds = (np.min(data), np.max(data))\n        vis2d.figure()\n        utils.histogram(data,\n                        nb,\n                        bounds,\n                        normalized=False,\n                        plot=True)\n        vis2d.xlabel(field, fontsize=font_size)\n        vis2d.ylabel('Count', fontsize=font_size)\n        data_filename = os.path.join(output_path, 'histogram_%s.pdf' %(field))\n        vis2d.show(data_filename, dpi=dpi)", "response": "Compute statistics of fields of a TensorDataset and save it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _preallocate_samples(self):\n        self.prealloc_samples_ = []\n        for i in range(self.num_prealloc_samples_):\n            self.prealloc_samples_.append(self.sample())", "response": "Preallocate samples for faster adaptive sampling."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples the random variable using the preallocated samples if possible.", "response": "def rvs(self, size=1, iteration=1):\n        \"\"\"Sample the random variable, using the preallocated samples if\n        possible.\n\n        Parameters\n        ----------\n        size : int\n            The number of samples to generate.\n\n        iteration : int\n            The location in the preallocated sample array to start sampling\n            from.\n\n        Returns\n        -------\n        :obj:`numpy.ndarray` of float or int\n            The samples of the random variable. If `size == 1`, then\n            the returned value will not be wrapped in an array.\n        \"\"\"\n        if self.num_prealloc_samples_ > 0:\n            samples = []\n            for i in range(size):\n                samples.append(self.prealloc_samples_[(iteration + i) % self.num_prealloc_samples_])\n            if size == 1:\n                return samples[0]\n            return samples\n        # generate a new sample\n        return self.sample(size=size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample(self, size=1):\n        samples = scipy.stats.bernoulli.rvs(self.p, size=size)\n        if size == 1:\n            return samples[0]\n        return samples", "response": "Generate samples of the random variable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample(self, size=1):\n        samples = scipy.stats.multivariate_normal.rvs(self.mu, self.sigma, size=size)\n        return samples", "response": "Generate samples of the random variable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sample(self, size=1):\n        samples = []\n        for i in range(size):\n            # sample random pose\n            xi = self._r_xi_rv.rvs(size=1)\n            S_xi = skew(xi)\n            R_sample = scipy.linalg.expm(S_xi)\n            t_sample = self._t_rv.rvs(size=1)\n            samples.append(RigidTransform(rotation=R_sample,\n                                          translation=t_sample,\n                                          from_frame=self._from_frame,\n                                          to_frame=self._to_frame))\n\n        # not a list if only 1 sample\n        if size == 1 and len(samples) > 0:\n            return samples[0]\n        return samples", "response": "Sample rigid transform random variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart recording the specified recording of the specified ISO - 8601 ISO - 8601 ISO - 8601 ISO - 8601 objects.", "response": "def _start_recording(self, *args, **kwargs):\n        \"\"\" Starts recording\n        Parameters\n        ----------\n            *args : any\n                    Ordinary args used for calling the specified data sampler method\n            **kwargs : any\n                    Keyword args used for calling the specified data sampler method\n        \"\"\"\n        while not self._cmds_q.empty():\n            self._cmds_q.get_nowait()\n        while not self._data_qs[self._cur_data_segment].empty():\n            self._data_qs[self._cur_data_segment].get_nowait()\n\n        self._args = args\n        self._kwargs = kwargs\n\n        self._recording = True\n        self.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _flush(self):\n        if self._recording:\n            raise Exception(\"Cannot flush data queue while recording!\")\n        if self._saving_cache:\n            logging.warn(\"Flush when using cache means unsaved data will be lost and not returned!\")\n            self._cmds_q.put((\"reset_data_segment\",))\n        else:\n            data = self._extract_q(0)\n            return data", "response": "Flushes the data queue and returns a list of all current data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _stop(self):\n        self._pause()\n        self._cmds_q.put((\"stop\",))\n        try:\n            self._recorder.terminate()\n        except Exception:\n            pass\n        self._recording = False", "response": "Stops recording. Returns all recorded data and their timestamps. Destroys recorder process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting directory root appending the path separator to subdirs.", "response": "def _listdir(self, root):\n        \"List directory 'root' appending the path separator to subdirs.\"\n        res = []\n        for name in os.listdir(root):\n            path = os.path.join(root, name)\n            if os.path.isdir(path):\n                name += os.sep\n            res.append(name)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef complete(self, text, state):\n        \"Generic readline completion entry point.\"\n\n        # dexnet entity tab completion\n        results = [w for w in self.words if w.startswith(text)] + [None]\n        if results != [None]:\n            return results[state]\n\n        buffer = readline.get_line_buffer()\n        line = readline.get_line_buffer().split()\n\n        # dexnet entity tab completion\n        results =  [w for w in self.words if w.startswith(text)] + [None]\n        if results != [None]:\n            return results[state]\n\n        # account for last argument ending in a space\n        if RE_SPACE.match(buffer):\n            line.append('')\n\n        return (self.complete_extra(line) + [None])[state]", "response": "Generic readline completion entry point."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the absolute value of the angle between two 3D vectors.", "response": "def abs_angle_diff(v_i, v_j):\n    \"\"\" \n    Returns the absolute value of the angle between two 3D vectors.\n    \n    Parameters\n    ----------\n    v_i : :obj:`numpy.ndarray`\n        the first 3D array\n    v_j : :obj:`numpy.ndarray`\n        the second 3D array\n    \"\"\"\n    # compute angle distance\n    dot_prod = min(max(v_i.dot(v_j), -1), 1)\n    angle_diff = np.arccos(dot_prod)\n    return np.abs(angle_diff)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop all the data stream recorders and terminate the syncer process.", "response": "def stop(self):\n        \"\"\" Stops syncer operations. Destroys syncer process. \"\"\"\n        self._cmds_q.put((\"stop\",))\n        for recorder in self._data_stream_recorders:\n            recorder._stop()\n        try:\n            self._syncer.terminate()\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure_root():\n    root_logger = logging.getLogger()\n\n    # clear any existing handles to streams because we don't want duplicate logs\n    # NOTE: we assume that any stream handles we find are to ROOT_LOG_STREAM, which is usually the case(because it is stdout). This is fine because we will be re-creating that handle. Otherwise we might be deleting a handle that won't be re-created, which could result in dropped logs.\n    for hdlr in root_logger.handlers:\n        if isinstance(hdlr, logging.StreamHandler):\n            root_logger.removeHandler(hdlr)\n\n    # configure the root logger\n    root_logger.setLevel(ROOT_LOG_LEVEL)\n    hdlr = logging.StreamHandler(ROOT_LOG_STREAM) \n    formatter = colorlog.ColoredFormatter(\n                        '%(purple)s%(name)-10s %(log_color)s%(levelname)-8s%(reset)s %(white)s%(message)s',\n                        reset=True,\n                        log_colors={\n                            'DEBUG': 'cyan',\n                            'INFO': 'green',\n                            'WARNING': 'yellow',\n                            'ERROR': 'red',\n                            'CRITICAL': 'red,bg_white',\n                        } \n                                         )   \n    hdlr.setFormatter(formatter)\n    root_logger.addHandler(hdlr)", "response": "Configure the root logger."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a log file to the root logger.", "response": "def add_root_log_file(log_file):\n    \"\"\"\n    Add a log file to the root logger.\n\n    Parameters\n    ----------\n    log_file :obj:`str`\n        The path to the log file.\n    \"\"\"\n    root_logger = logging.getLogger()\n\n    # add a file handle to the root logger\n    hdlr = logging.FileHandler(log_file)\n    formatter = logging.Formatter('%(asctime)s %(name)-10s %(levelname)-8s %(message)s', datefmt='%m-%d %H:%M:%S')\n    hdlr.setFormatter(formatter)\n    root_logger.addHandler(hdlr)\n    root_logger.info('Root logger now logging to {}'.format(log_file))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_logger(name, log_level=logging.INFO, log_file=None, global_log_file=False, silence=False):\n        no_op = False\n        # some checks for silencing/no-op logging\n        if silence and global_log_file:\n            raise ValueError(\"You can't silence a logger and log to a global log file!\")\n        if silence and log_file is None:\n            logging.warning('You are creating a no-op logger!')\n            no_op = True\n\n        # configure the root logger if it hasn't been already\n        if not Logger.ROOT_CONFIGURED:\n            configure_root()\n        Logger.ROOT_CONFIGURED = True\n        \n        # build a logger\n        logger = logging.getLogger(name)\n        logger.setLevel(log_level)\n\n        # silence the logger by preventing it from propagating upwards to the root\n        logger.propagate = not silence\n\n        # configure the log file stream \n        if log_file is not None:\n            # if the log file is global, add it to the root logger\n            if global_log_file:\n                add_root_log_file(log_file)\n            # otherwise add it to this particular logger\n            else:\n                hdlr = logging.FileHandler(log_file)\n                formatter = logging.Formatter('%(asctime)s %(name)-10s %(levelname)-8s %(message)s', datefmt='%m-%d %H:%M:%S')\n                hdlr.setFormatter(formatter)\n                logger.addHandler(hdlr)\n\n        # add a no-op handler to suppress warnings about there being no handlers\n        if no_op:\n            logger.addHandler(logging.NullHandler())\n        return logger", "response": "Creates a logger with the given name and level."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_log_file(logger, log_file, global_log_file=False):\n\n        if global_log_file:\n            add_root_log_file(log_file)\n        else:\n            hdlr = logging.FileHandler(log_file)\n            formatter = logging.Formatter('%(asctime)s %(name)-10s %(levelname)-8s %(message)s', datefmt='%m-%d %H:%M:%S')\n            hdlr.setFormatter(formatter)\n            logger.addHandler(hdlr)", "response": "Adds a log file to the given logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting or create a profile from a module and return it.", "response": "def get_module_profile(module, name=None):\n  \"\"\"\n  Get or create a profile from a module and return it.\n\n  If the name `module.profile` is present the value of that is returned.\n  Otherwise, if the name `module.profile_factory` is present, a new profile\n  is created using `module.profile_factory` and then `profile.auto_register`\n  is called with the module namespace.\n  If neither name is defined, the module is not considered a profile-module\n  and None is returned.\n\n  TODO: describe the `name` argument and better define the signature of `profile_factory`.\n\n  The `module` argument is expected to behave like a python module.\n  The optional `name` argument is used when `profile_factory` is called to\n  give a name to the default section of the new profile. If name is not\n  present `module.__name__` is the fallback.\n\n  `profile_factory` is called like this:\n      `profile = module.profile_factory(default_section=default_section)`\n\n  \"\"\"\n  try:\n    # if profile is defined we just use it\n    return module.profile\n  except AttributeError: # > 'module' object has no attribute 'profile'\n    # try to create one on the fly.\n    # e.g. module.__name__ == \"fontbakery.profiles.cmap\"\n    if 'profile_factory' not in module.__dict__:\n      return None\n    default_section = Section(name or module.__name__)\n    profile = module.profile_factory(default_section=default_section)\n    profile.auto_register(module.__dict__)\n    return profile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the iterargs as a dictionary", "response": "def iterargs(self):\n    \"\"\" uses the singular name as key \"\"\"\n    iterargs = OrderedDict()\n    for name in self._iterargs:\n      plural = self._profile.iterargs[name]\n      iterargs[name] = tuple(self._values[plural])\n    return iterargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_result(self, result):\n    if not isinstance(result, tuple):\n      return (FAIL, APIViolationError(\n        'Result must be a tuple but '\n        'it is {}.'.format(type(result)), result))\n\n    if len(result) != 2:\n      return (FAIL, APIViolationError(\n        'Result must have 2 items, but it '\n        'has {}.'.format(len(result)), result))\n\n    status, message = result\n    # Allow booleans, but there's no way to issue a WARNING\n    if isinstance(status, bool):\n      # normalize\n      status = PASS if status else FAIL\n      result = (status, message)\n\n    if not isinstance(status, Status):\n      return (FAIL, APIViolationError(\n        'Result item `status` must be an instance of '\n        'Status, but it is {} a {}.'.format(status, type(status)), result))\n\n    return result", "response": "Check that the check returned a well formed result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _exec_check(self, check: FontbakeryCallable, args: Dict[str, Any]):\n    try:\n      # A check can be either a normal function that returns one Status or a\n      # generator that yields one or more. The latter will return a generator\n      # object that we can detect with types.GeneratorType.\n      result = check(**args)  # Might raise.\n\n      if isinstance(result, types.GeneratorType):\n        # Iterate over sub-results one-by-one, list(result) would abort on\n        # encountering the first exception.\n        for sub_result in result:  # Might raise.\n          yield self._check_result(sub_result)\n        return  # Do not fall through to rest of method.\n    except Exception as e:\n      error = FailedCheckError(e)\n      result = (ERROR, error)\n\n    yield self._check_result(result)", "response": "Yields check sub - results."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_iterarg(self, name, index):\n    plural = self._profile.iterargs[name]\n    return self._values[plural][index]", "response": "Used by eg. reporters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the order is a subset of the base order.", "response": "def check_order(self, order):\n    \"\"\"\n      order must be a subset of self.order\n    \"\"\"\n    own_order = self.order\n    for item in order:\n      if item not in own_order:\n        raise ValueError(f'Order item {item} not found.')\n    return order"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a check to the internal list of checks.", "response": "def add_check(self, check):\n    \"\"\"\n    Please use rather `register_check` as a decorator.\n    \"\"\"\n    if self._add_check_callback is not None:\n      if not self._add_check_callback(self, check):\n        # rejected, skip!\n        return False\n\n    self._checkid2index[check.id] = len(self._checks)\n    self._checks.append(check)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_section(self, section, filter_func=None):\n    for check in section.checks:\n      if filter_func and not filter_func(check):\n        continue\n      self.add_check(check)", "response": "Add section. checks to self."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_values(self, values):\n    format_message = '{}: {} (value: {})'.format\n    messages = []\n    for name, value in values.items():\n      if name not in self.expected_values:\n        continue\n      valid, message = self.expected_values[name].validate(value)\n      if valid:\n        continue\n      messages.append(format_message(name, message, value))\n    if len(messages):\n      return False, '\\n'.join(messages)\n    return True, None", "response": "Validate the given dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_aggregate_args(self, item, key):\n    if not key in ('args', 'mandatoryArgs'):\n      raise TypeError('key must be \"args\" or \"mandatoryArgs\", got {}').format(key)\n    dependencies = list(getattr(item, key))\n    if hasattr(item, 'conditions'):\n      dependencies += [name for negated, name in map(is_negated, item.conditions)]\n    args = set()\n    while dependencies:\n      name = dependencies.pop()\n      if name in args:\n        continue\n      args.add(name)\n      # if this is a condition, expand its dependencies\n      c = self.conditions.get(name, None)\n      if c is None:\n        continue\n      dependencies += [dependency for dependency in getattr(c, key)\n                                              if dependency not in args]\n    return args", "response": "Get all arguments or mandatory arguments of the item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_iterargs(self, item):\n    # iterargs should always be mandatory, unless there's a good reason\n    # not to, which I can't think of right now.\n\n    args = self._get_aggregate_args(item, 'mandatoryArgs')\n    return tuple(sorted([arg for arg in args if arg in self.iterargs]))", "response": "Returns a tuple of all iterags for item sorted by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _section_execution_order(self, section, iterargs\n                             , reverse=False\n                             , custom_order=None\n                             , explicit_checks: Iterable = None\n                             , exclude_checks: Iterable = None):\n    \"\"\"\n      order must:\n        a) contain all variable args (we're appending missing ones)\n        b) not contian duplictates (we're removing repeated items)\n\n      order may contain *iterargs otherwise it is appended\n      to the end\n\n      order may contain \"*check\" otherwise, it is like *check is appended\n      to the end (Not done explicitly though).\n    \"\"\"\n    stack = list(custom_order) if custom_order is not None else list(section.order)\n    if '*iterargs' not in stack:\n      stack.append('*iterargs')\n    stack.reverse()\n\n    full_order = []\n    seen = set()\n    while len(stack):\n      item = stack.pop()\n      if item in seen:\n        continue\n      seen.add(item)\n      if item == '*iterargs':\n        all_iterargs = list(iterargs.keys())\n        # assuming there is a meaningful order\n        all_iterargs.reverse()\n        stack += all_iterargs\n        continue\n      full_order.append(item)\n\n    # Filter down checks. Checks to exclude are filtered for last as the user\n    # might e.g. want to include all tests with \"kerning\" in the ID, except for\n    # \"kerning_something\". explicit_checks could then be [\"kerning\"] and\n    # exclude_checks [\"something\"].\n    checks = section.checks\n    if explicit_checks:\n      checks = [\n          check for check in checks\n          if any(include_string in check.id for include_string in explicit_checks)\n      ]\n    if exclude_checks:\n      checks = [\n          check for check in checks\n          if not any(exclude_string in check.id for exclude_string in exclude_checks)\n      ]\n\n    scopes = self._analyze_checks(full_order, checks)\n    key = lambda item: item[1] # check, signature, scope = item\n    scopes.sort(key=key, reverse=reverse)\n\n    for check, args in self._execute_scopes(iterargs, scopes):\n      # this is the iterargs tuple that will be used as a key for caching\n      # and so on. we could sort it, to ensure it yields in the same\n      # cache locations always, but then again, it is already in a well\n      # defined order, by clustering.\n      yield check, tuple(args)", "response": "Internal method to order the items in a section in a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_check(self, section=None, *args, **kwds):\n    if section and len(kwds) == 0 and callable(section):\n      func = section\n      section = self._default_section\n      return self._add_check(section, func)\n    else:\n      return partial(self._add_check, section)", "response": "Register a check in a section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new condition to the sequence.", "response": "def register_condition(self, *args, **kwds):\n    \"\"\"\n    Usage:\n\n    @profile.register_condition\n    @condition\n    def myCondition():\n      return 123\n\n    #or\n\n    @profile.register_condition(name='my_condition')\n    @condition\n    def myCondition():\n      return 123\n    \"\"\"\n    if len(args) == 1 and len(kwds) == 0 and callable(args[0]):\n      return self._add_condition(args[0])\n    else:\n      return partial(self._add_condition, *args, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the profile_imports from the symbol_table.", "response": "def _load_profile_imports(self, symbol_table):\n    \"\"\"\n    profile_imports is a list of module names or tuples\n    of (module_name, names to import)\n    in the form of ('.', names) it behaces like:\n    from . import name1, name2, name3\n    or similarly\n    import .name1, .name2, .name3\n\n    i.e. \"name\" in names becomes \".name\"\n    \"\"\"\n    results = []\n    if 'profile_imports' not in symbol_table:\n      return results\n\n    package = self._get_package(symbol_table)\n    profile_imports = symbol_table['profile_imports']\n\n    for item in profile_imports:\n      if isinstance(item, str):\n        # import the whole module\n        module_name, names = (item, None)\n      else:\n        # expecting a 2 items tuple or list\n        # import only the names from the module\n        module_name, names = item\n\n      if '.' in module_name and len(set(module_name)) == 1  and names is not None:\n        # if you execute `from . import mod` from a module in the pkg package\n        # then you will end up importing pkg.mod\n        module_names = [f'{module_name}{name}' for name in names]\n        names = None\n      else:\n        module_names = [module_name]\n\n      for module_name in module_names:\n        module = importlib.import_module(module_name, package=package)\n        if names is None:\n          results.append(module)\n        else:\n          #  1. check if the imported module has an attribute by that name\n          #  2. if not, attempt to import a submodule with that name\n          #  3. if the attribute is not found, ImportError is raised.\n          #  \u2026\n          for name in names:\n            try:\n              results.append(getattr(module, name))\n            except AttributeError:\n              # attempt to import a submodule with that name\n              sub_module_name = '.'.join([module_name, name])\n              sub_module = importlib.import_module(sub_module_name, package=package)\n              results.append(sub_module)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto_register(self, symbol_table, filter_func=None, profile_imports=None):\n    if profile_imports:\n      symbol_table = symbol_table.copy()  # Avoid messing with original table\n      symbol_table['profile_imports'] = profile_imports\n\n    all_items = list(symbol_table.values()) + self._load_profile_imports(symbol_table)\n    namespace_types = (FontBakeryCondition, FontBakeryExpectedValue)\n    namespace_items = []\n\n    for item in all_items:\n      if isinstance(item, namespace_types):\n        # register these after all modules have been registered. That way,\n        # \"local\" items can optionally force override items registered\n        # previously by modules.\n        namespace_items.append(item)\n      elif isinstance(item, FontBakeryCheck):\n        if filter_func and not filter_func('check', item.id, item):\n          continue\n        self.register_check(item)\n      elif isinstance(item, types.ModuleType):\n        if filter_func and not filter_func('module', item.__name__, item):\n          continue\n        profile = get_module_profile(item)\n        if profile:\n          self.merge_profile(profile, filter_func=filter_func)\n\n    for item in namespace_items:\n      if isinstance(item, FontBakeryCondition):\n        if filter_func and not filter_func('condition', item.name, item):\n          continue\n        self.register_condition(item)\n      elif isinstance(item, FontBakeryExpectedValue):\n        if filter_func and not filter_func('expected_value', item.name, item):\n          continue\n        self.register_expected_value(item)", "response": "Register items from symbol_table in the profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_profile(self, profile, filter_func=None):\n    # 'iterargs', 'derived_iterables', 'aliases', 'conditions', 'expected_values'\n    for ns_type in self._valid_namespace_types:\n      # this will raise a NamespaceError if an item of profile.{ns_type}\n      # is already registered.\n      ns_dict = getattr(profile, ns_type)\n      if filter_func:\n        ns_type_singular = self._valid_namespace_types[ns_type]\n        ns_dict = {name:item for name,item in ns_dict.items()\n                        if filter_func(ns_type_singular, name, item)}\n      self._add_dict_to_namespace(ns_type, ns_dict)\n\n    check_filter_func = None if not filter_func else \\\n                      lambda check: filter_func('check', check.id, check)\n    for section in profile.sections:\n      my_section = self._sections.get(str(section), None)\n      if not len(section.checks):\n        continue\n      if my_section is None:\n        # create a new section: don't change other module/profile contents\n        my_section = section.clone(check_filter_func)\n        self.add_section(my_section)\n      else:\n        # order, description are not updated\n        my_section.merge_section(section, check_filter_func)", "response": "Copy all namespace items from a profile into this profile."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a json string that can also be used as a key.", "response": "def serialize_identity(self, identity):\n    \"\"\" Return a json string that can also  be used as a key.\n\n    The JSON is explicitly unambiguous in the item order\n    entries (dictionaries are not ordered usually)\n    Otherwise it is valid JSON\n    \"\"\"\n    section, check, iterargs = identity\n    values = map(\n        # separators are without space, which is the default in JavaScript;\n        # just in case we need to make these keys in JS.\n        partial(json.dumps, separators=(',', ':'))\n        # iterargs are sorted, because it doesn't matter for the result\n        # but it gives more predictable keys.\n        # Though, arguably, the order generated by the profile is also good\n        # and conveys insights on how the order came to be (clustering of\n        # iterargs). `sorted(iterargs)` however is more robust over time,\n        # the keys will be the same, even if the sorting order changes.\n      , [str(section), check.id, sorted(iterargs)]\n    )\n    return '{{\"section\":{},\"check\":{},\"iterargs\":{}}}'.format(*values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_profile():\n  argument_parser = ThrowingArgumentParser(add_help=False)\n  argument_parser.add_argument('profile')\n  try:\n    args, _ = argument_parser.parse_known_args()\n  except ArgumentParserError:\n    # silently fails, the main parser will show usage string.\n    return Profile()\n  imported = get_module(args.profile)\n  profile = get_module_profile(imported)\n  if not profile:\n    raise Exception(f\"Can't get a profile from {imported}.\")\n  return profile", "response": "Get the profile module from the current project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollating individual fonts data into a single glyph data list.", "response": "def collate_fonts_data(fonts_data):\n    \"\"\"Collate individual fonts data into a single glyph data list.\"\"\"\n    glyphs = {}\n\n    for family in fonts_data:\n        for glyph in family:\n            if glyph['unicode'] not in glyphs:\n                glyphs[glyph['unicode']] = glyph\n            else:\n                c = glyphs[glyph['unicode']]['contours']\n                glyphs[glyph['unicode']]['contours'] = c | glyph['contours']\n    return glyphs.values()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _quick_and_dirty_glyph_is_empty(font, glyph_name):\n    if 'glyf' in font:\n        glyph = font['glyf'][glyph_name]\n        if not glyph.isComposite():\n            if glyph.numberOfContours == 0:\n                return True\n        return False\n    elif 'CFF2' in font:\n        top_dict = font['CFF2'].cff.topDictIndex[0]\n    else:\n        top_dict = font['CFF '].cff.topDictIndex[0]\n    char_strings = top_dict.CharStrings\n    char_string = char_strings[glyph_name]\n    if len(char_string.bytecode) <= 1:\n        return True\n    return False", "response": "This method is used to test if a glyph is empty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nletter in font have glyphs that are not empty?", "response": "def com_adobe_fonts_check_find_empty_letters(ttFont):\n    \"\"\"Letters in font have glyphs that are not empty?\"\"\"\n    cmap = ttFont.getBestCmap()\n    passed = True\n\n    # http://unicode.org/reports/tr44/#General_Category_Values\n    letter_categories = {\n        'Ll', 'Lm', 'Lo', 'Lt', 'Lu',\n    }\n    invisible_letters = {\n        0x115F, 0x1160, 0x3164, 0xFFA0,  # Hangul filler chars (category='Lo')\n    }\n    for unicode_val, glyph_name in cmap.items():\n        category = unicodedata.category(chr(unicode_val))\n        if (_quick_and_dirty_glyph_is_empty(ttFont, glyph_name)) \\\n                and (category in letter_categories) \\\n                and (unicode_val not in invisible_letters):\n            yield FAIL, \\\n                (\"U+%04X should be visible, but its glyph ('%s') is empty.\"\n                 % (unicode_val, glyph_name))\n            passed = False\n    if passed:\n        yield PASS, \"No empty glyphs for letters found.\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking name table for empty records.", "response": "def com_adobe_fonts_check_name_empty_records(ttFont):\n    \"\"\"Check name table for empty records.\"\"\"\n    failed = False\n    for name_record in ttFont['name'].names:\n        name_string = name_record.toUnicode().strip()\n        if len(name_string) == 0:\n            failed = True\n            name_key = tuple([name_record.platformID, name_record.platEncID,\n                             name_record.langID, name_record.nameID])\n            yield FAIL, (\"'name' table record with key={} is \"\n                         \"empty and should be removed.\"\n                         ).format(name_key)\n    if not failed:\n        yield PASS, (\"No empty name table records found.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_monospace(ttFont, glyph_metrics_stats):\n  from fontbakery.constants import (IsFixedWidth,\n                                    PANOSE_Proportion)\n  failed = False\n  # Note: These values are read from the dict here only to\n  # reduce the max line length in the check implementation below:\n  seems_monospaced = glyph_metrics_stats[\"seems_monospaced\"]\n  most_common_width = glyph_metrics_stats[\"most_common_width\"]\n  width_max = glyph_metrics_stats['width_max']\n\n  if ttFont['hhea'].advanceWidthMax != width_max:\n    failed = True\n    yield FAIL, Message(\"bad-advanceWidthMax\",\n                        (\"Value of hhea.advanceWidthMax\"\n                         \" should be set to {} but got\"\n                         \" {} instead.\"\n                         \"\").format(width_max, ttFont['hhea'].advanceWidthMax))\n  if seems_monospaced:\n    if ttFont['post'].isFixedPitch == IsFixedWidth.NOT_MONOSPACED:\n      failed = True\n      yield FAIL, Message(\"mono-bad-post-isFixedPitch\",\n                          (\"On monospaced fonts, the value of\"\n                           \" post.isFixedPitch must be set to a non-zero value\"\n                           \" (meaning 'fixed width monospaced'),\"\n                           \" but got {} instead.\"\n                           \"\").format(ttFont['post'].isFixedPitch))\n\n    if ttFont['OS/2'].panose.bProportion != PANOSE_Proportion.MONOSPACED:\n      failed = True\n      yield FAIL, Message(\"mono-bad-panose-proportion\",\n                          (\"On monospaced fonts, the value of\"\n                           \" OS/2.panose.bProportion must be set to {}\"\n                           \" (proportion: monospaced), but got\"\n                           \" {} instead.\"\n                           \"\").format(PANOSE_Proportion.MONOSPACED,\n                                      ttFont['OS/2'].panose.bProportion))\n\n    num_glyphs = len(ttFont['glyf'].glyphs)\n    unusually_spaced_glyphs = [\n        g for g in ttFont['glyf'].glyphs\n        if g not in ['.notdef', '.null', 'NULL'] and\n        ttFont['hmtx'].metrics[g][0] != most_common_width\n    ]\n    outliers_ratio = float(len(unusually_spaced_glyphs)) / num_glyphs\n    if outliers_ratio > 0:\n      failed = True\n      yield WARN, Message(\"mono-outliers\",\n                          (\"Font is monospaced but {} glyphs\"\n                           \" ({}%) have a different width.\"\n                           \" You should check the widths of:\"\n                           \" {}\").format(\n                               len(unusually_spaced_glyphs),\n                               100.0 * outliers_ratio, unusually_spaced_glyphs))\n    if not failed:\n      yield PASS, Message(\"mono-good\", (\"Font is monospaced and all\"\n                                        \" related metadata look good.\"))\n  else:\n    # it is a non-monospaced font, so lets make sure\n    # that all monospace-related metadata is properly unset.\n\n    if ttFont['post'].isFixedPitch != IsFixedWidth.NOT_MONOSPACED:\n      failed = True\n      yield FAIL, Message(\"bad-post-isFixedPitch\",\n                          (\"On non-monospaced fonts, the\"\n                           \" post.isFixedPitch value must be set to {}\"\n                           \" (not monospaced), but got {} instead.\"\n                           \"\").format(IsFixedWidth.NOT_MONOSPACED,\n                                      ttFont['post'].isFixedPitch))\n\n    if ttFont['OS/2'].panose.bProportion == PANOSE_Proportion.MONOSPACED:\n      failed = True\n      yield FAIL, Message(\"bad-panose-proportion\",\n                          (\"On non-monospaced fonts, the\"\n                           \" OS/2.panose.bProportion value can be set to \"\n                           \" any value except 9 (proportion: monospaced)\"\n                           \" which is the bad value we got in this font.\"))\n    if not failed:\n      yield PASS, Message(\"good\", (\"Font is not monospaced and\"\n                                   \" all related metadata look good.\"))", "response": "Check that the monospaced metadata for a given font is correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_name_line_breaks(ttFont):\n  failed = False\n  for name in ttFont[\"name\"].names:\n    string = name.string.decode(name.getEncoding())\n    if \"\\n\" in string:\n      failed = True\n      yield FAIL, (\"Name entry {} on platform {} contains\"\n                   \" a line-break.\").format(NameID(name.nameID).name,\n                                            PlatformID(name.platformID).name)\n  if not failed:\n    yield PASS, (\"Name table entries are all single-line\"\n                 \" (no line-breaks found).\")", "response": "Name table entries should not contain line - breaks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_name_match_familyname_fullfont(ttFont):\n  from fontbakery.utils import get_name_entry_strings\n  familyname = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n  fullfontname = get_name_entry_strings(ttFont, NameID.FULL_FONT_NAME)\n\n  if len(familyname) == 0:\n    yield FAIL, Message(\"no-font-family-name\",\n                        (\"Font lacks a NameID.FONT_FAMILY_NAME\"\n                         \" entry in the 'name' table.\"))\n  elif len(fullfontname) == 0:\n    yield FAIL, Message(\"no-full-font-name\",\n                        (\"Font lacks a NameID.FULL_FONT_NAME\"\n                         \" entry in the 'name' table.\"))\n  else:\n    # we probably should check all found values are equivalent.\n    # and, in that case, then performing the rest of the check\n    # with only the first occurences of the name entries\n    # will suffice:\n    fullfontname = fullfontname[0]\n    familyname = familyname[0]\n\n    if not fullfontname.startswith(familyname):\n      yield FAIL, Message(\n          \"does-not\", (\" On the 'name' table, the full font name\"\n                       \" (NameID {} - FULL_FONT_NAME: '{}')\"\n                       \" does not begin with font family name\"\n                       \" (NameID {} - FONT_FAMILY_NAME:\"\n                       \" '{}')\".format(NameID.FULL_FONT_NAME, familyname,\n                                       NameID.FONT_FAMILY_NAME, fullfontname)))\n    else:\n      yield PASS, \"Full font name begins with the font family name.\"", "response": "Does full font name begin with the font family name?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nname table strings must not contain the string Reserved Font Name.", "response": "def com_google_fonts_check_name_rfn(ttFont):\n  \"\"\"Name table strings must not contain the string 'Reserved Font Name'.\"\"\"\n  failed = False\n  for entry in ttFont[\"name\"].names:\n    string = entry.toUnicode()\n    if \"reserved font name\" in string.lower():\n      yield WARN, (\"Name table entry (\\\"{}\\\")\"\n                   \" contains \\\"Reserved Font Name\\\".\"\n                   \" This is an error except in a few specific\"\n                   \" rare cases.\").format(string)\n      failed = True\n  if not failed:\n    yield PASS, (\"None of the name table strings\"\n                 \" contain \\\"Reserved Font Name\\\".\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nname table PostScript name must match CFF table FontName.", "response": "def com_adobe_fonts_check_name_postscript_vs_cff(ttFont):\n  \"\"\"CFF table FontName must match name table ID 6 (PostScript name).\"\"\"\n  failed = False\n  cff_names = ttFont['CFF '].cff.fontNames\n  if len(cff_names) != 1:\n    yield ERROR, (\"Unexpected number of font names in CFF table.\")\n    return\n  cff_name = cff_names[0]\n  for entry in ttFont['name'].names:\n    if entry.nameID == NameID.POSTSCRIPT_NAME:\n        postscript_name = entry.toUnicode()\n        if postscript_name != cff_name:\n          yield FAIL, (\"Name table PostScript name '{}' \"\n                       \"does not match CFF table FontName '{}'.\"\n                       .format(postscript_name, cff_name))\n          failed = True\n\n  if not failed:\n    yield PASS, (\"Name table PostScript name matches CFF table FontName.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_adobe_fonts_check_name_postscript_name_consistency(ttFont):\n  postscript_names = set()\n  for entry in ttFont['name'].names:\n    if entry.nameID == NameID.POSTSCRIPT_NAME:\n      postscript_name = entry.toUnicode()\n      postscript_names.add(postscript_name)\n\n  if len(postscript_names) > 1:\n    yield FAIL, (\"Entries in the 'name' table for ID 6 (PostScript name) are \"\n                 \"not consistent. Names found: {}.\"\n                 .format(sorted(postscript_names)))\n  else:\n    yield PASS, (\"Entries in the 'name' table for ID 6 \"\n                 \"(PostScript name) are consistent.\")", "response": "Name table ID 6 must be consistent across platforms."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_adobe_fonts_check_family_max_4_fonts_per_family_name(ttFonts):\n  from collections import Counter\n  from fontbakery.utils import get_name_entry_strings\n\n  failed = False\n  family_names = list()\n  for ttFont in ttFonts:\n    names_list = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n    # names_list will likely contain multiple entries, e.g. multiple copies\n    # of the same name in the same language for different platforms, but\n    # also different names in different languages, we use set() below\n    # to remove the duplicates and only store the unique family name(s)\n    # used for a given font\n    names_set = set(names_list)\n    family_names.extend(names_set)\n  counter = Counter(family_names)\n  for family_name, count in counter.items():\n    if count > 4:\n      failed = True\n      yield FAIL, (\"Family '{}' has {} fonts (should be 4 or fewer).\"\n                   ).format(family_name, count)\n  if not failed:\n    yield PASS, (\"There were no more than 4 fonts per family name.\")", "response": "Verify that each group of fonts with the same nameID 1\n has maximum of 4 fonts per family name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_family_equal_unicode_encodings(ttFonts):\n  encoding = None\n  failed = False\n  for ttFont in ttFonts:\n    cmap = None\n    for table in ttFont['cmap'].tables:\n      if table.format == 4:\n        cmap = table\n        break\n    # Could a font lack a format 4 cmap table ?\n    # If we ever find one of those, it would crash the check here.\n    # Then we'd have to yield a FAIL regarding the missing table entry.\n    if not encoding:\n      encoding = cmap.platEncID\n    if encoding != cmap.platEncID:\n      failed = True\n  if failed:\n    yield FAIL, \"Fonts have different unicode encodings.\"\n  else:\n    yield PASS, \"Fonts have equal unicode encodings.\"", "response": "Fonts have equal unicode encodings?"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking all glyphs have codepoints assigned.", "response": "def com_google_fonts_check_all_glyphs_have_codepoints(ttFont):\n  \"\"\"Check all glyphs have codepoints assigned.\"\"\"\n  failed = False\n  for subtable in ttFont['cmap'].tables:\n    if subtable.isUnicode():\n      for item in subtable.cmap.items():\n        codepoint = item[0]\n        if codepoint is None:\n          failed = True\n          yield FAIL, (\"Glyph {} lacks a unicode\"\n                       \" codepoint assignment\").format(codepoint)\n  if not failed:\n    yield PASS, \"All glyphs have a codepoint value assigned.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, order=None):\n    for event in self.runner.run(order=order):\n      self.receive(event)", "response": "run the event loop"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_name_trailing_spaces(ttFont):\n  failed = False\n  for name_record in ttFont['name'].names:\n    name_string = name_record.toUnicode()\n    if name_string != name_string.strip():\n      failed = True\n      name_key = tuple([name_record.platformID, name_record.platEncID,\n                       name_record.langID, name_record.nameID])\n      shortened_str = name_record.toUnicode()\n      if len(shortened_str) > 20:\n        shortened_str = shortened_str[:10] + \"[...]\" + shortened_str[-10:]\n      yield FAIL, (f\"Name table record with key = {name_key} has\"\n                    \" trailing spaces that must be removed:\"\n                   f\" '{shortened_str}'\")\n  if not failed:\n    yield PASS, (\"No trailing spaces on name table entries.\")", "response": "Name table records must not have trailing spaces."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_family_win_ascent_and_descent(ttFont, vmetrics):\n  failed = False\n\n  # OS/2 usWinAscent:\n  if ttFont['OS/2'].usWinAscent < vmetrics['ymax']:\n    failed = True\n    yield FAIL, Message(\"ascent\",\n                        (\"OS/2.usWinAscent value\"\n                         \" should be equal or greater than {}, but got\"\n                         \" {} instead\").format(vmetrics['ymax'],\n                                               ttFont['OS/2'].usWinAscent))\n  if ttFont['OS/2'].usWinAscent > vmetrics['ymax'] * 2:\n    failed = True\n    yield FAIL, Message(\n        \"ascent\", (\"OS/2.usWinAscent value {} is too large.\"\n                   \" It should be less than double the yMax.\"\n                   \" Current yMax value is {}\").format(ttFont['OS/2'].usWinDescent,\n                                                       vmetrics['ymax']))\n  # OS/2 usWinDescent:\n  if ttFont['OS/2'].usWinDescent < abs(vmetrics['ymin']):\n    failed = True\n    yield FAIL, Message(\n        \"descent\", (\"OS/2.usWinDescent value\"\n                    \" should be equal or greater than {}, but got\"\n                    \" {} instead\").format(\n                        abs(vmetrics['ymin']), ttFont['OS/2'].usWinDescent))\n\n  if ttFont['OS/2'].usWinDescent > abs(vmetrics['ymin']) * 2:\n    failed = True\n    yield FAIL, Message(\n        \"descent\", (\"OS/2.usWinDescent value {} is too large.\"\n                    \" It should be less than double the yMin.\"\n                    \" Current absolute yMin value is {}\").format(ttFont['OS/2'].usWinDescent,\n                                                                 abs(vmetrics['ymin'])))\n  if not failed:\n    yield PASS, \"OS/2 usWinAscent & usWinDescent values look good!\"", "response": "Checking the font s winAscent and winDescent values are within the range of the head table s yMax and abs ( yMin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking OS 2 Metrics match hhea vertical metric values.", "response": "def com_google_fonts_check_os2_metrics_match_hhea(ttFont):\n  \"\"\"Checking OS/2 Metrics match hhea Metrics.\n\n  OS/2 and hhea vertical metric values should match. This will produce\n  the same linespacing on Mac, GNU+Linux and Windows.\n\n  Mac OS X uses the hhea values.\n  Windows uses OS/2 or Win, depending on the OS or fsSelection bit value.\n  \"\"\"\n  # OS/2 sTypoAscender and sTypoDescender match hhea ascent and descent\n  if ttFont[\"OS/2\"].sTypoAscender != ttFont[\"hhea\"].ascent:\n    yield FAIL, Message(\"ascender\",\n                        \"OS/2 sTypoAscender and hhea ascent must be equal.\")\n  elif ttFont[\"OS/2\"].sTypoDescender != ttFont[\"hhea\"].descent:\n    yield FAIL, Message(\"descender\",\n                        \"OS/2 sTypoDescender and hhea descent must be equal.\")\n  else:\n    yield PASS, (\"OS/2.sTypoAscender/Descender values\"\n                 \" match hhea.ascent/descent.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_family_single_directory(fonts):\n\n  directories = []\n  for target_file in fonts:\n    directory = os.path.dirname(target_file)\n    if directory not in directories:\n      directories.append(directory)\n\n  if len(directories) == 1:\n    yield PASS, \"All files are in the same directory.\"\n  else:\n    yield FAIL, (\"Not all fonts passed in the command line\"\n                 \" are in the same directory. This may lead to\"\n                 \" bad results as the tool will interpret all\"\n                 \" font files as belonging to a single\"\n                 \" font family. The detected directories are:\"\n                 \" {}\".format(directories))", "response": "Checking all files in the same directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_ots(font):\n  import ots\n\n  try:\n    process = ots.sanitize(font, check=True, capture_output=True)\n  except ots.CalledProcessError as e:\n    yield FAIL, (\n      \"ots-sanitize returned an error code ({}). Output follows:\\n\\n{}{}\"\n    ).format(e.returncode, e.stderr.decode(), e.stdout.decode())\n  else:\n    if process.stderr:\n      yield WARN, (\n        \"ots-sanitize passed this file, however warnings were printed:\\n\\n{}\"\n      ).format(process.stderr.decode())\n    else:\n      yield PASS, \"ots-sanitize passed this file\"", "response": "Checking with ots - sanitize."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_fontbakery_version():\n\n  try:\n    import subprocess\n    installed_str = None\n    latest_str = None\n    is_latest = False\n    failed = False\n    pip_cmd = [\"pip\", \"search\", \"fontbakery\"]\n    pip_output = subprocess.check_output(pip_cmd, stderr=subprocess.STDOUT)\n    for line in pip_output.decode().split('\\n'):\n      if 'INSTALLED' in line:\n        installed_str = line.split('INSTALLED')[1].strip()\n      if 'LATEST' in line:\n        latest_str = line.split('LATEST')[1].strip()\n      if '(latest)' in line:\n        is_latest = True\n\n    if not (is_latest or is_up_to_date(installed_str, latest_str)):\n      failed = True\n      yield FAIL, (f\"Current Font Bakery version is {installed_str},\"\n                   f\" while a newer {latest_str} is already available.\"\n                    \" Please upgrade it with 'pip install -U fontbakery'\")\n    yield INFO, pip_output.decode()\n  except subprocess.CalledProcessError as e:\n    yield ERROR, (\"Running 'pip search fontbakery' returned an error code.\"\n                  \" Output follows :\\n\\n{}\\n\").format(e.output.decode())\n\n  if not failed:\n    yield PASS, \"Font Bakery is up-to-date\"", "response": "Check if FontBakery is up - to - date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_mandatory_glyphs(ttFont):\n  from fontbakery.utils import glyph_has_ink\n\n  if (\n    ttFont.getGlyphOrder()[0] == \".notdef\"\n    and \".notdef\" not in ttFont.getBestCmap().values()\n    and glyph_has_ink(ttFont, \".notdef\")\n  ):\n    yield PASS, (\n      \"Font contains the .notdef glyph as the first glyph, it does \"\n      \"not have a Unicode value assigned and contains a drawing.\"\n    )\n  else:\n    yield WARN, (\n      \"Font should contain the .notdef glyph as the first glyph, \"\n      \"it should not have a Unicode value assigned and should \"\n      \"contain a drawing.\"\n    )", "response": "Font contains. notdef as first glyph?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_whitespace_ink(ttFont):\n  from fontbakery.utils import get_glyph_name, glyph_has_ink\n\n  # code-points for all \"whitespace\" chars:\n  WHITESPACE_CHARACTERS = [\n      0x0009, 0x000A, 0x000B, 0x000C, 0x000D, 0x0020, 0x0085, 0x00A0, 0x1680,\n      0x2000, 0x2001, 0x2002, 0x2003, 0x2004, 0x2005, 0x2006, 0x2007, 0x2008,\n      0x2009, 0x200A, 0x2028, 0x2029, 0x202F, 0x205F, 0x3000, 0x180E, 0x200B,\n      0x2060, 0xFEFF\n  ]\n  failed = False\n  for codepoint in WHITESPACE_CHARACTERS:\n    g = get_glyph_name(ttFont, codepoint)\n    if g is not None and glyph_has_ink(ttFont, g):\n      failed = True\n      yield FAIL, (\"Glyph \\\"{}\\\" has ink.\"\n                   \" It needs to be replaced by\"\n                   \" an empty glyph.\").format(g)\n  if not failed:\n    yield PASS, \"There is no whitespace glyph with ink.\"", "response": "Whitespace glyphs have ink?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_unwanted_tables(ttFont):\n  UNWANTED_TABLES = {\n      'FFTM': '(from FontForge)',\n      'TTFA': '(from TTFAutohint)',\n      'TSI0': '(from VTT)',\n      'TSI1': '(from VTT)',\n      'TSI2': '(from VTT)',\n      'TSI3': '(from VTT)',\n      'TSI5': '(from VTT)',\n      'prop': '' # FIXME: why is this one unwanted?\n  }\n  unwanted_tables_found = []\n  for table in ttFont.keys():\n    if table in UNWANTED_TABLES.keys():\n      info = UNWANTED_TABLES[table]\n      unwanted_tables_found.append(f\"{table} {info}\")\n\n  if len(unwanted_tables_found) > 0:\n    yield FAIL, (\"Unwanted tables were found\"\n                 \" in the font and should be removed, either by\"\n                 \" fonttools/ttx or by editing them using the tool\"\n                 \" they are from:\"\n                 \" {}\").format(\", \".join(unwanted_tables_found))\n  else:\n    yield PASS, \"There are no unwanted tables.\"", "response": "Check that unwanted tables are found in the font."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_unique_glyphnames(ttFont):\n  if ttFont.sfntVersion == b'\\x00\\x01\\x00\\x00' and ttFont.get(\n      \"post\") and ttFont[\"post\"].formatType == 3.0:\n    yield SKIP, (\"TrueType fonts with a format 3.0 post table contain no\"\n                 \" glyph names.\")\n  else:\n    import re\n    glyphs = []\n    duplicated_glyphIDs = []\n    for _, g in enumerate(ttFont.getGlyphOrder()):\n      glyphID = re.sub(r'#\\w+', '', g)\n      if glyphID in glyphs:\n        duplicated_glyphIDs.append(glyphID)\n      else:\n        glyphs.append(glyphID)\n\n    if len(duplicated_glyphIDs) == 0:\n      yield PASS, \"Font contains unique glyph names.\"\n    else:\n      yield FAIL, (\"The following glyph names\"\n                   \" occur twice: {}\").format(duplicated_glyphIDs)", "response": "Font contains unique glyph names?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_glyphnames_max_length(ttFont):\n  if ttFont.sfntVersion == b'\\x00\\x01\\x00\\x00' and ttFont.get(\n      \"post\") and ttFont[\"post\"].formatType == 3.0:\n    yield PASS, (\"TrueType fonts with a format 3.0 post table contain no \"\n                 \"glyph names.\")\n  else:\n    failed = False\n    for name in ttFont.getGlyphOrder():\n      if len(name) > 109:\n        failed = True\n        yield FAIL, (\"Glyph name is too long:\" \" '{}'\").format(name)\n    if not failed:\n      yield PASS, \"No glyph names exceed max allowed length.\"", "response": "Check that glyph names do not exceed max length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_ttx_roundtrip(font):\n  from fontTools import ttx\n  import sys\n  ttFont = ttx.TTFont(font)\n  failed = False\n\n  class TTXLogger:\n    msgs = []\n\n    def __init__(self):\n      self.original_stderr = sys.stderr\n      self.original_stdout = sys.stdout\n      sys.stderr = self\n      sys.stdout = self\n\n    def write(self, data):\n      if data not in self.msgs:\n        self.msgs.append(data)\n\n    def restore(self):\n      sys.stderr = self.original_stderr\n      sys.stdout = self.original_stdout\n\n  from xml.parsers.expat import ExpatError\n  try:\n    logger = TTXLogger()\n    xml_file = font + \".xml\"\n    ttFont.saveXML(xml_file)\n    export_error_msgs = logger.msgs\n\n    if len(export_error_msgs):\n      failed = True\n      yield INFO, (\"While converting TTF into an XML file,\"\n                   \" ttx emited the messages listed below.\")\n      for msg in export_error_msgs:\n        yield FAIL, msg.strip()\n\n    f = ttx.TTFont()\n    f.importXML(font + \".xml\")\n    import_error_msgs = [msg for msg in logger.msgs if msg not in export_error_msgs]\n\n    if len(import_error_msgs):\n      failed = True\n      yield INFO, (\"While importing an XML file and converting\"\n                   \" it back to TTF, ttx emited the messages\"\n                   \" listed below.\")\n      for msg in import_error_msgs:\n        yield FAIL, msg.strip()\n    logger.restore()\n  except ExpatError as e:\n    failed = True\n    yield FAIL, (\"TTX had some problem parsing the generated XML file.\"\n                 \" This most likely mean there's some problem in the font.\"\n\t\t \" Please inspect the output of ttx in order to find more\"\n\t\t \" on what went wrong. A common problem is the presence of\"\n                 \" control characteres outside the accepted character range\"\n                 \" as defined in the XML spec. FontTools has got a bug which\"\n                 \" causes TTX to generate corrupt XML files in those cases.\"\n                 \" So, check the entries of the name table and remove any\"\n                 \" control chars that you find there.\"\n\t\t \" The full ttx error message was:\\n\"\n\t\t \"======\\n{}\\n======\".format(e))\n\n  if not failed:\n    yield PASS, \"Hey! It all looks good!\"\n\n  # and then we need to cleanup our mess...\n  if os.path.exists(xml_file):\n    os.remove(xml_file)", "response": "Checking with fontTools. ttx"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks Vertical Metric Linegaps.", "response": "def com_google_fonts_check_linegaps(ttFont):\n  \"\"\"Checking Vertical Metric Linegaps.\"\"\"\n  if ttFont[\"hhea\"].lineGap != 0:\n    yield WARN, Message(\"hhea\", \"hhea lineGap is not equal to 0.\")\n  elif ttFont[\"OS/2\"].sTypoLineGap != 0:\n    yield WARN, Message(\"OS/2\", \"OS/2 sTypoLineGap is not equal to 0.\")\n  else:\n    yield PASS, \"OS/2 sTypoLineGap and hhea lineGap are both 0.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_maxadvancewidth(ttFont):\n  hhea_advance_width_max = ttFont['hhea'].advanceWidthMax\n  hmtx_advance_width_max = None\n  for g in ttFont['hmtx'].metrics.values():\n    if hmtx_advance_width_max is None:\n      hmtx_advance_width_max = max(0, g[0])\n    else:\n      hmtx_advance_width_max = max(g[0], hmtx_advance_width_max)\n\n  if hmtx_advance_width_max != hhea_advance_width_max:\n    yield FAIL, (\"AdvanceWidthMax mismatch: expected {} (from hmtx);\"\n                 \" got {} (from hhea)\").format(hmtx_advance_width_max,\n                                               hhea_advance_width_max)\n  else:\n    yield PASS, (\"MaxAdvanceWidth is consistent\"\n                 \" with values in the Hmtx and Hhea tables.\")", "response": "MaxAdvanceWidth is consistent with values in the Hmtx and Hhea tables?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict containing whether the font seems monospaced at least 80% of \u2013 the maximum glyph width and what s the most common width.", "response": "def glyph_metrics_stats(ttFont):\n  \"\"\"Returns a dict containing whether the font seems_monospaced,\n  what's the maximum glyph width and what's the most common width.\n\n  For a font to be considered monospaced, at least 80% of\n  the ascii glyphs must have the same width.\"\"\"\n  glyph_metrics = ttFont['hmtx'].metrics\n  ascii_glyph_names = [ttFont.getBestCmap()[c] for c in range(32, 128)\n                       if c in ttFont.getBestCmap()]\n  ascii_widths = [adv for name, (adv, lsb) in glyph_metrics.items()\n                  if name in ascii_glyph_names]\n  ascii_width_count = Counter(ascii_widths)\n  ascii_most_common_width = ascii_width_count.most_common(1)[0][1]\n  seems_monospaced = ascii_most_common_width >= len(ascii_widths) * 0.8\n\n  width_max = max([adv for k, (adv, lsb) in glyph_metrics.items()])\n  most_common_width = Counter(glyph_metrics.values()).most_common(1)[0][0][0]\n  return {\n      \"seems_monospaced\": seems_monospaced,\n      \"width_max\": width_max,\n      \"most_common_width\": most_common_width,\n  }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the tags of VTT source tables found in a font.", "response": "def vtt_talk_sources(ttFont) -> List[str]:\n  \"\"\"Return the tags of VTT source tables found in a font.\"\"\"\n  VTT_SOURCE_TABLES = {'TSI0', 'TSI1', 'TSI2', 'TSI3', 'TSI5'}\n  tables_found = [tag for tag in ttFont.keys() if tag in VTT_SOURCE_TABLES]\n  return tables_found"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting data to stdout every now and then", "response": "def write(self, data):\n    \"\"\"only put to stdout every now and then\"\"\"\n    self._buffer.append(data)\n    self._current_ticks += 1\n    # first entry ever will be flushed immediately\n\n    flush=False\n    if self._last_flush_time is None or \\\n                (self._holdback_time is None and self._max_ticks == 0):\n      flush = True\n    elif self._max_ticks and self._current_ticks >= self._max_ticks or \\\n         self._holdback_time and time() - self._holdback_time >= self._last_flush_time:\n      flush=True\n\n    if flush:\n      self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flush(self, draw_progress=True):\n    reset_progressbar = None\n    if self._draw_progressbar and draw_progress:\n      progressbar, reset_progressbar = self._draw_progressbar()\n      self._buffer.append(progressbar)\n\n    for line in self._buffer:\n      self._outFile.write(line)\n    #self._outFile.flush() needed?\n    self._buffer = []\n    if reset_progressbar:\n      # first thing on next flush is to reset the current progressbar\n      self._buffer.append(reset_progressbar)\n    self._current_ticks = 0\n    self._last_flush_time = time()", "response": "flushes the buffer to the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _draw_progressbar(self, columns=None, len_prefix=0, right_margin=0):\n    if self._order == None:\n      total = len(self._results)\n    else:\n      total = max(len(self._order), len(self._results))\n\n    percent = int(round(len(self._results)/total*100)) if total else 0\n\n    needs_break = lambda count: columns and count > columns \\\n                                and (count % (columns - right_margin))\n\n    # together with unicode_literals `str('status')` seems the best\n    # py2 and py3 compatible solution\n    status = type(str('status'), (object,), dict(count=0,progressbar=[]))\n    def _append(status, item, length=1, separator=''):\n      # * assuming a standard item will take one column in the tty\n      # * length must not be bigger than columns (=very narrow columns)\n      progressbar = status.progressbar\n      if needs_break(status.count + length + len(separator)):\n        progressbar.append('\\n')\n        status.count = 0\n      else:\n        progressbar.append(separator)\n      status.count += length + len(separator)\n      progressbar.append(item)\n    append=partial(_append, status)\n    progressbar = status.progressbar\n\n    append('', len_prefix)\n    append('[')\n    for item in self._progressbar:\n      append(item)\n    append(']')\n    percentstring = f'{percent:3d}%'\n    append(percentstring, len(percentstring), ' ')\n    return ''.join(progressbar)", "response": "Draw a progress bar for the current order and the number of columns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_file(url, dst_path):\n    request = requests.get(url, stream=True)\n    with open(dst_path, 'wb') as downloaded_file:\n        request.raw.decode_content = True\n        shutil.copyfileobj(request.raw, downloaded_file)", "response": "Download a file from a url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download_fonts(gh_url, dst):\n    font_paths = []\n    r = requests.get(gh_url)\n    for item in r.json():\n        if item['name'].endswith(\".ttf\"):\n            f = item['download_url']\n            dl_path = os.path.join(dst, os.path.basename(f))\n            download_file(f, dl_path)\n            font_paths.append(dl_path)\n    return font_paths", "response": "Download fonts from a github dir"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake sure all font files have the same version value.", "response": "def com_google_fonts_check_family_equal_font_versions(ttFonts):\n  \"\"\"Make sure all font files have the same version value.\"\"\"\n  all_detected_versions = []\n  fontfile_versions = {}\n  for ttFont in ttFonts:\n    v = ttFont['head'].fontRevision\n    fontfile_versions[ttFont] = v\n\n    if v not in all_detected_versions:\n      all_detected_versions.append(v)\n  if len(all_detected_versions) != 1:\n    versions_list = \"\"\n    for v in fontfile_versions.keys():\n      versions_list += \"* {}: {}\\n\".format(v.reader.file.name,\n                                           fontfile_versions[v])\n    yield WARN, (\"version info differs among font\"\n                 \" files of the same font project.\\n\"\n                 \"These were the version values found:\\n\"\n                 \"{}\").format(versions_list)\n  else:\n    yield PASS, \"All font files have the same version.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks unitsPerEm value is reasonable.", "response": "def com_google_fonts_check_unitsperem(ttFont):\n  \"\"\"Checking unitsPerEm value is reasonable.\"\"\"\n  upem = ttFont['head'].unitsPerEm\n  target_upem = [2**i for i in range(4, 15)]\n  target_upem.append(1000)\n  target_upem.append(2000)\n  if upem < 16 or upem > 16384:\n    yield FAIL, (\"The value of unitsPerEm at the head table\"\n                 \" must be a value between 16 and 16384.\"\n                 \" Got '{}' instead.\").format(upem)\n  elif upem not in target_upem:\n    yield WARN, (\"In order to optimize performance on some\"\n                 \" legacy renderers, the value of unitsPerEm\"\n                 \" at the head table should idealy be\"\n                 \" a power of between 16 to 16384.\"\n                 \" And values of 1000 and 2000 are also\"\n                 \" common and may be just fine as well.\"\n                 \" But we got upm={} instead.\").format(upem)\n  else:\n    yield PASS, (\"unitsPerEm value ({}) on the 'head' table\"\n                 \" is reasonable.\").format(upem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_version_string(name: str) -> Tuple[str, str]:\n  import re\n\n  # We assume \";\" is the universal delimiter here.\n  version_entry = name.split(\";\")[0]\n\n  # Catch both \"Version 1.234\" and \"1.234\" but not \"1x2.34\". Note: search()\n  # will return the first match.\n  version_string = re.search(r\"(?: |^)(\\d+\\.\\d+)\", version_entry)\n\n  if version_string is None:\n    raise ValueError(\"The version string didn't contain a number of the format\"\n                     \" major.minor.\")\n\n  major, minor = version_string.group(1).split('.')\n  major = str(int(major))  # \"01.123\" -> \"1.123\"\n  minor = minor.ljust(3, '0')  # \"3.0\" -> \"3.000\", but \"3.123\" -> \"3.123\"\n  return major, minor", "response": "Parse a version string in the form of a major. minor number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_font_version(ttFont):\n  from decimal import Decimal\n  head_version_str = str(Decimal(ttFont[\"head\"].fontRevision).quantize(Decimal('1.000')))\n  head_version = parse_version_string(head_version_str)\n\n  # Compare the head version against the name ID 5 strings in all name records.\n  name_id_5_records = [\n      record for record in ttFont[\"name\"].names\n      if record.nameID == NameID.VERSION_STRING\n  ]\n\n  failed = False\n  if name_id_5_records:\n    for record in name_id_5_records:\n      try:\n        name_version = parse_version_string(record.toUnicode())\n        if name_version != head_version:\n          failed = True\n          yield FAIL, Message(\"mismatch\",\n                              \"head version is '{}' while name version string\"\n                              \" (for platform {}, encoding {}) is '{}'.\"\n                              \"\".format(head_version_str,\n                                        record.platformID,\n                                        record.platEncID,\n                                        record.toUnicode()))\n      except ValueError:\n        failed = True\n        yield FAIL, Message(\"parse\",\n                            \"name version string for platform {},\"\n                            \" encoding {} ('{}'), could not be parsed.\"\n                            \"\".format(record.platformID,\n                                      record.platEncID,\n                                      record.toUnicode()))\n  else:\n    failed = True\n    yield FAIL, Message(\"missing\",\n                        \"There is no name ID 5 (version string) in the font.\")\n\n  if not failed:\n    yield PASS, \"All font version fields match.\"", "response": "Font version string is correct?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecorating a property by executing it at instatiation time and cache the result on the instance object.", "response": "def cached_getter(func):\n  \"\"\"Decorate a property by executing it at instatiation time and cache the\n  result on the instance object.\"\"\"\n  @wraps(func)\n  def wrapper(self):\n    attribute = f'_{func.__name__}'\n    value = getattr(self, attribute, None)\n    if value is None:\n      value = func(self)\n      setattr(self, attribute, value)\n    return value\n  return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef condition(*args, **kwds):\n  if len(args) == 1 and len(kwds) == 0 and callable(args[0]):\n    # used as `@decorator`\n    func = args[0]\n    return wraps(func)(FontBakeryCondition(func))\n  else:\n    # used as `@decorator()` maybe with args\n    def wrapper(func):\n      return wraps(func)(FontBakeryCondition(func, *args, **kwds))\n  return wrapper", "response": "Check wrapper for FontBakeryCondition"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(*args, **kwds):\n  def wrapper(checkfunc):\n    return wraps(checkfunc)(FontBakeryCheck(checkfunc, *args, **kwds))\n  return wrapper", "response": "Check wrapper for FontBakeryCheck"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_adobe_fonts_check_cff_call_depth(ttFont):\n    any_failures = False\n    cff = ttFont['CFF '].cff\n\n    for top_dict in cff.topDictIndex:\n        if hasattr(top_dict, 'FDArray'):\n            for fd_index, font_dict in enumerate(top_dict.FDArray):\n                if hasattr(font_dict, 'Private'):\n                    private_dict = font_dict.Private\n                else:\n                    private_dict = None\n                failed = yield from \\\n                    _check_call_depth(top_dict, private_dict, fd_index)\n                any_failures = any_failures or failed\n        else:\n            if hasattr(top_dict, 'Private'):\n                private_dict = top_dict.Private\n            else:\n                private_dict = None\n            failed = yield from _check_call_depth(top_dict, private_dict)\n            any_failures = any_failures or failed\n\n    if not any_failures:\n        yield PASS, 'Maximum call depth not exceeded.'", "response": "Check if the maximum call depth is exceeded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_adobe_fonts_check_cff2_call_depth(ttFont):\n    any_failures = False\n    cff = ttFont['CFF2'].cff\n\n    for top_dict in cff.topDictIndex:\n        for fd_index, font_dict in enumerate(top_dict.FDArray):\n            if hasattr(font_dict, 'Private'):\n                private_dict = font_dict.Private\n            else:\n                private_dict = None\n            failed = yield from \\\n                _check_call_depth(top_dict, private_dict, fd_index)\n            any_failures = any_failures or failed\n\n    if not any_failures:\n        yield PASS, 'Maximum call depth not exceeded.'", "response": "Check that the maximum call depth is exceeded."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns max and min bounding box of given truetype font", "response": "def get_bounding_box(font):\n    \"\"\" Returns max and min bbox of given truetype font \"\"\"\n    ymin = 0\n    ymax = 0\n    if font.sfntVersion == 'OTTO':\n        ymin = font['head'].yMin\n        ymax = font['head'].yMax\n    else:\n        for g in font['glyf'].glyphs:\n            char = font['glyf'][g]\n            if hasattr(char, 'yMin') and ymin > char.yMin:\n                ymin = char.yMin\n            if hasattr(char, 'yMax') and ymax < char.yMax:\n                ymax = char.yMax\n    return ymin, ymax"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef glyph_contour_count(font, name):\n    contour_count = 0\n    items = [font['glyf'][name]]\n\n    while items:\n        g = items.pop(0)\n        if g.isComposite():\n            for comp in g.components:\n                if comp.glyphName != \".ttfautohint\":\n                    items.append(font['glyf'][comp.glyphName])\n        if g.numberOfContours != -1:\n            contour_count += g.numberOfContours\n    return contour_count", "response": "Return the number of contours for a glyph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_font_glyph_data(font):\n    from fontbakery.constants import (PlatformID,\n                                      WindowsEncodingID)\n    font_data = []\n\n    try:\n        subtable = font['cmap'].getcmap(PlatformID.WINDOWS,\n                                        WindowsEncodingID.UNICODE_BMP)\n        if not subtable:\n          # Well... Give it a chance here...\n          # It may be using a different Encoding_ID value\n          subtable = font['cmap'].tables[0]\n\n        cmap = subtable.cmap\n    except:\n        return None\n\n    cmap_reversed = dict(zip(cmap.values(), cmap.keys()))\n\n    for glyph_name in font.getGlyphSet().keys():\n        if glyph_name in cmap_reversed:\n            uni_glyph = cmap_reversed[glyph_name]\n            contours = glyph_contour_count(font, glyph_name)\n            font_data.append({\n                'unicode': uni_glyph,\n                'name': glyph_name,\n                'contours': {contours}\n            })\n    return font_data", "response": "Return information for each glyph in a font"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef glyph_has_ink(font: TTFont, name: Text) -> bool:\n  if 'glyf' in font:\n    return ttf_glyph_has_ink(font, name)\n  elif ('CFF ' in font) or ('CFF2' in font):\n    return cff_glyph_has_ink(font, name)\n  else:\n    raise Exception(\"Could not find 'glyf', 'CFF ', or 'CFF2' table.\")", "response": "Checks if specified glyph has any ink."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assert_results_contain(check_results, expected_status, expected_msgcode=None):\n  found = False\n  for status, message in check_results:\n    if status == expected_status and message.code == expected_msgcode:\n      found = True\n      break\n  assert(found)", "response": "This helper function is used to make sure that the check_results contains the expected_status and expected_msgcode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_post_table_version(ttFont, is_ttf):\n  formatType = ttFont['post'].formatType\n  if is_ttf:\n    expected = 2\n  else:\n    expected = 3\n  if formatType != expected:\n    yield FAIL, (\"Post table should be version {} instead of {}.\"\n                 \" More info at https://github.com/google/fonts/\"\n                 \"issues/215\").format(expected, formatType)\n  else:\n    yield PASS, f\"Font has post table version {expected}.\"", "response": "Font has correct post table version?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_fontvalidator(font):\n\n  # In some cases we want to override the severity level of\n  # certain checks in FontValidator:\n  downgrade_to_warn = [\n    # There are reports that this fontval check has an out-of-date\n    # understanding of valid bits in fsSelection.\n    # More info at:\n    # https://github.com/googlei18n/fontmake/issues/414#issuecomment-379408127\n    \"There are undefined bits set in fsSelection field\",\n\n    # FIX-ME: Why did we downgrade this one to WARN?\n    \"Misoriented contour\"\n  ]\n\n  # Some other checks we want to completely disable:\n  disabled_fval_checks = [\n    # FontVal E4012 thinks that\n    # \"Versions 0x00010000 and 0x0001002 are currently\n    #  the only defined versions of the GDEF table.\"\n    # but the GDEF chapter of the OpenType specification at\n    # https://docs.microsoft.com/en-us/typography/opentype/spec/gdef\n    # describes GDEF header version 1.3, which is not yet recognized\n    # by FontVal, thus resulting in this spurious false-FAIL:\n    \"The version number is neither 0x00010000 nor 0x0001002\",\n\n    # These messages below are simply fontval given user feedback\n    # on the progress of runnint it. It has nothing to do with\n    # actual issues on the font files:\n    \"Validating glyph with index\",\n    \"Table Test:\",\n\n    # No software is affected by Mac strings nowadays.\n    # More info at: googlei18n/fontmake#414\n    \"The table doesn't contain strings for Mac platform\",\n    \"The PostScript string is not present for both required platforms\",\n\n    # Font Bakery has got a native check for the xAvgCharWidth field\n    # which is: com.google.fonts/check/xavgcharwidth\n    \"The xAvgCharWidth field does not equal the calculated value\",\n\n    # The optimal ordering suggested by FVal check W0020 seems to only be\n    # relevant to performance optimizations on old versions of Windows\n    # running on old hardware. Since such performance considerations\n    # are most likely negligible, we're not going to bother users with\n    # this check's table ordering requirements.\n    # More info at:\n    # https://github.com/googlefonts/fontbakery/issues/2105\n    \"Tables are not in optimal order\",\n\n    # Font Bakery has its own check for required/optional tables:\n    # com.google.fonts/check/required_tables\n    \"Recommended table is missing\"\n  ]\n\n  # There are also some checks that do not make\n  # sense when we're dealing with variable fonts:\n  VARFONT_disabled_fval_checks = [\n    # Variable fonts typically do have lots of self-intersecting\n    # contours because they are used to draw each portion\n    # of variable glyph features.\n    \"Intersecting contours\",\n    \"Intersecting components of composite glyph\",\n\n    # DeltaFormat = 32768 (same as 0x8000) means VARIATION_INDEX,\n    # according to https://docs.microsoft.com/en-us/typography/opentype/spec/chapter2\n    # The FontVal problem description for this check (E5200) only mentions\n    # the other values as possible valid ones. So apparently this means FontVal\n    # implementation is not up-to-date with more recent versions of the OpenType spec\n    # and that's why these spurious FAILs are being emitted.\n    # That's good enough reason to mute it.\n    # More info at:\n    # https://github.com/googlefonts/fontbakery/issues/2109\n    \"The device table's DeltaFormat value is invalid\"\n  ]\n\n  from fontTools.ttLib import TTFont\n  if is_variable_font(TTFont(font)):\n    disabled_fval_checks.extend(VARFONT_disabled_fval_checks)\n\n  try:\n    import subprocess\n    fval_cmd = [\n        \"FontValidator\", \"-file\", font, \"-all-tables\",\n        \"-report-in-font-dir\", \"-no-raster-tests\"\n    ]\n    subprocess.check_output(fval_cmd, stderr=subprocess.STDOUT)\n  except subprocess.CalledProcessError as e:\n    filtered_msgs = \"\"\n    for line in e.output.decode().split(\"\\n\"):\n      disable_it = False\n      for substring in disabled_fval_checks:\n        if substring in line:\n          disable_it = True\n      if not disable_it:\n        filtered_msgs += line + \"\\n\"\n    yield INFO, (\"Microsoft Font Validator returned an error code.\"\n                 \" Output follows :\\n\\n{}\\n\").format(filtered_msgs)\n  except (OSError, IOError) as error:\n    yield ERROR, (\"Mono runtime and/or \"\n                  \"Microsoft Font Validator are not available!\")\n    raise error\n\n  def report_message(msg, details):\n    if details:\n      if isinstance(details, list) and len(details) > 1:\n        # We'll print lists with one item per line for\n        # improved readability.\n        if None in details:\n          details.remove(None)\n\n        # A designer will likely not need the full list\n        # in order to fix a problem.\n        # Showing only the 10 first ones is more than enough\n        # and helps avoid flooding the report.\n        if len(details) > 25:\n          num_similar = len(details) - 10\n          details = details[:10]\n          details.append(f\"NOTE: {num_similar} other similar\"\n                          \" results were hidden!\")\n        details = '\\n\\t- ' + '\\n\\t- '.join(details)\n      return f\"MS-FonVal: {msg} DETAILS: {details}\"\n    else:\n      return f\"MS-FonVal: {msg}\"\n\n  xml_report_file = f\"{font}.report.xml\"\n  html_report_file = f\"{font}.report.html\"\n  fval_file = os.path.join(os.path.dirname(font), 'fval.xsl')\n\n  grouped_msgs = {}\n  with open(xml_report_file, \"rb\") as xml_report:\n    import defusedxml.lxml\n    doc = defusedxml.lxml.parse(xml_report)\n\n    for report in doc.iter('Report'):\n      msg = report.get(\"Message\")\n      details = report.get(\"Details\")\n\n      disable_it = False\n      for substring in disabled_fval_checks:\n        if substring in msg:\n          disable_it = True\n      if disable_it:\n        continue\n\n      if msg not in grouped_msgs:\n        grouped_msgs[msg] = {\"errortype\": report.get(\"ErrorType\"),\n                             \"details\": [details]}\n      else:\n        if details not in grouped_msgs[msg][\"details\"]:\n          # avoid cluttering the output with tons of identical reports\n          # yield INFO, 'grouped_msgs[msg][\"details\"]: {}'.format(grouped_msgs[msg][\"details\"])\n          grouped_msgs[msg][\"details\"].append(details)\n\n  # ---------------------------\n  # Clean-up generated files...\n  os.remove(xml_report_file)\n  # FontVal internal detail: HTML report generated only on non-Windows due to\n  # Mono or the used HTML renderer not being able to render XML with a\n  # stylesheet directly. https://github.com/googlefonts/fontbakery/issues/1747\n  if os.path.exists(html_report_file):\n    os.remove(html_report_file)\n  os.remove(fval_file)\n\n  # ---------------------------\n  # Here we start emitting the grouped log messages\n  for msg, data in grouped_msgs.items():\n    # But before printing we try to make the \"details\" more\n    # readable. Otherwise the user would get the text terminal\n    # flooded with messy data.\n\n    # No need to print is as a list if wereally only\n    # got one log message of this kind:\n    if len(data[\"details\"]) == 1:\n      data[\"details\"] = data[\"details\"][0]\n\n    # Simplify the list of glyph indices by only displaying\n    # their numerical values in a list:\n    for glyph_index in [\"Glyph index \", \"glyph# \"]:\n      if data[\"details\"] and \\\n         data[\"details\"][0] and \\\n         glyph_index in data[\"details\"][0]:\n        try:\n          data[\"details\"] = {'Glyph index': [int(x.split(glyph_index)[1])\n                                             for x in data[\"details\"]]}\n          break\n        except ValueError:\n          pass\n\n    # And, finally, the log messages are emitted:\n    if data[\"errortype\"] == \"P\":\n      yield PASS, report_message(msg, data[\"details\"])\n\n    elif data[\"errortype\"] == \"E\":\n      status = FAIL\n      for substring in downgrade_to_warn:\n        if substring in msg:\n          status = WARN\n      yield status, report_message(msg, data[\"details\"])\n\n    elif data[\"errortype\"] == \"W\":\n      yield WARN, report_message(msg, data[\"details\"])\n\n    else:\n      yield INFO, report_message(msg, data[\"details\"])", "response": "Checking with Microsoft Font Validator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef summary_table(\n    errors: int, fails: int, warns: int, skips: int, infos: int, passes: int, total: int\n) -> str:\n    \"\"\"Return summary table with statistics.\"\"\"\n\n    return f\"\"\"<h2>Summary</h2>\n            <table>\n            <tr>\n                <th>{EMOTICON['ERROR']} ERROR</th>\n                <th>{EMOTICON['FAIL']} FAIL</th>\n                <th>{EMOTICON['WARN']} WARN</th>\n                <th>{EMOTICON['SKIP']} SKIP</th>\n                <th>{EMOTICON['INFO']} INFO</th>\n                <th>{EMOTICON['PASS']} PASS</th>\n            </tr>\n            <tr>\n                <td>{errors}</td>\n                <td>{fails}</td>\n                <td>{warns}</td>\n                <td>{skips}</td>\n                <td>{infos}</td>\n                <td>{passes}</td>\n            </tr>\n            <tr>\n                <td>{round(errors / total * 100)}%</td>\n                <td>{round(fails / total * 100)}%</td>\n                <td>{round(warns / total * 100)}%</td>\n                <td>{round(skips / total * 100)}%</td>\n                <td>{round(infos / total * 100)}%</td>\n                <td>{round(passes / total * 100)}%</td>\n            </tr>\n            </table>\n            \"\"\"", "response": "Return summary table with statistics."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_html(self) -> str:\n        data = self.getdoc()\n        num_checks = 0\n        body_elements = []\n\n        # Order by section first...\n        for section in data[\"sections\"]:\n            section_name = html.escape(section[\"key\"][0])\n            section_stati_of_note = (\n                e for e in section[\"result\"].elements() if e != \"PASS\"\n            )\n            section_stati = \"\".join(\n                EMOTICON[s] for s in sorted(section_stati_of_note, key=LOGLEVELS.index)\n            )\n            body_elements.append(f\"<h2>{section_name} {section_stati}</h2>\")\n\n            checks_by_id: Dict[str, List[Dict[str, str]]] = collections.defaultdict(\n                list\n            )\n            # ...and check second.\n            for cluster in section[\"checks\"]:\n                if not isinstance(cluster, list):\n                    cluster = [cluster]\n                num_checks += len(cluster)\n                for check in cluster:\n                    checks_by_id[check[\"key\"][1]].append(check)\n            for check, results in checks_by_id.items():\n                check_name = html.escape(check)\n                body_elements.append(f\"<h3>{results[0]['description']}</h3>\")\n                body_elements.append(f\"<div>Check ID: {check_name}</div>\")\n                for result in results:\n                    if \"filename\" in result:\n                        body_elements.append(\n                            html5_collapsible(\n                                f\"{EMOTICON[result['result']]} <strong>{result['filename']}</strong>\",\n                                self.html_for_check(result),\n                            )\n                        )\n                    else:\n                        body_elements.append(\n                            html5_collapsible(\n                                f\"{EMOTICON[result['result']]} <strong>Family check</strong>\",\n                                self.html_for_check(result),\n                            )\n                        )\n\n        body_top = [\n            \"<h1>Fontbakery Technical Report</h1>\",\n            \"<div>If you think a check is flawed or have an idea for a check, please \"\n            f\" file an issue at <a href='{ISSUE_URL}'>{ISSUE_URL}</a> and remember \"\n            \"to include a pointer to the repo and branch you're checking.</div>\",\n        ]\n\n        if num_checks:\n            results_summary = [data[\"result\"][k] for k in LOGLEVELS]\n            body_top.append(summary_table(*results_summary, num_checks))\n\n        omitted = [l for l in LOGLEVELS if self.omit_loglevel(l)]\n        if omitted:\n            body_top.append(\n                \"<p><strong>Note:</strong>\"\n                \" The following loglevels were omitted in this report:\"\n                f\" {', '.join(omitted)}</p>\"\n            )\n\n        body_elements[0:0] = body_top\n        return html5_document(body_elements)", "response": "Return complete report as a HTML string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef omit_loglevel(self, msg) -> bool:\n        return self.loglevels and (\n            self.loglevels[0] > fontbakery.checkrunner.Status(msg)\n        )", "response": "Determine if a message is below the log level."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html_for_check(self, check) -> str:\n        check[\"logs\"].sort(key=lambda c: LOGLEVELS.index(c[\"status\"]))\n        logs = \"<ul>\" + \"\".join([self.log_html(log) for log in check[\"logs\"]]) + \"</ul>\"\n        return logs", "response": "Return HTML string for complete single check."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns single check sub - result string as HTML or not if below log level.", "response": "def log_html(self, log) -> str:\n        \"\"\"Return single check sub-result string as HTML or not if below log\n        level.\"\"\"\n        if not self.omit_loglevel(log[\"status\"]):\n            emoticon = EMOTICON[log[\"status\"]]\n            status = log[\"status\"]\n            message = html.escape(log[\"message\"]).replace(\"\\n\", \"<br/>\")\n            return (\n                \"<li class='details_item'>\"\n                f\"<span class='details_indicator'>{emoticon} {status}</span>\"\n                f\"<span class='details_text'>{message}</span>\"\n                \"</li>\"\n            )\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining font style from canonical filename.", "response": "def style(font):\n  \"\"\"Determine font style from canonical filename.\"\"\"\n  from fontbakery.constants import STATIC_STYLE_NAMES\n  filename = os.path.basename(font)\n  if '-' in filename:\n    stylename = os.path.splitext(filename)[0].split('-')[1]\n    if stylename in [name.replace(' ', '') for name in STATIC_STYLE_NAMES]:\n      return stylename\n  return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef canonical_stylename(font):\n  from fontbakery.constants import (STATIC_STYLE_NAMES,\n                                    VARFONT_SUFFIXES)\n  from fontbakery.profiles.shared_conditions import is_variable_font\n  from fontTools.ttLib import TTFont\n\n  # remove spaces in style names\n  valid_style_suffixes = [name.replace(' ', '') for name in STATIC_STYLE_NAMES]\n\n  filename = os.path.basename(font)\n  basename = os.path.splitext(filename)[0]\n  s = suffix(font)\n  varfont = os.path.exists(font) and is_variable_font(TTFont(font))\n  if ('-' in basename and\n      (s in VARFONT_SUFFIXES and varfont)\n      or (s in valid_style_suffixes and not varfont)):\n    return s", "response": "Returns the canonical stylename of a given font."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks file is named canonically.", "response": "def com_google_fonts_check_canonical_filename(font):\n  \"\"\"Checking file is named canonically.\n\n  A font's filename must be composed in the following manner:\n  <familyname>-<stylename>.ttf\n\n  e.g. Nunito-Regular.ttf,\n       Oswald-BoldItalic.ttf\n\n  Variable fonts must use the \"-VF\" suffix:\n\n  e.g. Roboto-VF.ttf,\n       Barlow-VF.ttf,\n       Example-Roman-VF.ttf,\n       Familyname-Italic-VF.ttf\n  \"\"\"\n  from fontTools.ttLib import TTFont\n  from fontbakery.profiles.shared_conditions import is_variable_font\n  from fontbakery.constants import (STATIC_STYLE_NAMES,\n                                    VARFONT_SUFFIXES)\n  if canonical_stylename(font):\n    yield PASS, f\"{font} is named canonically.\"\n  else:\n    if os.path.exists(font) and is_variable_font(TTFont(font)):\n      if suffix(font) in STATIC_STYLE_NAMES:\n        yield FAIL, (f'This is a variable font, but it is using'\n                      ' a naming scheme typical of a static font.')\n      yield FAIL, ('Please change the font filename to use one'\n                   ' of the following valid suffixes for variable fonts:'\n                  f' {\", \".join(VARFONT_SUFFIXES)}')\n    else:\n      style_names = '\", \"'.join(STATIC_STYLE_NAMES)\n      yield FAIL, (f'Style name used in \"{font}\" is not canonical.'\n                    ' You should rebuild the font using'\n                    ' any of the following'\n                   f' style names: \"{style_names}\".')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef family_directory(fonts):\n  if fonts:\n    dirname = os.path.dirname(fonts[0])\n    if dirname == '':\n      dirname = '.'\n    return dirname", "response": "Get the path of font project directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef descfile(family_directory):\n  if family_directory:\n    descfilepath = os.path.join(family_directory, \"DESCRIPTION.en_us.html\")\n    if os.path.exists(descfilepath):\n      return descfilepath", "response": "Get the path of the DESCRIPTION file of a given font project."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo the DESCRIPTION file contain broken links?", "response": "def com_google_fonts_check_description_broken_links(description):\n  \"\"\"Does DESCRIPTION file contain broken links?\"\"\"\n  from lxml.html import HTMLParser\n  import defusedxml.lxml\n  import requests\n  doc = defusedxml.lxml.fromstring(description, parser=HTMLParser())\n  broken_links = []\n  for link in doc.xpath('//a/@href'):\n    if link.startswith(\"mailto:\") and \\\n       \"@\" in link and \\\n       \".\" in link.split(\"@\")[1]:\n      yield INFO, (f\"Found an email address: {link}\")\n      continue\n\n    try:\n      response = requests.head(link, allow_redirects=True, timeout=10)\n      code = response.status_code\n      if code != requests.codes.ok:\n        broken_links.append((\"url: '{}' \"\n                             \"status code: '{}'\").format(link, code))\n    except requests.exceptions.Timeout:\n      yield WARN, (\"Timedout while attempting to access: '{}'.\"\n                   \" Please verify if that's a broken link.\").format(link)\n    except requests.exceptions.RequestException:\n      broken_links.append(link)\n\n  if len(broken_links) > 0:\n    yield FAIL, (\"The following links are broken\"\n                 \" in the DESCRIPTION file:\"\n                 \" '{}'\").format(\"', '\".join(broken_links))\n  else:\n    yield PASS, \"All links in the DESCRIPTION file look good!\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck METADATA. pb parse correctly.", "response": "def com_google_fonts_check_metadata_parses(family_directory):\n  \"\"\" Check METADATA.pb parse correctly. \"\"\"\n  from google.protobuf import text_format\n  from fontbakery.utils import get_FamilyProto_Message\n  try:\n    pb_file = os.path.join(family_directory, \"METADATA.pb\")\n    get_FamilyProto_Message(pb_file)\n    yield PASS, \"METADATA.pb parsed successfuly.\"\n  except text_format.ParseError as e:\n    yield FAIL, (f\"Family metadata at {family_directory} failed to parse.\\n\"\n                 f\"TRACEBACK:\\n{e}\")\n  except FileNotFoundError:\n    yield SKIP, f\"Font family at '{family_directory}' lacks a METADATA.pb file.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_fstype(ttFont):\n  value = ttFont['OS/2'].fsType\n  if value != 0:\n    FSTYPE_RESTRICTIONS = {\n      0x0002: (\"* The font must not be modified, embedded or exchanged in\"\n               \" any manner without first obtaining permission of\"\n               \" the legal owner.\"),\n      0x0004: (\"The font may be embedded, and temporarily loaded on the\"\n               \" remote system, but documents that use it must\"\n               \" not be editable.\"),\n      0x0008: (\"The font may be embedded but must only be installed\"\n               \" temporarily on other systems.\"),\n      0x0100: (\"The font may not be subsetted prior to embedding.\"),\n      0x0200: (\"Only bitmaps contained in the font may be embedded.\"\n               \" No outline data may be embedded.\")\n    }\n    restrictions = \"\"\n    for bit_mask in FSTYPE_RESTRICTIONS.keys():\n      if value & bit_mask:\n        restrictions += FSTYPE_RESTRICTIONS[bit_mask]\n\n    if value & 0b1111110011110001:\n      restrictions += (\"* There are reserved bits set,\"\n                       \" which indicates an invalid setting.\")\n\n    yield FAIL, (\"OS/2 fsType is a legacy DRM-related field.\\n\"\n                 \"In this font it is set to {} meaning that:\\n\"\n                 \"{}\\n\"\n                 \"No such DRM restrictions can be enabled on the\"\n                 \" Google Fonts collection, so the fsType field\"\n                 \" must be set to zero (Installable Embedding) instead.\\n\"\n                 \"Fonts with this setting indicate that they may be embedded\"\n                 \" and permanently installed on the remote system\"\n                 \" by an application.\\n\\n\"\n                 \" More detailed info is available at:\\n\"\n                 \" https://docs.microsoft.com/en-us\"\n                 \"/typography/opentype/spec/os2#fstype\"\n                 \"\").format(value, restrictions)\n  else:\n    yield PASS, (\"OS/2 fsType is properly set to zero.\")", "response": "Fonts with fsType field set to zero must be set to installable embedding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef registered_vendor_ids():\n  from bs4 import BeautifulSoup\n  from pkg_resources import resource_filename\n\n  registered_vendor_ids = {}\n  CACHED = resource_filename('fontbakery',\n                             'data/fontbakery-microsoft-vendorlist.cache')\n  content = open(CACHED, encoding='utf-8').read()\n  soup = BeautifulSoup(content, 'html.parser')\n\n  IDs = [chr(c + ord('a')) for c in range(ord('z') - ord('a') + 1)]\n  IDs.append(\"0-9-\")\n\n  for section_id in IDs:\n    section = soup.find('h2', {'id': section_id})\n    table = section.find_next_sibling('table')\n    if not table: continue\n\n    #print (\"table: '{}'\".format(table))\n    for row in table.findAll('tr'):\n      #print(\"ROW: '{}'\".format(row))\n      cells = row.findAll('td')\n      # pad the code to make sure it is a 4 char string,\n      # otherwise eg \"CF  \" will not be matched to \"CF\"\n      code = cells[0].string.strip()\n      code = code + (4 - len(code)) * ' '\n      labels = [label for label in cells[1].stripped_strings]\n      registered_vendor_ids[code] = labels[0]\n\n  return registered_vendor_ids", "response": "Get a list of vendor IDs from Microsoft s website."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck OS / 2 vendor id.", "response": "def com_google_fonts_check_vendor_id(ttFont, registered_vendor_ids):\n  \"\"\"Checking OS/2 achVendID.\"\"\"\n\n  SUGGEST_MICROSOFT_VENDORLIST_WEBSITE = (\n    \" You should set it to your own 4 character code,\"\n    \" and register that code with Microsoft at\"\n    \" https://www.microsoft.com\"\n  \"/typography/links/vendorlist.aspx\")\n\n  vid = ttFont['OS/2'].achVendID\n  bad_vids = ['UKWN', 'ukwn', 'PfEd']\n  if vid is None:\n    yield WARN, Message(\"not set\", \"OS/2 VendorID is not set.\" +\n                                   SUGGEST_MICROSOFT_VENDORLIST_WEBSITE)\n  elif vid in bad_vids:\n    yield WARN, Message(\"bad\", (\"OS/2 VendorID is '{}',\"\n                                \" a font editor default.\").format(vid) +\n                                SUGGEST_MICROSOFT_VENDORLIST_WEBSITE)\n  elif vid not in registered_vendor_ids.keys():\n    yield WARN, Message(\"unknown\", (\"OS/2 VendorID value '{}' is not\"\n                                    \" a known registered id.\").format(vid) +\n                                    SUGGEST_MICROSOFT_VENDORLIST_WEBSITE)\n  else:\n    yield PASS, f\"OS/2 VendorID '{vid}' looks good!\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_name_unwanted_chars(ttFont):\n  failed = False\n  replacement_map = [(\"\\u00a9\", '(c)'),\n                     (\"\\u00ae\", '(r)'),\n                     (\"\\u2122\", '(tm)')]\n  for name in ttFont['name'].names:\n    string = str(name.string, encoding=name.getEncoding())\n    for mark, ascii_repl in replacement_map:\n      new_string = string.replace(mark, ascii_repl)\n      if string != new_string:\n        yield FAIL, (\"NAMEID #{} contains symbol that should be\"\n                     \" replaced by '{}'.\").format(name.nameID,\n                                                  ascii_repl)\n        failed = True\n  if not failed:\n    yield PASS, (\"No need to substitute copyright, registered and\"\n                 \" trademark symbols in name table entries of this font.\")", "response": "Substitute copyright registered and trademark symbols in name table entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks OS / 2 usWeightClass.", "response": "def com_google_fonts_check_usweightclass(font, ttFont, style):\n  \"\"\"Checking OS/2 usWeightClass.\"\"\"\n  from fontbakery.profiles.shared_conditions import is_ttf\n\n  weight_name, expected_value = expected_os2_weight(style)\n  value = ttFont['OS/2'].usWeightClass\n\n  if value != expected_value:\n\n    if is_ttf(ttFont) and \\\n       (weight_name == 'Thin' and value == 100) or \\\n       (weight_name == 'ExtraLight' and value == 200):\n      yield WARN, (\"{}:{} is OK on TTFs, but OTF files with those values\"\n                   \" will cause bluring on Windows.\"\n                   \" GlyphsApp users must set a Instance Custom Parameter\"\n                   \" for the Thin and ExtraLight styles to 250 and 275,\"\n                   \" so that if OTFs are exported then it will not\"\n                   \" blur on Windows.\")\n    else:\n      yield FAIL, (\"OS/2 usWeightClass expected value for\"\n                   \" '{}' is {} but this font has\"\n                   \" {}.\").format(weight_name, expected_value, value)\n  else:\n    yield PASS, \"OS/2 usWeightClass value looks good!\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of paths for every license file found in a font project.", "response": "def licenses(family_directory):\n  \"\"\"Get a list of paths for every license\n     file found in a font project.\"\"\"\n  found = []\n  search_paths = [family_directory]\n  gitroot = git_rootdir(family_directory)\n  if gitroot and gitroot not in search_paths:\n    search_paths.append(gitroot)\n\n  for directory in search_paths:\n    if directory:\n      for license in ['OFL.txt', 'LICENSE.txt']:\n        license_path = os.path.join(directory, license)\n        if os.path.exists(license_path):\n          found.append(license_path)\n  return found"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_family_has_license(licenses):\n  if len(licenses) > 1:\n    yield FAIL, Message(\"multiple\",\n                        (\"More than a single license file found.\"\n                         \" Please review.\"))\n  elif not licenses:\n    yield FAIL, Message(\"no-license\",\n                        (\"No license file was found.\"\n                         \" Please add an OFL.txt or a LICENSE.txt file.\"\n                         \" If you are running fontbakery on a Google Fonts\"\n                         \" upstream repo, which is fine, just make sure\"\n                         \" there is a temporary license file in\"\n                         \" the same folder.\"))\n  else:\n    yield PASS, \"Found license at '{}'\".format(licenses[0])", "response": "Check font has a license."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking copyright namerecords match license file.", "response": "def com_google_fonts_check_name_license(ttFont, license):\n  \"\"\"Check copyright namerecords match license file.\"\"\"\n  from fontbakery.constants import PLACEHOLDER_LICENSING_TEXT\n  failed = False\n  placeholder = PLACEHOLDER_LICENSING_TEXT[license]\n  entry_found = False\n  for i, nameRecord in enumerate(ttFont[\"name\"].names):\n    if nameRecord.nameID == NameID.LICENSE_DESCRIPTION:\n      entry_found = True\n      value = nameRecord.toUnicode()\n      if value != placeholder:\n        failed = True\n        yield FAIL, Message(\"wrong\", \\\n                            (\"License file {} exists but\"\n                             \" NameID {} (LICENSE DESCRIPTION) value\"\n                             \" on platform {} ({})\"\n                             \" is not specified for that.\"\n                             \" Value was: \\\"{}\\\"\"\n                             \" Must be changed to \\\"{}\\\"\"\n                             \"\").format(license,\n                                        NameID.LICENSE_DESCRIPTION,\n                                        nameRecord.platformID,\n                                        PlatformID(nameRecord.platformID).name,\n                                        value,\n                                        placeholder))\n  if not entry_found:\n    yield FAIL, Message(\"missing\", \\\n                        (\"Font lacks NameID {} \"\n                         \"(LICENSE DESCRIPTION). A proper licensing entry\"\n                         \" must be set.\").format(NameID.LICENSE_DESCRIPTION))\n  elif not failed:\n    yield PASS, \"Licensing entry on name table is correctly set.\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlicensing URL matches License text on name table?", "response": "def com_google_fonts_check_name_license_url(ttFont, familyname):\n  \"\"\"\"License URL matches License text on name table?\"\"\"\n  from fontbakery.constants import PLACEHOLDER_LICENSING_TEXT\n  LEGACY_UFL_FAMILIES = [\"Ubuntu\", \"UbuntuCondensed\", \"UbuntuMono\"]\n  LICENSE_URL = {\n    'OFL.txt': 'http://scripts.sil.org/OFL',\n    'LICENSE.txt': 'http://www.apache.org/licenses/LICENSE-2.0',\n    'UFL.txt': 'https://www.ubuntu.com/legal/terms-and-policies/font-licence'\n  }\n  LICENSE_NAME = {\n    'OFL.txt': 'Open Font',\n    'LICENSE.txt': 'Apache',\n    'UFL.txt': 'Ubuntu Font License'\n  }\n  detected_license = False\n  for license in ['OFL.txt', 'LICENSE.txt', 'UFL.txt']:\n    placeholder = PLACEHOLDER_LICENSING_TEXT[license]\n    for nameRecord in ttFont['name'].names:\n      string = nameRecord.string.decode(nameRecord.getEncoding())\n      if nameRecord.nameID == NameID.LICENSE_DESCRIPTION and\\\n         string == placeholder:\n        detected_license = license\n        break\n\n  if detected_license == \"UFL.txt\" and familyname not in LEGACY_UFL_FAMILIES:\n    yield FAIL, Message(\"ufl\",\n                        (\"The Ubuntu Font License is only acceptable on\"\n                         \" the Google Fonts collection for legacy font\"\n                         \" families that already adopted such license.\"\n                         \" New Families should use eigther Apache or\"\n                         \" Open Font License.\"))\n  else:\n    found_good_entry = False\n    if detected_license:\n      failed = False\n      expected = LICENSE_URL[detected_license]\n      for nameRecord in ttFont['name'].names:\n        if nameRecord.nameID == NameID.LICENSE_INFO_URL:\n          string = nameRecord.string.decode(nameRecord.getEncoding())\n          if string == expected:\n            found_good_entry = True\n          else:\n            failed = True\n            yield FAIL, Message(\"licensing-inconsistency\",\n                                (\"Licensing inconsistency in name table\"\n                                 \" entries! NameID={} (LICENSE DESCRIPTION)\"\n                                 \" indicates {} licensing, but NameID={}\"\n                                 \" (LICENSE URL) has '{}'. Expected: '{}'\"\n                                 \"\").format(NameID.LICENSE_DESCRIPTION,\n                                            LICENSE_NAME[detected_license],\n                                            NameID.LICENSE_INFO_URL,\n                                            string, expected))\n    if not found_good_entry:\n      yield FAIL, Message(\"no-license-found\",\n                          (\"A known license URL must be provided in the\"\n                           \" NameID {} (LICENSE INFO URL) entry.\"\n                           \" Currently accepted licenses are Apache or\"\n                           \" Open Font License. For a small set of legacy\"\n                           \" families the Ubuntu Font License may be\"\n                           \" acceptable as well.\"\n                           \"\").format(NameID.LICENSE_INFO_URL))\n    else:\n      if failed:\n        yield FAIL, Message(\"bad-entries\",\n                            (\"Even though a valid license URL was seen in\"\n                             \" NAME table, there were also bad entries.\"\n                             \" Please review NameIDs {} (LICENSE DESCRIPTION)\"\n                             \" and {} (LICENSE INFO URL).\"\n                             \"\").format(NameID.LICENSE_DESCRIPTION,\n                                        NameID.LICENSE_INFO_URL))\n      else:\n        yield PASS, \"Font has a valid license URL in NAME table.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_name_description_max_length(ttFont):\n  failed = False\n  for name in ttFont['name'].names:\n    if (name.nameID == NameID.DESCRIPTION and\n        len(name.string.decode(name.getEncoding())) > 200):\n      failed = True\n      break\n\n  if failed:\n    yield WARN, (\"A few name table entries with ID={} (NameID.DESCRIPTION)\"\n                 \" are longer than 200 characters.\"\n                 \" Please check whether those entries are copyright notices\"\n                 \" mistakenly stored in the description string entries by\"\n                 \" a bug in an old FontLab version.\"\n                 \" If that's the case, then such copyright notices must be\"\n                 \" removed from these entries.\"\n                 \"\").format(NameID.DESCRIPTION)\n  else:\n    yield PASS, \"All description name records have reasonably small lengths.\"", "response": "Description strings in the name table must not exceed 200 characters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow hinting filesize impact. Current implementation simply logs useful info but there s no fail scenario for this checker.", "response": "def com_google_fonts_check_hinting_impact(font, ttfautohint_stats):\n  \"\"\"Show hinting filesize impact.\n\n     Current implementation simply logs useful info\n     but there's no fail scenario for this checker.\"\"\"\n\n  hinted = ttfautohint_stats[\"hinted_size\"]\n  dehinted = ttfautohint_stats[\"dehinted_size\"]\n  increase = hinted - dehinted\n  change = (float(hinted)/dehinted - 1) * 100\n\n  def filesize_formatting(s):\n    if s < 1024:\n      return f\"{s} bytes\"\n    elif s < 1024*1024:\n      return \"{:.1f}kb\".format(s/1024)\n    else:\n      return \"{:.1f}Mb\".format(s/(1024*1024))\n\n  hinted_size = filesize_formatting(hinted)\n  dehinted_size = filesize_formatting(dehinted)\n  increase = filesize_formatting(increase)\n\n  results_table = \"Hinting filesize impact:\\n\\n\"\n  results_table += f\"|  | {font} |\\n\"\n  results_table += \"|:--- | ---:|\\n\"\n  results_table += f\"| Dehinted Size | {dehinted_size} |\\n\"\n  results_table += f\"| Hinted Size | {hinted_size} |\\n\"\n  results_table += f\"| Increase | {increase} |\\n\"\n  results_table += f\"| Change   | {change:.1f} % |\\n\"\n  yield INFO, results_table"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_name_version_format(ttFont):\n  from fontbakery.utils import get_name_entry_strings\n  import re\n  def is_valid_version_format(value):\n    return re.match(r'Version\\s0*[1-9]+\\.\\d+', value)\n\n  failed = False\n  version_entries = get_name_entry_strings(ttFont, NameID.VERSION_STRING)\n  if len(version_entries) == 0:\n    failed = True\n    yield FAIL, Message(\"no-version-string\",\n                        (\"Font lacks a NameID.VERSION_STRING (nameID={})\"\n                         \" entry\").format(NameID.VERSION_STRING))\n  for ventry in version_entries:\n    if not is_valid_version_format(ventry):\n      failed = True\n      yield FAIL, Message(\"bad-version-strings\",\n                          (\"The NameID.VERSION_STRING (nameID={}) value must\"\n                           \" follow the pattern \\\"Version X.Y\\\" with X.Y\"\n                           \" between 1.000 and 9.999.\"\n                           \" Current version string is:\"\n                           \" \\\"{}\\\"\").format(NameID.VERSION_STRING,\n                                             ventry))\n  if not failed:\n    yield PASS, \"Version format in NAME table entries is correct.\"", "response": "Version format is correct in NAME table?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking gasp table for optimization rendering?", "response": "def com_google_fonts_check_gasp(ttFont):\n  \"\"\"Is 'gasp' table set to optimize rendering?\"\"\"\n\n  if \"gasp\" not in ttFont.keys():\n    yield FAIL, (\"Font is missing the 'gasp' table.\"\n                 \" Try exporting the font with autohinting enabled.\")\n  else:\n    if not isinstance(ttFont[\"gasp\"].gaspRange, dict):\n      yield FAIL, \"'gasp' table has no values.\"\n    else:\n      failed = False\n      if 0xFFFF not in ttFont[\"gasp\"].gaspRange:\n        yield WARN, (\"'gasp' table does not have an entry for all\"\n                     \" font sizes (gaspRange 0xFFFF).\")\n      else:\n        gasp_meaning = {\n          0x01: \"- Use gridfitting\",\n          0x02: \"- Use grayscale rendering\",\n          0x04: \"- Use gridfitting with ClearType symmetric smoothing\",\n          0x08: \"- Use smoothing along multiple axes with ClearType\u00ae\"\n        }\n        table = []\n        for key in ttFont[\"gasp\"].gaspRange.keys():\n          value = ttFont[\"gasp\"].gaspRange[key]\n          meaning = []\n          for flag, info in gasp_meaning.items():\n            if value & flag:\n              meaning.append(info)\n\n          meaning = \"\\n\\t\".join(meaning)\n          table.append(f\"PPM <= {key}:\\n\\tflag = 0x{value:02X}\\n\\t{meaning}\")\n\n        table = \"\\n\".join(table)\n        yield INFO, (\"These are the ppm ranges declared on the\"\n                    f\" gasp table:\\n\\n{table}\\n\")\n\n        for key in ttFont[\"gasp\"].gaspRange.keys():\n          if key != 0xFFFF:\n            yield WARN, (\"'gasp' table has a gaspRange of {} that\"\n                         \" may be unneccessary.\").format(key)\n            failed = True\n          else:\n            value = ttFont[\"gasp\"].gaspRange[0xFFFF]\n            if value != 0x0F:\n              failed = True\n              yield WARN, (f\"gaspRange 0xFFFF value 0x{value:02X}\"\n                            \" should be set to 0x0F.\")\n        if not failed:\n          yield PASS, (\"'gasp' table is correctly set, with one \"\n                       \"gaspRange:value of 0xFFFF:0x0F.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_name_familyname_first_char(ttFont):\n  from fontbakery.utils import get_name_entry_strings\n  failed = False\n  for familyname in get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME):\n    digits = map(str, range(0, 10))\n    if familyname[0] in digits:\n      yield FAIL, (\"Font family name '{}'\"\n                   \" begins with a digit!\").format(familyname)\n      failed = True\n  if failed is False:\n    yield PASS, \"Font family name first character is not a digit.\"", "response": "Font family name first character is not a digit?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_currency_chars(ttFont):\n\n  def font_has_char(ttFont, codepoint):\n    for subtable in ttFont['cmap'].tables:\n      if codepoint in subtable.cmap:\n        return True\n    #otherwise\n    return False\n\n  failed = False\n\n  OPTIONAL = {\n    #TODO: Do we want to check for this one?\n    #0x20A0: \"EUROPEAN CURRENCY SIGN\"\n  }\n  MANDATORY = {\n    0x20AC: \"EURO SIGN\"\n    # TODO: extend this list\n  }\n  for codepoint, charname in OPTIONAL.items():\n    if not font_has_char(ttFont, codepoint):\n      failed = True\n      yield WARN, f\"Font lacks \\\"{charname}\\\" character (unicode: 0x{codepoint:04X})\"\n\n  for codepoint, charname in MANDATORY.items():\n    if not font_has_char(ttFont, codepoint):\n      failed = True\n      yield FAIL, f\"Font lacks \\\"{charname}\\\" character (unicode: 0x{codepoint:04X})\"\n\n  if not failed:\n    yield PASS, \"Font has all expected currency sign characters.\"", "response": "Font has all expected currency sign characters?"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_name_ascii_only_entries(ttFont):\n  bad_entries = []\n  for name in ttFont[\"name\"].names:\n    if name.nameID == NameID.COPYRIGHT_NOTICE or \\\n       name.nameID == NameID.POSTSCRIPT_NAME:\n      string = name.string.decode(name.getEncoding())\n      try:\n        string.encode('ascii')\n      except:\n        bad_entries.append(name)\n        yield INFO, (\"Bad string at\"\n                     \" [nameID {}, '{}']:\"\n                     \" '{}'\"\n                     \"\").format(name.nameID,\n                                name.getEncoding(),\n                                string.encode(\"ascii\",\n                                              errors='xmlcharrefreplace'))\n  if len(bad_entries) > 0:\n    yield FAIL, (\"There are {} strings containing\"\n                 \" non-ASCII characters in the ASCII-only\"\n                 \" NAME table entries.\").format(len(bad_entries))\n  else:\n    yield PASS, (\"None of the ASCII-only NAME table entries\"\n                 \" contain non-ASCII characteres.\")", "response": "Check that all non - ASCII characters in ASCII - only NAME table entries are present in the font."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_metadata_unique_full_name_values(family_metadata):\n  fonts = {}\n  for f in family_metadata.fonts:\n    fonts[f.full_name] = f\n\n  if len(set(fonts.keys())) != len(family_metadata.fonts):\n    yield FAIL, (\"Found duplicated \\\"full_name\\\" values\"\n                 \" in METADATA.pb fonts field.\")\n  else:\n    yield PASS, (\"METADATA.pb \\\"fonts\\\" field only has\"\n                 \" unique \\\"full_name\\\" values.\")", "response": "METADATA. pb fonts field only has\n     unique full_name values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_metadata_license(family_metadata):\n  licenses = [\"APACHE2\", \"OFL\", \"UFL\"]\n  if family_metadata.license in licenses:\n    yield PASS, (\"Font license is declared\"\n                 \" in METADATA.pb as \\\"{}\\\"\").format(family_metadata.license)\n  else:\n    yield FAIL, (\"METADATA.pb license field (\\\"{}\\\")\"\n                 \" must be one of the following:\"\n                 \" {}\").format(family_metadata.license,\n                               licenses)", "response": "METADATA. pb license is declared in METADATA. pb?"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_metadata_menu_and_latin(family_metadata):\n  missing = []\n  for s in [\"menu\", \"latin\"]:\n    if s not in list(family_metadata.subsets):\n      missing.append(s)\n\n  if missing != []:\n    yield FAIL, (\"Subsets \\\"menu\\\" and \\\"latin\\\" are mandatory,\"\n                 \" but METADATA.pb is missing\"\n                 \" \\\"{}\\\"\").format(\" and \".join(missing))\n  else:\n    yield PASS, \"METADATA.pb contains \\\"menu\\\" and \\\"latin\\\" subsets.\"", "response": "METADATA. pb should contain at least menu and latin subsets."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that METADATA.pb family values are all the same.", "response": "def com_google_fonts_check_metadata_familyname(family_metadata):\n  \"\"\"Check that METADATA.pb family values are all the same.\"\"\"\n  name = \"\"\n  fail = False\n  for f in family_metadata.fonts:\n    if name and f.name != name:\n      fail = True\n    name = f.name\n  if fail:\n    yield FAIL, (\"METADATA.pb: Family name is not the same\"\n                 \" in all metadata \\\"fonts\\\" items.\")\n  else:\n    yield PASS, (\"METADATA.pb: Family name is the same\"\n                 \" in all metadata \\\"fonts\\\" items.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_metadata_regular_is_400(family_metadata):\n  badfonts = []\n  for f in family_metadata.fonts:\n    if f.full_name.endswith(\"Regular\") and f.weight != 400:\n      badfonts.append(f\"{f.filename} (weight: {f.weight})\")\n  if len(badfonts) > 0:\n    yield FAIL, (\"METADATA.pb: Regular font weight must be 400.\"\n                 \" Please fix these: {}\").format(\", \".join(badfonts))\n  else:\n    yield PASS, \"Regular has weight = 400.\"", "response": "METADATA. pb Regular font weight should be 400."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_metadata_nameid_family_name(ttFont, font_metadata):\n  from fontbakery.utils import get_name_entry_strings\n\n  familynames = get_name_entry_strings(ttFont, NameID.TYPOGRAPHIC_FAMILY_NAME)\n  if not familynames:\n      familynames = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n  if len(familynames) == 0:\n    yield FAIL, Message(\"missing\",\n                        (\"This font lacks a FONT_FAMILY_NAME entry\"\n                         \" (nameID={}) in the name\"\n                         \" table.\").format(NameID.FONT_FAMILY_NAME))\n  else:\n    if font_metadata.name not in familynames:\n      yield FAIL, Message(\"mismatch\",\n                          (\"Unmatched family name in font:\"\n                           \" TTF has \\\"{}\\\" while METADATA.pb\"\n                           \" has \\\"{}\\\"\").format(familynames[0],\n                                                 font_metadata.name))\n    else:\n      yield PASS, (\"Family name \\\"{}\\\" is identical\"\n                   \" in METADATA.pb and on the\"\n                   \" TTF file.\").format(font_metadata.name)", "response": "METADATA. pb font. name field matches family name declared on the name table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_metadata_nameid_post_script_name(ttFont, font_metadata):\n  failed = False\n  from fontbakery.utils import get_name_entry_strings\n\n  postscript_names = get_name_entry_strings(ttFont, NameID.POSTSCRIPT_NAME)\n  if len(postscript_names) == 0:\n    failed = True\n    yield FAIL, Message(\"missing\",\n                        (\"This font lacks a POSTSCRIPT_NAME\"\n                         \" entry (nameID={}) in the \"\n                         \"name table.\").format(NameID.POSTSCRIPT_NAME))\n  else:\n    for psname in postscript_names:\n      if psname != font_metadata.post_script_name:\n        failed = True\n        yield FAIL, Message(\"mismatch\",\n                            (\"Unmatched postscript name in font:\"\n                             \" TTF has \\\"{}\\\" while METADATA.pb\"\n                             \" has \\\"{}\\\".\"\n                             \"\").format(psname,\n                                        font_metadata.post_script_name))\n  if not failed:\n    yield PASS, (\"Postscript name \\\"{}\\\" is identical\"\n                 \" in METADATA.pb and on the\"\n                 \" TTF file.\").format(font_metadata.post_script_name)", "response": "METADATA. pb font. post_script_name matches the postscript name declared on the name table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_metadata_nameid_font_name(ttFont, style, font_metadata):\n  from fontbakery.utils import get_name_entry_strings\n  from fontbakery.constants import RIBBI_STYLE_NAMES\n\n  if style in RIBBI_STYLE_NAMES:\n    font_familynames = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n    nameid = NameID.FONT_FAMILY_NAME\n  else:\n    font_familynames = get_name_entry_strings(ttFont, NameID.TYPOGRAPHIC_FAMILY_NAME)\n    nameid = NameID.TYPOGRAPHIC_FAMILY_NAME\n\n  if len(font_familynames) == 0:\n    yield FAIL, Message(\"lacks-entry\",\n                        (f\"This font lacks a {NameID(nameid).name} entry\"\n                         f\" (nameID={nameid}) in the name table.\"))\n  else:\n    for font_familyname in font_familynames:\n      if font_familyname != font_metadata.name:\n        yield FAIL, Message(\"mismatch\",\n                            (\"Unmatched familyname in font:\"\n                             \" TTF has \\\"{}\\\" while METADATA.pb has\"\n                             \" name=\\\"{}\\\".\").format(font_familyname,\n                                                     font_metadata.name))\n      else:\n        yield PASS, (\"OK: Family name \\\"{}\\\" is identical\"\n                     \" in METADATA.pb and on the\"\n                     \" TTF file.\").format(font_metadata.name)", "response": "METADATA. pb font. name value should be same as the family name declared on the name table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_metadata_match_fullname_postscript(font_metadata):\n  import re\n  regex = re.compile(r\"\\W\")\n  post_script_name = regex.sub(\"\", font_metadata.post_script_name)\n  fullname = regex.sub(\"\", font_metadata.full_name)\n  if fullname != post_script_name:\n    yield FAIL, (\"METADATA.pb font full_name=\\\"{}\\\"\"\n                 \" does not match post_script_name =\"\n                 \" \\\"{}\\\"\").format(font_metadata.full_name,\n                                   font_metadata.post_script_name)\n  else:\n    yield PASS, (\"METADATA.pb font fields \\\"full_name\\\" and\"\n                 \" \\\"post_script_name\\\" have equivalent values.\")", "response": "METADATA. pb font. full_name and font. post_script_name\n     fields have equivalent values?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_metadata_match_filename_postscript(font_metadata):\n  post_script_name = font_metadata.post_script_name\n  filename = os.path.splitext(font_metadata.filename)[0]\n\n  if filename != post_script_name:\n    yield FAIL, (\"METADATA.pb font filename=\\\"{}\\\" does not match\"\n                 \" post_script_name=\\\"{}\\\".\"\n                 \"\").format(font_metadata.filename,\n                            font_metadata.post_script_name)\n  else:\n    yield PASS, (\"METADATA.pb font fields \\\"filename\\\" and\"\n                 \" \\\"post_script_name\\\" have equivalent values.\")", "response": "METADATA. pb font. filename and font. post_script_name fields have equivalent values?"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_metadata_valid_name_values(style,\n                                                      font_metadata,\n                                                      font_familynames,\n                                                      typographic_familynames):\n  \"\"\"METADATA.pb font.name field contains font name in right format?\"\"\"\n  from fontbakery.constants import RIBBI_STYLE_NAMES\n  if style in RIBBI_STYLE_NAMES:\n    familynames = font_familynames\n  else:\n    familynames = typographic_familynames\n\n  failed = False\n  for font_familyname in familynames:\n    if font_familyname not in font_metadata.name:\n      failed = True\n      yield FAIL, (\"METADATA.pb font.name field (\\\"{}\\\")\"\n                   \" does not match correct font name format (\\\"{}\\\").\"\n                   \"\").format(font_metadata.name,\n                              font_familyname)\n  if not failed:\n    yield PASS, (\"METADATA.pb font.name field contains\"\n                 \" font name in right format.\")", "response": "METADATA. pb font. name field contains font name in right format?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_metadata_valid_full_name_values(style,\n                                                           font_metadata,\n                                                           font_familynames,\n                                                           typographic_familynames):\n  \"\"\"METADATA.pb font.full_name field contains font name in right format?\"\"\"\n  from fontbakery.constants import RIBBI_STYLE_NAMES\n  if style in RIBBI_STYLE_NAMES:\n    familynames = font_familynames\n    if familynames == []:\n      yield SKIP, \"No FONT_FAMILYNAME\"\n  else:\n    familynames = typographic_familynames\n    if familynames == []:\n      yield SKIP, \"No TYPOGRAPHIC_FAMILYNAME\"\n\n  for font_familyname in familynames:\n    if font_familyname in font_metadata.full_name:\n      yield PASS, (\"METADATA.pb font.full_name field contains\"\n                   \" font name in right format.\"\n                   \" ('{}' in '{}')\").format(font_familyname,\n                                             font_metadata.full_name)\n    else:\n      yield FAIL, (\"METADATA.pb font.full_name field (\\\"{}\\\")\"\n                   \" does not match correct font name format (\\\"{}\\\").\"\n                   \"\").format(font_metadata.full_name,\n                              font_familyname)", "response": "METADATA. pb font. full_name field contains font name in right format?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef com_google_fonts_check_metadata_valid_post_script_name_values(font_metadata,\n                                                                  font_familynames):\n  \"\"\"METADATA.pb font.post_script_name field\n     contains font name in right format?\n  \"\"\"\n  for font_familyname in font_familynames:\n    psname = \"\".join(str(font_familyname).split())\n    if psname in \"\".join(font_metadata.post_script_name.split(\"-\")):\n      yield PASS, (\"METADATA.pb postScriptName field\"\n                   \" contains font name in right format.\")\n    else:\n      yield FAIL, (\"METADATA.pb postScriptName (\\\"{}\\\")\"\n                   \" does not match correct font name format (\\\"{}\\\").\"\n                   \"\").format(font_metadata.post_script_name,\n                              font_familyname)", "response": "METADATA. pb font. post_script_name field\n     contains font name in right format?"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopyrights notices match canonical pattern in METADATA.pb", "response": "def com_google_fonts_check_metadata_valid_copyright(font_metadata):\n  \"\"\"Copyright notices match canonical pattern in METADATA.pb\"\"\"\n  import re\n  string = font_metadata.copyright\n  does_match = re.search(r'Copyright [0-9]{4} The .* Project Authors \\([^\\@]*\\)',\n                           string)\n  if does_match:\n    yield PASS, \"METADATA.pb copyright string is good\"\n  else:\n    yield FAIL, (\"METADATA.pb: Copyright notices should match\"\n                 \" a pattern similar to:\"\n                 \" 'Copyright 2017 The Familyname\"\n                 \" Project Authors (git url)'\\n\"\n                 \"But instead we have got:\"\n                 \" '{}'\").format(string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_font_copyright(ttFont):\n  import re\n  from fontbakery.utils import get_name_entry_strings\n\n  failed = False\n  for string in get_name_entry_strings(ttFont, NameID.COPYRIGHT_NOTICE):\n    does_match = re.search(r'Copyright [0-9]{4} The .* Project Authors \\([^\\@]*\\)',\n                           string)\n    if does_match:\n      yield PASS, (\"Name Table entry: Copyright field '{}'\"\n                   \" matches canonical pattern.\").format(string)\n    else:\n      failed = True\n      yield FAIL, (\"Name Table entry: Copyright notices should match\"\n                   \" a pattern similar to:\"\n                   \" 'Copyright 2017 The Familyname\"\n                   \" Project Authors (git url)'\\n\"\n                   \"But instead we have got:\"\n                   \" '{}'\").format(string)\n  if not failed:\n    yield PASS, \"Name table copyright entries are good\"", "response": "Copyright notices match canonical pattern in fonts?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef com_google_fonts_check_metadata_italic_style(ttFont, font_metadata):\n  from fontbakery.utils import get_name_entry_strings\n  from fontbakery.constants import MacStyle\n\n  if font_metadata.style != \"italic\":\n    yield SKIP, \"This check only applies to italic fonts.\"\n  else:\n    font_fullname = get_name_entry_strings(ttFont, NameID.FULL_FONT_NAME)\n    if len(font_fullname) == 0:\n      yield SKIP, \"Font lacks fullname entries in name table.\"\n      # this fail scenario was already checked above\n      # (passing those previous checks is a prerequisite for this one)\n      # FIXME: Could we pack this into a condition ?\n    else:\n      # FIXME: here we only check the first name entry.\n      #        Should we iterate over them all ? Or should we check\n      #        if they're all the same?\n      font_fullname = font_fullname[0]\n\n      if not bool(ttFont[\"head\"].macStyle & MacStyle.ITALIC):\n        yield FAIL, Message(\"bad-macstyle\",\n                            \"METADATA.pb style has been set to italic\"\n                            \" but font macStyle is improperly set.\")\n      elif not font_fullname.split(\"-\")[-1].endswith(\"Italic\"):\n        yield FAIL, Message(\"bad-fullfont-name\",\n                            (\"Font macStyle Italic bit is set\"\n                             \" but nameID {} (\\\"{}\\\") is not ended with\"\n                             \" \\\"Italic\\\"\").format(NameID.FULL_FONT_NAME,\n                                                   font_fullname))\n      else:\n        yield PASS, (\"OK: METADATA.pb font.style \\\"italic\\\"\"\n                     \" matches font internals.\")", "response": "METADATA. pb font. style italic matches font internals?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_metadata_normal_style(ttFont, font_metadata):\n  from fontbakery.utils import get_name_entry_strings\n  from fontbakery.constants import MacStyle\n\n  if font_metadata.style != \"normal\":\n    yield SKIP, \"This check only applies to normal fonts.\"\n    # FIXME: declare a common condition called \"normal_style\"\n  else:\n    font_familyname = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n    font_fullname = get_name_entry_strings(ttFont, NameID.FULL_FONT_NAME)\n    if len(font_familyname) == 0 or len(font_fullname) == 0:\n      yield SKIP, (\"Font lacks familyname and/or\"\n                   \" fullname entries in name table.\")\n      # FIXME: This is the same SKIP condition as in check/metadata/italic_style\n      #        so we definitely need to address them with a common condition!\n    else:\n      font_familyname = font_familyname[0]\n      font_fullname = font_fullname[0]\n\n      if bool(ttFont[\"head\"].macStyle & MacStyle.ITALIC):\n        yield FAIL, Message(\"bad-macstyle\",\n                            (\"METADATA.pb style has been set to normal\"\n                             \" but font macStyle is improperly set.\"))\n      elif font_familyname.split(\"-\")[-1].endswith('Italic'):\n        yield FAIL, Message(\"familyname-italic\",\n                            (\"Font macStyle indicates a non-Italic font, but\"\n                             \" nameID {} (FONT_FAMILY_NAME: \\\"{}\\\") ends with\"\n                             \" \\\"Italic\\\".\").format(NameID.FONT_FAMILY_NAME,\n                                                    font_familyname))\n      elif font_fullname.split(\"-\")[-1].endswith(\"Italic\"):\n        yield FAIL, Message(\"fullfont-italic\",\n                            (\"Font macStyle indicates a non-Italic font but\"\n                             \" nameID {} (FULL_FONT_NAME: \\\"{}\\\") ends with\"\n                             \" \\\"Italic\\\".\").format(NameID.FULL_FONT_NAME,\n                                                    font_fullname))\n      else:\n        yield PASS, (\"METADATA.pb font.style \\\"normal\\\"\"\n                     \" matches font internals.\")", "response": "METADATA. pb font. style normal matches font internals?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_metadata_nameid_family_and_full_names(ttFont, font_metadata):\n  from fontbakery.utils import get_name_entry_strings\n\n  font_familynames = get_name_entry_strings(ttFont, NameID.TYPOGRAPHIC_FAMILY_NAME)\n  if font_familynames:\n      font_familyname = font_familynames[0]\n  else:\n      font_familyname = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)[0]\n  font_fullname = get_name_entry_strings(ttFont, NameID.FULL_FONT_NAME)[0]\n  # FIXME: common condition/name-id check as in the two previous checks.\n\n  if font_fullname != font_metadata.full_name:\n    yield FAIL, Message(\"fullname-mismatch\",\n                        (\"METADATA.pb: Fullname (\\\"{}\\\")\"\n                         \" does not match name table\"\n                         \" entry \\\"{}\\\" !\").format(font_metadata.full_name,\n                                                   font_fullname))\n  elif font_familyname != font_metadata.name:\n    yield FAIL, Message(\"familyname-mismatch\",\n                        (\"METADATA.pb Family name \\\"{}\\\")\"\n                         \" does not match name table\"\n                         \" entry \\\"{}\\\" !\").format(font_metadata.name,\n                                                   font_familyname))\n  else:\n    yield PASS, (\"METADATA.pb familyname and fullName fields\"\n                 \" match corresponding name table entries.\")", "response": "METADATA. pb font. name and font. full_name fields match corresponding name table entries?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_metadata_match_name_familyname(family_metadata, font_metadata):\n  if font_metadata.name != family_metadata.name:\n    yield FAIL, (\"METADATA.pb: {}: Family name \\\"{}\\\"\"\n                 \" does not match\"\n                 \" font name: \\\"{}\\\"\").format(font_metadata.filename,\n                                              family_metadata.name,\n                                              font_metadata.name)\n  else:\n    yield PASS, \"Font name is the same as family name.\"", "response": "METADATA. pb font. name is the same as family name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_metadata_os2_weightclass(ttFont,\n                                                    font_metadata):\n  \"\"\"Checking OS/2 usWeightClass matches weight specified at METADATA.pb.\"\"\"\n  # Weight name to value mapping:\n  GF_API_WEIGHT_NAMES = {250: \"Thin\",\n                         275: \"ExtraLight\",\n                         300: \"Light\",\n                         400: \"Regular\",\n                         500: \"Medium\",\n                         600: \"SemiBold\",\n                         700: \"Bold\",\n                         800: \"ExtraBold\",\n                         900: \"Black\"}\n  CSS_WEIGHT_NAMES = {\n    100: \"Thin\",\n    200: \"ExtraLight\",\n    300: \"Light\",\n    400: \"Regular\",\n    500: \"Medium\",\n    600: \"SemiBold\",\n    700: \"Bold\",\n    800: \"ExtraBold\",\n    900: \"Black\"\n  }\n  gf_weight = GF_API_WEIGHT_NAMES.get(ttFont[\"OS/2\"].usWeightClass,\n                                      \"bad Google Fonts API weight value\")\n  css_weight = CSS_WEIGHT_NAMES.get(font_metadata.weight,\n                                    \"bad CSS weight value\")\n  if gf_weight != css_weight:\n    yield FAIL, (\"OS/2 usWeightClass ({}:\\\"{}\\\") does not match\"\n                 \" weight specified at METADATA.pb ({}:\\\"{}\\\").\"\n                 \"\").format(ttFont[\"OS/2\"].usWeightClass,\n                            gf_weight,\n                            font_metadata.weight,\n                            css_weight)\n  else:\n    yield PASS, (\"OS/2 usWeightClass matches\"\n                 \" weight specified at METADATA.pb\")", "response": "Check OS / 2 usWeightClass matches weight specified at METADATA. pb."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_unitsperem_strict(ttFont):\n  upm_height = ttFont[\"head\"].unitsPerEm\n  ACCEPTABLE = [16, 32, 64, 128, 256, 500,\n                512, 1000, 1024, 2000, 2048]\n  if upm_height not in ACCEPTABLE:\n    yield FAIL, (f\"Font em size (unitsPerEm) is {upm_height}.\"\n                  \" If possible, please consider using 1000\"\n                  \" or even 2000 (which is ideal for\"\n                  \" Variable Fonts).\"\n                  \" The acceptable values for unitsPerEm,\"\n                 f\" though, are: {ACCEPTABLE}.\")\n  elif upm_height != 2000:\n    yield WARN, (f\"Even though unitsPerEm ({upm_height}) in\"\n                  \" this font is reasonable. It is strongly\"\n                  \" advised to consider changing it to 2000,\"\n                  \" since it will likely improve the quality of\"\n                  \" Variable Fonts by avoiding excessive\"\n                  \" rounding of coordinates on interpolations.\")\n  else:\n    yield PASS, \"Font em size is good (unitsPerEm = 2000).\"", "response": "Strict unitsPerEm criteria for Google Fonts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a dictionary of TTFont objects of all font files of a given family.", "response": "def remote_styles(family_metadata):\n  \"\"\"Get a dictionary of TTFont objects of all font files of\n     a given family as currently hosted at Google Fonts.\n  \"\"\"\n\n  def download_family_from_Google_Fonts(family_name):\n    \"\"\"Return a zipfile containing a font family hosted on fonts.google.com\"\"\"\n    from zipfile import ZipFile\n    from fontbakery.utils import download_file\n    url_prefix = 'https://fonts.google.com/download?family='\n    url = '{}{}'.format(url_prefix, family_name.replace(' ', '+'))\n    return ZipFile(download_file(url))\n\n\n  def fonts_from_zip(zipfile):\n    '''return a list of fontTools TTFonts'''\n    from fontTools.ttLib import TTFont\n    from io import BytesIO\n    fonts = []\n    for file_name in zipfile.namelist():\n      if file_name.lower().endswith(\".ttf\"):\n        file_obj = BytesIO(zipfile.open(file_name).read())\n        fonts.append([file_name, TTFont(file_obj)])\n    return fonts\n\n  if (not listed_on_gfonts_api(family_metadata) or\n      not family_metadata):\n    return None\n\n  remote_fonts_zip = download_family_from_Google_Fonts(family_metadata.name)\n  rstyles = {}\n\n  for remote_filename, remote_font in fonts_from_zip(remote_fonts_zip):\n    remote_style = os.path.splitext(remote_filename)[0]\n    if '-' in remote_style:\n      remote_style = remote_style.split('-')[1]\n    rstyles[remote_style] = remote_font\n  return rstyles"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef github_gfonts_ttFont(ttFont, license):\n  if not license:\n    return\n\n  from fontbakery.utils import download_file\n  from fontTools.ttLib import TTFont\n  from urllib.request import HTTPError\n  LICENSE_DIRECTORY = {\n    \"OFL.txt\": \"ofl\",\n    \"UFL.txt\": \"ufl\",\n    \"LICENSE.txt\": \"apache\"\n  }\n  filename = os.path.basename(ttFont.reader.file.name)\n  fontname = filename.split('-')[0].lower()\n  url = (\"https://github.com/google/fonts/raw/master\"\n         \"/{}/{}/{}\").format(LICENSE_DIRECTORY[license],\n                             fontname,\n                             filename)\n  try:\n    fontfile = download_file(url)\n    return TTFont(fontfile)\n  except HTTPError:\n    return None", "response": "Download a TTFont object from Google Fonts git repository."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nversion number has increased since previous release on Google Fonts?", "response": "def com_google_fonts_check_version_bump(ttFont,\n                                        api_gfonts_ttFont,\n                                        github_gfonts_ttFont):\n  \"\"\"Version number has increased since previous release on Google Fonts?\"\"\"\n  v_number = ttFont[\"head\"].fontRevision\n  api_gfonts_v_number = api_gfonts_ttFont[\"head\"].fontRevision\n  github_gfonts_v_number = github_gfonts_ttFont[\"head\"].fontRevision\n  failed = False\n\n  if v_number == api_gfonts_v_number:\n    failed = True\n    yield FAIL, (\"Version number {} is equal to\"\n                 \" version on Google Fonts.\").format(v_number)\n\n  if v_number < api_gfonts_v_number:\n    failed = True\n    yield FAIL, (\"Version number {} is less than\"\n                 \" version on Google Fonts ({}).\"\n                 \"\").format(v_number,\n                            api_gfonts_v_number)\n\n  if v_number == github_gfonts_v_number:\n    failed = True\n    yield FAIL, (\"Version number {} is equal to\"\n                 \" version on Google Fonts GitHub repo.\"\n                 \"\").format(v_number)\n\n  if v_number < github_gfonts_v_number:\n    failed = True\n    yield FAIL, (\"Version number {} is less than\"\n                 \" version on Google Fonts GitHub repo ({}).\"\n                 \"\").format(v_number,\n                            github_gfonts_v_number)\n\n  if not failed:\n    yield PASS, (\"Version number {} is greater than\"\n                 \" version on Google Fonts GitHub ({})\"\n                 \" and production servers ({}).\"\n                 \"\").format(v_number,\n                            github_gfonts_v_number,\n                            api_gfonts_v_number)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_production_glyphs_similarity(ttFont, api_gfonts_ttFont):\n\n  def glyphs_surface_area(ttFont):\n    \"\"\"Calculate the surface area of a glyph's ink\"\"\"\n    from fontTools.pens.areaPen import AreaPen\n    glyphs = {}\n    glyph_set = ttFont.getGlyphSet()\n    area_pen = AreaPen(glyph_set)\n\n    for glyph in glyph_set.keys():\n      glyph_set[glyph].draw(area_pen)\n\n      area = area_pen.value\n      area_pen.value = 0\n      glyphs[glyph] = area\n    return glyphs\n\n  bad_glyphs = []\n  these_glyphs = glyphs_surface_area(ttFont)\n  gfonts_glyphs = glyphs_surface_area(api_gfonts_ttFont)\n\n  shared_glyphs = set(these_glyphs) & set(gfonts_glyphs)\n\n  this_upm = ttFont['head'].unitsPerEm\n  gfonts_upm = api_gfonts_ttFont['head'].unitsPerEm\n\n  for glyph in shared_glyphs:\n    # Normalize area difference against comparison's upm\n    this_glyph_area = (these_glyphs[glyph] / this_upm) * gfonts_upm\n    gfont_glyph_area = (gfonts_glyphs[glyph] / gfonts_upm) * this_upm\n\n    if abs(this_glyph_area - gfont_glyph_area) > 7000:\n      bad_glyphs.append(glyph)\n\n  if bad_glyphs:\n    yield WARN, (\"Following glyphs differ greatly from\"\n                 \" Google Fonts version: [{}]\").format(\", \".join(bad_glyphs))\n  else:\n    yield PASS, (\"Glyphs are similar in\"\n                 \" comparison to the Google Fonts version.\")", "response": "Fonts version is similar to Google Fonts version?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking OS / 2 fsSelection value.", "response": "def com_google_fonts_check_fsselection(ttFont, style):\n  \"\"\"Checking OS/2 fsSelection value.\"\"\"\n  from fontbakery.utils import check_bit_entry\n  from fontbakery.constants import (STATIC_STYLE_NAMES,\n                                    RIBBI_STYLE_NAMES,\n                                    FsSelection)\n\n  # Checking fsSelection REGULAR bit:\n  expected = \"Regular\" in style or \\\n             (style in STATIC_STYLE_NAMES and\n              style not in RIBBI_STYLE_NAMES and\n              \"Italic\" not in style)\n  yield check_bit_entry(ttFont, \"OS/2\", \"fsSelection\",\n                        expected,\n                        bitmask=FsSelection.REGULAR,\n                        bitname=\"REGULAR\")\n\n  # Checking fsSelection ITALIC bit:\n  expected = \"Italic\" in style\n  yield check_bit_entry(ttFont, \"OS/2\", \"fsSelection\",\n                        expected,\n                        bitmask=FsSelection.ITALIC,\n                        bitname=\"ITALIC\")\n\n  # Checking fsSelection BOLD bit:\n  expected = style in [\"Bold\", \"BoldItalic\"]\n  yield check_bit_entry(ttFont, \"OS/2\", \"fsSelection\",\n                        expected,\n                        bitmask=FsSelection.BOLD,\n                        bitname=\"BOLD\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck post. italicAngle value.", "response": "def com_google_fonts_check_italic_angle(ttFont, style):\n  \"\"\"Checking post.italicAngle value.\"\"\"\n  failed = False\n  value = ttFont[\"post\"].italicAngle\n\n  # Checking that italicAngle <= 0\n  if value > 0:\n    failed = True\n    yield FAIL, Message(\"positive\",\n                        (\"The value of post.italicAngle is positive, which\"\n                         \" is likely a mistake and should become negative,\"\n                         \" from {} to {}.\").format(value, -value))\n\n  # Checking that italicAngle is less than 20\u00b0 (not good) or 30\u00b0 (bad)\n  # Also note we invert the value to check it in a clear way\n  if abs(value) > 30:\n    failed = True\n    yield FAIL, Message(\"over -30 degrees\",\n                        (\"The value of post.italicAngle ({}) is very\"\n                         \" high (over -30\u00b0!) and should be\"\n                         \" confirmed.\").format(value))\n  elif abs(value) > 20:\n    failed = True\n    yield WARN, Message(\"over -20 degrees\",\n                        (\"The value of post.italicAngle ({}) seems very\"\n                         \" high (over -20\u00b0!) and should be\"\n                         \" confirmed.\").format(value))\n\n\n  # Checking if italicAngle matches font style:\n  if \"Italic\" in style:\n    if ttFont['post'].italicAngle == 0:\n      failed = True\n      yield FAIL, Message(\"zero-italic\",\n                          (\"Font is italic, so post.italicAngle\"\n                           \" should be non-zero.\"))\n  else:\n    if ttFont[\"post\"].italicAngle != 0:\n      failed = True\n      yield FAIL, Message(\"non-zero-normal\",\n                          (\"Font is not italic, so post.italicAngle\"\n                           \" should be equal to zero.\"))\n\n  if not failed:\n    yield PASS, (\"Value of post.italicAngle is {}\"\n                 \" with style='{}'.\").format(value, style)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking head. macStyle value.", "response": "def com_google_fonts_check_mac_style(ttFont, style):\n  \"\"\"Checking head.macStyle value.\"\"\"\n  from fontbakery.utils import check_bit_entry\n  from fontbakery.constants import MacStyle\n\n  # Checking macStyle ITALIC bit:\n  expected = \"Italic\" in style\n  yield check_bit_entry(ttFont, \"head\", \"macStyle\",\n                        expected,\n                        bitmask=MacStyle.ITALIC,\n                        bitname=\"ITALIC\")\n\n  # Checking macStyle BOLD bit:\n  expected = style in [\"Bold\", \"BoldItalic\"]\n  yield check_bit_entry(ttFont, \"head\", \"macStyle\",\n                        expected,\n                        bitmask=MacStyle.BOLD,\n                        bitname=\"BOLD\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_contour_count(ttFont):\n  from fontbakery.glyphdata import desired_glyph_data as glyph_data\n  from fontbakery.utils import (get_font_glyph_data,\n                                pretty_print_list)\n  # rearrange data structure:\n  desired_glyph_data = {}\n  for glyph in glyph_data:\n    desired_glyph_data[glyph['unicode']] = glyph\n\n  bad_glyphs = []\n  desired_glyph_contours = {f: desired_glyph_data[f]['contours']\n                            for f in desired_glyph_data}\n\n  font_glyph_data = get_font_glyph_data(ttFont)\n\n  if font_glyph_data is None:\n      yield FAIL, \"This font lacks cmap data.\"\n  else:\n    font_glyph_contours = {f['unicode']: list(f['contours'])[0]\n                           for f in font_glyph_data}\n\n    shared_glyphs = set(desired_glyph_contours) & set(font_glyph_contours)\n    for glyph in shared_glyphs:\n      if font_glyph_contours[glyph] not in desired_glyph_contours[glyph]:\n        bad_glyphs.append([glyph,\n                           font_glyph_contours[glyph],\n                           desired_glyph_contours[glyph]])\n\n    if len(bad_glyphs) > 0:\n      cmap = ttFont['cmap'].getcmap(PlatformID.WINDOWS,\n                                    WindowsEncodingID.UNICODE_BMP).cmap\n      bad_glyphs_name = [(\"Glyph name: {}\\t\"\n                          \"Contours detected: {}\\t\"\n                          \"Expected: {}\").format(cmap[name],\n                                                 count,\n                                                 pretty_print_list(expected,\n                                                                   shorten=None,\n                                                                   glue=\"or\"))\n                         for name, count, expected in bad_glyphs]\n      yield WARN, ((\"This check inspects the glyph outlines and detects the\"\n                    \" total number of contours in each of them. The expected\"\n                    \" values are infered from the typical ammounts of\"\n                    \" contours observed in a large collection of reference\"\n                    \" font families. The divergences listed below may simply\"\n                    \" indicate a significantly different design on some of\"\n                    \" your glyphs. On the other hand, some of these may flag\"\n                    \" actual bugs in the font such as glyphs mapped to an\"\n                    \" incorrect codepoint. Please consider reviewing\"\n                    \" the design and codepoint assignment of these to make\"\n                    \" sure they are correct.\\n\"\n                    \"\\n\"\n                    \"The following glyphs do not have the recommended\"\n                    \" number of contours:\\n\"\n                    \"\\n{}\").format('\\n'.join(bad_glyphs_name)))\n    else:\n      yield PASS, \"All glyphs have the recommended amount of contours\"", "response": "Check if each glyph has the recommended amount of contours."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks font has same encoded glyphs as version hosted on fonts.google.com", "response": "def com_google_fonts_check_production_encoded_glyphs(ttFont, api_gfonts_ttFont):\n  \"\"\"Check font has same encoded glyphs as version hosted on\n  fonts.google.com\"\"\"\n  cmap = ttFont['cmap'].getcmap(3, 1).cmap\n  gf_cmap = api_gfonts_ttFont['cmap'].getcmap(3, 1).cmap\n  missing_codepoints = set(gf_cmap.keys()) - set(cmap.keys())\n\n  if missing_codepoints:\n    hex_codepoints = ['0x' + hex(c).upper()[2:].zfill(4) for c\n                      in missing_codepoints]\n    yield FAIL, (\"Font is missing the following glyphs\"\n                 \" from the previous release\"\n                 \" [{}]\").format(', '.join(hex_codepoints))\n  else:\n    yield PASS, ('Font has all the glyphs from the previous release')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopyright field for this font on METADATA. pb matches all copyright notice entries on the name table?", "response": "def com_google_fonts_check_metadata_nameid_copyright(ttFont, font_metadata):\n  \"\"\"Copyright field for this font on METADATA.pb matches\n     all copyright notice entries on the name table ?\"\"\"\n  failed = False\n  for nameRecord in ttFont['name'].names:\n    string = nameRecord.string.decode(nameRecord.getEncoding())\n    if nameRecord.nameID == NameID.COPYRIGHT_NOTICE and\\\n       string != font_metadata.copyright:\n        failed = True\n        yield FAIL, (\"Copyright field for this font on METADATA.pb ('{}')\"\n                     \" differs from a copyright notice entry\"\n                     \" on the name table:\"\n                     \" '{}'\").format(font_metadata.copyright,\n                                     string)\n  if not failed:\n    yield PASS, (\"Copyright field for this font on METADATA.pb matches\"\n                 \" copyright notice entries on the name table.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_name_mandatory_entries(ttFont, style):\n  from fontbakery.utils import get_name_entry_strings\n  from fontbakery.constants import RIBBI_STYLE_NAMES\n\n  required_nameIDs = [NameID.FONT_FAMILY_NAME,\n                      NameID.FONT_SUBFAMILY_NAME,\n                      NameID.FULL_FONT_NAME,\n                      NameID.POSTSCRIPT_NAME]\n  if style not in RIBBI_STYLE_NAMES:\n    required_nameIDs += [NameID.TYPOGRAPHIC_FAMILY_NAME,\n                         NameID.TYPOGRAPHIC_SUBFAMILY_NAME]\n  failed = False\n  # The font must have at least these name IDs:\n  for nameId in required_nameIDs:\n    if len(get_name_entry_strings(ttFont, nameId)) == 0:\n      failed = True\n      yield FAIL, (f\"Font lacks entry with nameId={nameId}\"\n                   f\" ({NameID(nameId).name})\")\n  if not failed:\n    yield PASS, \"Font contains values for all mandatory name table entries.\"", "response": "Font has all mandatory name table entries?"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks name table: FONT_FAMILY_NAME entries.", "response": "def com_google_fonts_check_name_familyname(ttFont, style, familyname_with_spaces):\n  \"\"\" Check name table: FONT_FAMILY_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n  failed = False\n  only_weight = get_only_weight(style)\n  for name in ttFont['name'].names:\n    if name.nameID == NameID.FONT_FAMILY_NAME:\n\n      if name.platformID == PlatformID.MACINTOSH:\n        expected_value = familyname_with_spaces\n\n      elif name.platformID == PlatformID.WINDOWS:\n        if style in ['Regular',\n                     'Italic',\n                     'Bold',\n                     'Bold Italic']:\n          expected_value = familyname_with_spaces\n        else:\n          expected_value = \" \".join([familyname_with_spaces,\n                                     only_weight]).strip()\n      else:\n        failed = True\n        yield FAIL, (\"Font should not have a \"\n                     \"{} entry!\").format(name_entry_id(name))\n        continue\n\n      string = name.string.decode(name.getEncoding()).strip()\n      if string != expected_value:\n        failed = True\n        yield FAIL, (\"Entry {} on the 'name' table: \"\n                     \"Expected '{}' \"\n                     \"but got '{}'.\").format(name_entry_id(name),\n                                             expected_value,\n                                             string)\n  if not failed:\n    yield PASS, \"FONT_FAMILY_NAME entries are all good.\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking name table: FONT_SUBFAMILY_NAME entries.", "response": "def com_google_fonts_check_name_subfamilyname(ttFont,\n                                              style_with_spaces,\n                                              familyname_with_spaces):\n  \"\"\" Check name table: FONT_SUBFAMILY_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n\n  failed = False\n  for name in ttFont['name'].names:\n    if name.nameID == NameID.FONT_SUBFAMILY_NAME:\n      if name.platformID == PlatformID.MACINTOSH:\n        expected_value = style_with_spaces\n\n      elif name.platformID == PlatformID.WINDOWS:\n        if style_with_spaces in [\"Bold\", \"Bold Italic\"]:\n          expected_value = style_with_spaces\n        else:\n          if \"Italic\" in style_with_spaces:\n            expected_value = \"Italic\"\n          else:\n            expected_value = \"Regular\"\n      else:\n        yield FAIL, Message(\"invalid-entry\",\n                            (\"Font should not have a \"\n                             \"{} entry!\").format(name_entry_id(name)))\n        failed = True\n        continue\n\n      string = name.string.decode(name.getEncoding()).strip()\n      if string != expected_value:\n        failed = True\n        yield FAIL, Message(\"bad-familyname\",\n                            (\"Entry {} on the 'name' table: \"\n                             \"Expected '{}' \"\n                             \"but got '{}'.\").format(name_entry_id(name),\n                                                     expected_value,\n                                                     string))\n\n  if not failed:\n    yield PASS, \"FONT_SUBFAMILY_NAME entries are all good.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef com_google_fonts_check_name_fullfontname(ttFont,\n                                             style_with_spaces,\n                                             familyname_with_spaces):\n  \"\"\" Check name table: FULL_FONT_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n  failed = False\n  for name in ttFont['name'].names:\n    if name.nameID == NameID.FULL_FONT_NAME:\n      expected_value = \"{} {}\".format(familyname_with_spaces,\n                                      style_with_spaces)\n      string = name.string.decode(name.getEncoding()).strip()\n      if string != expected_value:\n        failed = True\n        # special case\n        # see https://github.com/googlefonts/fontbakery/issues/1436\n        if style_with_spaces == \"Regular\" \\\n           and string == familyname_with_spaces:\n          yield WARN, (\"Entry {} on the 'name' table:\"\n                       \" Got '{}' which lacks 'Regular',\"\n                       \" but it is probably OK in this case.\"\n                       \"\").format(name_entry_id(name),\n                                  string)\n        else:\n          yield FAIL, (\"Entry {} on the 'name' table: \"\n                       \"Expected '{}' \"\n                       \"but got '{}'.\").format(name_entry_id(name),\n                                               expected_value,\n                                               string)\n\n  if not failed:\n    yield PASS, \"FULL_FONT_NAME entries are all good.\"", "response": "Check the full font name table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the name table contains the POSTSCRIPT_NAME entries.", "response": "def com_google_fonts_check_name_postscriptname(ttFont, style, familyname):\n  \"\"\" Check name table: POSTSCRIPT_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n\n  failed = False\n  for name in ttFont['name'].names:\n    if name.nameID == NameID.POSTSCRIPT_NAME:\n      expected_value = f\"{familyname}-{style}\"\n\n      string = name.string.decode(name.getEncoding()).strip()\n      if string != expected_value:\n        failed = True\n        yield FAIL, (\"Entry {} on the 'name' table: \"\n                     \"Expected '{}' \"\n                     \"but got '{}'.\").format(name_entry_id(name),\n                                             expected_value,\n                                             string)\n  if not failed:\n    yield PASS, \"POSTCRIPT_NAME entries are all good.\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck name table: TYPOGRAPHIC_FAMILY_NAME entries.", "response": "def com_google_fonts_check_name_typographicfamilyname(ttFont, style, familyname_with_spaces):\n  \"\"\" Check name table: TYPOGRAPHIC_FAMILY_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n\n  failed = False\n  if style in ['Regular',\n               'Italic',\n               'Bold',\n               'BoldItalic']:\n    for name in ttFont['name'].names:\n      if name.nameID == NameID.TYPOGRAPHIC_FAMILY_NAME:\n        failed = True\n        yield FAIL, Message(\"ribbi\",\n                            (\"Font style is '{}' and, for that reason,\"\n                             \" it is not expected to have a \"\n                             \"{} entry!\").format(style,\n                                                 name_entry_id(name)))\n  else:\n    expected_value = familyname_with_spaces\n    has_entry = False\n    for name in ttFont['name'].names:\n      if name.nameID == NameID.TYPOGRAPHIC_FAMILY_NAME:\n        string = name.string.decode(name.getEncoding()).strip()\n        if string == expected_value:\n          has_entry = True\n        else:\n          failed = True\n          yield FAIL, Message(\"non-ribbi-bad-value\",\n                              (\"Entry {} on the 'name' table: \"\n                               \"Expected '{}' \"\n                               \"but got '{}'.\").format(name_entry_id(name),\n                                                       expected_value,\n                                                       string))\n    if not failed and not has_entry:\n      failed = True\n      yield FAIL, Message(\"non-ribbi-lacks-entry\",\n                          (\"non-RIBBI fonts must have a\"\n                           \" TYPOGRAPHIC_FAMILY_NAME entry\"\n                           \" on the name table.\"))\n  if not failed:\n    yield PASS, \"TYPOGRAPHIC_FAMILY_NAME entries are all good.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that the name table contains the correct TYPOGRAPHIC_SUBFAMILY_NAME entries.", "response": "def com_google_fonts_check_name_typographicsubfamilyname(ttFont, style_with_spaces):\n  \"\"\" Check name table: TYPOGRAPHIC_SUBFAMILY_NAME entries. \"\"\"\n  from fontbakery.utils import name_entry_id\n\n  failed = False\n  if style_with_spaces in ['Regular',\n                           'Italic',\n                           'Bold',\n                           'Bold Italic']:\n    for name in ttFont['name'].names:\n      if name.nameID == NameID.TYPOGRAPHIC_SUBFAMILY_NAME:\n        failed = True\n        yield FAIL, Message(\"ribbi\",\n                            (\"Font style is '{}' and, for that reason,\"\n                             \" it is not expected to have a \"\n                             \"{} entry!\").format(style_with_spaces,\n                                                 name_entry_id(name)))\n  else:\n    expected_value = style_with_spaces\n    has_entry = False\n    for name in ttFont['name'].names:\n      if name.nameID == NameID.TYPOGRAPHIC_SUBFAMILY_NAME:\n        string = name.string.decode(name.getEncoding()).strip()\n        if string == expected_value:\n          has_entry = True\n        else:\n          failed = True\n          yield FAIL, Message(\"non-ribbi-bad-value\",\n                              (\"Entry {} on the 'name' table: \"\n                               \"Expected '{}' \"\n                               \"but got '{}'.\").format(name_entry_id(name),\n                                                       expected_value,\n                                                       string))\n    if not failed and not has_entry:\n      failed = True\n      yield FAIL, Message(\"non-ribbi-lacks-entry\",\n                          (\"non-RIBBI fonts must have a\"\n                           \" TYPOGRAPHIC_SUBFAMILY_NAME entry\"\n                           \" on the name table.\"))\n  if not failed:\n    yield PASS, \"TYPOGRAPHIC_SUBFAMILY_NAME entries are all good.\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_fontdata_namecheck(ttFont, familyname):\n  FB_ISSUE_TRACKER = \"https://github.com/googlefonts/fontbakery/issues\"\n  import requests\n  url = f\"http://namecheck.fontdata.com/?q={familyname}\"\n  try:\n    response = requests.get(url, timeout=10)\n    data = response.content.decode(\"utf-8\")\n    if \"fonts by that exact name\" in data:\n      yield INFO, (\"The family name '{}' seem to be already in use.\\n\"\n                   \"Please visit {} for more info.\").format(familyname, url)\n    else:\n      yield PASS, \"Font familyname seems to be unique.\"\n  except:\n    yield ERROR, (\"Failed to access: '{}'.\\n\"\n                  \"Please report this issue at:\\n{}\").format(url,\n                                                             FB_ISSUE_TRACKER)", "response": "Font familyname must be unique according to namecheck. fontdata. com"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_fontv(ttFont):\n  from fontv.libfv import FontVersion\n\n  fv = FontVersion(ttFont)\n  if fv.version and (fv.is_development or fv.is_release):\n    yield PASS, \"Font version string looks GREAT!\"\n  else:\n    yield INFO, (\"Version string is: \\\"{}\\\"\\n\"\n                 \"The version string must ideally include a git commit hash\"\n                 \" and either a 'dev' or a 'release' suffix such as in the\"\n                 \" example below:\\n\"\n                 \"\\\"Version 1.3; git-0d08353-release\\\"\"\n                 \"\").format(fv.get_name_id5_version_string())", "response": "Check for font-v versioning"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that advance widths cannot be inferred as negative.", "response": "def com_google_fonts_check_negative_advance_width(ttFont):\n  \"\"\" Check that advance widths cannot be inferred as negative. \"\"\"\n  failed = False\n  for glyphName in ttFont[\"glyf\"].glyphs:\n    coords = ttFont[\"glyf\"][glyphName].coordinates\n    rightX = coords[-3][0]\n    leftX = coords[-4][0]\n    advwidth = rightX - leftX\n    if advwidth < 0:\n      failed = True\n      yield FAIL, (\"glyph '{}' has bad coordinates on the glyf table,\"\n                   \" which may lead to the advance width to be\"\n                   \" interpreted as a negative\"\n                   \" value ({}).\").format(glyphName,\n                                          advwidth)\n  if not failed:\n    yield PASS, \"The x-coordinates of all glyphs look good.\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_varfont_generate_static(ttFont):\n  import tempfile\n  from fontTools.varLib import mutator\n\n  try:\n    loc = {k.axisTag: float((k.maxValue + k.minValue) / 2)\n           for k in ttFont['fvar'].axes}\n    with tempfile.TemporaryFile() as instance:\n      font = mutator.instantiateVariableFont(ttFont, loc)\n      font.save(instance)\n      yield PASS, (\"fontTools.varLib.mutator generated a static font \"\n                   \"instance\")\n  except Exception as e:\n    yield FAIL, (\"fontTools.varLib.mutator failed to generated a static font \"\n                 \"instance\\n{}\".format(repr(e)))", "response": "Check a static ttf can be generated from a variable font."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_smart_dropout(ttFont):\n  INSTRUCTIONS = b\"\\xb8\\x01\\xff\\x85\\xb0\\x04\\x8d\"\n\n  if (\"prep\" in ttFont and\n      INSTRUCTIONS in ttFont[\"prep\"].program.getBytecode()):\n    yield PASS, (\"'prep' table contains instructions\"\n                  \" enabling smart dropout control.\")\n  else:\n    yield FAIL, (\"'prep' table does not contain TrueType \"\n                  \" instructions enabling smart dropout control.\"\n                  \" To fix, export the font with autohinting enabled,\"\n                  \" or run ttfautohint on the font, or run the \"\n                  \" `gftools fix-nonhinting` script.\")", "response": "Font enables smart dropout control in prep table instructions?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbeing there unwanted Apple tables?", "response": "def com_google_fonts_check_aat(ttFont):\n  \"\"\"Are there unwanted Apple tables?\"\"\"\n  UNWANTED_TABLES = {\n    'EBSC', 'Zaph', 'acnt', 'ankr', 'bdat', 'bhed', 'bloc',\n    'bmap', 'bsln', 'fdsc', 'feat', 'fond', 'gcid', 'just',\n    'kerx', 'lcar', 'ltag', 'mort', 'morx', 'opbd', 'prop',\n    'trak', 'xref'\n  }\n  unwanted_tables_found = []\n  for table in ttFont.keys():\n    if table in UNWANTED_TABLES:\n      unwanted_tables_found.append(table)\n\n  if len(unwanted_tables_found) > 0:\n    yield FAIL, (\"Unwanted AAT tables were found\"\n                 \" in the font and should be removed, either by\"\n                 \" fonttools/ttx or by editing them using the tool\"\n                 \" they built with:\"\n                 \" {}\").format(\", \".join(unwanted_tables_found))\n  else:\n    yield PASS, \"There are no unwanted AAT tables.\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_fvar_name_entries(ttFont):\n\n  failed = False\n  for instance in ttFont[\"fvar\"].instances:\n\n    entries = [entry for entry in ttFont[\"name\"].names if entry.nameID == instance.subfamilyNameID]\n    if len(entries) == 0:\n      failed = True\n      yield FAIL, (f\"Named instance with coordinates {instance.coordinates}\"\n                   f\" lacks an entry on the name table (nameID={instance.subfamilyNameID}).\")\n\n  if not failed:\n    yield PASS, \"OK\"", "response": "All name entries referenced by fvar instances exist on the name table?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_family_tnum_horizontal_metrics(fonts):\n  from fontbakery.constants import RIBBI_STYLE_NAMES\n  from fontTools.ttLib import TTFont\n  RIBBI_ttFonts = [TTFont(f)\n                   for f in fonts\n                   if style(f) in RIBBI_STYLE_NAMES]\n  tnum_widths = {}\n  for ttFont in RIBBI_ttFonts:\n    glyphs = ttFont.getGlyphSet()\n    tnum_glyphs = [(glyph_id, glyphs[glyph_id])\n                   for glyph_id in glyphs.keys()\n                   if glyph_id.endswith(\".tnum\")]\n    for glyph_id, glyph in tnum_glyphs:\n      if glyph.width not in tnum_widths:\n        tnum_widths[glyph.width] = [glyph_id]\n      else:\n        tnum_widths[glyph.width].append(glyph_id)\n\n  if len(tnum_widths.keys()) > 1:\n    max_num = 0\n    most_common_width = None\n    for width, glyphs in tnum_widths.items():\n      if len(glyphs) > max_num:\n        max_num = len(glyphs)\n        most_common_width = width\n\n    del tnum_widths[most_common_width]\n    yield FAIL, (f\"The most common tabular glyph width is {most_common_width}.\"\n                  \" But there are other tabular glyphs with different widths\"\n                 f\" such as the following ones:\\n\\t{tnum_widths}.\")\n  else:\n    yield PASS, \"OK\"", "response": "All tabular figures must have the same width across the RIBBI - family."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that caret positions declared for every ligature glyphs are declared for every glyph.", "response": "def com_google_fonts_check_ligature_carets(ttFont, ligature_glyphs):\n  \"\"\"Are there caret positions declared for every ligature?\"\"\"\n  if ligature_glyphs == -1:\n    yield FAIL, Message(\"malformed\", \"Failed to lookup ligatures.\"\n                        \" This font file seems to be malformed.\"\n                        \" For more info, read:\"\n                        \" https://github.com\"\n                        \"/googlefonts/fontbakery/issues/1596\")\n  elif \"GDEF\" not in ttFont:\n    yield WARN, Message(\"GDEF-missing\",\n                        (\"GDEF table is missing, but it is mandatory\"\n                         \" to declare it on fonts that provide ligature\"\n                         \" glyphs because the caret (text cursor)\"\n                         \" positioning for each ligature must be\"\n                         \" provided in this table.\"))\n  else:\n    lig_caret_list = ttFont[\"GDEF\"].table.LigCaretList\n    if lig_caret_list is None:\n      missing = set(ligature_glyphs)\n    else:\n      missing = set(ligature_glyphs) - set(lig_caret_list.Coverage.glyphs)\n\n    if lig_caret_list is None or lig_caret_list.LigGlyphCount == 0:\n      yield WARN, Message(\"lacks-caret-pos\",\n                          (\"This font lacks caret position values for\"\n                           \" ligature glyphs on its GDEF table.\"))\n    elif missing:\n      missing = \"\\n\\t- \".join(missing)\n      yield WARN, Message(\"incomplete-caret-pos-data\",\n                          (\"This font lacks caret positioning\"\n                           \" values for these ligature glyphs:\"\n                           f\"\\n\\t- {missing}\\n\\n  \"))\n    else:\n      yield PASS, \"Looks good!\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef com_google_fonts_check_kerning_for_non_ligated_sequences(ttFont, ligatures, has_kerning_info):\n\n  def look_for_nonligated_kern_info(table):\n    for pairpos in table.SubTable:\n      for i, glyph in enumerate(pairpos.Coverage.glyphs):\n        if not hasattr(pairpos, 'PairSet'):\n          continue\n        for pairvalue in pairpos.PairSet[i].PairValueRecord:\n          kern_pair = (glyph, pairvalue.SecondGlyph)\n          if kern_pair in ligature_pairs:\n            ligature_pairs.remove(kern_pair)\n\n  def ligatures_str(pairs):\n    result = [f\"\\t- {first} + {second}\" for first, second in pairs]\n    return \"\\n\".join(result)\n\n  if ligatures == -1:\n    yield FAIL, Message(\"malformed\", \"Failed to lookup ligatures.\"\n                        \" This font file seems to be malformed.\"\n                        \" For more info, read:\"\n                        \" https://github.com\"\n                        \"/googlefonts/fontbakery/issues/1596\")\n  else:\n    ligature_pairs = []\n    for first, comp in ligatures.items():\n      for components in comp:\n        while components:\n          pair = (first, components[0])\n          if pair not in ligature_pairs:\n            ligature_pairs.append(pair)\n          first = components[0]\n          components.pop(0)\n\n    for record in ttFont[\"GSUB\"].table.FeatureList.FeatureRecord:\n      if record.FeatureTag == 'kern':\n        for index in record.Feature.LookupListIndex:\n          lookup = ttFont[\"GSUB\"].table.LookupList.Lookup[index]\n          look_for_nonligated_kern_info(lookup)\n\n    if ligature_pairs:\n      yield WARN, Message(\"lacks-kern-info\",\n                          (\"GPOS table lacks kerning info for the following\"\n                           \" non-ligated sequences:\\n\"\n                           \"{}\\n\\n  \").format(ligatures_str(ligature_pairs)))\n    else:\n      yield PASS, (\"GPOS table provides kerning info for \"\n                   \"all non-ligated sequences.\")", "response": "Check kerning info for non - ligated sequences."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking that the combined length of family and style of a name table record is not exceeding 27 characters.", "response": "def com_google_fonts_check_name_family_and_style_max_length(ttFont):\n  \"\"\"Combined length of family and style must not exceed 27 characters.\"\"\"\n  from fontbakery.utils import (get_name_entries,\n                                get_name_entry_strings)\n  failed = False\n  for familyname in get_name_entries(ttFont,\n                                     NameID.FONT_FAMILY_NAME):\n    # we'll only match family/style name entries with the same platform ID:\n    plat = familyname.platformID\n    familyname_str = familyname.string.decode(familyname.getEncoding())\n    for stylename_str in get_name_entry_strings(ttFont,\n                                                NameID.FONT_SUBFAMILY_NAME,\n                                                platformID=plat):\n      if len(familyname_str + stylename_str) > 27:\n        failed = True\n        yield WARN, (\"The combined length of family and style\"\n                     \" exceeds 27 chars in the following '{}' entries:\"\n                     \" FONT_FAMILY_NAME = '{}' / SUBFAMILY_NAME = '{}'\"\n                     \"\").format(PlatformID(plat).name,\n                                familyname_str,\n                                stylename_str)\n        yield WARN, (\"Please take a look at the conversation at\"\n                     \" https://github.com/googlefonts/fontbakery/issues/2179\"\n                     \" in order to understand the reasoning behing these\"\n                     \" name table records max-length criteria.\")\n  if not failed:\n    yield PASS, \"All name entries are good.\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo font file include unacceptable control characters?", "response": "def com_google_fonts_check_family_control_chars(ttFonts):\n  \"\"\"Does font file include unacceptable control character glyphs?\"\"\"\n  # list of unacceptable control character glyph names\n  # definition includes the entire control character Unicode block except:\n  #    - .null (U+0000)\n  #    - CR (U+000D)\n  unacceptable_cc_list = [\n      \"uni0001\",\n      \"uni0002\",\n      \"uni0003\",\n      \"uni0004\",\n      \"uni0005\",\n      \"uni0006\",\n      \"uni0007\",\n      \"uni0008\",\n      \"uni0009\",\n      \"uni000A\",\n      \"uni000B\",\n      \"uni000C\",\n      \"uni000E\",\n      \"uni000F\",\n      \"uni0010\",\n      \"uni0011\",\n      \"uni0012\",\n      \"uni0013\",\n      \"uni0014\",\n      \"uni0015\",\n      \"uni0016\",\n      \"uni0017\",\n      \"uni0018\",\n      \"uni0019\",\n      \"uni001A\",\n      \"uni001B\",\n      \"uni001C\",\n      \"uni001D\",\n      \"uni001E\",\n      \"uni001F\"\n  ]\n\n  # a dict with key:value of font path that failed check : list of unacceptable glyph names\n  failed_font_dict = {}\n\n  for ttFont in ttFonts:\n    font_failed = False\n    unacceptable_glyphs_in_set = []  # a list of unacceptable glyph names identified\n    glyph_name_set = set(ttFont[\"glyf\"].glyphs.keys())\n    fontname = ttFont.reader.file.name\n\n    for unacceptable_glyph_name in unacceptable_cc_list:\n      if unacceptable_glyph_name in glyph_name_set:\n        font_failed = True\n        unacceptable_glyphs_in_set.append(unacceptable_glyph_name)\n\n    if font_failed:\n        failed_font_dict[fontname] = unacceptable_glyphs_in_set\n\n  if len(failed_font_dict) > 0:\n    unacceptable_cc_report_string = \"The following unacceptable control characters were identified:\\n\"\n    for fnt in failed_font_dict.keys():\n      unacceptable_cc_report_string += \" {}: {}\\n\".format(\n          fnt, \", \".join(failed_font_dict[fnt])\n      )\n    yield FAIL, (\"{}\".format(unacceptable_cc_report_string))\n  else:\n    yield PASS, (\"Unacceptable control characters were not identified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning true if the font at the given font path is in the expected structure.", "response": "def gfonts_repo_structure(fonts):\n  \"\"\" The family at the given font path\n      follows the files and directory structure\n      typical of a font project hosted on\n      the Google Fonts repo on GitHub ? \"\"\"\n  from fontbakery.utils import get_absolute_path\n\n  # FIXME: Improve this with more details\n  #        about the expected structure.\n  abspath = get_absolute_path(fonts[0])\n  return abspath.split(os.path.sep)[-3] in [\"ufl\", \"ofl\", \"apache\"]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_repo_dirname_match_nameid_1(fonts,\n                                                       gfonts_repo_structure):\n  \"\"\"Directory name in GFonts repo structure must\n     match NameID 1 of the regular.\"\"\"\n  from fontTools.ttLib import TTFont\n  from fontbakery.utils import (get_name_entry_strings,\n                                get_absolute_path,\n                                get_regular)\n  regular = get_regular(fonts)\n  if not regular:\n    yield FAIL, \"The font seems to lack a regular.\"\n\n  entry = get_name_entry_strings(TTFont(regular), NameID.FONT_FAMILY_NAME)[0]\n  expected = entry.lower()\n  expected = \"\".join(expected.split(' '))\n  expected = \"\".join(expected.split('-'))\n\n  license, familypath, filename = get_absolute_path(regular).split(os.path.sep)[-3:]\n  if familypath == expected:\n    yield PASS, \"OK\"\n  else:\n    yield FAIL, (f\"Family name on the name table ('{entry}') does not match\"\n                 f\" directory name in the repo structure ('{familypath}').\"\n                 f\" Expected '{expected}'.\")", "response": "Directory name in GFonts repo structure must\n     match NameID 1 of the regular."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_google_fonts_check_family_panose_proportion(ttFonts):\n  failed = False\n  proportion = None\n  for ttFont in ttFonts:\n    if proportion is None:\n      proportion = ttFont['OS/2'].panose.bProportion\n    if proportion != ttFont['OS/2'].panose.bProportion:\n      failed = True\n\n  if failed:\n    yield FAIL, (\"PANOSE proportion is not\"\n                 \" the same accross this family.\"\n                 \" In order to fix this,\"\n                 \" please make sure that the panose.bProportion value\"\n                 \" is the same in the OS/2 table of all of this family\"\n                 \" font files.\")\n  else:\n    yield PASS, \"Fonts have consistent PANOSE proportion.\"", "response": "Fonts have consistent PANOSE proportion?"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_google_fonts_check_family_panose_familytype(ttFonts):\n  failed = False\n  familytype = None\n  for ttfont in ttFonts:\n    if familytype is None:\n      familytype = ttfont['OS/2'].panose.bFamilyType\n    if familytype != ttfont['OS/2'].panose.bFamilyType:\n      failed = True\n\n  if failed:\n    yield FAIL, (\"PANOSE family type is not\"\n                 \" the same accross this family.\"\n                 \" In order to fix this,\"\n                 \" please make sure that the panose.bFamilyType value\"\n                 \" is the same in the OS/2 table of all of this family\"\n                 \" font files.\")\n  else:\n    yield PASS, \"Fonts have consistent PANOSE family type.\"", "response": "Fonts have consistent PANOSE family type?"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if OS / 2 xAvgCharWidth is correct.", "response": "def com_google_fonts_check_xavgcharwidth(ttFont):\n  \"\"\"Check if OS/2 xAvgCharWidth is correct.\"\"\"\n  current_value = ttFont['OS/2'].xAvgCharWidth\n  ACCEPTABLE_ERROR = 10  # Width deviation tolerance in font units\n\n  # Since version 3, the average is computed using _all_ glyphs in a font.\n  if ttFont['OS/2'].version >= 3:\n    calculation_rule = \"the average of the widths of all glyphs in the font\"\n    if not ttFont['hmtx'].metrics:  # May contain just '.notdef', which is valid.\n      yield FAIL, Message(\"missing-glyphs\",\n                          \"CRITICAL: Found no glyph width data in the hmtx table!\")\n      return\n\n    width_sum = 0\n    count = 0\n    for glyph_id in ttFont['glyf'].glyphs:  # At least .notdef must be present.\n      width = ttFont['hmtx'].metrics[glyph_id][0]\n      # The OpenType spec doesn't exclude negative widths, but only positive\n      # widths seems to be the assumption in the wild?\n      if width > 0:\n        count += 1\n        width_sum += width\n\n    expected_value = int(round(width_sum / count))\n  else:  # Version 2 and below only consider lowercase latin glyphs and space.\n    calculation_rule = (\"the weighted average of the widths of the latin\"\n                        \" lowercase glyphs in the font\")\n    weightFactors = {\n        'a': 64,\n        'b': 14,\n        'c': 27,\n        'd': 35,\n        'e': 100,\n        'f': 20,\n        'g': 14,\n        'h': 42,\n        'i': 63,\n        'j': 3,\n        'k': 6,\n        'l': 35,\n        'm': 20,\n        'n': 56,\n        'o': 56,\n        'p': 17,\n        'q': 4,\n        'r': 49,\n        's': 56,\n        't': 71,\n        'u': 31,\n        'v': 10,\n        'w': 18,\n        'x': 3,\n        'y': 18,\n        'z': 2,\n        'space': 166\n    }\n    glyph_order = ttFont.getGlyphOrder()\n    if not all(character in glyph_order for character in weightFactors):\n      yield FAIL, Message(\"missing-glyphs\",\n                          \"Font is missing the required latin lowercase \"\n                          \"letters and/or space.\")\n      return\n\n    width_sum = 0\n    for glyph_id in weightFactors:\n      width = ttFont['hmtx'].metrics[glyph_id][0]\n      width_sum += (width * weightFactors[glyph_id])\n\n    expected_value = int(width_sum / 1000.0 + 0.5)  # round to closest int\n\n  difference = abs(current_value - expected_value)\n\n  # We accept matches and off-by-ones due to rounding as correct.\n  if current_value == expected_value or difference == 1:\n    yield PASS, \"OS/2 xAvgCharWidth value is correct.\"\n  elif difference < ACCEPTABLE_ERROR:\n    yield INFO, (f\"OS/2 xAvgCharWidth is {current_value} but it should be\"\n                 f\" {expected_value} which corresponds to {calculation_rule}.\"\n                  \" These are similar values, which\"\n                  \" may be a symptom of the slightly different\"\n                  \" calculation of the xAvgCharWidth value in\"\n                  \" font editors. There's further discussion on\"\n                  \" this at https://github.com/googlefonts/fontbakery\"\n                  \"/issues/1622\")\n  else:\n    yield WARN, (f\"OS/2 xAvgCharWidth is {current_value} but it should be\"\n                 f\" {expected_value} which corresponds to {calculation_rule}.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_adobe_fonts_check_fsselection_matches_macstyle(ttFont):\n  from fontbakery.constants import FsSelection, MacStyle\n  failed = False\n  head_bold = (ttFont['head'].macStyle & MacStyle.BOLD) != 0\n  os2_bold = (ttFont['OS/2'].fsSelection & FsSelection.BOLD) != 0\n  if head_bold != os2_bold:\n    failed = True\n    yield FAIL, \"The OS/2.fsSelection and head.macStyle \" \\\n                \"bold settings do not match.\"\n  head_italic = (ttFont['head'].macStyle & MacStyle.ITALIC) != 0\n  os2_italic = (ttFont['OS/2'].fsSelection & FsSelection.ITALIC) != 0\n  if head_italic != os2_italic:\n    failed = True\n    yield FAIL, \"The OS/2.fsSelection and head.macStyle \" \\\n                \"italic settings do not match.\"\n  if not failed:\n    yield PASS, \"The OS/2.fsSelection and head.macStyle \" \\\n                \"bold and italic settings match.\"", "response": "Check if OS / 2 fsSelection matches head macStyle bold and italic bits."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that OS / 2. fsSelection bold & italic settings are unique for each NameID1.", "response": "def com_adobe_fonts_check_family_bold_italic_unique_for_nameid1(ttFonts):\n  \"\"\"Check that OS/2.fsSelection bold & italic settings are unique\n  for each NameID1\"\"\"\n  from collections import Counter\n  from fontbakery.utils import get_name_entry_strings\n  from fontbakery.constants import NameID, FsSelection\n\n  failed = False\n  family_name_and_bold_italic = list()\n  for ttFont in ttFonts:\n    names_list = get_name_entry_strings(ttFont, NameID.FONT_FAMILY_NAME)\n    # names_list will likely contain multiple entries, e.g. multiple copies\n    # of the same name in the same language for different platforms, but\n    # also different names in different languages, we use set() below\n    # to remove the duplicates and only store the unique family name(s)\n    # used for a given font\n    names_set = set(names_list)\n\n    bold = (ttFont['OS/2'].fsSelection & FsSelection.BOLD) != 0\n    italic = (ttFont['OS/2'].fsSelection & FsSelection.ITALIC) != 0\n    bold_italic = 'Bold=%r, Italic=%r' % (bold, italic)\n\n    for name in names_set:\n      family_name_and_bold_italic.append((name, bold_italic,))\n\n  counter = Counter(family_name_and_bold_italic)\n\n  for (family_name, bold_italic), count in counter.items():\n    if count > 1:\n      failed = True\n      yield FAIL, (\"Family '{}' has {} fonts (should be no more than 1) with \"\n                   \"the same OS/2.fsSelection bold & italic settings: {}\"\n                   ).format(family_name, count, bold_italic)\n  if not failed:\n    yield PASS, (\"The OS/2.fsSelection bold & italic settings were unique \"\n                 \"within each compatible family group.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking code pages character ranges.", "response": "def com_google_fonts_check_code_pages(ttFont):\n  \"\"\"Check code page character ranges\"\"\"\n\n  if not hasattr(ttFont['OS/2'], \"ulCodePageRange1\") or \\\n     not hasattr(ttFont['OS/2'], \"ulCodePageRange2\") or \\\n     (ttFont['OS/2'].ulCodePageRange1 == 0 and \\\n      ttFont['OS/2'].ulCodePageRange2 == 0):\n    yield FAIL, (\"No code pages defined in the OS/2 table\"\n                 \" ulCodePageRage1 and CodePageRage2 fields.\")\n  else:\n    yield PASS, \"At least one code page is defined.\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef com_google_fonts_check_glyf_unused_data(ttFont):\n  try:\n    expected_glyphs = len(ttFont.getGlyphOrder())\n    actual_glyphs = len(ttFont['glyf'].glyphs)\n    diff = actual_glyphs - expected_glyphs\n\n    if diff < 0:\n      yield FAIL, Message(\"unreachable-data\",\n                          (\"Glyf table has unreachable data at the end of \"\n                           \" the table. Expected glyf table length {}\"\n                           \" (from loca table), got length\"\n                           \" {} (difference: {})\").format(\n                               expected_glyphs, actual_glyphs, diff))\n    elif not diff:  # negative diff -> exception below\n      yield PASS, \"There is no unused data at the end of the glyf table.\"\n    else:\n      raise Exception(\"Bug: fontTools did not raise an expected exception.\")\n  except fontTools.ttLib.TTLibError as error:\n    if \"not enough 'glyf' table data\" in format(error):\n      yield FAIL, Message(\"missing-data\",\n                          (\"Loca table references data beyond\"\n                           \" the end of the glyf table.\"\n                           \" Expected glyf table length {}\"\n                           \" (from loca table).\").format(expected_glyphs))\n    else:\n      raise Exception(\"Bug: Unexpected fontTools exception.\")", "response": "Check that there is no unused data at the end of the glyf table?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck for points out of bounds.", "response": "def com_google_fonts_check_points_out_of_bounds(ttFont):\n  \"\"\"Check for points out of bounds.\"\"\"\n  failed = False\n  out_of_bounds = []\n  for glyphName in ttFont['glyf'].keys():\n    glyph = ttFont['glyf'][glyphName]\n    coords = glyph.getCoordinates(ttFont['glyf'])[0]\n    for x, y in coords:\n      if x < glyph.xMin or x > glyph.xMax or \\\n         y < glyph.yMin or y > glyph.yMax or \\\n         abs(x) > 32766 or abs(y) > 32766:\n        failed = True\n        out_of_bounds.append((glyphName, x, y))\n\n  if failed:\n    yield WARN, (\"The following glyphs have coordinates which are\"\n                 \" out of bounds:\\n{}\\nThis happens a lot when points\"\n                 \" are not extremes, which is usually bad. However,\"\n                 \" fixing this alert by adding points on extremes may\"\n                 \" do more harm than good, especially with italics,\"\n                 \" calligraphic-script, handwriting, rounded and\"\n                 \" other fonts. So it is common to\"\n                 \" ignore this message\".format(out_of_bounds))\n  else:\n    yield PASS, \"All glyph paths have coordinates within bounds!\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef com_daltonmaag_check_ufolint(font):\n  import subprocess\n  ufolint_cmd = [\"ufolint\", font]\n\n  try:\n    subprocess.check_output(ufolint_cmd, stderr=subprocess.STDOUT)\n  except subprocess.CalledProcessError as e:\n    yield FAIL, (\"ufolint failed the UFO source. Output follows :\"\n                 \"\\n\\n{}\\n\").format(e.output.decode())\n  except OSError:\n    yield ERROR, \"ufolint is not available!\"\n  else:\n    yield PASS, \"ufolint passed the UFO source.\"", "response": "Run ufolint on UFO source directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that required fields are present in the UFO fontinfo.", "response": "def com_daltonmaag_check_required_fields(ufo_font):\n  \"\"\"Check that required fields are present in the UFO fontinfo.\n\n    ufo2ft requires these info fields to compile a font binary:\n    unitsPerEm, ascender, descender, xHeight, capHeight and familyName.\n    \"\"\"\n  recommended_fields = []\n\n  for field in [\n      \"unitsPerEm\", \"ascender\", \"descender\", \"xHeight\", \"capHeight\",\n      \"familyName\"\n  ]:\n    if ufo_font.info.__dict__.get(\"_\" + field) is None:\n      recommended_fields.append(field)\n\n  if recommended_fields:\n    yield FAIL, f\"Required field(s) missing: {recommended_fields}\"\n  else:\n    yield PASS, \"Required fields present.\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef com_daltonmaag_check_recommended_fields(ufo_font):\n  recommended_fields = []\n\n  for field in [\n      \"postscriptUnderlineThickness\", \"postscriptUnderlinePosition\",\n      \"versionMajor\", \"versionMinor\", \"styleName\", \"copyright\",\n      \"openTypeOS2Panose\"\n  ]:\n    if ufo_font.info.__dict__.get(\"_\" + field) is None:\n      recommended_fields.append(field)\n\n  if recommended_fields:\n    yield WARN, f\"Recommended field(s) missing: {recommended_fields}\"\n  else:\n    yield PASS, \"Recommended fields present.\"", "response": "Check that recommended fields are present in the UFO fontinfo."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_daltonmaag_check_unnecessary_fields(ufo_font):\n  unnecessary_fields = []\n\n  for field in [\n      \"openTypeNameUniqueID\", \"openTypeNameVersion\", \"postscriptUniqueID\",\n      \"year\"\n  ]:\n    if ufo_font.info.__dict__.get(\"_\" + field) is not None:\n      unnecessary_fields.append(field)\n\n  if unnecessary_fields:\n    yield WARN, f\"Unnecessary field(s) present: {unnecessary_fields}\"\n  else:\n    yield PASS, \"Unnecessary fields omitted.\"", "response": "Check that no unnecessary fields are present in the UFO fontinfo."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up custom arguments needed for this profile.", "response": "def setup_argparse(self, argument_parser):\n    \"\"\"Set up custom arguments needed for this profile.\"\"\"\n    import glob\n    import logging\n    import argparse\n\n    def get_fonts(pattern):\n\n      fonts_to_check = []\n      # use glob.glob to accept *.ufo\n\n      for fullpath in glob.glob(pattern):\n        fullpath_absolute = os.path.abspath(fullpath)\n        if fullpath_absolute.lower().endswith(\".ufo\") and os.path.isdir(\n            fullpath_absolute):\n          fonts_to_check.append(fullpath)\n        else:\n          logging.warning(\n              (\"Skipping '{}' as it does not seem \"\n               \"to be valid UFO source directory.\").format(fullpath))\n      return fonts_to_check\n\n    class MergeAction(argparse.Action):\n\n      def __call__(self, parser, namespace, values, option_string=None):\n        target = [item for l in values for item in l]\n        setattr(namespace, self.dest, target)\n\n    argument_parser.add_argument(\n        'fonts',\n        # To allow optional commands like \"-L\" to work without other input\n        # files:\n        nargs='*',\n        type=get_fonts,\n        action=MergeAction,\n        help='font file path(s) to check.'\n        ' Wildcards like *.ufo are allowed.')\n\n    return ('fonts',)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef com_google_fonts_check_varfont_regular_opsz_coord(ttFont, regular_opsz_coord):\n\n  if regular_opsz_coord >= 9 and regular_opsz_coord <= 13:\n    yield PASS, (\"Regular:opsz coordinate ({})\"\n                 \" looks good.\").format(regular_opsz_coord)\n  else:\n    yield WARN, (\"The 'opsz' (Optical Size) coordinate\"\n                 \" on the 'Regular' instance is recommended\"\n                 \" to be a value in the range 9 to 13.\"\n                 \" Got a '{}' coordinate instead.\"\n                 \"\").format(regular_opsz_coord)", "response": "Regular opsz coordinate is between 9 and 13."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the variable font wght coordinate is within the valid range of 1 to 1000 on all instances.", "response": "def com_google_fonts_check_wght_valid_range(ttFont):\n  \"\"\"The variable font 'wght' (Weight) axis coordinate\n     must be within spec range of 1 to 1000 on all instances.\"\"\"\n\n  Failed = False\n  for instance in ttFont['fvar'].instances:\n    if 'wght' in instance.coordinates:\n      value = instance.coordinates['wght']\n      if value < 1 or value > 1000:\n        Failed = True\n        yield FAIL, (f\"Found a bad wght coordinate with value '{value}'\"\n                      \" outside of the valid range from 1 to 1000.\") \n        break\n\n  if not Failed:\n    yield PASS, (\"OK\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize_variable_name(node, reachability_tester):\n    # type: (Dict[str, Any], ReferenceReachabilityTester) -> Optional[str]\n    \"\"\" Returns normalized variable name.\n    Normalizing means that variable names get explicit visibility by\n    visibility prefix such as: \"g:\", \"s:\", ...\n\n    Returns None if the specified node is unanalyzable.\n    A node is unanalyzable if:\n\n    - the node is not identifier-like\n    - the node is named dynamically\n    \"\"\"\n\n    node_type = NodeType(node['type'])\n\n    if not is_analyzable_identifier(node):\n        return None\n\n    if node_type is NodeType.IDENTIFIER:\n        return _normalize_identifier_value(node, reachability_tester)\n\n    # Nodes identifier-like without identifier is always normalized because\n    # the nodes can not have a visibility prefix.\n    if node_type in IdentifierLikeNodeTypes:\n        return node['value']", "response": "Normalizes a variable name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef traverse(node, on_enter=None, on_leave=None):\n    node_type = NodeType(node['type'])\n\n    if node_type not in ChildNodeAccessorMap:\n        raise UnknownNodeTypeException(node_type)\n\n    if on_enter:\n        should_traverse_children = on_enter(node) is not SKIP_CHILDREN\n    else:\n        should_traverse_children = True\n\n    if should_traverse_children:\n        for property_accessor in ChildNodeAccessorMap[node_type]:\n            accessor_func = property_accessor['accessor']\n            prop_name = property_accessor['property_name']\n\n            accessor_func(lambda child_node: traverse(child_node, on_enter, on_leave),\n                          node[prop_name])\n\n        for handler in _traverser_extensions:\n            handler(node, on_enter=on_enter, on_leave=on_leave)\n\n    if on_leave:\n        on_leave(node)", "response": "Traverse the specified Vim script AST node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_by_config(self, config_dict):\n        policy_enabling_map = self._get_enabling_map(config_dict)\n        self.enabled_policies = []\n\n        for policy_name, is_policy_enabled in policy_enabling_map.items():\n            if not self._is_policy_exists(policy_name):\n                self._warn_unexistent_policy(policy_name)\n                continue\n\n            if is_policy_enabled:\n                enabled_policy = self._get_policy(policy_name)\n                self.enabled_policies.append(enabled_policy)", "response": "Update the list of enabled policies by the config dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_cmdargs(argv):\n    parser = _build_arg_parser()\n    namespace = parser.parse_args(argv[1:])\n\n    cmdargs = vars(namespace)\n    return cmdargs", "response": "Build command line arguments dict to use ;"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses vim script file and return the AST.", "response": "def parse(self, lint_target):  # type: (AbstractLintTarget) -> Dict[str, Any]\n        \"\"\" Parse vim script file and return the AST. \"\"\"\n        decoder = Decoder(default_decoding_strategy)\n        decoded = decoder.decode(lint_target.read())\n        decoded_and_lf_normalized = decoded.replace('\\r\\n', '\\n')\n\n        return self.parse_string(decoded_and_lf_normalized)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse vim script string and return the AST.", "response": "def parse_string(self, string):  # type: (str) -> Dict[str, Any]\n        \"\"\" Parse vim script string and return the AST. \"\"\"\n        lines = string.split('\\n')\n\n        reader = vimlparser.StringReader(lines)\n        parser = vimlparser.VimLParser(self._enable_neovim)\n        ast = parser.parse(reader)\n\n        # TOPLEVEL does not have a pos, but we need pos for all nodes\n        ast['pos'] = {'col': 1, 'i': 0, 'lnum': 1}\n\n        for plugin in self.plugins:\n            plugin.process(ast)\n\n        return ast"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_redir(self, redir_cmd):\n        redir_cmd_str = redir_cmd['str']\n\n        matched = re.match(r'redir?!?\\s*(=>>?\\s*)(\\S+)', redir_cmd_str)\n        if matched:\n            redir_cmd_op = matched.group(1)\n            redir_cmd_body = matched.group(2)\n\n            arg_pos = redir_cmd['ea']['argpos']\n\n            # Position of the \"redir_cmd_body\"\n            start_pos = {\n                'col': arg_pos['col'] + len(redir_cmd_op),\n                'i': arg_pos['i'] + len(redir_cmd_op),\n                'lnum': arg_pos['lnum'],\n            }\n\n            # NOTE: This is a hack to parse variable node.\n            raw_ast = self.parse_string('echo ' + redir_cmd_body)\n\n            # We need the left node of ECHO node\n            redir_cmd_ast = raw_ast['body'][0]['list'][0]\n\n            def adjust_position(node):\n                pos = node['pos']\n                # Care 1-based index and the length of \"echo \".\n                pos['col'] += start_pos['col'] - 1 - 5\n\n                # Care the length of \"echo \".\n                pos['i'] += start_pos['i'] - 5\n\n                # Care 1-based index\n                pos['lnum'] += start_pos['lnum'] - 1\n\n            traverse(redir_cmd_ast, on_enter=adjust_position)\n\n            return redir_cmd_ast\n\n        return None", "response": "Parses a command : redir content."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_string_expr(self, string_expr_node):\n        string_expr_node_value = string_expr_node['value']\n        string_expr_str = string_expr_node_value[1:-1]\n\n        # Care escaped string literals\n        if string_expr_node_value[0] == \"'\":\n            string_expr_str = string_expr_str.replace(\"''\", \"'\")\n        else:\n            string_expr_str = string_expr_str.replace('\\\\\"', '\"')\n\n        # NOTE: This is a hack to parse expr1. See :help expr1\n        raw_ast = self.parse_string('echo ' + string_expr_str)\n\n        # We need the left node of ECHO node\n        parsed_string_expr_nodes = raw_ast['body'][0]['list']\n\n        start_pos = string_expr_node['pos']\n\n        def adjust_position(node):\n            pos = node['pos']\n\n            # Care 1-based index and the length of \"echo \".\n            pos['col'] += start_pos['col'] - 1 - 5\n\n            # Care the length of \"echo \".\n            pos['i'] += start_pos['i'] - 5\n\n            # Care 1-based index\n            pos['lnum'] += start_pos['lnum'] - 1\n\n        for parsed_string_expr_node in parsed_string_expr_nodes:\n            traverse(parsed_string_expr_node, on_enter=adjust_position)\n\n        return parsed_string_expr_nodes", "response": "Parse a string expression node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining if the specified node is a builtin identifier.", "response": "def is_builtin_variable(id_node):  # type: (Dict[str, Any]) -> bool\n    \"\"\" Whether the specified node is a builtin identifier. \"\"\"\n    # Builtin variables are always IDENTIFIER.\n    if NodeType(id_node['type']) is not NodeType.IDENTIFIER:\n        return False\n\n    id_value = id_node['value']\n\n    if id_value.startswith('v:'):\n        # It is an explicit builtin variable such as: \"v:count\", \"v:char\"\n        # TODO: Add unknown builtin flag\n        return True\n\n    if is_builtin_function(id_node):\n        return True\n\n    if id_value in ['key', 'val']:\n        # These builtin variable names are available on only map() or filter().\n        return is_on_lambda_string_context(id_node)\n\n    # It is an implicit builtin variable such as: \"count\", \"char\"\n    return id_value in BuiltinVariablesCanHaveImplicitScope"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if the given node is a builtin function name identifier.", "response": "def is_builtin_function(id_node):  # type: (Dict[str, Any]) -> bool\n    \"\"\" Whether the specified node is a builtin function name identifier.\n    The given identifier should be a child node of NodeType.CALL.\n    \"\"\"\n    # Builtin functions are always IDENTIFIER.\n    if NodeType(id_node['type']) is not NodeType.IDENTIFIER:\n        return False\n\n    id_value = id_node['value']\n\n    if not is_function_identifier(id_node):\n        return False\n\n    # There are difference between a function identifier and variable\n    # identifier:\n    #\n    #   let localtime = 0\n    #   echo localtime \" => 0\n    #   echo localtime() \" => 1420011455\n    return id_value in BuiltinFunctions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetect the possible scope visibility by the specified node.", "response": "def detect_possible_scope_visibility(node, context_scope):  # type: (Dict[str, Any], Scope) -> ScopeVisibilityHint\n    \"\"\" Returns a *possible* variable visibility by the specified node.\n    The \"possible\" means that we can not determine a scope visibility of lambda arguments until reachability check.\n    \"\"\"\n    node_type = NodeType(node['type'])\n\n    if not is_analyzable_identifier(node):\n        return ScopeVisibilityHint(\n            ScopeVisibility.UNANALYZABLE,\n            ExplicityOfScopeVisibility.UNANALYZABLE\n        )\n\n    if node_type is NodeType.IDENTIFIER:\n        return _detect_possible_identifier_scope_visibility(node, context_scope)\n\n    if node_type in GlobalLikeScopeVisibilityNodeTypes:\n        return ScopeVisibilityHint(\n            ScopeVisibility.GLOBAL_LIKE,\n            ExplicityOfScopeVisibility.IMPLICIT_BUT_CONSTRAINED\n        )\n\n    return ScopeVisibilityHint(\n        ScopeVisibility.UNANALYZABLE,\n        ExplicityOfScopeVisibility.UNANALYZABLE\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach_identifier_attributes(self, ast):  # type: (Dict[str, Any]) -> Dict[str, Any]\n        redir_assignment_parser = RedirAssignmentParser()\n        ast_with_parsed_redir = redir_assignment_parser.process(ast)\n\n        map_and_filter_parser = CallNodeParser()\n        ast_with_parse_map_and_filter_and_redir = \\\n            map_and_filter_parser.process(ast_with_parsed_redir)\n\n        traverse(\n            ast_with_parse_map_and_filter_and_redir,\n            on_enter=lambda node: self._enter_handler(\n                node,\n                is_on_lambda_str=None,\n                is_on_lambda_body=None,\n            )\n        )\n        return ast", "response": "Attach 5 flags to the AST."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a violation report for the node.", "response": "def create_violation_report(self, node, lint_context):\n        \"\"\" Returns a violation report for the node. \"\"\"\n        return {\n            'name': self.name,\n            'level': self.level,\n            'description': self.description,\n            'reference': self.reference,\n            'position': {\n                'line': node['pos']['lnum'],\n                'column': node['pos']['col'],\n                'path': lint_context['lint_target'].path,\n            },\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a config of the concrete policy.", "response": "def get_policy_config(self, lint_context):\n        \"\"\"\n        Returns a config of the concrete policy. For example, a config of ProhibitSomethingEvil is located on\n        config.policies.ProhibitSomethingEvil.\n        \"\"\"\n        policy_config = lint_context['config']\\\n            .get('policies', {})\\\n            .get(self.__class__.__name__, {})\n\n        return policy_config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a violation if the node is invalid.", "response": "def get_violation_if_found(self, node, lint_context):\n        \"\"\" Returns a violation if the node is invalid. \"\"\"\n        if self.is_valid(node, lint_context):\n            return None\n\n        return self.create_violation_report(node, lint_context)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_all_policies():\n    pkg_name = _get_policy_package_name_for_test()\n    pkg_path_list = pkg_name.split('.')\n\n    pkg_path = str(Path(_get_vint_root(), *pkg_path_list).resolve())\n\n    for _, module_name, is_pkg in pkgutil.iter_modules([pkg_path]):\n        if not is_pkg:\n            module_fqn = pkg_name + '.' + module_name\n            logging.debug('Loading the policy module: `{fqn}`'.format(fqn=module_fqn))\n            importlib.import_module(module_fqn)", "response": "Imports all policies that were registered by vint. policy_registry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the ast and returns the scope tree and links between the identifiers and the identifiers.", "response": "def process(self, ast):  # type: (Dict[str, Any]) -> None\n        \"\"\" Build a scope tree and links between scopes and identifiers by the\n        specified ast. You can access the built scope tree and the built links\n        by .scope_tree and .link_registry.\n        \"\"\"\n        id_classifier = IdentifierClassifier()\n        attached_ast = id_classifier.attach_identifier_attributes(ast)\n\n        # We are already in script local scope.\n        self._scope_tree_builder.enter_new_scope(ScopeVisibility.SCRIPT_LOCAL)\n\n        traverse(attached_ast,\n                 on_enter=self._enter_handler,\n                 on_leave=self._leave_handler)\n\n        self.scope_tree = self._scope_tree_builder.get_global_scope()\n        self.link_registry = self._scope_tree_builder.link_registry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_builds_by_revision(self, revision, job_type_name='Build', debug_build=False):\n        builds = set()\n\n        try:\n            self.logger.info('Querying {url} for list of builds for revision: {revision}'.format(\n                             url=self.client.server_url, revision=revision))\n\n            # Retrieve the option hash to filter for type of build (opt, and debug for now)\n            option_hash = None\n            for key, values in self.client.get_option_collection_hash().iteritems():\n                for value in values:\n                    if value['name'] == ('debug' if debug_build else 'opt'):\n                        option_hash = key\n                        break\n                if option_hash:\n                    break\n\n            resultsets = self.client.get_pushes(self.branch, revision=revision)\n\n            # Set filters to speed-up querying jobs\n            kwargs = {\n                'option_collection_hash': option_hash,\n                'job_type_name': job_type_name,\n                'exclusion_profile': False,\n            }\n            kwargs.update(self.get_treeherder_platform(self.platform))\n\n            for resultset in resultsets:\n                kwargs.update({'result_set_id': resultset['id']})\n                jobs = self.client.get_jobs(self.branch, **kwargs)\n                for job in jobs:\n                    log_urls = self.client.get_job_log_url(self.branch, job_id=job['id'])\n                    for log_url in log_urls:\n                        if self.application in log_url['url']:\n                            self.logger.debug('Found build folder: {}'.format(log_url['url']))\n                            builds.update([log_url['url']])\n\n        except Exception:\n            self.logger.exception('Failure occurred when querying Treeherder for builds')\n\n        return list(builds)", "response": "Query Treeherder for a list of builds for a given revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconcatenate multi part strings into urls.", "response": "def urljoin(*fragments):\n    \"\"\"Concatenate multi part strings into urls.\"\"\"\n    # Strip possible already existent final slashes of fragments except for the last one\n    parts = [fragment.rstrip('/') for fragment in fragments[:len(fragments) - 1]]\n    parts.append(fragments[-1])\n\n    return '/'.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the md5 hash of a file using the hashlib library.", "response": "def create_md5(path):\n    \"\"\"Create the md5 hash of a file using the hashlib library.\"\"\"\n    m = hashlib.md5()\n    # rb necessary to run correctly in windows.\n    with open(path, \"rb\") as f:\n        while True:\n            data = f.read(8192)\n            if not data:\n                break\n            m.update(data)\n\n    return m.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self, filter):\n        if hasattr(filter, '__call__'):\n            return [entry for entry in self.entries if filter(entry)]\n        else:\n            pattern = re.compile(filter, re.IGNORECASE)\n            return [entry for entry in self.entries if pattern.match(entry)]", "response": "Filter entries by calling function or applying regex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_starttag(self, tag, attrs):\n        if not tag == 'a':\n            return\n\n        for attr in attrs:\n            if attr[0] == 'href':\n                # Links look like: /pub/firefox/nightly/2015/\n                # We have to trim the fragment down to the last item. Also to ensure we\n                # always get it, we remove a possible final slash first\n                url = urllib.unquote(attr[1])\n                self.active_url = url.rstrip('/').split('/')[-1]\n\n                return", "response": "Callback for when a tag gets opened."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates delta for daylight saving.", "response": "def dst(self, dt):\n        \"\"\"Calculate delta for daylight saving.\"\"\"\n        # Daylight saving starts on the second Sunday of March at 2AM standard\n        dst_start_date = self.first_sunday(dt.year, 3) + timedelta(days=7) \\\n                                                       + timedelta(hours=2)\n        # Daylight saving ends on the first Sunday of November at 2AM standard\n        dst_end_date = self.first_sunday(dt.year, 11) + timedelta(hours=2)\n\n        if dst_start_date <= dt.replace(tzinfo=None) < dst_end_date:\n            return timedelta(hours=1)\n        else:\n            return timedelta(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef first_sunday(self, year, month):\n        date = datetime(year, month, 1, 0)\n        days_until_sunday = 6 - date.weekday()\n\n        return date + timedelta(days=days_until_sunday)", "response": "Get the first sunday of a month."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the name of the build.", "response": "def binary(self):\n        \"\"\"Return the name of the build.\"\"\"\n        def _get_binary():\n            # Retrieve all entries from the remote virtual folder\n            parser = self._create_directory_parser(self.path)\n            if not parser.entries:\n                raise errors.NotFoundError('No entries found', self.path)\n\n            # Download the first matched directory entry\n            pattern = re.compile(self.binary_regex, re.IGNORECASE)\n            for entry in parser.entries:\n                try:\n                    self._binary = pattern.match(entry).group()\n                    break\n                except Exception:\n                    # No match, continue with next entry\n                    continue\n            else:\n                raise errors.NotFoundError(\"Binary not found in folder\",\n                                           self.path)\n\n        self._retry_check_404(_get_binary)\n\n        return self._binary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url(self):\n        return urllib.quote(urljoin(self.path, self.binary),\n                            safe='%/:=&?~#+!$,;\\'@()*[]|')", "response": "Return the URL of the build."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filename(self):\n        if self._filename is None:\n            if os.path.splitext(self.destination)[1]:\n                # If the filename has been given make use of it\n                target_file = self.destination\n            else:\n                # Otherwise create it from the build details\n                target_file = os.path.join(self.destination,\n                                           self.build_filename(self.binary))\n\n            self._filename = os.path.abspath(target_file)\n\n        return self._filename", "response": "Return the local filename of the build."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect the current platform.", "response": "def detect_platform(self):\n        \"\"\"Detect the current platform.\"\"\"\n        # For Mac and Linux 32bit we do not need the bits appended\n        if mozinfo.os == 'mac' or \\\n                (mozinfo.os == 'linux' and mozinfo.bits == 32):\n            return mozinfo.os\n        else:\n            return \"%s%d\" % (mozinfo.os, mozinfo.bits)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads the specified file.", "response": "def download(self):\n        \"\"\"Download the specified file.\"\"\"\n        def total_seconds(td):\n            # Keep backward compatibility with Python 2.6 which doesn't have\n            # this method\n            if hasattr(td, 'total_seconds'):\n                return td.total_seconds()\n            else:\n                return (td.microseconds +\n                        (td.seconds + td.days * 24 * 3600) * 10 ** 6) / 10 ** 6\n\n        # Don't re-download the file\n        if os.path.isfile(os.path.abspath(self.filename)):\n            self.logger.info(\"File has already been downloaded: %s\" %\n                             (self.filename))\n            return self.filename\n\n        directory = os.path.dirname(self.filename)\n        if not os.path.isdir(directory):\n            os.makedirs(directory)\n\n        self.logger.info('Downloading from: %s' % self.url)\n        self.logger.info('Saving as: %s' % self.filename)\n\n        tmp_file = self.filename + \".part\"\n\n        def _download():\n            try:\n                start_time = datetime.now()\n\n                # Enable streaming mode so we can download content in chunks\n                r = self.session.get(self.url, stream=True)\n                r.raise_for_status()\n\n                content_length = r.headers.get('Content-length')\n                # ValueError: Value out of range if only total_size given\n                if content_length:\n                    total_size = int(content_length.strip())\n                    max_value = ((total_size / CHUNK_SIZE) + 1) * CHUNK_SIZE\n\n                bytes_downloaded = 0\n\n                log_level = self.logger.getEffectiveLevel()\n                if log_level <= logging.INFO and content_length:\n                    widgets = [pb.Percentage(), ' ', pb.Bar(), ' ', pb.ETA(),\n                               ' ', pb.FileTransferSpeed()]\n                    pbar = pb.ProgressBar(widgets=widgets,\n                                          maxval=max_value).start()\n\n                with open(tmp_file, 'wb') as f:\n                    for chunk in r.iter_content(CHUNK_SIZE):\n                        f.write(chunk)\n                        bytes_downloaded += CHUNK_SIZE\n\n                        if log_level <= logging.INFO and content_length:\n                            pbar.update(bytes_downloaded)\n\n                        t1 = total_seconds(datetime.now() - start_time)\n                        if self.timeout_download and \\\n                                t1 >= self.timeout_download:\n                            raise errors.TimeoutError\n\n                if log_level <= logging.INFO and content_length:\n                    pbar.finish()\n            except Exception:\n                if os.path.isfile(tmp_file):\n                    os.remove(tmp_file)\n                raise\n\n        self._retry(_download,\n                    retry_exceptions=(requests.exceptions.RequestException,\n                                      errors.TimeoutError))\n\n        os.rename(tmp_file, self.filename)\n\n        return self.filename"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_matching_builds(self, builds):\n        self.logger.info('Found %s build%s: %s' % (\n            len(builds),\n            len(builds) > 1 and 's' or '',\n            len(builds) > 10 and\n            ' ... '.join([', '.join(builds[:5]), ', '.join(builds[-5:])]) or\n            ', '.join(builds)))", "response": "Output the matching builds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_build_info(self):\n        # Retrieve build by revision\n        if self.revision:\n            th = treeherder.Treeherder(\n                APPLICATIONS_TO_FTP_DIRECTORY.get(self.application, self.application),\n                self.branch,\n                self.platform)\n            builds = th.query_builds_by_revision(\n                self.revision,\n                job_type_name='L10n Nightly' if self.locale_build else 'Nightly')\n\n            if not builds:\n                raise errors.NotFoundError('No builds have been found for revision', self.revision)\n\n            # Extract the build folders which are prefixed with the buildid\n            self.builds = [build.rsplit('/', 2)[1] for build in builds]\n            self.show_matching_builds(self.builds)\n\n            # There is only a single build per revision and platform\n            self.build_index = 0\n            self.logger.info('Selected build: %s' % self.builds[self.build_index])\n\n            # Retrieve the date from the build folder which is always 19 chars long\n            self.date = datetime.strptime(self.builds[self.build_index][:19],\n                                          '%Y-%m-%d-%H-%M-%S')\n\n            return\n\n        # Internally we access builds via index\n        if self.build_number is not None:\n            self.build_index = int(self.build_number) - 1\n        else:\n            self.build_index = None\n\n        if self.build_id:\n            # A build id has been specified. Split up its components so the\n            # date and time can be extracted:\n            # '20111212042025' -> '2011-12-12 04:20:25'\n            self.date = datetime.strptime(self.build_id, '%Y%m%d%H%M%S')\n\n        elif self.date:\n            # A date (without time) has been specified. Use its value and the\n            # build index to find the requested build for that day.\n            try:\n                self.date = datetime.strptime(self.date, '%Y-%m-%d')\n            except Exception:\n                raise ValueError('%s is not a valid date' % self.date)\n        else:\n            # If no querying option has been specified the latest available\n            # build of the given branch has to be identified. We also have to\n            # retrieve the date of the build via its build id.\n            self.date = self.get_latest_build_date()\n\n        self.builds, self.build_index = self.get_build_info_for_date(\n            self.date, self.build_index)", "response": "Define additional build information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning whether or not the given dir contains a build.", "response": "def is_build_dir(self, folder_name):\n        \"\"\"Return whether or not the given dir contains a build.\"\"\"\n        # Cannot move up to base scraper due to parser.entries call in\n        # get_build_info_for_date (see below)\n\n        url = '%s/' % urljoin(self.base_url, self.monthly_build_list_regex, folder_name)\n        if self.application in APPLICATIONS_MULTI_LOCALE \\\n                and self.locale != 'multi':\n            url = '%s/' % urljoin(url, self.locale)\n\n        parser = self._create_directory_parser(url)\n\n        pattern = re.compile(self.binary_regex, re.IGNORECASE)\n        for entry in parser.entries:\n            try:\n                pattern.match(entry).group()\n                return True\n            except Exception:\n                # No match, continue with next entry\n                continue\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_build_info_for_date(self, date, build_index=None):\n        url = urljoin(self.base_url, self.monthly_build_list_regex)\n        has_time = date and date.time()\n\n        self.logger.info('Retrieving list of builds from %s' % url)\n        parser = self._create_directory_parser(url)\n        regex = r'%(DATE)s-(\\d+-)+%(BRANCH)s%(L10N)s%(PLATFORM)s$' % {\n            'DATE': date.strftime('%Y-%m-%d'),\n            'BRANCH': self.branch,\n            # ensure to select the correct subfolder for localized builds\n            'L10N': '(-l10n)?' if self.locale_build else '',\n            'PLATFORM': '' if self.application not in (\n                        'fennec') else '-' + self.platform\n        }\n\n        parser.entries = parser.filter(regex)\n        parser.entries = parser.filter(self.is_build_dir)\n\n        if has_time:\n            # If a time is included in the date, use it to determine the\n            # build's index\n            regex = r'.*%s.*' % date.strftime('%H-%M-%S')\n            parser.entries = parser.filter(regex)\n\n        if not parser.entries:\n            date_format = '%Y-%m-%d-%H-%M-%S' if has_time else '%Y-%m-%d'\n            message = 'Folder for builds on %s has not been found' % \\\n                self.date.strftime(date_format)\n            raise errors.NotFoundError(message, url)\n\n        # If no index has been given, set it to the last build of the day.\n        self.show_matching_builds(parser.entries)\n        # If no index has been given, set it to the last build of the day.\n        if build_index is None:\n            # Find the most recent non-empty entry.\n            build_index = len(parser.entries)\n            for build in reversed(parser.entries):\n                build_index -= 1\n                if not build_index or self.is_build_dir(build):\n                    break\n        self.logger.info('Selected build: %s' % parser.entries[build_index])\n\n        return (parser.entries, build_index)", "response": "Return the build information for a given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the regex for the binary.", "response": "def binary_regex(self):\n        \"\"\"Return the regex for the binary.\"\"\"\n        regex_base_name = (r'^%(BINARY_NAME)s(\\s%(STUB_NEW)s\\.%(LOCALE)s|' +\n                           r'-.*\\.%(LOCALE)s\\.%(PLATFORM)s)')\n        regex_suffix = {'android-api-9': r'\\.%(EXT)s$',\n                        'android-api-11': r'\\.%(EXT)s$',\n                        'android-api-15': r'\\.%(EXT)s$',\n                        'android-api-16': r'\\.%(EXT)s$',\n                        'android-x86': r'\\.%(EXT)s$',\n                        'linux': r'\\.%(EXT)s$',\n                        'linux64': r'\\.%(EXT)s$',\n                        'mac': r'\\.%(EXT)s$',\n                        'mac64': r'\\.%(EXT)s$',\n                        'win32': r'(\\.installer%(STUB)s)?\\.%(EXT)s$',\n                        'win64': r'(\\.installer%(STUB)s)?\\.%(EXT)s$'}\n        regex = regex_base_name + regex_suffix[self.platform]\n\n        return regex % {'BINARY_NAME': APPLICATIONS_TO_BINARY_NAME.get(self.application,\n                                                                       self.application),\n                        'LOCALE': self.locale,\n                        'PLATFORM': self.platform_regex,\n                        'EXT': self.extension,\n                        'STUB': '-stub' if self.is_stub_installer else '',\n                        'STUB_NEW': 'Installer' if self.is_stub_installer else ''}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_filename(self, binary):\n        try:\n            # Get exact timestamp of the build to build the local file name\n            folder = self.builds[self.build_index]\n            timestamp = re.search(r'([\\d\\-]+)-\\D.*', folder).group(1)\n        except Exception:\n            # If it's not available use the build's date\n            timestamp = self.date.strftime('%Y-%m-%d')\n\n        return '%(TIMESTAMP)s-%(BRANCH)s-%(NAME)s' % {\n            'TIMESTAMP': timestamp,\n            'BRANCH': self.branch,\n            'NAME': binary}", "response": "Return the proposed filename with extension for the binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef monthly_build_list_regex(self):\n        # Regex for possible builds for the given date\n        return r'nightly/%(YEAR)s/%(MONTH)s/' % {\n            'YEAR': self.date.year,\n            'MONTH': str(self.date.month).zfill(2)}", "response": "Return the regex for the folder containing builds of a month."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path_regex(self):\n        try:\n            path = '%s/' % urljoin(self.monthly_build_list_regex,\n                                   self.builds[self.build_index])\n            if self.application in APPLICATIONS_MULTI_LOCALE \\\n                    and self.locale != 'multi':\n                path = '%s/' % urljoin(path, self.locale)\n            return path\n        except Exception:\n            folder = urljoin(self.base_url, self.monthly_build_list_regex)\n            raise errors.NotFoundError(\"Specified sub folder cannot be found\",\n                                       folder)", "response": "Return the regex for the path to the build folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the absolute path of the downloaded file.", "response": "def filename(self):\n        \"\"\"File name of the downloaded file.\"\"\"\n        if os.path.splitext(self.destination)[1]:\n            # If the filename has been given make use of it\n            target_file = self.destination\n        else:\n            # Otherwise determine it from the url.\n            parsed_url = urlparse(self.url)\n            source_filename = (parsed_url.path.rpartition('/')[-1] or\n                               parsed_url.hostname)\n            target_file = os.path.join(self.destination, source_filename)\n\n        return os.path.abspath(target_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef binary_regex(self):\n        regex = {'linux': r'^%(BINARY_NAME)s-%(VERSION)s\\.%(EXT)s$',\n                 'linux64': r'^%(BINARY_NAME)s-%(VERSION)s\\.%(EXT)s$',\n                 'mac': r'^%(BINARY_NAME)s(?:\\s|-)%(VERSION)s\\.%(EXT)s$',\n                 'mac64': r'^%(BINARY_NAME)s(?:\\s|-)%(VERSION)s\\.%(EXT)s$',\n                 'win32':\n                     r'^%(BINARY_NAME)s(%(STUB_NEW)s|(?:\\sSetup\\s|-)%(STUB)s%(VERSION)s)\\.%(EXT)s$',\n                 'win64':\n                     r'^%(BINARY_NAME)s(%(STUB_NEW)s|(?:\\sSetup\\s|-)%(STUB)s%(VERSION)s)\\.%(EXT)s$',\n                 }\n        return regex[self.platform] % {\n            'BINARY_NAME': APPLICATIONS_TO_BINARY_NAME.get(self.application, self.application),\n            'EXT': self.extension,\n            'STUB': 'Stub ' if self.is_stub_installer else '',\n            'STUB_NEW': ' Installer' if self.is_stub_installer else '',\n            'VERSION': self.version,\n        }", "response": "Return the regex for the binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path_regex(self):\n        regex = r'releases/%(VERSION)s/%(PLATFORM)s/%(LOCALE)s/'\n        return regex % {'LOCALE': self.locale,\n                        'PLATFORM': self.platform_regex,\n                        'VERSION': self.version}", "response": "Return the regex for the path to the build folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_filename(self, binary):\n        template = '%(APP)s-%(VERSION)s.%(LOCALE)s.%(PLATFORM)s%(STUB)s' \\\n                   '.%(EXT)s'\n        return template % {'APP': self.application,\n                           'VERSION': self.version,\n                           'LOCALE': self.locale,\n                           'PLATFORM': self.platform,\n                           'STUB': '-stub' if self.is_stub_installer else '',\n                           'EXT': self.extension}", "response": "Return the proposed filename with extension for the binary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks specified version and resolve special values.", "response": "def query_versions(self, version=None):\n        \"\"\"Check specified version and resolve special values.\"\"\"\n        if version not in RELEASE_AND_CANDIDATE_LATEST_VERSIONS:\n            return [version]\n\n        url = urljoin(self.base_url, 'releases/')\n        parser = self._create_directory_parser(url)\n        if version:\n            versions = parser.filter(RELEASE_AND_CANDIDATE_LATEST_VERSIONS[version])\n            from distutils.version import LooseVersion\n            versions.sort(key=LooseVersion)\n            return [versions[-1]]\n        else:\n            return parser.entries"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefining additional build information.", "response": "def get_build_info(self):\n        \"\"\"Define additional build information.\"\"\"\n        ReleaseScraper.get_build_info(self)\n\n        # Internally we access builds via index\n        url = urljoin(self.base_url, self.candidate_build_list_regex)\n        self.logger.info('Retrieving list of candidate builds from %s' % url)\n\n        parser = self._create_directory_parser(url)\n        if not parser.entries:\n            message = 'Folder for specific candidate builds at %s has not' \\\n                'been found' % url\n            raise errors.NotFoundError(message, url)\n\n        self.show_matching_builds(parser.entries)\n        self.builds = parser.entries\n        self.build_index = len(parser.entries) - 1\n\n        if self.build_number and \\\n                ('build%s' % self.build_number) in self.builds:\n            self.builds = ['build%s' % self.build_number]\n            self.build_index = 0\n            self.logger.info('Selected build: build%s' % self.build_number)\n        else:\n            self.logger.info('Selected build: %s' %\n                             (parser.entries[self.build_index]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef path_regex(self):\n        regex = r'%(PREFIX)s%(BUILD)s/%(PLATFORM)s/%(LOCALE)s/'\n        return regex % {'PREFIX': self.candidate_build_list_regex,\n                        'BUILD': self.builds[self.build_index],\n                        'LOCALE': self.locale,\n                        'PLATFORM': self.platform_regex}", "response": "Return the regex for the path to the build folder."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_build_info(self):\n        # Retrieve build by revision\n        if self.revision:\n            th = treeherder.Treeherder(\n                APPLICATIONS_TO_FTP_DIRECTORY.get(self.application, self.application),\n                self.branch,\n                self.platform)\n            builds = th.query_builds_by_revision(\n                self.revision, job_type_name='Build', debug_build=self.debug_build)\n\n            if not builds:\n                raise errors.NotFoundError('No builds have been found for revision', self.revision)\n\n            # Extract timestamp from each build folder\n            self.builds = [build.rsplit('/', 2)[1] for build in builds]\n            self.show_matching_builds(self.builds)\n\n            # There is only a single build\n            self.build_index = 0\n            self.logger.info('Selected build: %s' % self.builds[self.build_index])\n\n            return\n\n        # Internally we access builds via index\n        if self.build_number is not None:\n            self.build_index = int(self.build_number) - 1\n        else:\n            self.build_index = None\n\n        if self.date is not None:\n            try:\n                # date is provided in the format 2013-07-23\n                self.date = datetime.strptime(self.date, '%Y-%m-%d')\n            except Exception:\n                try:\n                    # date is provided as a unix timestamp\n                    datetime.fromtimestamp(float(self.date))\n                    self.timestamp = self.date\n                except Exception:\n                    raise ValueError('%s is not a valid date' % self.date)\n\n        # For localized builds we do not have to retrieve the list of builds\n        # because only the last build is available\n        if not self.locale_build:\n            self.builds, self.build_index = self.get_build_info_for_index(\n                self.build_index)\n            # Always force a timestamp prefix in the filename\n            self.timestamp = self.builds[self.build_index]", "response": "Define additional build information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef binary_regex(self):\n        regex_base_name = (r'^(%(STUB_NEW)s|%(BINARY_NAME)s-.*\\.%(LOCALE)s\\.%(PLATFORM)s)')\n        regex_suffix = {'linux': r'.*\\.%(EXT)s$',\n                        'linux64': r'.*\\.%(EXT)s$',\n                        'mac': r'.*\\.%(EXT)s$',\n                        'mac64': r'.*\\.%(EXT)s$',\n                        'win32': r'(\\.installer%(STUB)s)?\\.%(EXT)s$',\n                        'win64': r'(\\.installer%(STUB)s)?\\.%(EXT)s$'}\n\n        regex = regex_base_name + regex_suffix[self.platform]\n\n        return regex % {'BINARY_NAME': APPLICATIONS_TO_BINARY_NAME.get(self.application,\n                                                                       self.application),\n                        'LOCALE': self.locale,\n                        'PLATFORM': PLATFORM_FRAGMENTS[self.platform],\n                        'STUB': '-stub' if self.is_stub_installer else '',\n                        'STUB_NEW': 'setup' if self.is_stub_installer else '',\n                        'EXT': self.extension}", "response": "Return the regex for the binary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the proposed filename with extension for the binary.", "response": "def build_filename(self, binary):\n        \"\"\"Return the proposed filename with extension for the binary.\"\"\"\n\n        return '%(TIMESTAMP)s%(BRANCH)s%(DEBUG)s-%(NAME)s' % {\n            'TIMESTAMP': self.timestamp + '-' if self.timestamp else '',\n            'BRANCH': self.branch,\n            'DEBUG': '-debug' if self.debug_build else '',\n            'NAME': binary}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the regex for the folder which contains the list of builds.", "response": "def build_list_regex(self):\n        \"\"\"Return the regex for the folder which contains the list of builds.\"\"\"\n        regex = 'tinderbox-builds/%(BRANCH)s-%(PLATFORM)s%(L10N)s%(DEBUG)s/'\n\n        return regex % {\n            'BRANCH': self.branch,\n            'PLATFORM': '' if self.locale_build else self.platform_regex,\n            'L10N': 'l10n' if self.locale_build else '',\n            'DEBUG': '-debug' if self.debug_build else ''}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date_matches(self, timestamp):\n        if self.date is None:\n            return False\n\n        timestamp = datetime.fromtimestamp(float(timestamp), self.timezone)\n        if self.date.date() == timestamp.date():\n            return True\n\n        return False", "response": "Determine whether the timestamp date is equal to the argument date."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects the current platform.", "response": "def detect_platform(self):\n        \"\"\"Detect the current platform.\"\"\"\n        platform = Scraper.detect_platform(self)\n\n        # On OS X we have to special case the platform detection code and\n        # fallback to 64 bit builds for the en-US locale\n        if mozinfo.os == 'mac' and self.locale == 'en-US' and \\\n                mozinfo.bits == 64:\n            platform = \"%s%d\" % (mozinfo.os, mozinfo.bits)\n\n        return platform"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_build_info_for_index(self, build_index=None):\n        url = urljoin(self.base_url, self.build_list_regex)\n\n        self.logger.info('Retrieving list of builds from %s' % url)\n        parser = self._create_directory_parser(url)\n        parser.entries = parser.filter(r'^\\d+$')\n\n        if self.timestamp:\n            # If a timestamp is given, retrieve the folder with the timestamp\n            # as name\n            parser.entries = self.timestamp in parser.entries and \\\n                [self.timestamp]\n\n        elif self.date:\n            # If date is given, retrieve the subset of builds on that date\n            parser.entries = filter(self.date_matches, parser.entries)\n\n        if not parser.entries:\n            message = 'No builds have been found'\n            raise errors.NotFoundError(message, url)\n\n        self.show_matching_builds(parser.entries)\n\n        # If no index has been given, set it to the last build of the day.\n        if build_index is None:\n            # Find the most recent non-empty entry.\n            build_index = len(parser.entries)\n            for build in reversed(parser.entries):\n                build_index -= 1\n                if not build_index or self.is_build_dir(build):\n                    break\n\n        self.logger.info('Selected build: %s' % parser.entries[build_index])\n\n        return (parser.entries, build_index)", "response": "Get additional information for the build at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_regex(self):\n        if self.locale_build:\n            return self.build_list_regex\n\n        return '%s/' % urljoin(self.build_list_regex, self.builds[self.build_index])", "response": "Return the regex for the path to the build folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_build_info(self):\n        # Retrieve build by revision\n        th = treeherder.Treeherder(\n            APPLICATIONS_TO_FTP_DIRECTORY.get(self.application, self.application),\n            'try',\n            self.platform)\n        builds = th.query_builds_by_revision(\n            self.revision, job_type_name='Build', debug_build=self.debug_build)\n\n        if not builds:\n            raise errors.NotFoundError('No builds have been found for revision', self.revision)\n\n        # Extract username and revision from build folders\n        self.builds = [build.rsplit('/', 3)[1] for build in builds]\n        self.show_matching_builds(self.builds)\n\n        # There is only a single build per revision and platform\n        self.build_index = 0\n        self.logger.info('Selected build: %s' % self.builds[self.build_index])", "response": "Define additional build information."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the regex for the path to the build folder.", "response": "def path_regex(self):\n        \"\"\"Return the regex for the path to the build folder.\"\"\"\n        build_dir = 'try-%(PLATFORM)s%(DEBUG)s/' % {\n            'PLATFORM': self.platform_regex,\n            'DEBUG': '-debug' if self.debug_build else ''}\n        return urljoin(self.build_list_regex,\n                       self.builds[self.build_index],\n                       build_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning current TTY and DISPLAY settings for GnuPG pinentry.", "response": "def create_default_options_getter():\n    \"\"\"Return current TTY and DISPLAY settings for GnuPG pinentry.\"\"\"\n    options = []\n    try:\n        ttyname = subprocess.check_output(args=['tty']).strip()\n        options.append(b'ttyname=' + ttyname)\n    except subprocess.CalledProcessError as e:\n        log.warning('no TTY found: %s', e)\n\n    display = os.environ.get('DISPLAY')\n    if display is not None:\n        options.append('display={}'.format(display).encode('ascii'))\n    else:\n        log.warning('DISPLAY not defined')\n\n    log.info('using %s for pinentry options', options)\n    return lambda: options"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending and flush a single line to the subprocess stdin.", "response": "def write(p, line):\n    \"\"\"Send and flush a single line to the subprocess' stdin.\"\"\"\n    log.debug('%s <- %r', p.args, line)\n    p.stdin.write(line)\n    p.stdin.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expect(p, prefixes, confidential=False):\n    resp = p.stdout.readline()\n    log.debug('%s -> %r', p.args, resp if not confidential else '********')\n    for prefix in prefixes:\n        if resp.startswith(prefix):\n            return resp[len(prefix):]\n    raise UnexpectedError(resp)", "response": "Read a line and return it without required prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses GPG pinentry program to interact with the user.", "response": "def interact(title, description, prompt, binary, options):\n    \"\"\"Use GPG pinentry program to interact with the user.\"\"\"\n    args = [binary]\n    p = subprocess.Popen(args=args,\n                         stdin=subprocess.PIPE,\n                         stdout=subprocess.PIPE,\n                         env=os.environ)\n    p.args = args  # TODO: remove after Python 2 deprecation.\n    expect(p, [b'OK'])\n\n    title = util.assuan_serialize(title.encode('ascii'))\n    write(p, b'SETTITLE ' + title + b'\\n')\n    expect(p, [b'OK'])\n\n    if description:\n        description = util.assuan_serialize(description.encode('ascii'))\n        write(p, b'SETDESC ' + description + b'\\n')\n        expect(p, [b'OK'])\n\n    if prompt:\n        prompt = util.assuan_serialize(prompt.encode('ascii'))\n        write(p, b'SETPROMPT ' + prompt + b'\\n')\n        expect(p, [b'OK'])\n\n    log.debug('setting %d options', len(options))\n    for opt in options:\n        write(p, b'OPTION ' + opt + b'\\n')\n        expect(p, [b'OK', b'ERR'])\n\n    write(p, b'GETPIN\\n')\n    pin = expect(p, [b'OK', b'D '], confidential=True)\n\n    p.communicate()  # close stdin and wait for the process to exit\n    exit_code = p.wait()\n    if exit_code:\n        raise subprocess.CalledProcessError(exit_code, binary)\n\n    return pin.decode('ascii').strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nask the user for a SCRAMBLED PIN.", "response": "def get_pin(self, _code=None):\n        \"\"\"Ask the user for (scrambled) PIN.\"\"\"\n        description = (\n            'Use the numeric keypad to describe number positions.\\n'\n            'The layout is:\\n'\n            '    7 8 9\\n'\n            '    4 5 6\\n'\n            '    1 2 3')\n        return interact(\n            title='{} PIN'.format(self.device_name),\n            prompt='PIN:',\n            description=description,\n            binary=self.pin_entry_binary,\n            options=self.options_getter())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nask the user for passphrase.", "response": "def get_passphrase(self, prompt='Passphrase:'):\n        \"\"\"Ask the user for passphrase.\"\"\"\n        passphrase = None\n        if self.cached_passphrase_ack:\n            passphrase = self.cached_passphrase_ack.get()\n        if passphrase is None:\n            passphrase = interact(\n                title='{} passphrase'.format(self.device_name),\n                prompt=prompt,\n                description=None,\n                binary=self.passphrase_entry_binary,\n                options=self.options_getter())\n        if self.cached_passphrase_ack:\n            self.cached_passphrase_ack.set(passphrase)\n        return passphrase"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_public_keys(self, identities):\n        public_keys = []\n        with self.device:\n            for i in identities:\n                pubkey = self.device.pubkey(identity=i)\n                vk = formats.decompress_pubkey(pubkey=pubkey,\n                                               curve_name=i.curve_name)\n                public_key = formats.export_public_key(vk=vk,\n                                                       label=i.to_string())\n                public_keys.append(public_key)\n        return public_keys", "response": "Export SSH public keys from the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsign given blob using a private key on the device.", "response": "def sign_ssh_challenge(self, blob, identity):\n        \"\"\"Sign given blob using a private key on the device.\"\"\"\n        msg = _parse_ssh_blob(blob)\n        log.debug('%s: user %r via %r (%r)',\n                  msg['conn'], msg['user'], msg['auth'], msg['key_type'])\n        log.debug('nonce: %r', msg['nonce'])\n        fp = msg['public_key']['fingerprint']\n        log.debug('fingerprint: %s', fp)\n        log.debug('hidden challenge size: %d bytes', len(blob))\n\n        log.info('please confirm user \"%s\" login to \"%s\" using %s...',\n                 msg['user'].decode('ascii'), identity.to_string(),\n                 self.device)\n\n        with self.device:\n            return self.device.sign(blob=blob, identity=identity)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing SSH fingerprint for specified blob.", "response": "def fingerprint(blob):\n    \"\"\"\n    Compute SSH fingerprint for specified blob.\n\n    See https://en.wikipedia.org/wiki/Public_key_fingerprint for details.\n    \"\"\"\n    digest = hashlib.md5(blob).digest()\n    return ':'.join('{:02x}'.format(c) for c in bytearray(digest))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_pubkey(blob):\n    fp = fingerprint(blob)\n    s = io.BytesIO(blob)\n    key_type = util.read_frame(s)\n    log.debug('key type: %s', key_type)\n    assert key_type in SUPPORTED_KEY_TYPES, key_type\n\n    result = {'blob': blob, 'type': key_type, 'fingerprint': fp}\n\n    if key_type == SSH_NIST256_KEY_TYPE:\n        curve_name = util.read_frame(s)\n        log.debug('curve name: %s', curve_name)\n        point = util.read_frame(s)\n        assert s.read() == b''\n        _type, point = point[:1], point[1:]\n        assert _type == SSH_NIST256_DER_OCTET\n        size = len(point) // 2\n        assert len(point) == 2 * size\n        coords = (util.bytes2num(point[:size]), util.bytes2num(point[size:]))\n\n        curve = ecdsa.NIST256p\n        point = ecdsa.ellipticcurve.Point(curve.curve, *coords)\n\n        def ecdsa_verifier(sig, msg):\n            assert len(sig) == 2 * size\n            sig_decode = ecdsa.util.sigdecode_string\n            vk = ecdsa.VerifyingKey.from_public_point(point, curve, hashfunc)\n            vk.verify(signature=sig, data=msg, sigdecode=sig_decode)\n            parts = [sig[:size], sig[size:]]\n            return b''.join([util.frame(b'\\x00' + p) for p in parts])\n\n        result.update(point=coords, curve=CURVE_NIST256,\n                      verifier=ecdsa_verifier)\n\n    if key_type == SSH_ED25519_KEY_TYPE:\n        pubkey = util.read_frame(s)\n        assert s.read() == b''\n\n        def ed25519_verify(sig, msg):\n            assert len(sig) == 64\n            vk = ed25519.VerifyingKey(pubkey)\n            vk.verify(sig, msg)\n            return sig\n\n        result.update(curve=CURVE_ED25519, verifier=ed25519_verify)\n\n    return result", "response": "Parse SSH public key from given blob."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the public key from the serialized blob.", "response": "def _decompress_nist256(pubkey):\n    \"\"\"\n    Load public key from the serialized blob.\n\n    The leading byte least-significant bit is used to decide how to recreate\n    the y-coordinate from the specified x-coordinate. See bitcoin/main.py#L198\n    (from https://github.com/vbuterin/pybitcointools/) for details.\n    \"\"\"\n    if pubkey[:1] in {b'\\x02', b'\\x03'}:  # set by ecdsa_get_public_key33()\n        curve = ecdsa.NIST256p\n        P = curve.curve.p()\n        A = curve.curve.a()\n        B = curve.curve.b()\n        x = util.bytes2num(pubkey[1:33])\n        beta = pow(int(x * x * x + A * x + B), int((P + 1) // 4), int(P))\n\n        p0 = util.bytes2num(pubkey[:1])\n        y = (P - beta) if ((beta + p0) % 2) else beta\n\n        point = ecdsa.ellipticcurve.Point(curve.curve, x, y)\n        return ecdsa.VerifyingKey.from_public_point(point, curve=curve,\n                                                    hashfunc=hashfunc)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads public key from the serialized blob.", "response": "def decompress_pubkey(pubkey, curve_name):\n    \"\"\"\n    Load public key from the serialized blob.\n\n    Raise ValueError on parsing error.\n    \"\"\"\n    vk = None\n    if len(pubkey) == 33:\n        decompress = {\n            CURVE_NIST256: _decompress_nist256,\n            CURVE_ED25519: _decompress_ed25519,\n            ECDH_CURVE25519: _decompress_ed25519,\n        }[curve_name]\n        vk = decompress(pubkey)\n\n    if not vk:\n        msg = 'invalid {!s} public key: {!r}'.format(curve_name, pubkey)\n        raise ValueError(msg)\n\n    return vk"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize_verifying_key(vk):\n    if isinstance(vk, ed25519.keys.VerifyingKey):\n        pubkey = vk.to_bytes()\n        key_type = SSH_ED25519_KEY_TYPE\n        blob = util.frame(SSH_ED25519_KEY_TYPE) + util.frame(pubkey)\n        return key_type, blob\n\n    if isinstance(vk, ecdsa.keys.VerifyingKey):\n        curve_name = SSH_NIST256_CURVE_NAME\n        key_blob = SSH_NIST256_DER_OCTET + vk.to_string()\n        parts = [SSH_NIST256_KEY_TYPE, curve_name, key_blob]\n        key_type = SSH_NIST256_KEY_TYPE\n        blob = b''.join([util.frame(p) for p in parts])\n        return key_type, blob\n\n    raise TypeError('unsupported {!r}'.format(vk))", "response": "Serialize a verifying key into a binary blob."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport public key to text format.", "response": "def export_public_key(vk, label):\n    \"\"\"\n    Export public key to text format.\n\n    The resulting string can be written into a .pub file or\n    appended to the ~/.ssh/authorized_keys file.\n    \"\"\"\n    key_type, blob = serialize_verifying_key(vk)\n    log.debug('fingerprint: %s', fingerprint(blob))\n    b64 = base64.b64encode(blob).decode('ascii')\n    return u'{} {} {}\\n'.format(key_type.decode('ascii'), b64, label)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing public key textual format as saved at a. pub file.", "response": "def import_public_key(line):\n    \"\"\"Parse public key textual format, as saved at a .pub file.\"\"\"\n    log.debug('loading SSH public key: %r', line)\n    file_type, base64blob, name = line.split()\n    blob = base64.b64decode(base64blob)\n    result = parse_pubkey(blob)\n    result['name'] = name.encode('utf-8')\n    assert result['type'] == file_type.encode('ascii')\n    log.debug('loaded %s public key: %s', file_type, result['fingerprint'])\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a list of subpackets from a file - like object.", "response": "def parse_subpackets(s):\n    \"\"\"See https://tools.ietf.org/html/rfc4880#section-5.2.3.1 for details.\"\"\"\n    subpackets = []\n    total_size = s.readfmt('>H')\n    data = s.read(total_size)\n    s = util.Reader(io.BytesIO(data))\n\n    while True:\n        try:\n            first = s.readfmt('B')\n        except EOFError:\n            break\n\n        if first < 192:\n            subpacket_len = first\n        elif first < 255:\n            subpacket_len = ((first - 192) << 8) + s.readfmt('B') + 192\n        else:  # first == 255\n            subpacket_len = s.readfmt('>L')\n\n        subpackets.append(s.read(subpacket_len))\n\n    return subpackets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_mpi(s):\n    bits = s.readfmt('>H')\n    blob = bytearray(s.read(int((bits + 7) // 8)))\n    return sum(v << (8 * i) for i, v in enumerate(reversed(blob)))", "response": "See https://tools.ietf.org/html/rfc4880#section-3.2 for details."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a signature from a stream.", "response": "def _parse_signature(stream):\n    \"\"\"See https://tools.ietf.org/html/rfc4880#section-5.2 for details.\"\"\"\n    p = {'type': 'signature'}\n\n    to_hash = io.BytesIO()\n    with stream.capture(to_hash):\n        p['version'] = stream.readfmt('B')\n        p['sig_type'] = stream.readfmt('B')\n        p['pubkey_alg'] = stream.readfmt('B')\n        p['hash_alg'] = stream.readfmt('B')\n        p['hashed_subpackets'] = parse_subpackets(stream)\n\n    # https://tools.ietf.org/html/rfc4880#section-5.2.4\n    tail_to_hash = b'\\x04\\xff' + struct.pack('>L', to_hash.tell())\n\n    p['_to_hash'] = to_hash.getvalue() + tail_to_hash\n\n    p['unhashed_subpackets'] = parse_subpackets(stream)\n    embedded = list(_parse_embedded_signatures(p['unhashed_subpackets']))\n    if embedded:\n        log.debug('embedded sigs: %s', embedded)\n        p['embedded'] = embedded\n\n    p['hash_prefix'] = stream.readfmt('2s')\n    if p['pubkey_alg'] in ECDSA_ALGO_IDS:\n        p['sig'] = (parse_mpi(stream), parse_mpi(stream))\n    elif p['pubkey_alg'] in RSA_ALGO_IDS:  # RSA\n        p['sig'] = (parse_mpi(stream),)\n    elif p['pubkey_alg'] == DSA_ALGO_ID:\n        p['sig'] = (parse_mpi(stream), parse_mpi(stream))\n    else:\n        log.error('unsupported public key algo: %d', p['pubkey_alg'])\n\n    assert not stream.read()\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a public key packet.", "response": "def _parse_pubkey(stream, packet_type='pubkey'):\n    \"\"\"See https://tools.ietf.org/html/rfc4880#section-5.5 for details.\"\"\"\n    p = {'type': packet_type}\n    packet = io.BytesIO()\n    with stream.capture(packet):\n        p['version'] = stream.readfmt('B')\n        p['created'] = stream.readfmt('>L')\n        p['algo'] = stream.readfmt('B')\n        if p['algo'] in ECDSA_ALGO_IDS:\n            log.debug('parsing elliptic curve key')\n            # https://tools.ietf.org/html/rfc6637#section-11\n            oid_size = stream.readfmt('B')\n            oid = stream.read(oid_size)\n            assert oid in SUPPORTED_CURVES, util.hexlify(oid)\n            p['curve_oid'] = oid\n\n            mpi = parse_mpi(stream)\n            log.debug('mpi: %x (%d bits)', mpi, mpi.bit_length())\n            leftover = stream.read()\n            if leftover:\n                leftover = io.BytesIO(leftover)\n                # https://tools.ietf.org/html/rfc6637#section-8\n                # should be b'\\x03\\x01\\x08\\x07': SHA256 + AES128\n                size, = util.readfmt(leftover, 'B')\n                p['kdf'] = leftover.read(size)\n                p['secret'] = leftover.read()\n\n            parse_func, keygrip_func = SUPPORTED_CURVES[oid]\n            keygrip = keygrip_func(parse_func(mpi))\n            log.debug('keygrip: %s', util.hexlify(keygrip))\n            p['keygrip'] = keygrip\n\n        elif p['algo'] == DSA_ALGO_ID:\n            parse_mpis(stream, n=4)  # DSA keys are not supported\n        elif p['algo'] == ELGAMAL_ALGO_ID:\n            parse_mpis(stream, n=3)  # ElGamal keys are not supported\n        else:  # assume RSA\n            parse_mpis(stream, n=2)  # RSA keys are not supported\n        assert not stream.read()\n\n    # https://tools.ietf.org/html/rfc4880#section-12.2\n    packet_data = packet.getvalue()\n    data_to_hash = (b'\\x99' + struct.pack('>H', len(packet_data)) +\n                    packet_data)\n    p['key_id'] = hashlib.sha1(data_to_hash).digest()[-8:]\n    p['_to_hash'] = data_to_hash\n    log.debug('key ID: %s', util.hexlify(p['key_id']))\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_user_id(stream, packet_type='user_id'):\n    value = stream.read()\n    to_hash = b'\\xb4' + util.prefix_len('>L', value)\n    return {'type': packet_type, 'value': value, '_to_hash': to_hash}", "response": "Parse a user_id packet."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses GPG packet stream and yield GPG packet dict.", "response": "def parse_packets(stream):\n    \"\"\"\n    Support iterative parsing of available GPG packets.\n\n    See https://tools.ietf.org/html/rfc4880#section-4.2 for details.\n    \"\"\"\n    reader = util.Reader(stream)\n    while True:\n        try:\n            value = reader.readfmt('B')\n        except EOFError:\n            return\n\n        log.debug('prefix byte: %s', bin(value))\n        assert util.bit(value, 7) == 1\n\n        tag = util.low_bits(value, 6)\n        if util.bit(value, 6) == 0:\n            length_type = util.low_bits(tag, 2)\n            tag = tag >> 2\n            fmt = {0: '>B', 1: '>H', 2: '>L'}[length_type]\n            packet_size = reader.readfmt(fmt)\n        else:\n            first = reader.readfmt('B')\n            if first < 192:\n                packet_size = first\n            elif first < 224:\n                packet_size = ((first - 192) << 8) + reader.readfmt('B') + 192\n            elif first == 255:\n                packet_size = reader.readfmt('>L')\n            else:\n                log.error('Partial Body Lengths unsupported')\n\n        log.debug('packet length: %d', packet_size)\n        packet_data = reader.read(packet_size)\n        packet_type = PACKET_TYPES.get(tag)\n\n        p = {'type': 'unknown', 'tag': tag, 'raw': packet_data}\n        if packet_type is not None:\n            try:\n                p = packet_type(util.Reader(io.BytesIO(packet_data)))\n                p['tag'] = tag\n            except ValueError:\n                log.exception('Skipping packet: %s', util.hexlify(packet_data))\n\n        log.debug('packet \"%s\": %s', p['type'], p)\n        yield p"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing digest on specified packets according to _to_hash field.", "response": "def digest_packets(packets, hasher):\n    \"\"\"Compute digest on specified packets, according to '_to_hash' field.\"\"\"\n    data_to_hash = io.BytesIO()\n    for p in packets:\n        data_to_hash.write(p['_to_hash'])\n    hasher.update(data_to_hash.getvalue())\n    return hasher.digest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads public key and first user ID for specified keygrip.", "response": "def load_by_keygrip(pubkey_bytes, keygrip):\n    \"\"\"Return public key and first user ID for specified keygrip.\"\"\"\n    stream = io.BytesIO(pubkey_bytes)\n    packets = list(parse_packets(stream))\n    packets_per_pubkey = []\n    for p in packets:\n        if p['type'] == 'pubkey':\n            # Add a new packet list for each pubkey.\n            packets_per_pubkey.append([])\n        packets_per_pubkey[-1].append(p)\n\n    for packets in packets_per_pubkey:\n        user_ids = [p for p in packets if p['type'] == 'user_id']\n        for p in packets:\n            if p.get('keygrip') == keygrip:\n                return p, user_ids\n    raise KeyError('{} keygrip not found'.format(util.hexlify(keygrip)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_signature(stream, original_data):\n    signature, = list(parse_packets((stream)))\n    hash_alg = HASH_ALGORITHMS[signature['hash_alg']]\n    digest = digest_packets([{'_to_hash': original_data}, signature],\n                            hasher=hashlib.new(hash_alg))\n    assert signature['hash_prefix'] == digest[:2]\n    return signature, digest", "response": "Load signature from stream and compute GPG digest for verification."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_armor(armored_data):\n    stream = io.BytesIO(armored_data)\n    lines = stream.readlines()[3:-1]\n    data = base64.b64decode(b''.join(lines))\n    payload, checksum = data[:-3], data[-3:]\n    assert util.crc24(payload) == checksum\n    return payload", "response": "Decode armored data into its binary form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove file from the hierarchy.", "response": "def remove_file(path, remove=os.remove, exists=os.path.exists):\n    \"\"\"Remove file, and raise OSError if still exists.\"\"\"\n    try:\n        remove(path)\n    except OSError:\n        if exists(path):\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a UNIX - domain socket on sock_path and listen on it and delete it after the context is over.", "response": "def unix_domain_socket_server(sock_path):\n    \"\"\"\n    Create UNIX-domain socket on specified path.\n\n    Listen on it, and delete it after the generated context is over.\n    \"\"\"\n    log.debug('serving on %s', sock_path)\n    remove_file(sock_path)\n\n    server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    server.bind(sock_path)\n    server.listen(1)\n    try:\n        yield server\n    finally:\n        remove_file(sock_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle a single connection using the specified protocol handler.", "response": "def handle_connection(conn, handler, mutex):\n    \"\"\"\n    Handle a single connection using the specified protocol handler in a loop.\n\n    Since this function may be called concurrently from server_thread,\n    the specified mutex is used to synchronize the device handling.\n\n    Exit when EOFError is raised.\n    All other exceptions are logged as warnings.\n    \"\"\"\n    try:\n        log.debug('welcome agent')\n        with contextlib.closing(conn):\n            while True:\n                msg = util.read_frame(conn)\n                with mutex:\n                    reply = handler.handle(msg=msg)\n                util.send(conn, reply)\n    except EOFError:\n        log.debug('goodbye agent')\n    except Exception as e:  # pylint: disable=broad-except\n        log.warning('error: %s', e, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retry(func, exception_type, quit_event):\n    while True:\n        if quit_event.is_set():\n            raise StopIteration\n        try:\n            return func()\n        except exception_type:\n            pass", "response": "Run the function retrying when the specified exception_type occurs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a server thread on the specified socket.", "response": "def server_thread(sock, handle_conn, quit_event):\n    \"\"\"Run a server on the specified socket.\"\"\"\n    log.debug('server thread started')\n\n    def accept_connection():\n        conn, _ = sock.accept()\n        conn.settimeout(None)\n        return conn\n\n    while True:\n        log.debug('waiting for connection on %s', sock.getsockname())\n        try:\n            conn = retry(accept_connection, socket.timeout, quit_event)\n        except StopIteration:\n            log.debug('server stopped')\n            break\n        # Handle connections from SSH concurrently.\n        threading.Thread(target=handle_conn,\n                         kwargs=dict(conn=conn)).start()\n    log.debug('server thread stopped')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nspawns a thread and join it after the context is over.", "response": "def spawn(func, kwargs):\n    \"\"\"Spawn a thread, and join it after the context is over.\"\"\"\n    t = threading.Thread(target=func, kwargs=kwargs)\n    t.start()\n    yield\n    t.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a process and wait until it finishes.", "response": "def run_process(command, environ):\n    \"\"\"\n    Run the specified process and wait until it finishes.\n\n    Use environ dict for environment variables.\n    \"\"\"\n    log.info('running %r with %r', command, environ)\n    env = dict(os.environ)\n    env.update(environ)\n    try:\n        p = subprocess.Popen(args=command, env=env)\n    except OSError as e:\n        raise OSError('cannot run %r: %s' % (command, e))\n    log.debug('subprocess %d is running', p.pid)\n    ret = p.wait()\n    log.debug('subprocess %d exited: %d', p.pid, ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall an external binary and return its stdout.", "response": "def check_output(args, env=None, sp=subprocess):\n    \"\"\"Call an external binary and return its stdout.\"\"\"\n    log.debug('calling %s with env %s', args, env)\n    output = sp.check_output(args=args, env=env)\n    log.debug('output: %r', output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_agent_sock_path(env=None, sp=subprocess):\n    args = [util.which('gpgconf'), '--list-dirs']\n    output = check_output(args=args, env=env, sp=sp)\n    lines = output.strip().split(b'\\n')\n    dirs = dict(line.split(b':', 1) for line in lines)\n    log.debug('%s: %s', args, dirs)\n    return dirs[b'agent-socket']", "response": "Parse gpgconf output to find out GPG agent UNIX socket path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect_to_agent(env=None, sp=subprocess):\n    sock_path = get_agent_sock_path(sp=sp, env=env)\n    # Make sure the original gpg-agent is running.\n    check_output(args=['gpg-connect-agent', '/bye'], sp=sp)\n    sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    sock.connect(sock_path)\n    return sock", "response": "Connect to GPG agent s UNIX socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sendline(sock, msg, confidential=False):\n    log.debug('<- %r', ('<snip>' if confidential else msg))\n    sock.sendall(msg + b'\\n')", "response": "Send a binary message followed by EOL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving a single line from the socket.", "response": "def recvline(sock):\n    \"\"\"Receive a single line from the socket.\"\"\"\n    reply = io.BytesIO()\n\n    while True:\n        c = sock.recv(1)\n        if not c:\n            return None  # socket is closed\n\n        if c == b'\\n':\n            break\n        reply.write(c)\n\n    result = reply.getvalue()\n    log.debug('-> %r', result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unescape(s):\n    s = bytearray(s)\n    i = 0\n    while i < len(s):\n        if s[i] == ord('%'):\n            hex_bytes = bytes(s[i+1:i+3])\n            value = int(hex_bytes.decode('ascii'), 16)\n            s[i:i+3] = [value]\n        i += 1\n    return bytes(s)", "response": "Unescape ASSUAN message (0xAB <-> '%AB')."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_term(s):\n    size, s = s.split(b':', 1)\n    size = int(size)\n    return s[:size], s[size:]", "response": "Parse a single s - expr term from bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(s):\n    if s.startswith(b'('):\n        s = s[1:]\n        name, s = parse_term(s)\n        values = [name]\n        while not s.startswith(b')'):\n            value, s = parse(s)\n            values.append(value)\n        return values, s[1:]\n\n    return parse_term(s)", "response": "Parse full s - expr from bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses signature integer values from s - expr.", "response": "def parse_sig(sig):\n    \"\"\"Parse signature integer values from s-expr.\"\"\"\n    label, sig = sig\n    assert label == b'sig-val'\n    algo_name = sig[0]\n    parser = {b'rsa': _parse_rsa_sig,\n              b'ecdsa': _parse_ecdsa_sig,\n              b'eddsa': _parse_eddsa_sig,\n              b'dsa': _parse_dsa_sig}[algo_name]\n    return parser(args=sig[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign_digest(sock, keygrip, digest, sp=subprocess, environ=None):\n    hash_algo = 8  # SHA256\n    assert len(digest) == 32\n\n    assert communicate(sock, 'RESET').startswith(b'OK')\n\n    ttyname = check_output(args=['tty'], sp=sp).strip()\n    options = ['ttyname={}'.format(ttyname)]  # set TTY for passphrase entry\n\n    display = (environ or os.environ).get('DISPLAY')\n    if display is not None:\n        options.append('display={}'.format(display))\n\n    for opt in options:\n        assert communicate(sock, 'OPTION {}'.format(opt)) == b'OK'\n\n    assert communicate(sock, 'SIGKEY {}'.format(keygrip)) == b'OK'\n    hex_digest = binascii.hexlify(digest).upper().decode('ascii')\n    assert communicate(sock, 'SETHASH {} {}'.format(hash_algo,\n                                                    hex_digest)) == b'OK'\n\n    assert communicate(sock, 'SETKEYDESC '\n                       'Sign+a+new+TREZOR-based+subkey') == b'OK'\n    assert communicate(sock, 'PKSIGN') == b'OK'\n    while True:\n        line = recvline(sock).strip()\n        if line.startswith(b'S PROGRESS'):\n            continue\n        else:\n            break\n    line = unescape(line)\n    log.debug('unescaped: %r', line)\n    prefix, sig = line.split(b' ', 1)\n    if prefix != b'D':\n        raise ValueError(prefix)\n\n    sig, leftover = parse(sig)\n    assert not leftover, leftover\n    return parse_sig(sig)", "response": "Sign a digest using GPG agent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_gnupg_components(sp=subprocess):\n    args = [util.which('gpgconf'), '--list-components']\n    output = check_output(args=args, sp=sp)\n    components = dict(re.findall('(.*):.*:(.*)', output.decode('utf-8')))\n    log.debug('gpgconf --list-components: %s', components)\n    return components", "response": "Parse GnuPG components paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare common GPG command line arguments.", "response": "def gpg_command(args, env=None):\n    \"\"\"Prepare common GPG command line arguments.\"\"\"\n    if env is None:\n        env = os.environ\n    cmd = get_gnupg_binary(neopg_binary=env.get('NEOPG_BINARY'))\n    return [cmd] + args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_keygrip(user_id, sp=subprocess):\n    args = gpg_command(['--list-keys', '--with-keygrip', user_id])\n    output = check_output(args=args, sp=sp).decode('utf-8')\n    return re.findall(r'Keygrip = (\\w+)', output)[0]", "response": "Get a keygrip of the primary GPG key of the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a keygrip of the primary GPG key of the specified user.", "response": "def gpg_version(sp=subprocess):\n    \"\"\"Get a keygrip of the primary GPG key of the specified user.\"\"\"\n    args = gpg_command(['--version'])\n    output = check_output(args=args, sp=sp)\n    line = output.split(b'\\n')[0]  # b'gpg (GnuPG) 2.1.11'\n    line = line.split(b' ')[-1]  # b'2.1.11'\n    line = line.split(b'-')[0]  # remove trailing version parts\n    return line.split(b'v')[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_public_key(user_id, env=None, sp=subprocess):\n    args = gpg_command(['--export', user_id])\n    result = check_output(args=args, env=env, sp=sp)\n    if not result:\n        log.error('could not find public key %r in local GPG keyring', user_id)\n        raise KeyError(user_id)\n    return result", "response": "Export GPG public key for specified user_id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting all GPG public keys.", "response": "def export_public_keys(env=None, sp=subprocess):\n    \"\"\"Export all GPG public keys.\"\"\"\n    args = gpg_command(['--export'])\n    result = check_output(args=args, env=env, sp=sp)\n    if not result:\n        raise KeyError('No GPG public keys found at env: {!r}'.format(env))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_agent_signer(user_id):\n    sock = connect_to_agent(env=os.environ)\n    keygrip = get_keygrip(user_id)\n\n    def sign(digest):\n        \"\"\"Sign the digest and return an ECDSA/RSA/DSA signature.\"\"\"\n        return sign_digest(sock=sock, keygrip=keygrip, digest=digest)\n\n    return sign", "response": "Create a function that signs a digest using GPG - Agent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting integer message code into a string name.", "response": "def msg_name(code):\n    \"\"\"Convert integer message code into a string name.\"\"\"\n    ids = {v: k for k, v in COMMANDS.items()}\n    return ids[code]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _legacy_pubs(buf):\n    leftover = buf.read()\n    if leftover:\n        log.warning('skipping leftover: %r', leftover)\n    code = util.pack('B', msg_code('SSH_AGENT_RSA_IDENTITIES_ANSWER'))\n    num = util.pack('L', 0)  # no SSH v1 keys\n    return util.frame(code, num)", "response": "Legacy SSH v1 public keys are not supported."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle an SSH message from the SSH client and return the response.", "response": "def handle(self, msg):\n        \"\"\"Handle SSH message from the SSH client and return the response.\"\"\"\n        debug_msg = ': {!r}'.format(msg) if self.debug else ''\n        log.debug('request: %d bytes%s', len(msg), debug_msg)\n        buf = io.BytesIO(msg)\n        code, = util.recv(buf, '>B')\n        if code not in self.methods:\n            log.warning('Unsupported command: %s (%d)', msg_name(code), code)\n            return failure()\n\n        method = self.methods[code]\n        log.debug('calling %s()', method.__name__)\n        reply = method(buf=buf)\n        debug_reply = ': {!r}'.format(reply) if self.debug else ''\n        log.debug('reply: %d bytes%s', len(reply), debug_reply)\n        return reply"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsigns a message with the SSH v2 public key.", "response": "def sign_message(self, buf):\n        \"\"\"\n        SSH v2 public key authentication is performed.\n\n        If the required key is not supported, raise KeyError\n        If the signature is invalid, raise ValueError\n        \"\"\"\n        key = formats.parse_pubkey(util.read_frame(buf))\n        log.debug('looking for %s', key['fingerprint'])\n        blob = util.read_frame(buf)\n        assert util.read_frame(buf) == b''\n        assert not buf.read()\n\n        for k in self.conn.parse_public_keys():\n            if (k['fingerprint']) == (key['fingerprint']):\n                log.debug('using key %r (%s)', k['name'], k['fingerprint'])\n                key = k\n                break\n        else:\n            raise KeyError('key not found')\n\n        label = key['name'].decode('utf-8')\n        log.debug('signing %d-byte blob with \"%s\" key', len(blob), label)\n        try:\n            signature = self.conn.sign(blob=blob, identity=key['identity'])\n        except IOError:\n            return failure()\n        log.debug('signature: %r', signature)\n\n        try:\n            sig_bytes = key['verifier'](sig=signature, msg=blob)\n            log.info('signature status: OK')\n        except formats.ecdsa.BadSignatureError:\n            log.exception('signature status: ERROR')\n            raise ValueError('invalid ECDSA signature')\n\n        log.debug('signature size: %d bytes', len(sig_bytes))\n\n        data = util.frame(util.frame(key['type']), util.frame(sig_bytes))\n        code = util.pack('B', msg_code('SSH2_AGENT_SIGN_RESPONSE'))\n        return util.frame(code, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreceives bytes from a connection socket or stream.", "response": "def recv(conn, size):\n    \"\"\"\n    Receive bytes from connection socket or stream.\n\n    If size is struct.calcsize()-compatible format, use it to unpack the data.\n    Otherwise, return the plain blob as bytes.\n    \"\"\"\n    try:\n        fmt = size\n        size = struct.calcsize(fmt)\n    except TypeError:\n        fmt = None\n    try:\n        _read = conn.recv\n    except AttributeError:\n        _read = conn.read\n\n    res = io.BytesIO()\n    while size > 0:\n        buf = _read(size)\n        if not buf:\n            raise EOFError\n        size = size - len(buf)\n        res.write(buf)\n    res = res.getvalue()\n    if fmt:\n        return struct.unpack(fmt, res)\n    else:\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bytes2num(s):\n    res = 0\n    for i, c in enumerate(reversed(bytearray(s))):\n        res += c << (i * 8)\n    return res", "response": "Convert MSB - first bytes to an unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef num2bytes(value, size):\n    res = []\n    for _ in range(size):\n        res.append(value & 0xFF)\n        value = value >> 8\n    assert value == 0\n    return bytes(bytearray(list(reversed(res))))", "response": "Convert an unsigned integer to MSB - first bytes with specified size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing MSB - first length - prefixed frame.", "response": "def frame(*msgs):\n    \"\"\"Serialize MSB-first length-prefixed frame.\"\"\"\n    res = io.BytesIO()\n    for msg in msgs:\n        res.write(msg)\n    msg = res.getvalue()\n    return pack('L', len(msg)) + msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the CRC of a given byte array.", "response": "def crc24(blob):\n    \"\"\"See https://tools.ietf.org/html/rfc4880#section-6.1 for details.\"\"\"\n    CRC24_INIT = 0x0B704CE\n    CRC24_POLY = 0x1864CFB\n\n    crc = CRC24_INIT\n    for octet in bytearray(blob):\n        crc ^= (octet << 16)\n        for _ in range(8):\n            crc <<= 1\n            if crc & 0x1000000:\n                crc ^= CRC24_POLY\n    assert 0 <= crc < 0x1000000\n    crc_bytes = struct.pack('>L', crc)\n    assert crc_bytes[:1] == b'\\x00'\n    return crc_bytes[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_bits(value, *bits):\n    result = []\n    for b in reversed(bits):\n        mask = (1 << b) - 1\n        result.append(value & mask)\n        value = value >> b\n    assert value == 0\n\n    result.reverse()\n    return result", "response": "Split integer value into list of ints according to bits list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread and unpack an object from stream using a struct format string.", "response": "def readfmt(stream, fmt):\n    \"\"\"Read and unpack an object from stream, using a struct format string.\"\"\"\n    size = struct.calcsize(fmt)\n    blob = stream.read(size)\n    return struct.unpack(fmt, blob)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_logging(verbosity, filename=None):\n    levels = [logging.WARNING, logging.INFO, logging.DEBUG]\n    level = levels[min(verbosity, len(levels) - 1)]\n    logging.root.setLevel(level)\n\n    fmt = logging.Formatter('%(asctime)s %(levelname)-12s %(message)-100s '\n                            '[%(filename)s:%(lineno)d]')\n    hdlr = logging.StreamHandler()  # stderr\n    hdlr.setFormatter(fmt)\n    logging.root.addHandler(hdlr)\n\n    if filename:\n        hdlr = logging.FileHandler(filename, 'a')\n        hdlr.setFormatter(fmt)\n        logging.root.addHandler(hdlr)", "response": "Configure logging for this tool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning full path to specified command or raise OSError if missing.", "response": "def which(cmd):\n    \"\"\"Return full path to specified command, or raise OSError if missing.\"\"\"\n    try:\n        # For Python 3\n        from shutil import which as _which\n    except ImportError:\n        # For Python 2\n        from backports.shutil_which import which as _which  # pylint: disable=relative-import\n    full_path = _which(cmd)\n    if full_path is None:\n        raise OSError('Cannot find {!r} in $PATH'.format(cmd))\n    log.debug('which %r => %r', cmd, full_path)\n    return full_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assuan_serialize(data):\n    for c in [b'%', b'\\n', b'\\r']:\n        escaped = '%{:02X}'.format(ord(c)).encode('ascii')\n        data = data.replace(c, escaped)\n    return data", "response": "Serialize data according to ASSUAN protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readfmt(self, fmt):\n        size = struct.calcsize(fmt)\n        blob = self.read(size)\n        obj, = struct.unpack(fmt, blob)\n        return obj", "response": "Read a specified object using a struct format string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, size=None):\n        blob = self.s.read(size)\n        if size is not None and len(blob) < size:\n            raise EOFError\n        if self._captured:\n            self._captured.write(blob)\n        return blob", "response": "Read size bytes from stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns existing value or None if deadline has expired.", "response": "def get(self):\n        \"\"\"Returns existing value, or None if deadline has expired.\"\"\"\n        if self.timer() > self.deadline:\n            self.value = None\n        return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, value):\n        self.deadline = self.timer() + self.duration\n        self.value = value", "response": "Set new value and reset the deadline for expiration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields all connections from the specified socket.", "response": "def yield_connections(sock):\n    \"\"\"Run a server on the specified socket.\"\"\"\n    while True:\n        log.debug('waiting for connection on %s', sock.getsockname())\n        try:\n            conn, _ = sock.accept()\n        except KeyboardInterrupt:\n            return\n        conn.settimeout(None)\n        log.debug('accepted connection on %s', sock.getsockname())\n        yield conn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sig_encode(r, s):\n    r = util.assuan_serialize(util.num2bytes(r, 32))\n    s = util.assuan_serialize(util.num2bytes(s, 32))\n    return b'(7:sig-val(5:ecdsa(1:r32:' + r + b')(1:s32:' + s + b')))'", "response": "Serialize ECDSA signature data into GPG S - expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_ecdh(line):\n    prefix, line = line.split(b' ', 1)\n    assert prefix == b'D'\n    exp, leftover = keyring.parse(keyring.unescape(line))\n    log.debug('ECDH s-exp: %r', exp)\n    assert not leftover\n    label, exp = exp\n    assert label == b'enc-val'\n    assert exp[0] == b'ecdh'\n    items = exp[1:]\n    log.debug('ECDH parameters: %r', items)\n    return dict(items)[b'e']", "response": "Parse ECDH request and return remote public key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a message to the keyring to get the key grip.", "response": "def _key_info(conn, args):\n    \"\"\"\n    Dummy reply (mainly for 'gpg --edit' to succeed).\n\n    For details, see GnuPG agent KEYINFO command help.\n    https://git.gnupg.org/cgi-bin/gitweb.cgi?p=gnupg.git;a=blob;f=agent/command.c;h=c8b34e9882076b1b724346787781f657cac75499;hb=refs/heads/master#l1082\n    \"\"\"\n    fmt = 'S KEYINFO {0} X - - - - - - -'\n    keygrip, = args\n    keyring.sendline(conn, fmt.format(keygrip).encode('ascii'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring GPG agent - related options.", "response": "def handle_option(self, opt):\n        \"\"\"Store GPG agent-related options (e.g. for pinentry).\"\"\"\n        self.options.append(opt)\n        log.debug('options: %s', self.options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_get_passphrase(self, conn, _):\n        p1 = self.client.device.ui.get_passphrase('Symmetric encryption:')\n        p2 = self.client.device.ui.get_passphrase('Re-enter encryption:')\n        if p1 == p2:\n            result = b'D ' + util.assuan_serialize(p1.encode('ascii'))\n            keyring.sendline(conn, result, confidential=True)\n        else:\n            log.warning('Passphrase does not match!')", "response": "Allow simple GPG symmetric encryption using a passphrase"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_getinfo(self, conn, args):\n        result = None\n        if args[0] == b'version':\n            result = self.version\n        elif args[0] == b's2k_count':\n            # Use highest number of S2K iterations.\n            # https://www.gnupg.org/documentation/manuals/gnupg/OpenPGP-Options.html\n            # https://tools.ietf.org/html/rfc4880#section-3.7.1.3\n            result = '{}'.format(64 << 20).encode('ascii')\n        else:\n            log.warning('Unknown GETINFO command: %s', args)\n\n        if result:\n            keyring.sendline(conn, b'D ' + result)", "response": "Handle some of the GETINFO messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_scd(self, conn, args):\n        reply = {\n            (b'GETINFO', b'version'): self.version,\n        }.get(args)\n        if reply is None:\n            raise AgentError(b'ERR 100696144 No such device <SCD>')\n        keyring.sendline(conn, b'D ' + reply)", "response": "Handle a SCD command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_identity(self, keygrip):\n        keygrip_bytes = binascii.unhexlify(keygrip)\n        pubkey_dict, user_ids = decode.load_by_keygrip(\n            pubkey_bytes=self.pubkey_bytes, keygrip=keygrip_bytes)\n        # We assume the first user ID is used to generate TREZOR-based GPG keys.\n        user_id = user_ids[0]['value'].decode('utf-8')\n        curve_name = protocol.get_curve_name_by_oid(pubkey_dict['curve_oid'])\n        ecdh = (pubkey_dict['algo'] == protocol.ECDH_ALGO_ID)\n\n        identity = client.create_identity(user_id=user_id, curve_name=curve_name)\n        verifying_key = self.client.pubkey(identity=identity, ecdh=ecdh)\n        pubkey = protocol.PublicKey(\n            curve_name=curve_name, created=pubkey_dict['created'],\n            verifying_key=verifying_key, ecdh=ecdh)\n        assert pubkey.key_id() == pubkey_dict['key_id']\n        assert pubkey.keygrip() == keygrip_bytes\n        return identity", "response": "Returns the device. interface. Identity that matches specified keygrip."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pksign(self, conn):\n        log.debug('signing %r digest (algo #%s)', self.digest, self.algo)\n        identity = self.get_identity(keygrip=self.keygrip)\n        r, s = self.client.sign(identity=identity,\n                                digest=binascii.unhexlify(self.digest))\n        result = sig_encode(r, s)\n        log.debug('result: %r', result)\n        keyring.sendline(conn, b'D ' + result)", "response": "Sign a message digest using a private EC key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pkdecrypt(self, conn):\n        for msg in [b'S INQUIRE_MAXLEN 4096', b'INQUIRE CIPHERTEXT']:\n            keyring.sendline(conn, msg)\n\n        line = keyring.recvline(conn)\n        assert keyring.recvline(conn) == b'END'\n        remote_pubkey = parse_ecdh(line)\n\n        identity = self.get_identity(keygrip=self.keygrip)\n        ec_point = self.client.ecdh(identity=identity, pubkey=remote_pubkey)\n        keyring.sendline(conn, b'D ' + _serialize_point(ec_point))", "response": "Handle decryption using ECDH."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef have_key(self, *keygrips):\n        for keygrip in keygrips:\n            try:\n                self.get_identity(keygrip=keygrip)\n                break\n            except KeyError as e:\n                log.warning('HAVEKEY(%s) failed: %s', keygrip, e)\n        else:\n            raise AgentError(b'ERR 67108881 No secret key <GPG Agent>')", "response": "Check if any keygrips corresponds to a TREZOR - based key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets algorithm ID and hexadecimal digest for next operation.", "response": "def set_hash(self, algo, digest):\n        \"\"\"Set algorithm ID and hexadecimal digest for next operation.\"\"\"\n        self.algo = algo\n        self.digest = digest"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle(self, conn):\n        keyring.sendline(conn, b'OK')\n        for line in keyring.iterlines(conn):\n            parts = line.split(b' ')\n            command = parts[0]\n            args = tuple(parts[1:])\n\n            if command == b'BYE':\n                return\n            elif command == b'KILLAGENT':\n                keyring.sendline(conn, b'OK')\n                raise AgentStop()\n\n            if command not in self.handlers:\n                log.error('unknown request: %r', line)\n                continue\n\n            handler = self.handlers[command]\n            if handler:\n                try:\n                    handler(conn, args)\n                except AgentError as e:\n                    msg, = e.args\n                    keyring.sendline(conn, msg)\n                    continue\n            keyring.sendline(conn, b'OK')", "response": "Handle a connection from GPG binary using the ASSUAN protocol."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _verify_support(identity, ecdh):\n    protocol = identity.identity_dict['proto']\n    if protocol not in {'ssh'}:\n        raise NotImplementedError(\n            'Unsupported protocol: {}'.format(protocol))\n    if ecdh:\n        raise NotImplementedError('No support for ECDH')\n    if identity.curve_name not in {formats.CURVE_NIST256}:\n        raise NotImplementedError(\n            'Unsupported elliptic curve: {}'.format(identity.curve_name))", "response": "Make sure the device supports given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verify_support(identity):\n    if identity.curve_name not in {formats.CURVE_NIST256}:\n        raise NotImplementedError(\n            'Unsupported elliptic curve: {}'.format(identity.curve_name))", "response": "Make sure the device supports given configuration."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self):\n        log.critical('NEVER USE THIS CODE FOR REAL-LIFE USE-CASES!!!')\n        log.critical('ONLY FOR DEBUGGING AND TESTING!!!')\n        # The code below uses HARD-CODED secret key - and should be used ONLY\n        # for GnuPG integration tests (e.g. when no real device is available).\n        # pylint: disable=attribute-defined-outside-init\n        self.secexp = 1\n        self.sk = ecdsa.SigningKey.from_secret_exponent(\n            secexp=self.secexp, curve=ecdsa.curves.NIST256p, hashfunc=hashlib.sha256)\n        self.vk = self.sk.get_verifying_key()\n        return self", "response": "Connect to a new instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign(self, identity, blob):\n        if identity.identity_dict['proto'] in {'ssh'}:\n            digest = hashlib.sha256(blob).digest()\n        else:\n            digest = blob\n        return self.sk.sign_digest_deterministic(digest=digest,\n                                                 hashfunc=hashlib.sha256)", "response": "Sign given blob and return the signature as bytes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ecdh(self, identity, pubkey):\n        assert pubkey[:1] == b'\\x04'\n        peer = ecdsa.VerifyingKey.from_string(\n            pubkey[1:],\n            curve=ecdsa.curves.NIST256p,\n            hashfunc=hashlib.sha256)\n        shared = ecdsa.VerifyingKey.from_public_point(\n            point=(peer.pubkey.point * self.secexp),\n            curve=ecdsa.curves.NIST256p,\n            hashfunc=hashlib.sha256)\n        return shared.to_string()", "response": "Get shared session key using Elliptic Curve Diffie - Hellman."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate GPG identity for hardware device.", "response": "def create_identity(user_id, curve_name):\n    \"\"\"Create GPG identity for hardware device.\"\"\"\n    result = interface.Identity(identity_str='gpg://', curve_name=curve_name)\n    result.identity_dict['host'] = user_id\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning public key as VerifyingKey object.", "response": "def pubkey(self, identity, ecdh=False):\n        \"\"\"Return public key as VerifyingKey object.\"\"\"\n        with self.device:\n            pubkey = self.device.pubkey(ecdh=ecdh, identity=identity)\n        return formats.decompress_pubkey(\n            pubkey=pubkey, curve_name=identity.curve_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sign(self, identity, digest):\n        log.info('please confirm GPG signature on %s for \"%s\"...',\n                 self.device, identity.to_string())\n        if identity.curve_name == formats.CURVE_NIST256:\n            digest = digest[:32]  # sign the first 256 bits\n        log.debug('signing digest: %s', util.hexlify(digest))\n        with self.device:\n            sig = self.device.sign(blob=digest, identity=identity)\n        return (util.bytes2num(sig[:32]), util.bytes2num(sig[32:]))", "response": "Sign the digest and return a serialized signature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ecdh(self, identity, pubkey):\n        log.info('please confirm GPG decryption on %s for \"%s\"...',\n                 self.device, identity.to_string())\n        with self.device:\n            return self.device.ecdh(pubkey=pubkey, identity=identity)", "response": "Derive shared secret using ECDH from remote public key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenumerate and connect to the first available HID interface.", "response": "def connect(self):\n        \"\"\"Enumerate and connect to the first available interface.\"\"\"\n        transport = self._defs.find_device()\n        if not transport:\n            raise interface.NotFoundError('{} not connected'.format(self))\n\n        log.debug('using transport: %s', transport)\n        for _ in range(5):  # Retry a few times in case of PIN failures\n            connection = self._defs.Client(transport=transport,\n                                           ui=self.ui,\n                                           state=self.__class__.cached_state)\n            self._verify_version(connection)\n\n            try:\n                connection.ping(msg='', pin_protection=True)  # unlock PIN\n                return connection\n            except (self._defs.PinException, ValueError) as e:\n                log.error('Invalid PIN: %s, retrying...', e)\n                continue\n            except Exception as e:\n                log.exception('ping failed: %s', e)\n                connection.close()  # so the next HID open() will succeed\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pubkey(self, identity, ecdh=False):\n        curve_name = identity.get_curve_name(ecdh=ecdh)\n        log.debug('\"%s\" getting public key (%s) from %s',\n                  identity.to_string(), curve_name, self)\n        addr = identity.get_bip32_address(ecdh=ecdh)\n        result = self._defs.get_public_node(\n            self.conn,\n            n=addr,\n            ecdsa_curve_name=curve_name)\n        log.debug('result: %s', result)\n        return bytes(result.node.public_key)", "response": "Return public key from a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsigns given blob and return the signature as bytes.", "response": "def sign(self, identity, blob):\n        \"\"\"Sign given blob and return the signature (as bytes).\"\"\"\n        curve_name = identity.get_curve_name(ecdh=False)\n        log.debug('\"%s\" signing %r (%s) on %s',\n                  identity.to_string(), blob, curve_name, self)\n        try:\n            result = self._defs.sign_identity(\n                self.conn,\n                identity=self._identity_proto(identity),\n                challenge_hidden=blob,\n                challenge_visual='',\n                ecdsa_curve_name=curve_name)\n            log.debug('result: %s', result)\n            assert len(result.signature) == 65\n            assert result.signature[:1] == b'\\x00'\n            return bytes(result.signature[1:])\n        except self._defs.TrezorFailure as e:\n            msg = '{} error: {}'.format(self, e)\n            log.debug(msg, exc_info=True)\n            raise interface.DeviceError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget shared session key using Elliptic Curve Diffie - Hellman.", "response": "def ecdh(self, identity, pubkey):\n        \"\"\"Get shared session key using Elliptic Curve Diffie-Hellman.\"\"\"\n        curve_name = identity.get_curve_name(ecdh=True)\n        log.debug('\"%s\" shared session key (%s) for %r from %s',\n                  identity.to_string(), curve_name, pubkey, self)\n        try:\n            result = self._defs.get_ecdh_session_key(\n                self.conn,\n                identity=self._identity_proto(identity),\n                peer_public_key=pubkey,\n                ecdsa_curve_name=curve_name)\n            log.debug('result: %s', result)\n            assert len(result.session_key) in {65, 33}  # NIST256 or Curve25519\n            assert result.session_key[:1] == b'\\x04'\n            return bytes(result.session_key)\n        except self._defs.TrezorFailure as e:\n            msg = '{} error: {}'.format(self, e)\n            log.debug(msg, exc_info=True)\n            raise interface.DeviceError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses string into Identity dictionary.", "response": "def string_to_identity(identity_str):\n    \"\"\"Parse string into Identity dictionary.\"\"\"\n    m = _identity_regexp.match(identity_str)\n    result = m.groupdict()\n    log.debug('parsed identity: %s', result)\n    return {k: v for k, v in result.items() if v}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps Identity dictionary into its string representation.", "response": "def identity_to_string(identity_dict):\n    \"\"\"Dump Identity dictionary into its string representation.\"\"\"\n    result = []\n    if identity_dict.get('proto'):\n        result.append(identity_dict['proto'] + '://')\n    if identity_dict.get('user'):\n        result.append(identity_dict['user'] + '@')\n    result.append(identity_dict['host'])\n    if identity_dict.get('port'):\n        result.append(':' + identity_dict['port'])\n    if identity_dict.get('path'):\n        result.append(identity_dict['path'])\n    log.debug('identity parts: %s', result)\n    return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of identity_dict items.", "response": "def items(self):\n        \"\"\"Return a copy of identity_dict items.\"\"\"\n        return [(k, unidecode.unidecode(v))\n                for k, v in self.identity_dict.items()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransliterate Unicode into ASCII.", "response": "def to_bytes(self):\n        \"\"\"Transliterate Unicode into ASCII.\"\"\"\n        s = identity_to_string(self.identity_dict)\n        return unidecode.unidecode(s).encode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bip32_address(self, ecdh=False):\n        index = struct.pack('<L', self.identity_dict.get('index', 0))\n        addr = index + self.to_bytes()\n        log.debug('bip32 address string: %r', addr)\n        digest = hashlib.sha256(addr).digest()\n        s = io.BytesIO(bytearray(digest))\n\n        hardened = 0x80000000\n        addr_0 = 17 if bool(ecdh) else 13\n        address_n = [addr_0] + list(util.recv(s, '<LLLL'))\n        return [(hardened | value) for value in address_n]", "response": "Compute BIP32 derivation address according to SLIP - 0013 / 0017."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_curve_name(self, ecdh=False):\n        if ecdh:\n            return formats.get_ecdh_curve_name(self.curve_name)\n        else:\n            return self.curve_name", "response": "Return correct curve name for device operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ssh_args(conn):\n    I, = conn.identities\n    identity = I.identity_dict\n    pubkey_tempfile, = conn.public_keys_as_files()\n\n    args = []\n    if 'port' in identity:\n        args += ['-p', identity['port']]\n    if 'user' in identity:\n        args += ['-l', identity['user']]\n\n    args += ['-o', 'IdentityFile={}'.format(pubkey_tempfile.name)]\n    args += ['-o', 'IdentitiesOnly=true']\n    return args + [identity['host']]", "response": "Create SSH command for connecting specified server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mosh_args(conn):\n    I, = conn.identities\n    identity = I.identity_dict\n\n    args = []\n    if 'port' in identity:\n        args += ['-p', identity['port']]\n    if 'user' in identity:\n        args += [identity['user']+'@'+identity['host']]\n    else:\n        args += [identity['host']]\n\n    return args", "response": "Create SSH command for connecting specified server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_agent_parser(device_type):\n    epilog = ('See https://github.com/romanz/trezor-agent/blob/master/'\n              'doc/README-SSH.md for usage examples.')\n    p = configargparse.ArgParser(default_config_files=['~/.ssh/agent.config'],\n                                 epilog=epilog)\n    p.add_argument('-v', '--verbose', default=0, action='count')\n\n    agent_package = device_type.package_name()\n    resources_map = {r.key: r for r in pkg_resources.require(agent_package)}\n    resources = [resources_map[agent_package], resources_map['libagent']]\n    versions = '\\n'.join('{}={}'.format(r.key, r.version) for r in resources)\n    p.add_argument('--version', help='print the version info',\n                   action='version', version=versions)\n\n    curve_names = [name for name in formats.SUPPORTED_CURVES]\n    curve_names = ', '.join(sorted(curve_names))\n    p.add_argument('-e', '--ecdsa-curve-name', metavar='CURVE',\n                   default=formats.CURVE_NIST256,\n                   help='specify ECDSA curve name: ' + curve_names)\n    p.add_argument('--timeout',\n                   default=UNIX_SOCKET_TIMEOUT, type=float,\n                   help='timeout for accepting SSH client connections')\n    p.add_argument('--debug', default=False, action='store_true',\n                   help='log SSH protocol messages for debugging.')\n    p.add_argument('--log-file', type=str,\n                   help='Path to the log file (to be written by the agent).')\n    p.add_argument('--sock-path', type=str,\n                   help='Path to the UNIX domain socket of the agent.')\n\n    p.add_argument('--pin-entry-binary', type=str, default='pinentry',\n                   help='Path to PIN entry UI helper.')\n    p.add_argument('--passphrase-entry-binary', type=str, default='pinentry',\n                   help='Path to passphrase entry UI helper.')\n    p.add_argument('--cache-expiry-seconds', type=float, default=float('inf'),\n                   help='Expire passphrase from cache after this duration.')\n\n    g = p.add_mutually_exclusive_group()\n    g.add_argument('-d', '--daemonize', default=False, action='store_true',\n                   help='Daemonize the agent and print its UNIX socket path')\n    g.add_argument('-f', '--foreground', default=False, action='store_true',\n                   help='Run agent in foreground with specified UNIX socket path')\n    g.add_argument('-s', '--shell', default=False, action='store_true',\n                   help=('run ${SHELL} as subprocess under SSH agent, allowing '\n                         'regular SSH-based tools to be used in the shell'))\n    g.add_argument('-c', '--connect', default=False, action='store_true',\n                   help='connect to specified host via SSH')\n    g.add_argument('--mosh', default=False, action='store_true',\n                   help='connect to specified host via using Mosh')\n\n    p.add_argument('identity', type=_to_unicode, default=None,\n                   help='proto://[user@]host[:port][/path]')\n    p.add_argument('command', type=str, nargs='*', metavar='ARGUMENT',\n                   help='command to run under the SSH agent')\n    return p", "response": "Create an ArgumentParser for this tool."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serve(handler, sock_path, timeout=UNIX_SOCKET_TIMEOUT):\n    ssh_version = subprocess.check_output(['ssh', '-V'],\n                                          stderr=subprocess.STDOUT)\n    log.debug('local SSH version: %r', ssh_version)\n    environ = {'SSH_AUTH_SOCK': sock_path, 'SSH_AGENT_PID': str(os.getpid())}\n    device_mutex = threading.Lock()\n    with server.unix_domain_socket_server(sock_path) as sock:\n        sock.settimeout(timeout)\n        quit_event = threading.Event()\n        handle_conn = functools.partial(server.handle_connection,\n                                        handler=handler,\n                                        mutex=device_mutex)\n        kwargs = dict(sock=sock,\n                      handle_conn=handle_conn,\n                      quit_event=quit_event)\n        with server.spawn(server.server_thread, kwargs):\n            try:\n                yield environ\n            finally:\n                log.debug('closing server')\n                quit_event.set()", "response": "Start the SSH - agent server on a UNIX - domain socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfailing with non - zero exit code.", "response": "def handle_connection_error(func):\n    \"\"\"Fail with non-zero exit code.\"\"\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except device.interface.NotFoundError as e:\n            log.error('Connection error (try unplugging and replugging your device): %s', e)\n            return 1\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_config(contents):\n    for identity_str, curve_name in re.findall(r'\\<(.*?)\\|(.*?)\\>', contents):\n        yield device.interface.Identity(identity_str=identity_str,\n                                        curve_name=curve_name)", "response": "Parse a config file into a list of Identity objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads SSH public keys from a file s contents.", "response": "def import_public_keys(contents):\n    \"\"\"Load (previously exported) SSH public keys from a file's contents.\"\"\"\n    for line in io.StringIO(contents):\n        # Verify this line represents valid SSH public key\n        formats.import_public_key(line)\n        yield line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(device_type):\n    args = create_agent_parser(device_type=device_type).parse_args()\n    util.setup_logging(verbosity=args.verbose, filename=args.log_file)\n\n    public_keys = None\n    filename = None\n    if args.identity.startswith('/'):\n        filename = args.identity\n        contents = open(filename, 'rb').read().decode('utf-8')\n        # Allow loading previously exported SSH public keys\n        if filename.endswith('.pub'):\n            public_keys = list(import_public_keys(contents))\n        identities = list(parse_config(contents))\n    else:\n        identities = [device.interface.Identity(\n            identity_str=args.identity, curve_name=args.ecdsa_curve_name)]\n    for index, identity in enumerate(identities):\n        identity.identity_dict['proto'] = u'ssh'\n        log.info('identity #%d: %s', index, identity.to_string())\n\n    # override default PIN/passphrase entry tools (relevant for TREZOR/Keepkey):\n    device_type.ui = device.ui.UI(device_type=device_type, config=vars(args))\n    device_type.ui.cached_passphrase_ack = util.ExpiringCache(\n        args.cache_expiry_seconds)\n\n    conn = JustInTimeConnection(\n        conn_factory=lambda: client.Client(device_type()),\n        identities=identities, public_keys=public_keys)\n\n    sock_path = _get_sock_path(args)\n    command = args.command\n    context = _dummy_context()\n    if args.connect:\n        command = ['ssh'] + ssh_args(conn) + args.command\n    elif args.mosh:\n        command = ['mosh'] + mosh_args(conn) + args.command\n    elif args.daemonize:\n        out = 'SSH_AUTH_SOCK={0}; export SSH_AUTH_SOCK;\\n'.format(sock_path)\n        sys.stdout.write(out)\n        sys.stdout.flush()\n        context = daemon.DaemonContext()\n        log.info('running the agent as a daemon on %s', sock_path)\n    elif args.foreground:\n        log.info('running the agent on %s', sock_path)\n\n    use_shell = bool(args.shell)\n    if use_shell:\n        command = os.environ['SHELL']\n        sys.stdin.close()\n\n    if command or args.daemonize or args.foreground:\n        with context:\n            return run_server(conn=conn, command=command, sock_path=sock_path,\n                              debug=args.debug, timeout=args.timeout)\n    else:\n        for pk in conn.public_keys():\n            sys.stdout.write(pk)\n        return 0", "response": "Run ssh - agent using given hardware client factory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef public_keys(self):\n        if not self.public_keys_cache:\n            conn = self.conn_factory()\n            self.public_keys_cache = conn.export_public_keys(self.identities)\n        return self.public_keys_cache", "response": "Return a list of SSH public keys in textual format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing SSH public keys into dictionaries.", "response": "def parse_public_keys(self):\n        \"\"\"Parse SSH public keys into dictionaries.\"\"\"\n        public_keys = [formats.import_public_key(pk)\n                       for pk in self.public_keys()]\n        for pk, identity in zip(public_keys, self.identities):\n            pk['identity'] = identity\n        return public_keys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef public_keys_as_files(self):\n        if not self.public_keys_tempfiles:\n            for pk in self.public_keys():\n                f = tempfile.NamedTemporaryFile(prefix='trezor-ssh-pubkey-', mode='w')\n                f.write(pk)\n                f.flush()\n                self.public_keys_tempfiles.append(f)\n\n        return self.public_keys_tempfiles", "response": "Store public keys as temporary SSH identity files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsigning a given blob using the specified identity on the device.", "response": "def sign(self, blob, identity):\n        \"\"\"Sign a given blob using the specified identity on the device.\"\"\"\n        conn = self.conn_factory()\n        return conn.sign_ssh_challenge(blob=blob, identity=identity)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef packet(tag, blob):\n    assert len(blob) < 2**32\n\n    if len(blob) < 2**8:\n        length_type = 0\n    elif len(blob) < 2**16:\n        length_type = 1\n    else:\n        length_type = 2\n\n    fmt = ['>B', '>H', '>L'][length_type]\n    leading_byte = 0x80 | (tag << 2) | (length_type)\n    return struct.pack('>B', leading_byte) + util.prefix_len(fmt, blob)", "response": "Create small GPG packet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprefixing subpacket length according to RFC 4880 section - 5. 2. 3. 1.", "response": "def subpacket_prefix_len(item):\n    \"\"\"Prefix subpacket length according to RFC 4880 section-5.2.3.1.\"\"\"\n    n = len(item)\n    if n >= 8384:\n        prefix = b'\\xFF' + struct.pack('>L', n)\n    elif n >= 192:\n        n = n - 192\n        prefix = struct.pack('BB', (n // 256) + 192, n % 256)\n    else:\n        prefix = struct.pack('B', n)\n    return prefix + item"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subpackets(*items):\n    prefixed = [subpacket_prefix_len(item) for item in items]\n    return util.prefix_len('>H', b''.join(prefixed))", "response": "Serialize several GPG subpackets."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize multipresicion integer using GPG format.", "response": "def mpi(value):\n    \"\"\"Serialize multipresicion integer using GPG format.\"\"\"\n    bits = value.bit_length()\n    data_size = (bits + 7) // 8\n    data_bytes = bytearray(data_size)\n    for i in range(data_size):\n        data_bytes[i] = value & 0xFF\n        value = value >> 8\n\n    data_bytes.reverse()\n    return struct.pack('>H', bits) + bytes(data_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keygrip_nist256(vk):\n    curve = vk.curve.curve\n    gen = vk.curve.generator\n    g = (4 << 512) | (gen.x() << 256) | gen.y()\n    point = vk.pubkey.point\n    q = (4 << 512) | (point.x() << 256) | point.y()\n\n    return _compute_keygrip([\n        ['p', util.num2bytes(curve.p(), size=32)],\n        ['a', util.num2bytes(curve.a() % curve.p(), size=32)],\n        ['b', util.num2bytes(curve.b() % curve.p(), size=32)],\n        ['g', util.num2bytes(g, size=65)],\n        ['n', util.num2bytes(vk.curve.order, size=32)],\n        ['q', util.num2bytes(q, size=65)],\n    ])", "response": "Compute keygrip for NIST256 curve public keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing keygrip for Ed25519 public keys.", "response": "def keygrip_ed25519(vk):\n    \"\"\"Compute keygrip for Ed25519 public keys.\"\"\"\n    # pylint: disable=line-too-long\n    return _compute_keygrip([\n        ['p', util.num2bytes(0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED, size=32)],  # nopep8\n        ['a', b'\\x01'],\n        ['b', util.num2bytes(0x2DFC9311D490018C7338BF8688861767FF8FF5B2BEBE27548A14B235ECA6874A, size=32)],  # nopep8\n        ['g', util.num2bytes(0x04216936D3CD6E53FEC0A4E231FDD6DC5C692CC7609525A7B2C9562D608F25D51A6666666666666666666666666666666666666666666666666666666666666658, size=65)],  # nopep8\n        ['n', util.num2bytes(0x1000000000000000000000000000000014DEF9DEA2F79CD65812631A5CF5D3ED, size=32)],  # nopep8\n        ['q', vk.to_bytes()],\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes keygrip for Curve25519 public keys.", "response": "def keygrip_curve25519(vk):\n    \"\"\"Compute keygrip for Curve25519 public keys.\"\"\"\n    # pylint: disable=line-too-long\n    return _compute_keygrip([\n        ['p', util.num2bytes(0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED, size=32)],  # nopep8\n        ['a', b'\\x01\\xDB\\x41'],\n        ['b', b'\\x01'],\n        ['g', util.num2bytes(0x04000000000000000000000000000000000000000000000000000000000000000920ae19a1b8a086b4e01edd2c7748d14c923d4d7e6d7c61b229e9c5a27eced3d9, size=65)],  # nopep8\n        ['n', util.num2bytes(0x1000000000000000000000000000000014DEF9DEA2F79CD65812631A5CF5D3ED, size=32)],  # nopep8\n        ['q', vk.to_bytes()],\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the curve name matching the specified OID.", "response": "def get_curve_name_by_oid(oid):\n    \"\"\"Return curve name matching specified OID, or raise KeyError.\"\"\"\n    for curve_name, info in SUPPORTED_CURVES.items():\n        if info['oid'] == oid:\n            return curve_name\n    raise KeyError('Unknown OID: {!r}'.format(oid))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef armor(blob, type_str):\n    head = '-----BEGIN PGP {}-----\\nVersion: GnuPG v2\\n\\n'.format(type_str)\n    body = base64.b64encode(blob).decode('ascii')\n    checksum = base64.b64encode(util.crc24(blob)).decode('ascii')\n    tail = '-----END PGP {}-----\\n'.format(type_str)\n    return head + _split_lines(body, 64) + '=' + checksum + '\\n' + tail", "response": "Armor a blob into a single base64 encoded GnuPG v2 file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new GPG signature.", "response": "def make_signature(signer_func, data_to_sign, public_algo,\n                   hashed_subpackets, unhashed_subpackets, sig_type=0):\n    \"\"\"Create new GPG signature.\"\"\"\n    # pylint: disable=too-many-arguments\n    header = struct.pack('>BBBB',\n                         4,         # version\n                         sig_type,  # rfc4880 (section-5.2.1)\n                         public_algo,\n                         8)         # hash_alg (SHA256)\n    hashed = subpackets(*hashed_subpackets)\n    unhashed = subpackets(*unhashed_subpackets)\n    tail = b'\\x04\\xff' + struct.pack('>L', len(header) + len(hashed))\n    data_to_hash = data_to_sign + header + hashed + tail\n\n    log.debug('hashing %d bytes', len(data_to_hash))\n    digest = hashlib.sha256(data_to_hash).digest()\n    log.debug('signing digest: %s', util.hexlify(digest))\n    params = signer_func(digest=digest)\n    sig = b''.join(mpi(p) for p in params)\n\n    return bytes(header + hashed + unhashed +\n                 digest[:2] +  # used for decoder's sanity check\n                 sig)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new primary GPG public key ready for GPG2 -- import.", "response": "def create_primary(user_id, pubkey, signer_func, secret_bytes=b''):\n    \"\"\"Export new primary GPG public key, ready for \"gpg2 --import\".\"\"\"\n    pubkey_packet = protocol.packet(tag=(5 if secret_bytes else 6),\n                                    blob=(pubkey.data() + secret_bytes))\n    user_id_bytes = user_id.encode('utf-8')\n    user_id_packet = protocol.packet(tag=13, blob=user_id_bytes)\n    data_to_sign = (pubkey.data_to_hash() + user_id_packet[:1] +\n                    util.prefix_len('>L', user_id_bytes))\n    hashed_subpackets = [\n        protocol.subpacket_time(pubkey.created),  # signature time\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.7\n        protocol.subpacket_byte(0x0B, 9),  # preferred symmetric algo (AES-256)\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.4\n        protocol.subpacket_byte(0x1B, 1 | 2),  # key flags (certify & sign)\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.21\n        protocol.subpacket_bytes(0x15, [8, 9, 10]),  # preferred hash\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.8\n        protocol.subpacket_bytes(0x16, [2, 3, 1]),  # preferred compression\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.9\n        protocol.subpacket_byte(0x17, 0x80),  # key server prefs (no-modify)\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.17\n        protocol.subpacket_byte(0x1E, 0x01),  # advanced features (MDC)\n        # https://tools.ietf.org/html/rfc4880#section-5.2.3.24\n    ]\n    unhashed_subpackets = [\n        protocol.subpacket(16, pubkey.key_id()),  # issuer key id\n        protocol.CUSTOM_SUBPACKET]\n\n    signature = protocol.make_signature(\n        signer_func=signer_func,\n        public_algo=pubkey.algo_id,\n        data_to_sign=data_to_sign,\n        sig_type=0x13,  # user id & public key\n        hashed_subpackets=hashed_subpackets,\n        unhashed_subpackets=unhashed_subpackets)\n\n    sign_packet = protocol.packet(tag=2, blob=signature)\n    return pubkey_packet + user_id_packet + sign_packet"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_subkey(primary_bytes, subkey, signer_func, secret_bytes=b''):\n    subkey_packet = protocol.packet(tag=(7 if secret_bytes else 14),\n                                    blob=(subkey.data() + secret_bytes))\n    packets = list(decode.parse_packets(io.BytesIO(primary_bytes)))\n    primary, user_id, signature = packets[:3]\n\n    data_to_sign = primary['_to_hash'] + subkey.data_to_hash()\n\n    if subkey.ecdh:\n        embedded_sig = None\n    else:\n        # Primary Key Binding Signature\n        hashed_subpackets = [\n            protocol.subpacket_time(subkey.created)]  # signature time\n        unhashed_subpackets = [\n            protocol.subpacket(16, subkey.key_id())]  # issuer key id\n        embedded_sig = protocol.make_signature(\n            signer_func=signer_func,\n            data_to_sign=data_to_sign,\n            public_algo=subkey.algo_id,\n            sig_type=0x19,\n            hashed_subpackets=hashed_subpackets,\n            unhashed_subpackets=unhashed_subpackets)\n\n    # Subkey Binding Signature\n\n    # Key flags: https://tools.ietf.org/html/rfc4880#section-5.2.3.21\n    # (certify & sign)                   (encrypt)\n    flags = (2) if (not subkey.ecdh) else (4 | 8)\n\n    hashed_subpackets = [\n        protocol.subpacket_time(subkey.created),  # signature time\n        protocol.subpacket_byte(0x1B, flags)]\n\n    unhashed_subpackets = []\n    unhashed_subpackets.append(protocol.subpacket(16, primary['key_id']))\n    if embedded_sig is not None:\n        unhashed_subpackets.append(protocol.subpacket(32, embedded_sig))\n    unhashed_subpackets.append(protocol.CUSTOM_SUBPACKET)\n\n    if not decode.has_custom_subpacket(signature):\n        signer_func = keyring.create_agent_signer(user_id['value'])\n\n    signature = protocol.make_signature(\n        signer_func=signer_func,\n        data_to_sign=data_to_sign,\n        public_algo=primary['algo'],\n        sig_type=0x18,\n        hashed_subpackets=hashed_subpackets,\n        unhashed_subpackets=unhashed_subpackets)\n    sign_packet = protocol.packet(tag=2, blob=signature)\n    return primary_bytes + subkey_packet + sign_packet", "response": "Create a new subkey to GPG primary key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export_public_key(device_type, args):\n    log.warning('NOTE: in order to re-generate the exact same GPG key later, '\n                'run this command with \"--time=%d\" commandline flag (to set '\n                'the timestamp of the GPG key manually).', args.time)\n    c = client.Client(device=device_type())\n    identity = client.create_identity(user_id=args.user_id,\n                                      curve_name=args.ecdsa_curve)\n    verifying_key = c.pubkey(identity=identity, ecdh=False)\n    decryption_key = c.pubkey(identity=identity, ecdh=True)\n    signer_func = functools.partial(c.sign, identity=identity)\n\n    if args.subkey:  # add as subkey\n        log.info('adding %s GPG subkey for \"%s\" to existing key',\n                 args.ecdsa_curve, args.user_id)\n        # subkey for signing\n        signing_key = protocol.PublicKey(\n            curve_name=args.ecdsa_curve, created=args.time,\n            verifying_key=verifying_key, ecdh=False)\n        # subkey for encryption\n        encryption_key = protocol.PublicKey(\n            curve_name=formats.get_ecdh_curve_name(args.ecdsa_curve),\n            created=args.time, verifying_key=decryption_key, ecdh=True)\n        primary_bytes = keyring.export_public_key(args.user_id)\n        result = encode.create_subkey(primary_bytes=primary_bytes,\n                                      subkey=signing_key,\n                                      signer_func=signer_func)\n        result = encode.create_subkey(primary_bytes=result,\n                                      subkey=encryption_key,\n                                      signer_func=signer_func)\n    else:  # add as primary\n        log.info('creating new %s GPG primary key for \"%s\"',\n                 args.ecdsa_curve, args.user_id)\n        # primary key for signing\n        primary = protocol.PublicKey(\n            curve_name=args.ecdsa_curve, created=args.time,\n            verifying_key=verifying_key, ecdh=False)\n        # subkey for encryption\n        subkey = protocol.PublicKey(\n            curve_name=formats.get_ecdh_curve_name(args.ecdsa_curve),\n            created=args.time, verifying_key=decryption_key, ecdh=True)\n\n        result = encode.create_primary(user_id=args.user_id,\n                                       pubkey=primary,\n                                       signer_func=signer_func)\n        result = encode.create_subkey(primary_bytes=result,\n                                      subkey=subkey,\n                                      signer_func=signer_func)\n\n    return protocol.armor(result, 'PUBLIC KEY BLOCK')", "response": "Generate a new public key for a new or existing GPG identity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_gpg_version():\n    existing_gpg = keyring.gpg_version().decode('ascii')\n    required_gpg = '>=2.1.11'\n    msg = 'Existing GnuPG has version \"{}\" ({} required)'.format(existing_gpg,\n                                                                 required_gpg)\n    if not semver.match(existing_gpg, required_gpg):\n        log.error(msg)", "response": "Make sure that the installed GnuPG is not too old."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns command and returns the output as string.", "response": "def check_output(args):\n    \"\"\"Runs command and returns the output as string.\"\"\"\n    log.debug('run: %s', args)\n    out = subprocess.check_output(args=args).decode('utf-8')\n    log.debug('out: %r', out)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_call(args, stdin=None, env=None):\n    log.debug('run: %s%s', args, ' {}'.format(env) if env else '')\n    subprocess.check_call(args=args, stdin=stdin, env=env)", "response": "Runs command and verifies its success."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_file(path, data):\n    with open(path, 'w') as f:\n        log.debug('setting %s contents:\\n%s', path, data)\n        f.write(data)\n    return f", "response": "Writes data to specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_init(device_type, args):\n    util.setup_logging(verbosity=args.verbose)\n    log.warning('This GPG tool is still in EXPERIMENTAL mode, '\n                'so please note that the API and features may '\n                'change without backwards compatibility!')\n\n    verify_gpg_version()\n\n    # Prepare new GPG home directory for hardware-based identity\n    device_name = os.path.basename(sys.argv[0]).rsplit('-', 1)[0]\n    log.info('device name: %s', device_name)\n    homedir = args.homedir\n    if not homedir:\n        homedir = os.path.expanduser('~/.gnupg/{}'.format(device_name))\n\n    log.info('GPG home directory: %s', homedir)\n\n    if os.path.exists(homedir):\n        log.error('GPG home directory %s exists, '\n                  'remove it manually if required', homedir)\n        sys.exit(1)\n\n    check_call(['mkdir', '-p', homedir])\n    check_call(['chmod', '700', homedir])\n\n    agent_path = util.which('{}-gpg-agent'.format(device_name))\n\n    # Prepare GPG agent invocation script (to pass the PATH from environment).\n    with open(os.path.join(homedir, 'run-agent.sh'), 'w') as f:\n        f.write(r\"\"\"#!/bin/sh\nexport PATH={0}\n{1} \\\n-vv \\\n--pin-entry-binary={pin_entry_binary} \\\n--passphrase-entry-binary={passphrase_entry_binary} \\\n--cache-expiry-seconds={cache_expiry_seconds} \\\n$*\n\"\"\".format(os.environ['PATH'], agent_path, **vars(args)))\n    check_call(['chmod', '700', f.name])\n    run_agent_script = f.name\n\n    # Prepare GPG configuration file\n    with open(os.path.join(homedir, 'gpg.conf'), 'w') as f:\n        f.write(\"\"\"# Hardware-based GPG configuration\nagent-program {0}\npersonal-digest-preferences SHA512\ndefault-key \\\"{1}\\\"\n\"\"\".format(run_agent_script, args.user_id))\n\n    # Prepare a helper script for setting up the new identity\n    with open(os.path.join(homedir, 'env'), 'w') as f:\n        f.write(\"\"\"#!/bin/bash\nset -eu\nexport GNUPGHOME={0}\nCOMMAND=$*\nif [ -z \"${{COMMAND}}\" ]\nthen\n    ${{SHELL}}\nelse\n    ${{COMMAND}}\nfi\n\"\"\".format(homedir))\n    check_call(['chmod', '700', f.name])\n\n    # Generate new GPG identity and import into GPG keyring\n    pubkey = write_file(os.path.join(homedir, 'pubkey.asc'),\n                        export_public_key(device_type, args))\n    verbosity = ('-' + ('v' * args.verbose)) if args.verbose else '--quiet'\n    check_call(keyring.gpg_command(['--homedir', homedir, verbosity,\n                                    '--import', pubkey.name]))\n\n    # Make new GPG identity with \"ultimate\" trust (via its fingerprint)\n    out = check_output(keyring.gpg_command(['--homedir', homedir,\n                                            '--list-public-keys',\n                                            '--with-fingerprint',\n                                            '--with-colons']))\n    fpr = re.findall('fpr:::::::::([0-9A-F]+):', out)[0]\n    f = write_file(os.path.join(homedir, 'ownertrust.txt'), fpr + ':6\\n')\n    check_call(keyring.gpg_command(['--homedir', homedir,\n                                    '--import-ownertrust', f.name]))\n\n    # Load agent and make sure it responds with the new identity\n    check_call(keyring.gpg_command(['--homedir', homedir,\n                                    '--list-secret-keys', args.user_id]))", "response": "Initialize hardware - based GnuPG identity."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_unlock(device_type, args):\n    util.setup_logging(verbosity=args.verbose)\n    with device_type() as d:\n        log.info('unlocked %s device', d)", "response": "Unlock hardware device (for future interaction)."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a simple GPG - agent server.", "response": "def run_agent(device_type):\n    \"\"\"Run a simple GPG-agent server.\"\"\"\n    p = argparse.ArgumentParser()\n    p.add_argument('--homedir', default=os.environ.get('GNUPGHOME'))\n    p.add_argument('-v', '--verbose', default=0, action='count')\n    p.add_argument('--server', default=False, action='store_true',\n                   help='Use stdin/stdout for communication with GPG.')\n\n    p.add_argument('--pin-entry-binary', type=str, default='pinentry',\n                   help='Path to PIN entry UI helper.')\n    p.add_argument('--passphrase-entry-binary', type=str, default='pinentry',\n                   help='Path to passphrase entry UI helper.')\n    p.add_argument('--cache-expiry-seconds', type=float, default=float('inf'),\n                   help='Expire passphrase from cache after this duration.')\n\n    args, _ = p.parse_known_args()\n\n    assert args.homedir\n\n    log_file = os.path.join(args.homedir, 'gpg-agent.log')\n    util.setup_logging(verbosity=args.verbose, filename=log_file)\n\n    log.debug('sys.argv: %s', sys.argv)\n    log.debug('os.environ: %s', os.environ)\n    log.debug('pid: %d, parent pid: %d', os.getpid(), os.getppid())\n    try:\n        env = {'GNUPGHOME': args.homedir, 'PATH': os.environ['PATH']}\n        pubkey_bytes = keyring.export_public_keys(env=env)\n        device_type.ui = device.ui.UI(device_type=device_type,\n                                      config=vars(args))\n        device_type.ui.cached_passphrase_ack = util.ExpiringCache(\n            seconds=float(args.cache_expiry_seconds))\n        handler = agent.Handler(device=device_type(),\n                                pubkey_bytes=pubkey_bytes)\n\n        sock_server = _server_from_assuan_fd(os.environ)\n        if sock_server is None:\n            sock_server = _server_from_sock_path(env)\n\n        with sock_server as sock:\n            for conn in agent.yield_connections(sock):\n                with contextlib.closing(conn):\n                    try:\n                        handler.handle(conn)\n                    except agent.AgentStop:\n                        log.info('stopping gpg-agent')\n                        return\n                    except IOError as e:\n                        log.info('connection closed: %s', e)\n                        return\n                    except Exception as e:  # pylint: disable=broad-except\n                        log.exception('handler failed: %s', e)\n\n    except Exception as e:  # pylint: disable=broad-except\n        log.exception('gpg-agent failed: %s', e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(device_type):\n    epilog = ('See https://github.com/romanz/trezor-agent/blob/master/'\n              'doc/README-GPG.md for usage examples.')\n    parser = argparse.ArgumentParser(epilog=epilog)\n\n    agent_package = device_type.package_name()\n    resources_map = {r.key: r for r in pkg_resources.require(agent_package)}\n    resources = [resources_map[agent_package], resources_map['libagent']]\n    versions = '\\n'.join('{}={}'.format(r.key, r.version) for r in resources)\n    parser.add_argument('--version', help='print the version info',\n                        action='version', version=versions)\n\n    subparsers = parser.add_subparsers(title='Action', dest='action')\n    subparsers.required = True\n\n    p = subparsers.add_parser('init',\n                              help='initialize hardware-based GnuPG identity')\n    p.add_argument('user_id')\n    p.add_argument('-e', '--ecdsa-curve', default='nist256p1')\n    p.add_argument('-t', '--time', type=int, default=int(time.time()))\n    p.add_argument('-v', '--verbose', default=0, action='count')\n    p.add_argument('-s', '--subkey', default=False, action='store_true')\n\n    p.add_argument('--homedir', type=str, default=os.environ.get('GNUPGHOME'),\n                   help='Customize GnuPG home directory for the new identity.')\n\n    p.add_argument('--pin-entry-binary', type=str, default='pinentry',\n                   help='Path to PIN entry UI helper.')\n    p.add_argument('--passphrase-entry-binary', type=str, default='pinentry',\n                   help='Path to passphrase entry UI helper.')\n    p.add_argument('--cache-expiry-seconds', type=float, default=float('inf'),\n                   help='Expire passphrase from cache after this duration.')\n\n    p.set_defaults(func=run_init)\n\n    p = subparsers.add_parser('unlock', help='unlock the hardware device')\n    p.add_argument('-v', '--verbose', default=0, action='count')\n    p.set_defaults(func=run_unlock)\n\n    args = parser.parse_args()\n    device_type.ui = device.ui.UI(device_type=device_type, config=vars(args))\n    device_type.ui.cached_passphrase_ack = util.ExpiringCache(\n        seconds=float(args.cache_expiry_seconds))\n\n    return args.func(device_type=device_type, args=args)", "response": "Parse command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_device():\n    try:\n        return get_transport(os.environ.get(\"TREZOR_PATH\"))\n    except Exception as e:  # pylint: disable=broad-except\n        log.debug(\"Failed to find a Trezor device: %s\", e)", "response": "Selects a transport based on TREZOR_PATH environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert Ledger reply into PublicKey object.", "response": "def _convert_public_key(ecdsa_curve_name, result):\n    \"\"\"Convert Ledger reply into PublicKey object.\"\"\"\n    if ecdsa_curve_name == 'nist256p1':\n        if (result[64] & 1) != 0:\n            result = bytearray([0x03]) + result[1:33]\n        else:\n            result = bytearray([0x02]) + result[1:33]\n    else:\n        result = result[1:]\n        keyX = bytearray(result[0:32])\n        keyY = bytearray(result[32:][::-1])\n        if (keyX[31] & 1) != 0:\n            keyY[31] |= 0x80\n        result = b'\\x00' + bytes(keyY)\n    return bytes(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self):\n        try:\n            return comm.getDongle()\n        except comm.CommException as e:\n            raise interface.NotFoundError(\n                '{} not connected: \"{}\"'.format(self, e))", "response": "Enumerate and connect to the first USB HID interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget PublicKey object for specified BIP32 address and elliptic curve.", "response": "def pubkey(self, identity, ecdh=False):\n        \"\"\"Get PublicKey object for specified BIP32 address and elliptic curve.\"\"\"\n        curve_name = identity.get_curve_name(ecdh)\n        path = _expand_path(identity.get_bip32_address(ecdh))\n        if curve_name == 'nist256p1':\n            p2 = '01'\n        else:\n            p2 = '02'\n        apdu = '800200' + p2\n        apdu = binascii.unhexlify(apdu)\n        apdu += bytearray([len(path) + 1, len(path) // 4])\n        apdu += path\n        log.debug('apdu: %r', apdu)\n        result = bytearray(self.conn.exchange(bytes(apdu)))\n        log.debug('result: %r', result)\n        return _convert_public_key(curve_name, result[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign(self, identity, blob):\n        path = _expand_path(identity.get_bip32_address(ecdh=False))\n        if identity.identity_dict['proto'] == 'ssh':\n            ins = '04'\n            p1 = '00'\n        else:\n            ins = '08'\n            p1 = '00'\n        if identity.curve_name == 'nist256p1':\n            p2 = '81' if identity.identity_dict['proto'] == 'ssh' else '01'\n        else:\n            p2 = '82' if identity.identity_dict['proto'] == 'ssh' else '02'\n        apdu = '80' + ins + p1 + p2\n        apdu = binascii.unhexlify(apdu)\n        apdu += bytearray([len(blob) + len(path) + 1])\n        apdu += bytearray([len(path) // 4]) + path\n        apdu += blob\n        log.debug('apdu: %r', apdu)\n        result = bytearray(self.conn.exchange(bytes(apdu)))\n        log.debug('result: %r', result)\n        if identity.curve_name == 'nist256p1':\n            offset = 3\n            length = result[offset]\n            r = result[offset+1:offset+1+length]\n            if r[0] == 0:\n                r = r[1:]\n            offset = offset + 1 + length + 1\n            length = result[offset]\n            s = result[offset+1:offset+1+length]\n            if s[0] == 0:\n                s = s[1:]\n            offset = offset + 1 + length\n            return bytes(r) + bytes(s)\n        else:\n            return bytes(result[:64])", "response": "Sign given blob and return the signature as bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a setuptools version number from a specified location and return its filename.", "response": "def download_setuptools(version=DEFAULT_VERSION, download_base=DEFAULT_URL,\n                        to_dir=os.curdir, delay=15):\n    \"\"\"Download distribute from a specified location and return its filename\n\n    `version` should be a valid distribute version number that is available\n    as an egg for download under the `download_base` URL (which should end\n    with a '/'). `to_dir` is the directory where the egg will be downloaded.\n    `delay` is the number of seconds to pause before an actual download\n    attempt.\n    \"\"\"\n    # making sure we use the absolute path\n    to_dir = os.path.abspath(to_dir)\n    try:\n        from urllib.request import urlopen\n    except ImportError:\n        from urllib2 import urlopen\n    tgz_name = \"distribute-%s.tar.gz\" % version\n    url = download_base + tgz_name\n    saveto = os.path.join(to_dir, tgz_name)\n    src = dst = None\n    if not os.path.exists(saveto):  # Avoid repeated downloads\n        try:\n            log.warn(\"Downloading %s\", url)\n            src = urlopen(url)\n            # Read/write all in one block, so we don't create a corrupt file\n            # if the download is interrupted.\n            data = src.read()\n            dst = open(saveto, \"wb\")\n            dst.write(data)\n        finally:\n            if src:\n                src.close()\n            if dst:\n                dst.close()\n    return os.path.realpath(saveto)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a single SQ filter from querystring parameters that correspond to the SearchIndex fields that have been registered in the view. fields.", "response": "def build_query(self, **filters):\n        \"\"\"\n        Creates a single SQ filter from querystring parameters that correspond to the SearchIndex fields\n        that have been \"registered\" in `view.fields`.\n\n        Default behavior is to `OR` terms for the same parameters, and `AND` between parameters. Any\n        querystring parameters that are not registered in `view.fields` will be ignored.\n\n        :param dict[str, list[str]] filters: is an expanded QueryDict or a mapping of keys to a list of\n        parameters.\n        \"\"\"\n\n        applicable_filters = []\n        applicable_exclusions = []\n\n        for param, value in filters.items():\n            excluding_term = False\n            param_parts = param.split(\"__\")\n            base_param = param_parts[0]  # only test against field without lookup\n            negation_keyword = constants.DRF_HAYSTACK_NEGATION_KEYWORD\n            if len(param_parts) > 1 and param_parts[1] == negation_keyword:\n                excluding_term = True\n                param = param.replace(\"__%s\" % negation_keyword, \"\")  # haystack wouldn't understand our negation\n\n            if self.view.serializer_class:\n                if hasattr(self.view.serializer_class.Meta, 'field_aliases'):\n                    old_base = base_param\n                    base_param = self.view.serializer_class.Meta.field_aliases.get(base_param, base_param)\n                    param = param.replace(old_base, base_param)  # need to replace the alias\n\n                fields = getattr(self.view.serializer_class.Meta, 'fields', [])\n                exclude = getattr(self.view.serializer_class.Meta, 'exclude', [])\n                search_fields = getattr(self.view.serializer_class.Meta, 'search_fields', [])\n\n                # Skip if the parameter is not listed in the serializer's `fields`\n                # or if it's in the `exclude` list.\n                if ((fields or search_fields) and base_param not in\n                        chain(fields, search_fields)) or base_param in exclude or not value:\n                    continue\n\n            field_queries = []\n            if len(param_parts) > 1 and param_parts[-1] in ('in', 'range'):\n                # `in` and `range` filters expects a list of values\n                field_queries.append(self.view.query_object((param, list(self.tokenize(value, self.view.lookup_sep)))))\n            else:\n                for token in self.tokenize(value, self.view.lookup_sep):\n                    field_queries.append(self.view.query_object((param, token)))\n\n            field_queries = [fq for fq in field_queries if fq]\n            if len(field_queries) > 0:\n                term = six.moves.reduce(operator.or_, field_queries)\n                if excluding_term:\n                    applicable_exclusions.append(term)\n                else:\n                    applicable_filters.append(term)\n\n        applicable_filters = six.moves.reduce(\n            self.default_operator, filter(lambda x: x, applicable_filters)) if applicable_filters else []\n\n        applicable_exclusions = six.moves.reduce(\n            self.default_operator, filter(lambda x: x, applicable_exclusions)) if applicable_exclusions else []\n\n        return applicable_filters, applicable_exclusions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a dict of dictionaries suitable for passing to the SearchQuerySet facet date_facet or query_facet method.", "response": "def build_query(self, **filters):\n        \"\"\"\n        Creates a dict of dictionaries suitable for passing to the  SearchQuerySet `facet`,\n        `date_facet` or `query_facet` method. All key word arguments should be wrapped in a list.\n\n        :param view: API View\n        :param dict[str, list[str]] filters: is an expanded QueryDict or a mapping\n        of keys to a list of parameters.\n        \"\"\"\n        field_facets = {}\n        date_facets = {}\n        query_facets = {}\n        facet_serializer_cls = self.view.get_facet_serializer_class()\n\n        if self.view.lookup_sep == \":\":\n            raise AttributeError(\"The %(cls)s.lookup_sep attribute conflicts with the HaystackFacetFilter \"\n                                 \"query parameter parser. Please choose another `lookup_sep` attribute \"\n                                 \"for %(cls)s.\" % {\"cls\": self.view.__class__.__name__})\n\n        fields = facet_serializer_cls.Meta.fields\n        exclude = facet_serializer_cls.Meta.exclude\n        field_options = facet_serializer_cls.Meta.field_options\n\n        for field, options in filters.items():\n\n            if field not in fields or field in exclude:\n                continue\n\n            field_options = merge_dict(field_options, {field: self.parse_field_options(self.view.lookup_sep, *options)})\n\n        valid_gap = (\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\")\n        for field, options in field_options.items():\n            if any([k in options for k in (\"start_date\", \"end_date\", \"gap_by\", \"gap_amount\")]):\n\n                if not all((\"start_date\", \"end_date\", \"gap_by\" in options)):\n                    raise ValueError(\"Date faceting requires at least 'start_date', 'end_date' \"\n                                     \"and 'gap_by' to be set.\")\n\n                if not options[\"gap_by\"] in valid_gap:\n                    raise ValueError(\"The 'gap_by' parameter must be one of %s.\" % \", \".join(valid_gap))\n\n                options.setdefault(\"gap_amount\", 1)\n                date_facets[field] = field_options[field]\n\n            else:\n                field_facets[field] = field_options[field]\n\n        return {\n            \"date_facets\": date_facets,\n            \"field_facets\": field_facets,\n            \"query_facets\": query_facets\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_field_options(self, *options):\n        defaults = {}\n        for option in options:\n            if isinstance(option, six.text_type):\n                tokens = [token.strip() for token in option.split(self.view.lookup_sep)]\n\n                for token in tokens:\n                    if not len(token.split(\":\")) == 2:\n                        warnings.warn(\"The %s token is not properly formatted. Tokens need to be \"\n                                      \"formatted as 'token:value' pairs.\" % token)\n                        continue\n\n                    param, value = token.split(\":\", 1)\n\n                    if any([k == param for k in (\"start_date\", \"end_date\", \"gap_amount\")]):\n\n                        if param in (\"start_date\", \"end_date\"):\n                            value = parser.parse(value)\n\n                        if param == \"gap_amount\":\n                            value = int(value)\n\n                    defaults[param] = value\n\n        return defaults", "response": "Parse the field options query string and return it as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_query(self, **filters):\n\n        applicable_filters = None\n\n        filters = dict((k, filters[k]) for k in chain(self.D.UNITS.keys(),\n                                                      [constants.DRF_HAYSTACK_SPATIAL_QUERY_PARAM]) if k in filters)\n        distance = dict((k, v) for k, v in filters.items() if k in self.D.UNITS.keys())\n\n        try:\n            latitude, longitude = map(float, self.tokenize(filters[constants.DRF_HAYSTACK_SPATIAL_QUERY_PARAM],\n                                                           self.view.lookup_sep))\n            point = self.Point(longitude, latitude, srid=constants.GEO_SRID)\n        except ValueError:\n            raise ValueError(\"Cannot convert `from=latitude,longitude` query parameter to \"\n                             \"float values. Make sure to provide numerical values only!\")\n        except KeyError:\n            # If the user has not provided any `from` query string parameter,\n            # just return.\n            pass\n        else:\n            for unit in distance.keys():\n                if not len(distance[unit]) == 1:\n                    raise ValueError(\"Each unit must have exactly one value.\")\n                distance[unit] = float(distance[unit][0])\n\n            if point and distance:\n                applicable_filters = {\n                    \"dwithin\": {\n                        \"field\": self.backend.point_field,\n                        \"point\": point,\n                        \"distance\": self.D(**distance)\n                    },\n                    \"distance\": {\n                        \"field\": self.backend.point_field,\n                        \"point\": point\n                    }\n                }\n\n        return applicable_filters", "response": "Builds a query string for geo spatial filtering."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_dict(a, b):\n\n    if not isinstance(b, dict):\n        return b\n\n    result = deepcopy(a)\n    for key, val in six.iteritems(b):\n        if key in result and isinstance(result[key], dict):\n            result[key] = merge_dict(result[key], val)\n        elif key in result and isinstance(result[key], list):\n            result[key] = sorted(list(set(val) | set(result[key])))\n        else:\n            result[key] = deepcopy(val)\n\n    return result", "response": "Recursively merges dict a with dict b."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_queryset(self, index_models=[]):\n        if self.queryset is not None and isinstance(self.queryset, self.object_class):\n            queryset = self.queryset.all()\n        else:\n            queryset = self.object_class()._clone()\n            if len(index_models):\n                queryset = queryset.models(*index_models)\n            elif len(self.index_models):\n                queryset = queryset.models(*self.index_models)\n        return queryset", "response": "Returns the list of items for this view."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches a single document from the data store according to the given query parameters.", "response": "def get_object(self):\n        \"\"\"\n        Fetch a single document from the data store according to whatever\n        unique identifier is available for that document in the\n        SearchIndex.\n\n        In cases where the view has multiple ``index_models``, add a ``model`` query\n        parameter containing a single `app_label.model` name to the request in order\n        to override which model to include in the SearchQuerySet.\n\n        Example:\n            /api/v1/search/42/?model=myapp.person\n        \"\"\"\n        queryset = self.get_queryset()\n        if \"model\" in self.request.query_params:\n            try:\n                app_label, model = map(six.text_type.lower, self.request.query_params[\"model\"].split(\".\", 1))\n                ctype = ContentType.objects.get(app_label=app_label, model=model)\n                queryset = self.get_queryset(index_models=[ctype.model_class()])\n            except (ValueError, ContentType.DoesNotExist):\n                raise Http404(\"Could not find any models matching '%s'. Make sure to use a valid \"\n                              \"'app_label.model' name for the 'model' query parameter.\" % self.request.query_params[\"model\"])\n\n        lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field\n        if lookup_url_kwarg not in self.kwargs:\n            raise AttributeError(\n                \"Expected view %s to be called with a URL keyword argument \"\n                \"named '%s'. Fix your URL conf, or set the `.lookup_field` \"\n                \"attribute on the view correctly.\" % (self.__class__.__name__, lookup_url_kwarg)\n            )\n        queryset = queryset.filter(self.query_object((self.document_uid_field, self.kwargs[lookup_url_kwarg])))\n        count = queryset.count()\n        if count == 1:\n            return queryset[0]\n        elif count > 1:\n            raise Http404(\"Multiple results matches the given query. Expected a single result.\")\n\n        raise Http404(\"No result matches the given query.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of more - like - this objects.", "response": "def more_like_this(self, request, pk=None):\n        \"\"\"\n        Sets up a detail route for ``more-like-this`` results.\n        Note that you'll need backend support in order to take advantage of this.\n\n        This will add ie. ^search/{pk}/more-like-this/$ to your existing ^search pattern.\n        \"\"\"\n        obj = self.get_object().object\n        queryset = self.filter_queryset(self.get_queryset()).more_like_this(obj)\n\n        page = self.paginate_queryset(queryset)\n        if page is not None:\n            serializer = self.get_serializer(page, many=True)\n            return self.get_paginated_response(serializer.data)\n\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef facets(self, request):\n        queryset = self.filter_facet_queryset(self.get_queryset())\n\n        for facet in request.query_params.getlist(self.facet_query_params_text):\n\n            if \":\" not in facet:\n                continue\n\n            field, value = facet.split(\":\", 1)\n            if value:\n                queryset = queryset.narrow('%s:\"%s\"' % (field, queryset.query.clean(value)))\n\n        serializer = self.get_facet_serializer(queryset.facet_counts(), objects=queryset, many=False)\n        return Response(serializer.data)", "response": "Returns a list of facets for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a search queryset filter it with whichever facet filter backends in use.", "response": "def filter_facet_queryset(self, queryset):\n        \"\"\"\n        Given a search queryset, filter it with whichever facet filter backends\n        in use.\n        \"\"\"\n        for backend in list(self.facet_filter_backends):\n            queryset = backend().filter_queryset(self.request, queryset, self)\n\n        if self.load_all:\n            queryset = queryset.load_all()\n\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the facet serializer instance that should be used for serializing faceted output.", "response": "def get_facet_serializer(self, *args, **kwargs):\n        \"\"\"\n        Return the facet serializer instance that should be used for\n        serializing faceted output.\n        \"\"\"\n        assert \"objects\" in kwargs, \"`objects` is a required argument to `get_facet_serializer()`\"\n\n        facet_serializer_class = self.get_facet_serializer_class()\n        kwargs[\"context\"] = self.get_serializer_context()\n        kwargs[\"context\"].update({\n            \"objects\": kwargs.pop(\"objects\"),\n            \"facet_query_params_text\": self.facet_query_params_text,\n        })\n        return facet_serializer_class(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the class to use for serializing facets.", "response": "def get_facet_serializer_class(self):\n        \"\"\"\n        Return the class to use for serializing facets.\n        Defaults to using ``self.facet_serializer_class``.\n        \"\"\"\n        if self.facet_serializer_class is None:\n            raise AttributeError(\n                \"%(cls)s should either include a `facet_serializer_class` attribute, \"\n                \"or override %(cls)s.get_facet_serializer_class() method.\" %\n                {\"cls\": self.__class__.__name__}\n            )\n        return self.facet_serializer_class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_facet_objects_serializer(self, *args, **kwargs):\n        facet_objects_serializer_class = self.get_facet_objects_serializer_class()\n        kwargs[\"context\"] = self.get_serializer_context()\n        return facet_objects_serializer_class(*args, **kwargs)", "response": "Returns the serializer instance which should be used for faceted objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbinds the fields to the serializer instance.", "response": "def bind(self, field_name, parent):\n        \"\"\"\n        Initializes the field name and parent for the field instance.\n        Called when a field is added to the parent serializer instance.\n        Taken from DRF and modified to support drf_haystack multiple index\n        functionality.\n        \"\"\"\n\n        # In order to enforce a consistent style, we error if a redundant\n        # 'source' argument has been used. For example:\n        # my_field = serializer.CharField(source='my_field')\n        assert self.source != field_name, (\n            \"It is redundant to specify `source='%s'` on field '%s' in \"\n            \"serializer '%s', because it is the same as the field name. \"\n            \"Remove the `source` keyword argument.\" %\n            (field_name, self.__class__.__name__, parent.__class__.__name__)\n        )\n\n        self.field_name = field_name\n        self.parent = parent\n\n        # `self.label` should default to being based on the field name.\n        if self.label is None:\n            self.label = field_name.replace('_', ' ').capitalize()\n\n        # self.source should default to being the same as the field name.\n        if self.source is None:\n            self.source = self.convert_field_name(field_name)\n\n        # self.source_attrs is a list of attributes that need to be looked up\n        # when serializing the instance, or populating the validated data.\n        if self.source == '*':\n            self.source_attrs = []\n        else:\n            self.source_attrs = self.source.split('.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_default_field_kwargs(model, field):\n        kwargs = {}\n        try:\n            field_name = field.model_attr or field.index_fieldname\n            model_field = model._meta.get_field(field_name)\n            kwargs.update(get_field_kwargs(field_name, model_field))\n\n            # Remove stuff we don't care about!\n            delete_attrs = [\n                \"allow_blank\",\n                \"choices\",\n                \"model_field\",\n                \"allow_unicode\",\n            ]\n            for attr in delete_attrs:\n                if attr in kwargs:\n                    del kwargs[attr]\n        except FieldDoesNotExist:\n            pass\n\n        return kwargs", "response": "Get the kwargs that are passed to the REST Framework serializer field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_index_class_name(self, index_cls):\n        cls_name = index_cls.__name__\n        aliases = self.Meta.index_aliases\n        return aliases.get(cls_name, cls_name.split('.')[-1])", "response": "Converts an index model class to a name suitable for use as a field name prefix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the required fields for serializing the result.", "response": "def get_fields(self):\n        \"\"\"\n        Get the required fields for serializing the result.\n        \"\"\"\n\n        fields = self.Meta.fields\n        exclude = self.Meta.exclude\n        ignore_fields = self.Meta.ignore_fields\n        indices = self.Meta.index_classes\n\n        declared_fields = copy.deepcopy(self._declared_fields)\n        prefix_field_names = len(indices) > 1\n        field_mapping = OrderedDict()\n\n        # overlapping fields on multiple indices is supported by internally prefixing the field\n        # names with the index class to which they belong or, optionally, a user-provided alias\n        # for the index.\n        for index_cls in self.Meta.index_classes:\n            prefix = \"\"\n            if prefix_field_names:\n                prefix = \"_%s__\" % self._get_index_class_name(index_cls)\n            for field_name, field_type in six.iteritems(index_cls.fields):\n                orig_name = field_name\n                field_name = \"%s%s\" % (prefix, field_name)\n\n                # Don't use this field if it is in `ignore_fields`\n                if orig_name in ignore_fields or field_name in ignore_fields:\n                    continue\n                # When fields to include are decided by `exclude`\n                if exclude:\n                    if orig_name in exclude or field_name in exclude:\n                        continue\n                # When fields to include are decided by `fields`\n                if fields:\n                    if orig_name not in fields and field_name not in fields:\n                        continue\n\n                # Look up the field attributes on the current index model,\n                # in order to correctly instantiate the serializer field.\n                model = index_cls().get_model()\n                kwargs = self._get_default_field_kwargs(model, field_type)\n                kwargs['prefix_field_names'] = prefix_field_names\n                field_mapping[field_name] = self._field_mapping[field_type](**kwargs)\n\n        # Add any explicitly declared fields. They *will* override any index fields\n        # in case of naming collision!.\n        if declared_fields:\n            for field_name in declared_fields:\n                field_mapping[field_name] = declared_fields[field_name]\n        return field_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_representation(self, instance):\n        if self.Meta.serializers:\n            ret = self.multi_serializer_representation(instance)\n        else:\n            ret = super(HaystackSerializer, self).to_representation(instance)\n            prefix_field_names = len(getattr(self.Meta, \"index_classes\")) > 1\n            current_index = self._get_index_class_name(type(instance.searchindex))\n            for field in self.fields.keys():\n                # handle declared field value methods on serializer\n                value_method = getattr(self, \"get_{}\".format(field), None)\n                if value_method and callable(value_method):\n                    ret[field] = value_method()\n\n                # now convert namespaced field names\n                orig_field = field\n                if prefix_field_names:\n                    parts = field.split(\"__\")\n                    if len(parts) > 1:\n                        index = parts[0][1:]  # trim the preceding '_'\n                        field = parts[1]\n                        if index == current_index:\n                            ret[field] = ret[orig_field]\n                        del ret[orig_field]\n                elif field not in chain(instance.searchindex.fields.keys(), self._declared_fields.keys()):\n                    del ret[orig_field]\n\n        # include the highlighted field in either case\n        if getattr(instance, \"highlighted\", None):\n            ret[\"highlighted\"] = instance.highlighted[0]\n        return ret", "response": "Convert the given instance into a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the paginate_by_param attribute for the root view paginator class.", "response": "def get_paginate_by_param(self):\n        \"\"\"\n        Returns the ``paginate_by_param`` for the (root) view paginator class.\n        This is needed in order to remove the query parameter from faceted\n        narrow urls.\n\n        If using a custom pagination class, this class attribute needs to\n        be set manually.\n        \"\"\"\n        if hasattr(self.root, \"paginate_by_param\") and self.root.paginate_by_param:\n            return self.root.paginate_by_param\n\n        pagination_class = self.context[\"view\"].pagination_class\n        if not pagination_class:\n            return None\n\n        # PageNumberPagination\n        if hasattr(pagination_class, \"page_query_param\"):\n            return pagination_class.page_query_param\n\n        # LimitOffsetPagination\n        elif hasattr(pagination_class, \"offset_query_param\"):\n            return pagination_class.offset_query_param\n\n        # CursorPagination\n        elif hasattr(pagination_class, \"cursor_query_param\"):\n            return pagination_class.cursor_query_param\n\n        else:\n            raise AttributeError(\n                \"%(root_cls)s is missing a `paginate_by_param` attribute. \"\n                \"Define a %(root_cls)s.paginate_by_param or override \"\n                \"%(cls)s.get_paginate_by_param().\" % {\n                    \"root_cls\": self.root.__class__.__name__,\n                    \"cls\": self.__class__.__name__\n                })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_text(self, instance):\n        instance = instance[0]\n        if isinstance(instance, (six.text_type, six.string_types)):\n            return serializers.CharField(read_only=True).to_representation(instance)\n        elif isinstance(instance, datetime):\n            return serializers.DateTimeField(read_only=True).to_representation(instance)\n        return instance", "response": "Returns the text field of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_count(self, instance):\n        instance = instance[1]\n        return serializers.IntegerField(read_only=True).to_representation(instance)", "response": "Returns the count of the given object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_narrow_url(self, instance):\n        text = instance[0]\n        request = self.context[\"request\"]\n        query_params = request.GET.copy()\n\n        # Never keep the page query parameter in narrowing urls.\n        # It will raise a NotFound exception when trying to paginate a narrowed queryset.\n        page_query_param = self.get_paginate_by_param()\n        if page_query_param and page_query_param in query_params:\n            del query_params[page_query_param]\n\n        selected_facets = set(query_params.pop(self.root.facet_query_params_text, []))\n        selected_facets.add(\"%(field)s_exact:%(text)s\" % {\"field\": self.parent_field, \"text\": text})\n        query_params.setlist(self.root.facet_query_params_text, sorted(selected_facets))\n\n        path = \"%(path)s?%(query)s\" % {\"path\": request.path_info, \"query\": query_params.urlencode()}\n        url = request.build_absolute_uri(path)\n        return serializers.Hyperlink(url, \"narrow-url\")", "response": "Return a link suitable for narrowing on the current item."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noverrides to_representation to set the parent_field property to the current field on the serializer class and then call the parent serializer s to_representation method.", "response": "def to_representation(self, field, instance):\n        \"\"\"\n        Set the ``parent_field`` property equal to the current field on the serializer class,\n        so that each field can query it to see what kind of attribute they are processing.\n        \"\"\"\n        self.parent_field = field\n        return super(FacetFieldSerializer, self).to_representation(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_objects(self, instance):\n        view = self.context[\"view\"]\n        queryset = self.context[\"objects\"]\n\n        page = view.paginate_queryset(queryset)\n        if page is not None:\n            serializer = view.get_facet_objects_serializer(page, many=True)\n            return OrderedDict([\n                (\"count\", self.get_count(queryset)),\n                (\"next\", view.paginator.get_next_link()),\n                (\"previous\", view.paginator.get_previous_link()),\n                (\"results\", serializer.data)\n            ])\n\n        serializer = view.get_serializer(queryset, many=True)\n        return serializer.data", "response": "Return a list of objects matching the faceted result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning which field the search index has marked as it s document = True field.", "response": "def get_document_field(instance):\n        \"\"\"\n        Returns which field the search index has marked as it's\n        `document=True` field.\n        \"\"\"\n        for name, field in instance.searchindex.fields.items():\n            if field.document is True:\n                return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_filters(self, queryset, applicable_filters=None, applicable_exclusions=None):\n        if applicable_filters:\n            queryset = queryset.filter(applicable_filters)\n        if applicable_exclusions:\n            queryset = queryset.exclude(applicable_exclusions)\n        return queryset", "response": "Applies constructed filters and excludes and returns the queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the query filters for the current view.", "response": "def build_filters(self, view, filters=None):\n        \"\"\"\n        Get the query builder instance and return constructed query filters.\n        \"\"\"\n        query_builder = self.get_query_builder(backend=self, view=view)\n        return query_builder.build_query(**(filters if filters else {}))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the filtered queryset.", "response": "def filter_queryset(self, request, queryset, view):\n        \"\"\"\n        Return the filtered queryset.\n        \"\"\"\n        applicable_filters, applicable_exclusions = self.build_filters(view, filters=self.get_request_filters(request))\n        return self.apply_filters(\n            queryset=queryset,\n            applicable_filters=self.process_filters(applicable_filters, queryset, view),\n            applicable_exclusions=self.process_filters(applicable_exclusions, queryset, view)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the query builder class instance that should be used to build the query", "response": "def get_query_builder(self, *args, **kwargs):\n        \"\"\"\n        Return the query builder class instance that should be used to\n        build the query which is passed to the search engine backend.\n        \"\"\"\n        query_builder = self.get_query_builder_class()\n        return query_builder(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying faceting to the queryset", "response": "def apply_filters(self, queryset, applicable_filters=None, applicable_exclusions=None):\n        \"\"\"\n        Apply faceting to the queryset\n        \"\"\"\n        for field, options in applicable_filters[\"field_facets\"].items():\n            queryset = queryset.facet(field, **options)\n\n        for field, options in applicable_filters[\"date_facets\"].items():\n            queryset = queryset.date_facet(field, **options)\n\n        for field, options in applicable_filters[\"query_facets\"].items():\n            queryset = queryset.query_facet(field, **options)\n\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests for outliers in a 2 - sided set of data sets.", "response": "def outliers_grubbs(x, hypo = False, alpha = 0.05):\n\n    \"\"\"\n    Grubbs' Test for Outliers [1]_. This is the two-sided version of the test.\n\n    The null hypothesis implies that there are no outliers in the data set.\n\n    Parameters\n    ----------\n    x : array_like or ndarray, 1d\n        An array, any object exposing the array interface, containing\n        data to test for an outlier in.\n\n    hypo : bool, optional\n        Specifies whether to return a bool value of a hypothesis test result.\n        Returns True when we can reject the null hypothesis. Otherwise, False.\n        Available options are:\n        1) True - return a hypothesis test result\n        2) False - return a filtered array without an outlier (default)\n\n    alpha : float, optional\n        Significance level for a hypothesis test. Default is 0.05.\n\n    Returns\n    -------\n    Numpy array if hypo is False or a bool value of a hypothesis test result.\n\n    Notes\n    -----\n    .. [1] http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h1.htm\n\n    Examples\n    --------\n\n    >>> x = np.array([199.31,199.53,200.19,200.82,201.92,201.95,202.18,245.57])\n    >>> ph.outliers_grubbs(x)\n    array([ 199.31,  199.53,  200.19,  200.82,  201.92,  201.95,  202.18])\n    \"\"\"\n\n    val = np.max(np.abs(x - np.mean(x)))\n    ind = np.argmax(np.abs(x - np.mean(x)))\n    G = val / np.std(x, ddof=1)\n    N = len(x)\n    result = G > (N - 1)/np.sqrt(N) * np.sqrt((t.ppf(1-alpha/(2*N), N-2) ** 2) / (N - 2 + t.ppf(1-alpha/(2*N), N-2) ** 2 ))\n\n    if hypo:\n        return result\n    else:\n        if result:\n            return np.delete(x, ind)\n        else:\n            return x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef outliers_tietjen(x, k, hypo = False, alpha = 0.05):\n\n    \"\"\"\n    Tietjen-Moore test [1]_ to detect multiple outliers in a univariate\n    data set that follows an approximately normal distribution.\n    The Tietjen-Moore test [2]_ is a generalization of the Grubbs' test to\n    the case of multiple outliers. If testing for a single outlier,\n    the Tietjen-Moore test is equivalent to the Grubbs' test.\n\n    The null hypothesis implies that there are no outliers in the data set.\n\n    Parameters\n    ----------\n    x : array_like or ndarray, 1d\n        An array, any object exposing the array interface, containing\n        data to test for an outlier in.\n\n    k : int\n        Number of potential outliers to test for. Function tests for\n        outliers in both tails.\n\n    hypo : bool, optional\n        Specifies whether to return a bool value of a hypothesis test result.\n        Returns True when we can reject the null hypothesis. Otherwise, False.\n        Available options are:\n        1) True - return a hypothesis test result\n        2) False - return a filtered array without outliers (default)\n\n    alpha : float, optional\n        Significance level for a hypothesis test. Default is 0.05.\n\n    Returns\n    -------\n    Numpy array if hypo is False or a bool value of a hypothesis test result.\n\n    Notes\n    -----\n    .. [1] Tietjen and Moore (August 1972), Some Grubbs-Type Statistics\n        for the Detection of Outliers, Technometrics, 14(3), pp. 583-597.\n    .. [2] http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h2.htm\n\n    Examples\n    --------\n    >>> x = np.array([-1.40, -0.44, -0.30, -0.24, -0.22, -0.13, -0.05, 0.06,\n    0.10, 0.18, 0.20, 0.39, 0.48, 0.63, 1.01])\n    >>> outliers_tietjen(x, 2)\n    array([-0.44, -0.3 , -0.24, -0.22, -0.13, -0.05,  0.06,  0.1 ,  0.18,\n    0.2 ,  0.39,  0.48,  0.63])\n\n    \"\"\"\n\n    n = x.size\n    def tietjen(x_, k_):\n        x_mean = x_.mean()\n        r = np.abs(x_ - x_mean)\n        z = x_[r.argsort()]\n        E = np.sum((z[:-k_] - z[:-k_].mean()) ** 2) / np.sum((z - x_mean) ** 2)\n        return E\n\n    E_x = tietjen(x, k)\n    E_norm = np.zeros(10000)\n\n    for i in np.arange(10000):\n        norm = np.random.normal(size=n)\n        E_norm[i] = tietjen(norm, k)\n\n    CV = np.percentile(E_norm, alpha * 100)\n    result = E_x < CV\n\n    if hypo:\n        return result\n    else:\n        if result:\n            ind = np.argpartition(np.abs(x - x.mean()), -k)[-k:]\n            return np.delete(x, ind)\n        else:\n            return x", "response": "This function returns a univariate univariate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef outliers_gesd(data, outliers = 5, report = False, alpha=0.05):\n\n    \"\"\"\n    The generalized (Extreme Studentized Deviate) ESD test is used\n    to detect one or more outliers in a univariate data set that follows\n    an approximately normal distribution [1]_.\n\n    Parameters\n    ----------\n    data : array_like or ndarray, 1d\n        An array, any object exposing the array interface, containing\n        data to test for outliers.\n\n    outliers : int, optional\n        Number of potential outliers to test for. Test is two-tailed, i.e.\n        maximum and minimum values are checked for potential outliers.\n\n    report : bool, optional\n        Specifies whether to return a summary table of the test.\n        Available options are:\n        1) True - return a summary table\n        2) False - return the array with outliers removed. (default)\n\n    alpha : float, optional\n        Significance level for a hypothesis test. Default is 0.05.\n\n    Returns\n    -------\n    Numpy array if hypo is False or a bool value of a hypothesis test result.\n\n    Notes\n    -----\n    .. [1] Rosner, Bernard (May 1983), Percentage Points for a Generalized\n        ESD Many-Outlier Procedure,Technometrics, 25(2), pp. 165-172.\n\n    Examples\n    --------\n    >>> data = np.array([-0.25, 0.68, 0.94, 1.15, 1.2, 1.26, 1.26, 1.34, 1.38, 1.43, 1.49, 1.49, 1.55, 1.56, 1.58, 1.65, 1.69, 1.7, 1.76, 1.77, 1.81, 1.91, 1.94, 1.96, 1.99, 2.06, 2.09, 2.1, 2.14, 2.15, 2.23, 2.24, 2.26, 2.35, 2.37, 2.4, 2.47, 2.54, 2.62, 2.64, 2.9, 2.92, 2.92, 2.93, 3.21, 3.26, 3.3, 3.59, 3.68, 4.3, 4.64, 5.34, 5.42, 6.01])\n\n    >>> outliers_gesd(data, 5)\n    array([-0.25,  0.68,  0.94,  1.15,  1.2 ,  1.26,  1.26,  1.34,  1.38,\n            1.43,  1.49,  1.49,  1.55,  1.56,  1.58,  1.65,  1.69,  1.7 ,\n            1.76,  1.77,  1.81,  1.91,  1.94,  1.96,  1.99,  2.06,  2.09,\n            2.1 ,  2.14,  2.15,  2.23,  2.24,  2.26,  2.35,  2.37,  2.4 ,\n            2.47,  2.54,  2.62,  2.64,  2.9 ,  2.92,  2.92,  2.93,  3.21,\n            3.26,  3.3 ,  3.59,  3.68,  4.3 ,  4.64])\n\n    >>> outliers_gesd(data, outliers = 5, report = True)\n    H0: no outliers in the data\n    Ha: up to 5 outliers in the data\n    Significance level:  \u03b1 = 0.05\n    Reject H0 if Ri > Critical Value (\u03bbi)\n\n    Summary Table for Two-Tailed Test\n    ---------------------------------------\n          Exact           Test     Critical\n      Number of      Statistic    Value, \u03bbi\n    Outliers, i      Value, Ri          5 %\n    ---------------------------------------\n              1          3.119        3.159\n              2          2.943        3.151\n              3          3.179        3.144 *\n              4           2.81        3.136\n              5          2.816        3.128\n\n    \"\"\"\n\n    Rs, ls = np.zeros(outliers, dtype = np.float), np.zeros(outliers, dtype = np.float)\n    ms = []\n\n    data = np.sort(np.array(data))\n    data_proc = np.copy(data)\n    n = data_proc.size\n    mean = np.mean(data_proc)\n\n    for i in np.arange(outliers):\n\n        abs_d = np.abs(data_proc - np.mean(data_proc))\n\n        # R-value calculation\n        R = np.max(abs_d) / np.std(data_proc, ddof=1)\n        Rs[i] = R\n\n        # Masked values\n        lms = ms[-1] if len(ms) > 0 else []\n        ms.append(lms + [np.argmax(abs_d)])\n\n        # Lambdas calculation\n        p = 1 - alpha / (2 * (n - i))\n        df = n - i - 2\n        t_ppr = t.ppf(p, df)\n        lambd = ((n - i - 1) * t_ppr) / np.sqrt((n - i - 2 + t_ppr**2) * (n - i))\n        ls[i] = lambd\n\n        # Remove the observation that maximizes |xi \u2212 xmean|\n        data_proc = np.delete(data_proc, np.argmax(abs_d))\n\n    if report:\n\n        report = [\"H0: no outliers in the data\",\n                  \"Ha: up to \" + str(outliers) + \" outliers in the data\",\n                  \"Significance level:  \u03b1 = \" + str(alpha),\n                  \"Reject H0 if Ri > Critical Value (\u03bbi)\", \"\",\n                  \"Summary Table for Two-Tailed Test\",\n                  \"---------------------------------------\",\n                  \"      Exact           Test     Critical\",\n                  \"  Number of      Statistic    Value, \u03bbi\",\n                  \"Outliers, i      Value, Ri          5 %\",\n                  \"---------------------------------------\"]\n\n        for i, (r, l) in enumerate(zip(Rs, ls)):\n            report.append('{: >11s}'.format(str(i+1)) + \\\n                          '{: >15s}'.format(str(np.round(r, 3))) + \\\n                          '{: >13s}'.format(str(np.round(l, 3))) + (\" *\" if r > l else \"\"))\n\n        print(\"\\n\".join(report))\n\n    else:\n        # Remove masked values\n        # for which the test statistic is greater\n        # than the critical value and return the result\n\n        if any(Rs > ls):\n            data = np.delete(data, ms[np.max(np.where(Rs > ls))])\n\n        return data", "response": "Greedy GSD test for the Univariate Univariate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhide helper method to create a DataFrame with input data for further processing.", "response": "def __convert_to_df(a, val_col=None, group_col=None, val_id=None, group_id=None):\n\n    '''Hidden helper method to create a DataFrame with input data for further\n    processing.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas DataFrame.\n        Array must be two-dimensional. Second dimension may vary,\n        i.e. groups may have different lengths.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    val_id : int, optional\n        Index of a column that contains dependent variable values (test or\n        response variable). Should be specified if a NumPy ndarray is used as an\n        input. It will be inferred from data, if not specified.\n\n    group_id : int, optional\n        Index of a column that contains independent variable values (grouping or\n        predictor variable). Should be specified if a NumPy ndarray is used as\n        an input. It will be inferred from data, if not specified.\n\n    Returns\n    -------\n    x : pandas DataFrame\n        DataFrame with input data, `val_col` column contains numerical values and\n        `group_col` column contains categorical values.\n\n    val_col : str\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable).\n\n    group_col : str\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable).\n\n    Notes\n    -----\n    Inferrence algorithm for determining `val_id` and `group_id` args is rather\n    simple, so it is better to specify them explicitly to prevent errors.\n\n    '''\n\n    if not group_col:\n        group_col = 'groups'\n    if not val_col:\n        val_col = 'vals'\n\n    if isinstance(a, DataFrame):\n        x = a.copy()\n        if not {group_col, val_col}.issubset(a.columns):\n            raise ValueError('Specify correct column names using `group_col` and `val_col` args')\n        return x, val_col, group_col\n\n    elif isinstance(a, list) or (isinstance(a, np.ndarray) and not a.shape.count(2)):\n        grps_len = map(len, a)\n        grps = list(it.chain(*[[i+1] * l for i, l in enumerate(grps_len)]))\n        vals = list(it.chain(*a))\n\n        return DataFrame({val_col: vals, group_col: grps}), val_col, group_col\n\n    elif isinstance(a, np.ndarray):\n\n        # cols ids not defined\n        # trying to infer\n        if not(all([val_id, group_id])):\n\n            if np.argmax(a.shape):\n                a = a.T\n\n            ax = [np.unique(a[:, 0]).size, np.unique(a[:, 1]).size]\n\n            if np.asscalar(np.diff(ax)):\n                __val_col = np.argmax(ax)\n                __group_col = np.argmin(ax)\n            else:\n                raise ValueError('Cannot infer input format.\\nPlease specify `val_id` and `group_id` args')\n\n            cols = {__val_col: val_col,\n                    __group_col: group_col}\n        else:\n            cols = {val_id: val_col,\n                    group_id: group_col}\n\n        cols_vals = dict(sorted(cols.items())).values()\n        return DataFrame(a, columns=cols_vals), val_col, group_col"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef posthoc_conover(a, val_col=None, group_col=None, p_adjust=None, sort=True):\n\n    '''Post hoc pairwise test for multiple comparisons of mean rank sums\n    (Conover's test). May be used after Kruskal-Wallis one-way analysis of\n    variance by ranks to do pairwise comparisons [1]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas DataFrame.\n        Array must be two-dimensional. Second dimension may vary,\n        i.e. groups may have different lengths.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    p_adjust : str, optional\n        Method for adjusting p values. See `statsmodels.sandbox.stats.multicomp`\n        for details. Available methods are:\n        'bonferroni' : one-step correction\n        'sidak' : one-step correction\n        'holm-sidak' : step-down method using Sidak adjustments\n        'holm' : step-down method using Bonferroni adjustments\n        'simes-hochberg' : step-up method  (independent)\n        'hommel' : closed method based on Simes tests (non-negative)\n        'fdr_bh' : Benjamini/Hochberg  (non-negative)\n        'fdr_by' : Benjamini/Yekutieli (negative)\n        'fdr_tsbh' : two stage fdr correction (non-negative)\n        'fdr_tsbky' : two stage fdr correction (non-negative)\n\n    sort : bool, optional\n        Specifies whether to sort DataFrame by `group_col` or not. Recommended\n        unless you sort your data manually.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    A tie correction are employed according to Conover [1]_.\n\n    References\n    ----------\n    .. [1] W. J. Conover and R. L. Iman (1979), On multiple-comparisons procedures,\n        Tech. Rep. LA-7677-MS, Los Alamos Scientific Laboratory.\n\n    Examples\n    --------\n\n    >>> x = [[1,2,3,5,1], [12,31,54, np.nan], [10,12,6,74,11]]\n    >>> sp.posthoc_conover(x, p_adjust = 'holm')\n    '''\n\n    def compare_conover(i, j):\n        diff = np.abs(x_ranks_avg.loc[i] - x_ranks_avg.loc[j])\n        B = (1. / x_lens.loc[i] + 1. / x_lens.loc[j])\n        D = (n - 1. - H_cor) / (n - x_len)\n        t_value = diff / np.sqrt(S2 * B * D)\n        p_value = 2. * ss.t.sf(np.abs(t_value), df = n - x_len)\n        return p_value\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col, _val_col], ascending=True, inplace=True)\n    n = len(x.index)\n    x_groups_unique = np.unique(x[_group_col])\n    x_len = x_groups_unique.size\n    x_lens = x.groupby(_group_col)[_val_col].count()\n\n    x['ranks'] = x[_val_col].rank()\n    x_ranks_avg = x.groupby(_group_col)['ranks'].mean()\n    x_ranks_sum = x.groupby(_group_col)['ranks'].sum()\n\n    # ties\n    vals = x.groupby('ranks').count()[_val_col].values\n    tie_sum = np.sum(vals[vals != 1] ** 3 - vals[vals != 1])\n    tie_sum = 0 if not tie_sum else tie_sum\n    x_ties = np.min([1., 1. - tie_sum / (n ** 3. - n)])\n\n    H = (12. / (n * (n + 1.))) * np.sum(x_ranks_sum**2 / x_lens) - 3. * (n + 1.)\n    H_cor = H / x_ties\n\n    if x_ties == 1:\n        S2 = n * (n + 1.) / 12.\n    else:\n        S2 = (1. / (n - 1.)) * (np.sum(x['ranks'] ** 2.) - (n * (((n + 1.)**2.) / 4.)))\n\n    vs = np.zeros((x_len, x_len))\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    combs = it.combinations(range(x_len), 2)\n\n    for i, j in combs:\n        vs[i, j] = compare_conover(x_groups_unique[i], x_groups_unique[j])\n\n    if p_adjust:\n        vs[tri_upper] = multipletests(vs[tri_upper], method = p_adjust)[1]\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n\n    return DataFrame(vs, index=x_groups_unique, columns=x_groups_unique)", "response": "Posthoc pairwise test for multiple comparisons of mean rank sums\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef posthoc_dunn(a, val_col=None, group_col=None, p_adjust=None, sort=True):\n\n    '''Post hoc pairwise test for multiple comparisons of mean rank sums\n    (Dunn's test). May be used after Kruskal-Wallis one-way analysis of\n    variance by ranks to do pairwise comparisons [1]_, [2]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas DataFrame.\n        Array must be two-dimensional. Second dimension may vary,\n        i.e. groups may have different lengths.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    p_adjust : str, optional\n        Method for adjusting p values. See `statsmodels.sandbox.stats.multicomp`\n        for details. Available methods are:\n        'bonferroni' : one-step correction\n        'sidak' : one-step correction\n        'holm-sidak' : step-down method using Sidak adjustments\n        'holm' : step-down method using Bonferroni adjustments\n        'simes-hochberg' : step-up method  (independent)\n        'hommel' : closed method based on Simes tests (non-negative)\n        'fdr_bh' : Benjamini/Hochberg  (non-negative)\n        'fdr_by' : Benjamini/Yekutieli (negative)\n        'fdr_tsbh' : two stage fdr correction (non-negative)\n        'fdr_tsbky' : two stage fdr correction (non-negative)\n\n    sort : bool, optional\n        Specifies whether to sort DataFrame by group_col or not. Recommended\n        unless you sort your data manually.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    A tie correction will be employed according to Glantz (2012).\n\n    References\n    ----------\n    .. [1] O.J. Dunn (1964). Multiple comparisons using rank sums.\n        Technometrics, 6, 241-252.\n    .. [2] S.A. Glantz (2012), Primer of Biostatistics. New York: McGraw Hill.\n\n    Examples\n    --------\n\n    >>> x = [[1,2,3,5,1], [12,31,54, np.nan], [10,12,6,74,11]]\n    >>> sp.posthoc_dunn(x, p_adjust = 'holm')\n    '''\n\n    def compare_dunn(i, j):\n        diff = np.abs(x_ranks_avg.loc[i] - x_ranks_avg.loc[j])\n        A = n * (n + 1.) / 12.\n        B = (1. / x_lens.loc[i] + 1. / x_lens.loc[j])\n        z_value = diff / np.sqrt((A - x_ties) * B)\n        p_value = 2. * ss.norm.sf(np.abs(z_value))\n        return p_value\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col, _val_col], ascending=True, inplace=True)\n    n = len(x.index)\n    x_groups_unique = np.unique(x[_group_col])\n    x_len = x_groups_unique.size\n    x_lens = x.groupby(_group_col)[_val_col].count()\n\n    x['ranks'] = x[_val_col].rank()\n    x_ranks_avg = x.groupby(_group_col)['ranks'].mean()\n\n    # ties\n    vals = x.groupby('ranks').count()[_val_col].values\n    tie_sum = np.sum(vals[vals != 1] ** 3 - vals[vals != 1])\n    tie_sum = 0 if not tie_sum else tie_sum\n    x_ties = tie_sum / (12. * (n - 1))\n\n    vs = np.zeros((x_len, x_len))\n    combs = it.combinations(range(x_len), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    for i,j in combs:\n        vs[i, j] = compare_dunn(x_groups_unique[i], x_groups_unique[j])\n\n    if p_adjust:\n        vs[tri_upper] = multipletests(vs[tri_upper], method = p_adjust)[1]\n\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=x_groups_unique, columns=x_groups_unique)", "response": "Posthoc pairwise test for multiple comparisons of mean rank sums\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef posthoc_nemenyi(a, val_col=None, group_col=None,  dist='chi', sort=True):\n\n    '''Post hoc pairwise test for multiple comparisons of mean rank sums\n    (Nemenyi's test). May be used after Kruskal-Wallis one-way analysis of\n    variance by ranks to do pairwise comparisons [1]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame. Array must be two-dimensional. Second dimension may vary,\n        i.e. groups may have different lengths.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    dist : str, optional\n        Method for determining the p value. The default distribution is \"chi\"\n        (chi-squared), else \"tukey\" (studentized range).\n\n    sort : bool, optional\n        Specifies whether to sort DataFrame by group_col or not. Recommended\n        unless you sort your data manually.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    A tie correction will be employed according to Glantz (2012).\n\n    References\n    ----------\n    .. [1] Lothar Sachs (1997), Angewandte Statistik. Berlin: Springer.\n        Pages: 395-397, 662-664.\n\n    Examples\n    --------\n    >>> x = [[1,2,3,5,1], [12,31,54, np.nan], [10,12,6,74,11]]\n    >>> sp.posthoc_nemenyi(x)\n    '''\n\n    def compare_stats_chi(i, j):\n        diff = np.abs(x_ranks_avg.loc[i] - x_ranks_avg.loc[j])\n        A = n * (n + 1.) / 12.\n        B = (1. / x_lens.loc[i] + 1. / x_lens.loc[j])\n        chi = diff ** 2. / (A * B)\n        return chi\n\n    def compare_stats_tukey(i, j):\n        diff = np.abs(x_ranks_avg.loc[i] - x_ranks_avg.loc[j])\n        B = (1. / x_lens.loc[i] + 1. / x_lens.loc[j])\n        q = diff / np.sqrt((n * (n + 1.) / 12.) * B)\n        return q\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col, _val_col], ascending=True, inplace=True)\n    n = len(x.index)\n    x_groups_unique = np.unique(x[_group_col])\n    x_len = x_groups_unique.size\n    x_lens = x.groupby(_group_col)[_val_col].count()\n\n    x['ranks'] = x[_val_col].rank()\n    x_ranks_avg = x.groupby(_group_col)['ranks'].mean()\n\n    # ties\n    vals = x.groupby('ranks').count()[_val_col].values\n    tie_sum = np.sum(vals[vals != 1] ** 3 - vals[vals != 1])\n    tie_sum = 0 if not tie_sum else tie_sum\n    x_ties = np.min([1., 1. - tie_sum / (n ** 3. - n)])\n\n    vs = np.zeros((x_len, x_len))\n    combs = it.combinations(range(x_len), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    if dist == 'chi':\n        for i,j in combs:\n            vs[i, j] = compare_stats_chi(x_groups_unique[i], x_groups_unique[j]) / x_ties\n\n        vs[tri_upper] = ss.chi2.sf(vs[tri_upper], x_len - 1)\n\n    elif dist == 'tukey':\n        for i,j in combs:\n            vs[i, j] = compare_stats_tukey(x_groups_unique[i], x_groups_unique[j]) * np.sqrt(2.)\n\n        vs[tri_upper] = psturng(vs[tri_upper], x_len, np.inf)\n\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n\n    return DataFrame(vs, index=x_groups_unique, columns=x_groups_unique)", "response": "Posthoc pairwise test for multiple comparisons of mean rank sums\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates pairwise comparisons using Nemenyi post hoc test for unreplicated blocked data.", "response": "def posthoc_nemenyi_friedman(a, y_col=None, block_col=None, group_col=None, melted=False, sort=False):\n\n    '''Calculate pairwise comparisons using Nemenyi post hoc test for\n    unreplicated blocked data. This test is usually conducted post hoc if\n    significant results of the Friedman's test are obtained. The statistics\n    refer to upper quantiles of the studentized range distribution (Tukey) [1]_,\n    [2]_, [3]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n        If `melted` is set to False (default), `a` is a typical matrix of\n        block design, i.e. rows are blocks, and columns are groups. In this\n        case you do not need to specify col arguments.\n\n        If `a` is an array and `melted` is set to True,\n        y_col, block_col and group_col must specify the indices of columns\n        containing elements of correspondary type.\n\n        If `a` is a Pandas DataFrame and `melted` is set to True,\n        y_col, block_col and group_col must specify columns names (strings).\n\n    y_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains y data.\n\n    block_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains blocking factor values.\n\n    group_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains treatment (group) factor values.\n\n    melted : bool, optional\n        Specifies if data are given as melted columns \"y\", \"blocks\", and\n        \"groups\".\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    A one-way ANOVA with repeated measures that is also referred to as ANOVA\n    with unreplicated block design can also be conducted via Friedman's\n    test. The consequent post hoc pairwise multiple comparison test\n    according to Nemenyi is conducted with this function.\n\n    This function does not test for ties.\n\n    References\n    ----------\n    .. [1] J. Demsar (2006), Statistical comparisons of classifiers over\n        multiple data sets, Journal of Machine Learning Research, 7, 1-30.\n\n    .. [2] P. Nemenyi (1963) Distribution-free Multiple Comparisons. Ph.D.\n        thesis, Princeton University.\n\n    .. [3] L. Sachs (1997), Angewandte Statistik. Berlin: Springer.\n        Pages: 668-675.\n\n    Examples\n    --------\n    >>> # Non-melted case, x is a block design matrix, i.e. rows are blocks\n    >>> # and columns are groups.\n    >>> x = np.array([[31,27,24],[31,28,31],[45,29,46],[21,18,48],[42,36,46],[32,17,40]])\n    >>> sp.posthoc_nemenyi_friedman(x)\n\n    '''\n\n    if melted and not all([block_col, group_col, y_col]):\n        raise ValueError('block_col, group_col, y_col should be explicitly specified if using melted data')\n\n    def compare_stats(i, j):\n        dif = np.abs(R[groups[i]] - R[groups[j]])\n        qval = dif / np.sqrt(k * (k + 1.) / (6. * n))\n        return qval\n\n    x, _y_col, _group_col, _block_col = __convert_to_block_df(a, y_col, group_col, block_col, melted)\n\n    #if not sort:\n    #    x[group_col] = Categorical(x[group_col], categories=x[group_col].unique(), ordered=True)\n    #    x[block_col] = Categorical(x[block_col], categories=x[block_col].unique(), ordered=True)\n    x.sort_values(by=[_group_col, _block_col], ascending=True, inplace=True)\n    x.dropna(inplace=True)\n\n    groups = x[_group_col].unique()\n    k = groups.size\n    n = x[_block_col].unique().size\n\n    x['mat'] = x.groupby(_block_col)[_y_col].rank()\n    R = x.groupby(_group_col)['mat'].mean()\n    vs = np.zeros((k, k))\n    combs = it.combinations(range(k), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    for i, j in combs:\n        vs[i, j] = compare_stats(i, j)\n\n    vs *= np.sqrt(2.)\n    vs[tri_upper] = psturng(vs[tri_upper], k, np.inf)\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef posthoc_conover_friedman(a, y_col=None, block_col=None, group_col=None, melted=False, sort=False, p_adjust=None):\n\n    '''Calculate pairwise comparisons using Conover post hoc test for unreplicated\n    blocked data. This test is usually conducted post hoc after\n    significant results of the Friedman test. The statistics refer to\n    the Student t distribution [1]_, [2]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n        If `melted` is set to False (default), `a` is a typical matrix of\n        block design, i.e. rows are blocks, and columns are groups. In this\n        case you do not need to specify col arguments.\n\n        If `a` is an array and `melted` is set to True,\n        y_col, block_col and group_col must specify the indices of columns\n        containing elements of correspondary type.\n\n        If `a` is a Pandas DataFrame and `melted` is set to True,\n        y_col, block_col and group_col must specify columns names (strings).\n\n    y_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains y data.\n\n    block_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains blocking factor values.\n\n    group_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains treatment (group) factor values.\n\n    melted : bool, optional\n        Specifies if data are given as melted columns \"y\", \"blocks\", and\n        \"groups\".\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    p_adjust : str, optional\n        Method for adjusting p values. See statsmodels.sandbox.stats.multicomp\n        for details. Available methods are:\n        'bonferroni' : one-step correction\n        'sidak' : one-step correction\n        'holm-sidak' : step-down method using Sidak adjustments\n        'holm' : step-down method using Bonferroni adjustments\n        'simes-hochberg' : step-up method  (independent)\n        'hommel' : closed method based on Simes tests (non-negative)\n        'fdr_bh' : Benjamini/Hochberg  (non-negative)\n        'fdr_by' : Benjamini/Yekutieli (negative)\n        'fdr_tsbh' : two stage fdr correction (non-negative)\n        'fdr_tsbky' : two stage fdr correction (non-negative)\n        'single-step' : uses Tukey distribution for multiple comparisons\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    A one-way ANOVA with repeated measures that is also referred to as ANOVA\n    with unreplicated block design can also be conducted via the\n    friedman.test. The consequent post hoc pairwise multiple comparison test\n    according to Conover is conducted with this function.\n\n    If y is a matrix, than the columns refer to the treatment and the rows\n    indicate the block.\n\n    References\n    ----------\n    .. [1] W. J. Conover and R. L. Iman (1979), On multiple-comparisons procedures,\n        Tech. Rep. LA-7677-MS, Los Alamos Scientific Laboratory.\n\n    .. [2] W. J. Conover (1999), Practical nonparametric Statistics, 3rd. Edition,\n        Wiley.\n\n    Examples\n    --------\n    >>> x = np.array([[31,27,24],[31,28,31],[45,29,46],[21,18,48],[42,36,46],[32,17,40]])\n    >>> sp.posthoc_conover_friedman(x)\n\n    '''\n\n    if melted and not all([block_col, group_col, y_col]):\n        raise ValueError('block_col, group_col, y_col should be explicitly specified if using melted data')\n\n    def compare_stats(i, j):\n        dif = np.abs(R.loc[groups[i]] - R.loc[groups[j]])\n        tval = dif / np.sqrt(A) / np.sqrt(B)\n        pval = 2. * ss.t.sf(np.abs(tval), df = (m*n*k - k - n + 1))\n        return pval\n\n    def compare_tukey(i, j):\n        dif = np.abs(R.loc[groups[i]] - R.loc[groups[j]])\n        qval = np.sqrt(2.) * dif / (np.sqrt(A) * np.sqrt(B))\n        pval = psturng(qval, k, np.inf)\n        return pval\n\n    x, _y_col, _group_col, _block_col = __convert_to_block_df(a, y_col, group_col, block_col, melted)\n\n    #if not sort:\n    #    x[group_col] = Categorical(x[group_col], categories=x[group_col].unique(), ordered=True)\n    #    x[block_col] = Categorical(x[block_col], categories=x[block_col].unique(), ordered=True)\n    x.sort_values(by=[_group_col,_block_col], ascending=True, inplace=True)\n    x.dropna(inplace=True)\n\n    groups = np.unique(x[_group_col])\n    k = groups.size\n    n = x[_block_col].unique().size\n\n    x['mat'] = x.groupby(_block_col)[_y_col].rank()\n    R = x.groupby(_group_col)['mat'].sum()\n    A1 = (x['mat'] ** 2).sum()\n    m = 1\n    S2 = m/(m*k - 1.) * (A1 - m*k*n*(m*k + 1.)**2./4.)\n    T2 = 1 / S2 * (np.sum(R) - n * m * ((m * k + 1.) / 2.)**2.)\n    A = S2 * (2. * n * (m * k - 1.)) / ( m * n * k - k - n + 1.)\n    B = 1. - T2 / (n * (m * k - 1.))\n\n    vs = np.zeros((k, k))\n    combs = it.combinations(range(k), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    if p_adjust == 'single-step':\n        for i, j in combs:\n            vs[i, j] = compare_tukey(i, j)\n    else:\n        for i, j in combs:\n            vs[i, j] = compare_stats(i, j)\n\n        if p_adjust is not None:\n            vs[tri_upper] = multipletests(vs[tri_upper], method = p_adjust)[1]\n\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)", "response": "Calculate pairwise comparisons using Conover post hoc test for unreplicated unreplicated"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef posthoc_anderson(a, val_col=None, group_col=None, midrank=True, sort=False, p_adjust=None):\n\n    '''Anderson-Darling Pairwise Test for k-samples. Tests the null hypothesis\n    that k-samples are drawn from the same population without having to specify\n    the distribution function of that population [1]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    midrank : bool, optional\n        Type of Anderson-Darling test which is computed. If set to True (default), the\n        midrank test applicable to continuous and discrete populations is performed. If\n        False, the right side empirical distribution is used.\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    p_adjust : str, optional\n        Method for adjusting p values. See statsmodels.sandbox.stats.multicomp for details. Available methods are:\n        'bonferroni' : one-step correction\n        'sidak' : one-step correction\n        'holm-sidak' : step-down method using Sidak adjustments\n        'holm' : step-down method using Bonferroni adjustments\n        'simes-hochberg' : step-up method  (independent)\n        'hommel' : closed method based on Simes tests (non-negative)\n        'fdr_bh' : Benjamini/Hochberg  (non-negative)\n        'fdr_by' : Benjamini/Yekutieli (negative)\n        'fdr_tsbh' : two stage fdr correction (non-negative)\n        'fdr_tsbky' : two stage fdr correction (non-negative)\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    References\n    ----------\n    .. [1] F.W. Scholz, M.A. Stephens (1987), K-Sample Anderson-Darling Tests,\n        Journal of the American Statistical Association, Vol. 82, pp. 918-924.\n\n    Examples\n    --------\n    >>> x = np.array([[2.9, 3.0, 2.5, 2.6, 3.2], [3.8, 2.7, 4.0, 2.4], [2.8, 3.4, 3.7, 2.2, 2.0]])\n    >>> sp.posthoc_anderson(x)\n\n    '''\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n    x.sort_values(by=[_group_col], ascending=True, inplace=True)\n\n    groups = x[_group_col].unique()\n    k = groups.size\n    vs = np.zeros((k, k), dtype=np.float)\n    combs = it.combinations(range(k), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    for i, j in combs:\n        vs[i, j] = ss.anderson_ksamp([x.loc[x[_group_col] == groups[i], _val_col], x.loc[x[_group_col] == groups[j], _val_col]])[2]\n\n    if p_adjust:\n        vs[tri_upper] = multipletests(vs[tri_upper], method = p_adjust)[1]\n\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)", "response": "The Anderson - Darling Pairwise Test for k - samples."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates pairwise comparisons using Quade s posthoc test for the unreplicated blocked data.", "response": "def posthoc_quade(a, y_col=None, block_col=None, group_col=None, dist='t', melted=False, sort=False, p_adjust=None):\n\n    '''Calculate pairwise comparisons using Quade's post hoc test for\n    unreplicated blocked data. This test is usually conducted if significant\n    results were obtained by the omnibus test [1]_, [2]_, [3]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n        If `melted` is set to False (default), `a` is a typical matrix of\n        block design, i.e. rows are blocks, and columns are groups. In this\n        case you do not need to specify col arguments.\n\n        If `a` is an array and `melted` is set to True,\n        y_col, block_col and group_col must specify the indices of columns\n        containing elements of correspondary type.\n\n        If `a` is a Pandas DataFrame and `melted` is set to True,\n        y_col, block_col and group_col must specify columns names (string).\n\n    y_col : str or int, optional\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains y data.\n\n    block_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains blocking factor values.\n\n    group_col : str or int\n        Must be specified if `a` is a pandas DataFrame object.\n        Name of the column that contains treatment (group) factor values.\n\n    dist : str, optional\n        Method for determining p values.\n        The default distribution is \"t\", else \"normal\".\n\n    melted : bool, optional\n        Specifies if data are given as melted columns \"y\", \"blocks\", and\n        \"groups\".\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    p_adjust : str, optional\n        Method for adjusting p values.\n        See statsmodels.sandbox.stats.multicomp for details.\n        Available methods are:\n        'bonferroni' : one-step correction\n        'sidak' : one-step correction\n        'holm-sidak' : step-down method using Sidak adjustments\n        'holm' : step-down method using Bonferroni adjustments\n        'simes-hochberg' : step-up method  (independent)\n        'hommel' : closed method based on Simes tests (non-negative)\n        'fdr_bh' : Benjamini/Hochberg  (non-negative)\n        'fdr_by' : Benjamini/Yekutieli (negative)\n        'fdr_tsbh' : two stage fdr correction (non-negative)\n        'fdr_tsbky' : two stage fdr correction (non-negative)\n\n    Returns\n    -------\n    Pandas DataFrame containing p values.\n\n    References\n    ----------\n    .. [1] W. J. Conover (1999), Practical nonparametric Statistics, 3rd. Edition,\n        Wiley.\n\n    .. [2] N. A. Heckert and J. J. Filliben (2003). NIST Handbook 148: Dataplot\n        Reference Manual, Volume 2: Let Subcommands and Library Functions.\n        National Institute of Standards and Technology Handbook Series, June 2003.\n\n    .. [3] D. Quade (1979), Using weighted rankings in the analysis of complete\n        blocks with additive block effects. Journal of the American Statistical\n        Association, 74, 680-683.\n\n    Examples\n    --------\n    >>> x = np.array([[31,27,24],[31,28,31],[45,29,46],[21,18,48],[42,36,46],[32,17,40]])\n    >>> sp.posthoc_quade(x)\n    '''\n\n    if melted and not all([block_col, group_col, y_col]):\n        raise ValueError('block_col, group_col, y_col should be explicitly specified if using melted data')\n\n    def compare_stats_t(i, j):\n        dif = np.abs(S[groups[i]] - S[groups[j]])\n        tval = dif / denom\n        pval = 2. * ss.t.sf(np.abs(tval), df = (b - 1) * (k - 1))\n        return pval\n\n    def compare_stats_norm(i, j):\n        dif = np.abs(W[groups[i]] * ff - W[groups[j]] * ff)\n        zval = dif / denom\n        pval = 2. * ss.norm.sf(np.abs(zval))\n        return pval\n\n    x, y_col, group_col, block_col = __convert_to_block_df(a, y_col, group_col, block_col, melted)\n\n    if not sort:\n        x[group_col] = Categorical(x[group_col], categories=x[group_col].unique(), ordered=True)\n        x[block_col] = Categorical(x[block_col], categories=x[block_col].unique(), ordered=True)\n    x.sort_values(by=[block_col, group_col], ascending=True, inplace=True)\n    x.dropna(inplace=True)\n\n    groups = x[group_col].unique()\n    k = len(groups)\n    b = x[block_col].unique().size\n\n    x['r'] = x.groupby(block_col)[y_col].rank()\n    q = (x.groupby(block_col)[y_col].max() - x.groupby(block_col)[y_col].min()).rank()\n    x['rr'] = x['r'] - (k + 1)/2\n    x['s'] = x.apply(lambda x, y: x['rr'] * y[x['blocks']], axis=1, args=(q,))\n    x['w'] = x.apply(lambda x, y: x['r'] * y[x['blocks']], axis=1, args=(q,))\n    A = (x['s'] ** 2).sum()\n    S = x.groupby(group_col)['s'].sum()\n    B = np.sum(S ** 2) / b\n    W = x.groupby(group_col)['w'].sum()\n\n    vs = np.zeros((k, k), dtype=np.float)\n    combs = it.combinations(range(k), 2)\n\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    if dist == 't':\n        denom = np.sqrt((2 * b * (A - B)) / ((b - 1) * (k - 1)))\n\n        for i, j in combs:\n            vs[i, j] = compare_stats_t(i, j)\n\n    else:\n        n = b * k\n        denom = np.sqrt((k * (k + 1) * (2 * n + 1) * (k-1)) / (18 * n * (n + 1)))\n        ff = 1. / (b * (b + 1)/2)\n\n        for i, j in combs:\n            vs[i, j] = compare_stats_norm(i, j)\n\n    if p_adjust:\n        vs[tri_upper] = multipletests(vs[tri_upper], method = p_adjust)[1]\n\n    vs[tri_lower] = vs.T[tri_lower]\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef posthoc_tamhane(a, val_col=None, group_col=None, welch=True, sort=False):\n\n    '''Tamhane's T2 all-pairs comparison test for normally distributed data with\n    unequal variances. Tamhane's T2 test can be performed for all-pairs\n    comparisons in an one-factorial layout with normally distributed residuals\n    but unequal groups variances. A total of m = k(k-1)/2 hypotheses can be\n    tested. The null hypothesis is tested in the two-tailed test against the\n    alternative hypothesis [1]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    welch : bool, optional\n        If True, use Welch's approximate solution for calculating the degree of\n        freedom. T2 test uses the usual df = N - 2 approximation.\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    The p values are computed from the t-distribution and adjusted according to\n    Dunn-Sidak.\n\n    References\n    ----------\n    .. [1] A.C. Tamhane (1979), A Comparison of Procedures for Multiple Comparisons of\n        Means with Unequal Variances. Journal of the American Statistical Association,\n        74, 471-480.\n\n    Examples\n    --------\n    >>> import scikit_posthocs as sp\n    >>> import pandas as pd\n    >>> x = pd.DataFrame({\"a\": [1,2,3,5,1], \"b\": [12,31,54,62,12], \"c\": [10,12,6,74,11]})\n    >>> x = x.melt(var_name='groups', value_name='values')\n    >>> sp.posthoc_tamhane(x, val_col='values', group_col='groups')\n\n    '''\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col], ascending=True, inplace=True)\n    groups = x[_group_col].unique()\n\n    x_grouped = x.groupby(_group_col)[_val_col]\n\n    ni = x_grouped.count()\n    n = ni.sum()\n    xi = x_grouped.mean()\n    si = x_grouped.var()\n    sin = 1. / (n - groups.size) * np.sum(si * (ni - 1))\n\n    def compare(i, j):\n        dif = xi[i] - xi[j]\n        A = si[i] / ni[i] + si[j] / ni[j]\n        t_val = dif / np.sqrt(A)\n        if welch:\n            df = A ** 2. / (si[i] ** 2. / (ni[i] ** 2. * (ni[i] - 1.)) + si[j] ** 2. / (ni[j] ** 2. * (ni[j] - 1.)))\n        else:\n            ## checks according to Tamhane (1979, p. 474)\n            ok1 = (9./10. <= ni[i]/ni[j]) and (ni[i]/ni[j] <= 10./9.)\n            ok2 = (9./10. <= (s2i[i] / ni[i]) / (s2i[j] / ni[j])) and ((s2i[i] / ni[i]) / (s2i[j] / ni[j]) <= 10./9.)\n            ok3 = (4./5. <= ni[i]/ni[j]) and (ni[i]/ni[j] <= 5./4.) and (1./2. <= (s2i[i] / ni[i]) / (s2i[j] / ni[j])) and ((s2i[i] / ni[i]) / (s2i[j] / ni[j]) <= 2.)\n            ok4 = (2./3. <= ni[i]/ni[j]) and (ni[i]/ni[j] <= 3./2.) and (3./4. <= (s2i[i] / ni[i]) / (s2i[j] / ni[j])) and ((s2i[i] / ni[i]) / (s2i[j] / ni[j]) <= 4./3.)\n            OK = any(ok1, ok2, ok3, ok4)\n            if not OK:\n                print(\"Sample sizes or standard errors are not balanced. T2 test is recommended.\")\n            df = ni[i] + ni[j] - 2.\n        p_val = 2. * ss.t.sf(np.abs(t_val), df=df)\n        return p_val\n\n    vs = np.zeros((groups.size, groups.size), dtype=np.float)\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    combs = it.combinations(range(groups.size), 2)\n\n    for i,j in combs:\n        vs[i, j] = compare(groups[i], groups[j])\n\n    vs[tri_upper] = 1. - (1. - vs[tri_upper]) ** groups.size\n    vs[tri_lower] = vs.T[tri_lower]\n    vs[vs > 1] = 1\n\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)", "response": "Tamhane s T2 all - pairs comparison test for normally distributed data with unequal variances."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef posthoc_tukey(a, val_col = None, group_col = None, sort = False):\n\n    '''Performs Tukey's all-pairs comparisons test for normally distributed data\n    with equal group variances. For all-pairs comparisons in an\n    one-factorial layout with normally distributed residuals and equal variances\n    Tukey's test can be performed. A total of m = k(k-1)/2 hypotheses can be\n    tested. The null hypothesis is tested in the two-tailed test against\n    the alternative hypothesis [1]_, [2]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    Returns\n    -------\n    result : pandas DataFrame\n        P values.\n\n    Notes\n    -----\n    The p values are computed from the Tukey-distribution.\n\n    References\n    ----------\n    .. [1] L. Sachs (1997) Angewandte Statistik, New York: Springer.\n    .. [2] J. Tukey (1949) Comparing Individual Means in the Analysis of Variance,\n        Biometrics 5, 99-114.\n\n    Examples\n    --------\n    >>> import scikit_posthocs as sp\n    >>> import pandas as pd\n    >>> x = pd.DataFrame({\"a\": [1,2,3,5,1], \"b\": [12,31,54,62,12], \"c\": [10,12,6,74,11]})\n    >>> x = x.melt(var_name='groups', value_name='values')\n    >>> sp.posthoc_tukey(x, val_col='values', group_col='groups')\n\n    '''\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col], ascending=True, inplace=True)\n    groups = np.unique(x[_group_col])\n    x_grouped = x.groupby(_group_col)[_val_col]\n\n    ni = x_grouped.count()\n    n = ni.sum()\n    xi = x_grouped.mean()\n    si = x_grouped.var()\n    sin = 1. / (n - groups.size) * np.sum(si * (ni - 1))\n\n    def compare(i, j):\n        dif = xi[i] - xi[j]\n        A = sin * 0.5 * (1. / ni.loc[i] + 1. / ni.loc[j])\n        q_val = dif / np.sqrt(A)\n        return q_val\n\n    vs = np.zeros((groups.size, groups.size), dtype=np.float)\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    combs = it.combinations(range(groups.size), 2)\n\n    for i,j in combs:\n        vs[i, j] = compare(groups[i], groups[j])\n\n    vs[tri_upper] = psturng(np.abs(vs[tri_upper]), groups.size, n - groups.size)\n    vs[tri_lower] = vs.T[tri_lower]\n\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)", "response": "Tukey s all - pairs comparisons test for normally distributed data and equal group variances."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef posthoc_dscf(a, val_col=None, group_col=None, sort=False):\n\n    '''Dwass, Steel, Critchlow and Fligner all-pairs comparison test for a\n    one-factorial layout with non-normally distributed residuals. As opposed to\n    the all-pairs comparison procedures that depend on Kruskal ranks, the DSCF\n    test is basically an extension of the U-test as re-ranking is conducted for\n    each pairwise test [1]_, [2]_, [3]_.\n\n    Parameters\n    ----------\n    a : array_like or pandas DataFrame object\n        An array, any object exposing the array interface or a pandas\n        DataFrame.\n\n    val_col : str, optional\n        Name of a DataFrame column that contains dependent variable values (test\n        or response variable). Values should have a non-nominal scale. Must be\n        specified if `a` is a pandas DataFrame object.\n\n    group_col : str, optional\n        Name of a DataFrame column that contains independent variable values\n        (grouping or predictor variable). Values should have a nominal scale\n        (categorical). Must be specified if `a` is a pandas DataFrame object.\n\n    sort : bool, optional\n        If True, sort data by block and group columns.\n\n    Returns\n    -------\n    Pandas DataFrame containing p values.\n\n    Notes\n    -----\n    The p values are computed from the Tukey-distribution.\n\n    References\n    ----------\n    .. [1] Douglas, C. E., Fligner, A. M. (1991) On distribution-free multiple\n        comparisons in the one-way analysis of variance, Communications in\n        Statistics - Theory and Methods, 20, 127-139.\n\n    .. [2] Dwass, M. (1960) Some k-sample rank-order tests. In Contributions to\n        Probability and Statistics, Edited by: I. Olkin, Stanford: Stanford\n        University Press.\n\n    .. [3] Steel, R. G. D. (1960) A rank sum test for comparing all pairs of\n        treatments, Technometrics, 2, 197-207.\n\n    Examples\n    --------\n    >>> import scikit_posthocs as sp\n    >>> import pandas as pd\n    >>> x = pd.DataFrame({\"a\": [1,2,3,5,1], \"b\": [12,31,54,62,12], \"c\": [10,12,6,74,11]})\n    >>> x = x.melt(var_name='groups', value_name='values')\n    >>> sp.posthoc_dscf(x, val_col='values', group_col='groups')\n\n    '''\n\n    x, _val_col, _group_col = __convert_to_df(a, val_col, group_col)\n\n    if not sort:\n        x[_group_col] = Categorical(x[_group_col], categories=x[_group_col].unique(), ordered=True)\n\n    x.sort_values(by=[_group_col], ascending=True, inplace=True)\n    groups = np.unique(x[_group_col])\n    x_grouped = x.groupby(_group_col)[_val_col]\n    n = x_grouped.count()\n    k = groups.size\n\n    def get_ties(x):\n        t = x.value_counts().values\n        c = np.sum((t ** 3 - t) / 12.)\n        return c\n\n    def compare(i, j):\n        ni = n.loc[i]\n        nj = n.loc[j]\n        x_raw = x.loc[(x[_group_col] == i) | (x[_group_col] == j)].copy()\n        x_raw['ranks'] = x_raw.loc[:, _val_col].rank()\n        r = x_raw.groupby(_group_col)['ranks'].sum().loc[[i, j]]\n        u = np.array([nj * ni + (nj * (nj + 1) / 2),\n                      nj * ni + (ni * (ni + 1) / 2)]) - r\n        u_min = np.min(u)\n        s = ni + nj\n        var = (nj*ni/(s*(s - 1.))) * ((s**3 - s)/12. - get_ties(x_raw['ranks']))\n        p = np.sqrt(2.) * (u_min - nj * ni / 2.) / np.sqrt(var)\n        return p\n\n    vs = np.zeros((k, k))\n    tri_upper = np.triu_indices(vs.shape[0], 1)\n    tri_lower = np.tril_indices(vs.shape[0], -1)\n    vs[:,:] = 0\n\n    combs = it.combinations(range(k), 2)\n\n    for i, j in combs:\n        vs[i, j] = compare(groups[i], groups[j])\n\n    vs[tri_upper] = psturng(np.abs(vs[tri_upper]), k, np.inf)\n    vs[tri_lower] = vs.T[tri_lower]\n\n    np.fill_diagonal(vs, -1)\n    return DataFrame(vs, index=groups, columns=groups)", "response": "A posthoc DSCF test for all - pairs of a Tukey - distribution with non - normally distributed residuals."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sign_table(p_values, lower=True, upper=True):\n    if not any([lower, upper]):\n        raise ValueError(\"Either lower or upper triangle must be returned\")\n\n    if not isinstance(p_values, DataFrame):\n        p_values = np.array(p_values, dtype=np.float)\n\n    ns = p_values > 0.05\n    three = (p_values < 0.001) & (p_values >= 0)\n    two = (p_values < 0.01) & (p_values >= 0.001)\n    one = (p_values < 0.05) & (p_values >= 0.01)\n\n    p_values = p_values.astype(object)\n    p_values[ns] = 'NS'\n    p_values[three] = '***'\n    p_values[two] = '**'\n    p_values[one] = '*'\n\n    if not isinstance(p_values, DataFrame):\n        np.fill_diagonal(p_values, '-')\n        if not lower:\n            p_values[np.tril_indices(p_values.shape[0], -1)] = ''\n        elif not upper:\n            p_values[np.triu_indices(p_values.shape[0], 1)] = ''\n    else:\n        np.fill_diagonal(p_values.values, '-')\n        if not lower:\n            p_values.values[np.tril_indices(p_values.shape[0], -1)] = ''\n        elif not upper:\n            p_values.values[np.triu_indices(p_values.shape[0], 1)] = ''\n\n    return p_values", "response": "Significance table for a given set of P values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreventing coro from being cancelled during the shutdown sequence. The trick here is that we add this coro to the global \"DO_NOT_CANCEL\" collection, and then later during the shutdown sequence we make sure that the task that wraps this coro will NOT be cancelled. To make this work, we have to create a super-secret task, below, that communicates with the caller (which \"awaits\" us) via a Future. Using a Future in this way allows us to avoid awaiting the Task, which decouples the Task from the normal exception propagation which would normally happen when the outer Task gets cancelled. We get the result of coro back to the caller via Future.set_result. NOTE that during the shutdown sequence, the caller WILL NOT be able to receive a result, since the caller will likely have been cancelled. So you should probably not rely on capturing results via this function.", "response": "def shutdown_waits_for(coro, loop=None):\n    \"\"\"Prevent coro from being cancelled during the shutdown sequence.\n\n    The trick here is that we add this coro to the global\n    \"DO_NOT_CANCEL\" collection, and then later during the shutdown\n    sequence we make sure that the task that wraps this coro will NOT\n    be cancelled.\n\n    To make this work, we have to create a super-secret task, below, that\n    communicates with the caller (which \"awaits\" us) via a Future. Using\n    a Future in this way allows us to avoid awaiting the Task, which\n    decouples the Task from the normal exception propagation which would\n    normally happen when the outer Task gets cancelled.  We get the\n    result of coro back to the caller via Future.set_result.\n\n    NOTE that during the shutdown sequence, the caller WILL NOT be able\n    to receive a result, since the caller will likely have been\n    cancelled.  So you should probably not rely on capturing results\n    via this function.\n    \"\"\"\n    loop = loop or get_event_loop()\n    fut = loop.create_future()  # This future will connect coro and the caller.\n\n    async def coro_proxy():\n        \"\"\"This function will await coro, but it will also send the result\n        over the the future. Remember: the outside caller (of\n        shutdown_waits_for) will be awaiting fut, NOT coro(), due to\n        the decoupling. However, when coro completes, we need to send its\n        result over to the fut to make it look *as if* it was just coro\n        running the whole time. This whole thing is a teeny magic trick.\n        \"\"\"\n        try:\n            result = await coro\n        except (CancelledError, Exception) as e:\n            set_fut_done = partial(fut.set_exception, e)\n        else:\n            set_fut_done = partial(fut.set_result, result)\n\n        if not fut.cancelled():\n            set_fut_done()\n\n    new_coro = coro_proxy()  # We'll taskify this one instead of coro.\n    _DO_NOT_CANCEL_COROS.add(new_coro)  # The new task must not be cancelled.\n    loop.create_task(new_coro)  # Make the task\n\n    # Ok, so we *could* simply return fut.  Callers can await it as normal,\n    # e.g.\n    #\n    # async def blah():\n    #   x = await shutdown_waits_for(bleh())\n    #\n    # That will work fine.  However, callers may *also* want to detach the\n    # call from the current execution context, e.g.\n    #\n    # async def blah():\n    #   loop.create_task(shutdown_waits_for(bleh()))\n    #\n    # This will only work if shutdown_waits_for() returns a coroutine.\n    # Therefore, we just make a new coroutine to wrap the `await fut` and\n    # return that.  Then both things will work.\n    #\n    # (Side note: instead of callers using create_tasks, it would also work\n    # if they used `asyncio.ensure_future()` instead, since that can work\n    # with futures. But I don't like ensure_future.)\n    #\n    # (Another side note: You don't even need `create_task()` or\n    # `ensure_future()`...If you don't want a result, you can just call\n    # `shutdown_waits_for()` as a flat function call, no await or anything,\n    # and it should still work; unfortunately it causes a RuntimeWarning to\n    # tell you that ``inner()`` was never awaited :/\n\n    async def inner():\n        return await fut\n\n    return inner()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting the event loop and waits for a signal to shut down.", "response": "def run(coro: 'Optional[Coroutine]' = None, *,\n        loop: Optional[AbstractEventLoop] = None,\n        shutdown_handler: Optional[Callable[[AbstractEventLoop], None]] = None,\n        executor_workers: int = 10,\n        executor: Optional[Executor] = None,\n        use_uvloop: bool = False) -> None:\n    \"\"\"\n    Start up the event loop, and wait for a signal to shut down.\n\n    :param coro: Optionally supply a coroutine. The loop will still\n        run if missing. The loop will continue to run after the supplied\n        coroutine finishes. The supplied coroutine is typically\n        a \"main\" coroutine from which all other work is spawned.\n    :param loop: Optionally supply your own loop. If missing, the\n        default loop attached to the current thread context will\n        be used, i.e., whatever ``asyncio.get_event_loop()`` returns.\n    :param shutdown_handler: By default, SIGINT and SIGTERM will be\n        handled and will stop the loop, thereby invoking the shutdown\n        sequence. Alternatively you can supply your own shutdown\n        handler function. It should conform to the type spec as shown\n        in the function signature.\n    :param executor_workers: The number of workers in the executor.\n        (NOTE: ``run()`` creates a new executor instance internally,\n        regardless of whether you supply your own loop.)\n    :param executor: You can decide to use your own executor instance\n        if you like.\n    :param use_uvloop: The loop policy will be set to use uvloop. It\n        is your responsibility to install uvloop. If missing, an\n        ``ImportError`` will be raised.\n    \"\"\"\n    logger.debug('Entering run()')\n\n    assert not (loop and use_uvloop), (\n        \"'loop' and 'use_uvloop' parameters are mutually \"\n        \"exclusive. (Just make your own uvloop and pass it in).\"\n    )\n    if use_uvloop:\n        import uvloop\n        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n\n    loop_was_supplied = bool(loop)\n    if not loop_was_supplied:\n        loop = get_event_loop()\n\n    if coro:\n        async def new_coro():\n            \"\"\"During shutdown, run_until_complete() will exit\n            if a CancelledError bubbles up from anything in the\n            group. To counteract that, we'll try to handle\n            any CancelledErrors that bubble up from the given\n            coro. This isn't fool-proof: if the user doesn't\n            provide a coro, and instead creates their own with\n            loop.create_task, that task might bubble\n            a CancelledError into the run_until_complete().\"\"\"\n            try:\n                await coro\n            except asyncio.CancelledError:\n                pass\n        loop.create_task(new_coro())\n\n    shutdown_handler = shutdown_handler or _shutdown_handler\n\n    if WINDOWS:  # pragma: no cover\n        # This is to allow CTRL-C to be detected in a timely fashion,\n        # see: https://bugs.python.org/issue23057#msg246316\n        loop.create_task(windows_support_wakeup())\n\n        # This is to be able to handle SIGBREAK.\n        def windows_handler(sig, frame):\n            # Disable the handler so it won't be called again.\n            signame = signal.Signals(sig).name\n            logger.critical('Received signal: %s. Stopping the loop.', signame)\n            shutdown_handler(loop)\n\n        signal.signal(signal.SIGBREAK, windows_handler)\n        signal.signal(signal.SIGINT, windows_handler)\n    else:\n        loop.add_signal_handler(SIGINT, shutdown_handler, loop)\n        loop.add_signal_handler(SIGTERM, shutdown_handler, loop)\n\n    # TODO: We probably don't want to create a different executor if the\n    # TODO: loop was supplied. (User might have put stuff on that loop's\n    # TODO: executor).\n    if not executor:\n        logger.debug('Creating default executor')\n        executor = ThreadPoolExecutor(max_workers=executor_workers)\n    loop.set_default_executor(executor)\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:  # pragma: no cover\n        logger.info('Got KeyboardInterrupt')\n        if WINDOWS:\n            # Windows doesn't do any POSIX signal handling, and no\n            # abstraction layer for signals is currently implemented in\n            # asyncio. So we fall back to KeyboardInterrupt (triggered\n            # by the user/environment sending CTRL-C, or signal.CTRL_C_EVENT\n            shutdown_handler()\n    logger.info('Entering shutdown phase.')\n\n    def sep():\n        tasks = all_tasks(loop=loop)\n        do_not_cancel = set()\n        for t in tasks:\n            # TODO: we don't need access to the coro. We could simply\n            # TODO: store the task itself in the weakset.\n            if t._coro in _DO_NOT_CANCEL_COROS:\n                do_not_cancel.add(t)\n\n        tasks -= do_not_cancel\n\n        logger.info('Cancelling pending tasks.')\n        for t in tasks:\n            logger.debug('Cancelling task: %s', t)\n            t.cancel()\n        return tasks, do_not_cancel\n\n    tasks, do_not_cancel = sep()\n    # Here's a protip: if you group a bunch of tasks, and some of them\n    # get cancelled, and they DON'T HANDLE THE CANCELLATION, then the\n    # raised CancelledError will bubble up to, and stop the\n    # loop.run_until_complete() line: meaning, not all the tasks in\n    # the gathered group will actually be complete. You need to\n    # enable this with the ``return_exceptions`` flag.\n    group = gather(*tasks, *do_not_cancel, return_exceptions=True)\n    logger.info('Running pending tasks till complete')\n    # TODO: obtain all the results, and log any results that are exceptions\n    # other than CancelledError. Will be useful for troubleshooting.\n    loop.run_until_complete(group)\n\n    logger.info('Waiting for executor shutdown.')\n    executor.shutdown(wait=True)\n    # If loop was supplied, it's up to the caller to close!\n    if not loop_was_supplied:\n        logger.info('Closing the loop.')\n        loop.close()\n    logger.critical('Leaving. Bye!')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a command parser for given function.", "response": "def _generate_command(self, func, name=None, **kwargs):\n        \"\"\"Generates a command parser for given func.\n\n        :param func: func to generate related command parser\n        :param type: function\n\n        :param name: command name\n        :param type: str\n\n        :param **kwargs: keyword arguments those passed through to\n                         :py:class:``argparse.ArgumentParser.add_parser``\n        :param type: dict\n\n        \"\"\"\n        func_pointer = name or func.__name__\n        storm_config = get_storm_config()\n        aliases, additional_kwarg = None, None\n        if 'aliases' in storm_config:\n            for command, alias_list in \\\n                    six.iteritems(storm_config.get(\"aliases\")):\n                if func_pointer == command:\n                    aliases = alias_list\n                    break\n\n        func_help = func.__doc__ and func.__doc__.strip()\n        subparser = self.subparsers.add_parser(name or func.__name__,\n                                               aliases=aliases,\n                                               help=func_help)\n        spec = inspect.getargspec(func)\n        opts = reversed(list(izip_longest(reversed(spec.args or []),\n                                          reversed(spec.defaults or []),\n                                          fillvalue=self._POSITIONAL())))\n        for k, v in opts:\n            argopts = getattr(func, 'argopts', {})\n            args, kwargs = argopts.get(k, ([], {}))\n            args = list(args)\n            is_positional = isinstance(v, self._POSITIONAL)\n            options = [arg for arg in args if arg.startswith('-')]\n            if isinstance(v, list):\n                kwargs.update({\n                    'action': 'append',\n                })\n            if is_positional:\n                if options:\n                    args = options\n                    kwargs.update({'required': True, 'dest': k})\n                else:\n                    args = [k]\n\n            else:\n                args = options or ['--%s' % k]\n                kwargs.update({'default': v, 'dest': k})\n\n            arg = subparser.add_argument(*args, **kwargs)\n\n        subparser.set_defaults(**{self._COMMAND_FLAG: func})\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses and dispatch commands by given list of arguments", "response": "def execute(self, arg_list):\n        \"\"\"Main function to parse and dispatch commands by given ``arg_list``\n\n        :param arg_list: all arguments provided by the command line\n        :param type: list\n\n        \"\"\"\n        arg_map = self.parser.parse_args(arg_list).__dict__\n        command = arg_map.pop(self._COMMAND_FLAG)\n        return command(**arg_map)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses SSH connection uri - like sentences.", "response": "def parse(uri, user=None, port=22):\n    \"\"\"\n    parses ssh connection uri-like sentences.\n    ex:\n        - root@google.com -> (root, google.com, 22)\n        - noreply@facebook.com:22 -> (noreply, facebook.com, 22)\n        - facebook.com:3306 -> ($USER, facebook.com, 3306)\n        - twitter.com -> ($USER, twitter.com, 22)\n\n    default port: 22\n    default user: $USER (getpass.getuser())\n    \"\"\"\n\n    uri = uri.strip()\n\n    if not user:\n        user = getpass.getuser()\n\n    # get user\n    if '@' in uri:\n        user = uri.split(\"@\")[0]\n\n    # get port\n    if ':' in uri:\n        port = uri.split(\":\")[-1]\n\n    try:\n        port = int(port)\n    except ValueError:\n        raise ValueError(\"port must be numeric.\")\n\n    # get host\n    uri = re.sub(\":.*\", \"\", uri)\n    uri = re.sub(\".*@\", \"\", uri)\n    host = uri\n\n    return (\n        user,\n        host,\n        port,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(name, connection_uri, id_file=\"\", o=[], config=None):\n    storm_ = get_storm_instance(config)\n\n    try:\n\n        # validate name\n        if '@' in name:\n            raise ValueError('invalid value: \"@\" cannot be used in name.')\n\n        user, host, port = parse(\n            connection_uri,\n            user=get_default(\"user\", storm_.defaults),\n            port=get_default(\"port\", storm_.defaults)\n        )\n\n        storm_.add_entry(name, host, user, port, id_file, o)\n\n        print(\n            get_formatted_message(\n                '{0} added to your ssh config. you can connect '\n                'it by typing \"ssh {0}\".'.format(name),\n            'success')\n        )\n\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)", "response": "Adds a new entry to the sshconfig."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclone an entry to the sshconfig.", "response": "def clone(name, clone_name, config=None):\n    \"\"\"\n    Clone an entry to the sshconfig.\n    \"\"\"\n    storm_ = get_storm_instance(config)\n\n    try:\n\n        # validate name\n        if '@' in name:\n            raise ValueError('invalid value: \"@\" cannot be used in name.')\n\n        storm_.clone_entry(name, clone_name)\n\n        print(\n            get_formatted_message(\n                '{0} added to your ssh config. you can connect '\n                'it by typing \"ssh {0}\".'.format(clone_name),\n            'success')\n        )\n\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move(name, entry_name, config=None):\n    storm_ = get_storm_instance(config)\n\n    try:\n\n        if '@' in name:\n            raise ValueError('invalid value: \"@\" cannot be used in name.')\n\n        storm_.clone_entry(name, entry_name, keep_original=False)\n\n        print(\n            get_formatted_message(\n                '{0} moved in ssh config. you can '\n                'connect it by typing \"ssh {0}\".'.format(\n                    entry_name\n                ),\n            'success')\n        )\n\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)", "response": "Move an entry to the sshconfig."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edit(name, connection_uri, id_file=\"\", o=[], config=None):\n    storm_ = get_storm_instance(config)\n\n    try:\n        if ',' in name:\n            name = \" \".join(name.split(\",\"))\n\n        user, host, port = parse(\n            connection_uri,\n            user=get_default(\"user\", storm_.defaults),\n            port=get_default(\"port\", storm_.defaults)\n        )\n\n        storm_.edit_entry(name, host, user, port, id_file, o)\n        print(get_formatted_message(\n            '\"{0}\" updated successfully.'.format(\n                name\n            ), 'success'))\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)", "response": "Edit an entry in a new entry in the ssh config."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(name, connection_uri=\"\", id_file=\"\", o=[], config=None):\n    storm_ = get_storm_instance(config)\n    settings = {}\n\n    if id_file != \"\": \n        settings['identityfile'] = id_file\n\n    for option in o:\n        k, v = option.split(\"=\")\n        settings[k] = v\n\n    try:\n        storm_.update_entry(name, **settings)\n        print(get_formatted_message(\n            '\"{0}\" updated successfully.'.format(\n                name\n            ), 'success'))\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)", "response": "Update an entry in the nation. xml file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a single host.", "response": "def delete(name, config=None):\n    \"\"\"\n    Deletes a single host.\n    \"\"\"\n    storm_ = get_storm_instance(config)\n\n    try:\n        storm_.delete_entry(name)\n        print(\n            get_formatted_message(\n                'hostname \"{0}\" deleted successfully.'.format(name),\n            'success')\n        )\n    except ValueError as error:\n        print(get_formatted_message(error, 'error'), file=sys.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all hosts from ssh config.", "response": "def list(config=None):\n    \"\"\"\n    Lists all hosts from ssh config.\n    \"\"\"\n    storm_ = get_storm_instance(config)\n\n    try:\n        result = colored('Listing entries:', 'white', attrs=[\"bold\", ]) + \"\\n\\n\"\n        result_stack = \"\"\n        for host in storm_.list_entries(True):\n\n            if host.get(\"type\") == 'entry':\n                if not host.get(\"host\") == \"*\":\n                    result += \"    {0} -> {1}@{2}:{3}\".format(\n                        colored(host[\"host\"], 'green', attrs=[\"bold\", ]),\n                        host.get(\"options\").get(\n                            \"user\", get_default(\"user\", storm_.defaults)\n                        ),\n                        host.get(\"options\").get(\n                            \"hostname\", \"[hostname_not_specified]\"\n                        ),\n                        host.get(\"options\").get(\n                            \"port\", get_default(\"port\", storm_.defaults)\n                        )\n                    )\n\n                    extra = False\n                    for key, value in six.iteritems(host.get(\"options\")):\n\n                        if not key in [\"user\", \"hostname\", \"port\"]:\n                            if not extra:\n                                custom_options = colored(\n                                    '\\n\\t[custom options] ', 'white'\n                                )\n                                result += \" {0}\".format(custom_options)\n                            extra = True\n\n                            if isinstance(value, collections.Sequence):\n                                if isinstance(value, builtins.list):\n                                    value = \",\".join(value)\n                                    \n                            result += \"{0}={1} \".format(key, value)\n                    if extra:\n                        result = result[0:-1]\n\n                    result += \"\\n\\n\"\n                else:\n                    result_stack = colored(\n                        \"   (*) General options: \\n\", \"green\", attrs=[\"bold\",]\n                    )\n                    for key, value in six.iteritems(host.get(\"options\")):\n                        if isinstance(value, type([])):\n                            result_stack += \"\\t  {0}: \".format(\n                                colored(key, \"magenta\")\n                            )\n                            result_stack += ', '.join(value)\n                            result_stack += \"\\n\"\n                        else:\n                            result_stack += \"\\t  {0}: {1}\\n\".format(\n                                colored(key, \"magenta\"),\n                                value,\n                            )\n                    result_stack = result_stack[0:-1] + \"\\n\"\n\n        result += result_stack\n        print(get_formatted_message(result, \"\"))\n    except Exception as error:\n        print(get_formatted_message(str(error), 'error'), file=sys.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(search_text, config=None):\n    storm_ = get_storm_instance(config)\n\n    try:\n        results = storm_.search_host(search_text)\n        if len(results) == 0:\n            print ('no results found.')\n\n        if len(results) > 0:\n            message = 'Listing results for {0}:\\n'.format(search_text)\n            message += \"\".join(results)\n            print(message)\n    except Exception as error:\n        print(get_formatted_message(str(error), 'error'), file=sys.stderr)\n        sys.exit(1)", "response": "Searches entries by given search text."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all hosts from ssh config.", "response": "def delete_all(config=None):\n    \"\"\"\n    Deletes all hosts from ssh config.\n    \"\"\"\n    storm_ = get_storm_instance(config)\n\n    try:\n        storm_.delete_all_entries()\n        print(get_formatted_message('all entries deleted.', 'success'))\n    except Exception as error:\n        print(get_formatted_message(str(error), 'error'), file=sys.stderr)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the web UI.", "response": "def web(port, debug=False, theme=\"modern\", ssh_config=None):\n    \"\"\"Starts the web UI.\"\"\"\n    from storm import web as _web\n    _web.run(port, debug, theme, ssh_config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, file_obj):\n        order = 1\n        host = {\"host\": ['*'], \"config\": {}, }\n        for line in file_obj:\n            line = line.rstrip('\\n').lstrip()\n            if line == '':\n                self._config.append({\n                    'type': 'empty_line',\n                    'value': line,\n                    'host': '',\n                    'order': order,\n                })\n                order += 1\n                continue\n\n            if line.startswith('#'):\n                self._config.append({\n                    'type': 'comment',\n                    'value': line,\n                    'host': '',\n                    'order': order,\n                })\n                order += 1\n                continue\n\n            if '=' in line:\n                # Ensure ProxyCommand gets properly split\n                if line.lower().strip().startswith('proxycommand'):\n                    proxy_re = re.compile(r\"^(proxycommand)\\s*=*\\s*(.*)\", re.I)\n                    match = proxy_re.match(line)\n                    key, value = match.group(1).lower(), match.group(2)\n                else:\n                    key, value = line.split('=', 1)\n                    key = key.strip().lower()\n            else:\n                # find first whitespace, and split there\n                i = 0\n                while (i < len(line)) and not line[i].isspace():\n                    i += 1\n                if i == len(line):\n                    raise Exception('Unparsable line: %r' % line)\n                key = line[:i].lower()\n                value = line[i:].lstrip()\n            if key == 'host':\n                self._config.append(host)\n                value = value.split()\n                host = {\n                    key: value,\n                    'config': {},\n                    'type': 'entry',\n                    'order': order\n                }\n                order += 1\n            elif key in ['identityfile', 'localforward', 'remoteforward']:\n                if key in host['config']:\n                    host['config'][key].append(value)\n                else:\n                    host['config'][key] = [value]\n            elif key not in host['config']:\n                host['config'].update({key: value})\n        self._config.append(host)", "response": "Read an OpenSSH config file from the given file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dxgmml(graphcollection, path): # [#61510094]\n\n    # TODO: make sure C is a GraphCollection.\n\n    nodes = {}\n    for n in graphcollection.nodes():\n        nodes[n] = { 'periods' : [] }   # Each period will be a dict with\n                                        #  'start' and 'end' values.\n    edges = {}\n    for e in graphcollection.edges():\n        edges[e] = { 'periods' : [] }\n\n    # Build node list.\n    current = []\n    for k in sorted(graphcollection.keys()):\n        graph = _strip_list_attributes(graphcollection[k])\n        preceding = [ c for c in current ]\n        current = []\n        for n in graph.nodes(data=True):\n            n_ = graphcollection.node_index[n[0]]\n            if n_ not in preceding:   # Looking for gaps in presence of node.\n                nodes[n_]['periods'].append({'start': k, 'end': k})\n            else:\n                if k > nodes[n_]['periods'][-1]['end']:\n                    nodes[n_]['periods'][-1]['end'] = k\n            current.append(n_)\n\n            nodes[n_][k] = {}\n            for attr, value in n[1].iteritems():\n                if type(value) is str:\n                    value = value.replace(\"&\", \"&amp;\").replace('\"', '')\n                nodes[n_][k][attr] = value\n\n    # Build edge list.\n    current = []\n    for k in sorted(graphcollection.keys()):\n        graph = _strip_list_attributes(graphcollection[k])\n        preceding = [ c for c in current ]\n        current = []\n        for e in graph.edges(data=True):\n            e_key = (graphcollection.node_index[e[0]],\n                     graphcollection.node_index[e[1]])\n            if e_key not in preceding:   # Looking for gaps in presence of edge.\n                try:\n                    edges[e_key]['periods'].append( { 'start': k, 'end': k } )\n                except KeyError:\n                    e_key = (graphcollection.node_index[e[1]],\n                             graphcollection.node_index[e[0]])\n                    edges[e_key]['periods'].append( { 'start': k, 'end': k } )\n            else:\n                if k > edges[e_key]['periods'][-1]['end']:\n                    edges[e_key]['periods'][-1]['end'] = k\n            current.append(e_key)\n\n            edges[e_key][k] = {}\n            for attr, value in e[2].iteritems():\n                if type(value) is str:\n                    value = value.replace(\"&\", \"&amp;\").replace('\"', '')\n                edges[e_key][k][attr] = value\n\n    # Write graph to XGMML.\n    xst = '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n'\n\n    sg = '<graph>\\n'\n    eg = '</graph>'\n\n    nst = '\\t<node label=\"{0}\" id=\"{0}\" start=\"{1}\" end=\"{2}\">\\n'\n    ast = '\\t\\t<att name=\"{0}\" type=\"{1}\" value=\"{2}\" start=\"{3}\" end=\"{4}\"/>\\n'\n    enn = '\\t</node>\\n'\n\n    est = '\\t<edge source=\"{0}\" target=\"{1}\" start=\"{2}\" end=\"{3}\">\\n'\n    eas = '\\t\\t<att name=\"{0}\" type=\"{1}\" value=\"{2}\" start=\"{3}\" end=\"{4}\"/>\\n'\n    ene = '\\t</edge>\\n'\n\n    with open(path, \"w\") as f:\n        f.write(xst)    # xml element.\n        f.write(sg)     # Graph element.\n        for n in nodes.keys():\n            for period in nodes[n]['periods']:\n                label = unicode(n).replace(\"&\", \"&amp;\").replace('\"', '')\n\n                # Node element.\n                f.write(nst.format(label, period['start'], period['end']+1))\n\n                for i in sorted(nodes[n].keys()):\n                    if period['start'] <= i <= period['end']:\n                        for attr, value in nodes[n][i].iteritems():\n                            # Type names are slightly different in XGMML.\n                            dtype = _safe_type(value)\n                            attr = unicode(attr).replace(\"&\", \"&amp;\")\n\n                            # Node attribute element.\n                            f.write(ast.format(attr, dtype, value, i, i+1))\n\n                f.write(enn)    # End node element.\n\n        for e in edges.keys():\n            for period in edges[e]['periods']:\n                src = unicode(e[0]).replace(\"&\", \"&amp;\").replace('\"', '')\n                tgt = unicode(e[1]).replace(\"&\", \"&amp;\").replace('\"', '')\n                start = period['start']\n                end = period['end'] + 1\n\n                # Edge element.\n                f.write(est.format(src, tgt, start, end))\n\n                for i in sorted(edges[e].keys()):\n                    if period['start'] <= i <= period['end']:\n                        for attr, value in edges[e][i].iteritems():\n                            # Type names are slightly different in XGMML.\n                            dtype = _safe_type(value)\n\n                            # Edge attribute element.\n                            f.write(eas.format(attr, dtype, value, i, i+1)\n                                       .replace(\"&\", \"&amp;\"))\n\n                f.write(ene)    # End edge element.\n        f.write(eg)", "response": "Writes a graphcollection to a dynamic XGMML file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _strip_list_attributes(graph_):\n    for n_ in graph_.nodes(data=True):\n        for k,v in n_[1].iteritems():\n            if type(v) is list:\n                graph_.node[n_[0]][k] = unicode(v)\n    for e_ in graph_.edges(data=True):\n        for k,v in e_[2].iteritems():\n            if type(v) is list:\n                graph_.edge[e_[0]][e_[1]][k] = unicode(v)\n\n    return graph_", "response": "Converts lists attributes to strings for all nodes and edges in G."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _safe_type(value):\n\n    if type(value) is str: dtype = 'string'\n    if type(value) is unicode: dtype = 'string'\n    if type(value) is int: dtype = 'integer'\n    if type(value) is float: dtype = 'real'\n\n    return dtype", "response": "Converts Python type names to XGMML - safe type names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(path, corpus=True, index_by='wosid', streaming=False, parse_only=None,\n         corpus_class=Corpus, **kwargs):\n    \"\"\"\n    Parse one or more WoS field-tagged data files.\n\n    Examples\n    --------\n    .. code-block:: python\n\n       >>> from tethne.readers import wos\n       >>> corpus = wos.read(\"/path/to/some/wos/data\")\n       >>> corpus\n       <tethne.classes.corpus.Corpus object at 0x10057c2d0>\n\n    Parameters\n    ----------\n    path : str\n        Path to WoS field-tagged data. Can be a path directly to a single data\n        file, or to a directory containing several data files.\n    corpus : bool\n        If True (default), returns a :class:`.Corpus`\\. If False, will return\n        only a list of :class:`.Paper`\\s.\n\n    Returns\n    -------\n    :class:`.Corpus` or :class:`.Paper`\n    \"\"\"\n\n    if not os.path.exists(path):\n        raise ValueError('No such file or directory')\n\n    # We need the primary index field in the parse results.\n    if parse_only:\n        parse_only.append(index_by)\n\n    if streaming:\n        return streaming_read(path, corpus=corpus, index_by=index_by,\n                              parse_only=parse_only, **kwargs)\n\n    if os.path.isdir(path):    # Directory containing 1+ WoS data files.\n        papers = []\n        for sname in os.listdir(path):\n            if sname.endswith('txt') and not sname.startswith('.'):\n                papers += read(os.path.join(path, sname),\n                               corpus=False,\n                               parse_only=parse_only)\n    else:   # A single data file.\n        papers = WoSParser(path).parse(parse_only=parse_only)\n\n    if corpus:\n        return corpus_class(papers, index_by=index_by, **kwargs)\n    return papers", "response": "Read a WoS field - tagged data file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts to split an author name into last and first parts.", "response": "def parse_author(self, value):\n        \"\"\"\n        Attempts to split an author name into last and first parts.\n        \"\"\"\n        tokens = tuple([t.upper().strip() for t in value.split(',')])\n        if len(tokens) == 1:\n            tokens = value.split(' ')\n        if len(tokens) > 0:\n            if len(tokens) > 1:\n                aulast, auinit = tokens[0:2]    # Ignore JR, II, III, etc.\n            else:\n                aulast = tokens[0]\n                auinit = ''\n        else:\n            aulast, auinit = tokens[0], ''\n        aulast = _strip_punctuation(aulast).upper()\n        auinit = _strip_punctuation(auinit).upper()\n        return aulast, auinit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the value of the CR field and sets the citation attributes.", "response": "def handle_CR(self, value):\n        \"\"\"\n        Parses cited references.\n        \"\"\"\n        citation = self.entry_class()\n\n        value = strip_tags(value)\n\n        # First-author name and publication date.\n        ptn = '([\\w\\s\\W]+),\\s([0-9]{4}),\\s([\\w\\s]+)'\n        ny_match = re.match(ptn, value, flags=re.U)\n        nj_match = re.match('([\\w\\s\\W]+),\\s([\\w\\s]+)',\n                            value, flags=re.U)\n        if ny_match is not None:\n            name_raw, date, journal = ny_match.groups()\n        elif nj_match is not None:\n            name_raw, journal = nj_match.groups()\n            date = None\n        else:\n            return\n\n        datematch = re.match('([0-9]{4})', value)\n        if datematch:\n            date = datematch.group(1)\n            name_raw = None\n\n        if name_raw:\n            name_tokens = [t.replace('.', '') for t in name_raw.split(' ')]\n            if len(name_tokens) > 4 or value.startswith('*'):    # Probably not a person.\n                proc = lambda x: _strip_punctuation(x)\n                aulast = ' '.join([proc(n) for n in name_tokens]).upper()\n                auinit = ''\n            elif len(name_tokens) > 0:\n                aulast = name_tokens[0].upper()\n                proc = lambda x: _space_sep(_strip_punctuation(x))\n                auinit = ' '.join([proc(n) for n in name_tokens[1:]]).upper()\n            else:\n                aulast = name_tokens[0].upper()\n                auinit = ''\n\n            setattr(citation, 'authors_init', [(aulast, auinit)])\n\n        if date:\n            date = int(date)\n        setattr(citation, 'date', date)\n        setattr(citation, 'journal', journal)\n\n        # Volume.\n        v_match = re.search('\\,\\s+V([0-9A-Za-z]+)', value)\n        if v_match is not None:\n            volume = v_match.group(1)\n        else:\n            volume = None\n        setattr(citation, 'volume', volume)\n\n        # Start page.\n        p_match = re.search('\\,\\s+[Pp]([0-9A-Za-z]+)', value)\n        if p_match is not None:\n            page = p_match.group(1)\n        else:\n            page = None\n        setattr(citation, 'pageStart', page)\n\n        # DOI.\n        doi_match = re.search('DOI\\s(.*)', value)\n        if doi_match is not None:\n            doi = doi_match.group(1)\n        else:\n            doi = None\n        setattr(citation, 'doi', doi)\n        return citation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing WC keywords and convert to uppercase.", "response": "def postprocess_WC(self, entry):\n        \"\"\"\n        Parse WC keywords.\n\n        Subject keywords are usually semicolon-delimited.\n        \"\"\"\n\n        if type(entry.WC) not in [str, unicode]:\n            WC= u' '.join([unicode(k) for k in entry.WC])\n        else:\n            WC= entry.WC\n        entry.WC= [k.strip().upper() for k in WC.split(';')]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef postprocess_subject(self, entry):\n\n        if type(entry.subject) not in [str, unicode]:\n            subject = u' '.join([unicode(k) for k in entry.subject])\n        else:\n            subject = entry.subject\n        entry.subject = [k.strip().upper() for k in subject.split(';')]", "response": "Parse subject keywords.\n\n        Subject keywords are usually semicolon-delimited."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef postprocess_authorKeywords(self, entry):\n\n        if type(entry.authorKeywords) not in [str, unicode]:\n            aK = u' '.join([unicode(k) for k in entry.authorKeywords])\n        else:\n            aK = entry.authorKeywords\n        entry.authorKeywords = [k.strip().upper() for k in aK.split(';')]", "response": "Parse author keywords.\n\n        Author keywords are usually semicolon-delimited."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses WoS Keyword Plus keywords.", "response": "def postprocess_keywordsPlus(self, entry):\n        \"\"\"\n        Parse WoS \"Keyword Plus\" keywords.\n\n        Keyword Plus keywords are usually semicolon-delimited.\n        \"\"\"\n\n        if type(entry.keywordsPlus) in [str, unicode]:\n            entry.keywordsPlus = [k.strip().upper() for k\n                                  in entry.keywordsPlus.split(';')]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef postprocess_funding(self, entry):\n\n        if type(entry.funding) not in [str, unicode]:\n            return\n\n        sources = [fu.strip() for fu in entry.funding.split(';')]\n        sources_processed = []\n        for source in sources:\n            m = re.search('(.*)?\\s+\\[(.+)\\]', source)\n            if m:\n                agency, grant = m.groups()\n            else:\n                agency, grant = source, None\n            sources_processed.append((agency, grant))\n        entry.funding = sources_processed", "response": "Separates funding agency from grant numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef postprocess_authors_full(self, entry):\n        if type(entry.authors_full) is not list:\n            entry.authors_full = [entry.authors_full]", "response": "If only a single author was found ensure that the authors_full is not a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef postprocess_authors_init(self, entry):\n        if type(entry.authors_init) is not list:\n            entry.authors_init = [entry.authors_init]", "response": "Ensure that the authors_init is not a list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nposting - process the cited references.", "response": "def postprocess_citedReferences(self, entry):\n        \"\"\"\n        If only a single cited reference was found, ensure that\n        ``citedReferences`` is nonetheless a list.\n        \"\"\"\n        if type(entry.citedReferences) is not list:\n            entry.citedReferences = [entry.citedReferences]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the documents to a file.", "response": "def write_documents(corpus, target, featureset_name, metadata_fields=[]):\n    \"\"\"\n    Parameters\n    ----------\n\n\n    \"\"\"\n\n    docpath = target + '_docs.txt'\n    metapath = target + '_meta.csv'\n\n    features = corpus.features[featureset_name].features\n    ftype = type(corpus.features[featureset_name])\n    index = corpus.features[featureset_name].index\n\n    try:\n        docFile = open(docpath, 'wb')\n    except IOError:\n        raise IOError('Invalid target. Could not open files for writing.')\n\n    # Generate metadata.\n    with codecs.open(metapath, 'w', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow([corpus.index_by] + list(metadata_fields))\n        for i, p in corpus.indexed_papers.iteritems():\n            getter = lambda m: getattr(p, m) if hasattr(p, m) else None\n            writer.writerow([i] + list(map(getter, metadata_fields)))\n\n    # Write documents content.\n    with codecs.open(docpath, 'w', encoding='utf-8') as f:\n        for i, p in corpus.indexed_papers.iteritems():\n            if i in features:\n                row = [i, u'en']\n                if ftype is FeatureSet:\n                    row += [u' '.join(repeat(e, c)) for e, c in features[i]]\n                elif ftype is StructuredFeatureSet:\n                    row += features[i]\n                f.write(u'\\t'.join(row) + u'\\n')\n\n    return docpath, metapath"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_burstness(corpus, B, **kwargs):\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.patches as mpatches\n    except ImportError:\n        raise RuntimeError('This method requires the package matplotlib.')\n\n    color = kwargs.get('color', 'red')\n\n    # Get width based on slices.\n    years = sorted(corpus.indices['date'].keys())\n    width = years[1] - years[0]\n    height = 1.0\n\n    fig = plt.figure(figsize=(10,len(B)/4.))\n\n    f = 1\n    axes = {}\n    for key, value in B.iteritems():\n        x,y = value\n        ax = fig.add_subplot(len(B),1,f)\n        f+=1\n        ax.set_yticks([])\n        ax.set_xbound(min(years), max(years) + 1)\n\n        if not f == len(B)+1:   # Only show xticks on the bottom subplot.\n            ax.set_xticklabels([])\n\n        # Block out years until first occurrence of feature.\n\n        rect = mpatches.Rectangle((min(years), 0), sorted(x)[0]-min(years),\n                                   height, fill=True, linewidth=0.0)\n        rect.set_facecolor('black')\n        rect.set_alpha(0.3)\n        ax.add_patch(rect)\n\n        # Add a rectangle for each year, shaded according to burstness state.\n        for d in xrange(min(x), max(x)):\n            try:\n                i = x.index(d)\n            except ValueError:\n                continue\n\n            xy = (d, 0.)\n\n            state = y[i]\n            rect = mpatches.Rectangle(xy, width, height,\n                                      fill=True, linewidth=0.0)\n            rect.set_facecolor(color)\n            rect.set_alpha(state)\n            ax.add_patch(rect)\n\n        ax.set_ylabel(key, rotation=0,\n                      horizontalalignment='right',\n                      verticalalignment='center')\n    plt.subplots_adjust(left=0.5)\n    fig.tight_layout(h_pad=0.25)\n\n    plt.show()", "response": "Generates a figure that displays bursty features for each feature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_sigma(corpus, sigma, nodes=None, **kwargs):\n\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.patches as mpatches\n    except ImportError:\n        raise RuntimeError('This method requires the package matplotlib.')\n\n    if nodes == 'all':\n        nodes = sigma.keys()\n\n    # Display parameters.\n    color = kwargs.get('color', 'red')\n    years = sorted(corpus.indices['date'].keys())\n    width = years[1] - years[0] # Get width based on slices.\n    height = 1.0\n\n    sort_by = kwargs.get('sort_by', 'max')\n    perslice = kwargs.get('perslice', False)\n    topn = kwargs.get('topn', 20)\n\n    if not nodes:\n        # Get only the topn most significant papers.\n        include = []\n        if sort_by == 'max':\n            if perslice:    # Get topn per slice.\n                vals = {}\n                norm_by = 0.\n\n                # Organize values in a way that makes selection easier.\n                for node, history in sigma.iteritems():\n                    years, values = history\n                    if max(values) == 0.:\n                        continue\n                    for year, val in zip(years, values):\n                        if year not in vals:\n                            vals[year] = {}\n                        vals[year][node] = val\n\n                # Get the maximum values for each slice.\n                for year, node_values in vals.iteritems():\n                    indices = argsort(node_values.values())[-topn:][::-1]\n                    include += [node_values.keys()[i] for i in indices]\n                    max_value = max(node_values.values())\n                    if max_value > norm_by:\n                        norm_by = max_value\n\n            else:   # Get topn overall.\n                maxes = [max(v[1]) for v in sigma.values() ]\n                indices = argsort(maxes)[-topn:][::-1]\n                include = [sigma.keys()[i] for i in indices]\n                norm_by = max(maxes)\n\n        # Nodes to include.\n        nodes = [node for node, values in sigma.iteritems()\n                 if max(values[1]) > 0 and node in include]\n\n#     if fig is None: # Create a new Figure instance.\n    fig = plt.figure(figsize=(10, len(nodes)/4.))\n\n    # Plot!\n    f = 1   # Current subplot.\n    axes = {}\n\n    # Earliest year for which we have values.\n    x_min = min([min(years) for years, values in sigma.values()])\n\n    for node in nodes:\n        x_order = argsort(sigma[node][0])\n        x = sorted(sigma[node][0])\n        y = [sigma[node][1][i]/norm_by for i in x_order]\n\n        ax = fig.add_subplot(len(nodes), 1, f)\n        f+=1\n        ax.set_yticks([])\n        ax.set_xbound(x_min, max(years)+1)\n\n        # Only show xticks on the bottom subplot.\n        if not f == len(nodes) + 1:\n            ax.set_xticklabels([])\n\n        # Block out years until first occurrence of feature.\n        rect = mpatches.Rectangle((x_min, 0), x[0] - x_min,\n                                  height, fill=True, linewidth=0.0)\n        rect.set_facecolor('black')\n        rect.set_alpha(0.1)\n        ax.add_patch(rect)\n\n        # Add a rectangle for each year, shaded according to burstness state.\n        for d in xrange(min(x), max(x)):\n            try:    # May not have values for all years.\n                i = x.index(d)\n            except ValueError:\n                continue\n\n            xy = (d, 0.)\n\n            state = y[i]\n            rect = mpatches.Rectangle(xy, width, height,\n                                      fill=True, linewidth=0.0)\n            rect.set_facecolor(color)\n            rect.set_alpha(state + 0.1)\n            ax.add_patch(rect)\n\n        ax.set_ylabel(node, rotation=0,\n                      horizontalalignment='right',\n                      verticalalignment='center')\n\n    plt.subplots_adjust(left=0.5)\n    fig.tight_layout(h_pad=0.25)\n    plt.show()", "response": "Plot sigma values for the top 5 most influential nodes in a corpus."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simplify_multigraph(multigraph, time=False):\n\n    graph = nx.Graph()\n\n    for node in multigraph.nodes(data=True):\n        u = node[0]\n        node_attribs = node[1]\n        graph.add_node(u, node_attribs)\n\n\n        for v in multigraph[u]:\n            edges = multigraph.get_edge_data(u, v) # Dict.\n\n            edge_attribs = { 'weight': len(edges) }\n\n            if time:    # Look for a date in each edge.\n                start = 3000\n                end = 0\n                found_date = False\n                for edge in edges.values():\n                    try:\n                        found_date = True\n                        if edge['date'] < start:\n                            start = edge['date']\n                        if edge['date'] > end:\n                            end = edge['date']\n                    except KeyError:    # No date to be found.\n                        pass\n\n                if found_date:  # If no date found, don't add start/end atts.\n                    edge_attribs['start'] = start\n                    edge_attribs['end'] = end\n\n            graph.add_edge(u, v, edge_attribs)\n\n    return graph", "response": "Simplifies a networkx. MultiGraph by condensing multiple edges between the same node pair\n    into a single edge."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef citation_count(papers, key='ayjid', verbose=False):\n\n    if verbose:\n        print \"Generating citation counts for \"+unicode(len(papers))+\" papers...\"\n\n    counts = Counter()\n    for P in papers:\n        if P['citations'] is not None:\n            for p in P['citations']:\n                counts[p[key]] += 1\n\n    return counts", "response": "Returns a dictionary containing citation counts for all of the given papers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef top_cited(papers, topn=20, verbose=False):\n\n    if verbose:\n        print \"Finding top \"+unicode(topn)+\" most cited papers...\"\n\n    counts = citation_count(papers, verbose=verbose)\n\n    if type(topn) is int:\n        n = topn\n    elif type(topn) is float:\n        n = int(np.around(topn*len(counts), decimals=-1))\n    top = dict(sorted(counts.items(),\n                       key=operator.itemgetter(1),\n                       reverse=True)[:n]).keys()\n\n    return top, counts", "response": "Generates a list of the top n most cited papers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef top_parents(papers, topn=20, verbose=False):\n\n    if verbose:\n        print \"Getting parents of top \"+unicode(topn)+\" most cited papers.\"\n\n    top, counts = top_cited(papers, topn=topn, verbose=verbose)\n    papers = [ P for P in papers if P['citations'] is not None ]\n    parents = [ P for P in papers if len(\n                    set([ c['ayjid'] for c in P['citations'] ]) &\n                    set(top) ) > 0 ]\n\n    if verbose:\n        print \"Found \" + unicode(len(parents)) + \" parents.\"\n\n    return parents, top, counts", "response": "Returns a list of list of dicts containing the top n most cited papers and their counts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef algorithm(G, method_name, **kwargs):\n    warnings.warn(\"To be removed in 0.8. Use GraphCollection.analyze instead.\",\n                  DeprecationWarning)\n\n    return G.analyze(method_name, **kwargs)", "response": "A method that performs a single method on a networkx. GraphCollection object G."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new graph with the specified method applied to each node in the graph.", "response": "def connected(G, method_name, **kwargs):\n    \"\"\"\n    Performs analysis methods from networkx.connected on each graph in the\n    collection.\n\n    Parameters\n    ----------\n    G : :class:`.GraphCollection`\n        The :class:`.GraphCollection` to analyze. The specified method will be\n        applied to each graph in ``G``.\n    method : string\n        Name of method in networkx.connected.\n    **kwargs : kwargs\n        Keyword arguments, passed directly to method.\n\n    Returns\n    -------\n    results : dict\n        Keys are graph indices, values are output of method for that graph.\n\n    Raises\n    ------\n    ValueError\n        If name is not in networkx.connected, or if no such method exists.\n\n    \"\"\"\n    warnings.warn(\"To be removed in 0.8. Use GraphCollection.analyze instead.\",\n                  DeprecationWarning)\n\n    return G.analyze(['connected', method_name], **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the observed attachment probability for each node at each time - step.", "response": "def attachment_probability(G):\n    \"\"\"\n    Calculates the observed attachment probability for each node at each\n    time-step.\n    \n    \n    Attachment probability is calculated based on the observed new edges in the\n    next time-step. So if a node acquires new edges at time t, this will accrue\n    to the node's attachment probability at time t-1. Thus at a given time,\n    one can ask whether degree and attachment probability are related.\n\n    Parameters\n    ----------\n    G : :class:`.GraphCollection`\n        Must be sliced by 'date'. See :func:`.GraphCollection.slice`\\.\n    \n    Returns\n    -------\n    probs : dict\n        Keyed by index in G.graphs, and then by node.\n    \"\"\"\n    warnings.warn(\"Removed in 0.8. Too domain-specific.\")\n\n    probs = {}\n    G_ = None\n    k_ = None\n    for k,g in G.graphs.iteritems():\n        new_edges = {}\n        if G_ is not None: \n            for n in g.nodes():\n                try:\n                    old_neighbors = set(G_[n].keys())\n                    if len(old_neighbors) > 0:\n                        new_neighbors = set(g[n].keys()) - old_neighbors\n                        new_edges[n] = float(len(new_neighbors))\n                    else:\n                        new_edges[n] = 0.\n                except KeyError:\n                    pass\n    \n            N = sum( new_edges.values() )\n            probs[k_] = { n:0. for n in G_.nodes() }\n            if N > 0.:\n                for n in G.nodes():\n                    try:\n                        probs[k_][n] = new_edges[n]/N\n                    except KeyError:\n                        pass\n\n            if probs[k_] is not None:\n                networkx.set_node_attributes(G.graphs[k_],\n                                             'attachment_probability',\n                                             probs[k_])\n    \n        G_ = G\n        k_ = k\n\n    # Handle last graph (no values).\n    key = G.graphs.keys()[-1]\n    zprobs = { n:0. for n in G.graphs[key].nodes() }\n    networkx.set_node_attributes(G.graphs[key], 'attachment_probability', zprobs)\n\n    return probs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef global_closeness_centrality(g, node=None, normalize=True):\n\n    if not node:\n        C = {}\n        for node in g.nodes():\n            C[node] = global_closeness_centrality(g, node, normalize=normalize)\n        return C\n\n    values = nx.shortest_path_length(g, node).values()\n    c = sum([1./pl for pl in values if pl != 0.]) / len(g)\n\n    if normalize:\n        ac = 0\n        for sg in nx.connected_component_subgraphs(g):\n            if len(sg.nodes()) > 1:\n                aspl = nx.average_shortest_path_length(sg)\n                ac += (1./aspl) * (float(len(sg)) / float(len(g))**2 )\n        c = c/ac\n\n    return c", "response": "Calculates the global closeness centrality for a given graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(path, corpus=True, index_by='doi', load_ngrams=True, parse_only=None,\n         corpus_class=Corpus, **kwargs):\n    \"\"\"\n    Yields :class:`.Paper` s from JSTOR DfR package.\n\n    Each :class:`.Paper` is tagged with an accession id for this\n    read/conversion.\n\n    Parameters\n    ----------\n    filepath : string\n        Filepath to unzipped JSTOR DfR folder containing a citations.xml file.\n\n    Returns\n    -------\n    papers : list\n        A list of :class:`.Paper` objects.\n\n    Examples\n    --------\n\n    .. code-block:: python\n\n       >>> from tethne.readers import dfr\n       >>> papers = dfr.read(\"/Path/to/DfR\")\n    \"\"\"\n\n    citationfname = _get_citation_filename(path)\n    features = {}\n    featureset_types = {}\n\n    # We need the primary index field in the parse results.\n    if parse_only:\n        parse_only.append(index_by)\n\n    papers = []\n    if citationfname:   # Valid DfR dataset.\n        parser = DfRParser(os.path.join(path, citationfname))\n        papers += parser.parse(parse_only=parse_only)\n\n    else:   # Possibly a directory containing several DfR datasets?\n        papers = []\n\n        # Search for DfR datasets in subdirectories.\n        for dirpath, dirnames, filenames in os.walk(path):\n            citationfname = _get_citation_filename(dirpath)\n            if citationfname:\n                subcorpus = read(dirpath, index_by=index_by,\n                                 parse_only=parse_only)\n                papers += subcorpus.papers\n                for featureset_name, featureset in subcorpus.features.iteritems():\n                    if featureset_name not in features:\n                        features[featureset_name] = {}\n                    features[featureset_name].update(featureset.items())\n                    featureset_types[featureset_name] = type(featureset)\n        load_ngrams = False\n\n    if len(papers) == 0:\n        raise ValueError('No DfR datasets found at %s' % path)\n\n    if corpus:\n        corpus = corpus_class(papers, index_by=index_by, **kwargs)\n\n        if load_ngrams:     # Find and read N-gram data.\n            for sname in os.listdir(path):\n                fpath = os.path.join(path, sname)   # Full path.\n                if os.path.isdir(fpath) and not sname.startswith('.'):\n                    datafiles = [f for f in os.listdir(fpath)\n                                 if f.lower().endswith('xml')]\n                    if len(datafiles) > 0:\n                        features[sname] = ngrams(path, sname)\n\n        for featureset_name, featureset_values in features.iteritems():\n            if type(featureset_values) is dict:\n                fclass = featureset_types[featureset_name]\n                featureset_values = fclass(featureset_values)\n            corpus.features[featureset_name] = featureset_values\n\n        return corpus\n    return papers", "response": "Read a JSTOR DfR file and return a list of all the papers that are found in the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a FeatureSet containing all N - grams from a JSTOR DfR dataset.", "response": "def ngrams(path, elem, ignore_hash=True):\n    \"\"\"\n    Yields N-grams from a JSTOR DfR dataset.\n\n    Parameters\n    ----------\n    path : string\n        Path to unzipped JSTOR DfR folder containing N-grams.\n    elem : string\n        Name of subdirectory containing N-grams. (e.g. 'bigrams').\n    ignore_hash : bool\n        If True, will exclude all N-grams that contain the hash '#' character.\n\n    Returns\n    -------\n    ngrams : :class:`.FeatureSet`\n\n    \"\"\"\n\n    grams = GramGenerator(path, elem, ignore_hash=ignore_hash)\n    return FeatureSet({k: Feature(f) for k, f in grams})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a vocabulary and replaces words with vocab indices.", "response": "def tokenize(ngrams, min_tf=2, min_df=2, min_len=3, apply_stoplist=False):\n    \"\"\"\n    Builds a vocabulary, and replaces words with vocab indices.\n\n    Parameters\n    ----------\n    ngrams : dict\n        Keys are paper DOIs, values are lists of (Ngram, frequency) tuples.\n    apply_stoplist : bool\n        If True, will exclude all N-grams that contain words in the NLTK\n        stoplist.\n\n    Returns\n    -------\n    t_ngrams : dict\n        Tokenized ngrams, as doi:{i:count}.\n    vocab : dict\n        Vocabulary as i:term.\n    token_tf : :class:`.Counter`\n        Term counts for corpus, as i:count.\n    \"\"\"\n\n    vocab = {}\n    vocab_ = {}\n    word_tf = Counter()\n    word_df = Counter()\n    token_tf = Counter()\n    token_df = Counter()\n    t_ngrams = {}\n\n    # Get global word counts, first.\n    for grams in ngrams.values():\n        for g,c in grams:\n            word_tf[g] += c\n            word_df[g] += 1\n\n    if apply_stoplist:\n        stoplist = stopwords.words()\n\n    # Now tokenize.\n    for doi, grams in ngrams.iteritems():\n        t_ngrams[doi] = []\n        for g,c in grams:\n            ignore = False\n\n            # Ignore extremely rare words (probably garbage).\n            if word_tf[g] < min_tf or word_df[g] < min_df or len(g) < min_len:\n                ignore = True\n\n            # Stoplist.\n            elif apply_stoplist:\n                for w in g.split():\n                    if w in stoplist:\n                        ignore = True\n\n            if not ignore:\n\n                # Coerce unicode to string.\n                if type(g) is str:\n                    g = unicode(g)\n                g = unidecode(g)\n\n                if g not in vocab.values():\n                    i = len(vocab)\n                    vocab[i] = g\n                    vocab_[g] = i\n                else:\n                    i = vocab_[g]\n                token_tf[i] += c\n                token_df[i] += 1\n\n                t_ngrams[doi].append( (i,c) )\n\n    return t_ngrams, vocab, token_tf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the paper XML node.", "response": "def _handle_paper(article):\n    \"\"\"\n    Yields a :class:`.Paper` from an article ET node.\n\n    Parameters\n    ----------\n    article : Element\n        ElementTree Element 'article'.\n\n    Returns\n    -------\n    paper : :class:`.Paper`\n    \"\"\"\n    paper = Paper()\n    pdata = dict_from_node(article)\n\n    for key, value in pdata.iteritems():\n\n        datum = pdata[key]\n        if type(datum) is str:\n            datum = unicode(datum)\n        if type(datum) is unicode:\n            datum = unidecode(datum).upper()\n\n        paper[key] = datum\n\n    # Handle author names.\n    adata = _handle_authors(pdata['author'])\n    paper.authors_init = zip(adata[0], adata[1])\n\n    # Handle pubdate.\n    paper['date'] = _handle_pubdate(pdata['pubdate'])\n\n    # Handle pagerange.\n    paper['spage'], paper['epage'] = _handle_pagerange(pdata['pagerange'])\n\n    return paper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_pagerange(pagerange):\n\n    try:\n        pr = re.compile(\"pp\\.\\s([0-9]+)\\-([0-9]+)\")\n        start, end = re.findall(pr, pagerange)[0]\n    except IndexError:\n        start = end = 0\n\n    return unicode(start), unicode(end)", "response": "Yields start and end pages from DfR pagerange field.\n\n    Parameters\n    ----------\n    pagerange : str or unicode\n        DfR-style pagerange, e.g. \"pp. 435-444\".\n\n    Returns\n    -------\n    start : str\n        Start page.\n    end : str\n        End page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_authors(authors):\n\n    aulast = []\n    auinit = []\n    if type(authors) is list:\n        for author in authors:\n            if type(author) is str:\n                author = unicode(author)\n            author = unidecode(author)\n            try:\n                l,i = _handle_author(author)\n                aulast.append(l)\n                auinit.append(i)\n            except ValueError:\n                pass\n    elif type(authors) is str or type(authors) is unicode:\n        if type(authors) is str:\n            authors = unicode(authors)\n        author = unidecode(authors)\n        try:\n            l,i = _handle_author(author)\n            aulast.append(l)\n            auinit.append(i)\n        except ValueError:\n            pass\n    else:\n        raise ValueError(\"authors must be a list or a string\")\n\n    return aulast, auinit", "response": "Handles the authors node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle an author name and returns aulast and auinit from an author s full name.", "response": "def _handle_author(author):\n    \"\"\"\n    Yields aulast and auinit from an author's full name.\n\n    Parameters\n    ----------\n    author : str or unicode\n        Author fullname, e.g. \"Richard L. Nixon\".\n\n    Returns\n    -------\n    aulast : str\n        Author surname.\n    auinit : str\n        Author first-initial.\n    \"\"\"\n\n    lname = author.split(' ')\n\n    try:\n        auinit = lname[0][0]\n        final = lname[-1].upper()\n        if final in ['JR.', 'III']:\n            aulast = lname[-2].upper() + \" \" + final.strip(\".\")\n        else:\n            aulast = final\n    except IndexError:\n        raise ValueError(\"malformed author name\")\n\n    return aulast, auinit"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a fuzzy identifier ayjid from the given parameters.", "response": "def _create_ayjid(aulast=None, auinit=None, date=None, jtitle=None, **kwargs):\n    \"\"\"\n    Convert aulast, auinit, and jtitle into the fuzzy identifier ayjid\n    Returns 'Unknown paper' if all id components are missing (None).\n\n    Parameters\n    ----------\n    Kwargs : dict\n        A dictionary of keyword arguments.\n    aulast : string\n        Author surname.\n    auinit: string\n        Author initial(s).\n    date : string\n        Four-digit year.\n    jtitle : string\n        Title of the journal.\n\n    Returns\n    -------\n    ayj : string\n        Fuzzy identifier ayjid, or 'Unknown paper' if all id components are\n        missing (None).\n\n    \"\"\"\n    if aulast is None:\n        aulast = ''\n    elif isinstance(aulast, list):\n        aulast = aulast[0]\n\n    if auinit is None:\n        auinit = ''\n    elif isinstance(auinit, list):\n        auinit = auinit[0]\n\n    if date is None:\n        date = ''\n\n    if jtitle is None:\n        jtitle = ''\n\n    ayj = aulast + ' ' + auinit + ' ' + unicode(date) + ' ' + jtitle\n\n    if ayj == '   ':\n        ayj = 'Unknown paper'\n\n    return ayj.upper()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef items(self):\n        return GramGenerator(self.path, self.elem,\n                             ignore_hash=self.ignore_hash)", "response": "Returns a generator that produces key value tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef values(self):\n        return GramGenerator(self.path, self.elem, values=True,\n                             ignore_hash=self.ignore_hash)", "response": "Returns a GramGenerator that produces only values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keys(self):\n        return GramGenerator(self.path, self.elem, keys=True,\n                             ignore_hash=self.ignore_hash)", "response": "Returns a GramGenerator that produces only keys."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get(self, i):\n        with open(os.path.join(self.path, self.elem, self.files[i]), 'r') as f:\n            # JSTOR hasn't always produced valid XML.\n            contents = re.sub('(&)(?!amp;)', lambda match: '&amp;', f.read())\n            root = ET.fromstring(contents)\n        doi = root.attrib['id']\n\n        if self.K:  # Keys only.\n            return doi\n\n        grams = []\n        for gram in root.findall(self.elem_xml):\n            text = unidecode(unicode(gram.text.strip()))\n            if ( not self.ignore_hash or '#' not in list(text) ):\n                c = ( text, number(gram.attrib['weight']) )\n                grams.append(c)\n\n        if self.V:  # Values only.\n            return grams\n\n        return doi, grams", "response": "Retrieve data for the ith file in the dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a corpus file for the current instance of the class.", "response": "def _generate_corpus(self):\n        \"\"\"\n        Writes a corpus to disk amenable to MALLET topic modeling.\n        \"\"\"\n\n        target = self.temp + 'mallet'\n        paths = write_documents(self.corpus, target, self.featureset_name,\n                                ['date', 'title'])\n        self.corpus_path, self.metapath = paths\n\n        self._export_corpus()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls MALLET s import - file method.", "response": "def _export_corpus(self):\n        \"\"\"\n        Calls MALLET's `import-file` method.\n        \"\"\"\n        # bin/mallet import-file --input /Users/erickpeirson/mycorpus_docs.txt\n        #     --output mytopic-input.mallet --keep-sequence --remove-stopwords\n\n        if not os.path.exists(self.mallet_bin):\n            raise IOError(\"MALLET path invalid or non-existent.\")\n        self.input_path = os.path.join(self.temp, \"input.mallet\")\n\n        exit = subprocess.call([\n                self.mallet_bin,\n                'import-file',\n                '--input', self.corpus_path,\n                '--output', self.input_path,\n                '--keep-sequence',          # Required for LDA.\n                '--remove-stopwords'])      # Probably redundant.\n\n        if exit != 0:\n            msg = \"MALLET import-file failed with exit code {0}.\".format(exit)\n            raise RuntimeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning MALLET s train - topic method.", "response": "def run(self, **kwargs):\n        \"\"\"\n        Calls MALLET's `train-topic` method.\n        \"\"\"\n        #$ bin/mallet train-topics --input mytopic-input.mallet\n        #> --num-topics 100\n        #> --output-doc-topics /Users/erickpeirson/doc_top\n        #> --word-topic-counts-file /Users/erickpeirson/word_top\n        #> --output-topic-keys /Users/erickpeirson/topic_keys\n\n        if not os.path.exists(self.mallet_bin):\n            raise IOError(\"MALLET path invalid or non-existent.\")\n\n        for attr in ['Z', 'max_iter']:\n            if not hasattr(self, attr):\n                raise AttributeError('Please set {0}'.format(attr))\n\n        self.ll = []\n        self.num_iters = 0\n        logger.debug('run() with k={0} for {1} iterations'.format(self.Z, self.max_iter))\n\n        prog = re.compile(u'\\<([^\\)]+)\\>')\n        ll_prog = re.compile(r'(\\d+)')\n        p = subprocess.Popen([\n                    self.mallet_bin,\n                    'train-topics',\n                    '--input', self.input_path,\n                    '--num-topics', unicode(self.Z),\n                    '--num-iterations', unicode(self.max_iter),\n                    '--output-doc-topics', self.dt,\n                    '--word-topic-counts-file', self.wt,\n                    '--output-model', self.om],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE)\n\n        # Handle output of MALLET in real time.\n        while p.poll() is None:\n            l = p.stderr.readline()\n\n            # Keep track of LL/topic.\n            try:\n                this_ll = float(re.findall(u'([-+]\\d+\\.\\d+)', l)[0])\n                self.ll.append(this_ll)\n            except IndexError:  # Not every line will match.\n                pass\n\n            # Keep track of modeling progress.\n            try:\n                this_iter = float(prog.match(l).groups()[0])\n                progress = int(100. * this_iter/self.max_iter)\n                print 'Modeling progress: {0}%.\\r'.format(progress),\n            except AttributeError:  # Not every line will match.\n                pass\n\n        self.num_iters += self.max_iter\n        self.load()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the theta from a file.", "response": "def _read_theta(self, dt):\n        \"\"\"\n        Used by :func:`.from_mallet` to reconstruct theta posterior\n        distributions.\n\n        Returns\n        -------\n        td : Numpy array\n            Rows are documents, columns are topics. Rows sum to ~1.\n        \"\"\"\n\n        self.theta = FeatureSet()\n\n        with open(dt, \"rb\") as f:\n            i = -1\n            reader = csv.reader(f, delimiter='\\t')\n            for line in reader:\n                i += 1\n                if i == 0:\n                    continue     # Avoid header row.\n\n                d, id, t = int(line[0]), unicode(line[1]), line[2:]\n                feature = Feature([(int(t[i]), float(t[i + 1]))\n                                   for i in xrange(0, len(t) - 1, 2)])\n                self.theta.add(id, feature)\n\n        self.corpus.features['topics'] = self.theta\n        return self.theta"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the phi posterior distributions from a file.", "response": "def _read_phi(self, wt):\n        \"\"\"\n        Used by :func:`.from_mallet` to reconstruct phi posterior distributions.\n\n        Returns\n        -------\n        wt : Numpy array\n            Rows are topics, columns are words. Rows sum to ~1.\n        \"\"\"\n\n        self.vocabulary = {}\n        phi_features = {}\n\n        # TODO: make this encoding-safe.\n        with open(wt, \"r\") as f:\n            reader = csv.reader(f, delimiter=' ')\n            topics = defaultdict(list)\n            for line in reader:\n                w, term = int(line[0]), unicode(line[1])\n                self.vocabulary[w] = term\n\n                for l in line[2:]:\n                    k, c = l.split(':')    # Topic and assignment count.\n                    topics[int(k)].append((w, int(c)))\n\n        for k, data in topics.iteritems():\n            nfeature = Feature(data).norm\n\n            phi_features[k] = nfeature\n        self.phi = FeatureSet(phi_features)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the top topn topics in document d.", "response": "def topics_in(self, d, topn=5):\n        \"\"\"\n        List the top ``topn`` topics in document ``d``.\n        \"\"\"\n        return self.theta.features[d].top(topn)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist the top n words for topic k.", "response": "def list_topic(self, k, Nwords=10):\n        \"\"\"\n        List the top ``topn`` words for topic ``k``.\n\n\n        Examples\n        --------\n\n        .. code-block:: python\n\n           >>> model.list_topic(1, Nwords=5)\n           [ 'opposed', 'terminates', 'trichinosis', 'cistus', 'acaule' ]\n\n        \"\"\"\n\n        return [(self.vocabulary[w], p) for w, p\n                in self.phi.features[k].top(Nwords)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_topics(self, Nwords=10):\n        return [(k, self.list_topic(k, Nwords)) for k in xrange(len(self.phi))]", "response": "List the top Nwords words for each topic."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting the top Nwords words for each topic.", "response": "def print_topics(self, Nwords=10):\n        \"\"\"\n        Print the top ``Nwords`` words for each topic.\n        \"\"\"\n        print('Topic\\tTop %i words' % Nwords)\n        for k, words in self.list_topics(Nwords):\n            print(unicode(k).ljust(3) + '\\t' + ' '.join(list(zip(*words))[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the representation of the topic k in the corpus over time.", "response": "def topic_over_time(self, k, mode='counts', slice_kwargs={}):\n        \"\"\"\n        Calculate the representation of topic ``k`` in the corpus over time.\n        \"\"\"\n\n        return self.corpus.feature_distribution('topics', k, mode=mode,\n                                                **slice_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_index(self, paper):\n        if self.index_by is None or not hasattr(paper, self.index_by):\n            if not hasattr(paper, 'hashIndex'): # Generate a new index for this paper.\n                m = hashlib.md5()\n\n                # If we dont have author name then we just use the title of the paper\n                # to generate unique identifier.\n                if paper.authors is None:\n                    hashable = paper.title\n                else:\n                    if hasattr(paper, 'title'):\n                        title = paper.title\n                    else:\n                        title = ''\n                    if len(paper.authors) == 0:\n                        hashable = title\n                    else:\n                        authors = list(zip(*paper.authors))[0]\n                        hashable = u' '.join(list([title] + [l + f for l, f in authors]))\n\n                m.update(hashable.encode('utf-8'))\n                setattr(paper, 'hashIndex', m.hexdigest())\n            return getattr(paper, 'hashIndex')\n        identifier = getattr(paper, self.index_by)\n        if type(identifier) is list:\n            identifier = identifier[0]\n        if self.index_by == 'link':\n            _, identifier = os.path.split(identifier)\n        return identifier", "response": "Generate a unique identifier for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index_feature(self, feature_name, tokenize=lambda x: x, structured=False):\n        self._init_featureset(feature_name, structured=structured)\n\n        for paper in self.papers:\n            self.index_paper_by_feature(paper, feature_name, tokenize, structured)", "response": "Index a feature in each paper."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindex the instance by the attribute attr.", "response": "def index(self, attr):\n        \"\"\"\n        Indexes the :class:`.Paper`\\s in this :class:`.Corpus` instance\n        by the attribute ``attr``.\n\n        New indices are added to :attr:`.indices`\\.\n\n        Parameters\n        ----------\n        attr : str\n            The name of a :class:`.Paper` attribute.\n\n        \"\"\"\n\n        for i, paper in self.indexed_papers.iteritems():\n            self.index_paper_by_attr(paper, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, selector, index_only=False):\n\n        papers = []\n        if type(selector) is tuple: # Select papers by index.\n            index, value = selector\n            if type(value) is list:  # Set of index values.\n                papers = [p for v in value for p in self.select((index, v), index_only=index_only)]\n            else:\n                if value in self.indices[index]:\n                    if index_only:\n                        papers = self.indices[index][value]\n                    else:\n                        papers = [self.indexed_papers[p] for p  # Single index value.\n                                  in self.indices[index][value]]\n                else:\n                    papers = []\n        elif type(selector) is list:\n            if selector[0] in self.indexed_papers:\n                # Selector is a list of primary indices.\n                if index_only:\n                    papers = selector\n                else:\n                    papers = [self.indexed_papers[s] for s in selector]\n            elif type(selector[0]) is int:\n                if index_only:\n                    papers = [self.indexed_papers.keys()[i] for i in selector]\n                else:\n                    papers = [self.papers[i] for i in selector]\n        elif type(selector) is int:\n            if index_only:\n                papers = self.indexed_papers.keys()[selector]\n            else:\n                papers = self.papers[selector]\n\n        elif type(selector) in [str, unicode]:\n            if selector in self.indexed_papers:\n                if index_only:\n                    papers = selector\n                else:\n                    papers = self.indexed_papers[selector]\n        return papers", "response": "Returns a subset of the current object for the given selector criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a generator that yields tuples for each of the sequential time windows in the corpus.", "response": "def slice(self, window_size=1, step_size=1, cumulative=False,\n              count_only=False, subcorpus=True, feature_name=None):\n        \"\"\"\n        Returns a generator that yields ``(key, subcorpus)`` tuples for\n        sequential time windows.\n\n        Two common slicing patterns are the \"sliding time-window\" and the\n        \"time-period\" patterns. Whereas time-period slicing divides the corpus\n        into subcorpora by sequential non-overlapping time periods, subcorpora\n        generated by time-window slicing can overlap.\n\n        .. figure:: _static/images/bibliocoupling/timeline.timeslice.png\n           :width: 400\n           :align: center\n\n           **Time-period** slicing, with a window-size of 4 years.\n\n        .. figure:: _static/images/bibliocoupling/timeline.timewindow.png\n           :width: 400\n           :align: center\n\n           **Time-window** slicing, with a window-size of 4 years and a\n           step-size of 1 year.\n\n        *Sliding time-window* -- Set ``step_size=1``, and ``window_size`` to\n        the desired value.\n        *Time-period* -- ``step_size`` and ``window_size`` should have the same\n        value.\n\n        The value of ``key`` is always the first year in the slice.\n\n        Examples\n        --------\n        .. code-block:: python\n\n           >>> from tethne.readers.wos import read\n           >>> corpus = read('/path/to/data')\n           >>> for key, subcorpus in corpus.slice():\n           ...     print key, len(subcorpus)\n           2005, 5\n           2006, 5\n\n        Parameters\n        ----------\n        window_size : int\n            (default: 1) Size of the time window, in years.\n        step_size : int\n            (default: 1) Number of years to advance window at each step.\n\n        Returns\n        -------\n        generator\n        \"\"\"\n\n        if 'date' not in self.indices:\n            self.index('date')\n\n        start = min(self.indices['date'].keys())\n        end = max(self.indices['date'].keys())\n\n        while start <= end - (window_size - 1):\n            selector = ('date', range(start, start + window_size, 1))\n            if cumulative:\n                year = start + window_size\n            else:\n                year = start\n            if count_only:\n                yield year, len(self.select(selector))\n            elif feature_name:\n                yield year, self.subfeatures(selector, feature_name)\n            elif subcorpus:\n                yield year, self.subcorpus(selector)\n            else:\n                yield year, self.select(selector)\n            if cumulative:\n                window_size += step_size\n            else:\n                start += step_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distribution(self, **slice_kwargs):\n        values = []\n        keys = []\n\n        for key, size in self.slice(count_only=True, **slice_kwargs):\n            values.append(size)\n            keys.append(key)\n        return keys, values", "response": "Calculates the distribution of the papers in each slice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feature_distribution(self, featureset_name, feature, mode='counts',\n                             **slice_kwargs):\n        \"\"\"\n        Calculates the distribution of a feature across slices of the corpus.\n\n        Examples\n        --------\n        .. code-block:: python\n\n           >>> corpus.feature_distribution(featureset_name='citations', \\\n           ...                             feature='DOLE RJ 1965 CELL', \\\n           ...                             step_size=1, window_size=1)\n           [2, 15, 25, 1]\n\n        Parameters\n        ----------\n        featureset_name : str\n            Name of a :class:`.FeatureSet` in the :class:`.Corpus`\\.\n        feature : str\n            Name of the specific feature of interest. E.g. if\n            ``featureset_name='citations'``, then ``feature`` could be\n            something like ``'DOLE RJ 1965 CELL'``.\n        mode : str\n            (default: ``'counts'``) If set to ``'counts'``, values will be the\n            sum of all count values for the feature in each slice. If set to\n            ``'documentCounts'``, values will be the number of papers in which\n            the feature occurs in each slice.\n        slice_kwargs : kwargs\n            Keyword arguments to be passed to :meth:`.Corpus.slice`\\.\n\n        Returns\n        -------\n        list\n        \"\"\"\n\n        values = []\n        keys = []\n        fset = self.features[featureset_name]\n\n        for key, papers in self.slice(subcorpus=False, **slice_kwargs):\n            allfeatures = [v for v\n                           in chain(*[fset.features[self._generate_index(p)]\n                                      for p in papers\n                                      if self._generate_index(p)\n                                      in fset.features])]\n\n            if len(allfeatures) < 1:\n                keys.append(key)\n                values.append(0.)\n                continue\n\n            count = 0.\n            for elem, v in allfeatures:\n                if elem != feature:\n                    continue\n                if mode == 'counts':\n                    count += v\n                else:\n                    count += 1.\n            values.append(count)\n            keys.append(key)\n        return keys, values", "response": "Calculates the distribution of a specific feature across a corpus."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef top_features(self, featureset_name, topn=20, by='counts',\n                     perslice=False, slice_kwargs={}):\n        \"\"\"\n        Retrieves the top ``topn`` most numerous features in the corpus.\n\n        Parameters\n        ----------\n        featureset_name : str\n            Name of a :class:`.FeatureSet` in the :class:`.Corpus`\\.\n        topn : int\n            (default: ``20``) Number of features to return.\n        by : str\n            (default: ``'counts'``) If ``'counts'``, uses the sum of feature\n            count values to rank features. If ``'documentCounts'``, uses the\n            number of papers in which features occur.\n        perslice : bool\n            (default: False) If True, retrieves the top ``topn`` features in\n            each slice.\n        slice_kwargs : kwargs\n            If ``perslice=True``, these keyword arguments are passed to\n            :meth:`.Corpus.slice`\\.\n        \"\"\"\n\n        if perslice:\n            return [(k, subcorpus.features[featureset_name].top(topn, by=by))\n                    for k, subcorpus in self.slice(**slice_kwargs)]\n        return self.features[featureset_name].top(topn, by=by)", "response": "Returns the top n most numerous features in the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subcorpus(self, selector):\n        subcorpus = self.__class__(self[selector],\n                           index_by=self.index_by,\n                           index_fields=self.indices.keys(),\n                           index_features=self.features.keys())\n\n        return subcorpus", "response": "Returns a new subcorpus object with the specified criteria"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge(corpus_1, corpus_2, match_by=['ayjid'], match_threshold=1.,\n          index_by='ayjid'):\n    \"\"\"\n    Combines two :class:`.Corpus` instances.\n\n    The default behavior is to match :class:`.Paper`\\s using the fields in\n    ``match_by``\\. If several fields are specified, ``match_threshold`` can be\n    used to control how well two :class:`.Paper`\\s must match to be combined.\n\n    Alternatively, ``match_by`` can be a callable object that accepts two\n    :class:`.Paper` instances, and returns bool. This allows for more complex\n    evaluations.\n\n    Where two matched :class:`.Paper`\\s have values for the same field, values\n    from the :class:`.Paper` instance in ``corpus_1`` will always be  preferred.\n\n    Parameters\n    ----------\n    corpus_1 : :class:`.Corpus`\n        Values from this :class:`.Corpus` will always be preferred in cases of\n        conflict.\n    corpus_2 : :class:`.Corpus`\n    match_by : list or callable\n        Either a list of fields used to evaluate whether or not two\n        :class:`.Paper`\\s should be combined, **OR** a callable that accepts\n        two :class:`.Paper` instances and returns bool.\n    match_threshold : float\n        if ``match_by`` is a list containing more than one field, specifies the\n        proportion of fields that must match for two :class:`.Paper` instances\n        to be combined.\n    index_by : str\n        The field to use as the primary indexing field in the new\n        :class:`.Corpus`\\. Default is `ayjid`, since this is virtually always\n        available.\n\n    Returns\n    -------\n    combined : :class:`.Corpus`\n\n    Examples\n    --------\n\n    .. code-block:: python\n\n       >>> from tethne.readers import wos, dfr, merge\n       >>> wos_corpus = wos.read(\"/Path/to/data1.txt\")\n       >>> dfr_corpus = dfr.read(\"/Path/to/DfR\")\n       >>> corpus = merge(wos_corpus, dfr_corpus)\n\n    \"\"\"\n\n    def norm(value):\n        if type(value) in [str, unicode]:\n            return value.strip().lower()\n        return value\n\n\n    combined = []\n    exclude_1 = []\n    exclude_2 = []\n\n    # Attempt to match Papers\n    for paper_1 in corpus_1:\n        for paper_2 in corpus_2:\n            # The user can provide their own matching logic. In this case,\n            #  match_threshold is ignored.\n            if callable(match_by):\n                match = match_by(paper_1, paper_2)\n\n            # Otherwise we match using the fields in ``match_by``.\n            else:\n                matches = 0.\n                for field in match_by:\n                    if hasattr(paper_1, field) and hasattr(paper_2, field):\n                        value_1 = norm(getattr(paper_1, field))\n                        value_2 = norm(getattr(paper_2, field))\n                        if value_1 == value_2:\n                            matches += 1.\n                match = matches/len(match_by) >= match_threshold\n\n            # Not every field needs to match precisely;\n            if match:\n                paper_new = Paper()\n                # We add values from paper_2 first, so that...\n                for key, value in paper_2.__dict__.iteritems():\n                    if value not in ['', [], None]:\n                        paper_new[key] = value\n\n                # ...values from paper_1 will override values from paper_2.\n                for key, value in paper_1.__dict__.iteritems():\n                    if value not in ['', [], None]:\n                        paper_new[key] = value\n\n                # We assemble all papers before creating a new Corpus, so that\n                #  indexing happens all in one shot.\n                combined.append(paper_new)\n\n                # Flag matched papers for exclusion.\n                exclude_1.append(corpus_1._generate_index(paper_1))\n                exclude_2.append(corpus_2._generate_index(paper_2))\n\n\n    # Include papers that were not matched.\n    combined += [paper for paper in corpus_1\n                 if corpus_1._generate_index(paper) not in exclude_1]\n    combined += [paper for paper in corpus_2\n                 if corpus_2._generate_index(paper) not in exclude_2]\n\n    # Here indexing happens all at once, with the new ``index_by`` field.\n    corpus = Corpus(combined, index_by=index_by)\n\n    featuresets = {}\n    for featureset_name, featureset_1 in corpus_1.features.iteritems():\n        # We avoid FeatureSets that were generated during the indexing process\n        #  (e.g. 'citations', 'authors').\n        if featureset_name in featuresets or featureset_name in corpus.features:\n            continue\n\n        features = {}\n\n        # Can be FeatureSet or StructuredFeatureSet.\n        fclass = type(featureset_1)\n        if featureset_name in corpus_2.features:\n            featureset_2 = corpus_2.features[featureset_name]\n            for index, feature in featureset_2.iteritems():\n                features[getattr(corpus_2[index], index_by)] = feature\n\n        # Features from corpus_1 will be preferred over those from corpus_2.\n        for index, feature in featureset_1.iteritems():\n            features[getattr(corpus_1[index], index_by)] = feature\n\n        featuresets[featureset_name] = fclass(features)\n\n    # FeatureSets unique to corpus_2.\n    for featureset_name, featureset_2 in corpus_2.features.iteritems():\n        # We avoid FeatureSets that were generated during the indexing process\n        #  (e.g. 'citations', 'authors').\n        if featureset_name in featuresets or featureset_name in corpus.features:\n            continue\n\n        features = {}\n\n        # Can be FeatureSet or StructuredFeatureSet.\n        fclass = type(featureset_2)\n        for index, feature in featureset_2.iteritems():\n            features[getattr(corpus_2[index], index_by)] = feature\n\n        featuresets[featureset_name] = fclass(features)\n\n    corpus.features.update(featuresets)\n\n    return corpus", "response": "Merge two corpus objects into one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of authors of the current paper instance.", "response": "def authors(self):\n        \"\"\"\n        Get the authors of the current :class:`.Paper` instance.\n\n        Uses ``authors_full`` if it is available. Otherwise, uses\n        ``authors_init``.\n\n        Returns\n        -------\n        authors : :class:`.Feature`\n            Author names are in the format ``LAST F``.\n        \"\"\"\n\n        if hasattr(self, 'authors_full'):\n            return self.authors_full\n        elif hasattr(self, 'authors_init'):\n            return self.authors_init\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all citations in this object.", "response": "def citations(self):\n        \"\"\"\n        Cited references as a :class:`.Feature`\\.\n\n        Returns\n        -------\n        citations : :class:`.Feature`\n        \"\"\"\n\n        if hasattr(self, 'citedReferences'):\n            return [cr.ayjid for cr in self.citedReferences if cr is not None]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _forward(X, s=1.1, gamma=1., k=5):\n    X = list(X)\n\n    def alpha(i):\n        return (n/T)*(s**i)\n\n    def tau(i, j):\n        if j > i:\n            return (j-i)*gamma*log(n)\n        return 0.\n\n    def f(j, x):\n        return alpha(j) * exp(-1. * alpha(j) * x)\n\n    def C(j, t):\n        if j == 0 and t == 0:\n            return 0.\n        elif t == 0:\n            return float(\"inf\")\n\n        C_tau = min([C_values[l][t-1] + tau(l, j) for l in xrange(k)])\n        return (-1. * log(f(j,X[t]))) + C_tau\n\n    T = sum(X)\n    n = len(X)\n\n    # C() requires default (0) values, so we construct the \"array\" in advance.\n    C_values = [[0 for t in xrange(len(X))] for j in xrange(k)]\n    for j in xrange(k):\n        for t in xrange(len(X)):\n            C_values[j][t] = C(j,t)\n\n    # Find the optimal state sequence.\n    states = [argmin([c[t] for c in C_values]) for t in xrange(n)]\n    return states", "response": "Forward function for burstness automaton HMM."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef burstness(corpus, featureset_name, features=[], k=5, topn=20,\n              perslice=False, normalize=True, **kwargs):\n    \"\"\"\n    Estimate burstness profile for the ``topn`` features (or ``flist``) in\n    ``feature``.\n\n    Uses the popular burstness automaton model inroduced by `Kleinberg (2002)\n    <http://www.cs.cornell.edu/home/kleinber/bhs.pdf>`_.\n\n    Parameters\n    ----------\n    corpus : :class:`.Corpus`\n    feature : str\n        Name of featureset in ``corpus``. E.g. ``'citations'``.\n    k : int\n        (default: 5) Number of burst states.\n    topn : int or float {0.-1.}\n        (default: 20) Number (int) or percentage (float) of top-occurring\n        features to return. If ``flist`` is provided, this parameter is ignored.\n    perslice : bool\n        (default: False) If True, loads ``topn`` features per slice. Otherwise,\n        loads ``topn`` features overall. If ``flist`` is provided, this\n        parameter is ignored.\n    flist : list\n        List of features. If provided, ``topn`` and ``perslice`` are ignored.\n    normalize : bool\n        (default: True) If True, burstness is expressed relative to the hightest\n        possible state (``k-1``). Otherwise, states themselves are returned.\n    kwargs : kwargs\n        Parameters for burstness automaton HMM.\n\n    Returns\n    -------\n    B : dict\n        Keys are features, values are tuples of ( dates, burstness )\n\n    Examples\n    --------\n\n    .. code-block:: python\n\n       >>> from tethne.analyze.corpus import burstness\n       >>> B = burstness(corpus, 'abstractTerms', flist=['process', 'method']\n       >>> B['process']\n       ([1990, 1991, 1992, 1993], [0., 0.4, 0.6, 0.])\n\n    \"\"\"\n\n    # If `features` of interest are not specified, calculate burstness for the\n    #  top `topn` features.\n    if len(features) == 0:\n        T = corpus.top_features(featureset_name, topn=topn, perslice=perslice)\n        if perslice:\n            features = list(set([f[0] for flist in zip(*T)[1] for f in flist]))\n        else:\n            features = list(zip(*T))[0]\n\n    B = {feature: feature_burstness(corpus, featureset_name, feature, k=k,\n                                    normalize=normalize, **kwargs)\n         for feature in features}\n    return B", "response": "Return a burstness profile for the given featureset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feature_burstness(corpus, featureset_name, feature, k=5, normalize=True,\n                      s=1.1, gamma=1., **slice_kwargs):\n    \"\"\"\n    Estimate burstness profile for a feature over the ``'date'`` axis.\n\n    Parameters\n    ----------\n    corpus : :class:`.Corpus`\n    feature : str\n        Name of featureset in ``corpus``. E.g. ``'citations'``.\n    findex : int\n        Index of ``feature`` in ``corpus``.\n    k : int\n        (default: 5) Number of burst states.\n    normalize : bool\n        (default: True) If True, burstness is expressed relative to the hightest\n        possible state (``k-1``). Otherwise, states themselves are returned.\n    kwargs : kwargs\n        Parameters for burstness automaton HMM.\n    \"\"\"\n\n\n    if featureset_name not in corpus.features:\n        corpus.index_feature(featureset_name)\n\n    if 'date' not in corpus.indices:\n        corpus.index('date')\n\n    # Get time-intervals between occurrences.\n    dates = [min(corpus.indices['date'].keys()) - 1]    # Pad start.\n    X_ = [1.]\n\n    years, values = corpus.feature_distribution(featureset_name, feature)\n    for year, N in izip(years, values):\n        if N == 0:\n            continue\n\n        if N > 1:\n            if year == dates[-1] + 1:\n                for n in xrange(int(N)):\n                    X_.append(1./N)\n                    dates.append(year)\n            else:\n                X_.append(float(year - dates[-1]))\n                dates.append(year)\n                for n in xrange(int(N) - 1):\n                    X_.append(1./(N - 1))\n                    dates.append(year)\n        else:\n            X_.append(float(year - dates[-1]))\n            dates.append(year)\n\n    # Get optimum state sequence.\n    st = _forward(map(lambda x: x*100, X_), s=s, gamma=gamma, k=k)\n\n    # Bin by date.\n    A = defaultdict(list)\n    for i in xrange(len(X_)):\n        A[dates[i]].append(st[i])\n\n    # Normalize.\n    if normalize:\n        A = {key: mean(values)/k for key, values in A.items()}\n    else:\n        A = {key: mean(values) for key, values in A.items()}\n\n    D = sorted(A.keys())\n    return D[1:], [A[d] for d in D[1:]]", "response": "Estimate burstness profile for a feature in a corpus."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the sigma of a given feature set in a given corpus.", "response": "def sigma(G, corpus, featureset_name, B=None, **kwargs):\n    \"\"\"\n    Calculate sigma (from `Chen 2009 <http://arxiv.org/pdf/0904.1439.pdf>`_)\n    for all of the nodes in a :class:`.GraphCollection`\\.\n\n    You can set parameters for burstness estimation using ``kwargs``:\n\n    =========   ===============================================================\n    Parameter   Description\n    =========   ===============================================================\n    s           Scaling parameter ( > 1.)that controls graininess of burst\n                detection. Lower values make the model more sensitive. Defaults\n                to 1.1.\n    gamma       Parameter that controls the 'cost' of higher burst states.\n                Defaults to 1.0.\n    k           Number of burst states. Defaults to 5.\n    =========   ===============================================================\n\n    Parameters\n    ----------\n    G : :class:`.GraphCollection`\n    corpus : :class:`.Corpus`\n    feature : str\n        Name of a featureset in `corpus`.\n\n\n    Examples\n    --------\n\n    Assuming that you have a :class:`.Corpus` generated from WoS data that has\n    been sliced by ``date``.\n\n    .. code-block:: python\n\n       >>> # Generate a co-citation graph collection.\n       >>> from tethne import GraphCollection\n       >>> kwargs = { 'threshold':2, 'topn':100 }\n       >>> G = GraphCollection()\n       >>> G.build(corpus, 'date', 'papers', 'cocitation', method_kwargs=kwargs)\n\n       >>> # Calculate sigma. This may take several minutes, depending on the\n       >>> #  size of your co-citaiton graph collection.\n       >>> from tethne.analyze.corpus import sigma\n       >>> G = sigma(G, corpus, 'citations')\n\n       >>> # Visualize...\n       >>> from tethne.writers import collection\n       >>> collection.to_dxgmml(G, '~/cocitation.xgmml')\n\n    In the visualization below, node and label sizes are mapped to ``sigma``,\n    and border width is mapped to ``citations``.\n\n    .. figure:: _static/images/cocitation_sigma2.png\n       :width: 600\n       :align: center\n\n    \"\"\"\n    if 'date' not in corpus.indices:\n        corpus.index('date')\n\n    # Calculate burstness if not provided.\n    if not B:\n        B = burstness(corpus, featureset_name, features=G.nodes(), **kwargs)\n\n    Sigma = {}      # Keys are dates (from GraphCollection), values are\n                    #  node:sigma dicts.\n    for key, graph in G.iteritems():\n        centrality = nx.betweenness_centrality(graph)\n        sigma = {}  # Sigma values for all features in this year.\n        attrs = {}  # Sigma values for only those features in this graph.\n        for n_, burst in B.iteritems():\n            burst = dict(list(zip(*burst)))     # Reorganize for easier lookup.\n\n            # Nodes are indexed as integers in the GraphCollection.\n            n = G.node_lookup[n_]\n\n            # We have burstness values for years in which the feature ``n``\n            #  occurs, and we have centrality values for years in which ``n``\n            #  made it into the graph.\n            if n in graph.nodes() and key in burst:\n                sigma[n] = ((centrality[n] + 1.) ** burst[key]) - 1.\n                attrs[n] = sigma[n]\n\n        # Update graph with sigma values.\n        nx.set_node_attributes(graph, 'sigma', attrs)\n        Sigma[key] = sigma\n\n    # Invert results and update the GraphCollection.master_graph.\n    # TODO: is there a more efficient way to do this?\n    inverse = defaultdict(dict)\n    for gname, result in Sigma.iteritems():\n        if hasattr(result, '__iter__'):\n            for n, val in result.iteritems():\n                inverse[n].update({gname: val})\n    nx.set_node_attributes(G.master_graph, 'sigma', inverse)\n\n    # We want to return results in the same format as burstness(); with node\n    #  labels as keys; values are tuples ([years...], [sigma...]).\n    return {n: list(zip(*G.node_history(G.node_lookup[n], 'sigma').items()))\n            for n in B.keys()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cocitation(corpus, min_weight=1, edge_attrs=['ayjid', 'date'], **kwargs):\n    return cooccurrence(corpus, 'citations', min_weight=min_weight,\n                        edge_attrs=edge_attrs, **kwargs)", "response": "Generate a co - occurrence network for a corpus."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all tokens divided into the chunks in context context.", "response": "def context_chunks(self, context):\n        \"\"\"\n        Retrieves all tokens, divided into the chunks in context ``context``.\n\n        Parameters\n        ----------\n        context : str\n            Context name.\n\n        Returns\n        -------\n        chunks : list\n            Each item in ``chunks`` is a list of tokens.\n        \"\"\"\n        N_chunks = len(self.contexts[context])\n        chunks = []\n        for j in xrange(N_chunks):\n            chunks.append(self.context_chunk(context, j))\n        return chunks"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the tokens in the jth chunk of context.", "response": "def context_chunk(self, context, j):\n        \"\"\"\n        Retrieve the tokens in the ``j``th chunk of context ``context``.\n\n        Parameters\n        ----------\n        context : str\n            Context name.\n        j : int\n            Index of a context chunk.\n\n        Returns\n        -------\n        chunk : list\n            List of tokens in the selected chunk.\n        \"\"\"\n\n        N_chunks = len(self.contexts[context])\n        start = self.contexts[context][j]\n        if j == N_chunks - 1:\n            end = len(self)\n        else:\n            end = self.contexts[context][j+1]\n        return [self[i] for i in xrange(start, end)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new context to the hierarchy.", "response": "def add_context(self, name, indices, level=None):\n        \"\"\"\n        Add a new context level to the hierarchy.\n\n        By default, new contexts are added to the lowest level of the hierarchy.\n        To insert the context elsewhere in the hierarchy, use the ``level``\n        argument. For example, ``level=0`` would insert the context at the\n        highest level of the hierarchy.\n\n        Parameters\n        ----------\n        name : str\n        indices : list\n            Token indices at which each chunk in the context begins.\n        level : int\n            Level in the hierarchy at which to insert the context. By default,\n            inserts context at the lowest level of the hierarchy\n\n        \"\"\"\n\n        self._validate_context((name, indices))\n\n        if level is None:\n            level = len(self.contexts_ranked)\n        self.contexts_ranked.insert(level, name)\n        self.contexts[name] = indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef top(self, topn=10):\n        return [self[i] for i in argsort(list(zip(*self))[1])[::-1][:topn]]", "response": "Return a list of the top n features in this set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef top(self, topn, by='counts'):\n\n        if by not in ['counts', 'documentCounts']:\n            raise NameError('kwarg `by` must be \"counts\" or \"documentCounts\"')\n\n        cvalues = getattr(self, by)\n        order = argsort(list(cvalues.values()))[::-1][:topn]\n        keys = list(cvalues.keys())\n        return [(self.index[keys[i]], cvalues[keys[i]]) for i in order]", "response": "Return a list of top n features in the feature set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef context_chunks(self, context):\n\n        chunks = []\n        papers = []\n        for paper, feature in self.features.iteritems():\n            if context in feature.contexts:\n                new_chunks = feature.context_chunks(context)\n            else:\n                new_chunks = list(feature)\n            indices = range(len(chunks), len(chunks) + len(new_chunks))\n            papers.append((paper, indices))\n            chunks += new_chunks\n        return papers, chunks", "response": "Returns all tokens divided into the chunks in context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a transformation to tokens in this : class :. FeatureSet.", "response": "def transform(self, func):\n        \"\"\"\n        Apply a transformation to tokens in this :class:`.FeatureSet`\\.\n\n        Parameters\n        ----------\n        func : callable\n            Should take four parameters: token, value in document (e.g. count),\n            value in :class:`.FeatureSet` (e.g. overall count), and document\n            count (i.e. number of documents in which the token occurs). Should\n            return a new numeric (int or float) value, or None. If value is 0\n            or None, the token will be excluded.\n\n        Returns\n        -------\n        :class:`.FeatureSet`\n\n        Examples\n        --------\n\n        Apply a tf*idf transformation.\n\n        .. code-block:: python\n\n           >>> words = corpus.features['words']\n           >>> def tfidf(f, c, C, DC):\n           ... tf = float(c)\n           ... idf = log(float(len(words.features))/float(DC))\n           ... return tf*idf\n           >>> corpus.features['words_tfidf'] = words.transform(tfidf)\n\n        \"\"\"\n        features = {}\n        for i, feature in self.features.iteritems():\n            feature_ = []\n            for f, v in feature:\n                t = self.lookup[f]\n                v_ = func(f, v, self.counts[t], self.documentCounts[t])\n                if v_:\n                    feature_.append((f, v_))\n            features[i] = Feature(feature_)\n\n        return FeatureSet(features)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(self, corpus, method, slice_kwargs={}, method_kwargs={}):\n        if not hasattr(method, '__call__'):\n            if not hasattr(networks, method):\n                raise NameError('No such method')\n            method = getattr(networks, method)\n        for key, subcorpus in corpus.slice(**slice_kwargs):\n            graph = method(subcorpus, **method_kwargs)\n            self.add(key, graph)", "response": "Builds a set of networkx. Graph objects from a corpus and a method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new entry to the internal dictionary.", "response": "def add(self, name, graph):\n        \"\"\"\n        Index and add a :ref:`networkx.Graph <networkx:graph>` to the\n        :class:`.GraphCollection`.\n\n        Parameters\n        ----------\n        name : hashable\n            Unique name used to identify the `graph`.\n        graph : :ref:`networkx.Graph <networkx:graph>`\n\n        Raises\n        ------\n        ValueError\n            If `name` has already been used in this :class:`.GraphCollection`\\.\n        \"\"\"\n        if name in self:\n            raise ValueError(\"{0} exists in this GraphCollection\".format(name))\n        elif hasattr(self, unicode(name)):\n            raise ValueError(\"Name conflicts with an existing attribute\")\n\n        indexed_graph = self.index(name, graph)\n\n        # Add all edges to the `master_graph`.\n        for s, t, attrs in indexed_graph.edges(data=True):\n            attrs.update({'graph': name})\n            self.master_graph.add_edge(s, t, **attrs)\n\n        # Add all node attributes to the `master_graph`.\n        for n, attrs in indexed_graph.nodes(data=True):\n            for k,v in attrs.iteritems():\n                if k not in self.master_graph.node[n]:\n                    self.master_graph.node[n][k] = {}\n                self.master_graph.node[n][k][name] = v\n\n        dict.__setitem__(self, name, indexed_graph)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nindex any new nodes in graph and relabel the nodes in graph using the index.", "response": "def index(self, name, graph):\n        \"\"\"\n        Index any new nodes in `graph`, and relabel the nodes in `graph` using\n        the index.\n\n        Parameters\n        ----------\n        name : hashable\n            Unique name used to identify the `graph`.\n        graph : networkx.Graph\n\n        Returns\n        -------\n        indexed_graph : networkx.Graph\n        \"\"\"\n        nodes = graph.nodes()\n\n        # Index new nodes.\n        new_nodes = list(set(nodes) - set(self.node_index.values()))\n        start = max(len(self.node_index) - 1, max(self.node_index.keys()))\n        for i in xrange(start, start + len(new_nodes)):\n            n = new_nodes.pop()\n            self.node_index[i], self.node_lookup[n] = n, i\n            self.graphs_containing[n].append(name)\n\n        # Relabel nodes in `graph`.\n        new_labels = {n: self.node_lookup[n] for n in nodes}\n        indexed_graph = nx.relabel.relabel_nodes(graph, new_labels, copy=True)\n\n        return indexed_graph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all nodes in the master graph.", "response": "def nodes(self, data=False, native=True):\n        \"\"\"\n        Returns a list of all nodes in the :class:`.GraphCollection`\\.\n\n        Parameters\n        ----------\n        data : bool\n            (default: False) If True, returns a list of 2-tuples containing\n            node labels and attributes.\n\n        Returns\n        -------\n        nodes : list\n        \"\"\"\n\n        nodes = self.master_graph.nodes(data=data)\n        if native:\n            if data:\n                nodes = [(self.node_index[n], attrs) for n, attrs in nodes]\n            else:\n                nodes = [self.node_index[n] for n in nodes]\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all edges in the master graph.", "response": "def edges(self, data=False, native=True):\n        \"\"\"\n        Returns a list of all edges in the :class:`.GraphCollection`\\.\n\n        Parameters\n        ----------\n        data : bool\n            (default: False) If True, returns a list of 3-tuples containing\n            source and target node labels, and attributes.\n\n        Returns\n        -------\n        edges : list\n        \"\"\"\n        edges = self.master_graph.edges(data=data)\n        if native:\n            if data:\n                edges = [(self.node_index[s], self.node_index[t], attrs)\n                         for s, t, attrs in edges]\n            else:\n                edges = [(self.node_index[s], self.node_index[t])\n                         for s, t in edges]\n        return edges"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the total number of nodes in the master graph.", "response": "def order(self, piecewise=False):\n        \"\"\"\n        Returns the total number of nodes in the :class:`.GraphCollection`\\.\n        \"\"\"\n        if piecewise:\n            return {k: v.order() for k, v in self.items()}\n        return self.master_graph.order()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef size(self, piecewise=False):\n        if piecewise:\n            return {k: v.size() for k, v in self.items()}\n        return self.master_graph.size()", "response": "Returns the total number of edges in the master graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a graph with the edges between each pair of nodes and edges.", "response": "def collapse(self, weight_attr='weight'):\n        \"\"\"\n        Returns a :ref:`networkx.Graph <networkx:graph>` or :class:`networkx.DiGraph` in which\n        the edges between each pair of nodes are collapsed into a single\n        weighted edge.\n        \"\"\"\n\n        if self.directed:\n            graph = nx.DiGraph()\n        else:\n            graph = nx.Graph()\n\n        # Transfer all nodes and attributes.\n        for n, attrs in self.master_graph.nodes(data=True):\n            graph.add_node(n, attrs)\n\n        for s, t, attrs in self.master_graph.edges(data=True):\n            if not graph.has_edge(s, t):\n                graph.add_edge(s, t)\n\n            if 'weight' not in graph[s][t]:\n                graph[s][t]['weight'] = 0.\n            if weight_attr in attrs:\n                graph[s][t]['weight'] += attrs[weight_attr]\n            else:\n                graph[s][t]['weight'] += 1.\n\n            gname = attrs['graph']\n            for k, v in attrs.iteritems():\n                if k in [weight_attr, 'graph']:\n                    continue\n                if k not in graph[s][t]:\n                    graph[s][t][k] = {}\n                graph[s][t][k][gname] = v\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, method_name, mapper=map, invert=False, **kwargs):\n\n        # Find the analysis method, if possible.\n        if hasattr(method_name, '__iter__'):\n            mpath = method_name\n            if type(mpath) in [str, unicode]:\n                mpath = [mpath]\n\n            root = nx\n            while len(mpath) > 0:\n                head = getattr(root, mpath.pop(0))\n            if hasattr(head, '__call__'):\n                method = head\n            else:\n                raise NameError(\"No matching method in NetworkX\")\n\n        elif hasattr(nx, method_name):\n            method = getattr(nx, method_name)\n        else:\n            raise AttributeError('No such method in NetworkX')\n\n        # Farm out the analysis using ``mapper``. This allows us to use\n        #  multiprocessing in the future, or to add pre- or post-processing\n        #  routines.\n        keys, graphs = zip(*self.items())\n        results = mapper(method, graphs, **kwargs)\n\n        # Group the results by graph.\n        by_graph = dict(zip(keys, results))\n\n        # Invert results.\n        inverse = defaultdict(dict)\n        for gname, result in by_graph.iteritems():\n            if hasattr(result, '__iter__'):\n                for n, val in result.iteritems():\n                    inverse[n].update({gname: val})\n\n        if type(list(by_graph.values())[0]) is dict:\n            # Look for a result set that we can inspect.\n            i = 0\n            while True:\n                if len(by_graph.values()[i]) > 0:\n                    inspect = by_graph.values()[i]\n                    break\n                i += 1\n\n            if type(list(inspect.keys())[0]) is tuple:\n                # Results correspond to edges.\n                by_edge = dict(inverse)\n\n                # Set edge attributes in each graph.\n                for graph, attrs in by_graph.iteritems():\n                    nx.set_edge_attributes(self[graph], method_name, attrs)\n\n                # Set edge attributes in the master graph.\n                for (s, t), v in by_edge.iteritems():\n                    for i, attrs in self.master_graph.edge[s][t].iteritems():\n                        val = v[attrs['graph']]\n                        self.master_graph.edge[s][t][i][method_name] = val\n\n                if invert:\n                    return by_edge\n            else:\n                # Results correspond to nodes.\n                by_node = dict(inverse)\n\n                # Set node attributes for each graph.\n                for graph, attrs in by_graph.iteritems():\n                    nx.set_node_attributes(self[graph], method_name, attrs)\n\n                # Store node attributes in the master graph.\n                nx.set_node_attributes(self.master_graph, method_name, by_node)\n\n                if invert:\n                    return by_node\n        return by_graph", "response": "Analyze a method from NetworkX to get the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edge_history(self, source, target, attribute):\n\n        return {attr['graph']: attr[attribute] for i, attr\n                in self.master_graph.edge[source][target].items()}", "response": "Returns a dictionary of attribute vales for each Graph in the master_graph for a single edge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef union(self, weight_attr='_weight'):\n\n        if type(self.master_graph) is nx.MultiDiGraph:\n            graph = nx.DiGraph()\n        else:\n            graph = nx.Graph()\n\n        edge_attrs = defaultdict(list)\n\n        for u, v, a in self.master_graph.edges(data=True):\n            if not graph.has_edge(u, v):\n                graph.add_edge(u, v)\n                graph[u][v]['graphs'] = []\n                graph[u][v][weight_attr] = 0.\n\n            for key, value in a.iteritems():\n                if key not in graph[u][v]:\n                    graph[u][v][key] = []\n                graph[u][v][key].append(value)\n            graph[u][v]['graphs'].append(a['graph'])\n            graph[u][v][weight_attr] += 1.\n\n        for u, a in self.master_graph.nodes(data=True):\n            for key, value in a.iteritems():\n                graph.node[u][key] = value\n\n        return graph", "response": "Returns the union of all graphs in this. GraphCollection."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new node that is coupled to the terms in the same topic.", "response": "def terms(model, threshold=0.01, **kwargs):\n    \"\"\"\n    Two terms are coupled if the posterior probability for both terms is\n    greather than ``threshold`` for the same topic.\n\n    Parameters\n    ----------\n    model : :class:`.LDAModel`\n    threshold : float\n        Default: 0.01\n    kwargs : kwargs\n        Passed on to :func:`.cooccurrence`\\.\n\n    Returns\n    -------\n    :ref:`networkx.Graph <networkx:graph>`\n\n    \"\"\"\n\n    select = lambda f, v, c, dc: v > threshold\n    graph = cooccurrence(model.phi, filter=select, **kwargs)\n\n    # Only include labels for terms that are actually in the graph.\n    label_map = {k: v for k, v in model.vocabulary.items()\n                 if k in graph.nodes()}\n    graph.name = ''\n    return networkx.relabel_nodes(graph, label_map)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef topic_coupling(model, threshold=None, **kwargs):\n    if not threshold:\n        threshold = 3./model.Z\n    select = lambda f, v, c, dc: v > threshold\n\n    graph = coupling(model.corpus, 'topics', filter=select, **kwargs)\n    graph.name = ''\n    return graph", "response": "Returns a networkx. Graph containing two papers that are both shared by a specific topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new set of two topics that occur below a given threshold.", "response": "def cotopics(model, threshold=None, **kwargs):\n    \"\"\"\n    Two topics are coupled if they occur (above some ``threshold``) in the same\n    document (s).\n\n    Parameters\n    ----------\n    model : :class:`.LDAModel`\n    threshold : float\n        Default: ``2./model.Z``\n    kwargs : kwargs\n        Passed on to :func:`.cooccurrence`\\.\n\n    Returns\n    -------\n    :ref:`networkx.Graph <networkx:graph>`\n\n    \"\"\"\n    if not threshold:\n        threshold = 2./model.Z\n\n    select = lambda f, v, c, dc: v > threshold\n    return cooccurrence(model.corpus, 'topics', filter=select, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a network of the distance metric from a model.", "response": "def distance(model, method='cosine', percentile=90, bidirectional=False,\n             normalize=True, smooth=False, transform='log', **kwargs):\n    \"\"\"\n    Generate a network of :class:`.Paper`\\s based on a distance metric from\n    `scipy.spatial.distance\n    <http://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_\n    using :ref:`sparse-feature-vector`\\s over the dimensions in ``model``.\n\n    The only two methods that will not work in this context are ``hamming`` and\n    ``jaccard``.\n\n    Distances are inverted to a similarity metric, which is log-transformed by\n    default (see ``transform`` parameter, below). Edges are included if they are\n    at or above the ``percentile``th percentile.\n\n    Parameters\n    ----------\n    model : :class:`.LDAModel` or :class:`.DTMModel`\n        :func:`.distance` uses ``model.item`` and ``model.metadata``.\n    method : str\n        Name of a distance method from `scipy.spatial.distance\n        <http://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_.\n        See :func:`.analyze.features.distance` for a list of distance\n        statistics. ``hamming`` or ``jaccard`` will raise a RuntimeError.\n        :func:`.analyze.features.kl_divergence` is also available as\n        'kl_divergence'.\n    percentile : int\n        (default: 90) Edges are included if they are at or above the\n        ``percentile`` for all distances in the ``model``.\n    bidirectional : bool\n        (default: False) If True, ``method`` is calculated twice for each pair\n        of :class:`.Paper`\\s ( ``(i,j)`` and ``(j,i)`` ), and the mean is used.\n    normalize : bool\n        (default: True) If True, vectors over topics are normalized so that they\n        sum to 1.0 for each :class:`.Paper`.\n    smooth : bool\n        (default: False) If True, vectors over topics are smoothed according to\n        `Bigi 2003\n        <http://lvk.cs.msu.su/~bruzz/articles/classification/Using%20Kullback-Leibler%20Distance%20for%20Text%20Categorization.pdf>`_.\n        This may be useful if vectors over topics are very sparse.\n    transform : str\n        (default: 'log') Transformation to apply to similarity values before\n        building the graph. So far only 'log' and None are supported.\n\n    Returns\n    -------\n    :ref:`networkx.Graph <networkx:graph>`\n        Similarity values are included as edge weights. Node attributes are set\n        using the fields in ``model.metadata``. See\n        :meth:`networkx.Graph.__init__`\n\n    Examples\n    --------\n\n    .. code-block:: python\n\n       >>> from tethne.networks import topics\n       >>> thegraph = topics.distance(myLDAModel, 'cosine')\n\n       >>> import tethne.writers as wr\n       >>> wr.to_graphml(thegraph, '~./thegraph.graphml')\n\n    .. figure:: _static/images/lda_cosine_network.png\n       :width: 80%\n\n       Edge weight and opacity indicate similarity. Node color indicates the\n       journal in which each :class:`.Paper` was published. In this graph,\n       papers published in the same journal tend to cluster together.\n\n    \"\"\"\n\n    if method in ['hamming','jaccard']:\n        raise RuntimeError(\n            'There is no sensicle interpretation of {0} for these data.'\n                                                            .format(method))\n\n    thegraph = networkx.Graph()\n\n    edges = {}\n    for i in xrange(model.M):\n        for j in xrange(i+1, model.M):\n            if method == 'kl_divergence':   # Not a SciPy method.\n                dist = features.kl_divergence( model.item(i), model.item(j) )\n                dist_ = features.kl_divergence( model.item(j), model.item(i) )\n                dist = (dist + dist_)/2.\n            else:\n                dist = features.distance( model.item(i), model.item(j), method,\n                                          normalize=normalize, smooth=smooth  )\n\n            if bidirectional:\n                dist_ = features.distance(\n                            model.item(j), model.item(i), method,\n                            normalize=normalize, smooth=smooth  )\n\n                dist = (dist + dist_)/2.\n\n            sim = 1./dist\n\n            if transform == 'log':\n                sim = log(sim)\n\n            edges[(i,j)] = sim\n\n    # pct = numpy.percentile(edges.values(), percentile)\n    pct = int(round(len(edges)*(percentile/100.)))\n    for i in argsort(edges.values())[::-1][:pct]:\n        edge, sim = edges.keys()[i], edges.values()[i]\n        thegraph.add_edge(edge[0], edge[1], weight=float(sim))\n\n    for key in model.metadata[0].keys():\n        values = { k:v[key] for k,v in model.metadata.items()\n                                if k in thegraph.nodes()    }\n        networkx.set_node_attributes(thegraph, key, values)\n\n    return thegraph"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kl_divergence(V_a, V_b):\n\n    # Find shared features.\n    Ndiff = _shared_features(V_a, V_b)\n\n    # aprob and bprob should each sum to 1.0\n    aprob = map(lambda v: float(v)/sum(V_a), V_a)\n    bprob = map(lambda v: float(v)/sum(V_b), V_b)\n\n    # Smooth according to Bigi 2003.\n    aprob, bprob = _smooth(aprob, bprob, Ndiff)\n\n    return sum(map(lambda a, b: (a-b)*log(a/b), aprob, bprob))", "response": "Calculate Kullback - Leibler distance between vectors V_a and V_b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cosine_similarity(F_a, F_b):\n\n    shared = list(F_a.unique & F_b.unique)\n    A = [dict(F_a.norm)[i] for i in shared]\n    B = [dict(F_b.norm)[i] for i in shared]\n    dot = sum(map(lambda a, b: a*b, A, B))\n    mag_A = sqrt(sum(map(lambda a: a**2, A)))\n    mag_B = sqrt(sum(map(lambda a: a**2, B)))\n\n    return dot / (mag_A + mag_B)", "response": "Calculate cosine similarity between two feature vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _shared_features(adense, bdense):\n    a_indices = set(nonzero(adense))\n    b_indices = set(nonzero(bdense))\n\n    shared = list(a_indices & b_indices)\n    diff = list(a_indices - b_indices)\n    Ndiff = len(diff)\n\n    return Ndiff", "response": "Returns the number of features in adense that are also in bdense."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _smooth(aprob, bprob, Ndiff):\n    gamma, epsilon = _smoothing_parameters(aprob, bprob, Ndiff)\n\n    # Remove zeros.\n    in_a = [i for i,v in enumerate(aprob) if abs(v) > 0.0]\n    aprob = list([list(aprob)[i] for i in in_a])\n    bprob = list([list(bprob)[i]*gamma for i in in_a])\n\n    # Replace zero values with epsilon.\n    bprob = list(map(lambda v: v if v != 0. else epsilon, bprob))\n\n    return aprob, bprob", "response": "Smooth distributions for KL - divergence according to Bigi 2003\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cooccurrence(corpus_or_featureset, featureset_name=None, min_weight=1,\n                 edge_attrs=['ayjid', 'date'],\n                 filter=None):\n    \"\"\"\n    A network of feature elements linked by their joint occurrence in papers.\n    \"\"\"\n\n    if not filter:\n        filter = lambda f, v, c, dc: dc >= min_weight\n\n    featureset = _get_featureset(corpus_or_featureset, featureset_name)\n\n    if type(corpus_or_featureset) in [Corpus, StreamingCorpus]:\n        attributes = {i: {a: corpus_or_featureset.indices_lookup[i][a] for a in edge_attrs}\n                      for i in corpus_or_featureset.indexed_papers.keys()}\n\n    c = lambda f: featureset.count(f)           # Overall count.\n    dc = lambda f: featureset.documentCount(f)  # Document count.\n    attributes = {}\n\n    # select applies filter to the elements in a (Structured)Feature. The\n    #  iteration behavior of Feature and StructuredFeature are different, as is\n    #  the manner in which the count for an element in each (Structured)Feature.\n    if type(featureset) is FeatureSet:\n        select = lambda feature: [f for f, v in feature\n                                  if filter(f, v, c(f), dc(f))]\n    elif type(featureset) is StructuredFeatureSet:\n        select = lambda feature: [f for f in feature\n                                  if filter(f, feature.count(f), c(f), dc(f))]\n\n    pairs = Counter()\n    eattrs = defaultdict(dict)\n    nattrs = defaultdict(dict)\n    nset = set()\n\n    for paper, feature in featureset.iteritems():\n        if len(feature) == 0:\n            continue\n\n        selected = select(feature)\n        nset |= set(selected)\n        for combo in combinations(selected, 2):\n            combo = tuple(sorted(combo))\n            pairs[combo] += 1\n\n            if paper in attributes:\n                eattrs[combo] = attributes[paper]\n\n    # Generate node attributes.\n    for n in list(nset):\n        nattrs[n]['count'] = featureset.count(n)\n        nattrs[n]['documentCount'] = featureset.documentCount(n)\n\n    return _generate_graph(nx.Graph, pairs, edge_attrs=eattrs,\n                            node_attrs=nattrs, min_weight=min_weight)", "response": "Returns a network of feature elements linked by their joint occurrence in papers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef multipartite(corpus, featureset_names, min_weight=1, filters={}):\n\n    pairs = Counter()\n    node_type = {corpus._generate_index(p): {'type': 'paper'}\n                 for p in corpus.papers}\n    for featureset_name in featureset_names:\n        ftypes = {}\n\n        featureset = _get_featureset(corpus, featureset_name)\n        for paper, feature in featureset.iteritems():\n            if featureset_name in filters:\n                if not filters[featureset_name](featureset, feature):\n                    continue\n            if len(feature) < 1:\n                continue\n            for f in list(zip(*feature))[0]:\n                ftypes[f] = {'type': featureset_name}\n                pairs[(paper, f)] += 1\n        node_type.update(ftypes)\n\n    return _generate_graph(nx.DiGraph, pairs, node_attrs=node_type,\n                           min_weight=min_weight)", "response": "A network of papers and one or more featuresets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mutual_information(corpus, featureset_name, min_weight=0.9,\n                       filter=lambda f, v, c, dc: True):\n    \"\"\"\n    Generates a graph of features in ``featureset`` based on normalized\n    `pointwise mutual information (nPMI)\n    <http://en.wikipedia.org/wiki/Pointwise_mutual_information>`_.\n\n    .. math::\n\n       nPMI(i,j)=\\\\frac{log(\\\\frac{p_{ij}}{p_i*p_j})}{-1*log(p_{ij})}\n\n    ...where :math:`p_i` and :math:`p_j` are the probabilities that features\n    *i* and *j* will occur in a document (independently), and :math:`p_{ij}` is\n    the probability that those two features will occur in the same document.\n    \"\"\"\n\n    graph = feature_cooccurrence(corpus, featureset_name, min_weight=1,\n                                 filter=filter)\n    mgraph = type(graph)()\n    keep_nodes = set()\n\n    fset = corpus.features[featureset_name]\n    for s, t, attrs in graph.edges(data=True):\n        p_ij = float(attrs['weight'])/len(corpus.papers)\n        p_i = float(fset.documentCounts[fset.lookup[s]])/len(corpus.papers)\n        p_j = float(fset.documentCounts[fset.lookup[t]])/len(corpus.papers)\n        MI = _nPMI(p_ij, p_i, p_j)\n        if MI >= min_weight:\n            mgraph.add_edge(s, t, nPMI=MI, **attrs)\n            keep_nodes.add(s)\n            keep_nodes.add(t)\n\n    for n in list(keep_nodes):  # Retain node attributes.\n        mgraph.node[n].update(graph.node[n])\n\n    return mgraph", "response": "Generates a graph of features in featureset based on pointwise mutual information."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all punctuation characters from a string.", "response": "def _strip_punctuation(s):\n    \"\"\"\n    Removes all punctuation characters from a string.\n    \"\"\"\n    if type(s) is str and not PYTHON_3:    # Bytestring (default in Python 2.x).\n        return s.translate(string.maketrans(\"\",\"\"), string.punctuation)\n    else:                 # Unicode string (default in Python 3.x).\n        translate_table = dict((ord(char), u'') for char in u'!\"#%\\'()*+,-./:;<=>?@[\\]^_`{|}~')\n        return s.translate(translate_table)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn list of objects shared by listA listB.", "response": "def overlap(listA, listB):\n    \"\"\"\n    Return list of objects shared by listA, listB.\n    \"\"\"\n    if (listA is None) or (listB is None):\n        return []\n    else:\n        return list(set(listA) & set(listB))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subdict(super_dict, keys):\n    sub_dict = {}\n    valid_keys = super_dict.keys()\n    for key in keys:\n        if key in valid_keys:\n            sub_dict[key] = super_dict[key]\n\n    return sub_dict", "response": "Returns a subset of the super_dict with the specified keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a dictionary of node and edge attributes to a string.", "response": "def attribs_to_string(attrib_dict, keys):\n    \"\"\"\n    A more specific version of the subdict utility aimed at handling\n    node and edge attribute dictionaries for NetworkX file formats such as\n    gexf (which does not allow attributes to have a list type) by making\n    them writable in those formats\n    \"\"\"\n    for key, value in attrib_dict.iteritems():\n        if (isinstance(value, list) or isinstance(value, dict) or\n            isinstance(value, tuple)):\n            attrib_dict[key] = value\n\n    return attrib_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconcatenate list elements pair - wise with the delim character.", "response": "def concat_list(listA, listB, delim=' '):\n    \"\"\"\n    Concatenate list elements pair-wise with the delim character\n    Returns the concatenated list\n    Raises index error if lists are not parallel\n    \"\"\"\n\n    # Lists must be of equal length.\n    if len(listA) != len(listB):\n        raise IndexError('Input lists are not parallel.')\n\n    # Concatenate lists.\n    listC = []\n    for i in xrange(len(listA)):\n        app = listA[i] + delim + listB[i]\n        listC.append(app)\n\n    return listC"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_non_ascii(s):\n    stripped = (c for c in s if 0 < ord(c) < 127)\n    clean_string = u''.join(stripped)\n    return clean_string", "response": "Returns the string with non - ASCII characters removed from the string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts ElementTree node to a dictionary.", "response": "def dict_from_node(node, recursive=False):\n    \"\"\"\n    Converts ElementTree node to a dictionary.\n\n    Parameters\n    ----------\n    node : ElementTree node\n    recursive : boolean\n        If recursive=False, the value of any field with children will be the\n        number of children.\n\n    Returns\n    -------\n    dict : nested dictionary.\n        Tags as keys and values as values. Sub-elements that occur multiple\n        times in an element are contained in a list.\n    \"\"\"\n\n    dict = {}\n    for snode in node:\n        if len(snode) > 0:\n            if recursive:\n                # Will drill down until len(snode) <= 0.\n                value = dict_from_node(snode, True)\n            else:\n                value = len(snode)\n        elif snode.text is not None:\n            value = snode.text\n        else:\n            value = u''\n\n        if snode.tag in dict.keys():    # If there are multiple subelements\n                                        #  with the same tag, then the value\n                                        #  of the element should be a list\n                                        #  rather than a dict.\n            if type(dict[snode.tag]) is list:   # If a list has already been\n                                                #  started, just append to\n                                                #  it.\n                dict[snode.tag].append(value)\n            else:\n                dict[snode.tag] = [ dict[snode.tag], value ]\n        else:\n            dict[snode.tag] = value     # Default behavior.\n    return dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feed(self, data):\n        try:\n            self.rawdata = self.rawdata + data\n        except TypeError:\n            data = unicode(data)\n            self.rawdata = self.rawdata + data\n\n        self.goahead(0)", "response": "Feed the data into the internal data structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a networkx. Graph to a CSV file.", "response": "def write_csv(graph, prefix):\n    \"\"\"\n    Write ``graph`` as tables of nodes (``prefix-nodes.csv``) and edges\n    (``prefix-edges.csv``).\n\n    Parameters\n    ----------\n    graph : :ref:`networkx.Graph <networkx:graph>`\n    prefix : str\n    \"\"\"\n    node_headers = list(set([a for n, attrs in graph.nodes(data=True)\n                             for a in attrs.keys()]))\n    edge_headers = list(set([a for s, t, attrs in graph.edges(data=True)\n                             for a in attrs.keys()]))\n\n    value = lambda attrs, h: _recast_value(attrs[h]) if h in attrs else ''\n    with open(prefix + '_nodes.csv', 'w') as f:\n        writer = csv.writer(f)\n        writer.writerow(['node'] + node_headers)\n        for n, attrs in graph.nodes(data=True):\n            values = map(value, repeat(attrs, len(node_headers)), node_headers)\n            writer.writerow([_recast_value(n)] + list(values))\n\n    with open(prefix + '_edges.csv', 'w') as f:\n        writer = csv.writer(f)\n        writer.writerow(['source', 'target'] + edge_headers)\n        for s, t, attrs in graph.edges(data=True):\n            values = map(value, repeat(attrs, len(edge_headers)), edge_headers)\n            writer.writerow([_recast_value(s), _recast_value(t)] + list(values))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating Simple Interaction Format output file from provided graph. The SIF specification is described `here <http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats>`_. :func:`.to_sif` will generate a .sif file describing the network, and a few .eda and .noa files containing edge and node attributes, respectively. These are equivalent to tab-delimited tables, and can be imported as such in Cytoscape 3.0. Parameters ---------- graph : networkx.Graph The Graph to be exported to SIF. output_path : str Full path, including filename (without suffix). e.g. using \"./graphFolder/graphFile\" will result in a SIF file at ./graphFolder/graphFile.sif, and corresponding .eda and .noa files.", "response": "def to_sif(graph, output_path):\n    \"\"\"\n    Generates Simple Interaction Format output file from provided graph.\n\n    The SIF specification is described\n    `here <http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats>`_.\n\n    :func:`.to_sif` will generate a .sif file describing the network, and a few\n    .eda and .noa files containing edge and node attributes, respectively. These\n    are equivalent to tab-delimited tables, and can be imported as such in\n    Cytoscape 3.0.\n\n    Parameters\n    ----------\n    graph : networkx.Graph\n        The Graph to be exported to SIF.\n    output_path : str\n        Full path, including filename (without suffix).\n        e.g. using \"./graphFolder/graphFile\" will result in a SIF file at\n        ./graphFolder/graphFile.sif, and corresponding .eda and .noa files.\n\n    \"\"\"\n\n    warnings.warn(\"Removed in 0.8. Use write_csv instead.\", DeprecationWarning)\n\n    graph = _strip_list_attributes(graph)\n\n    if output_path[-4:] == \".sif\":\n        output_path = output_path[:-4]\n\n    if nx.number_of_nodes(graph) == 0:\n        # write an empty file (for a non-existant graph)\n        f = open(output_path + \".sif\",\"w\")\n        f.write(\"\")\n        f.close()\n\n    else:\n        # write node files\n        nodes = graph.nodes(data=True)\n        for node in nodes:\n            node_name = node[0]\n            node_attribs = node[1]\n            for key, value in node_attribs.iteritems():\n                # generate a node attribute file for each node attribute\n                if node == nodes[0]:\n                    # first node, overwrite file\n                    with open(output_path + \"_\" + key + \".noa\",\n                              \"w\") as f:\n                        f.write(unicode(key) + '\\n')\n                        f.write(unicode(node_name).replace(\" \",\"_\") + \" = \" +\n                                unicode(value) + \"\\n\")\n                else:\n                    # not first, append file\n                    with open(output_path + \"_\" + key + \".noa\",\n                              \"a\") as f:\n                        f.write(unicode(node_name).replace(\" \",\"_\") + \" = \" +\n                                unicode(value) + \"\\n\")\n\n        if nx.number_of_edges(graph) == 0:\n            # write an empty graph to a .sif file (just its nodes)\n            for node in nodes:\n                node_name = node[0]\n                if node == nodes[0]:\n                    # first node, overwrite file\n                    with open(output_path + \".sif\",\"w\") as f:\n                        f.write(unicode(node_name).replace(\" \",\"_\") + \"\\n\")\n                else:\n                    # not first, append file\n                    with open(output_path + \".sif\",\"a\") as f:\n                        f.write(unicode(node_name).replace(\" \",\"_\") + \"\\n\")\n\n        else:\n            # write the graph to a .sif file as well as other edge\n            # attribute files\n\n            if graph.is_multigraph():\n                # then the NetworkX graph supports multiple interaction\n                # types just like the .sif format\n                edges = graph.edges(data=True, keys=True)\n                edge_attribs = set()\n                for edge in edges:\n                    for key in edge[3].iterkeys():\n                        edge_attribs.add(key)\n\n                # create edge attribute files\n                for attrib in edge_attribs:\n                    str_attrib = unicode(attrib)\n                    with open(output_path + '_' + str_attrib + \".eda\",\"w\") as f:\n                        f.write(unicode(attrib) + \"\\n\")\n\n                # add data to eda files and write sif file\n                with open(output_path + '.sif', 'w') as f:\n                    for edge in edges:\n                        node1 = unicode(edge[0]).replace(\" \", \"_\")\n                        node2 = unicode(edge[1]).replace(\" \", \"_\")\n                        intr_type = unicode(edge[2]).replace(\" \", \"_\")\n                        sif_line = node1 + ' ' + intr_type + ' ' + node2 + '\\n'\n                        f.write(sif_line)\n\n                        for attrib, value in edge[3].iteritems():\n                            eda_line = (node1 + ' (' + intr_type + ') ' +\n                                        node2 + ' = ' + unicode(value) + '\\n')\n                            with open(output_path + '_' + unicode(attrib) + '.eda',\n                                      'a') as g:\n                                g.write(eda_line)\n\n            else:\n                # then we support only one interaction type 'rel'\n                edges = graph.edges(data=True)\n                edge_attribs = set()\n                for edge in edges:\n                    for key in edge[2].iterkeys():\n                        edge_attribs.add(key)\n\n                # create edge attribute files\n                for attrib in edge_attribs:\n                    str_attrib = unicode(attrib)\n                    with open(output_path + '_' + str_attrib + \".eda\",\"w\") as f:\n                        f.write(unicode(attrib) + \"\\n\")\n\n                # add data to eda files and write sif file\n                with open(output_path + '.sif', 'w') as f:\n                    for edge in edges:\n                        node1 = unicode(edge[0]).replace(\" \", \"_\")\n                        node2 = unicode(edge[1]).replace(\" \", \"_\")\n                        intr_type = 'rel'\n                        sif_line = node1 + ' ' + intr_type + ' ' + node2 + '\\n'\n                        f.write(sif_line)\n\n                        for attrib, value in edge[2].iteritems():\n                            eda_line = (node1 + ' (' + intr_type + ') ' +\n                                        node2 + ' = ' + unicode(value) + '\\n')\n                            with open(output_path + '_' + unicode(attrib) +\n                                      '.eda', 'a') as g:\n                                g.write(eda_line)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_gexf(graph, output_path):\n    warnings.warn(\"Removed in 0.8.\", DeprecationWarning)\n\n    graph = _strip_list_attributes(graph)\n\n    nx.write_gexf(graph, output_path + \".gexf\")", "response": "Writes a graph to GEXF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_graphml(graph, path, encoding='utf-8', prettyprint=True):\n    graph = _strip_list_attributes(graph)\n\n    writer = TethneGraphMLWriter(encoding=encoding, prettyprint=prettyprint)\n    writer.add_graph_element(graph)\n    writer.dump(open(path, 'wb'))", "response": "Writes a graph to GraphML file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serializeCorpus(self):\n        corpus_details = [{\n                \"model\": \"django-tethne.corpus\",\n                \"pk\": self.corpus_id,\n                \"fields\": {\n                    \"source\": self.source,\n                    \"date_created\":strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()),\n                    \"length\" : len(self.corpus),\n                }\n            }]\n        return corpus_details", "response": "This method creates a fixture for the django - tethne_corpus model. It creates a fixture for the django - tethne_corpus model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serializeCitation(self):\n        citation_details = []\n        citation_id = tethnedao.getMaxCitationID()\n        for citation in self.corpus.features['citations'].index.values():\n\n            date_match = re.search(r'(\\d+)', citation)\n            if date_match is not None:\n                date = date_match.group(1)\n            if date_match is None:\n                date_match = re.search(r\"NONE\", citation)\n                date = date_match.group()\n            first_author = citation.replace('_', ' ').split(date)[0].rstrip()\n            journal = citation.replace('_', ' ').split(date)[1].lstrip()\n            citation_key = citation\n            if citation_key not in self.citationIdMap:\n                citation_id += 1\n                self.citationIdMap[citation_key] = citation_id\n                citation_data = {\n                        \"model\": \"django-tethne.citation\",\n                        \"pk\": citation_id,\n                        \"fields\": {\n                            \"literal\": citation,\n                            \"journal\": journal,\n                            \"first_author\": first_author,\n                            \"date\": date\n                        }\n                    }\n                citation_details.append(citation_data)\n        return citation_details", "response": "This method creates a fixture for the django - tethne_citation model. It creates a fixture for the django - tethne_citation model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_details_from_inst_literal(self, institute_literal, institution_id, institution_instance_id, paper_key):\n        institute_details = institute_literal.split(',')\n        institute_name = institute_details[0]\n        country = institute_details[len(institute_details)-1].lstrip().replace('.', '')\n        institute_row = None\n        zipcode = \"\"\n        state = \"\"\n        city = \"\"\n        if 'USA' in country:\n            temp = country\n            if(len(temp.split())) == 3:\n                country = temp.split()[2]\n                zipcode = temp.split()[1]\n                state = temp.split()[0]\n            elif(len(temp.split())) == 2:\n                country = temp.split()[1]\n                state = temp.split()[0]\n            city = institute_details[len(institute_details)-2].lstrip()\n\n        addressline1 = \"\"\n        for i in range(1, len(institute_details)-1, 1):\n            if i != len(institute_details)-2:\n                addressline1 = addressline1 + institute_details[i]+','\n            else:\n                addressline1 = addressline1 + institute_details[i]\n        if institute_literal not in self.instituteIdMap:\n                self.instituteIdMap[institute_literal] = institution_id\n                institute_row = {\n                    \"model\": \"django-tethne.institution\",\n                    \"pk\": institution_id,\n                    \"fields\": {\n                        \"institute_name\": institute_name,\n                        \"addressLine1\": addressline1,\n                        \"country\": country,\n                        \"zip\": zipcode,\n                        \"state\": state,\n                        \"city\": city\n                    }\n                }\n        department = \"\"\n        if re.search('Dept([^,]*),', institute_literal) is not None:\n            department = re.search('Dept([^,]*),', institute_literal).group().replace(',', '')\n        institute_instance_row = {\n            \"model\": \"django-tethne.institution_instance\",\n            \"pk\": institution_instance_id,\n            \"fields\": {\n                \"institution\": self.instituteIdMap[institute_literal],\n                \"literal\": institute_literal,\n                \"institute_name\": institute_name,\n                \"addressLine1\": addressline1,\n                \"country\": country,\n                \"paper\": self.paperIdMap[paper_key],\n                \"department\": department,\n                \"zip\": zipcode,\n                \"state\": state,\n                \"city\": city\n\n            }\n        }\n        return institute_row, institute_instance_row", "response": "This method parses the Institution Instance ID and returns the details of the Institution Instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the first data entry and prepare to parse.", "response": "def start(self):\n        \"\"\"\n        Find the first data entry and prepare to parse.\n        \"\"\"\n\n        while not self.is_start(self.current_tag):\n            self.next()\n        self.new_entry()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(self, tag, data):\n\n        if self.is_end(tag):\n            self.postprocess_entry()\n\n        if self.is_start(tag):\n            self.new_entry()\n\n        if not data or not tag:\n            return\n\n        if getattr(self, 'parse_only', None) and tag not in self.parse_only:\n            return\n\n        # TODO: revisit encoding here.\n        if isinstance(data, unicode):\n            data = unicodedata.normalize('NFKD', data)#.encode('utf-8','ignore')\n\n        handler = self._get_handler(tag)\n        if handler is not None:\n            data = handler(data)\n\n        if tag in self.tags:    # Rename the field.\n            tag = self.tags[tag]\n\n        # Multiline fields are represented as lists of values.\n        if hasattr(self.data[-1], tag):\n            value = getattr(self.data[-1], tag)\n            if tag in self.concat_fields:\n                value = ' '.join([value, unicode(data)])\n            elif type(value) is list:\n                value.append(data)\n            elif value not in [None, '']:\n                value = [value, data]\n        else:\n            value = data\n        setattr(self.data[-1], tag, value)\n        self.fields.add(tag)", "response": "Process a single line of data and store the result in the self. fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open(self):\n\n        if not os.path.exists(self.path):\n            raise IOError(\"No such path: {0}\".format(self.path))\n\n\n        with open(self.path, \"rb\") as f:\n            msg = f.read()\n        result = chardet.detect(msg)\n\n        self.buffer = codecs.open(self.path, \"rb\", encoding=result['encoding'])\n\n        self.at_eof = False", "response": "Open the data file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the next line of data.", "response": "def next(self):\n        \"\"\"\n        Get the next line of data.\n\n        Returns\n        -------\n        tag : str\n        data :\n        \"\"\"\n        line = self.buffer.readline()\n\n        while line == '\\n':       # Skip forward to the next line with content.\n            line = self.buffer.readline()\n\n        if line == '':            # End of file.\n            self.at_eof = True\n            return None, None\n\n        match = re.match('([A-Z]{2}|[C][1])\\W(.*)', line)\n        if match is not None:\n            self.current_tag, data = match.groups()\n        else:\n            self.current_tag = self.last_tag\n            data = line.strip()\n        return self.current_tag, _cast(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coauthors(corpus, min_weight=1, edge_attrs=['ayjid', 'date'], **kwargs):\n    return cooccurrence(corpus, 'authors', min_weight=min_weight,\n                        edge_attrs=edge_attrs, **kwargs)", "response": "A graph describing joint authorship in corpus."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _infer_spaces(s):\n    s = s.lower()\n\n    # Find the best match for the i first characters, assuming cost has\n    # been built for the i-1 first characters.\n    # Returns a pair (match_cost, match_length).\n    def best_match(i):\n        candidates = enumerate(reversed(cost[max(0, i - MAXWORD):i]))\n        return min((c + WORDCOST.get(s[i-k-1: i], 9e999), k + 1)\n                    for k, c in candidates)\n\n    # Build the cost array.\n    cost = [0]\n    for i in range(1, len(s) + 1):\n        c, k = best_match(i)\n        cost.append(c)\n\n    # Backtrack to recover the minimal-cost string.\n    out = []\n    i = len(s)\n    while i > 0:\n        c, k = best_match(i)\n        assert c == cost[i]\n        out.append(s[i-k:i])\n        i -= k\n\n    return u\" \".join(reversed(out))", "response": "Infer the location of spaces in a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract structured text content from a plain - text file at fpath.", "response": "def extract_text(fpath):\n    \"\"\"\n    Extracts structured text content from a plain-text file at ``fpath``.\n\n    Parameters\n    ----------\n    fpath : str\n        Path to the text file..\n\n    Returns\n    -------\n    :class:`.StructuredFeature`\n        A :class:`.StructuredFeature` that contains sentence context.\n    \"\"\"\n    with codecs.open(fpath, 'r') as f:  # Determine the encoding of the file.\n        document = f.read()\n    encoding = chardet.detect(document)['encoding']\n    document = document.decode(encoding)\n\n    tokens = []\n    sentences = []\n\n    i = 0\n    for sentence in nltk.tokenize.sent_tokenize(document):\n        sentences.append(i)\n\n        for word in nltk.tokenize.word_tokenize(sentence):\n            tokens.append(word)\n            i += 1\n\n    contexts = [('sentence', sentences)]\n    return StructuredFeature(tokens, contexts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract structured text content from a PDF at fpath.", "response": "def extract_pdf(fpath):\n    \"\"\"\n    Extracts structured text content from a PDF at ``fpath``.\n\n    Parameters\n    ----------\n    fpath : str\n        Path to the PDF.\n\n    Returns\n    -------\n    :class:`.StructuredFeature`\n        A :class:`.StructuredFeature` that contains page and sentence contexts.\n    \"\"\"\n\n    with codecs.open(fpath, 'r') as f:  # Determine the encoding of the file.\n        document = slate.PDF(f)\n    encoding = chardet.detect(document[0])\n\n    tokens = []\n    pages = []\n    sentences = []\n\n    tokenizer = nltk.tokenize.TextTilingTokenizer()\n\n    i = 0\n    for page in document:\n        pages.append(i)\n\n        # Decode using the correct encoding.\n        page = page.decode(encoding['encoding'])\n        for sentence in nltk.tokenize.sent_tokenize(page):\n            sentences.append(i)\n\n            for word in nltk.tokenize.word_tokenize(sentence):\n                if len(word) > 15:\n                    words = nltk.tokenize.word_tokenize(_infer_spaces(word))\n                    if mean([len(w) for w in words]) > 2:\n                        for w in words:\n                            tokens.append(w)\n                            i += 1\n                        continue\n\n                tokens.append(word)\n                i += 1\n\n    contexts = [('page', pages), ('sentence', sentences)]\n    return StructuredFeature(tokens, contexts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(path, corpus=True, index_by='uri', follow_links=False, **kwargs):\n    # TODO: is there a case where `from_dir` would make sense?\n\n    parser = ZoteroParser(path, index_by=index_by, follow_links=follow_links)\n    papers = parser.parse()\n\n    if corpus:\n        c = Corpus(papers, index_by=index_by, **kwargs)\n        if c.duplicate_papers:\n            warnings.warn(\"Duplicate papers detected. Use the 'duplicate_papers' attribute of the corpus to get the list\", UserWarning)\n\n        for fset_name, fset_values in parser.full_text.iteritems():\n            c.features[fset_name] = StructuredFeatureSet(fset_values)\n        return c\n    return papers", "response": "Read bibliographic data from a Zotero RDF file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open(self):\n\n        with open(self.path, 'r') as f:\n            corrected = f.read().replace('rdf:resource rdf:resource',\n                                         'link:link rdf:resource')\n        with open(self.path, 'w') as f:\n            f.write(corrected)\n\n        super(ZoteroParser, self).open()", "response": "Open the zotero file and read the content of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling links in the resource store.", "response": "def handle_link(self, value):\n        \"\"\"\n        rdf:link rdf:resource points to the resource described by a record.\n        \"\"\"\n        for s, p, o in self.graph.triples((value, None, None)):\n            if p == LINK_ELEM:\n                return unicode(o).replace('file://', '')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to coerced date to ISO8601.", "response": "def handle_date(self, value):\n        \"\"\"\n        Attempt to coerced date to ISO8601.\n        \"\"\"\n        try:\n            return iso8601.parse_date(unicode(value)).year\n        except iso8601.ParseError:\n            for datefmt in (\"%B %d, %Y\", \"%Y-%m\", \"%Y-%m-%d\", \"%m/%d/%Y\"):\n                try:\n                    # TODO: remove str coercion.\n                    return datetime.strptime(unicode(value), datefmt).date().year\n                except ValueError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload full - text content from resource.", "response": "def postprocess_link(self, entry):\n        \"\"\"\n        Attempt to load full-text content from resource.\n        \"\"\"\n\n        if not self.follow_links:\n            return\n\n        if type(entry.link) is not list:\n            entry.link = [entry.link]\n\n        for link in list(entry.link):\n            if not os.path.exists(link):\n                continue\n\n            mime_type = magic.from_file(link, mime=True)\n            if mime_type == 'application/pdf':\n                structuredfeature = extract_pdf(link)\n            elif mime_type == 'text/plain':\n                structuredfeature = extract_text(link)\n            else:\n                structuredfeature = None\n\n            if not structuredfeature:\n                continue\n\n            fset_name = mime_type.split('/')[-1] + '_text'\n            if not fset_name in self.full_text:\n                self.full_text[fset_name] = {}\n\n            if hasattr(self, 'index_by'):\n                ident = getattr(entry, self.index_by)\n                if type(ident) is list:\n                    ident = ident[0]\n            else:   # If `index_by` is not set, use `uri` by default.\n                ident = entry.uri\n\n            self.full_text[fset_name][ident] = structuredfeature"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n\n    try:\n        args = get_config()\n        result = webpush(\n            args.sub_info,\n            data=args.data,\n            vapid_private_key=args.key,\n            vapid_claims=args.claims,\n            curl=args.curl,\n            content_encoding=args.encoding)\n        print(result)\n    except Exception as ex:\n        print(\"ERROR: {}\".format(ex))", "response": "Send data to the server"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef webpush(subscription_info,\n            data=None,\n            vapid_private_key=None,\n            vapid_claims=None,\n            content_encoding=\"aes128gcm\",\n            curl=False,\n            timeout=None,\n            ttl=0):\n    \"\"\"\n        One call solution to endcode and send `data` to the endpoint\n        contained in `subscription_info` using optional VAPID auth headers.\n\n        in example:\n\n        .. code-block:: python\n\n        from pywebpush import python\n\n        webpush(\n            subscription_info={\n                \"endpoint\": \"https://push.example.com/v1/abcd\",\n                \"keys\": {\"p256dh\": \"0123abcd...\",\n                         \"auth\": \"001122...\"}\n                 },\n            data=\"Mary had a little lamb, with a nice mint jelly\",\n            vapid_private_key=\"path/to/key.pem\",\n            vapid_claims={\"sub\": \"YourNameHere@example.com\"}\n            )\n\n        No additional method call is required. Any non-success will throw a\n        `WebPushException`.\n\n    :param subscription_info: Provided by the client call\n    :type subscription_info: dict\n    :param data: Serialized data to send\n    :type data: str\n    :param vapid_private_key: Vapid instance or path to vapid private key PEM \\\n                              or encoded str\n    :type vapid_private_key: Union[Vapid, str]\n    :param vapid_claims: Dictionary of claims ('sub' required)\n    :type vapid_claims: dict\n    :param content_encoding: Optional content type string\n    :type content_encoding: str\n    :param curl: Return as \"curl\" string instead of sending\n    :type curl: bool\n    :param timeout: POST requests timeout\n    :type timeout: float or tuple\n    :param ttl: Time To Live\n    :type ttl: int\n    :return requests.Response or string\n\n    \"\"\"\n    vapid_headers = None\n    if vapid_claims:\n        if not vapid_claims.get('aud'):\n            url = urlparse(subscription_info.get('endpoint'))\n            aud = \"{}://{}\".format(url.scheme, url.netloc)\n            vapid_claims['aud'] = aud\n        if not vapid_claims.get('exp'):\n            # encryption lives for 12 hours\n            vapid_claims['exp'] = int(time.time()) + (12 * 60 * 60)\n        if not vapid_private_key:\n            raise WebPushException(\"VAPID dict missing 'private_key'\")\n        if isinstance(vapid_private_key, Vapid):\n            vv = vapid_private_key\n        elif os.path.isfile(vapid_private_key):\n            # Presume that key from file is handled correctly by\n            # py_vapid.\n            vv = Vapid.from_file(\n                private_key_file=vapid_private_key)  # pragma no cover\n        else:\n            vv = Vapid.from_string(private_key=vapid_private_key)\n        vapid_headers = vv.sign(vapid_claims)\n    response = WebPusher(subscription_info).send(\n        data,\n        vapid_headers,\n        ttl=ttl,\n        content_encoding=content_encoding,\n        curl=curl,\n        timeout=timeout,\n    )\n    if not curl and response.status_code > 202:\n        raise WebPushException(\"Push failed: {} {}\".format(\n            response.status_code, response.reason),\n            response=response)\n    return response", "response": "This function is used to send data to the endpoint of the current instance of a new instance of a new instance of a new instance of a new instance of a new instance of a new instance of a new instance of a new instance of a new class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(self, data, content_encoding=\"aes128gcm\"):\n        # Salt is a random 16 byte array.\n        if not data:\n            return\n        if not self.auth_key or not self.receiver_key:\n            raise WebPushException(\"No keys specified in subscription info\")\n        salt = None\n        if content_encoding not in self.valid_encodings:\n            raise WebPushException(\"Invalid content encoding specified. \"\n                                   \"Select from \" +\n                                   json.dumps(self.valid_encodings))\n        if content_encoding == \"aesgcm\":\n            salt = os.urandom(16)\n        # The server key is an ephemeral ECDH key used only for this\n        # transaction\n        server_key = ec.generate_private_key(ec.SECP256R1, default_backend())\n        crypto_key = server_key.public_key().public_bytes(\n            encoding=serialization.Encoding.X962,\n            format=serialization.PublicFormat.UncompressedPoint\n        )\n\n        if isinstance(data, six.string_types):\n            data = bytes(data.encode('utf8'))\n        if content_encoding == \"aes128gcm\":\n            encrypted = http_ece.encrypt(\n                data,\n                salt=salt,\n                private_key=server_key,\n                dh=self.receiver_key,\n                auth_secret=self.auth_key,\n                version=content_encoding)\n            reply = CaseInsensitiveDict({\n                'body': encrypted\n            })\n        else:\n            crypto_key = base64.urlsafe_b64encode(crypto_key).strip(b'=')\n            encrypted = http_ece.encrypt(\n                data,\n                salt=salt,\n                private_key=server_key,\n                keyid=crypto_key.decode(),\n                dh=self.receiver_key,\n                auth_secret=self.auth_key,\n                version=content_encoding)\n            reply = CaseInsensitiveDict({\n                'crypto_key': crypto_key,\n                'body': encrypted,\n            })\n            if salt:\n                reply['salt'] = base64.urlsafe_b64encode(salt).strip(b'=')\n        return reply", "response": "Encrypt the data.\n\n        :param data: A serialized block of byte data (String, JSON, bit array,\n            etc.) Make sure that whatever you send, your client knows how\n            to understand it.\n        :type data: str\n        :param content_encoding: The content_encoding type to use to encrypt\n            the data. Defaults to RFC8188 \"aes128gcm\". The previous draft-01 is\n            \"aesgcm\", however this format is now deprecated.\n        :type content_encoding: enum(\"aesgcm\", \"aes128gcm\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the send as a curl command.", "response": "def as_curl(self, endpoint, encoded_data, headers):\n        \"\"\"Return the send as a curl command.\n\n        Useful for debugging. This will write out the encoded data to a local\n        file named `encrypted.data`\n\n        :param endpoint: Push service endpoint URL\n        :type endpoint: basestring\n        :param encoded_data: byte array of encoded data\n        :type encoded_data: bytearray\n        :param headers: Additional headers for the send\n        :type headers: dict\n        :returns string\n\n        \"\"\"\n        header_list = [\n            '-H \"{}: {}\" \\\\ \\n'.format(\n                key.lower(), val) for key, val in headers.items()\n        ]\n        data = \"\"\n        if encoded_data:\n            with open(\"encrypted.data\", \"wb\") as f:\n                f.write(encoded_data)\n            data = \"--data-binary @encrypted.data\"\n        if 'content-length' not in headers:\n            header_list.append(\n                '-H \"content-length: {}\" \\\\ \\n'.format(len(encoded_data)))\n        return (\"\"\"curl -vX POST {url} \\\\\\n{headers}{data}\"\"\".format(\n            url=endpoint, headers=\"\".join(header_list), data=data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding and send the data to the Push Service.", "response": "def send(self, data=None, headers=None, ttl=0, gcm_key=None, reg_id=None,\n             content_encoding=\"aes128gcm\", curl=False, timeout=None):\n        \"\"\"Encode and send the data to the Push Service.\n\n        :param data: A serialized block of data (see encode() ).\n        :type data: str\n        :param headers: A dictionary containing any additional HTTP headers.\n        :type headers: dict\n        :param ttl: The Time To Live in seconds for this message if the\n            recipient is not online. (Defaults to \"0\", which discards the\n            message immediately if the recipient is unavailable.)\n        :type ttl: int\n        :param gcm_key: API key obtained from the Google Developer Console.\n            Needed if endpoint is https://android.googleapis.com/gcm/send\n        :type gcm_key: string\n        :param reg_id: registration id of the recipient. If not provided,\n            it will be extracted from the endpoint.\n        :type reg_id: str\n        :param content_encoding: ECE content encoding (defaults to \"aes128gcm\")\n        :type content_encoding: str\n        :param curl: Display output as `curl` command instead of sending\n        :type curl: bool\n        :param timeout: POST requests timeout\n        :type timeout: float or tuple\n\n        \"\"\"\n        # Encode the data.\n        if headers is None:\n            headers = dict()\n        encoded = {}\n        headers = CaseInsensitiveDict(headers)\n        if data:\n            encoded = self.encode(data, content_encoding)\n            if \"crypto_key\" in encoded:\n                # Append the p256dh to the end of any existing crypto-key\n                crypto_key = headers.get(\"crypto-key\", \"\")\n                if crypto_key:\n                    # due to some confusion by a push service provider, we\n                    # should use ';' instead of ',' to append the headers.\n                    # see\n                    # https://github.com/webpush-wg/webpush-encryption/issues/6\n                    crypto_key += ';'\n                crypto_key += (\n                    \"dh=\" + encoded[\"crypto_key\"].decode('utf8'))\n                headers.update({\n                    'crypto-key': crypto_key\n                })\n            if \"salt\" in encoded:\n                headers.update({\n                    'encryption': \"salt=\" + encoded['salt'].decode('utf8')\n                })\n            headers.update({\n                'content-encoding': content_encoding,\n            })\n        if gcm_key:\n            # guess if it is a legacy GCM project key or actual FCM key\n            # gcm keys are all about 40 chars (use 100 for confidence),\n            # fcm keys are 153-175 chars\n            if len(gcm_key) < 100:\n                endpoint = 'https://android.googleapis.com/gcm/send'\n            else:\n                endpoint = 'https://fcm.googleapis.com/fcm/send'\n            reg_ids = []\n            if not reg_id:\n                reg_id = self.subscription_info['endpoint'].rsplit('/', 1)[-1]\n            reg_ids.append(reg_id)\n            gcm_data = dict()\n            gcm_data['registration_ids'] = reg_ids\n            if data:\n                gcm_data['raw_data'] = base64.b64encode(\n                    encoded.get('body')).decode('utf8')\n            gcm_data['time_to_live'] = int(\n                headers['ttl'] if 'ttl' in headers else ttl)\n            encoded_data = json.dumps(gcm_data)\n            headers.update({\n                'Authorization': 'key='+gcm_key,\n                'Content-Type': 'application/json',\n            })\n        else:\n            encoded_data = encoded.get('body')\n            endpoint = self.subscription_info['endpoint']\n\n        if 'ttl' not in headers or ttl:\n            headers['ttl'] = str(ttl or 0)\n        # Additionally useful headers:\n        # Authorization / Crypto-Key (VAPID headers)\n        if curl:\n            return self.as_curl(endpoint, encoded_data, headers)\n        return self.requests_method.post(endpoint,\n                                         data=encoded_data,\n                                         headers=headers,\n                                         timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot one year from a timeseries.", "response": "def yearplot(data, year=None, how='sum', vmin=None, vmax=None, cmap='Reds',\n             fillcolor='whitesmoke', linewidth=1, linecolor=None,\n             daylabels=calendar.day_abbr[:], dayticks=True,\n             monthlabels=calendar.month_abbr[1:], monthticks=True, ax=None,\n             **kwargs):\n    \"\"\"\n    Plot one year from a timeseries as a calendar heatmap.\n\n    Parameters\n    ----------\n    data : Series\n        Data for the plot. Must be indexed by a DatetimeIndex.\n    year : integer\n        Only data indexed by this year will be plotted. If `None`, the first\n        year for which there is data will be plotted.\n    how : string\n        Method for resampling data by day. If `None`, assume data is already\n        sampled by day and don't resample. Otherwise, this is passed to Pandas\n        `Series.resample`.\n    vmin, vmax : floats\n        Values to anchor the colormap. If `None`, min and max are used after\n        resampling data by day.\n    cmap : matplotlib colormap name or object\n        The mapping from data values to color space.\n    fillcolor : matplotlib color\n        Color to use for days without data.\n    linewidth : float\n        Width of the lines that will divide each day.\n    linecolor : color\n        Color of the lines that will divide each day. If `None`, the axes\n        background color is used, or 'white' if it is transparent.\n    daylabels : list\n        Strings to use as labels for days, must be of length 7.\n    dayticks : list or int or bool\n        If `True`, label all days. If `False`, don't label days. If a list,\n        only label days with these indices. If an integer, label every n day.\n    monthlabels : list\n        Strings to use as labels for months, must be of length 12.\n    monthticks : list or int or bool\n        If `True`, label all months. If `False`, don't label months. If a\n        list, only label months with these indices. If an integer, label every\n        n month.\n    ax : matplotlib Axes\n        Axes in which to draw the plot, otherwise use the currently-active\n        Axes.\n    kwargs : other keyword arguments\n        All other keyword arguments are passed to matplotlib `ax.pcolormesh`.\n\n    Returns\n    -------\n    ax : matplotlib Axes\n        Axes object with the calendar heatmap.\n\n    Examples\n    --------\n\n    By default, `yearplot` plots the first year and sums the values per day:\n\n    .. plot::\n        :context: close-figs\n\n        calmap.yearplot(events)\n\n    We can choose which year is plotted with the `year` keyword argment:\n\n    .. plot::\n        :context: close-figs\n\n        calmap.yearplot(events, year=2015)\n\n    The appearance can be changed by using another colormap. Here we also use\n    a darker fill color for days without data and remove the lines:\n\n    .. plot::\n        :context: close-figs\n\n        calmap.yearplot(events, cmap='YlGn', fillcolor='grey',\n                        linewidth=0)\n\n    The axis tick labels can look a bit crowded. We can ask to draw only every\n    nth label, or explicitely supply the label indices. The labels themselves\n    can also be customized:\n\n    .. plot::\n        :context: close-figs\n\n        calmap.yearplot(events, monthticks=3, daylabels='MTWTFSS',\n                        dayticks=[0, 2, 4, 6])\n\n    \"\"\"\n    if year is None:\n        year = data.index.sort_values()[0].year\n\n    if how is None:\n        # Assume already sampled by day.\n        by_day = data\n    else:\n        # Sample by day.\n        if _pandas_18:\n            by_day = data.resample('D').agg(how)\n        else:\n            by_day = data.resample('D', how=how)\n\n    # Min and max per day.\n    if vmin is None:\n        vmin = by_day.min()\n    if vmax is None:\n        vmax = by_day.max()\n\n    if ax is None:\n        ax = plt.gca()\n\n    if linecolor is None:\n        # Unfortunately, linecolor cannot be transparent, as it is drawn on\n        # top of the heatmap cells. Therefore it is only possible to mimic\n        # transparent lines by setting them to the axes background color. This\n        # of course won't work when the axes itself has a transparent\n        # background so in that case we default to white which will usually be\n        # the figure or canvas background color.\n        linecolor = ax.get_axis_bgcolor()\n        if ColorConverter().to_rgba(linecolor)[-1] == 0:\n            linecolor = 'white'\n\n    # Filter on year.\n    by_day = by_day[str(year)]\n\n    # Add missing days.\n    by_day = by_day.reindex(\n        pd.date_range(start=str(year), end=str(year + 1), freq='D')[:-1])\n\n    # Create data frame we can pivot later.\n    by_day = pd.DataFrame({'data': by_day,\n                           'fill': 1,\n                           'day': by_day.index.dayofweek,\n                           'week': by_day.index.week})\n\n    # There may be some days assigned to previous year's last week or\n    # next year's first week. We create new week numbers for them so\n    # the ordering stays intact and week/day pairs unique.\n    by_day.loc[(by_day.index.month == 1) & (by_day.week > 50), 'week'] = 0\n    by_day.loc[(by_day.index.month == 12) & (by_day.week < 10), 'week'] \\\n        = by_day.week.max() + 1\n\n    # Pivot data on day and week and mask NaN days.\n    plot_data = by_day.pivot('day', 'week', 'data').values[::-1]\n    plot_data = np.ma.masked_where(np.isnan(plot_data), plot_data)\n\n    # Do the same for all days of the year, not just those we have data for.\n    fill_data = by_day.pivot('day', 'week', 'fill').values[::-1]\n    fill_data = np.ma.masked_where(np.isnan(fill_data), fill_data)\n\n    # Draw heatmap for all days of the year with fill color.\n    ax.pcolormesh(fill_data, vmin=0, vmax=1, cmap=ListedColormap([fillcolor]))\n\n    # Draw heatmap.\n    kwargs['linewidth'] = linewidth\n    kwargs['edgecolors'] = linecolor\n    ax.pcolormesh(plot_data, vmin=vmin, vmax=vmax, cmap=cmap, **kwargs)\n\n    # Limit heatmap to our data.\n    ax.set(xlim=(0, plot_data.shape[1]), ylim=(0, plot_data.shape[0]))\n\n    # Square cells.\n    ax.set_aspect('equal')\n\n    # Remove spines and ticks.\n    for side in ('top', 'right', 'left', 'bottom'):\n        ax.spines[side].set_visible(False)\n    ax.xaxis.set_tick_params(which='both', length=0)\n    ax.yaxis.set_tick_params(which='both', length=0)\n\n    # Get indices for monthlabels.\n    if monthticks is True:\n        monthticks = range(len(monthlabels))\n    elif monthticks is False:\n        monthticks = []\n    elif isinstance(monthticks, int):\n        monthticks = range(len(monthlabels))[monthticks // 2::monthticks]\n\n    # Get indices for daylabels.\n    if dayticks is True:\n        dayticks = range(len(daylabels))\n    elif dayticks is False:\n        dayticks = []\n    elif isinstance(dayticks, int):\n        dayticks = range(len(daylabels))[dayticks // 2::dayticks]\n\n    ax.set_xlabel('')\n    ax.set_xticks([by_day.ix[datetime.date(year, i + 1, 15)].week\n                   for i in monthticks])\n    ax.set_xticklabels([monthlabels[i] for i in monthticks], ha='center')\n\n    ax.set_ylabel('')\n    ax.yaxis.set_ticks_position('right')\n    ax.set_yticks([6 - i + 0.5 for i in dayticks])\n    ax.set_yticklabels([daylabels[i] for i in dayticks], rotation='horizontal',\n                       va='center')\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calendarplot(data, how='sum', yearlabels=True, yearascending=True, yearlabel_kws=None,\n                 subplot_kws=None, gridspec_kws=None, fig_kws=None, **kwargs):\n    \"\"\"\n    Plot a timeseries as a calendar heatmap.\n\n    Parameters\n    ----------\n    data : Series\n        Data for the plot. Must be indexed by a DatetimeIndex.\n    how : string\n        Method for resampling data by day. If `None`, assume data is already\n        sampled by day and don't resample. Otherwise, this is passed to Pandas\n        `Series.resample`.\n    yearlabels : bool\n       Whether or not to draw the year for each subplot.\n    yearascending : bool\n       Sort the calendar in ascending or descending order.\n    yearlabel_kws : dict\n       Keyword arguments passed to the matplotlib `set_ylabel` call which is\n       used to draw the year for each subplot.\n    subplot_kws : dict\n        Keyword arguments passed to the matplotlib `add_subplot` call used to\n        create each subplot.\n    gridspec_kws : dict\n        Keyword arguments passed to the matplotlib `GridSpec` constructor used\n        to create the grid the subplots are placed on.\n    fig_kws : dict\n        Keyword arguments passed to the matplotlib `figure` call.\n    kwargs : other keyword arguments\n        All other keyword arguments are passed to `yearplot`.\n\n    Returns\n    -------\n    fig, axes : matplotlib Figure and Axes\n        Tuple where `fig` is the matplotlib Figure object `axes` is an array\n        of matplotlib Axes objects with the calendar heatmaps, one per year.\n\n    Examples\n    --------\n\n    With `calendarplot` we can plot several years in one figure:\n\n    .. plot::\n        :context: close-figs\n\n        calmap.calendarplot(events)\n\n    \"\"\"\n    yearlabel_kws = yearlabel_kws or {}\n    subplot_kws = subplot_kws or {}\n    gridspec_kws = gridspec_kws or {}\n    fig_kws = fig_kws or {}\n\n    years = np.unique(data.index.year)\n    if not yearascending:\n        years = years[::-1]\n\n    fig, axes = plt.subplots(nrows=len(years), ncols=1, squeeze=False,\n                             subplot_kw=subplot_kws,\n                             gridspec_kw=gridspec_kws, **fig_kws)\n    axes = axes.T[0]\n\n    # We explicitely resample by day only once. This is an optimization.\n    if how is None:\n        by_day = data\n    else:\n        if _pandas_18:\n            by_day = data.resample('D').agg(how)\n        else:\n            by_day = data.resample('D', how=how)\n\n    ylabel_kws = dict(\n        fontsize=32,\n        color=kwargs.get('fillcolor', 'whitesmoke'),\n        fontweight='bold',\n        fontname='Arial',\n        ha='center')\n    ylabel_kws.update(yearlabel_kws)\n\n    max_weeks = 0\n\n    for year, ax in zip(years, axes):\n        yearplot(by_day, year=year, how=None, ax=ax, **kwargs)\n        max_weeks = max(max_weeks, ax.get_xlim()[1])\n\n        if yearlabels:\n            ax.set_ylabel(str(year), **ylabel_kws)\n\n    # In a leap year it might happen that we have 54 weeks (e.g., 2012).\n    # Here we make sure the width is consistent over all years.\n    for ax in axes:\n        ax.set_xlim(0, max_weeks)\n\n    # Make the axes look good.\n    plt.tight_layout()\n\n    return fig, axes", "response": "Plot a timeseries as a calendar heatmap."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a geosgeometry string into a dictionary.", "response": "def geosgeometry_str_to_struct(value):\n    '''\n    Parses a geosgeometry string into struct.\n\n    Example:\n        SRID=5432;POINT(12.0 13.0)\n    Returns:\n        >> [5432, 12.0, 13.0]\n    '''\n\n    result = geos_ptrn.match(value)\n\n    if not result:\n        return None\n\n    return {\n        'srid': result.group(1),\n        'x': result.group(2),\n        'y': result.group(3),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_env(name, default=None):\n    if name in os.environ:\n        return os.environ[name]\n\n    if default is not None:\n        return default\n\n    error_msg = \"Set the {} env variable\".format(name)\n    raise ImproperlyConfigured(error_msg)", "response": "Get the environment variable or return exception"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_nodehandler(self, node):\n        out = None\n        if node in self.node_handlers:\n            out = self.node_handlers.pop(node)\n        return out", "response": "remove support for a node\n        returns the current node handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set of symbols that have been added to symtable after the system has been constructed.", "response": "def user_defined_symbols(self):\n        \"\"\"Return a set of symbols that have been added to symtable after\n        construction.\n\n        I.e., the symbols from self.symtable that are not in\n        self.no_deepcopy.\n\n        Returns\n        -------\n        unique_symbols : set\n            symbols in symtable that are not in self.no_deepcopy\n\n        \"\"\"\n        sym_in_current = set(self.symtable.keys())\n        sym_from_construction = set(self.no_deepcopy)\n        unique_symbols = sym_in_current.difference(sym_from_construction)\n        return unique_symbols"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self, text):\n        self.expr = text\n        try:\n            out = ast.parse(text)\n        except SyntaxError:\n            self.raise_exception(None, msg='Syntax Error', expr=text)\n        except:\n            self.raise_exception(None, msg='Runtime Error', expr=text)\n\n        return out", "response": "Parse statement to Ast representation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, node, expr=None, lineno=None, with_raise=True):\n        # Note: keep the 'node is None' test: internal code here may run\n        #    run(None) and expect a None in return.\n        if time.time() - self.start_time > self.max_time:\n            raise RuntimeError(ERR_MAX_TIME.format(self.max_time))\n        out = None\n        if len(self.error) > 0:\n            return out\n        if node is None:\n            return out\n        if isinstance(node, str):\n            node = self.parse(node)\n        if lineno is not None:\n            self.lineno = lineno\n        if expr is not None:\n            self.expr = expr\n\n        # get handler for this node:\n        #   on_xxx with handle nodes of type 'xxx', etc\n        try:\n            handler = self.node_handlers[node.__class__.__name__.lower()]\n        except KeyError:\n            return self.unimplemented(node)\n\n        # run the handler:  this will likely generate\n        # recursive calls into this run method.\n        try:\n            ret = handler(node)\n            if isinstance(ret, enumerate):\n                ret = list(ret)\n            return ret\n        except:\n            if with_raise:\n                self.raise_exception(node, expr=expr)", "response": "Execute parsed Ast representation for an expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eval(self, expr, lineno=0, show_errors=True):\n        self.lineno = lineno\n        self.error = []\n        self.start_time = time.time()\n        try:\n            node = self.parse(expr)\n        except:\n            errmsg = exc_info()[1]\n            if len(self.error) > 0:\n                errmsg = \"\\n\".join(self.error[0].get_error())\n            if not show_errors:\n                try:\n                    exc = self.error[0].exc\n                except:\n                    exc = RuntimeError\n                raise exc(errmsg)\n            print(errmsg, file=self.err_writer)\n            return\n        try:\n            return self.run(node, expr=expr, lineno=lineno)\n        except:\n            errmsg = exc_info()[1]\n            if len(self.error) > 0:\n                errmsg = \"\\n\".join(self.error[0].get_error())\n            if not show_errors:\n                try:\n                    exc = self.error[0].exc\n                except:\n                    exc = RuntimeError\n                raise exc(errmsg)\n            print(errmsg, file=self.err_writer)\n            return", "response": "Evaluate a single statement."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn statement: look for None return special sentinal.", "response": "def on_return(self, node):  # ('value',)\n        \"\"\"Return statement: look for None, return special sentinal.\"\"\"\n        self.retval = self.run(node.value)\n        if self.retval is None:\n            self.retval = ReturnedNone\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_dict(self, node):    # ('keys', 'values')\n        return dict([(self.run(k), self.run(v)) for k, v in\n                     zip(node.keys, node.values)])", "response": "Returns a dictionary of keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassign a value to a node. This is used by on_assign but also by on_list comprehension and list comprehension etc.", "response": "def node_assign(self, node, val):\n        \"\"\"Assign a value (not the node.value object) to a node.\n\n        This is used by on_assign, but also by for, list comprehension,\n        etc.\n\n        \"\"\"\n        if node.__class__ == ast.Name:\n            if not valid_symbol_name(node.id) or node.id in self.readonly_symbols:\n                errmsg = \"invalid symbol name (reserved word?) %s\" % node.id\n                self.raise_exception(node, exc=NameError, msg=errmsg)\n            self.symtable[node.id] = val\n            if node.id in self.no_deepcopy:\n                self.no_deepcopy.remove(node.id)\n\n        elif node.__class__ == ast.Attribute:\n            if node.ctx.__class__ == ast.Load:\n                msg = \"cannot assign to attribute %s\" % node.attr\n                self.raise_exception(node, exc=AttributeError, msg=msg)\n\n            setattr(self.run(node.value), node.attr, val)\n\n        elif node.__class__ == ast.Subscript:\n            sym = self.run(node.value)\n            xslice = self.run(node.slice)\n            if isinstance(node.slice, ast.Index):\n                sym[xslice] = val\n            elif isinstance(node.slice, ast.Slice):\n                sym[slice(xslice.start, xslice.stop)] = val\n            elif isinstance(node.slice, ast.ExtSlice):\n                sym[xslice] = val\n        elif node.__class__ in (ast.Tuple, ast.List):\n            if len(val) == len(node.elts):\n                for telem, tval in zip(node.elts, val):\n                    self.node_assign(telem, tval)\n            else:\n                raise ValueError('too many values to unpack')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_print(self, node):    # ('dest', 'values', 'nl')\n        dest = self.run(node.dest) or self.writer\n        end = ''\n        if node.nl:\n            end = '\\n'\n        out = [self.run(tnode) for tnode in node.values]\n        if out and len(self.error) == 0:\n            self._printer(*out, file=dest, end=end)", "response": "Print the set of keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_if(self, node):    # ('test', 'body', 'orelse')\n        block = node.body\n        if not self.run(node.test):\n            block = node.orelse\n        for tnode in block:\n            self.run(tnode)", "response": "Regular if - then - else statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_try(self, node):    # ('body', 'handlers', 'orelse', 'finalbody')\n        no_errors = True\n        for tnode in node.body:\n            self.run(tnode, with_raise=False)\n            no_errors = no_errors and len(self.error) == 0\n            if len(self.error) > 0:\n                e_type, e_value, e_tback = self.error[-1].exc_info\n                for hnd in node.handlers:\n                    htype = None\n                    if hnd.type is not None:\n                        htype = builtins.get(hnd.type.id, None)\n                    if htype is None or isinstance(e_type(), htype):\n                        self.error = []\n                        if hnd.name is not None:\n                            self.node_assign(hnd.name, e_value)\n                        for tline in hnd.body:\n                            self.run(tline)\n                        break\n                break\n        if no_errors and hasattr(node, 'orelse'):\n            for tnode in node.orelse:\n                self.run(tnode)\n\n        if hasattr(node, 'finalbody'):\n            for tnode in node.finalbody:\n                self.run(tnode)", "response": "Try and catch blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_raise(self, node):    # ('type', 'inst', 'tback')\n        if version_info[0] == 3:\n            excnode = node.exc\n            msgnode = node.cause\n        else:\n            excnode = node.type\n            msgnode = node.inst\n        out = self.run(excnode)\n        msg = ' '.join(out.args)\n        msg2 = self.run(msgnode)\n        if msg2 not in (None, 'None'):\n            msg = \"%s: %s\" % (msg, msg2)\n        self.raise_exception(None, exc=out.__class__, msg=msg, expr='')", "response": "Raise statement for the current exception and exception."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _open(filename, mode='r', buffering=0):\n    if mode not in ('r', 'rb', 'rU'):\n        raise RuntimeError(\"Invalid open file mode, must be 'r', 'rb', or 'rU'\")\n    if buffering > MAX_OPEN_BUFFER:\n        raise RuntimeError(\"Invalid buffering value, max buffer size is {}\".format(MAX_OPEN_BUFFER))\n    return open(filename, mode, buffering)", "response": "read only version of open"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsafing version of pow", "response": "def safe_pow(base, exp):\n    \"\"\"safe version of pow\"\"\"\n    if exp > MAX_EXPONENT:\n        raise RuntimeError(\"Invalid exponent, max exponent is {}\".format(MAX_EXPONENT))\n    return base ** exp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef safe_mult(a, b):\n    if isinstance(a, str) and isinstance(b, int) and len(a) * b > MAX_STR_LEN:\n        raise RuntimeError(\"String length exceeded, max string length is {}\".format(MAX_STR_LEN))\n    return a * b", "response": "safe version of multiply"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef safe_add(a, b):\n    if isinstance(a, str) and isinstance(b, str) and len(a) + len(b) > MAX_STR_LEN:\n        raise RuntimeError(\"String length exceeded, max string length is {}\".format(MAX_STR_LEN))\n    return a + b", "response": "safe version of add"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_lshift(a, b):\n    if b > MAX_SHIFT:\n        raise RuntimeError(\"Invalid left shift, max left shift is {}\".format(MAX_SHIFT))\n    return a << b", "response": "safe version of lshift"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the input symbol name is a valid name.", "response": "def valid_symbol_name(name):\n    \"\"\"Determine whether the input symbol name is a valid name.\n\n    Arguments\n    ---------\n      name  : str\n         name to check for validity.\n\n    Returns\n    --------\n      valid :  bool\n        whether name is a a valid symbol name\n\n    This checks for Python reserved words and that the name matches\n    the regular expression ``[a-zA-Z_][a-zA-Z0-9_]``\n    \"\"\"\n    if name in RESERVED_WORDS:\n        return False\n\n    gen = generate_tokens(io.BytesIO(name.encode('utf-8')).readline)\n    typ, _, start, end, _ = next(gen)\n    if typ == tk_ENCODING:\n        typ, _, start, end, _ = next(gen)\n    return typ == tk_NAME and start == (1, 0) and end == (1, len(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_symbol_table(use_numpy=True, **kws):\n    symtable = {}\n\n    for sym in FROM_PY:\n        if sym in builtins:\n            symtable[sym] = builtins[sym]\n\n    for sym in FROM_MATH:\n        if hasattr(math, sym):\n            symtable[sym] = getattr(math, sym)\n\n    if HAS_NUMPY and use_numpy:\n        for sym in FROM_NUMPY:\n            if hasattr(numpy, sym):\n                symtable[sym] = getattr(numpy, sym)\n        for name, sym in NUMPY_RENAMES.items():\n            if hasattr(numpy, sym):\n                symtable[name] = getattr(numpy, sym)\n\n\n    symtable.update(LOCALFUNCS)\n    symtable.update(kws)\n\n    return symtable", "response": "Create a default symbol table for the user - defined symbols."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generic_visit(self, node):\n        if node.__class__.__name__ == 'Name':\n            if node.ctx.__class__ == ast.Load and node.id not in self.names:\n                self.names.append(node.id)\n        ast.NodeVisitor.generic_visit(self, node)", "response": "This method is called by the node visitor when the node is not in the list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_env(self, key):\n        if self._env_key_replacer is not None:\n            key = key.replace(*self._env_key_replacer)\n        return os.getenv(key)", "response": "Wrapper around os. getenv which replaces characters\n        in the original key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a path for Vyper to search for the config file in.", "response": "def add_config_path(self, path):\n        \"\"\"Add a path for Vyper to search for the config file in.\n        Can be called multiple times to define multiple search paths.\n        \"\"\"\n        abspath = util.abs_pathify(path)\n        if abspath not in self._config_paths:\n            log.info(\"Adding {0} to paths to search\".format(abspath))\n            self._config_paths.append(abspath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a remote provider to the list of remote providers.", "response": "def add_remote_provider(self, provider, client, path):\n        \"\"\"Adds a remote configuration source.\n        Remote Providers are searched in the order they are added.\n        provider is a string value, \"etcd\", \"consul\" and \"zookeeper\" are\n        currently supported.\n        client is a client object\n        path is the path in the k/v store to retrieve configuration\n        To retrieve a config file called myapp.json from /configs/myapp.json\n        you should set path to /configs and set config name (set_config_name)\n        to \"myapp\"\n        \"\"\"\n        if provider not in constants.SUPPORTED_REMOTE_PROVIDERS:\n            raise errors.UnsupportedRemoteProviderError(provider)\n\n        host = \"\"\n        if provider == \"etcd\":\n            host = \"{0}://{1}:{2}\".format(client.protocol, client.host,\n                                          client.port)\n        elif provider == \"consul\":\n            host = \"{0}://{1}:{2}\".format(client.http.scheme, client.http.host,\n                                          client.http.port)\n        elif provider == \"zookeeper\":\n            host = \",\".join(\n                str(\"{0}:{1}\".format(h[0], h[1])) for h in client.hosts)\n\n        log.info(\"Adding {0}:{1} to remote provider list\".format(\n            provider, host))\n\n        rp = remote.RemoteProvider(provider, client, path, self)\n        if not self._provider_path_exists(rp):\n            self._remote_providers.append(rp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a value from the configuration store.", "response": "def get(self, key):\n        \"\"\"Vyper is essentially repository for configurations.\n        `get` can retrieve any value given the key to use.\n        `get` has the behavior of returning the value associated with the first\n        place from where it is set. Viper will check in the following order:\n        override, arg, env, config file, key/value store, default.\n        \"\"\"\n        path = key.split(self._key_delimiter)\n\n        lowercase_key = key.lower()\n        val = self._find(lowercase_key)\n\n        if val is None:\n            source = self._find(path[0].lower())\n            if source is not None and isinstance(source, dict):\n                val = self._search_dict(source, path[1::])\n\n        if val is None:\n            return None\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new Vyper instance representing a sub tree of this instance.", "response": "def sub(self, key):\n        \"\"\"Returns new Vyper instance representing a sub tree of this instance.\n        \"\"\"\n        subv = Vyper()\n        data = self.get(key)\n        if isinstance(data, dict):\n            subv._config = data\n            return subv\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a single key and unmarshalls it into a class.", "response": "def unmarshall_key(self, key, cls):\n        \"\"\"Takes a single key and unmarshalls it into a class.\"\"\"\n        return setattr(cls, key, self.get(key))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unmarshall(self, cls):\n        for k, v in self.all_settings().items():\n            setattr(cls, k, v)\n\n        return cls", "response": "Unmarshalls the config into a class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbinds a Vyper key to an ENV variable.", "response": "def bind_env(self, *input_):\n        \"\"\"Binds a Vyper key to a ENV variable.\n        ENV variables are case sensitive.\n        If only a key is provided, it will use the env key matching the key,\n        uppercased.\n        `env_prefix` will be used when set when env name is not provided.\n        \"\"\"\n        if len(input_) == 0:\n            return \"bind_env missing key to bind to\"\n\n        key = input_[0].lower()\n\n        if len(input_) == 1:\n            env_key = self._merge_with_env_prefix(key)\n        else:\n            env_key = input_[1]\n\n        self._env[key] = env_key\n\n        if self._key_delimiter in key:\n            parts = input_[0].split(self._key_delimiter)\n            env_info = {\n                \"path\": parts[1:-1],\n                \"final_key\": parts[-1],\n                \"env_key\": env_key\n            }\n\n            if self._env.get(parts[0]) is None:\n                self._env[parts[0]] = [env_info]\n            else:\n                self._env[parts[0]].append(env_info)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a key find the value of the key in the cache.", "response": "def _find(self, key):\n        \"\"\"Given a key, find the value\n        Vyper will check in the following order:\n        override, arg, env, config file, key/value store, default\n        Vyper will check to see if an alias exists first.\n        \"\"\"\n        key = self._real_key(key)\n\n        # OVERRIDES\n        val = self._override.get(key)\n        if val is not None:\n            log.debug(\"{0} found in override: {1}\".format(key, val))\n            return val\n\n        # ARGS\n        val = self._args.get(key)\n        if val is not None:\n            log.debug(\"{0} found in args: {1}\".format(key, val))\n            return val\n\n        # ENVIRONMENT VARIABLES\n        if self._automatic_env_applied:\n            # even if it hasn't been registered, if `automatic_env` is used,\n            # check any `get` request\n            val = self._get_env(self._merge_with_env_prefix(key))\n            if val is not None:\n                log.debug(\"{0} found in environment: {1}\".format(key, val))\n                return val\n\n        env_key = self._find_insensitive(key, self._env)\n        log.debug(\"Looking for {0} in env\".format(key))\n        if isinstance(env_key, list):\n            parent = self._find_insensitive(key, self._config)\n            found_in_env = False\n            log.debug(\"Found env key parent {0}: {1}\".format(key, parent))\n\n            for item in env_key:\n                log.debug(\"{0} registered as env var parent {1}:\".format(\n                    key, item[\"env_key\"]))\n                val = self._get_env(item[\"env_key\"])\n\n                if val is not None:\n                    log.debug(\"{0} found in environment: {1}\".format(\n                        item[\"env_key\"], val))\n                    temp = parent\n                    for path in item[\"path\"]:\n                        real_key = self._find_real_key(path, temp)\n                        temp = temp[real_key]\n\n                    self._set_insensitive(item[\"final_key\"], val, temp)\n                    found_in_env = True\n                else:\n                    log.debug(\"{0} env value unset\".format(item[\"env_key\"]))\n\n            if found_in_env:\n                return parent\n\n        elif env_key is not None:\n            log.debug(\"{0} registered as env var: {1}\".format(key, env_key))\n            val = self._get_env(env_key)\n            if val is not None:\n                log.debug(\"{0} found in environment: {1}\".format(env_key, val))\n                return val\n            else:\n                log.debug(\"{0} env value unset\".format(env_key))\n\n        # CONFIG FILE\n        val = self._find_insensitive(key, self._config)\n        if val is not None:\n            log.debug(\"{0} found in config: {1}\".format(key, val))\n            return val\n\n        # Test for nested config parameter\n        if self._key_delimiter in key:\n            path = key.split(self._key_delimiter)\n\n            source = self._find(path[0])\n            if source is not None and isinstance(source, dict):\n                val = self._search_dict(source, path[1::])\n                if val is not None:\n                    log.debug(\"{0} found in nested config: {1}\".format(\n                        key, val))\n                    return val\n\n        # KEY/VALUE STORE\n        val = self._kvstore.get(key)\n        if val is not None:\n            log.debug(\"{0} found in key/value store: {1}\".format(key, val))\n            return val\n\n        # DEFAULTS\n        val = self._defaults.get(key)\n        if val is not None:\n            log.debug(\"{0} found in defaults: {1}\".format(key, val))\n            return val\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_set(self, key):\n        path = key.split(self._key_delimiter)\n\n        lower_case_key = key.lower()\n        val = self._find(lower_case_key)\n\n        if val is None:\n            source = self._find(path[0].lower())\n            if source is not None and isinstance(source, dict):\n                val = self._search_dict(source, path[1::])\n\n        return val is not None", "response": "Check to see if the key has been set in any of the data locations."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an alias to the current instance.", "response": "def register_alias(self, alias, key):\n        \"\"\"Aliases provide another accessor for the same key.\n        This enables one to change a name without breaking the application.\n        \"\"\"\n        alias = alias.lower()\n        key = key.lower()\n        if alias != key and alias != self._real_key(key):\n            exists = self._aliases.get(alias)\n\n            if exists is None:\n                # if we alias something that exists in one of the dicts to\n                # another name, we'll never be able to get that value using the\n                # original name, so move the config value to the new _real_key.\n                val = self._config.get(alias)\n                if val:\n                    self._config.pop(alias)\n                    self._config[key] = val\n                val = self._kvstore.get(alias)\n                if val:\n                    self._kvstore.pop(alias)\n                    self._kvstore[key] = val\n                val = self._defaults.get(alias)\n                if val:\n                    self._defaults.pop(alias)\n                    self._defaults[key] = val\n                val = self._override.get(alias)\n                if val:\n                    self._override.pop(alias)\n                    self._override[key] = val\n\n                self._aliases[alias] = key\n        else:\n            log.warning(\"Creating circular reference alias {0} {1} {2}\".format(\n                alias, key, self._real_key(key)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef in_config(self, key):\n        # if the requested key is an alias, then return the proper key\n        key = self._real_key(key)\n\n        exists = self._config.get(key)\n        return exists", "response": "Check to see if the given key is in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the default value for this key.", "response": "def set_default(self, key, value):\n        \"\"\"Set the default value for this key.\n        Default only used when no value is provided by the user via\n        arg, config or env.\n        \"\"\"\n        k = self._real_key(key.lower())\n        self._defaults[k] = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, key, value):\n        k = self._real_key(key.lower())\n        self._override[k] = value", "response": "Sets the value for the key in the override register."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_in_config(self):\n        log.info(\"Attempting to read in config file\")\n        if self._get_config_type() not in constants.SUPPORTED_EXTENSIONS:\n            raise errors.UnsupportedConfigError(self._get_config_type())\n\n        with open(self._get_config_file()) as fp:\n            f = fp.read()\n\n        self._config = {}\n\n        return self._unmarshall_reader(f, self._config)", "response": "Reads in the configuration file and returns the dictionary of the key - value store and the value - store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the first found remote configuration.", "response": "def _get_key_value_config(self):\n        \"\"\"Retrieves the first found remote configuration.\"\"\"\n        for rp in self._remote_providers:\n            val = self._get_remote_config(rp)\n            self._kvstore = val\n            return None\n\n        raise errors.RemoteConfigError(\"No Files Found\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_keys(self, uppercase_keys=False):\n        d = {}\n\n        for k in self._override.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._args.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._env.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._config.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._kvstore.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._defaults.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        for k in self._aliases.keys():\n            d[k.upper() if uppercase_keys else k.lower()] = {}\n\n        return d.keys()", "response": "Return all keys regardless where they are set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all settings as a dict.", "response": "def all_settings(self, uppercase_keys=False):\n        \"\"\"Return all settings as a `dict`.\"\"\"\n        d = {}\n\n        for k in self.all_keys(uppercase_keys):\n            d[k] = self.get(k)\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_config_file(self):\n        log.info(\"Searching for config in: {0}\".format(\n            \", \".join(str(p) for p in self._config_paths)))\n\n        for cp in self._config_paths:\n            f = self._search_in_path(cp)\n            if f != \"\":\n                return f\n\n        raise errors.ConfigFileNotFoundError(\n            self._config_name, self._config_paths)", "response": "Search all config_paths for any config file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef debug(self):  # pragma: no cover\n\n        print(\"Aliases:\")\n        pprint.pprint(self._aliases)\n        print(\"Override:\")\n        pprint.pprint(self._override)\n        print(\"Args:\")\n        pprint.pprint(self._args)\n        print(\"Env:\")\n        pprint.pprint(self._env)\n        print(\"Config:\")\n        pprint.pprint(self._config)\n        print(\"Key/Value Store:\")\n        pprint.pprint(self._kvstore)\n        print(\"Defaults:\")\n        pprint.pprint(self._defaults)", "response": "Prints all configuration registries for debugging purposes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef server(**kwargs):\n    start_server(**{k: v for k, v in kwargs.items() if v},\n                 blocking=True)", "response": "Starts the Clearly Server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting a Clearly Server programmatically.", "response": "def start_server(broker, backend=None, port=12223,\n                 max_tasks=10000, max_workers=100,\n                 blocking=False, debug=False):  # pragma: no cover\n    \"\"\"Starts a Clearly Server programmatically.\"\"\"\n    _setup_logging(debug)\n\n    queue_listener_dispatcher = Queue()\n    listener = EventListener(broker, queue_listener_dispatcher, backend=backend,\n                             max_tasks_in_memory=max_tasks,\n                             max_workers_in_memory=max_workers)\n    dispatcher = StreamingDispatcher(queue_listener_dispatcher)\n    clearlysrv = ClearlyServer(listener, dispatcher)\n    return _serve(clearlysrv, port, blocking)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _event_to_pb(event):\n        if isinstance(event, (TaskData, Task)):\n            key, klass = 'task', clearly_pb2.TaskMessage\n        elif isinstance(event, (WorkerData, Worker)):\n            key, klass = 'worker', clearly_pb2.WorkerMessage\n        else:\n            raise ValueError('unknown event')\n        keys = klass.DESCRIPTOR.fields_by_name.keys()\n        # noinspection PyProtectedMember\n        data = {k: v for k, v in\n                getattr(event, '_asdict',  # internal TaskData and WorkerData\n                        lambda: {f: getattr(event, f) for f in event._fields})  # celery Task and Worker\n                ().items() if k in keys}\n        return key, klass(**data)", "response": "Supports converting internal TaskData and WorkerData and celery Task and Worker to proto buffers messages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter tasks by matching patterns to name routing key and state.", "response": "def filter_tasks(self, request, context):\n        \"\"\"Filter tasks by matching patterns to name, routing key and state.\"\"\"\n        _log_request(request, context)\n        tasks_pattern, tasks_negate = PATTERN_PARAMS_OP(request.tasks_filter)\n        state_pattern = request.state_pattern\n        limit, reverse = request.limit, request.reverse\n\n        pregex = re.compile(tasks_pattern)  # pattern filter condition\n        sregex = re.compile(state_pattern)  # state filter condition\n\n        def pcondition(task):\n            return accepts(pregex, tasks_negate, task.name, task.routing_key)\n\n        def scondition(task):\n            return accepts(sregex, tasks_negate, task.state)\n\n        found_tasks = (task for _, task in\n                       self.listener.memory.tasks_by_time(limit=limit or None,\n                                                          reverse=reverse)\n                       if pcondition(task) and scondition(task))\n\n        def callback(t):\n            logger.debug('%s iterated %d tasks in %s (%s)', self.filter_tasks.__name__,\n                         t.count, t.duration_human, t.throughput_human)\n\n        for task in about_time(callback, found_tasks):\n            yield ClearlyServer._event_to_pb(task)[1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter workers by matching a pattern to hostname.", "response": "def filter_workers(self, request, context):\n        \"\"\"Filter workers by matching a pattern to hostname.\"\"\"\n        _log_request(request, context)\n        workers_pattern, workers_negate = PATTERN_PARAMS_OP(request.workers_filter)\n\n        hregex = re.compile(workers_pattern)  # hostname filter condition\n\n        def hcondition(worker):\n            return accepts(hregex, workers_negate, worker.hostname)  # pragma: no branch\n\n        found_workers = (worker for worker in\n                         sorted(self.listener.memory.workers.values(),\n                                key=WORKER_HOSTNAME_OP)\n                         if hcondition(worker))\n\n        def callback(t):\n            logger.debug('%s iterated %d workers in %s (%s)', self.filter_workers.__name__,\n                         t.count, t.duration_human, t.throughput_human)\n\n        for worker in about_time(callback, found_workers):\n            yield ClearlyServer._event_to_pb(worker)[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_task(self, request, context):\n        _log_request(request, context)\n        task = self.listener.memory.tasks.get(request.task_uuid)\n        if not task:\n            return clearly_pb2.TaskMessage()\n        return ClearlyServer._event_to_pb(task)[1]", "response": "Finds one specific task."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all seen task types.", "response": "def seen_tasks(self, request, context):\n        \"\"\"Returns all seen task types.\"\"\"\n        _log_request(request, context)\n        result = clearly_pb2.SeenTasksMessage()\n        result.task_types.extend(self.listener.memory.task_types())\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting all captured tasks.", "response": "def reset_tasks(self, request, context):\n        \"\"\"Resets all captured tasks.\"\"\"\n        _log_request(request, context)\n        self.listener.memory.clear_tasks()\n        return clearly_pb2.Empty()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_stats(self, request, context):\n        _log_request(request, context)\n        m = self.listener.memory\n        return clearly_pb2.StatsMessage(\n            task_count=m.task_count,\n            event_count=m.event_count,\n            len_tasks=len(m.tasks),\n            len_workers=len(m.workers)\n        )", "response": "Returns the server statistics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef safe_compile_text(txt, raises=False):\n\n    def _convert(node):\n        if isinstance(node, ast.Tuple):\n            return tuple(map(_convert, node.elts))\n\n        if isinstance(node, ast.List):\n            return list(map(_convert, node.elts))\n\n        if isinstance(node, ast.Set):\n            return set(map(_convert, node.elts))\n\n        if isinstance(node, ast.Dict):\n            return OrderedDict((_convert(k), _convert(v))\n                               for k, v in zip(node.keys, node.values))\n\n        if isinstance(node, ast.Call):\n            name = _convert(node.func)\n            args = tuple(map(_convert, node.args))\n            if name in ('tuple', 'list', 'set'):\n                if len(node.args) > 1:\n                    raise ValueError('{} takes at most 1 argument'.format(name))\n                params = args[0] if node.args else ()\n                return tuple(params) if name == 'tuple' else \\\n                    list(params) if name == 'list' else \\\n                        set(params)\n            kwargs = OrderedDict((k.arg, _convert(k.value))\n                                 for k in node.keywords)\n            if name == 'dict':\n                return kwargs\n            return CallDescriptor(name,\n                                  args if args else None,\n                                  kwargs if kwargs else None)\n\n        if isinstance(node, ast.Attribute):\n            return '.'.join((node.value.id, node.attr))\n\n        try:\n            return ast.literal_eval(node)\n        except ValueError:\n            if isinstance(node, ast.Name):\n                return node.id\n            return 'unsupported: {}'.format(type(node))\n\n    txt = NON_PRINTABLE_PATTERN.sub(_encode_to_hex, txt)\n    try:\n        txt = ast.parse(txt, mode='eval')\n    except SyntaxError:\n        if raises:\n            raise\n        return txt\n\n    return _convert(txt.body)", "response": "This function compiles the given text into a safe Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef accepts(regex, negate, *values):\n    return any(v and regex.search(v) for v in values) != negate", "response": "Returns True if any of the values in values match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the PB object with some fields updated.", "response": "def copy_update(pb_message, **kwds):\n    \"\"\"Returns a copy of the PB object, with some fields updated.\n\n    Args:\n        pb_message:\n        **kwds:\n\n    Returns:\n\n    \"\"\"\n    result = pb_message.__class__()\n    result.CopyFrom(pb_message)\n    for k, v in kwds.items():\n        setattr(result, k, v)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the real - time engine that captures tasks.", "response": "def __start(self):  # pragma: no cover\n        \"\"\"Starts the real-time engine that captures tasks.\"\"\"\n\n        assert not self.dispatcher_thread\n\n        self.dispatcher_thread = threading.Thread(target=self.__run_dispatcher,\n                                                  name='clearly-dispatcher')\n        self.dispatcher_thread.daemon = True\n        self.running = True  # graceful shutdown\n        self.dispatcher_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __stop(self):  # pragma: no cover\n\n        if not self.dispatcher_thread:\n            return\n\n        logger.info('Stopping dispatcher')\n        self.running = False  # graceful shutdown\n        self.dispatcher_thread.join()\n        self.dispatcher_thread = None", "response": "Stops the background engine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect a client to the streaming capture.", "response": "def streaming_client(self, tasks_regex, tasks_negate, workers_regex, workers_negate):\n        \"\"\"Connects a client to the streaming capture, filtering the events that are sent\n        to it.\n\n        Args:\n            tasks_regex (str): a pattern to filter tasks to capture.\n                ex.: '^dispatch|^email' to filter names starting with that\n                      or 'dispatch.*123456' to filter that exact name and number\n                      or even '123456' to filter that exact number anywhere.\n            tasks_negate (bool): if True, finds tasks that do not match criteria\n            workers_regex (str): a pattern to filter workers to capture.\n                ex.: 'service|priority' to filter names containing that\n            workers_negate (bool): if True, finds workers that do not match criteria\n        \"\"\"\n\n        cc = CapturingClient(Queue(),\n                             re.compile(tasks_regex), tasks_negate,\n                             re.compile(workers_regex), workers_negate)\n\n        self.observers.append(cc)\n        yield cc.queue\n        self.observers.remove(cc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef immutable_task(task, state, pre_state, created):\n    # noinspection PyUnresolvedReferences,PyProtectedMember\n    return TaskData._make(chain(\n        (getattr(task, f) for f in TASK_OWN_FIELDS),\n        (state, pre_state, created),\n    ))", "response": "Converts a task to an immutable slots class to handle internally."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef immutable_worker(worker, state, pre_state, created):\n    # noinspection PyUnresolvedReferences,PyProtectedMember\n    return WorkerData._make(chain(\n        (getattr(worker, f) for f in WORKER_OWN_FIELDS),\n        (state, pre_state, created),\n        (worker.heartbeats[-1] if worker.heartbeats else None,),\n    ))", "response": "Converts a worker to an immutable slots class to handle internally."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __start(self):  # pragma: no cover\n\n        assert not self._listener_thread\n\n        self._listener_thread = threading.Thread(target=self.__run_listener,\n                                                 name='clearly-listener')\n        self._listener_thread.daemon = True\n        self._listener_thread.start()\n        self._wait_event.wait()\n        self._wait_event.clear()", "response": "Starts the real - time engine that captures events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __stop(self):  # pragma: no cover\n\n        if not self._listener_thread:\n            return\n\n        logger.info('Stopping listener')\n        self._celery_receiver.should_stop = True\n        self._listener_thread.join()\n        self._listener_thread = self._celery_receiver = None", "response": "Stops the background engine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef capture(self, pattern=None, negate=False, workers=None, negate_workers=False,\n                params=None, success=False, error=True, stats=False):\n        \"\"\"Starts capturing selected events in real-time. You can filter exactly what\n        you want to see, as the Clearly Server handles all tasks and workers updates\n        being sent to celery. Several clients can see different sets of events at the\n        same time.\n\n        This runs in the foreground, so you can see in real-time exactly what your\n        clients and celery workers are doing.\n        Press CTRL+C at any time to stop it.\n\n        Args:\n            Filter args:\n\n            pattern (Optional[str]): a pattern to filter tasks to capture.\n                ex.: '^dispatch|^email' to filter names starting with that\n                      or 'dispatch.*123456' to filter that exact name and number\n                      or even '123456' to filter that exact number anywhere.\n            negate (bool): if True, finds tasks that do not match criteria.\n            workers (Optional[str]): a pattern to filter workers to capture.\n                ex.: 'service|priority' to filter names containing that\n            negate_workers (bool): if True, finds workers that do not match criteria.\n\n            Display args:\n\n            params (Optional[bool]): if True shows args and kwargs in the first and\n                last seen states, if False never shows, and if None follows the\n                success and error arguments.\n                default is None\n            success (bool): if True shows successful tasks' results.\n                default is False\n            error (bool): if True shows failed and retried tasks' tracebacks.\n                default is True, as you're monitoring to find errors, right?\n            stats (bool): if True shows complete workers' stats.\n                default is False\n        \"\"\"\n        request = clearly_pb2.CaptureRequest(\n            tasks_capture=clearly_pb2.PatternFilter(pattern=pattern or '.',\n                                                    negate=negate),\n            workers_capture=clearly_pb2.PatternFilter(pattern=workers or '.',\n                                                      negate=negate_workers),\n        )\n        try:\n            for realtime in self._stub.capture_realtime(request):\n                if realtime.HasField('task'):\n                    ClearlyClient._display_task(realtime.task, params, success, error)\n                elif realtime.HasField('worker'):\n                    ClearlyClient._display_worker(realtime.worker, stats)\n                else:\n                    print('unknown event:', realtime)\n                    break\n        except KeyboardInterrupt:\n            pass", "response": "Starts capturing selected events in real - time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stats(self):\n        stats = self._stub.get_stats(clearly_pb2.Empty())\n        print(Colors.DIM('Processed:'),\n              '\\ttasks', Colors.RED(stats.task_count),\n              '\\tevents', Colors.RED(stats.event_count))\n        print(Colors.DIM('Stored:'),\n              '\\ttasks', Colors.RED(stats.len_tasks),\n              '\\tworkers', Colors.RED(stats.len_workers))", "response": "Lists some metrics of the capturing system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tasks(self, pattern=None, negate=False, state=None, limit=None, reverse=True,\n              params=None, success=False, error=True):\n        \"\"\"Filters stored tasks and displays their current statuses.\n\n        Note that, to be able to list the tasks sorted chronologically, celery retrieves\n        tasks from the LRU event heap instead of the dict storage, so the total number\n        of tasks fetched may be different than the server `max_tasks` setting. For\n        instance, the `limit` field refers to max events searched, not max tasks.\n\n        Args:\n            Filter args:\n\n            pattern (Optional[str]): a pattern to filter tasks\n                ex.: '^dispatch|^email' to filter names starting with that\n                      or 'dispatch.*123456' to filter that exact name and number\n                      or even '123456' to filter that exact number anywhere.\n            negate (bool): if True, finds tasks that do not match criteria\n            state (Optional[str]): a celery task state to filter\n            limit (int): the maximum number of events to fetch\n                if None or 0, fetches all.\n            reverse (bool): if True (default), shows the most recent first\n\n            Display args:\n\n            params (Optional[bool]): if True shows args and kwargs in the first and\n                last seen states, if False never shows, and if None follows the\n                success and error arguments.\n                default is None\n            success (bool): if True shows successful tasks' results\n                default is False\n            error (bool): if True shows failed and retried tasks' tracebacks.\n                default is True, as you're monitoring to find errors, right?\n        \"\"\"\n        request = clearly_pb2.FilterTasksRequest(\n            tasks_filter=clearly_pb2.PatternFilter(pattern=pattern or '.',\n                                                   negate=negate),\n            state_pattern=state or '.', limit=limit, reverse=reverse\n        )\n\n        for task in about_time(ClearlyClient._fetched_callback, self._stub.filter_tasks(request)):\n            ClearlyClient._display_task(task, params, success, error)", "response": "Filter stored tasks and displays their current statuses."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef workers(self, pattern=None, negate=False, stats=True):\n        request = clearly_pb2.FilterWorkersRequest(\n            workers_filter=clearly_pb2.PatternFilter(pattern=pattern or '.',\n                                                     negate=negate),\n        )\n\n        for worker in about_time(ClearlyClient._fetched_callback, self._stub.filter_workers(request)):\n            ClearlyClient._display_worker(worker, stats)", "response": "Filters known workers and prints their current status."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef task(self, task_uuid):\n        request = clearly_pb2.FindTaskRequest(task_uuid=task_uuid)\n        task = self._stub.find_task(request)\n        if task.uuid:\n            ClearlyClient._display_task(task, True, True, True)\n        else:\n            print(EMPTY)", "response": "Finds one specific task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing a list of seen task types.", "response": "def seen_tasks(self):\n        \"\"\"Shows a list of seen task types.\"\"\"\n        print('\\n'.join(self._stub.seen_tasks(clearly_pb2.Empty()).task_types))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detail_action(**kwargs):\n    def decorator(func):\n        func.action = True\n        func.detail = True\n        func.kwargs = kwargs\n        return func\n    return decorator", "response": "A decorator that marks a method on a ResourceBinding that should be routed for detail actions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_action(**kwargs):\n    def decorator(func):\n        func.action = True\n        func.detail = False\n        func.kwargs = kwargs\n        return func\n    return decorator", "response": "A decorator that marks a function as a list action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbroadcasting an array to a new shape.", "response": "def broadcast_to(array, shape, subok=False):\n    \"\"\"Broadcast an array to a new shape.\n\n    Parameters\n    ----------\n    array : array_like\n        The array to broadcast.\n    shape : tuple\n        The shape of the desired array.\n    subok : bool, optional\n        If True, then sub-classes will be passed-through, otherwise\n        the returned array will be forced to be a base-class array (default).\n\n    Returns\n    -------\n    broadcast : array\n        A readonly view on the original array with the given shape. It is\n        typically not contiguous. Furthermore, more than one element of a\n        broadcasted array may refer to a single memory location.\n\n    Raises\n    ------\n    ValueError\n        If the array is not compatible with the new shape according to NumPy's\n        broadcasting rules.\n\n    Notes\n    -----\n    .. versionadded:: 1.10.0\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3])\n    >>> np.broadcast_to(x, (3, 3))\n    array([[1, 2, 3],\n           [1, 2, 3],\n           [1, 2, 3]])\n    \"\"\"\n    return _broadcast_to(array, shape, subok=subok, readonly=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating sequence of Wiener increments for m independent Wiener increments for N time intervals of length h", "response": "def deltaW(N, m, h):\n    \"\"\"Generate sequence of Wiener increments for m independent Wiener\n    processes W_j(t) j=0..m-1 for each of N time intervals of length h.    \n\n    Returns:\n      dW (array of shape (N, m)): The [n, j] element has the value\n      W_j((n+1)*h) - W_j(n*h) \n    \"\"\"\n    return np.random.normal(0.0, np.sqrt(h), (N, m))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _vec(A):\n    N, m, n = A.shape\n    return A.reshape((N, m*n, 1), order='F')", "response": "Linear operator _vec() from Wiktorsson2001 p478\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _unvec(vecA, m=None):\n    N = vecA.shape[0]\n    if m is None:\n        m = np.sqrt(vecA.shape[1] + 0.25).astype(np.int64)\n    return vecA.reshape((N, m, -1), order='F')", "response": "inverse of _vec() operator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _kp2(A, B):\n    N = A.shape[0]\n    if B.shape[0] != N:\n        raise(ValueError)\n    newshape1 = A.shape[1]*B.shape[1]\n    return np.einsum('ijk,ilm->ijlkm', A, B).reshape(N, newshape1, -1)", "response": "Special case Kronecker tensor product of A and B at each time interval i"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _AtildeTerm(N, h, m, k, dW, Km0, Pm0):\n    M = m*(m-1)//2\n    Xk = np.random.normal(0.0, 1.0, (N, m, 1))\n    Yk = np.random.normal(0.0, 1.0, (N, m, 1))\n    factor1 = np.dot(Km0, Pm0 - np.eye(m**2))\n    factor1 = broadcast_to(factor1, (N, M, m**2))\n    factor2 = _kp(Yk + np.sqrt(2.0/h)*dW, Xk)\n    return _dot(factor1, factor2)/k", "response": "kth term in the sum for Atilde"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sigmainf(N, h, m, dW, Km0, Pm0):\n    M = m*(m-1)//2\n    Im = broadcast_to(np.eye(m), (N, m, m))\n    IM = broadcast_to(np.eye(M), (N, M, M))\n    Ims0 = np.eye(m**2)\n    factor1 = broadcast_to((2.0/h)*np.dot(Km0, Ims0 - Pm0), (N, M, m**2))\n    factor2 = _kp2(Im, _dot(dW, _t(dW)))\n    factor3 = broadcast_to(np.dot(Ims0 - Pm0, Km0.T), (N, m**2, M))\n    return 2*IM + _dot(_dot(factor1, factor2), factor3)", "response": "Asymptotic covariance matrix \\Sigma_\\infty  Wiktorsson2001 eqn (4.5)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Jwik(dW, h, n=5):\n    m = dW.shape[1]\n    Atilde, I = Iwik(dW, h, n)\n    J = I + 0.5*h*np.eye(m).reshape((1, m, m))\n    return (Atilde, J)", "response": "matrix J approximating repeated Stratonovich integrals for each of the time intervals using Wiktorsson 2001."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_args(f, G, y0, tspan, dW=None, IJ=None):\n    if not np.isclose(min(np.diff(tspan)), max(np.diff(tspan))):\n        raise SDEValueError('Currently time steps must be equally spaced.')\n    # Be flexible to allow scalar equations. convert them to a 1D vector system\n    if isinstance(y0, numbers.Number):\n        if isinstance(y0, numbers.Integral):\n            numtype = np.float64\n        else:\n            numtype = type(y0)\n        y0_orig = y0\n        y0 = np.array([y0], dtype=numtype)\n        def make_vector_fn(fn):\n            def newfn(y, t):\n                return np.array([fn(y[0], t)], dtype=numtype)\n            newfn.__name__ = fn.__name__\n            return newfn\n        def make_matrix_fn(fn):\n            def newfn(y, t):\n                return np.array([[fn(y[0], t)]], dtype=numtype)\n            newfn.__name__ = fn.__name__\n            return newfn\n        if isinstance(f(y0_orig, tspan[0]), numbers.Number):\n            f = make_vector_fn(f)\n        if isinstance(G(y0_orig, tspan[0]), numbers.Number):\n            G = make_matrix_fn(G)\n    # determine dimension d of the system\n    d = len(y0)\n    if len(f(y0, tspan[0])) != d:\n        raise SDEValueError('y0 and f have incompatible shapes.')\n    message = \"\"\"y0 has length %d. So G must either be a single function\n              returning a matrix of shape (%d, m), or else a list of m separate\n              functions each returning a column of G, with shape (%d,)\"\"\" % (\n                  d, d, d)\n    if callable(G):\n        # then G must be a function returning a d x m matrix\n        Gtest = G(y0, tspan[0])\n        if Gtest.ndim != 2 or Gtest.shape[0] != d:\n            raise SDEValueError(message)\n        # determine number of independent Wiener processes m\n        m = Gtest.shape[1]\n    else:\n        # G should be a list of m functions g_i giving columns of G\n        G = tuple(G)\n        m = len(G)\n        Gtest = np.zeros((d, m))\n        for k in range(0, m):\n            if not callable(G[k]):\n                raise SDEValueError(message)\n            Gtestk = G[k](y0, tspan[0])\n            if np.shape(Gtestk) != (d,):\n                raise SDEValueError(message)\n            Gtest[:,k] = Gtestk\n    message = \"\"\"From function G, it seems m==%d. If present, the optional\n              parameter dW must be an array of shape (len(tspan)-1, m) giving\n              m independent Wiener increments for each time interval.\"\"\" % m\n    if dW is not None:\n        if not hasattr(dW, 'shape') or dW.shape != (len(tspan) - 1, m):\n            raise SDEValueError(message)\n    message = \"\"\"From function G, it seems m==%d. If present, the optional\n              parameter I or J must be an array of shape (len(tspan)-1, m, m)\n              giving an m x m matrix of repeated integral values for each\n              time interval.\"\"\" % m\n    if IJ is not None:\n        if not hasattr(IJ, 'shape') or IJ.shape != (len(tspan) - 1, m, m):\n            raise SDEValueError(message)\n    return (d, m, f, G, y0, tspan, dW, IJ)", "response": "Check the arguments of the functions f and G are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef itoint(f, G, y0, tspan):\n    # In future versions we can automatically choose here the most suitable\n    # Ito algorithm based on properties of the system and noise.\n    (d, m, f, G, y0, tspan, __, __) = _check_args(f, G, y0, tspan, None, None)\n    chosenAlgorithm = itoSRI2\n    return chosenAlgorithm(f, G, y0, tspan)", "response": "Numerically integrate the Ito equation   \u03c0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nintegrating the Ito equation with the Euler - Maruyama algorithm.", "response": "def itoEuler(f, G, y0, tspan, dW=None):\n    \"\"\"Use the Euler-Maruyama algorithm to integrate the Ito equation\n    dy = f(y,t)dt + G(y,t) dW(t)\n\n    where y is the d-dimensional state vector, f is a vector-valued function,\n    G is an d x m matrix-valued function giving the noise coefficients and\n    dW(t) = (dW_1, dW_2, ... dW_m) is a vector of independent Wiener increments\n\n    Args:\n      f: callable(y, t) returning (d,) array\n         Vector-valued function to define the deterministic part of the system\n      G: callable(y, t) returning (d,m) array\n         Matrix-valued function to define the noise coefficients of the system\n      y0: array of shape (d,) giving the initial state vector y(t==0)\n      tspan (array): The sequence of time points for which to solve for y.\n        These must be equally spaced, e.g. np.arange(0,10,0.005)\n        tspan[0] is the intial time corresponding to the initial state y0.\n      dW: optional array of shape (len(tspan)-1, d). This is for advanced use,\n        if you want to use a specific realization of the d independent Wiener\n        processes. If not provided Wiener increments will be generated randomly\n\n    Returns:\n      y: array, with shape (len(tspan), len(y0))\n         With the initial value y0 in the first row\n\n    Raises:\n      SDEValueError\n\n    See also:\n      G. Maruyama (1955) Continuous Markov processes and stochastic equations\n      Kloeden and Platen (1999) Numerical Solution of Differential Equations\n    \"\"\"\n    (d, m, f, G, y0, tspan, dW, __) = _check_args(f, G, y0, tspan, dW, None)\n    N = len(tspan)\n    h = (tspan[N-1] - tspan[0])/(N - 1)\n    # allocate space for result\n    y = np.zeros((N, d), dtype=type(y0[0]))\n    if dW is None:\n        # pre-generate Wiener increments (for m independent Wiener processes):\n        dW = deltaW(N - 1, m, h)\n    y[0] = y0;\n    for n in range(0, N-1):\n        tn = tspan[n]\n        yn = y[n]\n        dWn = dW[n,:]\n        y[n+1] = yn + f(yn, tn)*h + G(yn, tn).dot(dWn)\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stratHeun(f, G, y0, tspan, dW=None):\n    (d, m, f, G, y0, tspan, dW, __) = _check_args(f, G, y0, tspan, dW, None)\n    N = len(tspan)\n    h = (tspan[N-1] - tspan[0])/(N - 1)\n    # allocate space for result\n    y = np.zeros((N, d), dtype=type(y0[0]))\n    if dW is None:\n        # pre-generate Wiener increments (for m independent Wiener processes):\n        dW = deltaW(N - 1, m, h)\n    y[0] = y0;\n    for n in range(0, N-1):\n        tn = tspan[n]\n        tnp1 = tspan[n+1]\n        yn = y[n]\n        dWn = dW[n,:]\n        fn = f(yn, tn)\n        Gn = G(yn, tn)\n        ybar = yn + fn*h + Gn.dot(dWn)\n        fnbar = f(ybar, tnp1)\n        Gnbar = G(ybar, tnp1)\n        y[n+1] = yn + 0.5*(fn + fnbar)*h + 0.5*(Gn + Gnbar).dot(dWn)\n    return y", "response": "Integrate a function y with a random state vector y0 and a random state vector y0 with a random state vector y0 and a random state vector y0."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef itoSRI2(f, G, y0, tspan, Imethod=Ikpw, dW=None, I=None):\n    return _Roessler2010_SRK2(f, G, y0, tspan, Imethod, dW, I)", "response": "Use the Roessler2010 order 1. 0 strong Stochastic Runge - Kutta algorithm\n    SRI2 to integrate an Ito system with a strong - Stochastic Runge - Kutta algorithm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stratSRS2(f, G, y0, tspan, Jmethod=Jkpw, dW=None, J=None):\n    return _Roessler2010_SRK2(f, G, y0, tspan, Jmethod, dW, J)", "response": "Use the Roessler2010 order 1. 0 strong Stochastic Runge - Kutta algorithm\n    SRS2 to integrate a Stratonovich system with a given initial state vector y0 and a given sequence of time points tspan."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _Roessler2010_SRK2(f, G, y0, tspan, IJmethod, dW=None, IJ=None):\n    (d, m, f, G, y0, tspan, dW, IJ) = _check_args(f, G, y0, tspan, dW, IJ)\n    have_separate_g = (not callable(G)) # if G is given as m separate functions\n    N = len(tspan)\n    h = (tspan[N-1] - tspan[0])/(N - 1) # assuming equal time steps\n    if dW is None:\n        # pre-generate Wiener increments (for m independent Wiener processes):\n        dW = deltaW(N - 1, m, h) # shape (N, m)\n    if IJ is None: \n        # pre-generate repeated stochastic integrals for each time step.\n        # Must give I_ij for the Ito case or J_ij for the Stratonovich case:\n        __, I = IJmethod(dW, h) # shape (N, m, m)\n    else:\n        I = IJ\n    # allocate space for result\n    y = np.zeros((N, d), dtype=type(y0[0]))\n    y[0] = y0;\n    Gn = np.zeros((d, m), dtype=y.dtype)\n    for n in range(0, N-1):\n        tn = tspan[n]\n        tn1 = tspan[n+1]\n        h = tn1 - tn\n        sqrth = np.sqrt(h)\n        Yn = y[n] # shape (d,)\n        Ik = dW[n,:] # shape (m,)\n        Iij = I[n,:,:] # shape (m, m)\n        fnh = f(Yn, tn)*h # shape (d,)\n        if have_separate_g:\n            for k in range(0, m):\n                Gn[:,k] = G[k](Yn, tn)\n        else:\n            Gn = G(Yn, tn)\n        sum1 = np.dot(Gn, Iij)/sqrth # shape (d, m)\n        H20 = Yn + fnh # shape (d,)\n        H20b = np.reshape(H20, (d, 1))\n        H2 = H20b + sum1 # shape (d, m)\n        H30 = Yn\n        H3 = H20b - sum1\n        fn1h = f(H20, tn1)*h\n        Yn1 = Yn + 0.5*(fnh + fn1h) + np.dot(Gn, Ik)\n        if have_separate_g:\n            for k in range(0, m):\n                Yn1 += 0.5*sqrth*(G[k](H2[:,k], tn1) - G[k](H3[:,k], tn1))\n        else:\n            for k in range(0, m):\n                Yn1 += 0.5*sqrth*(G(H2[:,k], tn1)[:,k] - G(H3[:,k], tn1)[:,k])\n        y[n+1] = Yn1\n    return y", "response": "Implementation of the Roessler2010 order 1. 0 strong Stochastic Runge - Kutta\n    and SRS2 algorithms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stratKP2iS(f, G, y0, tspan, Jmethod=Jkpw, gam=None, al1=None, al2=None,\n               rtol=1e-4, dW=None, J=None):\n    \"\"\"Use the Kloeden and Platen two-step implicit order 1.0 strong algorithm\n    to integrate a Stratonovich equation dy = f(y,t)dt + G(y,t)\\circ dW(t)\n\n    This semi-implicit algorithm may be useful for stiff systems. The noise\n    does not need to be scalar, diagonal, or commutative.\n\n    This algorithm is defined in Kloeden and Platen (1999) section 12.4,\n    equations (4.5) and (4.7). Here implementing that scheme with default\n    parameters \\gamma_k = \\alpha_{1,k} = \\alpha_{2,k} = 0.5 for k=1..d using\n    MINPACK HYBRD algorithm to solve the implicit vector equation at each step.\n\n    Args:\n      f: A function f(y, t) returning an array of shape (d,) to define the\n        deterministic part of the system\n      G: A function G(y, t) returning an array of shape (d, m) to define the \n        noise coefficients of the system\n      y0: array of shape (d,) giving the initial state\n      tspan (array): Sequence of equally spaced time points\n      Jmethod (callable, optional): which function to use to simulate repeated\n        Stratonovich integrals. Here you can choose either sdeint.Jkpw (the\n        default) or sdeint.Jwik (which is more accurate but uses a lot of\n        memory in the current implementation).\n      gam, al1, al2 (optional arrays of shape (d,)): These can configure free\n        parameters \\gamma_k, \\alpha_{1,k}, \\alpha_{2,k} of the algorithm.\n        You can omit these, then the default values 0.5 will be used.\n      rtol (float, optional): Relative error tolerance. The default is 1e-4.\n        This is the relative tolerance used when solving the implicit equation\n        for Y_{n+1} at each step. It does not mean that the overall sample path\n        approximation has this relative precision.\n      dW: optional array of shape (len(tspan)-1, d). \n      J: optional array of shape (len(tspan)-1, m, m).\n        These optional arguments dW and J are for advanced use, if you want to\n        use a specific realization of the d independent Wiener processes and\n        their multiple integrals at each time step. If not provided, suitable\n        values will be generated randomly.\n \n    Returns:\n      y: array, with shape (len(tspan), len(y0))\n\n    Raises:\n      SDEValueError, RuntimeError\n\n    See also:\n      P. Kloeden and E. Platen (1999) Numerical Solution of Stochastic \n        Differential Equations, revised and updated 3rd printing.\n    \"\"\"\n    try:\n        from scipy.optimize import fsolve\n    except ImportError:\n        raise Error('stratKP2iS() requires package ``scipy`` to be installed.')\n    (d, m, f, G, y0, tspan, dW, J) = _check_args(f, G, y0, tspan, dW, J)\n    if not callable(G):\n        raise SDEValueError('G should be a function returning a d x m matrix.')\n    if np.iscomplexobj(y0):\n        raise SDEValueError(\"stratKP2iS() can't yet handle complex variables.\")\n    if gam is None:\n        gam = np.ones((d,))*0.5  # Default level of implicitness \\gamma_k = 0.5\n    if al1 is None:\n        al1 = np.ones((d,))*0.5  # Default \\alpha_{1,k} = 0.5\n    if al2 is None:\n        al2 = np.ones((d,))*0.5  # Default \\alpha_{2,k} = 0.5\n    N = len(tspan)\n    h = (tspan[N-1] - tspan[0])/(N - 1) # assuming equal time steps\n    if dW is None:\n        # pre-generate Wiener increments (for m independent Wiener processes):\n        dW = deltaW(N - 1, m, h) # shape (N, m)\n    if J is None: \n        # pre-generate repeated Stratonovich integrals for each time step\n        __, J = Jmethod(dW, h) # shape (N, m, m)\n    # allocate space for result\n    y = np.zeros((N, d), dtype=type(y0[0]))\n    def _imp(Ynp1, Yn, Ynm1, Vn, Vnm1, tnp1, tn, tnm1, fn, fnm1):\n        \"\"\"At each step we will solve _imp(Ynp1, ...) == 0 for Ynp1.\n        The meaning of these arguments is: Y_{n+1}, Y_n, Y_{n-1}, V_n, V_{n-1},\n        t_{n+1}, t_n, t_{n-1}, f(Y_n, t_n), f(Y_{n-1}, t_{n-1}).\"\"\"\n        return ((1 - gam)*Yn + gam*Ynm1 + (al2*f(Ynp1, tnp1) +\n                (gam*al1 + (1 - al2))*fn + gam*(1 - al1)*fnm1)*h + Vn +\n                gam*Vnm1 - Ynp1)\n    fn = None\n    Vn = None\n    y[0] = y0;\n    for n in range(0, N-1):\n        tn = tspan[n]\n        tnp1 = tspan[n+1]\n        h = tnp1 - tn\n        sqrth = np.sqrt(h)\n        Yn = y[n] # shape (d,)\n        Jk = dW[n,:] # shape (m,)\n        Jij = J[n,:,:] # shape (m, m)\n        fnm1 = fn\n        fn = f(Yn, tn)\n        Gn = G(Yn, tn)\n        Ybar = (Yn + fn*h).reshape((d, 1)) + Gn*sqrth # shape (d, m)\n        sum1 = np.zeros((d,))\n        for j1 in range(0, m):\n            sum1 += np.dot(G(Ybar[:,j1], tn) - Gn, Jij[j1,:])\n        Vnm1 = Vn\n        Vn = np.dot(Gn, Jk) + sum1/sqrth\n        if n == 0:\n            # First step uses Kloeden&Platen explicit order 1.0 strong scheme:\n            y[n+1] = Yn + fn*h + Vn\n            continue\n        tnm1 = tspan[n-1]\n        Ynm1 = y[n-1] # shape (d,)\n        # now solve _imp(Ynp1, ...) == 0 for Ynp1, near to Yn\n        args = (Yn, Ynm1, Vn, Vnm1, tnp1, tn, tnm1, fn, fnm1)\n        (Ynp1, __, status, msg) = fsolve(_imp, Yn, args=args, xtol=rtol,\n                                         full_output=True)\n        if status == 1:\n            y[n+1] = Ynp1\n        else:\n            m = \"\"\"At time t_n = %g Failed to solve for Y_{n+1} with args %s.\n                Reason: %s\"\"\" % (tn, args, msg)\n            raise RuntimeError(m)\n    return y", "response": "This function is used to integrate a Stratonovich approximation at each step of the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef actively_watch_logs_for_error(self, on_error_call, interval=1):\n        class LogWatchingThread(threading.Thread):\n            \"\"\"\n            This class is embedded here for now, because it is used only from\n            within Cluster, and depends on cluster.nodelist().\n            \"\"\"\n\n            def __init__(self, cluster):\n                super(LogWatchingThread, self).__init__()\n                self.cluster = cluster\n                self.daemon = True  # set so that thread will exit when main thread exits\n                self.req_stop_event = threading.Event()\n                self.done_event = threading.Event()\n                self.log_positions = defaultdict(int)\n\n            def scan(self):\n                errordata = OrderedDict()\n\n                try:\n                    for node in self.cluster.nodelist():\n                        scan_from_mark = self.log_positions[node.name]\n                        next_time_scan_from_mark = node.mark_log()\n                        if next_time_scan_from_mark == scan_from_mark:\n                            # log hasn't advanced, nothing to do for this node\n                            continue\n                        else:\n                            errors = node.grep_log_for_errors_from(seek_start=scan_from_mark)\n                        self.log_positions[node.name] = next_time_scan_from_mark\n                        if errors:\n                            errordata[node.name] = errors\n                except IOError as e:\n                    if 'No such file or directory' in str(e.strerror):\n                        pass  # most likely log file isn't yet written\n\n                    # in the case of unexpected error, report this thread to the callback\n                    else:\n                        errordata['log_scanner'] = [[str(e)]]\n\n                return errordata\n\n            def scan_and_report(self):\n                errordata = self.scan()\n\n                if errordata:\n                    on_error_call(errordata)\n\n            def run(self):\n                common.debug(\"Log-watching thread starting.\")\n\n                # run until stop gets requested by .join()\n                while not self.req_stop_event.is_set():\n                    self.scan_and_report()\n                    time.sleep(interval)\n\n                try:\n                    # do a final scan to make sure we got to the very end of the files\n                    self.scan_and_report()\n                finally:\n                    common.debug(\"Log-watching thread exiting.\")\n                    # done_event signals that the scan completed a final pass\n                    self.done_event.set()\n\n            def join(self, timeout=None):\n                # signals to the main run() loop that a stop is requested\n                self.req_stop_event.set()\n                # now wait for the main loop to get through a final log scan, and signal that it's done\n                self.done_event.wait(timeout=interval * 2)  # need to wait at least interval seconds before expecting thread to finish. 2x for safety.\n                super(LogWatchingThread, self).join(timeout)\n\n        log_watcher = LogWatchingThread(self)\n        log_watcher.start()\n        return log_watcher", "response": "Starts a thread that scans system. log for new errors and calls on_error_call with an OrderedDictionary containing node name to a list of error lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for_compactions(self, timeout=600):\n        for node in list(self.nodes.values()):\n            if node.is_running():\n                node.wait_for_compactions(timeout)\n        return self", "response": "Wait for all compactions to finish on all nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a named tuple containing the node and the lines that match the given log patterns.", "response": "def timed_grep_nodes_for_patterns(self, versions_to_patterns, timeout_seconds, filename=\"system.log\"):\n        \"\"\"\n        Searches all nodes in the cluster for a specific regular expression based on the node's version.\n        Params:\n        @versions_to_patterns : an instance of LogPatternToVersionMap, specifying the different log patterns based on a node's version.\n        @version : the earliest version the new pattern was introduced.\n        @timeout_seconds : the amount of time to spend searching the logs for.\n        @filename : the name of the file to search for the patterns. Defaults to \"system.log\".\n\n        Returns the first node where the pattern was found, along with the matching lines.\n        Raises a TimeoutError if the pattern is not found within the specified timeout period.\n        \"\"\"\n        end_time = time.time() + timeout_seconds\n        while True:\n            if time.time() > end_time:\n                raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) +\n                                   \" Unable to find: \" + versions_to_patterns.patterns + \" in any node log within \" + str(timeout_seconds) + \"s\")\n\n            for node in self.nodelist():\n                pattern = versions_to_patterns(node.get_cassandra_version())\n                matchings = node.grep_log(pattern, filename)\n                if matchings:\n                    ret = namedtuple('Node_Log_Matching', 'node matchings')\n                    return ret(node=node, matchings=matchings)\n            time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_logs(self, selected_nodes_names=None):\n\n        if selected_nodes_names is None:\n            selected_nodes_names = []\n\n        if len(self.nodes) == 0:\n            print_(\"There are no nodes in this cluster yet.\")\n            return\n\n        nodes = sorted(list(self.nodes.values()), key=lambda node: node.name)\n        nodes_names = [node.name for node in nodes]\n\n        names_logs_dict = {node.name: node.logfilename() for node in nodes}\n        if len(selected_nodes_names) == 0: # Parameter selected_nodes_names is empty\n            return names_logs_dict.values()\n        else:\n            if set(selected_nodes_names).issubset(nodes_names):\n                return [names_logs_dict[name] for name in selected_nodes_names]\n            else:\n                raise ValueError(\"nodes in this cluster are {}. But nodes in argments are {}\".format(\n                    nodes_names, selected_nodes_names\n                ))", "response": "Shows logs of nodes in this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef watch_log_for_alive(self, nodes, from_mark=None, timeout=720, filename='system.log'):\n        super(DseNode, self).watch_log_for_alive(nodes, from_mark=from_mark, timeout=timeout, filename=filename)", "response": "Watch the log of this node until it detects that one of the provided nodes is marked UP."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_dse_home_in_dse_env_sh(self):\n        '''\n        Due to the way CCM lays out files, separating the repository\n        from the node(s) confs, the `dse-env.sh` script of each node\n        needs to have its DSE_HOME var set and exported. Since DSE\n        4.5.x, the stock `dse-env.sh` file includes a commented-out\n        place to do exactly this, intended for installers.\n        Basically: read in the file, write it back out and add the two\n        lines.\n        'sstableloader' is an example of a node script that depends on\n        this, when used in a CCM-built cluster.\n        '''\n        with open(self.get_bin_dir() + \"/dse-env.sh\", \"r\") as dse_env_sh:\n            buf = dse_env_sh.readlines()\n\n        with open(self.get_bin_dir() + \"/dse-env.sh\", \"w\") as out_file:\n            for line in buf:\n                out_file.write(line)\n                if line == \"# This is here so the installer can force set DSE_HOME\\n\":\n                    out_file.write(\"DSE_HOME=\" + self.get_install_dir() + \"\\nexport DSE_HOME\\n\")", "response": "This function is used to export the DSE_HOME variable in the environment sh file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a node from the path on disk to the config files the node name and the cluster the node is part of.", "response": "def load(path, name, cluster):\n        \"\"\"\n        Load a node from from the path on disk to the config files, the node name and the\n        cluster the node is part of.\n        \"\"\"\n        node_path = os.path.join(path, name)\n        filename = os.path.join(node_path, 'node.conf')\n        with open(filename, 'r') as f:\n            data = yaml.safe_load(f)\n        try:\n            itf = data['interfaces']\n            initial_token = None\n            if 'initial_token' in data:\n                initial_token = data['initial_token']\n            cassandra_version = None\n            if 'cassandra_version' in data:\n                cassandra_version = LooseVersion(data['cassandra_version'])\n            remote_debug_port = 2000\n            if 'remote_debug_port' in data:\n                remote_debug_port = data['remote_debug_port']\n            binary_interface = None\n            if 'binary' in itf and itf['binary'] is not None:\n                binary_interface = tuple(itf['binary'])\n            thrift_interface = None\n            if 'thrift' in itf and itf['thrift'] is not None:\n                thrift_interface = tuple(itf['thrift'])\n            node = cluster.create_node(data['name'], data['auto_bootstrap'], thrift_interface, tuple(itf['storage']), data['jmx_port'], remote_debug_port, initial_token, save=False, binary_interface=binary_interface, byteman_port=data['byteman_port'], derived_cassandra_version=cassandra_version)\n            node.status = data['status']\n            if 'pid' in data:\n                node.pid = int(data['pid'])\n            if 'install_dir' in data:\n                node.__install_dir = data['install_dir']\n            if 'config_options' in data:\n                node.__config_options = data['config_options']\n            if 'dse_config_options' in data:\n                node._dse_config_options = data['dse_config_options']\n            if 'environment_variables' in data:\n                node.__environment_variables = data['environment_variables']\n            if 'data_center' in data:\n                node.data_center = data['data_center']\n            if 'workloads' in data:\n                node.workloads = data['workloads']\n            return node\n        except KeyError as k:\n            raise common.LoadError(\"Error Loading \" + filename + \", missing property: \" + str(k))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_path(self):\n        return os.path.join(self.cluster.get_path(), self.name)", "response": "Returns the path to this node s top level directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path to the cassandra source directory used by this node.", "response": "def get_install_dir(self):\n        \"\"\"\n        Returns the path to the cassandra source directory used by this node.\n        \"\"\"\n        if self.__install_dir is None:\n            return self.cluster.get_install_dir()\n        else:\n            common.validate_install_dir(self.__install_dir)\n            return self.__install_dir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the path to the cassandra source directory for use by this node.", "response": "def set_install_dir(self, install_dir=None, version=None, verbose=False):\n        \"\"\"\n        Sets the path to the cassandra source directory for use by this node.\n        \"\"\"\n        if version is None:\n            self.__install_dir = install_dir\n            if install_dir is not None:\n                common.validate_install_dir(install_dir)\n        else:\n            self.__install_dir = self.node_setup(version, verbose=verbose)\n\n        self._cassandra_version = common.get_version_from_build(self.__install_dir, cassandra=True)\n\n        if self.get_base_cassandra_version() >= 4.0:\n            self.network_interfaces['thrift'] = None\n\n        self.import_config_files()\n        self.import_bin_files()\n        self.__conf_updated = False\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset Cassandra configuration options.", "response": "def set_configuration_options(self, values=None):\n        \"\"\"\n        Set Cassandra configuration options.\n        ex:\n            node.set_configuration_options(values={\n                'hinted_handoff_enabled' : True,\n                'concurrent_writes' : 64,\n            })\n        \"\"\"\n        if not hasattr(self,'_config_options') or self.__config_options is None:\n            self.__config_options = {}\n\n        if values is not None:\n            self.__config_options = common.merge_configuration(self.__config_options, values)\n\n        self.import_config_files()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the batch_commitlog option for the current locale.", "response": "def set_batch_commitlog(self, enabled=False):\n        \"\"\"\n        The batch_commitlog option gives an easier way to switch to batch\n        commitlog (since it requires setting 2 options and unsetting one).\n        \"\"\"\n        if enabled:\n            values = {\n                \"commitlog_sync\": \"batch\",\n                \"commitlog_sync_batch_window_in_ms\": 5,\n                \"commitlog_sync_period_in_ms\": None\n            }\n        else:\n            values = {\n                \"commitlog_sync\": \"periodic\",\n                \"commitlog_sync_batch_window_in_ms\": None,\n                \"commitlog_sync_period_in_ms\": 10000\n            }\n        self.set_configuration_options(values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show(self, only_status=False, show_cluster=True):\n        self.__update_status()\n        indent = ''.join([\" \" for i in xrange(0, len(self.name) + 2)])\n        print_(\"{}: {}\".format(self.name, self.__get_status_string()))\n        if not only_status:\n            if show_cluster:\n                print_(\"{}{}={}\".format(indent, 'cluster', self.cluster.name))\n            print_(\"{}{}={}\".format(indent, 'auto_bootstrap', self.auto_bootstrap))\n            if self.network_interfaces['thrift'] is not None:\n                print_(\"{}{}={}\".format(indent, 'thrift', self.network_interfaces['thrift']))\n            if self.network_interfaces['binary'] is not None:\n                print_(\"{}{}={}\".format(indent, 'binary', self.network_interfaces['binary']))\n            print_(\"{}{}={}\".format(indent, 'storage', self.network_interfaces['storage']))\n            print_(\"{}{}={}\".format(indent, 'jmx_port', self.jmx_port))\n            print_(\"{}{}={}\".format(indent, 'remote_debug_port', self.remote_debug_port))\n            print_(\"{}{}={}\".format(indent, 'byteman_port', self.byteman_port))\n            print_(\"{}{}={}\".format(indent, 'initial_token', self.initial_token))\n            if self.pid:\n                print_(\"{}{}={}\".format(indent, 'pid', self.pid))", "response": "Prints information on this node configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true if the node is running", "response": "def is_running(self):\n        \"\"\"\n        Return true if the node is running\n        \"\"\"\n        self.__update_status()\n        return self.status == Status.UP or self.status == Status.DECOMMISSIONED"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of lines matching the regular expression in parameter in Cassandra log file.", "response": "def grep_log(self, expr, filename='system.log', from_mark=None):\n        \"\"\"\n        Returns a list of lines matching the regular expression in parameter\n        in the Cassandra log of this node\n        \"\"\"\n        matchings = []\n        pattern = re.compile(expr)\n        with open(os.path.join(self.get_path(), 'logs', filename)) as f:\n            if from_mark:\n                f.seek(from_mark)\n            for line in f:\n                m = pattern.search(line)\n                if m:\n                    matchings.append((line, m))\n        return matchings"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a mark to the current position of this node Cassandra log.", "response": "def mark_log(self, filename='system.log'):\n        \"\"\"\n        Returns \"a mark\" to the current position of this node Cassandra log.\n        This is for use with the from_mark parameter of watch_log_for_* methods,\n        allowing to watch the log from the position when this method was called.\n        \"\"\"\n        log_file = os.path.join(self.get_path(), 'logs', filename)\n        if not os.path.exists(log_file):\n            return 0\n        with open(log_file) as f:\n            f.seek(0, os.SEEK_END)\n            return f.tell()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef watch_log_for(self, exprs, from_mark=None, timeout=600, process=None, verbose=False, filename='system.log'):\n        start = time.time()\n        tofind = [exprs] if isinstance(exprs, string_types) else exprs\n        tofind = [re.compile(e) for e in tofind]\n        matchings = []\n        reads = \"\"\n        if len(tofind) == 0:\n            return None\n\n        log_file = os.path.join(self.get_path(), 'logs', filename)\n        output_read = False\n        while not os.path.exists(log_file):\n            time.sleep(.5)\n            if start + timeout < time.time():\n                raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Timed out waiting for {} to be created.\".format(log_file))\n            if process and not output_read:\n                process.poll()\n                if process.returncode is not None:\n                    self.print_process_output(self.name, process, verbose)\n                    output_read = True\n                    if process.returncode != 0:\n                        raise RuntimeError()  # Shouldn't reuse RuntimeError but I'm lazy\n\n        with open(log_file) as f:\n            if from_mark:\n                f.seek(from_mark)\n\n            while True:\n                # First, if we have a process to check, then check it.\n                # Skip on Windows - stdout/stderr is cassandra.bat\n                if not common.is_win() and not output_read:\n                    if process:\n                        process.poll()\n                        if process.returncode is not None:\n                            self.print_process_output(self.name, process, verbose)\n                            output_read = True\n                            if process.returncode != 0:\n                                raise RuntimeError()  # Shouldn't reuse RuntimeError but I'm lazy\n\n                line = f.readline()\n                if line:\n                    reads = reads + line\n                    for e in tofind:\n                        m = e.search(line)\n                        if m:\n                            matchings.append((line, m))\n                            tofind.remove(e)\n                            if len(tofind) == 0:\n                                return matchings[0] if isinstance(exprs, string_types) else matchings\n                else:\n                    # yep, it's ugly\n                    time.sleep(1)\n                    if start + timeout < time.time():\n                        raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\n                if process:\n                    if common.is_win():\n                        if not self.is_running():\n                            return None\n                    else:\n                        process.poll()\n                        if process.returncode == 0:\n                            return None", "response": "Watch the log file for a regular expression and return a list of pair tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef watch_log_for_death(self, nodes, from_mark=None, timeout=600, filename='system.log'):\n        tofind = nodes if isinstance(nodes, list) else [nodes]\n        tofind = [\"%s is now [dead|DOWN]\" % node.address() for node in tofind]\n        self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)", "response": "Watch the log of this node until it detects that one of the provided nodes is marked dead."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits for the Binary CQL interface to be listening.", "response": "def wait_for_binary_interface(self, **kwargs):\n        \"\"\"\n        Waits for the Binary CQL interface to be listening.  If > 1.2 will check\n        log for 'Starting listening for CQL clients' before checking for the\n        interface to be listening.\n\n        Emits a warning if not listening after 30 seconds.\n        \"\"\"\n        if self.cluster.version() >= '1.2':\n            self.watch_log_for(\"Starting listening for CQL clients\", **kwargs)\n\n        binary_itf = self.network_interfaces['binary']\n        if not common.check_socket_listening(binary_itf, timeout=30):\n            warnings.warn(\"Binary interface %s:%s is not listening after 30 seconds, node may have failed to start.\"\n                          % (binary_itf[0], binary_itf[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits for the Thrift interface to be listening.", "response": "def wait_for_thrift_interface(self, **kwargs):\n        \"\"\"\n        Waits for the Thrift interface to be listening.\n\n        Emits a warning if not listening after 30 seconds.\n        \"\"\"\n        if self.cluster.version() >= '4':\n            return;\n\n        self.watch_log_for(\"Listening for thrift clients...\", **kwargs)\n\n        thrift_itf = self.network_interfaces['thrift']\n        if not common.check_socket_listening(thrift_itf, timeout=30):\n            warnings.warn(\"Thrift interface {}:{} is not listening after 30 seconds, node may have failed to start.\".format(thrift_itf[0], thrift_itf[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the node. Options includes: - join_ring: if false, start the node with -Dcassandra.join_ring=False - no_wait: by default, this method returns when the node is started and listening to clients. If no_wait=True, the method returns sooner. - wait_other_notice: if truthy, this method returns only when all other live node of the cluster have marked this node UP. if an integer, sets the timeout for how long to wait - replace_token: start the node with the -Dcassandra.replace_token option. - replace_address: start the node with the -Dcassandra.replace_address option.", "response": "def start(self,\n              join_ring=True,\n              no_wait=False,\n              verbose=False,\n              update_pid=True,\n              wait_other_notice=True,\n              replace_token=None,\n              replace_address=None,\n              jvm_args=None,\n              wait_for_binary_proto=False,\n              profile_options=None,\n              use_jna=False,\n              quiet_start=False,\n              allow_root=False,\n              set_migration_task=True):\n        \"\"\"\n        Start the node. Options includes:\n          - join_ring: if false, start the node with -Dcassandra.join_ring=False\n          - no_wait: by default, this method returns when the node is started and listening to clients.\n            If no_wait=True, the method returns sooner.\n          - wait_other_notice: if truthy, this method returns only when all other live node of the cluster\n            have marked this node UP. if an integer, sets the timeout for how long to wait\n          - replace_token: start the node with the -Dcassandra.replace_token option.\n          - replace_address: start the node with the -Dcassandra.replace_address option.\n        \"\"\"\n        if jvm_args is None:\n            jvm_args = []\n\n        if set_migration_task and self.cluster.cassandra_version() >= '3.0.1':\n            jvm_args += ['-Dcassandra.migration_task_wait_in_seconds={}'.format(len(self.cluster.nodes) * 2)]\n\n        # Validate Windows env\n        if common.is_modern_windows_install(self.cluster.version()) and not common.is_ps_unrestricted():\n            raise NodeError(\"PS Execution Policy must be unrestricted when running C* 2.1+\")\n\n        if not common.is_win() and quiet_start:\n            common.warning(\"Tried to set Windows quiet start behavior, but we're not running on Windows.\")\n\n        if self.is_running():\n            raise NodeError(\"{} is already running\".format(self.name))\n\n        for itf in list(self.network_interfaces.values()):\n            if itf is not None and replace_address is None:\n                common.assert_socket_available(itf)\n\n        if wait_other_notice:\n            marks = [(node, node.mark_log()) for node in list(self.cluster.nodes.values()) if node.is_live()]\n\n        self.mark = self.mark_log()\n\n        launch_bin = self.get_launch_bin()\n\n        # If Windows, change entries in .bat file to split conf from binaries\n        if common.is_win():\n            self.__clean_bat()\n\n        if profile_options is not None:\n            config = common.get_config()\n            if 'yourkit_agent' not in config:\n                raise NodeError(\"Cannot enable profile. You need to set 'yourkit_agent' to the path of your agent in a ~/.ccm/config\")\n            cmd = '-agentpath:{}'.format(config['yourkit_agent'])\n            if 'options' in profile_options:\n                cmd = cmd + '=' + profile_options['options']\n            print_(cmd)\n            # Yes, it's fragile as shit\n            pattern = r'cassandra_parms=\"-Dlog4j.configuration=log4j-server.properties -Dlog4j.defaultInitOverride=true'\n            common.replace_in_file(launch_bin, pattern, '    ' + pattern + ' ' + cmd + '\"')\n\n        os.chmod(launch_bin, os.stat(launch_bin).st_mode | stat.S_IEXEC)\n\n        env = self.get_env()\n\n        extension.append_to_server_env(self, env)\n\n        if common.is_win():\n            self._clean_win_jmx()\n\n        pidfile = os.path.join(self.get_path(), 'cassandra.pid')\n        args = [launch_bin]\n\n        self.add_custom_launch_arguments(args)\n\n        args = args + ['-p', pidfile, '-Dcassandra.join_ring=%s' % str(join_ring)]\n\n        args.append('-Dcassandra.logdir=%s' % os.path.join(self.get_path(), 'logs'))\n        if replace_token is not None:\n            args.append('-Dcassandra.replace_token=%s' % str(replace_token))\n        if replace_address is not None:\n            args.append('-Dcassandra.replace_address=%s' % str(replace_address))\n        if use_jna is False:\n            args.append('-Dcassandra.boot_without_jna=true')\n        if allow_root:\n            args.append('-R')\n        env['JVM_EXTRA_OPTS'] = env.get('JVM_EXTRA_OPTS', \"\") + \" \" + \" \".join(jvm_args)\n\n        # In case we are restarting a node\n        # we risk reading the old cassandra.pid file\n        self._delete_old_pid()\n\n        process = None\n        FNULL = open(os.devnull, 'w')\n        stdout_sink = subprocess.PIPE if verbose else FNULL\n        # write stderr to a temporary file to prevent overwhelming pipe (> 65K data).\n        stderr_sink = tempfile.SpooledTemporaryFile(max_size=0xFFFF)\n\n        if common.is_win():\n            # clean up any old dirty_pid files from prior runs\n            if (os.path.isfile(self.get_path() + \"/dirty_pid.tmp\")):\n                os.remove(self.get_path() + \"/dirty_pid.tmp\")\n\n            if quiet_start and self.cluster.version() >= '2.2.4':\n                args.append('-q')\n\n            process = subprocess.Popen(args, cwd=self.get_bin_dir(), env=env, stdout=stdout_sink, stderr=stderr_sink)\n        else:\n            process = subprocess.Popen(args, env=env, stdout=stdout_sink, stderr=stderr_sink)\n\n        process.stderr_file = stderr_sink\n\n        # Our modified batch file writes a dirty output with more than just the pid - clean it to get in parity\n        # with *nix operation here.\n        if verbose:\n            stdout = process.communicate()[0]\n            print_(stdout)\n\n        if common.is_win():\n            self.__clean_win_pid()\n            self._update_pid(process)\n            print_(\"Started: {0} with pid: {1}\".format(self.name, self.pid), file=sys.stderr, flush=True)\n        elif update_pid:\n            self._update_pid(process)\n\n            if not self.is_running():\n                raise NodeError(\"Error starting node %s\" % self.name, process)\n\n        # If wait_other_notice is a bool, we don't want to treat it as a\n        # timeout. Other intlike types, though, we want to use.\n        if common.is_intlike(wait_other_notice) and not isinstance(wait_other_notice, bool):\n            for node, mark in marks:\n                node.watch_log_for_alive(self, from_mark=mark, timeout=wait_other_notice)\n        elif wait_other_notice:\n            for node, mark in marks:\n                node.watch_log_for_alive(self, from_mark=mark)\n\n        # If wait_for_binary_proto is a bool, we don't want to treat it as a\n        # timeout. Other intlike types, though, we want to use.\n        if common.is_intlike(wait_for_binary_proto) and not isinstance(wait_for_binary_proto, bool):\n            self.wait_for_binary_interface(from_mark=self.mark, timeout=wait_for_binary_proto)\n        elif wait_for_binary_proto:\n            self.wait_for_binary_interface(from_mark=self.mark)\n\n        return process"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self, wait=True, wait_other_notice=False, signal_event=signal.SIGTERM, **kwargs):\n        if self.is_running():\n            if wait_other_notice:\n                marks = [(node, node.mark_log()) for node in list(self.cluster.nodes.values()) if node.is_live() and node is not self]\n\n            if common.is_win():\n                # Just taskkill the instance, don't bother trying to shut it down gracefully.\n                # Node recovery should prevent data loss from hard shutdown.\n                # We have recurring issues with nodes not stopping / releasing files in the CI\n                # environment so it makes more sense just to murder it hard since there's\n                # really little downside.\n\n                # We want the node to flush its data before shutdown as some tests rely on small writes being present.\n                # The default Periodic sync at 10 ms may not have flushed data yet, causing tests to fail.\n                # This is not a hard requirement, however, so we swallow any exceptions this may throw and kill anyway.\n                if signal_event is signal.SIGTERM:\n                    try:\n                        self.flush()\n                    except:\n                        common.warning(\"Failed to flush node: {0} on shutdown.\".format(self.name))\n                        pass\n\n                os.system(\"taskkill /F /PID \" + str(self.pid))\n                if self._find_pid_on_windows():\n                    common.warning(\"Failed to terminate node: {0} with pid: {1}\".format(self.name, self.pid))\n            else:\n                # Determine if the signal event should be updated to keep API compatibility\n                if 'gently' in kwargs and kwargs['gently'] is False:\n                    signal_event = signal.SIGKILL\n\n                os.kill(self.pid, signal_event)\n\n            if wait_other_notice:\n                for node, mark in marks:\n                    node.watch_log_for_death(self, from_mark=mark)\n            else:\n                time.sleep(.1)\n\n            still_running = self.is_running()\n            if still_running and wait:\n                wait_time_sec = 1\n                for i in xrange(0, 7):\n                    # we'll double the wait time each try and cassandra should\n                    # not take more than 1 minute to shutdown\n                    time.sleep(wait_time_sec)\n                    if not self.is_running():\n                        return True\n                    wait_time_sec = wait_time_sec * 2\n                raise NodeError(\"Problem stopping node %s\" % self.name)\n            else:\n                return True\n        else:\n            return False", "response": "Stop the node.\n          - wait: if True (the default), wait for the Cassandra process to be\n            really dead. Otherwise return after having sent the kill signal.\n          - wait_other_notice: return only when the other live nodes of the\n            cluster have marked this node has dead.\n          - signal_event: Signal event to send to Cassandra; default is to\n            let Cassandra clean up and shut down properly (SIGTERM [15])\n          - Optional:\n             + gently: Let Cassandra clean up and shut down properly; unless\n                       false perform a 'kill -9' which shuts down faster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for all compactions to finish on this node.", "response": "def wait_for_compactions(self, timeout=120):\n        \"\"\"\n        Wait for all compactions to finish on this node.\n        \"\"\"\n        pattern = re.compile(\"pending tasks: 0\")\n        start = time.time()\n        while time.time() - start < timeout:\n            output, err, rc = self.nodetool(\"compactionstats\")\n            if pattern.search(output):\n                return\n            time.sleep(1)\n        raise TimeoutError(\"{} [{}] Compactions did not finish in {} seconds\".format(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()), self.name, timeout))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the byteman startup script i. e. rule injected before the node starts.", "response": "def update_startup_byteman_script(self, byteman_startup_script):\n        \"\"\"\n        Update the byteman startup script, i.e., rule injected before the node starts.\n\n        :param byteman_startup_script: the relative path to the script\n        :raise common.LoadError: if the node does not have byteman installed\n        \"\"\"\n        if self.byteman_port == '0':\n            raise common.LoadError('Byteman is not installed')\n        self.byteman_startup_script = byteman_startup_script\n        self.import_config_files()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_cmd(self, cmd):\n        cdir = self.get_install_cassandra_root()\n        if self.get_base_cassandra_version() >= 2.1:\n            fcmd = common.join_bin(cdir, os.path.join('tools', 'bin'), cmd)\n        else:\n            fcmd = common.join_bin(cdir, 'bin', cmd)\n        try:\n            if os.path.exists(fcmd):\n                os.chmod(fcmd, stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)\n        except:\n            common.warning(\"Couldn't change permissions to use {0}.\".format(cmd))\n            common.warning(\"If it didn't work, you will have to do so manually.\")\n        return fcmd", "response": "Locates command under cassandra root and fixes permissions if needed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing nodetool info to get the size of a node s data in KB.", "response": "def data_size(self, live_data=None):\n        \"\"\"Uses `nodetool info` to get the size of a node's data in KB.\"\"\"\n        if live_data is not None:\n            warnings.warn(\"The 'live_data' keyword argument is deprecated.\",\n                          DeprecationWarning)\n        output = self.nodetool('info')[0]\n        return _get_load_from_info_output(output)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sstable_data_files(self, ks, table):\n        p = self.get_sstable_data_files_process(ks=ks, table=table)\n\n        out, _, _ = handle_external_tool_process(p, [\"sstableutil\", '--type', 'final', ks, table])\n\n        return sorted(filter(lambda s: s.endswith('-Data.db'), out.splitlines()))", "response": "Read sstable data files by using sstableutil so we ignore temporary files\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_modern_windows_install(version):\n    version = LooseVersion(str(version))\n    if is_win() and version >= LooseVersion('2.1'):\n        return True\n    else:\n        return False", "response": "Check if we are running a modern Windows install."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the Java version as reported in the quoted string returned by invoking java - version.", "response": "def get_jdk_version():\n    \"\"\"\n    Retrieve the Java version as reported in the quoted string returned\n    by invoking 'java -version'.\n\n    Works for Java 1.8, Java 9 and should also be fine for Java 10.\n    \"\"\"\n    try:\n        version = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT)\n    except OSError:\n        print_(\"ERROR: Could not find java. Is it in your path?\")\n        exit(1)\n\n    return _get_jdk_version(version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_any_log(nodes, pattern, timeout, filename='system.log', marks=None):\n    if marks is None:\n        marks = {}\n    for _ in range(timeout):\n        for node in nodes:\n            found = node.grep_log(pattern, filename=filename, from_mark=marks.get(node, None))\n            if found:\n                return node\n        time.sleep(1)\n\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) +\n                       \" Unable to find: \" + repr(pattern) + \" in any node log within \" + str(timeout) + \"s\")", "response": "Wait for a pattern in a given list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download_version(version, url=None, verbose=False, binary=False):\n    assert_jdk_valid_for_cassandra_version(version)\n\n    archive_url = ARCHIVE\n    if CCM_CONFIG.has_option('repositories', 'cassandra'):\n        archive_url = CCM_CONFIG.get('repositories', 'cassandra')\n\n    if binary:\n        archive_url = \"%s/%s/apache-cassandra-%s-bin.tar.gz\" % (archive_url, version.split('-')[0], version) if url is None else url\n    else:\n        archive_url = \"%s/%s/apache-cassandra-%s-src.tar.gz\" % (archive_url, version.split('-')[0], version) if url is None else url\n    _, target = tempfile.mkstemp(suffix=\".tar.gz\", prefix=\"ccm-\")\n    try:\n        __download(archive_url, target, show_progress=verbose)\n        common.info(\"Extracting {} as version {} ...\".format(target, version))\n        tar = tarfile.open(target)\n        dir = tar.next().name.split(\"/\")[0]  # pylint: disable=all\n        tar.extractall(path=__get_dir())\n        tar.close()\n        target_dir = os.path.join(__get_dir(), version)\n        if os.path.exists(target_dir):\n            rmdirs(target_dir)\n        shutil.move(os.path.join(__get_dir(), dir), target_dir)\n\n        if binary:\n            # Binary installs don't have a build.xml that is needed\n            # for pulling the version from. Write the version number\n            # into a file to read later in common.get_version_from_build()\n            with open(os.path.join(target_dir, '0.version.txt'), 'w') as f:\n                f.write(version)\n        else:\n            compile_version(version, target_dir, verbose=verbose)\n\n    except urllib.error.URLError as e:\n        msg = \"Invalid version {}\".format(version) if url is None else \"Invalid url {}\".format(url)\n        msg = msg + \" (underlying error is: {})\".format(str(e))\n        raise ArgumentError(msg)\n    except tarfile.ReadError as e:\n        raise ArgumentError(\"Unable to uncompress downloaded file: {}\".format(str(e)))\n    except CCMError as e:\n        # wipe out the directory if anything goes wrong. Otherwise we will assume it has been compiled the next time it runs.\n        try:\n            rmdirs(target_dir)\n            common.error(\"Deleted {} due to error\".format(target_dir))\n        except:\n            raise CCMError(\"Building C* version {} failed. Attempted to delete {} but failed. This will need to be manually deleted\".format(version, target_dir))\n        raise e", "response": "Download extract and build a Cassandra version from a given URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tagged_version_numbers(series='stable'):\n    releases = []\n    if series == 'testing':\n        # Testing releases always have a hyphen after the version number:\n        tag_regex = re.compile('^refs/tags/cassandra-([0-9]+\\.[0-9]+\\.[0-9]+-.*$)')\n    else:\n        # Stable and oldstable releases are just a number:\n        tag_regex = re.compile('^refs/tags/cassandra-([0-9]+\\.[0-9]+\\.[0-9]+$)')\n\n    tag_url = urllib.request.urlopen(GITHUB_TAGS)\n    for ref in (i.get('ref', '') for i in json.loads(tag_url.read())):\n        m = tag_regex.match(ref)\n        if m:\n            releases.append(LooseVersion(m.groups()[0]))\n\n    # Sort by semver:\n    releases.sort(reverse=True)\n\n    stable_major_version = LooseVersion(str(releases[0].version[0]) + \".\" + str(releases[0].version[1]))\n    stable_releases = [r for r in releases if r >= stable_major_version]\n    oldstable_releases = [r for r in releases if r not in stable_releases]\n    oldstable_major_version = LooseVersion(str(oldstable_releases[0].version[0]) + \".\" + str(oldstable_releases[0].version[1]))\n    oldstable_releases = [r for r in oldstable_releases if r >= oldstable_major_version]\n\n    if series == 'testing':\n        return [r.vstring for r in releases]\n    elif series == 'stable':\n        return [r.vstring for r in stable_releases]\n    elif series == 'oldstable':\n        return [r.vstring for r in oldstable_releases]\n    else:\n        raise AssertionError(\"unknown release series: {series}\".format(series=series))", "response": "Retrieve git tags and find version numbers for a release series\n    series - stable oldstable or testing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a CCM command remotely", "response": "def execute_ccm_remotely(remote_options, ccm_args):\n    \"\"\"\n    Execute CCM operation(s) remotely\n\n    :return A tuple defining the execution of the command\n              * output      - The output of the execution if the output was not displayed\n              * exit_status - The exit status of remotely executed script\n    :raises Exception if invalid options are passed for `--dse-credentials`, `--ssl`, or\n                      `--node-ssl` when initiating a remote execution; also if\n                      error occured during ssh connection\n    \"\"\"\n    if not PARAMIKO_IS_AVAILABLE:\n        logging.warn(\"Paramiko is not Availble: Skipping remote execution of CCM command\")\n        return None, None\n\n    # Create the SSH client\n    ssh_client = SSHClient(remote_options.ssh_host, remote_options.ssh_port,\n                           remote_options.ssh_username, remote_options.ssh_password,\n                           remote_options.ssh_private_key)\n\n    # Handle CCM arguments that require SFTP\n    for index, argument in enumerate(ccm_args):\n        # Determine if DSE credentials argument is being used\n        if \"--dse-credentials\" in argument:\n            # Get the filename being used for the DSE credentials\n            tokens = argument.split(\"=\")\n            credentials_path = os.path.join(os.path.expanduser(\"~\"), \".ccm\", \".dse.ini\")\n            if len(tokens) == 2:\n                credentials_path = tokens[1]\n\n            # Ensure the credential file exists locally and copy to remote host\n            if not os.path.isfile(credentials_path):\n                raise Exception(\"DSE Credentials File Does not Exist: %s\"\n                                % credentials_path)\n            ssh_client.put(credentials_path, ssh_client.ccm_config_dir)\n\n            # Update the DSE credentials argument\n            ccm_args[index] = \"--dse-credentials\"\n\n        # Determine if SSL or node SSL path argument is being used\n        if \"--ssl\" in argument or \"--node-ssl\" in argument:\n            # Get the directory being used for the path\n            tokens = argument.split(\"=\")\n            if len(tokens) != 2:\n                raise Exception(\"Path is not Specified: %s\" % argument)\n            ssl_path = tokens[1]\n\n            # Ensure the path exists locally and copy to remote host\n            if not os.path.isdir(ssl_path):\n                raise Exception(\"Path Does not Exist: %s\" % ssl_path)\n            remote_ssl_path = ssh_client.temp + os.path.basename(ssl_path)\n            ssh_client.put(ssl_path, remote_ssl_path)\n\n            # Update the argument\n            ccm_args[index] = tokens[0] + \"=\" + remote_ssl_path\n\n    # Execute the CCM request, return output and exit status\n    return ssh_client.execute_ccm_command(ccm_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __connect(host, port, username, password, private_key):\n        # Initialize the SSH connection\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        if private_key is not None and password is not None:\n            private_key = paramiko.RSAKey.from_private_key_file(private_key, password)\n        elif private_key is not None:\n            private_key = paramiko.RSAKey.from_private_key_file(private_key, password)\n\n        # Establish the SSH connection\n        try:\n            ssh.connect(host, port, username, password, private_key)\n        except Exception as e:\n            raise e\n\n        # Return the established SSH connection\n        return ssh", "response": "Establish remote connection to the SSH server and return the SSH client instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, command, is_displayed=True, profile=None):\n        # Modify the command for remote execution\n        command = \" \".join(\"'{0}'\".format(argument) for argument in command)\n\n        # Execute the command and initialize for reading (close stdin/writes)\n        if not profile is None and not profile is \"None\":\n            command = \"source \" + profile + \";\" + command\n        stdin, stdout, stderr = self.ssh.exec_command(command)\n        stdin.channel.shutdown_write()\n        stdin.close()\n\n\n        # Print or gather output as is occurs\n        output = None\n        if not is_displayed:\n            output = []\n            output.append(stdout.channel.recv(len(stdout.channel.in_buffer)).decode(\"utf-8\"))\n            output.append(stderr.channel.recv(len(stderr.channel.in_buffer)).decode(\"utf-8\"))\n        channel = stdout.channel\n        while not channel.closed or channel.recv_ready() or channel.recv_stderr_ready():\n            # Ensure the channel was not closed prematurely and all data has been ready\n            is_data_present = False\n            handles = select.select([channel], [], [])\n            for read in handles[0]:\n                # Read stdout and/or stderr if data is present\n                buffer = None\n                if read.recv_ready():\n                    buffer = channel.recv(len(read.in_buffer)).decode(\"utf-8\")\n                    if is_displayed:\n                        sys.stdout.write(buffer)\n                if read.recv_stderr_ready():\n                    buffer = stderr.channel.recv_stderr(len(read.in_stderr_buffer)).decode(\"utf-8\")\n                    if is_displayed:\n                        sys.stderr.write(buffer)\n\n                # Determine if the output should be updated and displayed\n                if buffer is not None:\n                    is_data_present = True\n                    if not is_displayed:\n                        output.append(buffer)\n\n            # Ensure all the data has been read and exit loop if completed\n            if (not is_data_present and channel.exit_status_ready()\n                and not stderr.channel.recv_stderr_ready()\n                and not channel.recv_ready()):\n                # Stop reading and close the channel to stop processing\n                channel.shutdown_read()\n                channel.close()\n                break\n\n        # Close file handles for stdout and stderr\n        stdout.close()\n        stderr.close()\n\n        # Process the output (if available)\n        if output is not None:\n            output = \"\".join(output)\n\n        # Return the output from the executed command\n        return output, channel.recv_exit_status()", "response": "Execute a command on the remote server and return the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_ccm_command(self, ccm_args, is_displayed=True):\n        return self.execute([\"ccm\"] + ccm_args, profile=self.profile)", "response": "Execute a CCM command on the remote server"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_python_script(self, script):\n        # Create the local file to copy to remote\n        file_handle, filename = tempfile.mkstemp()\n        temp_file = os.fdopen(file_handle, \"wt\")\n        temp_file.write(script)\n        temp_file.close()\n\n        # Put the file into the remote user directory\n        self.put(filename, \"python_execute.py\")\n        command = [\"python\", \"python_execute.py\"]\n\n        # Execute the python script on the remote system, clean up, and return the output\n        output = self.execute(command, False)\n        self.remove(\"python_execute.py\")\n        os.unlink(filename)\n        return output", "response": "Execute a python script on the remote server and return the output of the script execution\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(self, local_path, remote_path=None):\n        # Determine if local_path should be put into remote user directory\n        if remote_path is None:\n            remote_path = os.path.basename(local_path)\n\n        ftp = self.ssh.open_sftp()\n        if os.path.isdir(local_path):\n            self.__put_dir(ftp, local_path, remote_path)\n        else:\n            ftp.put(local_path, remote_path)\n        ftp.close()", "response": "Copy a file or directory recursively to a location on the remote server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __put_dir(self, ftp, local_path, remote_path=None):\n        # Determine if local_path should be put into remote user directory\n        if remote_path is None:\n            remote_path = os.path.basename(local_path)\n        remote_path += self.separator\n\n        # Iterate over the local path and perform copy operations to remote server\n        for current_path, directories, files in os.walk(local_path):\n            # Create the remote directory (if needed)\n            try:\n                ftp.listdir(remote_path)\n            except IOError:\n                ftp.mkdir(remote_path)\n\n            # Copy the files in the current directory to the remote path\n            for filename in files:\n                ftp.put(os.path.join(current_path, filename), remote_path + filename)\n            # Copy the directory in the current directory to the remote path\n            for directory in directories:\n                self.__put_dir(ftp, os.path.join(current_path, directory), remote_path + directory)", "response": "Copy the files and directories in the local path to the remote path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a file or directory recursively on the remote server", "response": "def remove(self, remote_path):\n        \"\"\"\n        Delete a file or directory recursively on the remote server\n\n        :param remote_path: Remote path to remove\n        \"\"\"\n        # Based on the remote file stats; remove a file or directory recursively\n        ftp = self.ssh.open_sftp()\n        if stat.S_ISDIR(ftp.stat(remote_path).st_mode):\n            self.__remove_dir(ftp, remote_path)\n        else:\n            ftp.remove(remote_path)\n        ftp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef port(port):\n        value = int(port)\n        if value <= 0 or value > 65535:\n            raise argparse.ArgumentTypeError(\"%s must be between [1 - 65535]\" % port)\n        return value", "response": "Validator for the port argument"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef usage(self):\n        # Retrieve the text for just the arguments\n        usage = self.parser.format_help().split(\"optional arguments:\")[1]\n\n        # Remove any blank lines and return\n        return \"Remote Options:\" + os.linesep + \\\n               os.linesep.join([s for s in usage.splitlines() if s])", "response": "Get the usage for the remote execution options\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _jwt_required(realm):\n    token = _jwt.request_callback()\n\n    if token is None:\n        raise JWTError('Authorization Required', 'Request does not contain an access token',\n                       headers={'WWW-Authenticate': 'JWT realm=\"%s\"' % realm})\n\n    try:\n        payload = _jwt.jwt_decode_callback(token)\n    except jwt.InvalidTokenError as e:\n        raise JWTError('Invalid token', str(e))\n\n    _request_ctx_stack.top.current_identity = identity = _jwt.identity_callback(payload)\n\n    if identity is None:\n        raise JWTError('Invalid JWT', 'User does not exist')", "response": "This function checks that the request has the JWT data in the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jwt_required(realm=None):\n    def wrapper(fn):\n        @wraps(fn)\n        def decorator(*args, **kwargs):\n            _jwt_required(realm or current_app.config['JWT_DEFAULT_REALM'])\n            return fn(*args, **kwargs)\n        return decorator\n    return wrapper", "response": "Decorator that requires a valid JWT token to be present in the request\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspecifies the authentication response handler function.", "response": "def auth_request_handler(self, callback):\n        \"\"\"Specifies the authentication response handler function.\n\n        :param callable callback: the auth request handler function\n\n        .. deprecated\n        \"\"\"\n        warnings.warn(\"This handler is deprecated. The recommended approach to have control over \"\n                      \"the authentication resource is to disable the built-in  resource by \"\n                      \"setting JWT_AUTH_URL_RULE=None and registering your own authentication \"\n                      \"resource directly on your application.\", DeprecationWarning, stacklevel=2)\n        self.auth_request_callback = callback\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterencode(self, o, _one_shot=False):\n        c_make_encoder_original = json.encoder.c_make_encoder\n        json.encoder.c_make_encoder = None\n\n        if self.check_circular:\n            markers = {}\n        else:\n            markers = None\n        if self.ensure_ascii:\n            _encoder = json.encoder.encode_basestring_ascii\n        else:\n            _encoder = json.encoder.encode_basestring\n\n        def floatstr(o, allow_nan=self.allow_nan,\n                     _repr=lambda x: format(x, self._formatter),\n                     _inf=float(\"inf\"), _neginf=-float(\"inf\")):\n            # Check for specials.  Note that this type of test is processor\n            # and/or platform-specific, so do tests which don't depend on the\n            # internals.\n            if o != o:\n                text = 'NaN'\n            elif o == _inf:\n                text = 'Infinity'\n            elif o == _neginf:\n                text = '-Infinity'\n            else:\n                return _repr(o)\n\n            if not allow_nan:\n                raise ValueError(\n                    \"Out of range float values are not JSON compliant: \" +\n                    repr(o))\n\n            return text\n\n        if (_one_shot and json.encoder.c_make_encoder is not None\n                and self.indent is None):\n            _iterencode = json.encoder.c_make_encoder(\n                markers, self.default, _encoder, self.indent,\n                self.key_separator, self.item_separator, self.sort_keys,\n                self.skipkeys, self.allow_nan)\n        else:\n            _iterencode = json.encoder._make_iterencode(\n                markers, self.default, _encoder, self.indent, floatstr,\n                self.key_separator, self.item_separator, self.sort_keys,\n                self.skipkeys, _one_shot)\n        json.encoder.c_make_encoder = c_make_encoder_original\n        return _iterencode(o, 0)", "response": "Encode the given object and yield each string\n            representation as available."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the SVG path s d element.", "response": "def _svg_path(self, pathcodes, data):\n        \"\"\"\n        Return the SVG path's 'd' element.\n\n        \"\"\"\n        def gen_path_elements(pathcodes, data):\n            counts = {'M': 1, 'L': 1, 'C': 3, 'Z': 0}\n            it = iter(data)\n            for code in pathcodes:\n                yield code\n                for _ in range(counts[code]):\n                    p = next(it)\n                    yield str(p[0])\n                    yield str(p[1])\n\n        return ' '.join(gen_path_elements(pathcodes, data))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fig_to_html(fig=None, template='base.html', tiles=None, crs=None,\n                epsg=None, embed_links=False, float_precision=6):\n    \"\"\"\n    Convert a Matplotlib Figure to a Leaflet map\n\n    Parameters\n    ----------\n    fig : figure, default gcf()\n        Figure used to convert to map\n    template : string, default 'base.html'\n        The Jinja2 template to use\n    tiles : string or tuple\n        The tiles argument is used to control the map tile source in the\n        Leaflet map. Several simple shortcuts exist: 'osm', 'mapquest open',\n        and 'mapbox bright' may be specified to use those tiles.\n\n        The argument may be a tuple of two elements. The first element is the\n        tile URL to use in the map's TileLayer, the second argument is the\n        attribution to display.  See\n        http://leafletjs.com/reference.html#tilelayer for more information on\n        formatting the URL.\n\n        See also maptiles.mapbox() for specifying Mapbox tiles based on a\n        Mapbox map ID.\n    crs : dict, default assumes lon/lat\n        pyproj definition of the current figure. If None, then it is assumed\n        the plot is longitude, latitude in X, Y.\n    epsg : int, default 4326\n        The EPSG code of the current plot. This can be used in place of the\n        'crs' parameter.\n    embed_links : bool, default False\n        Whether external links (except tiles) shall be explicitly embedded in\n        the final html.\n    float_precision : int, default 6\n        The precision to be used for the floats in the embedded geojson.\n\n    Note: only one of 'crs' or 'epsg' may be specified. Both may be None, in\n    which case the plot is assumed to be longitude / latitude.\n\n    Returns\n    -------\n    String of html of the resulting webpage\n\n    \"\"\"\n    if tiles is None:\n        tiles = maptiles.osm\n    elif isinstance(tiles, six.string_types):\n        if tiles not in maptiles.tiles:\n            raise ValueError('Unknown tile source \"{}\"'.format(tiles))\n        else:\n            tiles = maptiles.tiles[tiles]\n\n    template = env.get_template(template)\n\n    if fig is None:\n        fig = plt.gcf()\n    dpi = fig.get_dpi()\n\n    renderer = LeafletRenderer(crs=crs, epsg=epsg)\n    exporter = Exporter(renderer)\n    exporter.run(fig)\n\n    attribution = _attribution + ' | ' + tiles[1]\n\n    mapid = str(uuid.uuid4()).replace('-', '')\n\n    FloatEncoder._formatter = \".{}f\".format(float_precision)\n    gjdata = json.dumps(renderer.geojson(), cls=FloatEncoder)\n    params = {\n        'geojson': gjdata,\n        'width': fig.get_figwidth()*dpi,\n        'height': fig.get_figheight()*dpi,\n        'mapid': mapid,\n        'tile_url': tiles[0],\n        'attribution': attribution,\n        'links': [_leaflet_js,_leaflet_css],\n        'embed_links': embed_links,\n    }\n    html = template.render(params)\n\n    return html", "response": "Convert a Matplotlib figure to a Leaflet map base. html."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fig_to_geojson(fig=None, **kwargs):\n    if fig is None:\n        fig = plt.gcf()\n    renderer = LeafletRenderer(**kwargs)\n    exporter = Exporter(renderer)\n    exporter.run(fig)\n\n    return renderer.geojson()", "response": "Returns a figure s GeoJSON representation as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a Matplotlib Figure to a Leaflet map.", "response": "def display(fig=None, closefig=True, **kwargs):\n    \"\"\"\n    Convert a Matplotlib Figure to a Leaflet map. Embed in IPython notebook.\n\n    Parameters\n    ----------\n    fig : figure, default gcf()\n        Figure used to convert to map\n    closefig : boolean, default True\n        Close the current Figure\n    \"\"\"\n    from IPython.display import HTML\n    if fig is None:\n        fig = plt.gcf()\n    if closefig:\n        plt.close(fig)\n\n    html = fig_to_html(fig, **kwargs)\n\n    # We embed everything in an iframe.\n    iframe_html = '<iframe src=\"data:text/html;base64,{html}\" width=\"{width}\" height=\"{height}\"></iframe>'\\\n    .format(html = base64.b64encode(html.encode('utf8')).decode('utf8'),\n            width = '100%',\n            height= int(60.*fig.get_figheight()),\n           )\n    return HTML(iframe_html)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show(fig=None, path='_map.html', **kwargs):\n    import webbrowser\n    fullpath = os.path.abspath(path)\n    with open(fullpath, 'w') as f:\n        save_html(fig, fileobj=f, **kwargs)\n    webbrowser.open('file://' + fullpath)", "response": "Convert a Matplotlib Figure to a Leaflet map."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, embedded=False):\n        if embedded:\n            if self.code is None:\n                self.code = urllib.request.urlopen(self.url).read()\n            return '<script>{}</script>'.format(self.code)\n        else:\n            return '<script src=\"{}\"></script>'.format(self.url)", "response": "Renders the object.\n        \n        Parameters\n        ----------\n            embedded : bool, default False\n                Whether the code shall be embedded explicitely in the render."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an incident in the cache set", "response": "def create_incident(**kwargs):\n    \"\"\"\n    Creates an incident\n    \"\"\"\n    incidents = cachet.Incidents(endpoint=ENDPOINT, api_token=API_TOKEN)\n    if 'component_id' in kwargs:\n        return incidents.post(name=kwargs['name'],\n                              message=kwargs['message'],\n                              status=kwargs['status'],\n                              component_id=kwargs['component_id'],\n                              component_status=kwargs['component_status'])\n    else:\n        return incidents.post(name=kwargs['name'],\n                              message=kwargs['message'],\n                              status=kwargs['status'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if an incident with these attributes already exists", "response": "def incident_exists(name, message, status):\n    \"\"\"\n    Check if an incident with these attributes already exists\n    \"\"\"\n    incidents = cachet.Incidents(endpoint=ENDPOINT)\n    all_incidents = json.loads(incidents.get())\n    for incident in all_incidents['data']:\n        if name == incident['name'] and \\\n           status == incident['status'] and \\\n           message.strip() == incident['message'].strip():\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_component(id):\n    components = cachet.Components(endpoint=ENDPOINT)\n    component = json.loads(components.get(id=id))\n    return component['data']", "response": "Gets a Cachet component by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if all required_args have a value.", "response": "def check_required_args(required_args, args):\n    \"\"\"\n    Checks if all required_args have a value.\n    :param required_args: list of required args\n    :param args: kwargs\n    :return: True (if an exception isn't raised)\n    \"\"\"\n    for arg in required_args:\n        if arg not in args:\n            raise KeyError('Required argument: %s' % arg)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, id=None, **kwargs):\n        if id is not None:\n            return self._get('components/%s' % id, data=kwargs)\n        elif 'params' in kwargs:\n            data = dict(kwargs)\n            params = data.pop('params')\n            return self._get('components', data=data, params=params)\n        else:\n            return self._get('components', data=kwargs)", "response": "Get a specific component from cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put(self, **kwargs):\n        required_args = ['id']\n        check_required_args(required_args, kwargs)\n\n        return self._put('components/groups/%s' % kwargs['id'], data=kwargs)", "response": "Update a component group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, id=None, **kwargs):\n        if id is not None:\n            return self._get('metrics/%s' % id, data=kwargs)\n        else:\n            return self._get('metrics', data=kwargs)", "response": "Get a specific metric from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npost a set of metrics to the cache.", "response": "def post(self, **kwargs):\n        \"\"\"\n        https://docs.cachethq.io/docs/metrics\n        \"\"\"\n        # default values\n        kwargs.setdefault('default_value', kwargs.get('default_value', 0))\n\n        required_args = ['name', 'suffix', 'description', 'default_value']\n        check_required_args(required_args, kwargs)\n\n        return self._post('metrics', data=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, metric_id=None, **kwargs):\n        if metric_id is None:\n            raise AttributeError('metric_id is required to get metric points.')\n\n        return self._get('metrics/%s/points' % metric_id, data=kwargs)", "response": "Get a metric point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post(self, **kwargs):\n        required_args = ['email']\n        check_required_args(required_args, kwargs)\n\n        return self._post('subscribers', data=kwargs)", "response": "Post a subscriber to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef synchronized(wrapped):\n    _lock = threading.RLock()\n\n    @functools.wraps(wrapped)\n    def _wrapper(*args, **kwargs):\n        with _lock:\n            return wrapped(*args, **kwargs)\n    return _wrapper", "response": "The missing @synchronized decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version():\n    file_dir = os.path.realpath(os.path.dirname(__file__))\n    with open(\n            os.path.join(file_dir, '..', 'behold', 'version.py')) as f:\n        txt = f.read()\n    version_match = re.search(\n        r\"\"\"^__version__ = ['\"]([^'\"]*)['\"]\"\"\", txt, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(\"Unable to find version string.\")", "response": "Obtain the packge version from a python file e. g. pkg / __init__. py\n    See <https://packaging. python. org / en / latest / single_source_version. html >"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef when(self, *bools):\n        self.passes = self.passes and all(bools)\n        return self", "response": "Sets the passed in flag to True for printing to be enabled."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stash(self, *values, **data):\n        if not self.tag:\n            raise ValueError(\n                'You must instantiate Behold with a tag name if you want to '\n                'use stashing'\n            )\n\n        item, att_names = self._get_item_and_att_names(*values, **data)\n        if not item:\n            self.reset()\n            return False\n\n        out = {name: item.__dict__.get(name, None) for name in att_names}\n\n        self.__class__._stash[self.tag].append(out)\n        self.reset()\n        return True", "response": "Stashes the values of the current object with the given values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the filter is true.", "response": "def is_true(self, item=None):\n        \"\"\"\n        If you are filtering on object values, you need to pass that object here.\n        \"\"\"\n        if item:\n            values = [item]\n        else:\n            values = []\n        self._get_item_and_att_names(*values)\n        return self._passes_all"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract(self, item, name):\n        val = ''\n        if hasattr(item, name):\n            val = getattr(item, name)\n        return str(val)", "response": "This method is used to extract the value of an attribute from an object. It is used to extract the value of a specific attribute from a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_html(self):\n        self.parsed_html = soup = BeautifulSoup(self.html, 'html.parser')\n        self.scripts = [script['src'] for script in\n                        soup.findAll('script', src=True)]\n        self.meta = {\n            meta['name'].lower():\n                meta['content'] for meta in soup.findAll(\n                    'meta', attrs=dict(name=True, content=True))\n        }", "response": "Parse the HTML with BeautifulSoup to find the script and meta tags."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_from_url(cls, url, verify=True):\n        response = requests.get(url, verify=verify, timeout=2.5)\n        return cls.new_from_response(response)", "response": "Constructs a new WebPage object from a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a new WebPage object from a response object.", "response": "def new_from_response(cls, response):\n        \"\"\"\n        Constructs a new WebPage object for the response,\n        using the `BeautifulSoup` module to parse the HTML.\n\n        Parameters\n        ----------\n\n        response : requests.Response object\n        \"\"\"\n        return cls(response.url, html=response.text, headers=response.headers)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prepare_app(self, app):\n\n        # Ensure these keys' values are lists\n        for key in ['url', 'html', 'script', 'implies']:\n            try:\n                value = app[key]\n            except KeyError:\n                app[key] = []\n            else:\n                if not isinstance(value, list):\n                    app[key] = [value]\n\n        # Ensure these keys exist\n        for key in ['headers', 'meta']:\n            try:\n                value = app[key]\n            except KeyError:\n                app[key] = {}\n\n        # Ensure the 'meta' key is a dict\n        obj = app['meta']\n        if not isinstance(obj, dict):\n            app['meta'] = {'generator': obj}\n\n        # Ensure keys are lowercase\n        for key in ['headers', 'meta']:\n            obj = app[key]\n            app[key] = {k.lower(): v for k, v in obj.items()}\n\n        # Prepare regular expression patterns\n        for key in ['url', 'html', 'script']:\n            app[key] = [self._prepare_pattern(pattern) for pattern in app[key]]\n\n        for key in ['headers', 'meta']:\n            obj = app[key]\n            for name, pattern in obj.items():\n                obj[name] = self._prepare_pattern(obj[name])", "response": "Prepare the app data for detection phase."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_pattern(self, pattern):\n        regex, _, rest = pattern.partition('\\\\;')\n        try:\n            return re.compile(regex, re.I)\n        except re.error as e:\n            warnings.warn(\n                \"Caught '{error}' compiling regex: {regex}\"\n                .format(error=e, regex=regex)\n            )\n            # regex that never matches:\n            # http://stackoverflow.com/a/1845097/413622\n            return re.compile(r'(?!x)x')", "response": "Prepare the regular expression for the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining whether the webpage has the app.", "response": "def _has_app(self, app, webpage):\n        \"\"\"\n        Determine whether the web page matches the app signature.\n        \"\"\"\n        # Search the easiest things first and save the full-text search of the\n        # HTML for last\n\n        for regex in app['url']:\n            if regex.search(webpage.url):\n                return True\n\n        for name, regex in app['headers'].items():\n            if name in webpage.headers:\n                content = webpage.headers[name]\n                if regex.search(content):\n                    return True\n\n        for regex in app['script']:\n            for script in webpage.scripts:\n                if regex.search(script):\n                    return True\n\n        for name, regex in app['meta'].items():\n            if name in webpage.meta:\n                content = webpage.meta[name]\n                if regex.search(content):\n                    return True\n\n        for regex in app['html']:\n            if regex.search(webpage.html):\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the set of apps implied by detected_apps.", "response": "def _get_implied_apps(self, detected_apps):\n        \"\"\"\n        Get the set of apps implied by `detected_apps`.\n        \"\"\"\n        def __get_implied_apps(apps):\n            _implied_apps = set()\n            for app in apps:\n                try:\n                    _implied_apps.update(set(self.apps[app]['implies']))\n                except KeyError:\n                    pass\n            return _implied_apps\n\n        implied_apps = __get_implied_apps(detected_apps)\n        all_implied_apps = set()\n\n        # Descend recursively until we've found all implied apps\n        while not all_implied_apps.issuperset(implied_apps):\n            all_implied_apps.update(implied_apps)\n            implied_apps = __get_implied_apps(all_implied_apps)\n\n        return all_implied_apps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_categories(self, app_name):\n        cat_nums = self.apps.get(app_name, {}).get(\"cats\", [])\n        cat_names = [self.categories.get(\"%s\" % cat_num, \"\")\n                     for cat_num in cat_nums]\n\n        return cat_names", "response": "Returns a list of the categories for an app name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of applications that can be detected on the web page.", "response": "def analyze(self, webpage):\n        \"\"\"\n        Return a list of applications that can be detected on the web page.\n        \"\"\"\n        detected_apps = set()\n\n        for app_name, app in self.apps.items():\n            if self._has_app(app, webpage):\n                detected_apps.add(app_name)\n\n        detected_apps |= self._get_implied_apps(detected_apps)\n\n        return detected_apps"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of applications and categories that can be detected on the web page.", "response": "def analyze_with_categories(self, webpage):\n        \"\"\"\n        Return a list of applications and categories that can be detected on the web page.\n        \"\"\"\n        detected_apps = self.analyze(webpage)\n        categorised_apps = {}\n\n        for app_name in detected_apps:\n            cat_names = self.get_categories(app_name)\n            categorised_apps[app_name] = {\"categories\": cat_names}\n\n        return categorised_apps"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self):\n        if self._initialized:\n            logger.info(\"brace yourselves, removing %r\", self.path)\n            shutil.rmtree(self.path)", "response": "remove the directory we operated on"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the directory if needed and configure it", "response": "def initialize(self):\n        \"\"\"\n        create the directory if needed and configure it\n\n        :return: None\n        \"\"\"\n        if not self._initialized:\n            logger.info(\"initializing %r\", self)\n            if not os.path.exists(self.path):\n                if self.mode is not None:\n                    os.makedirs(self.path, mode=self.mode)\n                else:\n                    os.makedirs(self.path)\n            self._set_mode()\n            self._add_facl_rules()\n            self._set_selinux_context()\n            self._set_ownership()\n            self._initialized = True\n            logger.info(\"initialized\")\n            return\n        logger.info(\"%r was already initialized\", self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets SELinux context or fields using chcon program.", "response": "def _set_selinux_context(self):\n        \"\"\"\n        Set SELinux context or fields using chcon program. Raises CommandDoesNotExistException\n        if the command is not present on the system.\n\n        :return: None\n        \"\"\"\n        chcon_command_exists()\n        # FIXME: do this using python API if possible\n        if self.selinux_context:\n            logger.debug(\"setting SELinux context of %s to %s\", self.path, self.selinux_context)\n            run_cmd([\"chcon\", self.selinux_context, self.path])\n        if any([self.selinux_user, self.selinux_role, self.selinux_type, self.selinux_range]):\n            logger.debug(\"setting SELinux fields of %s\", self.path, self.selinux_context)\n            # chcon [OPTION]... [-u USER] [-r ROLE] [-l RANGE] [-t TYPE] FILE...\n            pairs = [(\"-u\", self.selinux_user), (\"-r\", self.selinux_role),\n                     (\"-l\", self.selinux_range), (\"-t\", self.selinux_type)]\n            c = [\"chcon\"]\n            for p in pairs:\n                if p[1]:\n                    c += p\n            c += [self.path]\n            run_cmd(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_ownership(self):\n        if self.owner or self.group:\n            args = (\n                self.path,\n                self.owner if self.owner else -1,\n                self.group if self.group else -1,\n            )\n            logger.debug(\"changing ownership bits of %s to %s\", self.path, args)\n            os.chown(*args)", "response": "set ownership of the directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_mode(self):\n        if self.mode is not None:\n            logger.debug(\"changing permission bits of %s to %s\", self.path, oct(self.mode))\n            os.chmod(self.path, self.mode)", "response": "set permission bits if needed using python API os. chmod\n ArcGIS API"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies ACL rules on the directory using setfacl program.", "response": "def _add_facl_rules(self):\n        \"\"\"\n        Apply ACL rules on the directory using setfacl program. Raises CommandDoesNotExistException\n        if the command is not present on the system.\n\n        :return: None\n        \"\"\"\n        setfacl_command_exists()\n        # we are not using pylibacl b/c it's only for python 2\n        if self.facl_rules:\n            logger.debug(\"adding ACLs %s to %s\", self.facl_rules, self.path)\n            r = \",\".join(self.facl_rules)\n            run_cmd([\"setfacl\", \"-m\", r, self.path])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates instance from tuple.", "response": "def create_from_tuple(cls, volume):\n        \"\"\"\n        Create instance from tuple.\n        :param volume: tuple in one one of the following forms: target | source,target | source,target,mode\n        :return: instance of Volume\n        \"\"\"\n        if isinstance(volume, six.string_types):\n            return Volume(target=volume)\n        elif len(volume) == 2:\n            return Volume(source=volume[0],\n                          target=volume[1])\n        elif len(volume) == 3:\n            return Volume(source=volume[0],\n                          target=volume[1],\n                          mode=volume[2])\n        else:\n            logger.debug(\"Cannot create volume instance from {}.\"\n                         \"It has to be tuple of form target x source,target x source,target,mode.\".format(volume))\n            raise ConuException(\"Cannot create volume instance.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntag the image with the specified tag.", "response": "def tag_image(self, repository=None, tag=None):\n        \"\"\"\n        Apply additional tags to the image or a new name\n        >> podman tag image[:tag] target-name[:tag]\n\n        :param repository: str, see constructor\n        :param tag: str, see constructor\n        :return: instance of PodmanImage\n        \"\"\"\n        if not (repository or tag):\n            raise ValueError(\"You need to specify either repository or tag.\")\n        r = repository or self.name\n        t = tag or \"latest\"\n        identifier = self._id or self.get_id()\n        run_cmd([\"podman\", \"tag\", identifier, \"%s:%s\" % (r, t)])\n        return PodmanImage(r, tag=t)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rmi(self, force=False, via_name=False):\n        identifier = self.get_full_name() if via_name else (self._id or self.get_id())\n        cmdline = [\"podman\", \"rmi\", identifier, \"--force\" if force else \"\"]\n        run_cmd(cmdline)", "response": "remove this image from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run_container(self, run_command_instance, callback):\n        tmpfile = os.path.join(get_backend_tmpdir(), random_tmp_filename())\n        # the cid file must not exist\n        run_command_instance.options += [\"--cidfile=%s\" % tmpfile]\n        logger.debug(\"podman command: %s\" % run_command_instance)\n        response = callback()\n        # and we need to wait now; inotify would be better but is way more complicated and\n        # adds dependency\n        Probe(timeout=10, count=10, pause=0.1, fnc=lambda: self._file_not_empty(tmpfile)).run()\n        with open(tmpfile, 'r') as fd:\n            container_id = fd.read()\n        return container_id, response", "response": "this is internal method that runs a podman container"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _file_not_empty(tmpfile):\n        if os.path.exists(tmpfile):\n            return os.stat(tmpfile).st_size != 0\n        else:\n            return False", "response": "Checks if the file exists and is not empty"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new container using this image and run it in background", "response": "def run_via_binary(self, run_command_instance=None, command=None, volumes=None,\n                       additional_opts=None, **kwargs):\n        \"\"\"\n        create a container using this image and run it in background;\n        this method is useful to test real user scenarios when users invoke containers using\n        binary\n\n        :param run_command_instance: instance of PodmanRunBuilder\n        :param command: list of str, command to run in the container, examples:\n            - [\"ls\", \"/\"]\n            - [\"bash\", \"-c\", \"ls / | grep bin\"]\n        :param volumes: tuple or list of tuples in the form:\n\n            * `(\"/path/to/directory\", )`\n            * `(\"/host/path\", \"/container/path\")`\n            * `(\"/host/path\", \"/container/path\", \"mode\")`\n            * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also\n                Directory instance)\n\n        :param additional_opts: list of str, additional options for `podman run`\n        :return: instance of PodmanContainer\n        \"\"\"\n\n        logger.info(\"run container via binary in background\")\n\n        if (command is not None or additional_opts is not None) \\\n                and run_command_instance is not None:\n            raise ConuException(\n                \"run_command_instance and command parameters cannot be passed \"\n                \"into method at same time\")\n\n        if run_command_instance is None:\n            command = command or []\n            additional_opts = additional_opts or []\n\n            if (isinstance(command, list) or isinstance(command, tuple) and\n               isinstance(additional_opts, list) or isinstance(additional_opts, tuple)):\n                run_command_instance = PodmanRunBuilder(\n                    command=command, additional_opts=additional_opts)\n            else:\n                raise ConuException(\"command and additional_opts needs to be list of str or None\")\n        else:\n            run_command_instance = run_command_instance or PodmanRunBuilder()\n            if not isinstance(run_command_instance, PodmanRunBuilder):\n                raise ConuException(\n                    \"run_command_instance needs to be an instance of PodmanRunBuilder\")\n\n        run_command_instance.image_name = self.get_id()\n        run_command_instance.options += [\"-d\"]\n\n        if volumes:\n            run_command_instance.options += self.get_volume_options(volumes=volumes)\n\n        def callback():\n            try:\n                # FIXME: catch std{out,err}, print stdout to logger.debug, stderr to logger.error\n                run_cmd(run_command_instance.build())\n            except subprocess.CalledProcessError as ex:\n                raise ConuException(\"Container exited with an error: %s\" % ex.returncode)\n\n        container_id, _ = self._run_container(run_command_instance, callback)\n        container_name = graceful_get(self._inspect(container_id), \"Name\")\n\n        return PodmanContainer(self, container_id, name=container_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a container using this image and run it in foreground; this method is useful to test real user scenarios when users invoke containers using binary and pass input into the container via STDIN. You are also responsible for: * redirecting STDIN when intending to use container.write_to_stdin afterwards by setting popen_params={\"stdin\": subprocess.PIPE} during run_via_binary_in_foreground * checking whether the container exited successfully via: container.popen_instance.returncode Please consult the documentation for subprocess python module for best practices on how you should work with instance of Popen :param run_command_instance: instance of PodmanRunBuilder :param command: list of str, command to run in the container, examples: - [\"ls\", \"/\"] - [\"bash\", \"-c\", \"ls / | grep bin\"] :param volumes: tuple or list of tuples in the form: * `(\"/path/to/directory\", )` * `(\"/host/path\", \"/container/path\")` * `(\"/host/path\", \"/container/path\", \"mode\")` * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also Directory instance) :param additional_opts: list of str, additional options for `docker run` :param popen_params: dict, keyword arguments passed to Popen constructor :param container_name: str, pretty container identifier :return: instance of PodmanContainer", "response": "def run_via_binary_in_foreground(\n            self, run_command_instance=None, command=None, volumes=None,\n            additional_opts=None, popen_params=None, container_name=None):\n        \"\"\"\n        Create a container using this image and run it in foreground;\n        this method is useful to test real user scenarios when users invoke containers using\n        binary and pass input into the container via STDIN. You are also responsible for:\n\n         * redirecting STDIN when intending to use container.write_to_stdin afterwards by setting\n              popen_params={\"stdin\": subprocess.PIPE} during run_via_binary_in_foreground\n\n         * checking whether the container exited successfully via:\n              container.popen_instance.returncode\n\n        Please consult the documentation for subprocess python module for best practices on\n        how you should work with instance of Popen\n\n        :param run_command_instance: instance of PodmanRunBuilder\n        :param command: list of str, command to run in the container, examples:\n            - [\"ls\", \"/\"]\n            - [\"bash\", \"-c\", \"ls / | grep bin\"]\n        :param volumes: tuple or list of tuples in the form:\n\n            * `(\"/path/to/directory\", )`\n            * `(\"/host/path\", \"/container/path\")`\n            * `(\"/host/path\", \"/container/path\", \"mode\")`\n            * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also\n                Directory instance)\n\n        :param additional_opts: list of str, additional options for `docker run`\n        :param popen_params: dict, keyword arguments passed to Popen constructor\n        :param container_name: str, pretty container identifier\n        :return: instance of PodmanContainer\n        \"\"\"\n        logger.info(\"run container via binary in foreground\")\n\n        if (command is not None or additional_opts is not None) \\\n                and run_command_instance is not None:\n            raise ConuException(\n                \"run_command_instance and command parameters cannot be \"\n                \"passed into method at same time\")\n\n        if run_command_instance is None:\n            command = command or []\n            additional_opts = additional_opts or []\n\n            if (isinstance(command, list) or isinstance(command, tuple) and\n               isinstance(additional_opts, list) or isinstance(additional_opts, tuple)):\n                run_command_instance = PodmanRunBuilder(\n                    command=command, additional_opts=additional_opts)\n            else:\n                raise ConuException(\"command and additional_opts needs to be list of str or None\")\n        else:\n            run_command_instance = run_command_instance or PodmanRunBuilder()\n            if not isinstance(run_command_instance, PodmanRunBuilder):\n                raise ConuException(\"run_command_instance needs to be an \"\n                                    \"instance of PodmanRunBuilder\")\n\n        popen_params = popen_params or {}\n\n        run_command_instance.image_name = self.get_id()\n        if container_name:\n            run_command_instance.options += [\"--name\", container_name]\n\n        if volumes:\n            run_command_instance.options += self.get_volume_options(volumes=volumes)\n\n        def callback():\n            return subprocess.Popen(run_command_instance.build(), **popen_params)\n\n        container_id, popen_instance = self._run_container(run_command_instance, callback)\n\n        actual_name = graceful_get(self._inspect(container_id), \"Name\")\n\n        if container_name and container_name != actual_name:\n            raise ConuException(\n                \"Unexpected container name value. Expected = \"\n                + str(container_name) + \" Actual = \" + str(actual_name))\n        if not container_name:\n            container_name = actual_name\n        return PodmanContainer(\n            self, container_id, popen_instance=popen_instance, name=container_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating volume options to run methods.", "response": "def get_volume_options(volumes):\n        \"\"\"\n        Generates volume options to run methods.\n\n        :param volumes: tuple or list of tuples in form target x source,target x source,target,mode.\n        :return: list of the form [\"-v\", \"/source:/target\", \"-v\", \"/other/source:/destination:z\", ...]\n        \"\"\"\n        if not isinstance(volumes, list):\n            volumes = [volumes]\n        volumes = [Volume.create_from_tuple(v) for v in volumes]\n        result = []\n        for v in volumes:\n            result += [\"-v\", str(v)]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget IDs of image layers", "response": "def get_layer_ids(self, rev=True):\n        \"\"\"\n        Get IDs of image layers\n\n        :param rev: get layers reversed\n        :return: list of strings\n        \"\"\"\n        cmdline = [\"podman\", \"history\", \"--format\", \"{{.ID}}\", self._id or self.get_id()]\n        layers = [layer for layer in run_cmd(cmdline, return_output=True)]\n        if not rev:\n            layers = layers.reverse()\n        return layers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef layers(self, rev=True):\n        image_layers = [\n            PodmanImage(None, identifier=x, pull_policy=PodmanImagePullPolicy.NEVER)\n            for x in self.get_layer_ids()\n        ]\n        if not rev:\n            image_layers.reverse()\n        return image_layers", "response": "Get list of PodmanImage for every layer in image\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_metadata(self):\n        if self._metadata is None:\n            self._metadata = ImageMetadata()\n        inspect_to_metadata(self._metadata, self.inspect(refresh=True))\n        return self._metadata", "response": "Get metadata about this image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef http_client(self, host=None, port=None):\n\n        host = host or self.get_IPv4s()[0]\n        port = port or self.get_ports()[0]\n\n        yield HttpClient(host, port, self.http_session)", "response": "A context manager that returns a new HttpClient instance that can be used to access the HTTP server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs-in to the Docker registry", "response": "def login_to_registry(username, token=None):\n    \"\"\"\n    Login within docker daemon to docker registry running in this OpenShift cluster\n    :return:\n    \"\"\"\n\n    token = token or get_oc_api_token()\n\n    with DockerBackend() as backend:\n        backend.login(username, password=token,\n                      registry=get_internal_registry_ip(), reauth=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npushing the image to the registry", "response": "def push_to_registry(image, repository, tag, project):\n    \"\"\"\n    :param image: DockerImage, image to push\n    :param repository: str, new name of image\n    :param tag: str, new tag of image\n    :param project: str, oc project\n    :return: DockerImage, new docker image\n    \"\"\"\n    return image.push(\"%s/%s/%s\" % (get_internal_registry_ip(), project, repository), tag=tag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for docker - registry IP and return it", "response": "def get_internal_registry_ip():\n    \"\"\"\n    Search for `docker-registry` IP\n    :return: str, ip address\n    \"\"\"\n    with conu.backend.origin.backend.OpenshiftBackend() as origin_backend:\n        services = origin_backend.list_services()\n        for service in services:\n            if service.name == 'docker-registry':\n                logger.debug(\"Internal docker-registry IP: %s\",\n                             \"{ip}:{port}\".format(ip=service.get_ip(), port=INTERNAL_REGISTRY_PORT))\n                return \"{ip}:{port}\".format(ip=service.get_ip(), port=INTERNAL_REGISTRY_PORT)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the pod from the Kubernetes cluster", "response": "def delete(self):\n        \"\"\"\n        delete pod from the Kubernetes cluster\n        :return: None\n        \"\"\"\n        body = client.V1DeleteOptions()\n\n        try:\n            status = self.core_api.delete_namespaced_pod(self.name, self.namespace, body)\n            logger.info(\"Deleting Pod %s in namespace %s\", self.name, self.namespace)\n            self.phase = PodPhase.TERMINATING\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API - delete_namespaced_pod: %s\\n\" % e)\n\n        if status.status == 'Failure':\n            raise ConuException(\"Deletion of Pod failed\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_logs(self):\n        try:\n            api_response = self.core_api.read_namespaced_pod_log(self.name, self.namespace)\n            logger.debug(\"Logs from pod: %s in namespace: %s\", self.name, self.namespace)\n            for line in api_response.split('\\n'):\n                logger.debug(line)\n            return api_response\n        except ApiException as e:\n            # no reason to throw exception when logs cannot be obtain, just notify user\n            logger.debug(\"Cannot get pod logs because of \"\n                         \"exception during calling Kubernetes API %s\\n\", e)\n\n        return None", "response": "get logs from Kubernetes API"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_phase(self):\n\n        if self.phase != PodPhase.TERMINATING:\n            self.phase = PodPhase.get_from_string(self.get_status().phase)\n\n        return self.phase", "response": "get the phase of the pod\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting conditions through which the pod has passed", "response": "def get_conditions(self):\n        \"\"\"\n        get conditions through which the pod has passed\n        :return: list of PodCondition enum or empty list\n        \"\"\"\n\n        # filter just values that are true (means that pod has that condition right now)\n        return [PodCondition.get_from_string(c.type) for c in self.get_status().conditions\n                if c.status == 'True']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_ready(self):\n        if PodCondition.READY in self.get_conditions():\n            logger.info(\"Pod: %s in namespace: %s is ready!\", self.name, self.namespace)\n            return True\n        return False", "response": "Check if pod is in READY condition"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nblocks until the pod is ready.", "response": "def wait(self, timeout=15):\n        \"\"\"\n        block until pod is not ready, raises an exc ProbeTimeout if timeout is reached\n        :param timeout: int or float (seconds), time to wait for pod to run\n        :return: None\n        \"\"\"\n\n        Probe(timeout=timeout, fnc=self.is_ready, expected_retval=True).run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(image_data):\n\n        # convert environment variables to Kubernetes objects\n        env_variables = []\n        for key, value in image_data.env_variables.items():\n            env_variables.append(client.V1EnvVar(name=key, value=value))\n\n        # convert exposed ports to Kubernetes objects\n        exposed_ports = []\n        if image_data.exposed_ports is not None:\n            for port in image_data.exposed_ports:\n                splits = port.split(\"/\", 1)\n                port = int(splits[0])\n                protocol = splits[1].upper() if len(splits) > 1 else None\n                exposed_ports.append(client.V1ContainerPort(container_port=port, protocol=protocol))\n\n        # generate container name {image-name}-{username}-{random-4-letters}\n        # take just name of image and remove tag\n        image_name = image_data.name.split(\"/\")[-1].split(\":\")[0]\n        random_string = ''.join(\n            random.choice(string.ascii_lowercase + string.digits) for _ in range(4))\n        container_name = '{image_name}-{user_name}-{random_string}'.format(\n            image_name=image_name,\n            user_name=getpass.getuser(),\n            random_string=random_string)\n\n        container = client.V1Container(command=image_data.command,\n                                       env=env_variables,\n                                       image=image_data.name,\n                                       name=container_name,\n                                       ports=exposed_ports)\n\n        pod_metadata = client.V1ObjectMeta(name=container_name + \"-pod\")\n        pod_spec = client.V1PodSpec(containers=[container])\n        pod = client.V1Pod(spec=pod_spec, metadata=pod_metadata)\n\n        return pod", "response": "Create a new cluster with the specified image metadata."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_from_string(cls, string_phase):\n\n        if string_phase == 'Pending':\n            return cls.PENDING\n        elif string_phase == 'Running':\n            return cls.RUNNING\n        elif string_phase == 'Succeeded':\n            return cls.SUCCEEDED\n        elif string_phase == 'Failed':\n            return cls.FAILED\n        elif string_phase == 'Unknown':\n            return cls.UNKNOWN\n\n        return cls.UNKNOWN", "response": "Convert string value obtained from k8s API to PodPhase enum value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert string value obtained from k8s API to PodCondition enum value", "response": "def get_from_string(cls, string_condition):\n        \"\"\"\n        Convert string value obtained from k8s API to PodCondition enum value\n        :param string_condition: str, condition value from Kubernetes API\n        :return: PodCondition\n        \"\"\"\n\n        if string_condition == 'PodScheduled':\n            return cls.SCHEDULED\n        elif string_condition == 'Ready':\n            return cls.READY\n        elif string_condition == 'Initialized':\n            return cls.INITIALIZED\n        elif string_condition == 'Unschedulable':\n            return cls.UNSCHEDULABLE\n        elif string_condition == 'ContainersReady':\n            return cls.CONTAINERS_READY\n\n        return cls.UNKNOWN"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_id(self):\n        if self._id is None:\n            self._id = graceful_get(self.inspect(refresh=True), \"ID\")\n        return self._id", "response": "get unique identifier of this container"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_name(self):\n        self.name = self.name or graceful_get(self.inspect(refresh=False), \"Name\")\n        return self.name", "response": "Returns the name of the container"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inspect(self, refresh=True):\n        if refresh or not self._inspect_data:\n            identifier = self._id or self.name\n            if not identifier:\n                raise ConuException(\"This container does not have a valid identifier.\")\n            self._inspect_data = self._inspect(identifier)\n        return self._inspect_data", "response": "inspect the container s metadata"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_running(self):\n        try:\n            return graceful_get(self.inspect(refresh=True), \"State\", \"Running\")\n        except subprocess.CalledProcessError:\n            return False", "response": "Returns True if the container is running False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if given port is open and receiving connections on container ip_address", "response": "def is_port_open(self, port, timeout=2):\n        \"\"\"\n        check if given port is open and receiving connections on container ip_address\n\n        :param port: int, container port\n        :param timeout: int, how many seconds to wait for connection; defaults to 2\n        :return: True if the connection has been established inside timeout, False otherwise\n        \"\"\"\n        addresses = self.get_IPv4s()\n        if not addresses:\n            return False\n        return check_port(port, host=addresses[0], timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nblocking until specified port starts accepting connections raises an exc ProbeTimeout", "response": "def wait_for_port(self, port, timeout=10, **probe_kwargs):\n        \"\"\"\n        block until specified port starts accepting connections, raises an exc ProbeTimeout\n        if timeout is reached\n\n        :param port: int, port number\n        :param timeout: int or float (seconds), time to wait for establishing the connection\n        :param probe_kwargs: arguments passed to Probe constructor\n        :return: None\n        \"\"\"\n        Probe(timeout=timeout, fnc=functools.partial(self.is_port_open, port), **probe_kwargs).run()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving this container from the container store", "response": "def delete(self, force=False, **kwargs):\n        \"\"\"\n        remove this container; kwargs indicate that some container runtimes\n        might accept more parameters\n\n        :param force: bool, if container engine supports this, force the functionality\n        :return: None\n        \"\"\"\n        cmdline = [\"podman\", \"rm\", \"--force\" if force else \"\", self.get_name()]\n        run_cmd(cmdline)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmounts container filesystem :return: str, the location of the mounted file system", "response": "def mount(self, mount_point=None):\n        \"\"\"\n        mount container filesystem\n\n        :return: str, the location of the mounted file system\n        \"\"\"\n        cmd = [\"podman\", \"mount\", self._id or self.get_id()]\n        output = run_cmd(cmd, return_output=True).rstrip(\"\\n\\r\")\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting logs from this container.", "response": "def logs(self, follow=False):\n        \"\"\"\n        Get logs from this container. Iterator has one log line followed by a newline in next item.\n        The logs are NOT encoded (they are str, not bytes).\n\n        Let's look at an example::\n\n            image = conu.PodmanImage(\"fedora\", tag=\"27\")\n            command = [\"bash\", \"-c\", \"for x in `seq 1 5`; do echo $x; sleep 1; done\"]\n            container = image.run_via_binary(command=command)\n            for line in container.logs(follow=True):\n                print(line)\n\n        This will output\n\n        .. code-block:: none\n\n            '1' '\\n' '2' '\\n' '3' '\\n' '4' '\\n' '5' '\\n'\n\n        :param follow: bool, provide new logs as they come\n        :return: iterator (of str)\n        \"\"\"\n        # TODO: podman logs have different behavior than docker\n        follow = [\"--follow\"] if follow else []\n        cmdline = [\"podman\", \"logs\"] + follow + [self._id or self.get_id()]\n        output = run_cmd(cmdline, return_output=True)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nblocking until the container stops then return its exit code.", "response": "def wait(self, timeout=None):\n        \"\"\"\n        Block until the container stops, then return its exit code. Similar to\n        the ``podman wait`` command.\n\n        :param timeout: int, microseconds to wait before polling for completion\n        :return: int, exit code\n        \"\"\"\n        timeout = [\"--interval=%s\" % timeout] if timeout else []\n        cmdline = [\"podman\", \"wait\"] + timeout + [self._id or self.get_id()]\n        return run_cmd(cmdline, return_output=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a command in this container", "response": "def execute(self, command):\n        \"\"\"\n        Execute a command in this container -- the container needs to be running.\n\n        :param command: list of str, command to execute in the container\n        :return: str\n        \"\"\"\n\n        logger.info(\"running command %s\", command)\n        cmd = [\"podman\", \"exec\", self.get_id()] + command\n        output = run_cmd(cmd, return_output=True)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_metadata(self):\n        if self._metadata is None:\n            self._metadata = ContainerMetadata()\n        inspect_to_container_metadata(self._metadata, self.inspect(refresh=True), self.image)\n        return self._metadata", "response": "Get container metadata from dictionary returned after podman inspect command into instance of ContainerMetadata class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a list of V1ServicePort objects into a list of metadata ports.", "response": "def k8s_ports_to_metadata_ports(k8s_ports):\n    \"\"\"\n    :param k8s_ports: list of V1ServicePort\n    :return: list of str, list of exposed ports, example:\n            - ['1234/tcp', '8080/udp']\n    \"\"\"\n\n    ports = []\n\n    for k8s_port in k8s_ports:\n        if k8s_port.protocol is not None:\n            ports.append(\"%s/%s\" % (k8s_port.port, k8s_port.protocol.lower()))\n        else:\n            ports.append(str(k8s_port.port))\n\n    return ports"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list of ports to K8S ports.", "response": "def metadata_ports_to_k8s_ports(ports):\n    \"\"\"\n    :param ports: list of str, list of exposed ports, example:\n            - ['1234/tcp', '8080/udp']\n    :return: list of V1ServicePort\n    \"\"\"\n\n    exposed_ports = []\n\n    for port in ports:\n        splits = port.split(\"/\", 1)\n        port = int(splits[0])\n        protocol = splits[1].upper() if len(splits) > 1 else None\n        exposed_ports.append(client.V1ServicePort(port=port, protocol=protocol))\n\n    return exposed_ports"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p(self, path):\n        if path.startswith(\"/\"):\n            path = path[1:]\n        p = os.path.join(self.mount_point, path)\n        logger.debug(\"path = %s\", p)\n        return p", "response": "provide absolute path within the container\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_from(self, src, dest):\n        p = self.p(src)\n        if os.path.isfile(p):\n            logger.info(\"copying file %s to %s\", p, dest)\n            shutil.copy2(p, dest)\n        else:\n            logger.info(\"copying directory %s to %s\", p, dest)\n            shutil.copytree(p, dest)", "response": "Copy a file or a directory from container or image to host system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_file(self, file_path):\n        try:\n            with open(self.p(file_path)) as fd:\n                return fd.read()\n        except IOError as ex:\n            logger.error(\"error while accessing file %s: %r\", file_path, ex)\n            raise ConuException(\"There was an error while accessing file %s: %r\", file_path, ex)", "response": "read file specified via file_path and return its content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_file(self, file_path, mode=\"r\"):\n        return open(self.p(file_path), mode=mode)", "response": "provide File object specified via file_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_is_present(self, file_path):\n        p = self.p(file_path)\n        if not os.path.exists(p):\n            return False\n        if not os.path.isfile(p):\n            raise IOError(\"%s is not a file\" % file_path)\n        return True", "response": "check if file is present"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef directory_is_present(self, directory_path):\n        p = self.p(directory_path)\n        if not os.path.exists(p):\n            return False\n        if not os.path.isdir(p):\n            raise IOError(\"%s is not a directory\" % directory_path)\n        return True", "response": "check if directory is present"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_selinux_context(self, file_path):\n        # what if SELinux is not enabled?\n        p = self.p(file_path)\n        if not HAS_XATTR:\n            raise RuntimeError(\"'xattr' python module is not available, hence we cannot \"\n                               \"determine the SELinux context for this file. \"\n                               \"In Fedora this module is available as python3-pyxattr -- \"\n                               \"other distributions may follow similar naming scheme.\")\n        return xattr.get(p, \"security.selinux\")", "response": "Get the SELinux file context of the selected file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for the function that checks return status of Probe. fnc and provides the result for process managing", "response": "def _wrapper(self, q, start):\n        \"\"\"\n        _wrapper checks return status of Probe.fnc and provides the result for process managing\n\n        :param q:     Queue for function results\n        :param start: Time of function run (used for logging)\n        :return:      Return value or Exception\n        \"\"\"\n        try:\n            func_name = self.fnc.__name__\n        except AttributeError:\n            func_name = str(self.fnc)\n        logger.debug(\"Running \\\"%s\\\" with parameters: \\\"%s\\\":\\t%s/%s\"\n                     % (func_name, str(self.kwargs), round(time.time() - start), self.timeout))\n        try:\n            result = self.fnc(**self.kwargs)\n            # let's log only first 50 characters of the response\n            logger.debug(\"callback result = %s\", str(result)[:50])\n            q.put(result)\n        except self.expected_exceptions as ex:\n            logger.debug(\"expected exception was caught: %s\", ex)\n            q.put(False)\n        except Exception as ex:\n            logger.debug(\"adding exception %s to queue\", ex)\n            q.put(ex)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse DockerImage info into skopeo parameter", "response": "def transport_param(image):\n    \"\"\" Parse DockerImage info into skopeo parameter\n\n    :param image: DockerImage\n    :return: string. skopeo parameter specifying image\n    \"\"\"\n    transports = {SkopeoTransport.CONTAINERS_STORAGE: \"containers-storage:\",\n                  SkopeoTransport.DIRECTORY: \"dir:\",\n                  SkopeoTransport.DOCKER: \"docker://\",\n                  SkopeoTransport.DOCKER_ARCHIVE: \"docker-archive\",\n                  SkopeoTransport.DOCKER_DAEMON: \"docker-daemon:\",\n                  SkopeoTransport.OCI: \"oci:\",\n                  SkopeoTransport.OSTREE: \"ostree:\"}\n\n    transport = image.transport\n    tag = image.tag\n    repository = image.name\n    path = image.path\n\n    if not transport:\n        transport = SkopeoTransport.DOCKER\n    command = transports[transport]\n\n    path_required = [SkopeoTransport.DIRECTORY, SkopeoTransport.DOCKER_ARCHIVE, SkopeoTransport.OCI]\n    if transport in path_required and path is None:\n        raise ValueError(transports[transport] + \" path is required to be specified\")\n\n    if transport == SkopeoTransport.DIRECTORY:\n        return command + path\n    if transport == SkopeoTransport.DOCKER_ARCHIVE:\n        command += path\n        if repository is None:\n            return command\n        command += \":\"\n    if transport in [SkopeoTransport.CONTAINERS_STORAGE, SkopeoTransport.DOCKER,\n                     SkopeoTransport.DOCKER_ARCHIVE, transport.DOCKER_DAEMON]:\n        return command + repository + \":\" + tag\n    if transport == SkopeoTransport.OCI:\n        return command + path + \":\" + tag\n    if transport == SkopeoTransport.OSTREE:\n        return command + repository + (\"@\" + path if path else \"\")\n\n    raise ConuException(\"This transport is not supported\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_metadata(self, refresh=True):\n        if refresh or not self._metadata:\n            ident = self._id or self.name\n            if not ident:\n                raise ConuException(\n                    \"This container does not have a valid identifier.\")\n            out = run_cmd([\"machinectl\", \"--no-pager\", \"show\", ident], return_output=True, ignore_status=True)\n            if \"Could not get path to machine\" in out:\n                self._metadata = {}\n            else:\n                self._metadata = convert_kv_to_dict(out)\n        return self._metadata", "response": "Get the metadata of the current container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_running(self):\n        cmd = [\"machinectl\", \"--no-pager\", \"status\", self.name]\n        try:\n            subprocess.check_call(cmd)\n            return True\n        except subprocess.CalledProcessError as ex:\n            logger.info(\"nspawn container %s is not running probably: %s\",\n                        self.name, ex.output)\n            return False", "response": "Check if a nspawn container is running."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying a file or a directory from container or image to host system", "response": "def copy_from(self, src, dest):\n        \"\"\"\n        copy a file or a directory from container or image to host system.\n\n        :param src: str, path to a file or a directory within container or image\n        :param dest: str, path to a file or a directory on host system\n        :return: None\n        \"\"\"\n        logger.debug(\"copying %s from host to container at %s\", src, dest)\n        cmd = [\"machinectl\", \"--no-pager\", \"copy-from\", self.name, src, dest]\n        run_cmd(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _wait_until_machine_finish(self):\n        self.image._wait_for_machine_finish(self.name)\n        # kill main run process\n        self.start_process.kill()\n        # TODO: there are some backgroud processes, dbus async events or something similar, there is better to wait\n        # to provide enough time to finish also some async ops\n        time.sleep(constants.DEFAULT_SLEEP)", "response": "Internal method to wait until the machine is finished and kill main process"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, force=False, volumes=False):\n        try:\n            self.image.rmi()\n        except ConuException as ime:\n            if not force:\n                raise ime\n            else:\n                pass", "response": "delete underlying image\n\n        :param force: bool - force delete, do not care about errors\n        :param volumes: not used anyhow\n        :return: None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_systemdrun(\n            self, command, internal_background=False, return_full_dict=False,\n            **kwargs):\n        \"\"\"\n        execute command via systemd-run inside container\n\n        :param command: list of command params\n        :param internal_background: not used now\n        :param kwargs: pass params to subprocess\n        :return: dict with result\n        \"\"\"\n        internalkw = deepcopy(kwargs) or {}\n        original_ignore_st = internalkw.get(\"ignore_status\", False)\n        original_return_st = internalkw.get(\"return_output\", False)\n        internalkw[\"ignore_status\"] = True\n        internalkw[\"return_output\"] = False\n        unit_name = constants.CONU_ARTIFACT_TAG + \"unit_\" + random_str()\n        opts = [\"-M\", self.name, \"--unit\", unit_name]\n        lpath = \"/var/tmp/{}\".format(unit_name)\n        comout = {}\n        if self._run_systemdrun_decide():\n            add_wait_var = \"--wait\"\n        else:\n            # keep service exist after it finish, to be able to read exit code\n            add_wait_var = \"-r\"\n        if internal_background:\n            add_wait_var = \"\"\n        if add_wait_var:\n            opts.append(add_wait_var)\n        # TODO: behave move similar to run_cmd function, unable to work with clean subprocess objects because systemd-run\n        # does not support return stderr, stdout, and return code directly\n        # find way how to do this in better way, machinectl shell is not possible\n        # https://github.com/systemd/systemd/issues/5879\n        # https://github.com/systemd/systemd/issues/5878\n        bashworkaround = [\n            \"/bin/bash\",\n            \"-c\",\n            \"({comm})>{path}.stdout 2>{path}.stderr\".format(\n                comm=\" \".join(command),\n                path=lpath)]\n        whole_cmd = [\"systemd-run\"] + opts + bashworkaround\n        comout['command'] = command\n        comout['return_code'] = run_cmd(whole_cmd, **internalkw) or 0\n        if not internal_background:\n            if not self._run_systemdrun_decide():\n                comout['return_code'] = self._systemctl_wait_until_finish(\n                    self.name, unit_name)\n            if self.is_running():\n                self.copy_from(\n                    \"{pin}.stdout\".format(\n                        pin=lpath), \"{pin}.stdout\".format(\n                        pin=lpath))\n                with open(\"{pin}.stdout\".format(pin=lpath)) as f:\n                    comout['stdout'] = f.read()\n                self.copy_from(\n                    \"{pin}.stderr\".format(\n                        pin=lpath), \"{pin}.stderr\".format(\n                        pin=lpath))\n                with open(\"{pin}.stderr\".format(pin=lpath)) as f:\n                    comout['stderr'] = f.read()\n            logger.debug(comout)\n        if not original_ignore_st and comout['return_code'] != 0:\n            raise subprocess.CalledProcessError(comout['command'], comout)\n        if return_full_dict:\n            return comout\n        if original_return_st:\n            return comout['stdout']\n        else:\n            return comout['return_code']", "response": "execute command via systemd - run inside container\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _wait_for_machine_booted(name, suffictinet_texts=None):\n        # TODO: rewrite it using probes module in utils\n        suffictinet_texts = suffictinet_texts or [\"systemd-logind\"]\n        # optionally use: \"Unit: machine\"\n        for foo in range(constants.DEFAULT_RETRYTIMEOUT):\n            time.sleep(constants.DEFAULT_SLEEP)\n            out = run_cmd(\n                [\"machinectl\", \"--no-pager\", \"status\", name],\n                ignore_status=True, return_output=True)\n            for restr in suffictinet_texts:\n                if restr in out:\n                    time.sleep(constants.DEFAULT_SLEEP)\n                    return True\n        raise ConuException(\n            \"Unable to start machine %s within %d (machinectl status command dos not contain %s)\" %\n            (name, constants.DEFAULT_RETRYTIMEOUT, suffictinet_texts))", "response": "Internal method to wait until a machine is ready."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a throw - away container based on provided image and tag run command in it and return output of the container.", "response": "def get_container_output(backend, image_name, command, image_tag=\"latest\",\n                         additional_opts=None):\n    \"\"\"\n    Create a throw-away container based on provided image and tag, run the supplied command in it\n    and return output. The container is stopped and removed after it exits.\n\n    :param backend: instance of DockerBackend\n    :param image_name: str, name of the container image\n    :param command: list of str, command to run in the container\n    :param image_tag: str, container image tag, defaults to \"latest\"\n    :param additional_opts: list of str, by default this function creates the container using\n        docker binary and run command; with this argument you can supply addition options to the\n        \"docker run\" invocation\n    :return: str (unicode), output of the container\n    \"\"\"\n    image = backend.ImageClass(image_name, tag=image_tag)\n    # FIXME: use run_via_api and make this a generic function\n    c = image.run_via_binary(DockerRunBuilder(command=command, additional_opts=additional_opts))\n    try:\n        c.wait()\n        return c.logs_unicode()\n    finally:\n        c.stop()\n        c.wait()\n        c.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the service from the Kubernetes cluster", "response": "def delete(self):\n        \"\"\"\n        delete service from the Kubernetes cluster\n        :return: None\n        \"\"\"\n\n        body = client.V1DeleteOptions()\n\n        try:\n            status = self.api.delete_namespaced_service(self.name, self.namespace, body)\n\n            logger.info(\n                \"Deleting Service %s in namespace: %s\", self.name, self.namespace)\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API - delete_namespaced_service: {}\\n\".format(e))\n\n        if status.status == 'Failure':\n            raise ConuException(\"Deletion of Service failed\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_status(self):\n\n        try:\n            api_response = self.api.read_namespaced_service_status(self.name, self.namespace)\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API - read_namespaced_service_status: %s\\n\" % e)\n\n        return api_response.status", "response": "get status of service"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating this Service in Kubernetes API and return the ID of the created service in the cluster", "response": "def create_in_cluster(self):\n        \"\"\"\n        call Kubernetes API and create this Service in cluster,\n        raise ConuExeption if the API call fails\n        :return: None\n        \"\"\"\n        try:\n            self.api.create_namespaced_service(self.namespace, self.body)\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API - create_namespaced_service: {}\\n\".format(e))\n\n        logger.info(\n            \"Creating Service %s in namespace: %s\", self.name, self.namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npulling this image from the registry. Raises an exception if the image is not found in the registry.", "response": "def pull(self):\n        \"\"\"\n        Pull this image from registry. Raises an exception if the image is not found in\n        the registry.\n\n        :return: None\n        \"\"\"\n        for json_e in self.d.pull(repository=self.name, tag=self.tag, stream=True, decode=True):\n            logger.debug(json_e)\n            status = graceful_get(json_e, \"status\")\n            if status:\n                logger.info(status)\n            else:\n                error = graceful_get(json_e, \"error\")\n                logger.error(status)\n                raise ConuException(\"There was an error while pulling the image %s: %s\",\n                                    self.name, error)\n        self.using_transport(SkopeoTransport.DOCKER_DAEMON)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push(self, repository=None, tag=None):\n\n        image = self\n\n        if repository or tag:\n            image = self.tag_image(repository, tag)\n\n        for json_e in self.d.push(repository=image.name, tag=image.tag, stream=True, decode=True):\n            logger.debug(json_e)\n            status = graceful_get(json_e, \"status\")\n            if status:\n                logger.info(status)\n            else:\n                error = graceful_get(json_e, \"error\")\n                if error is not None:\n                    logger.error(status)\n                    raise ConuException(\"There was an error while pushing the image %s: %s\",\n                                        self.name, error)\n        return image", "response": "Push an image to the registry. Raise exception when push fail."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef using_transport(self, transport=None, path=None, logs=True):\n        if not transport:\n            return self\n\n        if self.transport == transport and self.path == path:\n            return self\n\n        path_required = [SkopeoTransport.DIRECTORY,\n                         SkopeoTransport.DOCKER_ARCHIVE,\n                         SkopeoTransport.OCI]\n\n        if transport in path_required:\n            if not path and logs:\n                logging.debug(\"path not provided, temporary path was used\")\n            self.path = self.mount(path).mount_point\n        elif transport == SkopeoTransport.OSTREE:\n            if path and not os.path.isabs(path):\n                raise ConuException(\"Path '\", path, \"' for OSTree transport is not absolute\")\n            if not path and logs:\n                logging.debug(\"path not provided, default /ostree/repo path was used\")\n            self.path = path\n        else:\n            if path and logs:\n                logging.warning(\"path %s was ignored!\", path)\n            self.path = None\n\n        self.transport = transport\n        return self", "response": "change used transport\n            = 1 return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving this image to another DockerImage", "response": "def save_to(self, image):\n        \"\"\" Save this image to another DockerImage\n\n        :param image: DockerImage\n        :return:\n        \"\"\"\n        if not isinstance(image, self.__class__):\n            raise ConuException(\"Invalid target image type\", type(image))\n        self.copy(image.name, image.tag,\n                  target_transport=image.transport, target_path=image.path,\n                  logs=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload from another DockerImage to this one.", "response": "def load_from(self, image):\n        \"\"\" Load from another DockerImage to this one\n\n        :param image:\n        :return:\n        \"\"\"\n        if not isinstance(image, self.__class__):\n            raise ConuException(\"Invalid source image type\", type(image))\n        image.save_to(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef skopeo_pull(self):\n        return self.copy(self.name, self.tag,\n                         SkopeoTransport.DOCKER, SkopeoTransport.DOCKER_DAEMON)\\\n            .using_transport(SkopeoTransport.DOCKER_DAEMON)", "response": "Pull image from Docker to local Docker daemon using skopeo\n clf."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef skopeo_push(self, repository=None, tag=None):\n        return self.copy(repository, tag, SkopeoTransport.DOCKER_DAEMON, SkopeoTransport.DOCKER)\\\n            .using_transport(SkopeoTransport.DOCKER)", "response": "Push image from Docker daemon to Docker using skopeo\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy this image to another image.", "response": "def copy(self, repository=None, tag=None,\n             source_transport=None,\n             target_transport=SkopeoTransport.DOCKER,\n             source_path=None, target_path=None,\n             logs=True):\n        \"\"\" Copy this image\n\n        :param repository to be copied to\n        :param tag\n        :param source_transport Transport\n        :param target_transport Transport\n        :param source_path needed to specify for dir, docker-archive or oci transport\n        :param target_path needed to specify for dir, docker-archive or oci transport\n        :param logs enable/disable logs\n        :return: the new DockerImage\n        \"\"\"\n        if not repository:\n            repository = self.name\n        if not tag:\n            tag = self.tag if self.tag else \"latest\"\n        if target_transport == SkopeoTransport.OSTREE and tag and logs:\n            logging.warning(\"tag was ignored\")\n        target = (DockerImage(repository, tag, pull_policy=DockerImagePullPolicy.NEVER)\n                  .using_transport(target_transport, target_path))\n        self.using_transport(source_transport, source_path)\n\n        try:\n            run_cmd([\"skopeo\", \"copy\",\n                     transport_param(self),\n                     transport_param(target)])\n        except subprocess.CalledProcessError:\n            raise ConuException(\"There was an error while copying repository\", self.name)\n\n        return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tag_image(self, repository=None, tag=None):\n        if not (repository or tag):\n            raise ValueError(\"You need to specify either repository or tag.\")\n        r = repository or self.name\n        t = \"latest\" if not tag else tag\n        self.d.tag(image=self.get_full_name(), repository=r, tag=t)\n        return DockerImage(r, tag=t)", "response": "Tag the image with the specified tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding metadata about the image ; flip refresh = True update the metadata with up to date content is set to True", "response": "def inspect(self, refresh=True):\n        \"\"\"\n        provide metadata about the image; flip refresh=True if cached metadata are enough\n\n        :param refresh: bool, update the metadata with up to date content\n        :return: dict\n        \"\"\"\n        if refresh or not self._inspect_data:\n            identifier = self._id or self.get_full_name()\n            if not identifier:\n                raise ConuException(\"This image does not have a valid identifier.\")\n            self._inspect_data = self.d.inspect_image(identifier)\n        return self._inspect_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rmi(self, force=False, via_name=False):\n        self.d.remove_image(self.get_full_name() if via_name else self.get_id(), force=force)", "response": "Removes this image from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _run_container(self, run_command_instance, callback):\n        tmpfile = os.path.join(get_backend_tmpdir(), random_tmp_filename())\n        # the cid file must not exist\n        run_command_instance.options += [\"--cidfile=%s\" % tmpfile]\n        logger.debug(\"docker command: %s\" % run_command_instance)\n        response = callback()\n\n        def get_cont_id():\n            if not os.path.exists(tmpfile):\n                return False\n            with open(tmpfile, 'r') as fd:\n                content = fd.read()\n            return bool(content)\n\n        Probe(timeout=2, count=10, pause=0.1, fnc=get_cont_id).run()\n\n        with open(tmpfile, 'r') as fd:\n            container_id = fd.read()\n\n        if not container_id:\n            raise ConuException(\"We could not get container's ID, it probably was not created\")\n        return container_id, response", "response": "this is internal method that runs a container"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_via_binary(self, run_command_instance=None, command=None, volumes=None,\n                       additional_opts=None, **kwargs):\n        \"\"\"\n        create a container using this image and run it in background;\n        this method is useful to test real user scenarios when users invoke containers using\n        binary\n\n        :param run_command_instance: instance of DockerRunBuilder\n        :param command: list of str, command to run in the container, examples:\n            - [\"ls\", \"/\"]\n            - [\"bash\", \"-c\", \"ls / | grep bin\"]\n        :param volumes: tuple or list of tuples in the form:\n\n            * `(\"/path/to/directory\", )`\n            * `(\"/host/path\", \"/container/path\")`\n            * `(\"/host/path\", \"/container/path\", \"mode\")`\n            * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also\n                Directory instance)\n\n        :param additional_opts: list of str, additional options for `docker run`\n        :return: instance of DockerContainer\n        \"\"\"\n\n        logger.info(\"run container via binary in background\")\n\n        if (command is not None or additional_opts is not None) \\\n                and run_command_instance is not None:\n            raise ConuException(\n                \"run_command_instance and command parameters cannot be passed \"\n                \"into method at same time\")\n\n        if run_command_instance is None:\n            command = command or []\n            additional_opts = additional_opts or []\n\n            if (isinstance(command, list) or isinstance(command, tuple) and\n                    isinstance(additional_opts, list) or isinstance(additional_opts, tuple)):\n                run_command_instance = DockerRunBuilder(\n                    command=command, additional_opts=additional_opts)\n            else:\n                raise ConuException(\"command and additional_opts needs to be list of str or None\")\n        else:\n            run_command_instance = run_command_instance or DockerRunBuilder()\n            if not isinstance(run_command_instance, DockerRunBuilder):\n                raise ConuException(\n                    \"run_command_instance needs to be an instance of DockerRunBuilder\")\n\n        run_command_instance.image_name = self.get_id()\n        run_command_instance.options += [\"-d\"]\n\n        if volumes:\n            run_command_instance.options += self.get_volume_options(volumes=volumes)\n\n        def callback():\n            try:\n                # FIXME: catch std{out,err}, print stdout to logger.debug, stderr to logger.error\n                run_cmd(run_command_instance.build())\n            except subprocess.CalledProcessError as ex:\n                raise ConuException(\"Container exited with an error: %s\" % ex.returncode)\n\n        container_id, _ = self._run_container(run_command_instance, callback)\n\n        container_name = self.d.inspect_container(container_id)['Name'][1:]\n        return DockerContainer(self, container_id, name=container_name)", "response": "create a container using this image and run it in background"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a container using this image and run it in foreground; this method is useful to test real user scenarios when users invoke containers using binary and pass input into the container via STDIN. You are also responsible for: * redirecting STDIN when intending to use container.write_to_stdin afterwards by setting popen_params={\"stdin\": subprocess.PIPE} during run_via_binary_in_foreground * checking whether the container exited successfully via: container.popen_instance.returncode Please consult the documentation for subprocess python module for best practices on how you should work with instance of Popen :param run_command_instance: instance of DockerRunBuilder :param command: list of str, command to run in the container, examples: - [\"ls\", \"/\"] - [\"bash\", \"-c\", \"ls / | grep bin\"] :param volumes: tuple or list of tuples in the form: * `(\"/path/to/directory\", )` * `(\"/host/path\", \"/container/path\")` * `(\"/host/path\", \"/container/path\", \"mode\")` * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also Directory instance) :param additional_opts: list of str, additional options for `docker run` :param popen_params: dict, keyword arguments passed to Popen constructor :param container_name: str, pretty container identifier :return: instance of DockerContainer", "response": "def run_via_binary_in_foreground(\n            self, run_command_instance=None, command=None, volumes=None,\n            additional_opts=None, popen_params=None, container_name=None):\n        \"\"\"\n        Create a container using this image and run it in foreground;\n        this method is useful to test real user scenarios when users invoke containers using\n        binary and pass input into the container via STDIN. You are also responsible for:\n\n         * redirecting STDIN when intending to use container.write_to_stdin afterwards by setting\n              popen_params={\"stdin\": subprocess.PIPE} during run_via_binary_in_foreground\n\n         * checking whether the container exited successfully via:\n              container.popen_instance.returncode\n\n        Please consult the documentation for subprocess python module for best practices on\n        how you should work with instance of Popen\n\n        :param run_command_instance: instance of DockerRunBuilder\n        :param command: list of str, command to run in the container, examples:\n            - [\"ls\", \"/\"]\n            - [\"bash\", \"-c\", \"ls / | grep bin\"]\n        :param volumes: tuple or list of tuples in the form:\n\n            * `(\"/path/to/directory\", )`\n            * `(\"/host/path\", \"/container/path\")`\n            * `(\"/host/path\", \"/container/path\", \"mode\")`\n            * `(conu.Directory('/host/path'), \"/container/path\")` (source can be also\n                Directory instance)\n\n        :param additional_opts: list of str, additional options for `docker run`\n        :param popen_params: dict, keyword arguments passed to Popen constructor\n        :param container_name: str, pretty container identifier\n        :return: instance of DockerContainer\n        \"\"\"\n        logger.info(\"run container via binary in foreground\")\n\n        if (command is not None or additional_opts is not None) \\\n                and run_command_instance is not None:\n            raise ConuException(\n                \"run_command_instance and command parameters cannot be \"\n                \"passed into method at same time\")\n\n        if run_command_instance is None:\n            command = command or []\n            additional_opts = additional_opts or []\n\n            if (isinstance(command, list) or isinstance(command, tuple) and\n                    isinstance(additional_opts, list) or isinstance(additional_opts, tuple)):\n                run_command_instance = DockerRunBuilder(\n                    command=command, additional_opts=additional_opts)\n            else:\n                raise ConuException(\"command and additional_opts needs to be list of str or None\")\n        else:\n            run_command_instance = run_command_instance or DockerRunBuilder()\n            if not isinstance(run_command_instance, DockerRunBuilder):\n                raise ConuException(\"run_command_instance needs to be an \"\n                                    \"instance of DockerRunBuilder\")\n\n        popen_params = popen_params or {}\n\n        run_command_instance.image_name = self.get_id()\n        if container_name:\n            run_command_instance.options += [\"--name\", container_name]\n\n        if volumes:\n            run_command_instance.options += self.get_volume_options(volumes=volumes)\n\n        def callback():\n            return subprocess.Popen(run_command_instance.build(), **popen_params)\n\n        container_id, popen_instance = self._run_container(run_command_instance, callback)\n\n        actual_name = self.d.inspect_container(container_id)['Name'][1:]\n        if container_name and container_name != actual_name:\n            raise ConuException(\n                \"Unexpected container name value. Expected = \"\n                + str(container_name) + \" Actual = \" + str(actual_name))\n        if not container_name:\n            container_name = actual_name\n        return DockerContainer(\n            self, container_id, popen_instance=popen_instance, name=container_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_via_api(self, container_params=None):\n\n        if not container_params:\n            container_params = DockerContainerParameters()\n\n        # Host-specific configuration\n        host_config = self.d.create_host_config(auto_remove=container_params.remove,\n                                                cap_add=container_params.cap_add,\n                                                cap_drop=container_params.cap_drop,\n                                                devices=container_params.devices,\n                                                dns=container_params.dns,\n                                                group_add=container_params.group_add,\n                                                init=container_params.init,\n                                                ipc_mode=container_params.ipc_mode,\n                                                isolation=container_params.isolation,\n                                                mem_limit=container_params.mem_limit,\n                                                mounts=container_params.mounts,\n                                                pids_limit=container_params.pids_limit,\n                                                privileged=container_params.privileged,\n                                                publish_all_ports=container_params.publish_all_ports,\n                                                port_bindings=container_params.port_mappings,\n                                                read_only=container_params.read_only)\n\n        container = self.d.create_container(self.get_id(), command=container_params.command,\n                                            detach=True,\n                                            hostname=container_params.hostname,\n                                            user=container_params.user,\n                                            stdin_open=container_params.stdin_open,\n                                            tty=container_params.tty,\n                                            ports=container_params.exposed_ports,\n                                            environment=container_params.env_variables,\n                                            volumes=container_params.volumes,\n                                            name=container_params.name,\n                                            entrypoint=container_params.entrypoint,\n                                            working_dir=container_params.working_dir,\n                                            host_config=host_config,\n                                            mac_address=container_params.mac_address,\n                                            labels=container_params.labels,\n                                            stop_signal=container_params.stop_signal,\n                                            healthcheck=container_params.healthcheck,\n                                            runtime=container_params.runtime)\n\n        return DockerContainer(self, container['Id'], name=container_params.name)", "response": "Create a container using this image and run it in background via Docker - py API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun image inside Kubernetes Pod", "response": "def run_in_pod(self, namespace=\"default\"):\n        \"\"\"\n        run image inside Kubernetes Pod\n        :param namespace: str, name of namespace where pod will be created\n        :return: Pod instance\n        \"\"\"\n\n        core_api = get_core_api()\n\n        image_data = self.get_metadata()\n\n        pod = Pod.create(image_data)\n\n        try:\n            pod_instance = core_api.create_namespaced_pod(namespace=namespace, body=pod)\n        except ApiException as e:\n            raise ConuException(\"Exception when calling CoreV1Api->create_namespaced_pod: %s\\n\" % e)\n\n        logger.info(\n            \"Starting Pod %s in namespace %s\" % (pod_instance.metadata.name, namespace))\n\n        return Pod(name=pod_instance.metadata.name,\n                   namespace=pod_instance.metadata.namespace,\n                   spec=pod_instance.spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_pkgs_signed_with(self, allowed_keys):\n\n        if not allowed_keys or not isinstance(allowed_keys, list):\n            raise ConuException(\"allowed_keys must be a list\")\n        command = ['rpm', '-qa', '--qf', '%{name} %{SIGPGP:pgpsig}\\n']\n        cont = self.run_via_binary(command=command)\n        try:\n            out = cont.logs_unicode()[:-1].split('\\n')\n            check_signatures(out, allowed_keys)\n        finally:\n            cont.stop()\n            cont.delete()\n        return True", "response": "Check if all packages in image are signed with one of allowed_keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the image from the provided Dockerfile in path and return the instance of DockerImage", "response": "def build(cls, path, tag=None, dockerfile=None):\n        \"\"\"\n        Build the image from the provided dockerfile in path\n\n        :param path : str, path to the directory containing the Dockerfile\n        :param tag: str, A tag to add to the final image\n        :param dockerfile: str, path within the build context to the Dockerfile\n        :return: instance of DockerImage\n        \"\"\"\n        if not path:\n            raise ConuException('Please specify path to the directory containing the Dockerfile')\n        client = get_client()\n        response = [line for line in client.build(path,\n                                                  rm=True, tag=tag,\n                                                  dockerfile=dockerfile,\n                                                  quiet=True)]\n        if not response:\n            raise ConuException('Failed to get ID of image')\n\n        # The expected output is just one line with image ID\n        if len(response) > 1:\n            raise ConuException('Build failed: ' + str(response))\n\n        # get ID from output\n        # b'{\"stream\":\"sha256:39c7bac4e2da37983203df4fcf612a02de9e6f6456a7f3434d1fccbc9ad639a5\\\\n\"}\\r\\n'\n        response_utf = response[0].decode('utf-8')\n        if response_utf[:11] != '{\"stream\":\"' or response_utf[-6:] != '\\\\n\"}\\r\\n':\n            raise ConuException('Failed to parse ID from ' + response_utf)\n        image_id = response_utf[11:-6]\n\n        return cls(None, identifier=image_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_layer_ids(self, rev=True):\n        layers = [x['Id'] for x in self.d.history(self.get_id())]\n        if not rev:\n            layers.reverse()\n        return layers", "response": "Get IDs of image layers in order of their name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef layers(self, rev=True):\n        image_layers = [\n            DockerImage(None, identifier=x, pull_policy=DockerImagePullPolicy.NEVER)\n            for x in self.get_layer_ids()\n        ]\n        if not rev:\n            image_layers.reverse()\n        return image_layers", "response": "Get list of DockerImage for every layer in image\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextending this s2i - enabled image using provided source", "response": "def extend(self, source, new_image_name, s2i_args=None):\n        \"\"\"\n        extend this s2i-enabled image using provided source, raises ConuException if\n        `s2i build` fails\n\n        :param source: str, source used to extend the image, can be path or url\n        :param new_image_name: str, name of the new, extended image\n        :param s2i_args: list of str, additional options and arguments provided to `s2i build`\n        :return: S2Image instance\n        \"\"\"\n        s2i_args = s2i_args or []\n        c = self._s2i_command([\"build\"] + s2i_args + [source, self.get_full_name()])\n        if new_image_name:\n            c.append(new_image_name)\n        try:\n            run_cmd(c)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"s2i build failed: %s\" % ex)\n        return S2IDockerImage(new_image_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef usage(self):\n        c = self._s2i_command([\"usage\", self.get_full_name()])\n        with open(os.devnull, \"w\") as fd:\n            process = subprocess.Popen(c, stdout=fd, stderr=subprocess.PIPE)\n            _, output = process.communicate()\n            retcode = process.poll()\n        if retcode:\n            raise ConuException(\"`s2i usage` failed: %s\" % output)\n        return output.decode(\"utf-8\").strip()", "response": "Provide output of s2i usage"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef http_request(self, path=\"/\", method=\"GET\", host=None, port=None, json=False, data=None):\n\n        host = host or '127.0.0.1'\n        port = port or 8080\n        url = get_url(host=host, port=port, path=path)\n\n        return self.http_session.request(method, url, json=json, data=data)", "response": "Perform a HTTP request to the cache store"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deploy_image(self, image_name, oc_new_app_args=None, project=None, name=None):\n        self.project = project or self.get_current_project()\n\n        # app name is generated randomly\n        name = name or 'app-{random_string}'.format(random_string=random_str(5))\n\n        oc_new_app_args = oc_new_app_args or []\n\n        new_image = self.import_image(image_name.split('/')[-1], image_name)\n\n        c = self._oc_command(\n            [\"new-app\"] + oc_new_app_args + [new_image] +\n            [\"-n\"] + [project] + [\"--name=%s\" % name])\n\n        logger.info(\"Creating new app in project %s\", project)\n\n        try:\n            run_cmd(c)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"oc new-app failed: %s\" % ex)\n\n        return name", "response": "Deploy an image in OpenShift cluster using oc new - app"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeploying app using source - to - image in OpenShift cluster using oc new - app", "response": "def create_new_app_from_source(self, image_name, project=None,\n                                   source=None, oc_new_app_args=None):\n        \"\"\"\n        Deploy app using source-to-image in OpenShift cluster using 'oc new-app'\n        :param image_name: image to be used as builder image\n        :param project: project where app should be created, default: current project\n        :param source: source used to extend the image, can be path or url\n        :param oc_new_app_args: additional parameters for the `oc new-app`\n        :return: str, name of the app\n        \"\"\"\n        self.project = project or self.get_current_project()\n\n        # app name is generated randomly\n        name = 'app-{random_string}'.format(random_string=random_str(5))\n\n        oc_new_app_args = oc_new_app_args or []\n\n        new_image = self.import_image(image_name.split('/')[-1], image_name)\n\n        c = self._oc_command(\n            [\"new-app\"] + [new_image + \"~\" + source] + oc_new_app_args\n            + [\"-n\"] + [project] + [\"--name=%s\" % name])\n\n        logger.info(\"Creating new app in project %s\", project)\n\n        try:\n            o = run_cmd(c, return_output=True)\n            logger.debug(o)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"oc new-app failed: %s\" % ex)\n\n        # build from local source\n        if os.path.isdir(source):\n            self.start_build(name, [\"-n\", project, \"--from-dir=%s\" % source])\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_build(self, build, args=None):\n\n        args = args or []\n\n        c = self._oc_command([\"start-build\"] + [build] + args)\n\n        logger.info(\"Executing build %s\", build)\n        logger.info(\"Build command: %s\", \" \".join(c))\n\n        try:\n            Probe(timeout=-1, pause=5, count=2, expected_exceptions=subprocess.CalledProcessError,\n                  expected_retval=None, fnc=run_cmd, cmd=c).run()\n        except ProbeTimeout as e:\n            raise ConuException(\"Cannot start build of application: %s\" % e)", "response": "Start new build, raise exception if build failed\n        :param build: str, name of the build\n        :param args: list of str, another args of 'oc start-build' commands\n        :return: None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_image_registry_url(self, image_name):\n        c = self._oc_command([\"get\", \"is\", image_name,\n                              \"--output=jsonpath=\\'{ .status.dockerImageRepository }\\'\"])\n        try:\n            internal_registry_name = run_cmd(c, return_output=True)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"oc get is failed: %s\" % ex)\n\n        logger.info(\"Image registry url: %s\", internal_registry_name)\n\n        return internal_registry_name.replace(\"'\", \"\").replace('\"', '')", "response": "Helper function for obtain registry url of an image from it s name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports an image from an openshift registry and return the short name of the image in the internal registry.", "response": "def import_image(self, imported_image_name, image_name):\n        \"\"\"\n        Import image using `oc import-image` command.\n        :param imported_image_name: str, short name of an image in internal registry, example:\n            - hello-openshift:latest\n        :param image_name: full repository name, example:\n            - docker.io/openshift/hello-openshift:latest\n        :return: str, short name in internal registry\n        \"\"\"\n\n        c = self._oc_command([\"import-image\", imported_image_name,\n                              \"--from=%s\" % image_name, \"--confirm\"])\n\n        logger.info(\"Importing image from: %s, as: %s\", image_name, imported_image_name)\n\n        try:\n            o = run_cmd(c, return_output=True, ignore_status=True)\n            logger.debug(o)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"oc import-image failed: %s\" % ex)\n\n        return imported_image_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests a service from the server.", "response": "def request_service(self, app_name, port, expected_output=None):\n        \"\"\"\n        Make request on service of app. If there is connection error function return False.\n        :param app_name: str, name of the app\n        :param expected_output: str, If not None method will check output returned from request\n               and try to find matching string.\n        :param port: str or int, port of the service\n        :return: bool, True if connection was established False if there was connection error\n        \"\"\"\n\n        # get ip of service\n        ip = [service.get_ip() for service in self.list_services(namespace=self.project)\n              if service.name == app_name][0]\n\n        # make http request to obtain output\n        if expected_output is not None:\n            try:\n                output = self.http_request(host=ip, port=port)\n                if expected_output not in output.text:\n                    raise ConuException(\n                        \"Connection to service established, but didn't match expected output\")\n                else:\n                    logger.info(\"Connection to service established and return expected output!\")\n                    return True\n            except ConnectionError as e:\n                logger.info(\"Connection to service failed %s!\", e)\n                return False\n        elif check_port(port, host=ip):  # check if port is open\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_for_service(self, app_name, port, expected_output=None, timeout=100):\n        logger.info('Waiting for service to get ready')\n        try:\n\n            Probe(timeout=timeout, pause=10, fnc=self.request_service, app_name=app_name,\n                  port=port, expected_output=expected_output, expected_retval=True).run()\n        except ProbeTimeout:\n            logger.warning(\"Timeout: Request to service unsuccessful.\")\n            raise ConuException(\"Timeout: Request to service unsuccessful.\")", "response": "Block until service is ready to accept requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_pods_are_ready(self, app_name):\n        app_pod_exists = False\n        for pod in self.list_pods(namespace=self.project):\n            if app_name in pod.name and 'build' not in pod.name and 'deploy' not in pod.name:\n                app_pod_exists = True\n                if not pod.is_ready():\n                    return False\n        if app_pod_exists:\n            logger.info(\"All pods are ready!\")\n            return True\n\n        return False", "response": "Check if all pods are ready for specific app_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets status of OpenShift cluster similar to oc status", "response": "def get_status(self):\n        \"\"\"\n        Get status of OpenShift cluster, similar to `oc status`\n        :return: str\n        \"\"\"\n        try:\n            c = self._oc_command([\"status\"])\n            o = run_cmd(c, return_output=True)\n            for line in o.split('\\n'):\n                logger.debug(line)\n            return o\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"Cannot obtain OpenShift cluster status: %s\" % ex)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all logs related to a given app", "response": "def get_logs(self, name):\n        \"\"\"\n        Obtain cluster status and logs from all pods and print them using logger.\n        This method is useful for debugging.\n        :param name: str, name of app generated by oc new-app\n        :return: str, cluster status and logs from all pods\n        \"\"\"\n        logs = self.get_status()\n\n        for pod in self.list_pods(namespace=self.project):\n            if name in pod.name:  # get just logs from pods related to app\n                pod_logs = pod.get_logs()\n                if pod_logs:\n                    logs += pod_logs\n\n        return logs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_project(self):\n\n        try:\n            command = self._oc_command([\"project\", \"-q\"])\n            output = run_cmd(command, return_output=True)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"Failed to obtain current project name : %s\" % ex)\n\n        try:\n            return output.rstrip()  # remove '\\n'\n        except IndexError:\n            raise ConuException(\"Failed to obtain project name\")", "response": "Get name of current project using oc project - q command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes objects in current project in OpenShift cluster.", "response": "def clean_project(self, app_name=None, delete_all=False):\n        \"\"\"\n        Delete objects in current project in OpenShift cluster. If both parameters are passed,\n        delete all objects in project.\n        :param app_name: str, name of app\n        :param delete_all: bool, if true delete all objects in current project\n        :return: None\n        \"\"\"\n\n        if not app_name and not delete_all:\n            ConuException(\"You need to specify either app_name or set delete_all=True\")\n\n        if delete_all:\n            args = [\"--all\"]\n            logger.info('Deleting all objects in current project')\n        else:\n            args = \"-l app=%s\" % app_name\n            logger.info('Deleting all objects with label app=%s', app_name)\n\n        try:\n            o = run_cmd(self._oc_command([\"delete\", \"all\", args]),\n                        return_output=True)\n            o_lines = o.split('\\n')\n            for line in o_lines:\n                logger.info(line)\n        except subprocess.CalledProcessError as ex:\n            raise ConuException(\"Cleanup failed because of exception: %s\" % ex)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef system_requirements():\n        command_exists(\"systemd-nspawn\",\n            [\"systemd-nspawn\", \"--version\"],\n            \"Command systemd-nspawn does not seems to be present on your system\"\n            \"Do you have system with systemd\")\n        command_exists(\n            \"machinectl\",\n            [\"machinectl\", \"--no-pager\", \"--help\"],\n            \"Command machinectl does not seems to be present on your system\"\n            \"Do you have system with systemd\")\n        if \"Enforcing\" in run_cmd([\"getenforce\"], return_output=True, ignore_status=True):\n            logger.error(\"Please disable selinux (setenforce 0), selinux blocks some nspawn operations\"\n                         \"This may lead to strange behaviour\")", "response": "Check if all necessary packages are installed on system"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new unique identifier", "response": "def _generate_id(self):\n        \"\"\" create new unique identifier \"\"\"\n        name = self.name.replace(self.special_separator, \"-\").replace(\".\", \"-\")\n        loc = \"\\/\"\n        if self.location:\n            loc = self.location\n        _id = \"{PREFIX}{SEP}{NAME}{HASH}{SEP}\".format(\n            PREFIX=constants.CONU_ARTIFACT_TAG,\n            NAME=name,\n            HASH=hashlib.sha512(loc).hexdigest()[: 10],\n            SEP=self.special_separator\n        )\n        return _id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npulling this image from URL.", "response": "def pull(self):\n        \"\"\"\n        Pull this image from URL.\n\n        :return: None\n        \"\"\"\n        if not os.path.exists(CONU_IMAGES_STORE):\n            os.makedirs(CONU_IMAGES_STORE)\n        logger.debug(\n            \"Try to pull: {} -> {}\".format(self.location, self.local_location))\n\n        if not self._is_local():\n            compressed_location = self.local_location + \".xz\"\n            run_cmd([\"curl\", \"-f\", \"-L\", \"-o\", compressed_location, self.location])\n            run_cmd([\"xz\", \"-d\", compressed_location])\n        else:\n            if self.location.endswith(\"xz\"):\n                compressed_location = self.local_location + \".xz\"\n                run_cmd([\"cp\", self.location, compressed_location])\n                run_cmd([\"xz\", \"-d\", compressed_location])\n            else:\n                run_cmd([\"cp\", self.location, self.local_location])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a snapshot of the image with the given name and tag.", "response": "def create_snapshot(self, name, tag):\n        \"\"\"\n        Create new instance of image with snaphot image (it is copied inside class constructuor)\n\n        :param name: str - name of image - not used now\n        :param tag: str - tag for image\n        :return: NspawnImage instance\n        \"\"\"\n        source = self.local_location\n        logger.debug(\"Create Snapshot: %s -> %s\" % (source, name))\n        # FIXME: actually create the snapshot via clone command\n        if name and tag:\n            output_tag = \"{}:{}\".format(name, tag)\n        else:\n            output_tag = name or tag\n        return self.__class__(repository=source, tag=output_tag)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the metadata of the current image", "response": "def get_metadata(self, refresh=True):\n        \"\"\"\n        return cached metadata by default\n\n        :param refresh: bool, update the metadata with up to date content\n        :return: dict\n        \"\"\"\n        if refresh or not self._metadata:\n            ident = self._id or self.get_full_name()\n            if not ident:\n                raise ConuException(\n                    \"This image does not have a valid identifier.\")\n            self._metadata = dict()\n        return self._metadata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the image from the cache", "response": "def rmi(self, force=False, via_name=False):\n        \"\"\"\n        remove this image\n\n        :param force: bool, force removal of the image\n        :param via_name: bool, refer to the image via name, if false, refer via ID, not used now\n        :return: None\n        \"\"\"\n        return os.remove(self.local_location)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _wait_for_machine_finish(self, name):\n        # TODO: rewrite it using probes module in utils\n        for foo in range(constants.DEFAULT_RETRYTIMEOUT):\n            time.sleep(constants.DEFAULT_SLEEP)\n            out = run_cmd(\n                [\"machinectl\", \"--no-pager\", \"status\", name],\n                ignore_status=True, return_output=True)\n            if out != 0:\n                return True\n        raise ConuException(\n            \"Unable to stop machine %s within %d\" %\n            (name, constants.DEFAULT_RETRYTIMEOUT))", "response": "Internal method to wait until a machine is really destroyed or an exception occurs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a container via systemd - nspawn", "response": "def run_via_binary(self, command=None, foreground=False, volumes=None,\n            additional_opts=None, default_options=None, name=None, *args, **kwargs):\n        \"\"\"\n        Create new instance NspawnContianer in case of not running at foreground, in case foreground run, return process\n        object\n\n        :param command: list - command to run\n        :param foreground: bool - run process at foreground\n        :param volumes: list - put additional bind mounts\n        :param additional_opts: list of more boot options for systemd-nspawn command\n        :param default_options: default boot option (-b)\n        :param name: str - name of running instance\n        :param args: pass thru params to subprocess.Popen\n        :param kwargs: pass thru params to subprocess.Popen\n        :return: process or NspawnContianer instance\n        \"\"\"\n        command = deepcopy(command) or []\n        volumes = deepcopy(volumes) or []\n        additional_opts = deepcopy(additional_opts) or []\n        internalkw = deepcopy(kwargs) or {}\n        inernalargs = deepcopy(args) or []\n        if default_options is None:\n            default_options = [\"-b\"]\n        # TODO: reconsile parameters (changed from API definition)\n        logger.info(\"run container via binary in background\")\n        machine_name = constants.CONU_ARTIFACT_TAG\n        if name:\n            machine_name += name\n        else:\n            machine_name += random_str()\n\n        if not foreground:\n            # WARN: avoid to run boot without stderr and stdout to terminal, it breaks terminal,\n            # it systemd-nspawn does some magic with console\n            # TODO: is able to avoid this behaviour in better way?\n            internalkw[\"stdout\"] = subprocess.PIPE\n            internalkw[\"stderr\"] = subprocess.PIPE\n        additional_opts += default_options\n        if volumes:\n            additional_opts += self.get_volume_options(volumes=volumes)\n        logger.debug(\"starting NSPAWN\")\n        systemd_command = [\n            \"systemd-nspawn\",\n            \"--machine\",\n            machine_name,\n            \"-i\",\n            self.local_location] + additional_opts + command\n        logger.debug(\"Start command: %s\" % \" \".join(systemd_command))\n        callback_method = (subprocess.Popen, systemd_command, inernalargs, internalkw)\n        self.container_process = NspawnContainer.internal_run_container(\n            name=machine_name,\n            callback_method=callback_method,\n            foreground=foreground\n        )\n        if foreground:\n            return self.container_process\n        else:\n            return NspawnContainer(self, None, name=machine_name,\n                                   start_process=self.container_process, start_action=callback_method)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the process at foreground.", "response": "def run_foreground(self, *args, **kwargs):\n        \"\"\"\n        Force to run process at foreground\n        :param args: pass args to run command\n        :param kwargs: pass args to run command\n        :return:  process or NspawnContianer instance\n        \"\"\"\n        return self.run_via_binary(foreground=True, default_options=[], *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bootstrap(\n            repositories, name, packages=None, additional_packages=None,\n            tag=\"latest\", prefix=constants.CONU_ARTIFACT_TAG, packager=None):\n        \"\"\"\n        bootstrap Image from scratch. It creates new image based on giver dnf repositories and package setts\n\n        :param repositories:list of repositories\n        :param packages: list of base packages in case you don't want to use base packages defined in contants\n        :param additional_packages: list of additonal packages\n        :param tag: tag the output image\n        :param prefix: use some prefix for newly cretaed image (internal usage)\n        :param packager: use another packages in case you dont want to use defined in constants (dnf)\n        :return: NspawnImage instance\n        \"\"\"\n        additional_packages = additional_packages or []\n        if packages is None:\n            packages = constants.CONU_NSPAWN_BASEPACKAGES\n        package_set = packages + additional_packages\n        if packager is None:\n            packager = constants.BOOTSTRAP_PACKAGER\n        mounted_dir = mkdtemp()\n        if not os.path.exists(mounted_dir):\n            os.makedirs(mounted_dir)\n        imdescriptor, tempimagefile = mkstemp()\n        image_size = constants.BOOTSTRAP_IMAGE_SIZE_IN_MB\n        # create no partitions when create own image\n        run_cmd([\"dd\", \"if=/dev/zero\", \"of={}\".format(tempimagefile),\n                 \"bs=1M\", \"count=1\", \"seek={}\".format(image_size)])\n        run_cmd([constants.BOOTSTRAP_FS_UTIL, tempimagefile])\n        # TODO: is there possible to use NspawnImageFS class instead of direct\n        # mount/umount, image objects does not exist\n        run_cmd([\"mount\", tempimagefile, mounted_dir])\n        if os.path.exists(os.path.join(mounted_dir, \"usr\")):\n            raise ConuException(\"Directory %s already in use\" % mounted_dir)\n        if not os.path.exists(mounted_dir):\n            os.makedirs(mounted_dir)\n        repo_params = []\n        repo_file_content = \"\"\n        for cnt in range(len(repositories)):\n            repo_params += [\"--repofrompath\",\n                            \"{0}{1},{2}\".format(prefix, cnt, repositories[cnt])]\n            repo_file_content += \"\"\"\n[{NAME}{CNT}]\nname={NAME}{CNT}\nbaseurl={REPO}\nenabled=1\ngpgcheck=0\n\"\"\".format(NAME=prefix, CNT=cnt, REPO=repositories[cnt])\n        packages += set(additional_packages)\n        logger.debug(\"Install system to direcory: %s\" % mounted_dir)\n        logger.debug(\"Install packages: %s\" % packages)\n        logger.debug(\"Repositories: %s\" % repositories)\n        packager_addition = [\n            \"--installroot\",\n            mounted_dir,\n            \"--disablerepo\",\n            \"*\",\n            \"--enablerepo\",\n            prefix + \"*\"]\n        final_command = packager + packager_addition + repo_params + package_set\n        try:\n            run_cmd(final_command)\n        except Exception as e:\n            raise ConuException(\"Unable to install packages via command: {} (original exception {})\".format(final_command, e))\n        insiderepopath = os.path.join(\n            mounted_dir,\n            \"etc\",\n            \"yum.repos.d\",\n            \"{}.repo\".format(prefix))\n        if not os.path.exists(os.path.dirname(insiderepopath)):\n            os.makedirs(os.path.dirname(insiderepopath))\n        with open(insiderepopath, 'w') as f:\n            f.write(repo_file_content)\n        run_cmd([\"umount\", mounted_dir])\n        # add sleep before umount, to ensure, that kernel finish ops\n        time.sleep(constants.DEFAULT_SLEEP)\n        nspawnimage = NspawnImage(repository=name, location=tempimagefile, tag=tag)\n        os.remove(tempimagefile)\n        os.rmdir(mounted_dir)\n        return nspawnimage", "response": "This function creates a new NspawnImage instance based on the given repositories and packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_rpm_ql_line(line_str, allowed_keys):\n    try:\n        name, key_str = line_str.split(' ', 1)\n    except ValueError:\n        logger.error(\"Failed to split line '{0}\".format(repr(line_str)))\n        return False\n    if name in no_key_pkgs:\n        return True\n    if key_str == NONE_KEY:\n        logger.error(\"Unsigned package {0}\".format(name))\n        return False\n    key_match = re.match(KEY, key_str)\n    if not key_match:\n        logger.error('Could not process line \"{0}\"'.format(line_str))\n        return False\n    used_key = key_match.group(1)\n    if used_key in allowed_keys:\n        return True\n    logger.error(\"Wrong key for '{0}' ({1})\".format(name, used_key))\n    return False", "response": "Checks single line of rpm - ql for correct keys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if all of the packages with signatures are properly signed by the rpm_ql file", "response": "def check_signatures(pkg_list, allowed_keys):\n    \"\"\"\n    Go through list of packages with signatures and check if all are properly signed\n\n    :param pkg_list: list of packages in format '%{name} %{SIGPGP:pgpsig}'\n    :param allowed_keys: list of allowed keys\n    :return: bool\n    \"\"\"\n    all_passed = True\n    for line_str in pkg_list:\n        all_passed &= process_rpm_ql_line(line_str.strip(), allowed_keys)\n\n    if not all_passed:\n        raise PackageSignatureException(\n            'Error while checking rpm signatures, see logs for more info')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_parameters(self):\n        import argparse\n        parser = argparse.ArgumentParser(add_help=False)\n\n        # without parameter\n        parser.add_argument(\"-i\", \"--interactive\", action=\"store_true\", dest=\"stdin_open\")\n        parser.add_argument(\"-d\", \"--detach\", action=\"store_true\", dest=\"detach\")\n        parser.add_argument(\"-t\", \"--tty\", action=\"store_true\", dest=\"tty\")\n        parser.add_argument(\"--init\", action=\"store_true\", dest=\"init\")\n        parser.add_argument(\"--privileged\", action=\"store_true\", dest=\"privileged\")\n        parser.add_argument(\"-P\", \"--publish-all\", action=\"store_true\", dest=\"publish_all_ports\")\n        parser.add_argument(\"--read-only\", action=\"store_true\", dest=\"read_only\")\n        parser.add_argument(\"--rm\", action=\"store_true\", dest=\"remove\")\n\n        # string parameter\n        parser.add_argument(\"--entrypoint\", action=\"store\", dest=\"entrypoint\")\n        parser.add_argument(\"-h\", \"--hostname\", action=\"store\", dest=\"hostname\")\n        parser.add_argument(\"--name\", action=\"store\", dest=\"name\")\n        parser.add_argument(\"--ipc\", action=\"store\", dest=\"ipc_mode\")\n        parser.add_argument(\"--isolation\", action=\"store\", dest=\"isolation\")\n        parser.add_argument(\"--mac-address\", action=\"store\", dest=\"mac_address\")\n        parser.add_argument(\"-m\", \"--memory\", action=\"store\", dest=\"mem_limit\")\n        parser.add_argument(\"--network\", action=\"store\", dest=\"network\")\n        parser.add_argument(\"--platform\", action=\"store\", dest=\"platform\")\n        parser.add_argument(\"--runtime\", action=\"store\", dest=\"runtime\")\n        parser.add_argument(\"--stop-signal\", action=\"store\", dest=\"stop_signal\")\n        parser.add_argument(\"-u\", \"--user\", action=\"store\", dest=\"user\")\n        parser.add_argument(\"-w\", \"--workdir\", action=\"store\", dest=\"working_dir\")\n\n        # int parameter\n        parser.add_argument(\"--pids-limit\", action=\"store\", dest=\"pids_limit\", type=int)\n\n        # list parameter\n        parser.add_argument(\"-e\", \"--env\", action=\"append\", dest=\"env_variables\")\n        parser.add_argument(\"--cap-add\", action=\"append\", dest=\"cap_add\")\n        parser.add_argument(\"--cap-drop\", action=\"append\", dest=\"cap_drop\")\n        parser.add_argument(\"--device\", action=\"append\", dest=\"devices\")\n        parser.add_argument(\"--dns\", action=\"append\", dest=\"dns\")\n        parser.add_argument(\"--group-add\", action=\"append\", dest=\"group_add\")\n        parser.add_argument(\"--mount\", action=\"append\", dest=\"mounts\")\n        parser.add_argument(\"-v\", \"--volume\", action=\"append\", dest=\"volumes\")\n\n        # dict parameter\n        parser.add_argument(\"-l\", \"--label\", action=\"append\", dest=\"labels\")\n        parser.add_argument(\"-p\", \"--publish\", action=\"append\", dest=\"port_mappings\")\n\n        # health\n        parser.add_argument(\"--health-cmd\", action=\"store\", dest=\"health_cmd\")\n        parser.add_argument(\"--health-interval\", action=\"store\", dest=\"health_interval\", type=int)\n        parser.add_argument(\"--health-retries\", action=\"store\", dest=\"health_retries\", type=int)\n        parser.add_argument(\"--health-timeout\", action=\"store\", dest=\"health_timeout\", type=int)\n        parser.add_argument(\"--no-healthcheck\", action=\"store_true\", dest=\"no_healthcheck\")\n\n        args, _ = parser.parse_known_args(args=self.options)\n        command = self.arguments\n\n        options_dict = vars(args)\n\n        # create Healthcheck object\n        if not options_dict.pop(\"no_healthcheck\", None):\n            options_dict[\"healthcheck\"] = Healthcheck(\n                test=options_dict.pop(\"health_cmd\", None),\n                interval=options_dict.pop(\"health_interval\", None),\n                timeout=options_dict.pop(\"health_timeout\", None),\n                retries=options_dict.pop(\"health_retries\", None)\n            )\n        else:\n            options_dict['healthcheck'] = None\n\n        # parse dictionary\n        # {'name': 'separator'}\n        with_dictionary_parameter = {'labels': '='}\n        for name, separator in with_dictionary_parameter.items():\n            if options_dict[name] is not None:\n                dictionary = {}\n                for item in options_dict[name]:\n                    try:\n                        key, value = item.split(separator)\n                        dictionary[key] = value\n                    except ValueError:\n                        dictionary = options_dict[name]\n                        raise ConuException('Wrong format of dictionary: {name}'.format(name=name))\n                        break\n                options_dict[name] = dictionary\n\n        # parse ports\n        # create dictionary according to https://docker-py.readthedocs.io/en/stable/containers.html\n        if options_dict['port_mappings'] is not None:\n            dictionary = {}\n            for port_string in options_dict['port_mappings']:\n                colon_count = port_string.count(':')\n                if colon_count == 2:\n                    split_array = port_string.split(':')\n                    if split_array[1] == '':\n                        # format - ip::containerPort\n                        # create dictionary - {'1111/tcp': ('127.0.0.1', None)}\n                        dictionary[split_array[2]] = (split_array[0], None)\n                    else:\n                        # format - ip:hostPort:containerPort\n                        # create dictionary - {'1111/tcp': ('127.0.0.1', 1111)}\n                        dictionary[split_array[2]] = (split_array[0], int(split_array[1]))\n                elif colon_count == 1:\n                    # format - hostPort:containerPort\n                    # create dictionary - {'2222/tcp': 3333}\n                    split_array = port_string.split(':')\n                    dictionary[split_array[1]] = int(split_array[0])\n                elif colon_count == 0:\n                    # format - containerPort\n                    # create dictionary - {'2222/tcp': None}\n                    dictionary[port_string] = None\n                else:\n                    raise ConuException('Wrong format of port mappings')\n\n            options_dict['port_mappings'] = dictionary\n\n        container_parameters = DockerContainerParameters(cap_add=options_dict['cap_add'],\n                                                         cap_drop=options_dict['cap_drop'],\n                                                         command=command, detach=options_dict['detach'],\n                                                         devices=options_dict['devices'], dns=options_dict['dns'],\n                                                         entrypoint=options_dict['entrypoint'],\n                                                         env_variables=options_dict['env_variables'],\n                                                         group_add=options_dict['group_add'],\n                                                         healthcheck=options_dict['healthcheck'],\n                                                         hostname=options_dict['hostname'],\n                                                         init=options_dict['init'],\n                                                         ipc_mode=options_dict['ipc_mode'],\n                                                         isolation=options_dict['isolation'],\n                                                         labels=options_dict['labels'],\n                                                         mac_address=options_dict['mac_address'],\n                                                         mem_limit=options_dict['mem_limit'],\n                                                         mounts=options_dict['mounts'],\n                                                         name=options_dict['name'],\n                                                         network=options_dict['network'],\n                                                         pids_limit=options_dict['pids_limit'],\n                                                         platform=options_dict['platform'],\n                                                         port_mappings=options_dict['port_mappings'],\n                                                         privileged=options_dict['privileged'],\n                                                         publish_all_ports=options_dict['publish_all_ports'],\n                                                         read_only=options_dict['read_only'],\n                                                         remove=options_dict['remove'],\n                                                         runtime=options_dict['runtime'],\n                                                         stdin_open=options_dict['stdin_open'],\n                                                         stop_signal=options_dict['stop_signal'],\n                                                         tty=options_dict['tty'],\n                                                         user=options_dict['user'],\n                                                         volumes=options_dict['volumes'],\n                                                         working_dir=options_dict['working_dir']\n                                                         )\n\n        return container_parameters", "response": "Parse DockerContainerBuilder options and create object with properties for docker - py run command\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting unique identifier of this container", "response": "def get_id(self):\n        \"\"\"\n        get unique identifier of this container\n\n        :return: str\n        \"\"\"\n        if self._id is None:\n            # FIXME: provide a better error message when key is not defined\n            self._id = self.inspect(refresh=False)[\"Id\"]\n        return self._id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inspect(self, refresh=True):\n        if refresh or not self._inspect_data:\n            ident = self._id or self.name\n            if not ident:\n                raise ConuException(\"This container does not have a valid identifier.\")\n            self._inspect_data = self.d.inspect_container(ident)\n        return self._inspect_data", "response": "return cached metadata by default\n\n        :param refresh: bool, returns up to date metadata if set to True\n        :return: dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting ports specified in container metadata", "response": "def get_ports(self):\n        \"\"\"\n        get ports specified in container metadata\n\n        :return: list of str\n        \"\"\"\n        ports = []\n        container_ports = self.inspect(refresh=True)[\"NetworkSettings\"][\"Ports\"]\n        if not container_ports:\n            return ports\n        for p in container_ports:\n            # TODO: gracefullness, error handling\n            ports.append(p.split(\"/\")[0])\n        return ports"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_port_mappings(self, port=None):\n        port_mappings = self.inspect(refresh=True)[\"NetworkSettings\"][\"Ports\"]\n\n        if not port:\n            return port_mappings\n\n        if str(port) not in self.get_ports():\n            return []\n\n        for p in port_mappings:\n            if p.split(\"/\")[0] == str(port):\n                return port_mappings[p]", "response": "Get list of port mappings between container and host."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, command, blocking=True, exec_create_kwargs=None, exec_start_kwargs=None):\n        logger.info(\"running command %s\", command)\n\n        exec_create_kwargs = exec_create_kwargs or {}\n        exec_start_kwargs = exec_start_kwargs or {}\n        exec_start_kwargs[\"stream\"] = True  # we want stream no matter what\n        exec_i = self.d.exec_create(self.get_id(), command, **exec_create_kwargs)\n        output = self.d.exec_start(exec_i, **exec_start_kwargs)\n        if blocking:\n            response = []\n            for line in output:\n                response.append(line)\n                logger.info(\"%s\", line.decode(\"utf-8\").strip(\"\\n\\r\"))\n\n            e_inspect = self.d.exec_inspect(exec_i)\n            exit_code = e_inspect[\"ExitCode\"]\n            if exit_code:\n                logger.error(\"command failed\")\n                logger.info(\"exec metadata: %s\", e_inspect)\n                raise ConuException(\"failed to execute command %s, exit code %s\" % (\n                                    command, exit_code))\n            return response\n        # TODO: for interactive use cases we need to provide API so users can do exec_inspect\n        return output", "response": "Execute a command in this container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logs(self, follow=False):\n        return self.d.logs(self.get_id(), stream=True, follow=follow)", "response": "Get logs from this container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kill(self, signal=None):\n        self.d.kill(self.get_id(), signal=signal)", "response": "send a signal to this container"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove this container from the container store", "response": "def delete(self, force=False, volumes=False, **kwargs):\n        \"\"\"\n        remove this container; kwargs indicate that some container runtimes\n        might accept more parameters\n\n        :param force: bool, if container engine supports this, force the functionality\n        :param volumes: bool, remove also associated volumes\n        :return: None\n        \"\"\"\n        self.d.remove_container(self.get_id(), v=volumes, force=force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites provided text to container s standard input.", "response": "def write_to_stdin(self, message):\n        \"\"\"\n        Write provided text to container's standard input. In order to make this function work, there needs to be several conditions met:\n         * the container needs to be running\n         * the container needs to have stdin open\n         * the container has to be created using method `run_via_binary_in_foreground`\n\n        For more info see documentation in run_via_binary_in_foreground()\n\n        :param message: str or bytes, text to be written to container standard input\n        \"\"\"\n        if not self.is_running():\n            raise ConuException(\n                \"Container must be running\")\n        if not self.popen_instance:\n            raise ConuException(\n                \"This container doesn't seem to be created using method `run_via_binary_in_foreground`.\")\n        if not self.popen_instance.stdin:\n            raise ConuException(\n                \"Container should be run with stdin redirection.\")\n\n        if not isinstance(message, bytes):\n            if isinstance(message, str):\n                message = message.encode()\n            else:\n                raise ConuException(\n                    \"Message should be an instance of str or bytes\")\n        try:\n            self.popen_instance.stdin.write(message)\n            self.popen_instance.stdin.flush()\n        except subprocess.CalledProcessError as e:\n            raise ConuException(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts dictionary returned after docker inspect command into instance of ContainerMetadata class", "response": "def get_metadata(self):\n        \"\"\"\n        Convert dictionary returned after docker inspect command into instance of ContainerMetadata class\n        :return: ContainerMetadata, container metadata instance\n        \"\"\"\n        inspect_data = self.inspect(refresh=True)\n        inspect_to_container_metadata(self.metadata, inspect_data, self.image)\n\n        return self.metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clean_tmp_dirs(self):\n\n        def onerror(fnc, path, excinfo):\n            # we might not have rights to do this, the files could be owned by root\n            self.logger.info(\"we were not able to remove temporary file %s: %s\", path, excinfo[1])\n\n        shutil.rmtree(self.tmpdir, onerror=onerror)\n        self.tmpdir = None\n        global _backend_tmpdir\n        _backend_tmpdir = None", "response": "Remove temporary directories associated with this backend instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _clean(self):\n        if CleanupPolicy.EVERYTHING in self.cleanup:\n                self.cleanup_containers()\n                self.cleanup_volumes()\n                self.cleanup_images()\n                self._clean_tmp_dirs()\n        else:\n            if CleanupPolicy.CONTAINERS in self.cleanup:\n                self.cleanup_containers()\n            if CleanupPolicy.VOLUMES in self.cleanup:\n                self.cleanup_volumes()\n            if CleanupPolicy.IMAGES in self.cleanup:\n                self.cleanup_images()\n            if CleanupPolicy.TMP_DIRS in self.cleanup:\n                self._clean_tmp_dirs()", "response": "Method for cleaning according to object cleanup policy value\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all available nspawn containers", "response": "def list_containers(self):\n        \"\"\"\n        list all available nspawn containers\n\n        :return: collection of instances of :class:`conu.backend.nspawn.container.NspawnContainer`\n        \"\"\"\n        data = run_cmd([\"machinectl\", \"list\", \"--no-legend\", \"--no-pager\"],\n                       return_output=True)\n        output = []\n        reg = re.compile(r\"\\s+\")\n        for line in data.split(\"\\n\"):\n            stripped = line.strip()\n            if stripped:\n                parts = reg.split(stripped)\n                name = parts[0]\n                output.append(self.ContainerClass(None, None, name=name))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all available nspawn images", "response": "def list_images(self):\n        \"\"\"\n        list all available nspawn images\n\n        :return: collection of instances of :class:`conu.backend.nspawn.image.NspawnImage`\n        \"\"\"\n        # Fedora-Cloud-Base-27-1.6.x86_64 raw  no  601.7M Sun 2017-11-05 08:30:10 CET \\\n        #   Sun 2017-11-05 08:30:10 CET\n        data = os.listdir(CONU_IMAGES_STORE)\n        output = []\n        for name in data:\n            output.append(self.ImageClass(name, pull_policy=ImagePullPolicy.NEVER))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cleanup_containers(self):\n        for cont in self.list_containers():\n            if CONU_ARTIFACT_TAG in cont.name:\n                try:\n                    logger.debug(\"removing container %s created by conu\", cont)\n                    # TODO: move this functionality to container.delete\n                    run_cmd([\"machinectl\", \"terminate\", cont.name])\n                except subprocess.CalledProcessError as e:\n                    logger.error(\"unable to remove container %s: %r\", cont, e)", "response": "stop all containers created by conu"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cleanup_images(self):\n        for image in self.list_images():\n            if CONU_ARTIFACT_TAG in image.name:\n                image.rmi()\n        # remove all hidden images -> causes trouble when pulling the image again\n        run_cmd([\"machinectl\", \"--no-pager\", \"clean\"])", "response": "Remove all images created by CONU and remove all hidden images"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_pods_ready(self):\n\n        if self.get_status().replicas and self.get_status().ready_replicas:\n            if self.get_status().replicas == self.get_status().ready_replicas:\n                logger.info(\"All pods are ready for deployment %s in namespace: %s\",\n                            self.name, self.namespace)\n                return True\n\n        return False", "response": "Check if all pods are ready for deployment"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_in_cluster(self):\n        try:\n            self.api.create_namespaced_deployment(self.namespace, self.body)\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API - create_namespaced_deployment: %s\\n\" % e)\n\n        logger.info(\"Creating Deployment %s in namespace: %s\", self.name, self.namespace)", "response": "create this Deployment in Kubernetes API and return the ID of the new Deployment in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_core_api():\n    global core_api\n\n    if core_api is None:\n        config.load_kube_config()\n        if API_KEY is not None:\n            # Configure API key authorization: BearerToken\n            configuration = client.Configuration()\n            configuration.api_key['authorization'] = API_KEY\n            configuration.api_key_prefix['authorization'] = 'Bearer'\n            core_api = client.CoreV1Api(client.ApiClient(configuration))\n        else:\n            core_api = client.CoreV1Api()\n\n    return core_api", "response": "Create instance of Core V1 API of kubernetes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates instance of Apps V1 API of kubernetes", "response": "def get_apps_api():\n    \"\"\"\n    Create instance of Apps V1 API of kubernetes:\n    https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/AppsV1Api.md\n    :return: instance of client\n    \"\"\"\n    global apps_api\n\n    if apps_api is None:\n        config.load_kube_config()\n        if API_KEY is not None:\n            # Configure API key authorization: BearerToken\n            configuration = client.Configuration()\n            configuration.api_key['authorization'] = API_KEY\n            configuration.api_key_prefix['authorization'] = 'Bearer'\n            apps_api = client.AppsV1Api(client.ApiClient(configuration))\n        else:\n            apps_api = client.AppsV1Api()\n\n    return apps_api"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_port(port, host, timeout=10):\n    logger.info(\"trying to open connection to %s:%s\", host, port)\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        sock.settimeout(timeout)\n        result = sock.connect_ex((host, port))\n        logger.info(\"was connection successful? errno: %s\", result)\n        if result == 0:\n            logger.debug('port is opened: %s:%s' % (host, port))\n            return True\n        else:\n            logger.debug('port is closed: %s:%s' % (host, port))\n            return False\n    finally:\n        sock.close()", "response": "Connect to a port on a host and return True on success"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget SELinux status of host", "response": "def get_selinux_status():\n    \"\"\"\n    get SELinux status of host\n\n    :return: string, one of Enforced, Permissive, Disabled\n    \"\"\"\n    getenforce_command_exists()\n    # alternatively, we could read directly from /sys/fs/selinux/{enforce,status}, but status is\n    # empty (why?) and enforce doesn't tell whether SELinux is disabled or not\n    o = run_cmd([\"getenforce\"], return_output=True).strip()  # libselinux-utils\n    logger.debug(\"SELinux is %r\", o)\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate random string of specified size", "response": "def random_str(size=10):\n    \"\"\"\n    create random string of selected size\n\n    :param size: int, length of the string\n    :return: the string\n    \"\"\"\n    return ''.join(random.choice(string.ascii_lowercase) for _ in range(size))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_cmd(cmd, return_output=False, ignore_status=False, log_output=True, **kwargs):\n    logger.debug('command: \"%s\"' % ' '.join(cmd))\n    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n                               universal_newlines=True, **kwargs)\n    output = process.communicate()[0]\n    if log_output:\n        logger.debug(output)\n\n    if process.returncode > 0:\n        if ignore_status:\n            if return_output:\n                return output\n            else:\n                return process.returncode\n        else:\n            raise subprocess.CalledProcessError(cmd=cmd, returncode=process.returncode)\n    if return_output:\n        return output", "response": "run command on host system"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command_exists(command, noop_invocation, exc_msg):\n    try:\n        found = bool(shutil.which(command))  # py3 only\n    except AttributeError:  # py2 branch\n        try:\n            p = subprocess.Popen(noop_invocation, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        except OSError:\n            found = False\n        else:\n            stdout, stderr = p.communicate()\n            found = p.returncode == 0\n            if not found:\n                logger.error(\"`%s` exited with a non-zero return code (%s)\",\n                             noop_invocation, p.returncode)\n                logger.error(\"command stdout = %s\", stdout)\n                logger.error(\"command stderr = %s\", stderr)\n    if not found:\n        raise CommandDoesNotExistException(exc_msg)\n    return True", "response": "Verify that the provided command exists. Raise CommandDoesNotExistException in case of an exception."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that dockerd and docker binary works.", "response": "def check_docker_command_works():\n    \"\"\"\n    Verify that dockerd and docker binary works fine. This is performed by calling `docker\n    version`, which also checks server API version.\n\n    :return: bool, True if all is good, otherwise ConuException or CommandDoesNotExistException\n              is thrown\n    \"\"\"\n    try:\n        out = subprocess.check_output([\"docker\", \"version\"],\n                                      stderr=subprocess.STDOUT,\n                                      universal_newlines=True)\n    except OSError:\n        logger.info(\"docker binary is not available\")\n        raise CommandDoesNotExistException(\n            \"docker command doesn't seem to be available on your system. \"\n            \"Please install and configure docker.\"\n        )\n    except subprocess.CalledProcessError as ex:\n        logger.error(\"exception: %s\", ex)\n        logger.error(\"rc: %s, output: %r\", ex.returncode, ex.output)\n        raise ConuException(\n            \"`docker version` call failed, it seems that your docker daemon is misconfigured or \"\n            \"this user can't communicate with dockerd.\"\n        )\n    else:\n        logger.info(\"docker environment info: %r\", out)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngrabbing values from dicts and lists gracefully.", "response": "def graceful_get(d, *args):\n    \"\"\"\n    Obtain values from dicts and lists gracefully. Example:\n\n    ::\n\n        print(graceful_get({\"a\": [{1: 2}, {\"b\": \"c\"}]}, \"a\", \"b\"))\n        c\n\n    :param d: collection (usually a dict or list)\n    :param args: list of keys which are used as a lookup\n    :return: the value from your collection\n    \"\"\"\n    if not d:\n        return d\n    value = d\n    for arg in args:\n        try:\n            value = value[arg]\n        except (IndexError, KeyError, AttributeError, TypeError) as ex:\n            logger.debug(\"exception while getting a value %r from %s\", ex, str(value)[:32])\n            return None\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport a docker container to a directory", "response": "def export_docker_container_to_directory(client, container, path):\n    \"\"\"\n    take selected docker container, create an archive out of it and\n    unpack it to a selected location\n\n    :param client: instance of docker.APIClient\n    :param container: instance of DockerContainer\n    :param path: str, path to a directory, doesn't need to exist\n    :return: None\n    \"\"\"\n    # we don't do this because of a bug in docker:\n    # https://bugzilla.redhat.com/show_bug.cgi?id=1570828\n    # stream, _ = client.get_archive(container.get_id(), \"/\")\n    check_docker_command_works()\n    export_p = subprocess.Popen(\n        [\"docker\", \"export\", container.get_id()],\n        stderr=subprocess.PIPE,\n        stdout=subprocess.PIPE\n    )\n\n    try:\n        os.mkdir(path, 0o0700)\n    except OSError as ex:\n        if ex.errno == errno.EEXIST:\n            logger.debug(\"mount point %s exists already\", path)\n        else:\n            logger.error(\"mount point %s can't be created: %s\", path, ex)\n            raise\n    logger.debug(\"about to untar the image\")\n    # we can't use tarfile because of --no-same-owner: files in containers are owned\n    # by root and tarfile is trying to `chown 0 file` when running as an unpriv user\n    p = subprocess.Popen(\n        [\"tar\", \"--no-same-owner\", \"-C\", path, \"-x\"],\n        stdin=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    while True:\n        data = export_p.stdout.read(1048576)\n        if not data:\n            break\n        p.stdin.write(data)\n    p.stdin.close()\n    p.wait()\n    export_p.wait()\n    if export_p.returncode:\n        logger.error(export_p.stderr.read())\n        raise ConuException(\"Failed to get rootfs of %s from docker.\" % container)\n    if p.returncode:\n        logger.error(p.stderr.read())\n        raise ConuException(\"Failed to unpack the archive.\")\n\n    logger.debug(\"image is unpacked\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_oc_api_token():\n    oc_command_exists()\n\n    try:\n        return run_cmd([\"oc\", \"whoami\", \"-t\"], return_output=True).rstrip()  # remove '\\n'\n    except subprocess.CalledProcessError as ex:\n        raise ConuException(\"oc whoami -t failed: %s\" % ex)", "response": "Get token of user logged in OpenShift cluster"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse provided image reference into list of images and tags", "response": "def parse_reference(reference):\n    \"\"\"\n    parse provided image reference into <image_repository>:<tag>\n\n    :param reference: str, e.g. (registry.fedoraproject.org/fedora:27)\n    :return: collection (tuple or list), (\"registry.fedoraproject.org/fedora\", \"27\")\n    \"\"\"\n    if \":\" in reference:\n        im, tag = reference.rsplit(\":\", 1)\n        if \"/\" in tag:\n            # this is case when there is port in the registry URI\n            return (reference, \"latest\")\n        else:\n            return (im, tag)\n\n    else:\n        return (reference, \"latest\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets version from podman version", "response": "def get_version(self):\n        \"\"\"\n        return 3-tuple of version info or None\n\n        :return: (str, str, str)\n        \"\"\"\n        raw_version = run_cmd([\"podman\", \"version\"], return_output=True)\n        regex = re.compile(r\"Version:\\s*(\\d+)\\.(\\d+)\\.(\\d+)\")\n        match = regex.findall(raw_version)\n        try:\n            return match[0]\n        except IndexError:\n            logger.error(\"unable to parse version from `podman version`\")\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all available podman containers.", "response": "def list_containers(self):\n        \"\"\"\n        List all available podman containers.\n\n        :return: collection of instances of :class:`conu.PodmanContainer`\n        \"\"\"\n        containers = []\n        for container in self._list_podman_containers():\n            identifier = container[\"ID\"]\n            name = container[\"Names\"]\n            image_name = container[\"Image\"]\n\n            try:\n                image_name, image_tag = parse_reference(image_name)\n            except (IndexError, TypeError):\n                image_name, image_tag = None, None\n\n            image = PodmanImage(image_name, tag=image_tag, identifier=None)\n            container = PodmanContainer(image, identifier, name=name)\n            containers.append(container)\n\n        return containers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_images(self):\n        images = []\n        for image in self._list_all_podman_images():\n            try:\n                i_name, tag = parse_reference(image[\"names\"][0])\n            except (IndexError, TypeError):\n                i_name, tag = None, None\n            d_im = PodmanImage(i_name, tag=tag, identifier=image[\"id\"],\n                               pull_policy=PodmanImagePullPolicy.NEVER)\n            images.append(d_im)\n\n        return images", "response": "List all available podman images."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _list_all_podman_images():\n        cmdline = [\"podman\", \"images\", \"--format\", \"json\"]\n        output = run_cmd(cmdline, return_output=True)\n        images = json.loads(output)\n        return images", "response": "Finds all podman containers and returns a list of dicts with image info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _list_podman_containers(filter=None):\n        option = [\"--filter\", filter] if filter else [\"-a\"]\n        cmdline = [\"podman\", \"ps\"] + option + [\"--format\", \"json\"]\n        output = run_cmd(cmdline, return_output=True)\n        containers = json.loads(output)\n        return containers", "response": "Finds podman containers by filter or all containers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inspect_to_metadata(metadata_object, inspect_data):\n    identifier = graceful_get(inspect_data, 'Id')\n    if identifier:\n        if \":\" in identifier:\n            # format of image name from docker inspect:\n            # sha256:8f0e66c924c0c169352de487a3c2463d82da24e9442fc097dddaa5f800df7129\n            metadata_object.identifier = identifier.split(':')[1]\n        else:\n            # container\n            metadata_object.identifier = identifier\n\n    # format of Environment Variables from docker inspect:\n    # ['DISTTAG=f26container', 'FGC=f26']\n    raw_env_vars = graceful_get(inspect_data, \"Config\", \"Env\") or []\n    if raw_env_vars:\n        metadata_object.env_variables = {}\n        for env_variable in raw_env_vars:\n            splits = env_variable.split(\"=\", 1)\n            name = splits[0]\n            value = splits[1] if len(splits) > 1 else None\n            if value is not None:\n                metadata_object.env_variables.update({name: value})\n\n    raw_exposed_ports = graceful_get(inspect_data, \"Config\", \"ExposedPorts\")\n    if raw_exposed_ports:\n        metadata_object.exposed_ports = list(raw_exposed_ports.keys())\n\n    # specific to images\n    raw_repo_tags = graceful_get(inspect_data, 'RepoTags')\n    if raw_repo_tags:\n        metadata_object.name = raw_repo_tags[0]\n    metadata_object.labels = graceful_get(inspect_data, 'Config', 'Labels')\n    metadata_object.command = graceful_get(inspect_data, 'Config', 'Cmd')\n    metadata_object.creation_timestamp = inspect_data.get('Created', None)\n    # specific to images\n    metadata_object.image_names = inspect_data.get('RepoTags', None)\n    # specific to images\n    digests = inspect_data.get(\"RepoDigests\", None)\n    if digests:\n        metadata_object.repo_digests = digests\n        metadata_object.digest = digests[0]\n\n    return metadata_object", "response": "process data from docker inspect and update provided metadata object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses data from docker container inspect and update container metadata object", "response": "def inspect_to_container_metadata(c_metadata_object, inspect_data, image_instance):\n    \"\"\"\n    process data from `docker container inspect` and update provided container metadata object\n\n    :param c_metadata_object: instance of ContainerMetadata\n    :param inspect_data: dict, metadata from `docker inspect` or `dockert_client.images()`\n    :param image_instance: instance of DockerImage\n    :return: instance of ContainerMetadata\n    \"\"\"\n    inspect_to_metadata(c_metadata_object, inspect_data)\n\n    status = ContainerStatus.get_from_docker(\n        graceful_get(inspect_data, \"State\", \"Status\"),\n        graceful_get(inspect_data, \"State\", \"ExitCode\"),\n    )\n\n    image_id = graceful_get(inspect_data, \"Image\")\n    if image_id:\n        if \":\" in image_id:\n            # format of image name from docker inspect:\n            # sha256:8f0e66c924c0c169352de487a3c2463d82da24e9442fc097dddaa5f800df7129\n            image_instance.identifier = image_id.split(':')[1]\n        else:\n            # container\n            image_instance.identifier = image_id\n\n    # format of Port mappings from docker inspect:\n    # {'12345/tcp': [\n    #   {'HostIp': '0.0.0.0', 'HostPort': '123'},\n    #   {'HostIp': '0.0.0.0', 'HostPort': '1234'}]}\n    port_mappings = dict()\n\n    raw_port_mappings = graceful_get(inspect_data, 'HostConfig', 'PortBindings') or {}\n\n    for key, value in raw_port_mappings.items():\n        for item in value:\n            logger.debug(\"parsing ports: key = %s, item = %s\", key, item)\n            li = port_mappings.get(key, [])\n            raw_host_port = item['HostPort']\n            if raw_host_port == \"\":\n                int_port = None\n            else:\n                try:\n                    int_port = int(raw_host_port)\n                except ValueError as ex:\n                    logger.error(\"could not parse port: %s\", ex)\n                    continue\n            li.append(int_port)\n            port_mappings.update({key: li})\n\n    c_metadata_object.status = status\n    c_metadata_object.port_mappings = port_mappings\n    c_metadata_object.hostname = graceful_get(inspect_data, 'Config', 'Hostname')\n    raw_networks = graceful_get(inspect_data, \"NetworkSettings\", \"Networks\").values()\n    if raw_networks:\n        c_metadata_object.ipv4_addresses = [\n            graceful_get(x, \"IPAddress\")\n            for x in raw_networks if graceful_get(x, \"IPAddress\")]\n        c_metadata_object.ipv6_addresses = [\n            graceful_get(x, \"GlobalIPv6Address\")\n            for x in raw_networks if graceful_get(x, \"GlobalIPv6Address\")]\n    c_metadata_object.image = image_instance\n    name = graceful_get(inspect_data, \"Name\")\n    if name:\n        name = name[1:] if name.startswith(\"/\") else name  # remove / at the beginning\n        c_metadata_object.name = name\n\n    return c_metadata_object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all available pods.", "response": "def list_pods(self, namespace=None):\n        \"\"\"\n        List all available pods.\n\n        :param namespace: str, if not specified list pods for all namespaces\n        :return: collection of instances of :class:`conu.backend.k8s.pod.Pod`\n        \"\"\"\n\n        if namespace:\n            return [Pod(name=p.metadata.name, namespace=namespace, spec=p.spec)\n                    for p in self.core_api.list_namespaced_pod(namespace, watch=False).items]\n\n        return [Pod(name=p.metadata.name, namespace=p.metadata.namespace, spec=p.spec)\n                for p in self.core_api.list_pod_for_all_namespaces(watch=False).items]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_services(self, namespace=None):\n\n        if namespace:\n            return [Service(name=s.metadata.name,\n                            ports=k8s_ports_to_metadata_ports(s.spec.ports),\n                            namespace=s.metadata.namespace,\n                            labels=s.metadata.labels, selector=s.spec.selector, spec=s.spec)\n                    for s in self.core_api.list_namespaced_service(namespace, watch=False).items]\n\n        return [Service(name=s.metadata.name,\n                        ports=k8s_ports_to_metadata_ports(s.spec.ports),\n                        namespace=s.metadata.namespace,\n                        labels=s.metadata.labels, selector=s.spec.selector, spec=s.spec)\n                for s in self.core_api.list_service_for_all_namespaces(watch=False).items]", "response": "List all available services."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_deployments(self, namespace=None):\n\n        if namespace:\n            return [Deployment(name=d.metadata.name,\n                               namespace=d.metadata.namespace,\n                               labels=d.metadata.labels, selector=d.spec.selector,\n                               image_metadata=ImageMetadata(\n                                   name=d.spec.template.spec.containers[0].name.split(\"-\", 1)[0]))\n                    for d in self.apps_api.list_namespaced_deployment(namespace, watch=False).items]\n\n        return [Deployment(name=d.metadata.name,\n                           namespace=d.metadata.namespace,\n                           labels=d.metadata.labels, selector=d.spec.selector,\n                           image_metadata=ImageMetadata(\n                               name=d.spec.template.spec.containers[0].name.split(\"-\", 1)[0]))\n                for d in self.apps_api.list_deployment_for_all_namespaces(watch=False).items]", "response": "List all available deployments for the specified namespace."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_namespace(self):\n        name = 'namespace-{random_string}'.format(random_string=random_str(5))\n\n        namespace = client.V1Namespace(metadata=client.V1ObjectMeta(name=name))\n\n        self.core_api.create_namespace(namespace)\n\n        logger.info(\"Creating namespace: %s\", name)\n\n        # save all namespaces created with this backend\n        self.managed_namespaces.append(name)\n\n        # wait for namespace to be ready\n        Probe(timeout=30, pause=5, expected_retval=True,\n              fnc=self._namespace_ready, namespace=name).run()\n\n        return name", "response": "Create a new namespace with random name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if API tokens for service accounts are generated", "response": "def _namespace_ready(self, namespace):\n        \"\"\"\n        Check if API tokens for service accounts are generated\n        :param namespace: str, namespace\n        :return: bool\n        \"\"\"\n        try:\n            secrets = self.core_api.list_namespaced_secret(namespace=namespace)\n            if len(secrets.items) > 0:\n                # API tokens for service accounts are generated\n                logger.info(\"Namespace is ready!\")\n                return True\n        except ApiException as e:\n            raise ConuException(\n                \"Exception when calling Kubernetes API %s\\n\" % e)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a namespace with specific name", "response": "def delete_namespace(self, name):\n        \"\"\"\n        Delete namespace with specific name\n        :param name: str, namespace to delete\n        :return: None\n        \"\"\"\n        self.core_api.delete_namespace(name, client.V1DeleteOptions())\n\n        logger.info(\"Deleting namespace: %s\", name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clean(self):\n        if K8sCleanupPolicy.NAMESPACES in self.cleanup:\n            self.cleanup_namespaces()\n        elif K8sCleanupPolicy.EVERYTHING in self.cleanup:\n            self.cleanup_pods()\n            self.cleanup_services()\n            self.cleanup_deployments()\n        else:\n            if K8sCleanupPolicy.PODS in self.cleanup:\n                self.cleanup_pods()\n            if K8sCleanupPolicy.SERVICES in self.cleanup:\n                self.cleanup_services()\n            if K8sCleanupPolicy.DEPLOYMENTS in self.cleanup:\n                self.cleanup_deployments()", "response": "Method for cleaning according to object cleanup policy value\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup_pods(self):\n        pods = self.list_pods()\n\n        for pod in pods:\n            if pod.namespace in self.managed_namespaces:\n                pod.delete()", "response": "Delete all pods created in namespaces associated with this backend"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup_services(self):\n        services = self.list_services()\n\n        for service in services:\n            if service.namespace in self.managed_namespaces:\n                service.delete()", "response": "Delete all services created in namespaces associated with this backend\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cleanup_deployments(self):\n        deployments = self.list_deployments()\n\n        for deployment in deployments:\n            if deployment.namespace in self.managed_namespaces:\n                deployment.delete()", "response": "Delete all deployments created in namespaces associated with this backend"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_url(path, host, port, method=\"http\"):\n    return urlunsplit(\n        (method, \"%s:%s\" % (host, port), path, \"\", \"\")\n    )", "response": "make url from path host and port"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_containers(self):\n        result = []\n        for c in self.d.containers(all=True):\n            name = None\n            names = c.get(\"Names\", None)\n            if names:\n                name = names[0]\n            i = DockerImage(None, identifier=c[\"ImageID\"])\n            cont = DockerContainer(i, c[\"Id\"], name=name)\n            # TODO: docker_client.containers produces different metadata than inspect\n            inspect_to_container_metadata(cont.metadata, c, i)\n            result.append(cont)\n        return result", "response": "List all available docker containers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_images(self):\n        response = []\n        for im in self.d.images():\n            try:\n                i_name, tag = parse_reference(im[\"RepoTags\"][0])\n            except (IndexError, TypeError):\n                i_name, tag = None, None\n            d_im = DockerImage(i_name, tag=tag, identifier=im[\"Id\"],\n                               pull_policy=DockerImagePullPolicy.NEVER)\n            inspect_to_metadata(d_im.metadata, im)\n\n            response.append(d_im)\n        return response", "response": "List all available docker images."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login(self, username, password=None, email=None, registry=None, reauth=False,\n              dockercfg_path=None):\n        \"\"\"\n        :param username: The registry username\n        :param password: The plaintext password\n        :param email: The email for the registry account\n        :param registry: URL to the registry, example:\n               - https://index.docker.io/v1/\n        :param reauth: Whether or not to refresh existing authentication on the Docker server.\n        :param dockercfg_path: Use a custom path for the Docker config file\n        :return: None\n        \"\"\"\n        self.d.login(username, password, email, registry, reauth, dockercfg_path)\n        logger.info(\"Login to %s succeed\", registry)", "response": "Login to the registry"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match(ctx, features, profile, gps_precision):\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n\n    features = list(features)\n    if len(features) != 1:\n        raise click.BadParameter(\n            \"Mapmatching requires a single LineString feature\")\n\n    service = mapbox.MapMatcher(access_token=access_token)\n    try:\n        res = service.match(\n            features[0],\n            profile=profile,\n            gps_precision=gps_precision)\n    except mapbox.errors.ValidationError as exc:\n        raise click.BadParameter(str(exc))\n\n    if res.status_code == 200:\n        stdout = click.open_file('-', 'w')\n        click.echo(res.text, file=stdout)\n    else:\n        raise MapboxCLIException(res.text.strip())", "response": "Mapbox Map Matching API lets you use snap your GPS traces\nto the OpenStreetMap road and path network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating static map images from existing Mapbox map ids.", "response": "def staticmap(ctx, mapid, output, features, lat, lon, zoom, size):\n    \"\"\"\n    Generate static map images from existing Mapbox map ids.\n    Optionally overlay with geojson features.\n\n      $ mapbox staticmap --features features.geojson mapbox.satellite out.png\n      $ mapbox staticmap --lon -61.7 --lat 12.1 --zoom 12 mapbox.satellite out2.png\n\n    An access token is required, see `mapbox --help`.\n    \"\"\"\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n    if features:\n        features = list(\n            cligj.normalize_feature_inputs(None, 'features', [features]))\n\n    service = mapbox.Static(access_token=access_token)\n\n    try:\n        res = service.image(\n            mapid,\n            lon=lon, lat=lat, z=zoom,\n            width=size[0], height=size[1],\n            features=features, sort_keys=True)\n    except mapbox.errors.ValidationError as exc:\n        raise click.BadParameter(str(exc))\n\n    if res.status_code == 200:\n        output.write(res.content)\n    else:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config(ctx):\n    ctx.default_map = ctx.obj['cfg']\n    click.echo(\"CLI:\")\n    click.echo(\"access-token = {0}\".format(ctx.obj['access_token']))\n    click.echo(\"verbosity = {0}\".format(ctx.obj['verbosity']))\n    click.echo(\"\")\n\n    click.echo(\"Environment:\")\n    if 'MAPBOX_ACCESS_TOKEN' in os.environ:\n        click.echo(\"MAPBOX_ACCESS_TOKEN = {0}\".format(\n            os.environ['MAPBOX_ACCESS_TOKEN']))\n    if 'MapboxAccessToken' in os.environ:\n        click.echo(\"MapboxAccessToken = {0}\".format(\n            os.environ['MapboxAccessToken']))\n    if 'MAPBOX_VERBOSE' in os.environ:\n        click.echo(\"MAPBOX_VERBOSE = {0}\".format(\n            os.environ['MAPBOX_VERBOSE']))\n    click.echo(\"\")\n\n    if 'config_file' in ctx.obj:\n        click.echo(\"Config file {0}:\".format(ctx.obj['config_file']))\n        for key, value in ctx.default_map.items():\n            click.echo(\"{0} = {1}\".format(key, value))\n        click.echo(\"\")", "response": "Show access token and other configuration settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coords_from_query(query):\n    try:\n        coords = json.loads(query)\n    except ValueError:\n        vals = re.split(r'[,\\s]+', query.strip())\n        coords = [float(v) for v in vals]\n    return tuple(coords[:2])", "response": "Transform a query line into a tuple of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geocoding(ctx, query, forward, include_headers, lat, lon,\n              place_type, output, dataset, country, bbox, features, limit):\n    \"\"\"This command returns places matching an address (forward mode) or\n    places matching coordinates (reverse mode).\n\n    In forward (the default) mode the query argument shall be an address\n    such as '1600 pennsylvania ave nw'.\n\n      $ mapbox geocoding '1600 pennsylvania ave nw'\n\n    In reverse mode the query argument shall be a JSON encoded array\n    of longitude and latitude (in that order) in decimal degrees.\n\n      $ mapbox geocoding --reverse '[-77.4371, 37.5227]'\n\n    An access token is required, see `mapbox --help`.\n    \"\"\"\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n    stdout = click.open_file(output, 'w')\n\n    geocoder = Geocoder(name=dataset, access_token=access_token)\n\n    if forward:\n        if country:\n            country = [x.lower() for x in country.split(\",\")]\n\n        if bbox:\n            try:\n                bbox = tuple(map(float, bbox.split(',')))\n            except ValueError:\n                bbox = json.loads(bbox)\n\n        for q in iter_query(query):\n            try:\n                resp = geocoder.forward(\n                    q, types=place_type, lat=lat, lon=lon,\n                    country=country, bbox=bbox, limit=limit)\n            except mapbox.errors.ValidationError as exc:\n                raise click.BadParameter(str(exc))\n\n            if include_headers:\n                echo_headers(resp.headers, file=stdout)\n            if resp.status_code == 200:\n                if features:\n                    collection = json.loads(resp.text)\n                    for feat in collection['features']:\n                        click.echo(json.dumps(feat), file=stdout)\n                else:\n                    click.echo(resp.text, file=stdout)\n            else:\n                raise MapboxCLIException(resp.text.strip())\n    else:\n        for lon, lat in map(coords_from_query, iter_query(query)):\n            try:\n                resp = geocoder.reverse(\n                    lon=lon, lat=lat, types=place_type, limit=limit)\n            except mapbox.errors.ValidationError as exc:\n                raise click.BadParameter(str(exc))\n\n            if include_headers:\n                echo_headers(resp.headers, file=stdout)\n            if resp.status_code == 200:\n                if features:\n                    collection = json.loads(resp.text)\n                    for feat in collection['features']:\n                        click.echo(json.dumps(feat), file=stdout)\n                else:\n                    click.echo(resp.text, file=stdout)\n            else:\n                raise MapboxCLIException(resp.text.strip())", "response": "This command returns a list of places matching an address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datasets(ctx):\n\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n    service = mapbox.Datasets(access_token=access_token)\n    ctx.obj['service'] = service", "response": "Read and write GeoJSON from Mapbox - hosted datasets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(ctx, name, description):\n\n    service = ctx.obj.get('service')\n    res = service.create(name, description)\n\n    if res.status_code == 200:\n        click.echo(res.text)\n    else:\n        raise MapboxCLIException(res.text.strip())", "response": "Create a new dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the attributes of a dataset.", "response": "def read_dataset(ctx, dataset, output):\n    \"\"\"Read the attributes of a dataset.\n\n    Prints a JSON object containing the attributes\n    of a dataset. The attributes: owner (a Mapbox account),\n    id (dataset id), created (Unix timestamp), modified\n    (timestamp), name (string), and description (string).\n\n        $ mapbox datasets read-dataset dataset-id\n\n    All endpoints require authentication. An access token with\n    `datasets:read` scope is required, see `mapbox --help`.\n    \"\"\"\n\n    stdout = click.open_file(output, 'w')\n    service = ctx.obj.get('service')\n    res = service.read_dataset(dataset)\n\n    if res.status_code == 200:\n        click.echo(res.text, file=stdout)\n    else:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a dataset. $ mapbox datasets delete-dataset dataset-id All endpoints require authentication. An access token with `datasets:write` scope is required, see `mapbox --help`.", "response": "def delete_dataset(ctx, dataset):\n    \"\"\"Delete a dataset.\n\n        $ mapbox datasets delete-dataset dataset-id\n\n    All endpoints require authentication. An access token with\n    `datasets:write` scope is required, see `mapbox --help`.\n    \"\"\"\n\n    service = ctx.obj.get('service')\n    res = service.delete_dataset(dataset)\n\n    if res.status_code != 204:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists features of a dataset.", "response": "def list_features(ctx, dataset, reverse, start, limit, output):\n    \"\"\"Get features of a dataset.\n\n    Prints the features of the dataset as a GeoJSON feature collection.\n\n        $ mapbox datasets list-features dataset-id\n\n    All endpoints require authentication. An access token with\n    `datasets:read` scope is required, see `mapbox --help`.\n    \"\"\"\n\n    stdout = click.open_file(output, 'w')\n    service = ctx.obj.get('service')\n    res = service.list_features(dataset, reverse, start, limit)\n\n    if res.status_code == 200:\n        click.echo(res.text, file=stdout)\n    else:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating or update a feature.", "response": "def put_feature(ctx, dataset, fid, feature, input):\n    \"\"\"Create or update a dataset feature.\n\n    The semantics of HTTP PUT apply: if the dataset has no feature\n    with the given `fid` a new feature will be created. Returns a\n    GeoJSON representation of the new or updated feature.\n\n        $ mapbox datasets put-feature dataset-id feature-id 'geojson-feature'\n\n    All endpoints require authentication. An access token with\n    `datasets:write` scope is required, see `mapbox --help`.\n    \"\"\"\n\n    if feature is None:\n        stdin = click.open_file(input, 'r')\n        feature = stdin.read()\n\n    feature = json.loads(feature)\n\n    service = ctx.obj.get('service')\n    res = service.update_feature(dataset, fid, feature)\n\n    if res.status_code == 200:\n        click.echo(res.text)\n    else:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_feature(ctx, dataset, fid):\n\n    service = ctx.obj.get('service')\n    res = service.delete_feature(dataset, fid)\n\n    if res.status_code != 204:\n        raise MapboxCLIException(res.text.strip())", "response": "Delete a feature.\n\n        $ mapbox datasets delete-feature dataset-id feature-id\n\n    All endpoints require authentication. An access token with\n    `datasets:write` scope is required, see `mapbox --help`."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a vector tileset from a dataset.", "response": "def create_tileset(ctx, dataset, tileset, name):\n    \"\"\"Create a vector tileset from a dataset.\n\n        $ mapbox datasets create-tileset dataset-id username.data\n\n    Note that the tileset must start with your username and the dataset\n    must be one that you own. To view processing status, visit\n    https://www.mapbox.com/data/. You may not generate another tilesets\n    from the same dataset until the first processing job has completed.\n\n    All endpoints require authentication. An access token with\n    `uploads:write` scope is required, see `mapbox --help`.\n    \"\"\"\n\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n    service = mapbox.Uploader(access_token=access_token)\n\n    uri = \"mapbox://datasets/{username}/{dataset}\".format(\n        username=tileset.split('.')[0], dataset=dataset)\n\n    res = service.create(uri, tileset, name)\n\n    if res.status_code == 201:\n        click.echo(res.text)\n    else:\n        raise MapboxCLIException(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef directions(ctx, features, profile, alternatives, \n               geometries, overview, steps, continue_straight, \n               waypoint_snapping, annotations, language, output):\n    \"\"\"The Mapbox Directions API will show you how to get\n       where you're going.\n\n       mapbox directions \"[0, 0]\" \"[1, 1]\"\n\n       An access token is required.  See \"mapbox --help\".\n    \"\"\"\n\n    access_token = (ctx.obj and ctx.obj.get(\"access_token\")) or None\n\n    service = mapbox.Directions(access_token=access_token)\n\n    # The Directions SDK expects False to be\n    # a bool, not a str.\n\n    if overview == \"False\":\n        overview = False\n\n    # When using waypoint snapping, the \n    # Directions SDK expects features to be \n    # a list, not a generator.\n\n    if waypoint_snapping is not None:\n        features = list(features)\n\n    if annotations:\n        annotations = annotations.split(\",\")\n\n    stdout = click.open_file(output, \"w\")\n\n    try:\n        res = service.directions(\n            features,\n            profile=profile,\n            alternatives=alternatives,\n            geometries=geometries,\n            overview=overview,\n            steps=steps,\n            continue_straight=continue_straight,\n            waypoint_snapping=waypoint_snapping,\n            annotations=annotations,\n            language=language\n        )\n    except mapbox.errors.ValidationError as exc:\n        raise click.BadParameter(str(exc))\n\n    if res.status_code == 200:\n        if geometries == \"geojson\":\n            click.echo(json.dumps(res.geojson()), file=stdout)\n        else:\n            click.echo(res.text, file=stdout)\n    else:\n        raise MapboxCLIException(res.text.strip())", "response": "Get a list of Mapbox Directions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload(ctx, tileset, datasource, name, patch):\n    access_token = (ctx.obj and ctx.obj.get('access_token')) or None\n\n    service = mapbox.Uploader(access_token=access_token)\n\n    if name is None:\n        name = tileset.split(\".\")[-1]\n\n    if datasource.startswith('https://'):\n        # Skip staging. Note this this only works for specific buckets.\n        res = service.create(datasource, tileset, name=name, patch=patch)\n\n    else:\n        sourcefile = click.File('rb')(datasource)\n\n        if hasattr(sourcefile, 'name'):\n            filelen = (\n                1 if sourcefile.name == '<stdin>'\n                else os.stat(sourcefile.name).st_size)\n        else:\n            filelen = (len(sourcefile.getbuffer())\n                       if hasattr(sourcefile, 'getbuffer') else 1)\n\n        with click.progressbar(length=filelen, label='Uploading data source',\n                               fill_char=\"#\", empty_char='-',\n                               file=sys.stderr) as bar:\n\n            def callback(num_bytes):\n                \"\"\"Update the progress bar\"\"\"\n                bar.update(num_bytes)\n\n            res = service.upload(sourcefile, tileset, name, patch=patch,\n                                 callback=callback)\n\n    if res.status_code == 201:\n        click.echo(res.text)\n    else:\n        raise MapboxCLIException(res.text.strip())", "response": "Upload data to Mapbox accounts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_notebook(self, os_path, as_version=4):\n        with self.open(os_path, 'r', encoding='utf-8') as f:\n            try:\n                if ftdetect(os_path) == 'notebook':\n                    return nbformat.read(f, as_version=as_version)\n                elif ftdetect(os_path) == 'markdown':\n                    nbjson = convert(os_path,\n                                     informat='markdown',\n                                     outformat='notebook')\n                    return nbformat.reads(nbjson, as_version=as_version)\n            except Exception as e:\n                raise web.HTTPError(\n                    400,\n                    u\"Unreadable Notebook: %s %r\" % (os_path, e),\n                )", "response": "Read a notebook from an os path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _save_notebook(self, os_path, nb):\n        with self.atomic_writing(os_path, encoding='utf-8') as f:\n            if ftdetect(os_path) == 'notebook':\n                nbformat.write(nb, f, version=nbformat.NO_CONVERT)\n            elif ftdetect(os_path) == 'markdown':\n                nbjson = nbformat.writes(nb, version=nbformat.NO_CONVERT)\n                markdown = convert(nbjson,\n                                   informat='notebook',\n                                   outformat='markdown',\n                                   strip_outputs=self.strip_outputs)\n                f.write(markdown)", "response": "Save a notebook to an os_path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if filename is markdown or notebook based on the file extension.", "response": "def ftdetect(filename):\n    \"\"\"Determine if filename is markdown or notebook,\n    based on the file extension.\n    \"\"\"\n    _, extension = os.path.splitext(filename)\n    md_exts = ['.md', '.markdown', '.mkd', '.mdown', '.mkdn', '.Rmd']\n    nb_exts = ['.ipynb']\n    if extension in md_exts:\n        return 'markdown'\n    elif extension in nb_exts:\n        return 'notebook'\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef command_line_parser():\n    description = \"Create an IPython notebook from markdown.\"\n    example_use = \"Example:  notedown some_markdown.md > new_notebook.ipynb\"\n    parser = argparse.ArgumentParser(description=description,\n                                     epilog=example_use)\n    parser.add_argument('input_file',\n                        help=\"markdown input file (default STDIN)\",\n                        nargs=\"?\",\n                        default='-')\n    parser.add_argument('-o', '--output',\n                        help=(\"output file, (default STDOUT). \"\n                              \"If flag used but no file given, use \"\n                              \"the name of the input file to \"\n                              \"determine the output filename. \"\n                              \"This will OVERWRITE if input and output \"\n                              \"formats are the same.\"),\n                        nargs=\"?\",\n                        default='-',\n                        const='')\n    parser.add_argument('--from',\n                        dest='informat',\n                        choices=('notebook', 'markdown'),\n                        help=(\"format to convert from, defaults to markdown \"\n                              \"or file extension\"))\n    parser.add_argument('--to',\n                        dest='outformat',\n                        choices=('notebook', 'markdown'),\n                        help=(\"format to convert to, defaults to notebook \"\n                              \"or file extension. Setting --render forces \"\n                              \"this to 'markdown'\"))\n    parser.add_argument('--run', '--execute',\n                        action='store_true',\n                        help=(\"run the notebook, executing the \"\n                              \"contents of each cell\"))\n    parser.add_argument('--timeout',\n                        default=30,\n                        type=int,\n                        help=(\"set the cell execution timeout (in seconds)\"))\n    parser.add_argument('--strip',\n                        action='store_true',\n                        dest='strip_outputs',\n                        help=(\"strip output cells\"))\n    parser.add_argument('--precode',\n                        nargs='+',\n                        default=[],\n                        help=(\"additional code to place at the start of the \"\n                              \"notebook, e.g. --pre '%%matplotlib inline' \"\n                              \"'import numpy as np'\"))\n    parser.add_argument('--knit',\n                        nargs='?',\n                        help=(\"pre-process the markdown with knitr. \"\n                              \"Default chunk options are 'eval=FALSE' \"\n                              \"but you can change this by passing a string. \"\n                              \"Requires R in your path and knitr installed.\"),\n                        const='eval=FALSE')\n    parser.add_argument('--rmagic',\n                        action='store_true',\n                        help=(\"autoload the rmagic extension. Synonym for \"\n                              \"--precode '%%load_ext rpy2.ipython'\"))\n    parser.add_argument('--nomagic',\n                        action='store_false',\n                        dest='magic',\n                        help=(\"disable code magic.\"))\n    parser.add_argument('--render',\n                        help=('render outputs, forcing markdown output'),\n                        action='store_true')\n    parser.add_argument('--template',\n                        help=('template file'))\n    parser.add_argument('--match',\n                        default='all',\n                        help=(\"determine kind of code blocks that get \"\n                              \"converted into code cells. \"\n                              \"choose from 'all' (default), 'fenced', \"\n                              \"'strict' or a specific language to match on\"))\n    parser.add_argument('--examples',\n                        help=('show example usage'),\n                        action='store_true')\n    parser.add_argument('--version',\n                        help=('print version number'),\n                        action='store_true')\n    parser.add_argument('--debug',\n                        help=('show logging output'),\n                        action='store_true')\n\n    return parser", "response": "Create an argument parser for command line usage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip(notebook):\n    for cell in notebook.cells:\n        if cell.cell_type == 'code':\n            cell.outputs = []\n            cell.execution_count = None", "response": "Remove outputs from a notebook."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving an id and a caption from a code cell.", "response": "def get_caption_comments(content):\n    \"\"\"Retrieve an id and a caption from a code cell.\n\n    If the code cell content begins with a commented\n    block that looks like\n\n    ## fig:id\n    # multi-line or single-line\n    # caption\n\n    then the 'fig:id' and the caption will be returned.\n    The '#' are stripped.\n    \"\"\"\n\n    if not content.startswith('## fig:'):\n        return None, None\n\n    content = content.splitlines()\n\n    id = content[0].strip('## ')\n\n    caption = []\n    for line in content[1:]:\n        if not line.startswith('# ') or line.startswith('##'):\n            break\n        else:\n            caption.append(line.lstrip('# ').rstrip())\n\n    # add \" around the caption. TODO: consider doing this upstream\n    # in pandoc-attributes\n    caption = '\"' + ' '.join(caption) + '\"'\n    return id, caption"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_code_block(self, **kwargs):\n        proto = {'content': '',\n                 'type': self.code,\n                 'IO': '',\n                 'attributes': ''}\n        proto.update(**kwargs)\n        return proto", "response": "Create a new code block."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_text_block(self, **kwargs):\n        proto = {'content': '', 'type': self.markdown}\n        proto.update(**kwargs)\n        return proto", "response": "Create a new text block."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a single code block.", "response": "def process_code_block(self, block):\n        \"\"\"Parse block attributes\"\"\"\n        if block['type'] != self.code:\n            return block\n\n        attr = PandocAttributes(block['attributes'], 'markdown')\n\n        if self.match == 'all':\n            pass\n\n        elif self.match == 'fenced' and block.get('indent'):\n            return self.new_text_block(content=('\\n' +\n                                                block['icontent'] +\n                                                '\\n'))\n\n        elif self.match == 'strict' and 'input' not in attr.classes:\n            return self.new_text_block(content=block['raw'])\n\n        elif self.match not in list(attr.classes) + ['fenced', 'strict']:\n            return self.new_text_block(content=block['raw'])\n\n        # set input / output status of cell\n        if 'output' in attr.classes and 'json' in attr.classes:\n            block['IO'] = 'output'\n        elif 'input' in attr.classes:\n            block['IO'] = 'input'\n            attr.classes.remove('input')\n        else:\n            block['IO'] = 'input'\n\n        if self.caption_comments:\n            # override attributes id and caption with those set in\n            # comments, if they exist\n            id, caption = get_caption_comments(block['content'])\n            if id:\n                attr.id = id\n            if caption:\n                attr['caption'] = caption\n\n        try:\n            # determine the language as the first class that\n            # is in the block attributes and also in the list\n            # of languages\n            language = set(attr.classes).intersection(languages).pop()\n            attr.classes.remove(language)\n        except KeyError:\n            language = None\n\n        block['language'] = language\n        block['attributes'] = attr\n\n        # ensure one identifier for python code\n        if language in ('python', 'py', '', None):\n            block['language'] = self.python\n        # add alternate language execution magic\n        elif language != self.python and self.magic:\n            block['content'] = CodeMagician.magic(language) + block['content']\n            block['language'] = language\n\n        return self.new_code_block(**block)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_blocks(self, text):\n        code_matches = [m for m in self.code_pattern.finditer(text)]\n\n        # determine where the limits of the non code bits are\n        # based on the code block edges\n        text_starts = [0] + [m.end() for m in code_matches]\n        text_stops = [m.start() for m in code_matches] + [len(text)]\n        text_limits = list(zip(text_starts, text_stops))\n\n        # list of the groups from the code blocks\n        code_blocks = [self.new_code_block(**m.groupdict())\n                       for m in code_matches]\n\n        text_blocks = [self.new_text_block(content=text[i:j])\n                       for i, j in text_limits]\n\n        # remove indents\n        list(map(self.pre_process_code_block, code_blocks))\n        # remove blank line at start and end of markdown\n        list(map(self.pre_process_text_block, text_blocks))\n\n        # create a list of the right length\n        all_blocks = list(range(len(text_blocks) + len(code_blocks)))\n\n        # NOTE: the behaviour here is a bit fragile in that we\n        # assume that cells must alternate between code and\n        # markdown. This isn't the case, as we could have\n        # consecutive code cells, and we get around this by\n        # stripping out empty cells. i.e. two consecutive code cells\n        # have an empty markdown cell between them which is stripped\n        # out because it is empty.\n\n        # cells must alternate in order\n        all_blocks[::2] = text_blocks\n        all_blocks[1::2] = code_blocks\n\n        # remove possible empty text cells\n        all_blocks = [cell for cell in all_blocks if cell['content']]\n\n        return all_blocks", "response": "Extract the code and non - code blocks from given markdown text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_code_cell(block):\n        code_cell = nbbase.new_code_cell(source=block['content'])\n\n        attr = block['attributes']\n        if not attr.is_empty:\n            code_cell.metadata \\\n                = nbbase.NotebookNode({'attributes': attr.to_dict()})\n            execution_count = attr.kvs.get('n')\n            if not execution_count:\n                code_cell.execution_count = None\n            else:\n                code_cell.execution_count = int(execution_count)\n\n        return code_cell", "response": "Create a notebook code cell from a block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_markdown_cell(block):\n        kwargs = {'cell_type': block['type'],\n                  'source': block['content']}\n        markdown_cell = nbbase.new_markdown_cell(**kwargs)\n        return markdown_cell", "response": "Create a markdown cell from a block."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn the list of blocks into a list of notebook cells.", "response": "def create_cells(self, blocks):\n        \"\"\"Turn the list of blocks into a list of notebook cells.\"\"\"\n        cells = []\n        for block in blocks:\n            if (block['type'] == self.code) and (block['IO'] == 'input'):\n                code_cell = self.create_code_cell(block)\n                cells.append(code_cell)\n\n            elif (block['type'] == self.code and\n                  block['IO'] == 'output' and\n                  cells[-1].cell_type == 'code'):\n                cells[-1].outputs = self.create_outputs(block)\n\n            elif block['type'] == self.markdown:\n                markdown_cell = self.create_markdown_cell(block)\n                cells.append(markdown_cell)\n\n            else:\n                raise NotImplementedError(\"{} is not supported as a cell\"\n                                          \"type\".format(block['type']))\n\n        return cells"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_notebook(self, s, **kwargs):\n        all_blocks = self.parse_blocks(s)\n        if self.pre_code_block['content']:\n            # TODO: if first block is markdown, place after?\n            all_blocks.insert(0, self.pre_code_block)\n\n        blocks = [self.process_code_block(block) for block in all_blocks]\n\n        cells = self.create_cells(blocks)\n\n        nb = nbbase.new_notebook(cells=cells)\n\n        return nb", "response": "Convert the markdown string s to an IPython notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_resources(self, resources):\n        for filename, data in list(resources.get('outputs', {}).items()):\n            # Determine where to write the file to\n            dest = os.path.join(self.output_dir, filename)\n            path = os.path.dirname(dest)\n            if path and not os.path.isdir(path):\n                os.makedirs(path)\n\n            # Write file\n            with open(dest, 'wb') as f:\n                f.write(data)", "response": "Write the output data in resources returned by exporter\n            to files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert json into its string representation.", "response": "def string2json(self, string):\n        \"\"\"Convert json into its string representation.\n        Used for writing outputs to markdown.\"\"\"\n        kwargs = {\n            'cls': BytesEncoder,  # use the IPython bytes encoder\n            'indent': 1,\n            'sort_keys': True,\n            'separators': (',', ': '),\n        }\n        return cast_unicode(json.dumps(string, **kwargs), 'utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_attributes(self, cell, cell_type=None):\n        if self.strip_outputs or not hasattr(cell, 'execution_count'):\n            return 'python'\n\n        attrs = cell.metadata.get('attributes')\n        attr = PandocAttributes(attrs, 'dict')\n\n        if 'python' in attr.classes:\n            attr.classes.remove('python')\n        if 'input' in attr.classes:\n            attr.classes.remove('input')\n\n        if cell_type == 'figure':\n            attr.kvs.pop('caption', '')\n            attr.classes.append('figure')\n            attr.classes.append('output')\n            return attr.to_html()\n\n        elif cell_type == 'input':\n            # ensure python goes first so that github highlights it\n            attr.classes.insert(0, 'python')\n            attr.classes.insert(1, 'input')\n            if cell.execution_count:\n                attr.kvs['n'] = cell.execution_count\n            return attr.to_markdown(format='{classes} {id} {kvs}')\n\n        else:\n            return attr.to_markdown()", "response": "Turn the attribute dict into an attribute string for the code block."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving excess quotes from a string.", "response": "def dequote(s):\n        \"\"\"Remove excess quotes from a string.\"\"\"\n        if len(s) < 2:\n            return s\n        elif (s[0] == s[-1]) and s.startswith(('\"', \"'\")):\n            return s[1: -1]\n        else:\n            return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data2uri(data, data_type):\n        MIME_MAP = {\n            'image/jpeg': 'jpeg',\n            'image/png': 'png',\n            'text/plain': 'text',\n            'text/html': 'html',\n            'text/latex': 'latex',\n            'application/javascript': 'html',\n            'image/svg+xml': 'svg',\n        }\n        inverse_map = {v: k for k, v in list(MIME_MAP.items())}\n        mime_type = inverse_map[data_type]\n        uri = r\"data:{mime};base64,{data}\"\n        return uri.format(mime=mime_type,\n                          data=data[mime_type].replace('\\n', ''))", "response": "Convert base64 data into a data uri with the given data_type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef magic(self, alias):\n        if alias in self.aliases:\n            return self.aliases[alias]\n        else:\n            return \"%%{}\\n\".format(alias)", "response": "Returns the appropriate IPython code magic when\n        called with an alias for a language."}
