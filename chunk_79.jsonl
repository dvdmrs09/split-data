{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_mpraw(mpv, npv):\n\n    globals()[mpv] = mpraw_as_np(npv.shape, npv.dtype)\n    globals()[mpv][:] = npv", "response": "Set a global variable as a multiprocessing RawArray in shared\n    memory with a numpy array wrapper and initialise its value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cbpdn_setdict():\n\n    global mp_DSf\n    # Set working dictionary for cbpdn step and compute DFT of dictionary\n    # D and of D^T S\n    mp_Df[:] = sl.rfftn(mp_D_Y, mp_cri.Nv, mp_cri.axisN)\n    if mp_cri.Cd == 1:\n        mp_DSf[:] = np.conj(mp_Df) * mp_Sf\n    else:\n        mp_DSf[:] = sl.inner(np.conj(mp_Df[np.newaxis, ...]), mp_Sf,\n                              axis=mp_cri.axisC+1)", "response": "Set the dictionary for the cbpdn stage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cbpdn_xstep(k):\n\n    YU = mp_Z_Y[k] - mp_Z_U[k]\n    b = mp_DSf[k] + mp_xrho * sl.rfftn(YU, None, mp_cri.axisN)\n    if mp_cri.Cd == 1:\n        Xf = sl.solvedbi_sm(mp_Df, mp_xrho, b, axis=mp_cri.axisM)\n    else:\n        Xf = sl.solvemdbi_ism(mp_Df, mp_xrho, b, mp_cri.axisM, mp_cri.axisC)\n    mp_Z_X[k] = sl.irfftn(Xf, mp_cri.Nv, mp_cri.axisN)", "response": "Do the X step of the cbpdn stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrelax the cbpdn stage.", "response": "def cbpdn_relax(k):\n    \"\"\"Do relaxation for the cbpdn stage. The only parameter is the slice\n    index `k` and there are no return values; all inputs and outputs are\n    from and to global variables.\n    \"\"\"\n\n    mp_Z_X[k] = mp_xrlx * mp_Z_X[k] + (1 - mp_xrlx) * mp_Z_Y[k]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo the Y step of the cbpdn stage.", "response": "def cbpdn_ystep(k):\n    \"\"\"Do the Y step of the cbpdn stage. The only parameter is the slice\n    index `k` and there are no return values; all inputs and outputs are\n    from and to global variables.\n    \"\"\"\n\n    AXU = mp_Z_X[k] + mp_Z_U[k]\n    mp_Z_Y[k] = sp.prox_l1(AXU, (mp_lmbda/mp_xrho))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the coefficient maps for the ccmod stage.", "response": "def ccmod_setcoef(k):\n    \"\"\"Set the coefficient maps for the ccmod stage. The only parameter is\n    the slice index `k` and there are no return values; all inputs and\n    outputs are from and to global variables.\n    \"\"\"\n\n    # Set working coefficient maps for ccmod step and compute DFT of\n    # coefficient maps Z and Z^T S\n    mp_Zf[k] = sl.rfftn(mp_Z_Y[k], mp_cri.Nv, mp_cri.axisN)\n    mp_ZSf[k] = np.conj(mp_Zf[k]) * mp_Sf[k]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ccmod_xstep(k):\n\n    YU = mp_D_Y - mp_D_U[k]\n    b = mp_ZSf[k] + mp_drho * sl.rfftn(YU, None, mp_cri.axisN)\n    Xf = sl.solvedbi_sm(mp_Zf[k], mp_drho, b, axis=mp_cri.axisM)\n    mp_D_X[k] = sl.irfftn(Xf, mp_cri.Nv, mp_cri.axisN)", "response": "Do the X step of the ccmod stage."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ccmod_ystep():\n\n    mAXU = np.mean(mp_D_X + mp_D_U, axis=0)\n    mp_D_Y[:] = mp_dprox(mAXU)", "response": "Do the Y step of the ccmod stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing a single iteration over cbpdn and ccmod steps that can be performed independently for each slice k of the input data set.", "response": "def step_group(k):\n    \"\"\"Do a single iteration over cbpdn and ccmod steps that can be\n    performed independently for each slice `k` of the input data set.\n    \"\"\"\n\n    cbpdn_xstep(k)\n    if mp_xrlx != 1.0:\n        cbpdn_relax(k)\n    cbpdn_ystep(k)\n    cbpdn_ustep(k)\n    ccmod_setcoef(k)\n    ccmod_xstep(k)\n    if mp_drlx != 1.0:\n        ccmod_relax(k)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cbpdnmd_xstep(k):\n\n    YU0 = mp_Z_Y0[k] + mp_S[k] - mp_Z_U0[k]\n    YU1 = mp_Z_Y1[k] - mp_Z_U1[k]\n    if mp_cri.Cd == 1:\n        b = np.conj(mp_Df) * sl.rfftn(YU0, None, mp_cri.axisN) + \\\n            sl.rfftn(YU1, None, mp_cri.axisN)\n        Xf = sl.solvedbi_sm(mp_Df, 1.0, b, axis=mp_cri.axisM)\n    else:\n        b = sl.inner(np.conj(mp_Df), sl.rfftn(YU0, None, mp_cri.axisN),\n                      axis=mp_cri.axisC) + \\\n            sl.rfftn(YU1, None, mp_cri.axisN)\n        Xf = sl.solvemdbi_ism(mp_Df, 1.0, b, mp_cri.axisM, mp_cri.axisC)\n    mp_Z_X[k] = sl.irfftn(Xf, mp_cri.Nv, mp_cri.axisN)\n    mp_DX[k] = sl.irfftn(sl.inner(mp_Df, Xf), mp_cri.Nv, mp_cri.axisN)", "response": "Do the X step of the cbpdn stage."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cbpdnmd_relax(k):\n\n    mp_Z_X[k] = mp_xrlx * mp_Z_X[k] + (1 - mp_xrlx) * mp_Z_Y1[k]\n    mp_DX[k] = mp_xrlx * mp_DX[k] + (1 - mp_xrlx) * (mp_Z_Y0[k] + mp_S[k])", "response": "Do relaxation for the cbpdn stage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cbpdnmd_ystep(k):\n\n    if mp_W.shape[0] > 1:\n        W = mp_W[k]\n    else:\n        W = mp_W\n    AXU0 = mp_DX[k] - mp_S[k] + mp_Z_U0[k]\n    AXU1 = mp_Z_X[k] + mp_Z_U1[k]\n    mp_Z_Y0[k] = mp_xrho*AXU0 / (W**2 + mp_xrho)\n    mp_Z_Y1[k] = sp.prox_l1(AXU1, (mp_lmbda/mp_xrho))", "response": "Do the Y step of the cbpdn stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo the U step of the cbpdn stage.", "response": "def cbpdnmd_ustep(k):\n    \"\"\"Do the U step of the cbpdn stage. The only parameter is the slice\n    index `k` and there are no return values; all inputs and outputs are\n    from and to global variables.\n    \"\"\"\n\n    mp_Z_U0[k] += mp_DX[k] - mp_Z_Y0[k] - mp_S[k]\n    mp_Z_U1[k] += mp_Z_X[k] - mp_Z_Y1[k]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ccmodmd_setcoef(k):\n\n    # Set working coefficient maps for ccmod step and compute DFT of\n    # coefficient maps Z\n    mp_Zf[k] = sl.rfftn(mp_Z_Y1[k], mp_cri.Nv, mp_cri.axisN)", "response": "Set the coefficient maps for the ccmod stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing the X step of the ccmod stage.", "response": "def ccmodmd_xstep(k):\n    \"\"\"Do the X step of the ccmod stage. The only parameter is the slice\n    index `k` and there are no return values; all inputs and outputs are\n    from and to global variables.\n    \"\"\"\n\n    YU0 = mp_D_Y0 - mp_D_U0[k]\n    YU1 = mp_D_Y1[k] + mp_S[k] - mp_D_U1[k]\n    b = sl.rfftn(YU0, None, mp_cri.axisN) + \\\n      np.conj(mp_Zf[k]) * sl.rfftn(YU1, None, mp_cri.axisN)\n    Xf = sl.solvedbi_sm(mp_Zf[k], 1.0, b, axis=mp_cri.axisM)\n    mp_D_X[k] = sl.irfftn(Xf, mp_cri.Nv, mp_cri.axisN)\n    mp_DX[k] = sl.irfftn(sl.inner(Xf, mp_Zf[k]), mp_cri.Nv, mp_cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ccmodmd_relax(k):\n\n    mp_D_X[k] = mp_drlx * mp_D_X[k] + (1 - mp_drlx) * mp_D_Y0\n    mp_DX[k] = mp_drlx * mp_DX[k] + (1 - mp_drlx) * (mp_D_Y1[k] + mp_S[k])", "response": "Do relaxation for the ccmod stage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo the Y step of the ccmod stage.", "response": "def ccmodmd_ystep():\n    \"\"\"Do the Y step of the ccmod stage. There are no parameters\n    or return values because all inputs and outputs are from and to\n    global variables.\n    \"\"\"\n\n    mAXU = np.mean(mp_D_X + mp_D_U0, axis=0)\n    mp_D_Y0[:] = mp_dprox(mAXU)\n    AXU1 = mp_DX - mp_S + mp_D_U1\n    mp_D_Y1[:] = mp_drho*AXU1 / (mp_W**2 + mp_drho)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo a single iteration over cbpdn and ccmod steps that can be performed independently for each slice k of the input data set.", "response": "def md_step_group(k):\n    \"\"\"Do a single iteration over cbpdn and ccmod steps that can be\n    performed independently for each slice `k` of the input data set.\n    \"\"\"\n\n    cbpdnmd_xstep(k)\n    if mp_xrlx != 1.0:\n        cbpdnmd_relax(k)\n    cbpdnmd_ystep(k)\n    cbpdnmd_ustep(k)\n    ccmodmd_setcoef(k)\n    ccmodmd_xstep(k)\n    if mp_drlx != 1.0:\n        ccmodmd_relax(k)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef step(self):\n\n        # If the nproc parameter of __init__ is zero, just iterate\n        # over the K consensus instances instead of using\n        # multiprocessing to do the computations in parallel. This is\n        # useful for debugging and timing comparisons.\n        if self.nproc == 0:\n            for k in range(self.xstep.cri.K):\n                step_group(k)\n        else:\n            self.pool.map(step_group, range(self.xstep.cri.K))\n\n        ccmod_ystep()\n        ccmod_ustep()\n        cbpdn_setdict()", "response": "Do a single iteration over all cbpdn and ccmod steps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solve(self):\n\n        # Construct tuple of status display column titles and set status\n        # display strings\n        hdrtxt = ['Itn', 'Fnc', 'DFid', u('Reg\u21131')]\n        hdrstr, fmtstr, nsep = common.solve_status_str(\n            hdrtxt, fwdth0=type(self).fwiter, fprec=type(self).fpothr)\n\n        # Print header and separator strings\n        if self.opt['Verbose']:\n            if self.opt['StatusHeader']:\n                print(hdrstr)\n                print(\"-\" * nsep)\n\n        # Reset timer\n        self.timer.start(['solve', 'solve_wo_eval'])\n\n        # Create process pool\n        if self.nproc > 0:\n            self.pool = mp.Pool(processes=self.nproc)\n\n        for self.j in range(self.j, self.j + self.opt['MaxMainIter']):\n\n            # Perform a set of update steps\n            self.step()\n\n            # Evaluate functional\n            self.timer.stop('solve_wo_eval')\n            fnev = self.evaluate()\n            self.timer.start('solve_wo_eval')\n\n            # Record iteration stats\n            tk = self.timer.elapsed('solve')\n            itst = self.IterationStats(*((self.j,) + fnev + (tk,)))\n            self.itstat.append(itst)\n\n            # Display iteration stats if Verbose option enabled\n            if self.opt['Verbose']:\n                print(fmtstr % itst[:-1])\n\n            # Call callback function if defined\n            if self.opt['Callback'] is not None:\n                if self.opt['Callback'](self):\n                    break\n\n        # Clean up process pool\n        if self.nproc > 0:\n            self.pool.close()\n            self.pool.join()\n\n        # Increment iteration count\n        self.j += 1\n\n        # Record solve time\n        self.timer.stop(['solve', 'solve_wo_eval'])\n\n        # Print final separator string if Verbose option enabled\n        if self.opt['Verbose'] and self.opt['StatusHeader']:\n            print(\"-\" * nsep)\n\n        # Return final dictionary\n        return self.getdict()", "response": "Start or re - start the optimisation of the a\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getcoef(self):\n\n        global mp_Z_Y\n        return np.swapaxes(mp_Z_Y, 0, self.xstep.cri.axisK+1)[0]", "response": "Get final coefficient map array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evaluate(self):\n\n        X = mp_Z_Y\n        Xf = mp_Zf\n        Df = mp_Df\n        Sf = mp_Sf\n        Ef = sl.inner(Df[np.newaxis, ...], Xf,\n                       axis=self.xstep.cri.axisM+1) - Sf\n        Ef = np.swapaxes(Ef, 0, self.xstep.cri.axisK+1)[0]\n        dfd = sl.rfl2norm2(Ef, self.xstep.S.shape,\n                            axis=self.xstep.cri.axisN)/2.0\n        rl1 = np.sum(np.abs(X))\n        obj = dfd + self.xstep.lmbda*rl1\n        return (obj, dfd, rl1)", "response": "Evaluate functional value of previous iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes a single iteration over all cbpdn and ccmod steps.", "response": "def step(self):\n        \"\"\"Do a single iteration over all cbpdn and ccmod steps. Those that\n        are not coupled on the K axis are performed in parallel.\"\"\"\n\n        # If the nproc parameter of __init__ is zero, just iterate\n        # over the K consensus instances instead of using\n        # multiprocessing to do the computations in parallel. This is\n        # useful for debugging and timing comparisons.\n        if self.nproc == 0:\n            for k in range(self.xstep.cri.K):\n                md_step_group(k)\n        else:\n            self.pool.map(md_step_group, range(self.xstep.cri.K))\n\n        ccmodmd_ystep()\n        ccmodmd_ustep()\n        cbpdnmd_setdict()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting final dictionary. If ``crop`` is ``True``, apply :func:`.cnvrep.bcrop` to returned array.", "response": "def getdict(self, crop=True):\n        \"\"\"Get final dictionary. If ``crop`` is ``True``, apply\n        :func:`.cnvrep.bcrop` to returned array.\n        \"\"\"\n\n        global mp_D_Y0\n        D = mp_D_Y0\n        if crop:\n            D = cr.bcrop(D, self.dstep.cri.dsz, self.dstep.cri.dimN)\n        return D"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getcoef(self):\n\n        global mp_Z_Y1\n        return np.swapaxes(mp_Z_Y1, 0, self.xstep.cri.axisK+1)[0]", "response": "Get final coefficient map array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evaluate(self):\n\n        if self.opt['AccurateDFid']:\n            DX = self.reconstruct()\n            W = self.dstep.W\n            S = self.dstep.S\n        else:\n            W = mp_W\n            S = mp_S\n            Xf = mp_Zf\n            Df = mp_Df\n            DX = sl.irfftn(sl.inner(\n                Df[np.newaxis, ...], Xf, axis=self.xstep.cri.axisM+1),\n                            self.xstep.cri.Nv,\n                            np.array(self.xstep.cri.axisN) + 1)\n\n        dfd = (np.linalg.norm(W * (DX - S))**2) / 2.0\n        rl1 = np.sum(np.abs(self.getcoef()))\n        obj = dfd + self.xstep.lmbda*rl1\n\n        return (obj, dfd, rl1)", "response": "Evaluate functional value of previous iteration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npatching version of : func : pyspo. adm. ADE. update_rho.", "response": "def _update_rho(self, k, r, s):\n    \"\"\"\n    Patched version of :func:`sporco.admm.admm.ADMM.update_rho`.\"\"\"\n\n    if self.opt['AutoRho', 'Enabled']:\n        tau = self.rho_tau\n        mu = self.rho_mu\n        xi = self.rho_xi\n        if k != 0 and cp.mod(k + 1, self.opt['AutoRho', 'Period']) == 0:\n            if self.opt['AutoRho', 'AutoScaling']:\n                if s == 0.0 or r == 0.0:\n                    rhomlt = tau\n                else:\n                    rhomlt = cp.sqrt(r / (s * xi) if r > s * xi\n                                     else (s * xi) / r)\n                    if rhomlt > tau:\n                        rhomlt = tau\n            else:\n                rhomlt = tau\n            rsf = 1.0\n            if r > xi * mu * s:\n                rsf = rhomlt\n            elif s > (mu / xi) * r:\n                rsf = 1.0 / rhomlt\n            self.rho *= float(rsf)\n            self.U /= rsf\n            if rsf != 1.0:\n                self.rhochange()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_grad(self):\n\n        # Compute D^T(D Y - S)\n        return self.D.T.dot(self.D.dot(self.Y) - self.S)", "response": "Compute gradient in spatial domain for variable Y."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval_proxop(self, V):\n\n        return np.asarray(sp.prox_l1(V, (self.lmbda / self.L) * self.wl1),\n                          dtype=self.dtype)", "response": "Compute proximal operator of g."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute fixed point residual.", "response": "def rsdl(self):\n        \"\"\"Compute fixed point residual.\"\"\"\n\n        return np.linalg.norm((self.X - self.Yprv).ravel())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval_objfn(self):\n\n        dfd = self.obfn_f()\n        reg = self.obfn_reg()\n        obj = dfd + reg[0]\n        return (obj, dfd) + reg[1:]", "response": "Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_grad(self):\n\n        # Compute D X - S\n        Ryf = self.eval_Rf(self.Yf)\n        # Compute D^H Ryf\n        gradf = np.conj(self.Df) * Ryf\n\n        # Multiple channel signal, multiple channel dictionary\n        if self.cri.Cd > 1:\n            gradf = np.sum(gradf, axis=self.cri.axisC, keepdims=True)\n\n        return gradf", "response": "Compute gradient in Fourier domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates smooth term in Vf.", "response": "def eval_Rf(self, Vf):\n        \"\"\"Evaluate smooth term in Vf.\"\"\"\n\n        return sl.inner(self.Df, Vf, axis=self.cri.axisM) - self.Sf"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes proximal operator of g.", "response": "def eval_proxop(self, V):\n        \"\"\"Compute proximal operator of :math:`g`.\"\"\"\n\n        return sp.prox_l1(V, (self.lmbda / self.L) * self.wl1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_objfn(self):\n\n        dfd = self.obfn_dfd()\n        reg = self.obfn_reg()\n        obj = dfd + reg[0]\n        return (obj, dfd) + reg[1:]", "response": "Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreconstruct representation of the object.", "response": "def reconstruct(self, X=None):\n        \"\"\"Reconstruct representation.\"\"\"\n\n        if X is None:\n            X = self.X\n        Xf = sl.rfftn(X, None, self.cri.axisN)\n        Sf = np.sum(self.Df * Xf, axis=self.cri.axisM)\n        return sl.irfftn(Sf, self.cri.Nv, self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes gradient in Fourier domain.", "response": "def eval_grad(self):\n        \"\"\"Compute gradient in Fourier domain.\"\"\"\n\n        # Compute D X - S\n        self.Ryf[:] = self.eval_Rf(self.Yf)\n\n        # Map to spatial domain to multiply by mask\n        Ry = sl.irfftn(self.Ryf, self.cri.Nv, self.cri.axisN)\n        # Multiply by mask\n        self.WRy[:] = (self.W**2) * Ry\n        # Map back to frequency domain\n        WRyf = sl.rfftn(self.WRy, self.cri.Nv, self.cri.axisN)\n\n        gradf = np.conj(self.Df) * WRyf\n\n        # Multiple channel signal, multiple channel dictionary\n        if self.cri.Cd > 1:\n            gradf = np.sum(gradf, axis=self.cri.axisC, keepdims=True)\n\n        return gradf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stdformD(D, Cd, M, dimN=2):\n\n    return D.reshape(D.shape[0:dimN] + (Cd,) + (1,) + (M,))", "response": "Reshapes a dictionary array to internal standard form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef l1Wshape(W, cri):\n\n    # Number of dimensions in input array `S`\n    sdim = cri.dimN + cri.dimC + cri.dimK\n\n    if W.ndim < sdim:\n        if W.size == 1:\n            # Weight array is a scalar\n            shpW = (1,) * (cri.dimN + 3)\n        else:\n            # Invalid weight array shape\n            raise ValueError('weight array must be scalar or have at least '\n                             'the same number of dimensions as input array')\n    elif W.ndim == sdim:\n        # Weight array has the same number of dimensions as the input array\n        shpW = W.shape + (1,) * (3 - cri.dimC - cri.dimK)\n    else:\n        # Weight array has more dimensions than the input array\n        if W.ndim == cri.dimN + 3:\n            # Weight array is already of the appropriate shape\n            shpW = W.shape\n        else:\n            # Assume that the final axis in the input array is the filter\n            # index\n            shpW = W.shape[0:-1] + (1,) * (2 - cri.dimC - cri.dimK) + \\\n                W.shape[-1:]\n\n    return shpW", "response": "r Returns the shape of an L1 norm weight array W as defined by the input array W and the given convolutional representation dimensions cri."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mskWshape(W, cri):\n\n    # Number of axes in W available for C and/or K axes\n    ckdim = W.ndim - cri.dimN\n    if ckdim >= 2:\n        # Both C and K axes are present in W\n        shpW = W.shape + (1,) if ckdim == 2 else W.shape\n    elif ckdim == 1:\n        # Exactly one of C or K axes is present in W\n        if cri.C == 1 and cri.K > 1:\n            # Input S has a single channel and multiple signals\n            shpW = W.shape[0:cri.dimN] + (1, W.shape[cri.dimN]) + (1,)\n        elif cri.C > 1 and cri.K == 1:\n            # Input S has multiple channels and a single signal\n            shpW = W.shape[0:cri.dimN] + (W.shape[cri.dimN], 1) + (1,)\n        else:\n            # Input S has multiple channels and signals: resolve ambiguity\n            # by taking extra axis in W as a channel axis\n            shpW = W.shape[0:cri.dimN] + (W.shape[cri.dimN], 1) + (1,)\n    else:\n        # Neither C nor K axis is present in W\n        shpW = W.shape + (1,) * (3 - ckdim)\n\n    return shpW", "response": "Returns the internal shape of the internal array of the specified data fidelity term mask array W."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubtract mean value from each filter in the input array v.", "response": "def zeromean(v, dsz, dimN=2):\n    \"\"\"Subtract mean value from each filter in the input array v. The\n    `dsz` parameter specifies the support sizes of each filter using the\n    same format as the `dsz` parameter of :func:`bcrop`. Support sizes\n    must be taken into account to ensure that the mean values are\n    computed over the correct number of samples, ignoring the\n    zero-padded region in which the filter is embedded.\n\n    Parameters\n    ----------\n    v : array_like\n      Input dictionary array\n    dsz : tuple\n      Filter support size(s)\n    dimN : int, optional (default 2)\n      Number of spatial dimensions\n\n    Returns\n    -------\n    vz : ndarray\n      Dictionary array with filter means subtracted\n    \"\"\"\n\n    vz = v.copy()\n    if isinstance(dsz[0], tuple):\n        # Multi-scale dictionary specification\n        axisN = tuple(range(0, dimN))\n        m0 = 0  # Initial index of current block of equi-sized filters\n        # Iterate over distinct filter sizes\n        for mb in range(0, len(dsz)):\n            # Determine end index of current block of filters\n            if isinstance(dsz[mb][0], tuple):\n                m1 = m0 + dsz[mb][0][-1]\n                c0 = 0  # Init. idx. of current chnl-block of equi-sized flt.\n                for cb in range(0, len(dsz[mb])):\n                    c1 = c0 + dsz[mb][cb][-2]\n                    # Construct slice corresponding to cropped part of\n                    # current block of filters in output array and set from\n                    # input array\n                    cbslc = tuple([slice(0, x) for x in dsz[mb][cb][0:dimN]]\n                                  ) + (slice(c0, c1),) + (Ellipsis,) + \\\n                                      (slice(m0, m1),)\n                    vz[cbslc] -= np.mean(v[cbslc], axisN)\n                    c0 = c1  # Update initial index for start of next block\n            else:\n                m1 = m0 + dsz[mb][-1]\n                # Construct slice corresponding to cropped part of\n                # current block of filters in output array and set from\n                # input array\n                mbslc = tuple([slice(0, x) for x in dsz[mb][0:-1]]\n                              ) + (Ellipsis,) + (slice(m0, m1),)\n                vz[mbslc] -= np.mean(v[mbslc], axisN)\n            m0 = m1  # Update initial index for start of next block\n    else:\n        # Single scale dictionary specification\n        axisN = tuple(range(0, dimN))\n        axnslc = tuple([slice(0, x) for x in dsz[0:dimN]])\n        vz[axnslc] -= np.mean(v[axnslc], axisN)\n\n    return vz"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zpad(v, Nv):\n\n    vp = np.zeros(Nv + v.shape[len(Nv):], dtype=v.dtype)\n    axnslc = tuple([slice(0, x) for x in v.shape])\n    vp[axnslc] = v\n    return vp", "response": "Zero - pad initial axes of array to specified size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bcrop(v, dsz, dimN=2):\n\n    if isinstance(dsz[0], tuple):\n        # Multi-scale dictionary specification\n        maxsz = np.zeros((dimN,), dtype=int)  # Max. support size\n        # Iterate over dsz to determine max. support size\n        for mb in range(0, len(dsz)):\n            if isinstance(dsz[mb][0], tuple):\n                for cb in range(0, len(dsz[mb])):\n                    maxsz = np.maximum(maxsz, np.asarray(dsz[mb][cb][0:dimN]))\n            else:\n                maxsz = np.maximum(maxsz, np.asarray(dsz[mb][0:dimN]))\n        # Init. cropped array\n        vc = np.zeros(maxsz.tolist() + list(v.shape[dimN:]), dtype=v.dtype)\n        m0 = 0  # Initial index of current block of equi-sized filters\n        # Iterate over distinct filter sizes\n        for mb in range(0, len(dsz)):\n            # Determine end index of current block of filters\n            if isinstance(dsz[mb][0], tuple):\n                m1 = m0 + dsz[mb][0][-1]\n                c0 = 0  # Init. idx. of current chnl-block of equi-sized flt.\n                for cb in range(0, len(dsz[mb])):\n                    c1 = c0 + dsz[mb][cb][-2]\n                    # Construct slice corresponding to cropped part of\n                    # current block of filters in output array and set from\n                    # input array\n                    cbslc = tuple([slice(0, x) for x in dsz[mb][cb][0:dimN]]\n                                  ) + (slice(c0, c1),) + (Ellipsis,) + \\\n                                      (slice(m0, m1),)\n                    vc[cbslc] = v[cbslc]\n                    c0 = c1  # Update initial index for start of next block\n            else:\n                m1 = m0 + dsz[mb][-1]\n                # Construct slice corresponding to cropped part of\n                # current block of filters in output array and set from\n                # input array\n                mbslc = tuple([slice(0, x) for x in dsz[mb][0:-1]]\n                              ) + (Ellipsis,) + (slice(m0, m1),)\n                vc[mbslc] = v[mbslc]\n            m0 = m1  # Update initial index for start of next block\n        return vc\n    else:\n        # Single scale dictionary specification\n        axnslc = tuple([slice(0, x) for x in dsz[0:dimN]])\n        return v[axnslc]", "response": "Crop specified number of initial spatial dimensions of dictionary\n    array to specified size."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getPcn(dsz, Nv, dimN=2, dimC=1, crp=False, zm=False):\n\n    fncdict = {(False, False): _Pcn,\n               (False, True): _Pcn_zm,\n               (True, False): _Pcn_crp,\n               (True, True): _Pcn_zm_crp}\n    fnc = fncdict[(crp, zm)]\n    return functools.partial(fnc, dsz=dsz, Nv=Nv, dimN=dimN, dimC=dimC)", "response": "Construct the constraint set projection function for convolutional\n    dictionary update problem."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Pcn_zm_crp(x, dsz, Nv, dimN=2, dimC=1):\n\n    return normalise(zeromean(bcrop(x, dsz, dimN), dsz, dimN), dimN + dimC)", "response": "This function is used to create a constraint set for a single problem with ZM problem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a named tuple object to a NumPy array.", "response": "def ntpl2array(ntpl):\n    \"\"\"\n    Convert a :func:`collections.namedtuple` object to a :class:`numpy.ndarray`\n    object that can be saved using :func:`numpy.savez`.\n\n    Parameters\n    ----------\n    ntpl : collections.namedtuple object\n      Named tuple object to be converted to ndarray\n\n    Returns\n    -------\n    arr : ndarray\n      Array representation of input named tuple\n    \"\"\"\n\n    return np.asarray((np.hstack([col for col in ntpl]), ntpl._fields,\n                       ntpl.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a numpy. ndarray object constructed by ntpl2array to the original named tuple representation.", "response": "def array2ntpl(arr):\n    \"\"\"\n    Convert a :class:`numpy.ndarray` object constructed by :func:`ntpl2array`\n    back to the original :func:`collections.namedtuple` representation.\n\n    Parameters\n    ----------\n    arr : ndarray\n      Array representation of named tuple constructed by :func:`ntpl2array`\n\n    Returns\n    -------\n    ntpl : collections.namedtuple object\n      Named tuple object with the same name and fields as the original named\n      typle object provided to :func:`ntpl2array`\n    \"\"\"\n\n    cls = collections.namedtuple(arr[2], arr[1])\n    return cls(*tuple(arr[0]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transpose_ntpl_list(lst):\n\n    if not lst:\n        return None\n    else:\n        cls = collections.namedtuple(lst[0].__class__.__name__,\n                                     lst[0]._fields)\n        return cls(*[[lst[k][l] for k in range(len(lst))]\n                     for l in range(len(lst[0]))])", "response": "Transpose a list of named tuple objects into a\n    named tuple of lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct an image allowing visualization of dictionary content.", "response": "def tiledict(D, sz=None):\n    \"\"\"Construct an image allowing visualization of dictionary content.\n\n    Parameters\n    ----------\n    D : array_like\n      Dictionary matrix/array.\n    sz : tuple\n      Size of each block in dictionary.\n\n    Returns\n    -------\n    im : ndarray\n      Image tiled with dictionary entries.\n    \"\"\"\n\n    # Handle standard 2D (non-convolutional) dictionary\n    if D.ndim == 2:\n        D = D.reshape((sz + (D.shape[1],)))\n        sz = None\n    dsz = D.shape\n\n    if D.ndim == 4:\n        axisM = 3\n        szni = 3\n    else:\n        axisM = 2\n        szni = 2\n\n    # Construct dictionary atom size vector if not provided\n    if sz is None:\n        sz = np.tile(np.array(dsz[0:2]).reshape([2, 1]), (1, D.shape[axisM]))\n    else:\n        sz = np.array(sum(tuple((x[0:2],) * x[szni] for x in sz), ())).T\n\n    # Compute the maximum atom dimensions\n    mxsz = np.amax(sz, 1)\n\n    # Shift and scale values to [0, 1]\n    D = D - D.min()\n    D = D / D.max()\n\n    # Construct tiled image\n    N = dsz[axisM]\n    Vr = int(np.floor(np.sqrt(N)))\n    Vc = int(np.ceil(N / float(Vr)))\n    if D.ndim == 4:\n        im = np.ones((Vr*mxsz[0] + Vr - 1, Vc*mxsz[1] + Vc - 1, dsz[2]))\n    else:\n        im = np.ones((Vr*mxsz[0] + Vr - 1, Vc*mxsz[1] + Vc - 1))\n    k = 0\n    for l in range(0, Vr):\n        for m in range(0, Vc):\n            r = mxsz[0]*l + l\n            c = mxsz[1]*m + m\n            if D.ndim == 4:\n                im[r:(r+sz[0, k]), c:(c+sz[1, k]), :] = D[0:sz[0, k],\n                                                          0:sz[1, k], :, k]\n            else:\n                im[r:(r+sz[0, k]), c:(c+sz[1, k])] = D[0:sz[0, k],\n                                                       0:sz[1, k], k]\n            k = k + 1\n            if k >= N:\n                break\n        if k >= N:\n            break\n\n    return im"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a rolling version of the array x with the given window size and optional padding.", "response": "def rolling_window(x, wsz, wnm=None, pad='wrap'):\n    \"\"\"\n    Use :func:`numpy.lib.stride_tricks.as_strided` to construct a view\n    of the input array that represents different positions of a rolling\n    window as additional axes of the array. If the number of shifts\n    requested is such that the window extends beyond the boundary of the\n    input array, it is padded before the view is constructed. For\n    example, if ``x`` is 4 x 5 array, the output of\n    ``y = rolling_window(x, (3, 3))`` is a 3 x 3 x 2 x 3 array, with the\n    first window position indexed as ``y[..., 0, 0]``.\n\n    Parameters\n    ----------\n    x : ndarray\n      Input array\n    wsz : tuple\n      Window size\n    wnm : tuple, optional (default None)\n      Number of shifts of window on each axis. If None, the number of\n      shifts is set so that the end sample in the array is also the end\n      sample in the final window position.\n    pad : string, optional (default 'wrap')\n      A pad mode specification for :func:`numpy.pad`\n\n    Returns\n    -------\n    xw : ndarray\n      An array of shape wsz + wnm representing all requested shifts of\n      the window within the input array\n    \"\"\"\n\n    if wnm is None:\n        wnm = tuple(np.array(x.shape) - np.array(wsz) + 1)\n    else:\n        over = np.clip(np.array(wsz) + np.array(wnm) - np.array(x.shape) - 1,\n                       0, np.iinfo(int).max)\n        if np.any(over > 0):\n            psz = [(0, p) for p in over]\n            x = np.pad(x, psz, mode=pad)\n    outsz = wsz + wnm\n    outstrd = x.strides + x.strides\n    return np.lib.stride_tricks.as_strided(x, outsz, outstrd)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing :func:`numpy.lib.stride_tricks.as_strided` to construct a view of the input array that represents a subsampling of the array by the specified step, with different offsets of the subsampling as additional axes of the array. If the input array shape is not evenly divisible by the subsampling step, it is padded before the view is constructed. For example, if ``x`` is 6 x 6 array, the output of ``y = subsample_array(x, (2, 2))`` is a 2 x 2 x 3 x 3 array, with the first subsampling offset indexed as ``y[0, 0]``. Parameters ---------- x : ndarray Input array step : tuple Subsampling step size pad : bool, optional (default False) Flag indicating whether the input array should be padded when its size is not integer divisible by the step size mode : string, optional (default 'reflect') A pad mode specification for :func:`numpy.pad` Returns ------- xs : ndarray An array representing different subsampling offsets in the input array", "response": "def subsample_array(x, step, pad=False, mode='reflect'):\n    \"\"\"\n    Use :func:`numpy.lib.stride_tricks.as_strided` to construct a view\n    of the input array that represents a subsampling of the array by the\n    specified step, with different offsets of the subsampling as\n    additional axes of the array. If the input array shape is not evenly\n    divisible by the subsampling step, it is padded before the view\n    is constructed. For example, if ``x`` is 6 x 6 array, the output of\n    ``y = subsample_array(x, (2, 2))`` is a 2 x 2 x 3 x 3 array, with\n    the first subsampling offset indexed as ``y[0, 0]``.\n\n    Parameters\n    ----------\n    x : ndarray\n      Input array\n    step : tuple\n      Subsampling step size\n    pad : bool, optional (default False)\n      Flag indicating whether the input array should be padded\n      when its size is not integer divisible by the step size\n    mode : string, optional (default 'reflect')\n      A pad mode specification for :func:`numpy.pad`\n\n    Returns\n    -------\n    xs : ndarray\n      An array representing different subsampling offsets in the input\n      array\n    \"\"\"\n\n    if np.any(np.greater_equal(step, x.shape)):\n        raise ValueError('Step size must be less than array size on each axis')\n    sbsz, dvmd = np.divmod(x.shape, step)\n    if pad and np.any(dvmd):\n        sbsz += np.clip(dvmd, 0, 1)\n        psz = np.subtract(np.multiply(sbsz, step), x.shape)\n        pdt = [(0, p) for p in psz]\n        x = np.pad(x, pdt, mode=mode)\n    outsz = step + tuple(sbsz)\n    outstrd = x.strides + tuple(np.multiply(step, x.strides))\n    return np.lib.stride_tricks.as_strided(x, outsz, outstrd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract blocks from an ndarray signal into an ndarray.", "response": "def extractblocks(img, blksz, stpsz=None):\n    \"\"\"Extract blocks from an ndarray signal into an ndarray.\n\n    Parameters\n    ----------\n    img : ndarray or tuple of ndarrays\n      nd array of images, or tuple of images\n    blksz : tuple\n      tuple of block sizes, blocks are taken starting from the first index\n      of img\n    stpsz : tuple, optional (default None, corresponds to steps of 1)\n      tuple of step sizes between neighboring blocks\n\n    Returns\n    -------\n    blks : ndarray\n      image blocks\n    \"\"\"\n\n    # See http://stackoverflow.com/questions/16774148 and\n    # sklearn.feature_extraction.image.extract_patches_2d\n    if isinstance(img, tuple):\n        img = np.stack(img, axis=-1)\n\n    if stpsz is None:\n        stpsz = (1,) * len(blksz)\n\n    imgsz = img.shape\n\n    # Calculate the number of blocks that can fit in each dimension of\n    # the images\n    numblocks = tuple(int(np.floor((a - b) / c) + 1) for a, b, c in\n                      zip_longest(imgsz, blksz, stpsz, fillvalue=1))\n\n    # Calculate the strides for blocks\n    blockstrides = tuple(a * b for a, b in zip_longest(img.strides, stpsz,\n                                                       fillvalue=1))\n\n    new_shape = blksz + numblocks\n    new_strides = img.strides[:len(blksz)] + blockstrides\n    blks = np.lib.stride_tricks.as_strided(img, new_shape, new_strides)\n    return np.reshape(blks, blksz + (-1,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\naverages blocks together from an ndarray to reconstruct ndarray signal.", "response": "def averageblocks(blks, imgsz, stpsz=None):\n    \"\"\"Average blocks together from an ndarray to reconstruct ndarray signal.\n\n    Parameters\n    ----------\n    blks : ndarray\n      nd array of blocks of a signal\n    imgsz : tuple\n      tuple of the signal size\n    stpsz : tuple, optional (default None, corresponds to steps of 1)\n      tuple of step sizes between neighboring blocks\n\n    Returns\n    -------\n    imgs : ndarray\n      reconstructed signal, unknown pixels are returned as np.nan\n    \"\"\"\n\n    blksz = blks.shape[:-1]\n\n    if stpsz is None:\n        stpsz = tuple(1 for _ in blksz)\n\n\n    # Calculate the number of blocks that can fit in each dimension of\n    # the images\n    numblocks = tuple(int(np.floor((a-b)/c)+1) for a, b, c in\n                      zip_longest(imgsz, blksz, stpsz, fillvalue=1))\n\n    new_shape = blksz + numblocks\n    blks = np.reshape(blks, new_shape)\n\n    # Construct an imgs matrix of empty lists\n    imgs = np.zeros(imgsz, dtype=blks.dtype)\n    normalizer = np.zeros(imgsz, dtype=blks.dtype)\n\n    # Iterate over each block and append the values to the corresponding\n    # imgs cell\n    for pos in np.ndindex(numblocks):\n        slices = tuple(slice(a*c, a*c+b) for a, b, c in\n                       zip(pos, blksz, stpsz))\n        imgs[slices+pos[len(blksz):]] += blks[(Ellipsis, )+pos]\n        normalizer[slices+pos[len(blksz):]] += blks.dtype.type(1)\n\n    return np.where(normalizer > 0, (imgs/normalizer).astype(blks.dtype),\n                    np.nan)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncombines blocks from an ndarray to reconstruct ndarray signal.", "response": "def combineblocks(blks, imgsz, stpsz=None, fn=np.median):\n    \"\"\"Combine blocks from an ndarray to reconstruct ndarray signal.\n\n    Parameters\n    ----------\n    blks : ndarray\n      nd array of blocks of a signal\n    imgsz : tuple\n      tuple of the signal size\n    stpsz : tuple, optional (default None, corresponds to steps of 1)\n      tuple of step sizes between neighboring blocks\n    fn : function, optional (default np.median)\n      the function used to resolve multivalued cells\n\n    Returns\n    -------\n    imgs : ndarray\n      reconstructed signal, unknown pixels are returned as np.nan\n    \"\"\"\n\n    # Construct a vectorized append function\n    def listapp(x, y):\n        x.append(y)\n    veclistapp = np.vectorize(listapp, otypes=[np.object_])\n\n    blksz = blks.shape[:-1]\n\n    if stpsz is None:\n        stpsz = tuple(1 for _ in blksz)\n\n    # Calculate the number of blocks that can fit in each dimension of\n    # the images\n    numblocks = tuple(int(np.floor((a-b)/c) + 1) for a, b, c in\n                      zip_longest(imgsz, blksz, stpsz, fillvalue=1))\n\n    new_shape = blksz + numblocks\n    blks = np.reshape(blks, new_shape)\n\n    # Construct an imgs matrix of empty lists\n    imgs = np.empty(imgsz, dtype=np.object_)\n    imgs.fill([])\n    imgs = np.frompyfunc(list, 1, 1)(imgs)\n\n    # Iterate over each block and append the values to the corresponding\n    # imgs cell\n    for pos in np.ndindex(numblocks):\n        slices = tuple(slice(a*c, a*c + b) for a, b, c in\n                       zip_longest(pos, blksz, stpsz, fillvalue=1))\n        veclistapp(imgs[slices].squeeze(), blks[(Ellipsis, ) + pos].squeeze())\n\n    return np.vectorize(fn, otypes=[blks.dtype])(imgs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rgb2gray(rgb):\n\n    w = sla.atleast_nd(rgb.ndim, np.array([0.299, 0.587, 0.144],\n                                          dtype=rgb.dtype, ndmin=3))\n    return np.sum(w * rgb, axis=2)", "response": "Convert an RGB image or images to grayscale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a complex array of samples drawn from a standard normal distribution.", "response": "def complex_randn(*args):\n    \"\"\"Return a complex array of samples drawn from a standard normal\n    distribution.\n\n    Parameters\n    ----------\n    d0, d1, ..., dn : int\n      Dimensions of the random array\n\n    Returns\n    -------\n    a : ndarray\n      Random array of shape (d0, d1, ..., dn)\n    \"\"\"\n\n    return np.random.randn(*args) + 1j*np.random.randn(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning image with salt & pepper noise imposed on it.", "response": "def spnoise(s, frc, smn=0.0, smx=1.0):\n    \"\"\"Return image with salt & pepper noise imposed on it.\n\n    Parameters\n    ----------\n    s : ndarray\n      Input image\n    frc : float\n      Desired fraction of pixels corrupted by noise\n    smn : float, optional (default 0.0)\n      Lower value for noise (pepper)\n    smx : float, optional (default 1.0)\n      Upper value for noise (salt)\n\n    Returns\n    -------\n    sn : ndarray\n      Noisy image\n    \"\"\"\n\n    sn = s.copy()\n    spm = np.random.uniform(-1.0, 1.0, s.shape)\n    sn[spm < frc - 1.0] = smn\n    sn[spm > 1.0 - frc] = smx\n    return sn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pca(U, centre=False):\n\n    if centre:\n        C = np.mean(U, axis=1, keepdims=True)\n        U = U - C\n    else:\n        C = None\n\n    B, S, _ = np.linalg.svd(U, full_matrices=False, compute_uv=True)\n    return B, S**2, C", "response": "Compute the PCA basis for columns of input array U."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tikhonov_filter(s, lmbda, npd=16):\n\n    grv = np.array([-1.0, 1.0]).reshape([2, 1])\n    gcv = np.array([-1.0, 1.0]).reshape([1, 2])\n    Gr = sla.fftn(grv, (s.shape[0] + 2*npd, s.shape[1] + 2*npd), (0, 1))\n    Gc = sla.fftn(gcv, (s.shape[0] + 2*npd, s.shape[1] + 2*npd), (0, 1))\n    A = 1.0 + lmbda*np.conj(Gr)*Gr + lmbda*np.conj(Gc)*Gc\n    if s.ndim > 2:\n        A = A[(slice(None),)*2 + (np.newaxis,)*(s.ndim-2)]\n    sp = np.pad(s, ((npd, npd),)*2 + ((0, 0),)*(s.ndim-2), 'symmetric')\n    slp = np.real(sla.ifftn(sla.fftn(sp, axes=(0, 1)) / A, axes=(0, 1)))\n    sl = slp[npd:(slp.shape[0] - npd), npd:(slp.shape[1] - npd)]\n    sh = s - sl\n    return sl.astype(s.dtype), sh.astype(s.dtype)", "response": "Lowpass filter based on Tikhonov regularization."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsampling a multivariate Gaussian pdf normalised to have unit sum.", "response": "def gaussian(shape, sd=1.0):\n    \"\"\"Sample a multivariate Gaussian pdf, normalised to have unit sum.\n\n    Parameters\n    ----------\n    shape : tuple\n      Shape of output array.\n    sd : float, optional (default 1.0)\n      Standard deviation of Gaussian pdf.\n\n    Returns\n    -------\n    gc : ndarray\n      Sampled Gaussian pdf.\n    \"\"\"\n\n    gfn = lambda x, sd: np.exp(-(x**2) / (2.0 * sd**2)) / \\\n                        (np.sqrt(2.0 * np.pi) *sd)\n    gc = 1.0\n    if isinstance(shape, int):\n        shape = (shape,)\n    for k, n in enumerate(shape):\n        x = np.linspace(-3.0, 3.0, n).reshape(\n            (1,) * k + (n,) + (1,) * (len(shape) - k - 1))\n        gc = gc * gfn(x, sd)\n    gc /= np.sum(gc)\n    return gc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform local contrast normalisation on an image.", "response": "def local_contrast_normalise(s, n=7, c=None):\n    \"\"\"\n    Perform local contrast normalisation :cite:`jarret-2009-what` of\n    an image, consisting of subtraction of the local mean and division\n    by the local norm. The original image can be reconstructed from the\n    contrast normalised image as (`snrm` * `scn`) + `smn`.\n\n    Parameters\n    ----------\n    s : array_like\n      Input image or array of images.\n    n : int, optional (default 7)\n      The size of the local region used for normalisation is :math:`2n+1`.\n    c : float, optional (default None)\n      The smallest value that can be used in the divisive normalisation.\n      If `None`, this value is set to the mean of the local region norms.\n\n    Returns\n    -------\n    scn : ndarray\n      Contrast normalised image(s)\n    smn : ndarray\n      Additive normalisation correction\n    snrm : ndarray\n      Multiplicative normalisation correction\n    \"\"\"\n\n    # Construct region weighting filter\n    N = 2 * n + 1\n    g = gaussian((N, N), sd=1.0)\n    # Compute required image padding\n    pd = ((n, n),) * 2\n    if s.ndim > 2:\n        g = g[..., np.newaxis]\n        pd += ((0, 0),)\n    sp = np.pad(s, pd, mode='symmetric')\n    # Compute local mean and subtract from image\n    smn = np.roll(sla.fftconv(g, sp), (-n, -n), axis=(0, 1))\n    s1 = sp - smn\n    # Compute local norm\n    snrm = np.roll(np.sqrt(np.clip(sla.fftconv(g, s1**2), 0.0, np.inf)),\n                   (-n, -n), axis=(0, 1))\n    # Set c parameter if not specified\n    if c is None:\n        c = np.mean(snrm, axis=(0, 1), keepdims=True)\n    # Divide mean-subtracted image by corrected local norm\n    snrm = np.maximum(c, snrm)\n    s2 = s1 / snrm\n    # Return contrast normalised image and normalisation components\n    return s2[n:-n, n:-n], smn[n:-n, n:-n], snrm[n:-n, n:-n]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef idle_cpu_count(mincpu=1):\n\n    if PY2:\n        ncpu = mp.cpu_count()\n    else:\n        ncpu = os.cpu_count()\n    idle = int(ncpu - np.floor(os.getloadavg()[0]))\n    return max(mincpu, idle)", "response": "Estimate number of idle CPUs for use by multiprocessing code\n    needing to determine how many processes can be run without excessive load."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a grid search for optimal parameters of a specified function at each axis.", "response": "def grid_search(fn, grd, fmin=True, nproc=None):\n    \"\"\"Perform a grid search for optimal parameters of a specified\n    function.  In the simplest case the function returns a float value,\n    and a single optimum value and corresponding parameter values are\n    identified. If the function returns a tuple of values, each of\n    these is taken to define a separate function on the search grid,\n    with optimum function values and corresponding parameter values\n    being identified for each of them. On all platforms except Windows\n    (where ``mp.Pool`` usage has some limitations), the computation\n    of the function at the grid points is computed in parallel.\n\n    **Warning:** This function will hang if `fn` makes use of :mod:`pyfftw`\n    with multi-threading enabled (the\n    `bug <https://github.com/pyFFTW/pyFFTW/issues/135>`_ has been reported).\n    When using the FFT functions in :mod:`sporco.linalg`, multi-threading\n    can be disabled by including the following code::\n\n      import sporco.linalg\n      sporco.linalg.pyfftw_threads = 1\n\n\n    Parameters\n    ----------\n    fn : function\n      Function to be evaluated. It should take a tuple of parameter values as\n      an argument, and return a float value or a tuple of float values.\n    grd : tuple of array_like\n      A tuple providing an array of sample points for each axis of the grid\n      on which the search is to be performed.\n    fmin : bool, optional (default True)\n      Determine whether optimal function values are selected as minima or\n      maxima. If `fmin` is True then minima are selected.\n    nproc : int or None, optional (default None)\n      Number of processes to run in parallel. If None, the number of\n      CPUs of the system is used.\n\n    Returns\n    -------\n    sprm : ndarray\n      Optimal parameter values on each axis. If `fn` is multi-valued,\n      `sprm` is a matrix with rows corresponding to parameter values\n      and columns corresponding to function values.\n    sfvl : float or ndarray\n      Optimum function value or values\n    fvmx : ndarray\n      Function value(s) on search grid\n    sidx : tuple of int or tuple of ndarray\n      Indices of optimal values on parameter grid\n    \"\"\"\n\n    if fmin:\n        slct = np.argmin\n    else:\n        slct = np.argmax\n    fprm = itertools.product(*grd)\n    if platform.system() == 'Windows':\n        fval = list(map(fn, fprm))\n    else:\n        if nproc is None:\n            nproc = mp.cpu_count()\n        pool = mp.Pool(processes=nproc)\n        fval = pool.map(fn, fprm)\n        pool.close()\n        pool.join()\n    if isinstance(fval[0], (tuple, list, np.ndarray)):\n        nfnv = len(fval[0])\n        fvmx = np.reshape(fval, [a.size for a in grd] + [nfnv,])\n        sidx = np.unravel_index(slct(fvmx.reshape((-1, nfnv)), axis=0),\n                                fvmx.shape[0:-1]) + (np.array((range(nfnv))),)\n        sprm = np.array([grd[k][sidx[k]] for k in range(len(grd))])\n        sfvl = tuple(fvmx[sidx])\n    else:\n        fvmx = np.reshape(fval, [a.size for a in grd])\n        sidx = np.unravel_index(slct(fvmx), fvmx.shape)\n        sprm = np.array([grd[k][sidx[k]] for k in range(len(grd))])\n        sfvl = fvmx[sidx]\n\n    return sprm, sfvl, fvmx, sidx"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\naccess a set of example learned convolutional dictionaries.", "response": "def convdicts():\n    \"\"\"Access a set of example learned convolutional dictionaries.\n\n    Returns\n    -------\n    cdd : dict\n      A dict associating description strings with dictionaries represented\n      as ndarrays\n\n    Examples\n    --------\n    Print the dict keys to obtain the identifiers of the available\n    dictionaries\n\n    >>> from sporco import util\n    >>> cd = util.convdicts()\n    >>> print(cd.keys())\n    ['G:12x12x72', 'G:8x8x16,12x12x32,16x16x48', ...]\n\n    Select a specific example dictionary using the corresponding identifier\n\n    >>> D = cd['G:8x8x96']\n    \"\"\"\n\n    pth = os.path.join(os.path.dirname(__file__), 'data', 'convdict.npz')\n    npz = np.load(pth)\n    cdd = {}\n    for k in list(npz.keys()):\n        cdd[k] = npz[k]\n    return cdd"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef netgetdata(url, maxtry=3, timeout=10):\n\n    err = ValueError('maxtry parameter should be greater than zero')\n    for ntry in range(maxtry):\n        try:\n            rspns = urlrequest.urlopen(url, timeout=timeout)\n            cntnt = rspns.read()\n            break\n        except urlerror.URLError as e:\n            err = e\n            if not isinstance(e.reason, socket.timeout):\n                raise\n    else:\n        raise err\n\n    return io.BytesIO(cntnt)", "response": "Download a file via a URL and return a byte stream of the content."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notebook_system_output():\n\n    from contextlib import contextmanager\n    @contextmanager\n    def null_context_manager():\n        yield\n\n    if in_notebook():\n        try:\n            from wurlitzer import sys_pipes\n        except ImportError:\n            sys_pipes = null_context_manager\n    else:\n        sys_pipes = null_context_manager\n\n    return sys_pipes", "response": "Return a context manager that can handle output redirection when run within a Jupyter Notebook shell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image(self, fname, group=None, scaled=None, dtype=None, idxexp=None,\n              zoom=None, gray=None):\n        \"\"\"Get named image.\n\n        Parameters\n        ----------\n        fname : string\n          Filename of image\n        group : string or None, optional (default None)\n          Name of image group\n        scaled : bool or None, optional (default None)\n          Flag indicating whether images should be on the range [0,...,255]\n          with np.uint8 dtype (False), or on the range [0,...,1] with\n          np.float32 dtype (True). If the value is None, scaling behaviour\n          is determined by the `scaling` parameter passed to the object\n          initializer, otherwise that selection is overridden.\n        dtype : data-type or None, optional (default None)\n          Desired data type of images. If `scaled` is True and `dtype` is an\n          integer type, the output data type is np.float32. If the value is\n          None, the data type is determined by the `dtype` parameter passed to\n          the object initializer, otherwise that selection is overridden.\n        idxexp :  index expression or None, optional (default None)\n          An index expression selecting, for example, a cropped region of\n          the requested image. This selection is applied *before* any\n          `zoom` rescaling so the expression does not need to be modified when\n          the zoom factor is changed.\n        zoom : float or None, optional (default None)\n          Optional rescaling factor to apply to the images. If the value is\n          None, support rescaling behaviour is determined by the `zoom`\n          parameter passed to the object initializer, otherwise that selection\n          is overridden.\n        gray : bool or None, optional (default None)\n          Flag indicating whether RGB images should be converted to grayscale.\n          If the value is None, behaviour is determined by the `gray`\n          parameter passed to the object initializer.\n\n        Returns\n        -------\n        img : ndarray\n          Image array\n\n        Raises\n        ------\n        IOError\n          If the image is not accessible\n        \"\"\"\n\n        if scaled is None:\n            scaled = self.scaled\n        if dtype is None:\n            if self.dtype is None:\n                dtype = np.uint8\n            else:\n                dtype = self.dtype\n        if scaled and np.issubdtype(dtype, np.integer):\n            dtype = np.float32\n        if zoom is None:\n            zoom = self.zoom\n        if gray is None:\n            gray = self.gray\n        if group is None:\n            pth = os.path.join(self.bpth, fname)\n        else:\n            pth = os.path.join(self.bpth, group, fname)\n\n        try:\n            img = np.asarray(imageio.imread(pth), dtype=dtype)\n        except IOError:\n            raise IOError('Could not access image %s in group %s' %\n                          (fname, group))\n\n        if scaled:\n            img /= 255.0\n        if idxexp is not None:\n            img = img[idxexp]\n        if zoom is not None:\n            if img.ndim == 2:\n                img = sni.zoom(img, zoom)\n            else:\n                img = sni.zoom(img, (zoom,)*2 + (1,)*(img.ndim-2))\n        if gray:\n            img = rgb2gray(img)\n\n        return img", "response": "Returns the image array for the named image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, labels=None):\n\n        # Default label is self.dfltlbl\n        if labels is None:\n            labels = self.dfltlbl\n        # If label is not a list or tuple, create a singleton list\n        # containing it\n        if not isinstance(labels, (list, tuple)):\n            labels = [labels,]\n        # Iterate over specified label(s)\n        t = timer()\n        for lbl in labels:\n            # On first call to start for a label, set its accumulator to zero\n            if lbl not in self.td:\n                self.td[lbl] = 0.0\n                self.t0[lbl] = None\n            # Record the time at which start was called for this lbl if\n            # it isn't already running\n            if self.t0[lbl] is None:\n                self.t0[lbl] = t", "response": "Start specified timer(s).\n\n        Parameters\n        ----------\n        labels : string or list, optional (default None)\n          Specify the label(s) of the timer(s) to be started. If it is\n          ``None``, start the default timer with label specified by the\n          ``dfltlbl`` parameter of :meth:`__init__`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self, labels=None):\n\n        # Get current time\n        t = timer()\n        # Default label is self.dfltlbl\n        if labels is None:\n            labels = self.dfltlbl\n        # All timers are affected if label is equal to self.alllbl,\n        # otherwise only the timer(s) specified by label\n        if labels == self.alllbl:\n            labels = self.t0.keys()\n        elif not isinstance(labels, (list, tuple)):\n            labels = [labels,]\n        # Iterate over specified label(s)\n        for lbl in labels:\n            if lbl not in self.t0:\n                raise KeyError('Unrecognized timer key %s' % lbl)\n            # If self.t0[lbl] is None, the corresponding timer is\n            # already stopped, so no action is required\n            if self.t0[lbl] is not None:\n                # Increment time accumulator from the elapsed time\n                # since most recent start call\n                self.td[lbl] += t - self.t0[lbl]\n                # Set start time to None to indicate timer is not running\n                self.t0[lbl] = None", "response": "Stop specified timer(s).\n\n        Parameters\n        ----------\n        labels : string or list, optional (default None)\n          Specify the label(s) of the timer(s) to be stopped. If it is\n          ``None``, stop the default timer with label specified by the\n          ``dfltlbl`` parameter of :meth:`__init__`. If it is equal to\n          the string specified by the ``alllbl`` parameter of\n          :meth:`__init__`, stop all timers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset(self, labels=None):\n\n        # Default label is self.dfltlbl\n        if labels is None:\n            labels = self.dfltlbl\n        # All timers are affected if label is equal to self.alllbl,\n        # otherwise only the timer(s) specified by label\n        if labels == self.alllbl:\n            labels = self.t0.keys()\n        elif not isinstance(labels, (list, tuple)):\n            labels = [labels,]\n        # Iterate over specified label(s)\n        for lbl in labels:\n            if lbl not in self.t0:\n                raise KeyError('Unrecognized timer key %s' % lbl)\n            # Set start time to None to indicate timer is not running\n            self.t0[lbl] = None\n            # Set time accumulator to zero\n            self.td[lbl] = 0.0", "response": "Reset the timer to the specified values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting elapsed time since the current timer.", "response": "def elapsed(self, label=None, total=True):\n        \"\"\"Get elapsed time since timer start.\n\n        Parameters\n        ----------\n        label : string, optional (default None)\n          Specify the label of the timer for which the elapsed time is\n          required.  If it is ``None``, the default timer with label\n          specified by the ``dfltlbl`` parameter of :meth:`__init__`\n          is selected.\n        total : bool, optional (default True)\n          If ``True`` return the total elapsed time since the first\n          call of :meth:`start` for the selected timer, otherwise\n          return the elapsed time since the most recent call of\n          :meth:`start` for which there has not been a corresponding\n          call to :meth:`stop`.\n\n        Returns\n        -------\n        dlt : float\n          Elapsed time\n        \"\"\"\n\n        # Get current time\n        t = timer()\n        # Default label is self.dfltlbl\n        if label is None:\n            label = self.dfltlbl\n            # Return 0.0 if default timer selected and it is not initialised\n            if label not in self.t0:\n                return 0.0\n        # Raise exception if timer with specified label does not exist\n        if label not in self.t0:\n            raise KeyError('Unrecognized timer key %s' % label)\n        # If total flag is True return sum of accumulated time from\n        # previous start/stop calls and current start call, otherwise\n        # return just the time since the current start call\n        te = 0.0\n        if self.t0[label] is not None:\n            te = t - self.t0[label]\n        if total:\n            te += self.td[label]\n\n        return te"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the elapsed time for the timer.", "response": "def elapsed(self, total=True):\n        \"\"\"Return the elapsed time for the timer.\n\n        Parameters\n        ----------\n        total : bool, optional (default True)\n          If ``True`` return the total elapsed time since the first\n          call of :meth:`start` for the selected timer, otherwise\n          return the elapsed time since the most recent call of\n          :meth:`start` for which there has not been a corresponding\n          call to :meth:`stop`.\n\n        Returns\n        -------\n        dlt : float\n          Elapsed time\n        \"\"\"\n\n        return self.timer.elapsed(self.label, total=total)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach_keypress(fig, scaling=1.1):\n\n    def press(event):\n        if event.key == 'q':\n            plt.close(fig)\n        elif event.key == 'e':\n            fig.set_size_inches(scaling * fig.get_size_inches(), forward=True)\n        elif event.key == 'c':\n            fig.set_size_inches(fig.get_size_inches() / scaling, forward=True)\n\n    # Avoid multiple event handlers attached to the same figure\n    if not hasattr(fig, '_sporco_keypress_cid'):\n        cid = fig.canvas.mpl_connect('key_press_event', press)\n        fig._sporco_keypress_cid = cid\n\n    return press", "response": "Attaches a key press event handler that configures keys for closing the figure and changing the figure size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattaches an event handler that supports zooming within a plot using matplotlib.", "response": "def attach_zoom(ax, scaling=2.0):\n    \"\"\"\n    Attach an event handler that supports zooming within a plot using\n    the mouse scroll wheel.\n\n    Parameters\n    ----------\n    ax : :class:`matplotlib.axes.Axes` object\n      Axes to which event handling is to be attached\n    scaling : float, optional (default 2.0)\n      Scaling factor for zooming in and out\n\n    Returns\n    -------\n    zoom : function\n      Mouse scroll wheel event handler function\n    \"\"\"\n\n    # See https://stackoverflow.com/questions/11551049\n    def zoom(event):\n        # Get the current x and y limits\n        cur_xlim = ax.get_xlim()\n        cur_ylim = ax.get_ylim()\n        # Get event location\n        xdata = event.xdata\n        ydata = event.ydata\n        # Return if cursor is not over valid region of plot\n        if xdata is None or ydata is None:\n            return\n\n        if event.button == 'up':\n            # Deal with zoom in\n            scale_factor = 1.0 / scaling\n        elif event.button == 'down':\n            # Deal with zoom out\n            scale_factor = scaling\n\n        # Get distance from the cursor to the edge of the figure frame\n        x_left = xdata - cur_xlim[0]\n        x_right = cur_xlim[1] - xdata\n        y_top = ydata - cur_ylim[0]\n        y_bottom = cur_ylim[1] - ydata\n\n        # Calculate new x and y limits\n        new_xlim = (xdata - x_left * scale_factor,\n                    xdata + x_right * scale_factor)\n        new_ylim = (ydata - y_top * scale_factor,\n                    ydata + y_bottom * scale_factor)\n\n        # Ensure that x limit range is no larger than that of the reference\n        if np.diff(new_xlim) > np.diff(zoom.xlim_ref):\n            new_xlim *= np.diff(zoom.xlim_ref) / np.diff(new_xlim)\n        # Ensure that lower x limit is not less than that of the reference\n        if new_xlim[0] < zoom.xlim_ref[0]:\n            new_xlim += np.array(zoom.xlim_ref[0] - new_xlim[0])\n        # Ensure that upper x limit is not greater than that of the reference\n        if new_xlim[1] > zoom.xlim_ref[1]:\n            new_xlim -= np.array(new_xlim[1] - zoom.xlim_ref[1])\n\n        # Ensure that ylim tuple has the smallest value first\n        if zoom.ylim_ref[1] < zoom.ylim_ref[0]:\n            ylim_ref = zoom.ylim_ref[::-1]\n            new_ylim = new_ylim[::-1]\n        else:\n            ylim_ref = zoom.ylim_ref\n\n        # Ensure that y limit range is no larger than that of the reference\n        if np.diff(new_ylim) > np.diff(ylim_ref):\n            new_ylim *= np.diff(ylim_ref) / np.diff(new_ylim)\n        # Ensure that lower y limit is not less than that of the reference\n        if new_ylim[0] < ylim_ref[0]:\n            new_ylim += np.array(ylim_ref[0] - new_ylim[0])\n        # Ensure that upper y limit is not greater than that of the reference\n        if new_ylim[1] > ylim_ref[1]:\n            new_ylim -= np.array(new_ylim[1] - ylim_ref[1])\n\n        # Return the ylim tuple to its original order\n        if zoom.ylim_ref[1] < zoom.ylim_ref[0]:\n            new_ylim = new_ylim[::-1]\n\n        # Set new x and y limits\n        ax.set_xlim(new_xlim)\n        ax.set_ylim(new_ylim)\n\n        # Force redraw\n        ax.figure.canvas.draw()\n\n    # Record reference x and y limits prior to any zooming\n    zoom.xlim_ref = ax.get_xlim()\n    zoom.ylim_ref = ax.get_ylim()\n\n    # Get figure for specified axes and attach the event handler\n    fig = ax.get_figure()\n    fig.canvas.mpl_connect('scroll_event', zoom)\n\n    return zoom"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(y, x=None, ptyp='plot', xlbl=None, ylbl=None, title=None,\n         lgnd=None, lglc=None, **kwargs):\n    \"\"\"\n    Plot points or lines in 2D. If a figure object is specified then the\n    plot is drawn in that figure, and ``fig.show()`` is not called. The\n    figure is closed on key entry 'q'.\n\n    Parameters\n    ----------\n    y : array_like\n        1d or 2d array of data to plot. If a 2d array, each column is\n        plotted as a separate curve.\n    x : array_like, optional (default None)\n        Values for x-axis of the plot\n    ptyp : string, optional (default 'plot')\n        Plot type specification (options are 'plot', 'semilogx',\n        'semilogy', and 'loglog')\n    xlbl : string, optional (default None)\n        Label for x-axis\n    ylbl : string, optional (default None)\n        Label for y-axis\n    title : string, optional (default None)\n        Figure title\n    lgnd : list of strings, optional (default None)\n        List of legend string\n    lglc : string, optional (default None)\n        Legend location string\n    **kwargs :  :class:`matplotlib.lines.Line2D` properties or figure \\\n    properties, optional\n        Keyword arguments specifying :class:`matplotlib.lines.Line2D`\n        properties, e.g. ``lw=2.0`` sets a line width of 2, or properties\n        of the figure and axes. If not specified, the defaults for line\n        width (``lw``) and marker size (``ms``) are 1.5 and 6.0\n        respectively. The valid figure and axes keyword arguments are\n        listed below:\n\n        .. |mplfg| replace:: :class:`matplotlib.figure.Figure` object\n        .. |mplax| replace:: :class:`matplotlib.axes.Axes` object\n\n        .. rst-class:: kwargs\n\n        =====  ==================== ======================================\n        kwarg  Accepts              Description\n        =====  ==================== ======================================\n        fgsz   tuple (width,height) Specify figure dimensions in inches\n        fgnm   integer              Figure number of figure\n        fig    |mplfg|              Draw in specified figure instead of\n                                    creating one\n        ax     |mplax|              Plot in specified axes instead of\n                                    current axes of figure\n        =====  ==================== ======================================\n\n\n    Returns\n    -------\n    fig : :class:`matplotlib.figure.Figure` object\n      Figure object for this figure\n    ax : :class:`matplotlib.axes.Axes` object\n      Axes object for this plot\n    \"\"\"\n\n    # Extract kwargs entries that are not related to line properties\n    fgsz = kwargs.pop('fgsz', None)\n    fgnm = kwargs.pop('fgnm', None)\n    fig = kwargs.pop('fig', None)\n    ax = kwargs.pop('ax', None)\n\n    figp = fig\n    if fig is None:\n        fig = plt.figure(num=fgnm, figsize=fgsz)\n        fig.clf()\n        ax = fig.gca()\n    elif ax is None:\n        ax = fig.gca()\n\n    # Set defaults for line width and marker size\n    if 'lw' not in kwargs and 'linewidth' not in kwargs:\n        kwargs['lw'] = 1.5\n    if 'ms' not in kwargs and 'markersize' not in kwargs:\n        kwargs['ms'] = 6.0\n\n    if ptyp not in ('plot', 'semilogx', 'semilogy', 'loglog'):\n        raise ValueError(\"Invalid plot type '%s'\" % ptyp)\n    pltmth = getattr(ax, ptyp)\n    if x is None:\n        pltln = pltmth(y, **kwargs)\n    else:\n        pltln = pltmth(x, y, **kwargs)\n\n    ax.fmt_xdata = lambda x: \"{: .2f}\".format(x)\n    ax.fmt_ydata = lambda x: \"{: .2f}\".format(x)\n\n    if title is not None:\n        ax.set_title(title)\n    if xlbl is not None:\n        ax.set_xlabel(xlbl)\n    if ylbl is not None:\n        ax.set_ylabel(ylbl)\n    if lgnd is not None:\n        ax.legend(lgnd, loc=lglc)\n\n    attach_keypress(fig)\n    attach_zoom(ax)\n\n    if have_mpldc:\n        mpldc.datacursor(pltln)\n\n    if figp is None:\n        fig.show()\n\n    return fig, ax", "response": "Plot points or lines in 2D."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot a 2D surface in 3D.", "response": "def surf(z, x=None, y=None, elev=None, azim=None, xlbl=None, ylbl=None,\n         zlbl=None, title=None, lblpad=8.0, cntr=None, cmap=None,\n         fgsz=None, fgnm=None, fig=None, ax=None):\n    \"\"\"\n    Plot a 2D surface in 3D. If a figure object is specified then the\n    surface is drawn in that figure, and ``fig.show()`` is not called.\n    The figure is closed on key entry 'q'.\n\n    Parameters\n    ----------\n    z : array_like\n        2d array of data to plot\n    x : array_like, optional (default None)\n        Values for x-axis of the plot\n    y : array_like, optional (default None)\n        Values for y-axis of the plot\n    elev : float\n        Elevation angle (in degrees) in the z plane\n    azim : foat\n        Azimuth angle  (in degrees) in the x,y plane\n    xlbl : string, optional (default None)\n        Label for x-axis\n    ylbl : string, optional (default None)\n        Label for y-axis\n    zlbl : string, optional (default None)\n        Label for z-axis\n    title : string, optional (default None)\n        Figure title\n    lblpad : float, optional (default 8.0)\n        Label padding\n    cntr : int or sequence of ints, optional (default None)\n        If not None, plot contours of the surface on the lower end of\n        the z-axis. An int specifies the number of contours to plot, and\n        a sequence specifies the specific contour levels to plot.\n    cmap : :class:`matplotlib.colors.Colormap` object, optional (default None)\n        Colour map for surface. If none specifed, defaults to cm.coolwarm\n    fgsz : tuple (width,height), optional (default None)\n        Specify figure dimensions in inches\n    fgnm : integer, optional (default None)\n        Figure number of figure\n    fig : :class:`matplotlib.figure.Figure` object, optional (default None)\n        Draw in specified figure instead of creating one\n    ax : :class:`matplotlib.axes.Axes` object, optional (default None)\n        Plot in specified axes instead of creating one\n\n    Returns\n    -------\n    fig : :class:`matplotlib.figure.Figure` object\n      Figure object for this figure\n    ax : :class:`matplotlib.axes.Axes` object\n      Axes object for this plot\n    \"\"\"\n\n    figp = fig\n    if fig is None:\n        fig = plt.figure(num=fgnm, figsize=fgsz)\n        fig.clf()\n        ax = plt.axes(projection='3d')\n    else:\n        if ax is None:\n            ax = plt.axes(projection='3d')\n        else:\n            # See https://stackoverflow.com/a/43563804\n            #     https://stackoverflow.com/a/35221116\n            if ax.name != '3d':\n                ax.remove()\n                ax = fig.add_subplot(*ax.get_geometry(), projection='3d')\n\n    if elev is not None or azim is not None:\n        ax.view_init(elev=elev, azim=azim)\n\n    if cmap is None:\n        cmap = cm.coolwarm\n\n    if x is None:\n        x = range(z.shape[1])\n    if y is None:\n        y = range(z.shape[0])\n\n    xg, yg = np.meshgrid(x, y)\n    ax.plot_surface(xg, yg, z, rstride=1, cstride=1, cmap=cmap)\n\n    if cntr is not None:\n        offset = np.around(z.min() - 0.2 * (z.max() - z.min()), 3)\n        ax.contour(xg, yg, z, cntr, cmap=cmap, linewidths=2,\n                   linestyles=\"solid\", offset=offset)\n        ax.set_zlim(offset, ax.get_zlim()[1])\n\n    ax.fmt_xdata = lambda x: \"{: .2f}\".format(x)\n    ax.fmt_ydata = lambda x: \"{: .2f}\".format(x)\n    ax.fmt_zdata = lambda x: \"{: .2f}\".format(x)\n\n    if title is not None:\n        ax.set_title(title)\n    if xlbl is not None:\n        ax.set_xlabel(xlbl, labelpad=lblpad)\n    if ylbl is not None:\n        ax.set_ylabel(ylbl, labelpad=lblpad)\n    if zlbl is not None:\n        ax.set_zlabel(zlbl, labelpad=lblpad)\n\n    attach_keypress(fig)\n\n    if figp is None:\n        fig.show()\n\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contour(z, x=None, y=None, v=5, xlbl=None, ylbl=None, title=None,\n            cfntsz=10, lfntsz=None, intrp='bicubic', alpha=0.5, cmap=None,\n            vmin=None, vmax=None, fgsz=None, fgnm=None, fig=None, ax=None):\n    \"\"\"\n    Contour plot of a 2D surface. If a figure object is specified then the\n    plot is drawn in that figure, and ``fig.show()`` is not called. The\n    figure is closed on key entry 'q'.\n\n    Parameters\n    ----------\n    z : array_like\n        2d array of data to plot\n    x : array_like, optional (default None)\n        Values for x-axis of the plot\n    y : array_like, optional (default None)\n        Values for y-axis of the plot\n    v : int or sequence of ints, optional (default 5)\n        An int specifies the number of contours to plot, and a sequence\n        specifies the specific contour levels to plot.\n    xlbl : string, optional (default None)\n        Label for x-axis\n    ylbl : string, optional (default None)\n        Label for y-axis\n    title : string, optional (default None)\n        Figure title\n    cfntsz : int or None, optional (default 10)\n        Contour label font size. No contour labels are displayed if\n        set to 0 or None.\n    lfntsz : int, optional (default None)\n        Axis label font size. The default font size is used if set to None.\n    intrp : string, optional (default 'bicubic')\n        Specify type of interpolation used to display image underlying\n        contours (see ``interpolation`` parameter of\n        :meth:`matplotlib.axes.Axes.imshow`)\n    alpha : float, optional (default 0.5)\n        Underlying image display alpha value\n    cmap : :class:`matplotlib.colors.Colormap`, optional (default None)\n        Colour map for surface. If none specifed, defaults to cm.coolwarm\n    vmin, vmax : float, optional (default None)\n        Set upper and lower bounds for the colour map (see the corresponding\n        parameters of :meth:`matplotlib.axes.Axes.imshow`)\n    fgsz : tuple (width,height), optional (default None)\n        Specify figure dimensions in inches\n    fgnm : integer, optional (default None)\n        Figure number of figure\n    fig : :class:`matplotlib.figure.Figure` object, optional (default None)\n        Draw in specified figure instead of creating one\n    ax : :class:`matplotlib.axes.Axes` object, optional (default None)\n        Plot in specified axes instead of current axes of figure\n\n    Returns\n    -------\n    fig : :class:`matplotlib.figure.Figure` object\n      Figure object for this figure\n    ax : :class:`matplotlib.axes.Axes` object\n      Axes object for this plot\n    \"\"\"\n\n    figp = fig\n    if fig is None:\n        fig = plt.figure(num=fgnm, figsize=fgsz)\n        fig.clf()\n        ax = fig.gca()\n    elif ax is None:\n        ax = fig.gca()\n\n    if cmap is None:\n        cmap = cm.coolwarm\n\n    if x is None:\n        x = np.arange(z.shape[1])\n    else:\n        x = np.array(x)\n    if y is None:\n        y = np.arange(z.shape[0])\n    else:\n        y = np.array(y)\n    xg, yg = np.meshgrid(x, y)\n\n    cntr = ax.contour(xg, yg, z, v, colors='black')\n    if cfntsz is not None and cfntsz > 0:\n        plt.clabel(cntr, inline=True, fontsize=cfntsz)\n    im = ax.imshow(z, origin='lower', interpolation=intrp, aspect='auto',\n                   extent=[x.min(), x.max(), y.min(), y.max()], cmap=cmap,\n                   vmin=vmin, vmax=vmax, alpha=alpha)\n\n    ax.fmt_xdata = lambda x: \"{: .2f}\".format(x)\n    ax.fmt_ydata = lambda x: \"{: .2f}\".format(x)\n\n    if title is not None:\n        ax.set_title(title)\n    if xlbl is not None:\n        ax.set_xlabel(xlbl, fontsize=lfntsz)\n    if ylbl is not None:\n        ax.set_ylabel(ylbl, fontsize=lfntsz)\n\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n    plt.colorbar(im, ax=ax, cax=cax)\n\n    attach_keypress(fig)\n    attach_zoom(ax)\n\n    if have_mpldc:\n        mpldc.datacursor()\n\n    if figp is None:\n        fig.show()\n\n    return fig, ax", "response": "Plots a contour plot of a 2D array of data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imview(img, title=None, copy=True, fltscl=False, intrp='nearest',\n           norm=None, cbar=False, cmap=None, fgsz=None, fgnm=None,\n           fig=None, ax=None):\n    \"\"\"\n    Display an image. Pixel values are displayed when the pointer is over\n    valid image data.  If a figure object is specified then the image is\n    drawn in that figure, and ``fig.show()`` is not called. The figure is\n    closed on key entry 'q'.\n\n    Parameters\n    ----------\n    img : array_like, shape (Nr, Nc) or (Nr, Nc, 3) or (Nr, Nc, 4)\n        Image to display\n    title : string, optional (default None)\n        Figure title\n    copy : boolean, optional (default True)\n        If True, create a copy of input `img` as a reference for displayed\n        pixel values, ensuring that displayed values do not change when the\n        array changes in the calling scope. Set this flag to False if the\n        overhead of an additional copy of the input image is not acceptable.\n    fltscl : boolean, optional (default False)\n        If True, rescale and shift floating point arrays to [0,1]\n    intrp : string, optional (default 'nearest')\n        Specify type of interpolation used to display image (see\n        ``interpolation`` parameter of :meth:`matplotlib.axes.Axes.imshow`)\n    norm : :class:`matplotlib.colors.Normalize` object, optional (default None)\n        Specify the :class:`matplotlib.colors.Normalize` instance used to\n        scale pixel values for input to the colour map\n    cbar : boolean, optional (default False)\n        Flag indicating whether to display colorbar\n    cmap : :class:`matplotlib.colors.Colormap`, optional (default None)\n        Colour map for image. If none specifed, defaults to cm.Greys_r\n        for monochrome image\n    fgsz : tuple (width,height), optional (default None)\n        Specify figure dimensions in inches\n    fgnm : integer, optional (default None)\n        Figure number of figure\n    fig : :class:`matplotlib.figure.Figure` object, optional (default None)\n        Draw in specified figure instead of creating one\n    ax : :class:`matplotlib.axes.Axes` object, optional (default None)\n        Plot in specified axes instead of current axes of figure\n\n    Returns\n    -------\n    fig : :class:`matplotlib.figure.Figure` object\n      Figure object for this figure\n    ax : :class:`matplotlib.axes.Axes` object\n      Axes object for this plot\n    \"\"\"\n\n    if img.ndim > 2 and img.shape[2] != 3:\n        raise ValueError('Argument img must be an Nr x Nc array or an '\n                         'Nr x Nc x 3 array')\n\n    figp = fig\n    if fig is None:\n        fig = plt.figure(num=fgnm, figsize=fgsz)\n        fig.clf()\n        ax = fig.gca()\n    elif ax is None:\n        ax = fig.gca()\n\n    # Deal with removal of 'box-forced' adjustable in Matplotlib 2.2.0\n    mplv = matplotlib.__version__.split('.')\n    if int(mplv[0]) > 2 or (int(mplv[0]) == 2 and int(mplv[1]) >= 2):\n        try:\n            ax.set_adjustable('box')\n        except Exception:\n            ax.set_adjustable('datalim')\n    else:\n        ax.set_adjustable('box-forced')\n\n    imgd = img.copy()\n    if copy:\n        # Keep a separate copy of the input image so that the original\n        # pixel values can be display rather than the scaled pixel\n        # values that are actually plotted.\n        img = img.copy()\n\n    if cmap is None and img.ndim == 2:\n        cmap = cm.Greys_r\n\n    if np.issubdtype(img.dtype, np.floating):\n        if fltscl:\n            imgd -= imgd.min()\n            imgd /= imgd.max()\n        if img.ndim > 2:\n            imgd = np.clip(imgd, 0.0, 1.0)\n    elif img.dtype == np.uint16:\n        imgd = np.float16(imgd) / np.iinfo(np.uint16).max\n    elif img.dtype == np.int16:\n        imgd = np.float16(imgd) - imgd.min()\n        imgd /= imgd.max()\n\n    if norm is None:\n        im = ax.imshow(imgd, cmap=cmap, interpolation=intrp, vmin=imgd.min(),\n                       vmax=imgd.max())\n    else:\n        im = ax.imshow(imgd, cmap=cmap, interpolation=intrp, norm=norm)\n\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n\n    if title is not None:\n        ax.set_title(title)\n\n    if cbar or cbar is None:\n        orient = 'vertical' if img.shape[0] >= img.shape[1] else 'horizontal'\n        pos = 'right' if orient == 'vertical' else 'bottom'\n        divider = make_axes_locatable(ax)\n        cax = divider.append_axes(pos, size=\"5%\", pad=0.2)\n        if cbar is None:\n            # See http://chris35wills.github.io/matplotlib_axis\n            if hasattr(cax, 'set_facecolor'):\n                cax.set_facecolor('none')\n            else:\n                cax.set_axis_bgcolor('none')\n            for axis in ['top', 'bottom', 'left', 'right']:\n                cax.spines[axis].set_linewidth(0)\n            cax.set_xticks([])\n            cax.set_yticks([])\n        else:\n            plt.colorbar(im, ax=ax, cax=cax, orientation=orient)\n\n    def format_coord(x, y):\n        nr, nc = imgd.shape[0:2]\n        col = int(x + 0.5)\n        row = int(y + 0.5)\n        if col >= 0 and col < nc and row >= 0 and row < nr:\n            z = img[row, col]\n            if imgd.ndim == 2:\n                return 'x=%6.2f, y=%6.2f, z=%.2f' % (x, y, z)\n            else:\n                return 'x=%6.2f, y=%6.2f, z=(%.2f,%.2f,%.2f)' % \\\n                    sum(((x,), (y,), tuple(z)), ())\n        else:\n            return 'x=%.2f, y=%.2f' % (x, y)\n\n    ax.format_coord = format_coord\n\n    if fig.canvas.toolbar is not None:\n        # See https://stackoverflow.com/a/47086132\n        def mouse_move(self, event):\n            if event.inaxes and event.inaxes.get_navigate():\n                s = event.inaxes.format_coord(event.xdata, event.ydata)\n                self.set_message(s)\n\n        def mouse_move_patch(arg):\n            return mouse_move(fig.canvas.toolbar, arg)\n\n        fig.canvas.toolbar._idDrag = fig.canvas.mpl_connect(\n            'motion_notify_event', mouse_move_patch)\n\n\n    attach_keypress(fig)\n    attach_zoom(ax)\n\n    if have_mpldc:\n        mpldc.datacursor(display='single')\n\n    if figp is None:\n        fig.show()\n\n    return fig, ax", "response": "Display an image in a key entry sequence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config_notebook_plotting():\n\n    # Check whether running within a notebook shell and have\n    # not already monkey patched the plot function\n    from sporco.util import in_notebook\n    module = sys.modules[__name__]\n    if in_notebook() and module.plot.__name__ == 'plot':\n\n        # Set inline backend (i.e. %matplotlib inline) if in a notebook shell\n        set_notebook_plot_backend()\n\n        # Replace plot function with a wrapper function that discards\n        # its return value (within a notebook with inline plotting, plots\n        # are duplicated if the return value from the original function is\n        # not assigned to a variable)\n        plot_original = module.plot\n\n        def plot_wrap(*args, **kwargs):\n            plot_original(*args, **kwargs)\n\n        module.plot = plot_wrap\n\n        # Replace surf function with a wrapper function that discards\n        # its return value (see comment for plot function)\n        surf_original = module.surf\n\n        def surf_wrap(*args, **kwargs):\n            surf_original(*args, **kwargs)\n\n        module.surf = surf_wrap\n\n        # Replace contour function with a wrapper function that discards\n        # its return value (see comment for plot function)\n        contour_original = module.contour\n\n        def contour_wrap(*args, **kwargs):\n            contour_original(*args, **kwargs)\n\n        module.contour = contour_wrap\n\n        # Replace imview function with a wrapper function that discards\n        # its return value (see comment for plot function)\n        imview_original = module.imview\n\n        def imview_wrap(*args, **kwargs):\n            imview_original(*args, **kwargs)\n\n        module.imview = imview_wrap\n\n        # Disable figure show method (results in a warning if used within\n        # a notebook with inline plotting)\n        import matplotlib.figure\n\n        def show_disable(self):\n            pass\n\n        matplotlib.figure.Figure.show = show_disable", "response": "Configure plotting functions for inline plotting within a Jupyter\n    Notebook shell."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rhochange(self):\n\n        if self.opt['HighMemSolve']:\n            self.c = sl.solvedbi_sm_c(self.gDf, np.conj(self.gDf), self.rho,\n                                      self.cri.axisM)", "response": "Updated cached c array when rho changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ystep(self):\n\n        self.Y = sp.prox_l1l2(self.AX + self.U, (self.lmbda/self.rho)*self.wl1,\n                             (self.mu/self.rho), axis=self.cri.axisC)\n        cbpdn.GenericConvBPDN.ystep(self)", "response": "Minimise Augmented Lagrangian with respect to\n        self. Y = sp. prox_l1l2 self. mu self. mu self. rho self. mu self. rho"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef block_sep0(self, Y):\n\n        # This method is overridden because we have to change the\n        # mechanism for combining the Y0 and Y1 blocks into a single\n        # array (see comment in the __init__ method).\n        shp = Y.shape[0:self.cri.axisC] + self.y0shp[self.cri.axisC:]\n        return Y[(slice(None),)*self.cri.axisC +\n                 (slice(0, self.y0I),)].reshape(shp)", "response": "rSeparate variable into component corresponding to to\n        y_0 in : math:` \\ mathbf { y}_0 in \\ mathbf { y}_1 in \\ mathbf { y}_0 in \\ mathbf { y}_1 in \\ mathbf { y}_0 in \\ mathbf { y}_1 in \\ mathbf { y}_0 in \\ mathbf { y}_1 in \\ mathbf { y}_0 in \\ mathbf { y}_0 in \\ mathbf ;."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef block_sep1(self, Y):\n\n        # This method is overridden because we have to change the\n        # mechanism for combining the Y0 and Y1 blocks into a single\n        # array (see comment in the __init__ method).\n        shp = Y.shape[0:self.cri.axisC] + self.y1shp[self.cri.axisC:]\n        return Y[(slice(None),)*self.cri.axisC +\n                 (slice(self.y0I, None),)].reshape(shp)", "response": "rSeparate variable into component corresponding to to\n        y_1 in : math:` \\ mathbf { y}_1 in \\ mathbf { y}_0 in \\ mathbf { y_1 in \\ mathbf { y_0 in \\ mathbf { y_1 in \\ mathbf { y_1 in \\ mathbf { y_1 } }."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the dictionary array.", "response": "def setdict(self, D=None, B=None):\n        \"\"\"Set dictionary array.\"\"\"\n\n        if D is not None:\n            self.D = np.asarray(D, dtype=self.dtype)\n        if B is not None:\n            self.B = np.asarray(B, dtype=self.dtype)\n\n        if B is not None or not hasattr(self, 'Gamma'):\n            self.Gamma, self.Q = np.linalg.eigh(self.B.T.dot(self.B))\n            self.Gamma = np.abs(self.Gamma)\n\n        if D is not None or not hasattr(self, 'Df'):\n            self.Df = sl.rfftn(self.D, self.cri.Nv, self.cri.axisN)\n\n        # Fold square root of Gamma into the dictionary array to enable\n        # use of the solvedbi_sm solver\n        shpg = [1] * len(self.cri.shpD)\n        shpg[self.cri.axisC] = self.Gamma.shape[0]\n        Gamma2 = np.sqrt(self.Gamma).reshape(shpg)\n        self.gDf = Gamma2 * self.Df\n\n        if self.opt['HighMemSolve']:\n            self.c = sl.solvedbd_sm_c(\n                self.gDf, np.conj(self.gDf),\n                (self.mu / self.rho) * self.GHGf + 1.0, self.cri.axisM)\n        else:\n            self.c = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nminimises Augmented Lagrangian with respect to .", "response": "def xstep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{x}`.\n        \"\"\"\n\n        self.YU[:] = self.Y - self.U\n        self.block_sep0(self.YU)[:] += self.S\n        Zf = sl.rfftn(self.YU, None, self.cri.axisN)\n        Z0f = self.block_sep0(Zf)\n        Z1f = self.block_sep1(Zf)\n\n        DZ0f = np.conj(self.Df) * Z0f\n        DZ0fBQ = sl.dot(self.B.dot(self.Q).T, DZ0f, axis=self.cri.axisC)\n        Z1fQ = sl.dot(self.Q.T, Z1f, axis=self.cri.axisC)\n        b = DZ0fBQ + Z1fQ\n\n        Xh = sl.solvedbd_sm(self.gDf, (self.mu / self.rho) * self.GHGf + 1.0,\n                            b, self.c, axis=self.cri.axisM)\n        self.Xf[:] = sl.dot(self.Q, Xh, axis=self.cri.axisC)\n        self.X = sl.irfftn(self.Xf, self.cri.Nv, self.cri.axisN)\n\n        if self.opt['LinSolveCheck']:\n            DDXf = np.conj(self.Df) *  sl.inner(self.Df, self.Xf,\n                                                axis=self.cri.axisM)\n            DDXfBB = sl.dot(self.B.T.dot(self.B), DDXf, axis=self.cri.axisC)\n            ax = self.rho * (DDXfBB + self.Xf) + \\\n                 self.mu * self.GHGf * self.Xf\n            b = self.rho * (sl.dot(self.B.T, DZ0f, axis=self.cri.axisC)\n                            + Z1f)\n            self.xrrs = sl.rrs(ax, b)\n        else:\n            self.xrrs = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing dual residual vector.", "response": "def rsdl_s(self, Yprev, Y):\n        \"\"\"Compute dual residual vector.\"\"\"\n\n        return self.rho * self.cnst_AT(self.U)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nminimises Augmented Lagrangian with respect to Y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        AXU = self.AX + self.U\n        Y0 = sp.prox_l1(self.block_sep0(AXU) - self.S, (1.0/self.rho)*self.W)\n        Y1 = sp.prox_l1l2(self.block_sep1(AXU), 0.0,\n                         (self.lmbda/self.rho)*self.wl21,\n                         axis=self.cri.axisC)\n        self.Y = self.block_cat(Y0, Y1)\n        cbpdn.ConvTwoBlockCnstrnt.ystep(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef solve(self, S, dimK=None):\n\n        # Use dimK specified in __init__ as default\n        if dimK is None and self.dimK is not None:\n            dimK = self.dimK\n\n        # Start solve timer\n        self.timer.start(['solve', 'solve_wo_eval'])\n\n        # Solve CSC problem on S and do dictionary step\n        self.init_vars(S, dimK)\n        self.xstep(S, self.lmbda, dimK)\n        self.dstep()\n\n        # Stop solve timer\n        self.timer.stop('solve_wo_eval')\n\n        # Extract and record iteration stats\n        self.manage_itstat()\n\n        # Increment iteration count\n        self.j += 1\n\n        # Stop solve timer\n        self.timer.stop('solve')\n\n        # Return current dictionary\n        return self.getdict()", "response": "Compute sparse coding and dictionary update for training\n        data S."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef manage_itstat(self):\n\n        # Extract and record iteration stats\n        itst = self.iteration_stats()\n        self.itstat.append(itst)\n        self.display_status(self.fmtstr, itst)", "response": "Compute record and display iteration statistics."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hdrval(cls):\n\n        hdrmap = {'Itn': 'Iter', 'X r': 'PrimalRsdl', 'X s': 'DualRsdl',\n                  u('X \u03c1'): 'Rho', 'D cnstr': 'Cnstr', 'D dlt': 'DeltaD',\n                  u('D \u03b7'): 'Eta'}\n        return hdrmap", "response": "Construct dictionary mapping display column title to iterationStats entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs iteration stats record tuple.", "response": "def iteration_stats(self):\n        \"\"\"Construct iteration stats record tuple.\"\"\"\n\n        tk = self.timer.elapsed(self.opt['IterTimer'])\n        if self.xstep_itstat is None:\n            objfn = (0.0,) * 3\n            rsdl = (0.0,) * 2\n            rho = (0.0,)\n        else:\n            objfn = (self.xstep_itstat.ObjFun, self.xstep_itstat.DFid,\n                     self.xstep_itstat.RegL1)\n            rsdl = (self.xstep_itstat.PrimalRsdl,\n                    self.xstep_itstat.DualRsdl)\n            rho = (self.xstep_itstat.Rho,)\n\n        cnstr = np.linalg.norm(cr.zpad(self.D, self.cri.Nv) - self.G)\n        dltd = np.linalg.norm(self.D - self.Dprv)\n\n        tpl = (self.j,) + objfn + rsdl + rho + (cnstr, dltd, self.eta) + \\\n              self.itstat_extra() + (tk,)\n        return type(self).IterationStats(*tpl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display_config(self):\n\n        if self.opt['Verbose']:\n            hdrtxt = type(self).hdrtxt()\n            # Call utility function to construct status display formatting\n            self.hdrstr, self.fmtstr, self.nsep = common.solve_status_str(\n                hdrtxt, fwdth0=type(self).fwiter, fprec=type(self).fpothr)\n        else:\n            self.hdrstr, self.fmtstr, self.nsep = '', '', 0", "response": "Set up status display if option selected."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_start(self):\n\n        if self.opt['Verbose'] and self.opt['StatusHeader']:\n            print(self.hdrstr)\n            print(\"-\" * self.nsep)", "response": "Start status display if option selected."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef solve(self, S, W=None, dimK=None):\n\n        # Use dimK specified in __init__ as default\n        if dimK is None and self.dimK is not None:\n            dimK = self.dimK\n\n        # Start solve timer\n        self.timer.start(['solve', 'solve_wo_eval'])\n\n        # Solve CSC problem on S and do dictionary step\n        self.init_vars(S, dimK)\n        if W is None:\n            W = np.array([1.0], dtype=self.dtype)\n        W = np.asarray(W.reshape(cr.mskWshape(W, self.cri)),\n                       dtype=self.dtype)\n        self.xstep(S, W, self.lmbda, dimK)\n        self.dstep(W)\n\n        # Stop solve timer\n        self.timer.stop('solve_wo_eval')\n\n        # Extract and record iteration stats\n        self.manage_itstat()\n\n        # Increment iteration count\n        self.j += 1\n\n        # Stop solve timer\n        self.timer.stop('solve')\n\n        # Return current dictionary\n        return self.getdict()", "response": "Compute sparse coding and dictionary update for training\n        data S and W."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xstep(self, S, W, lmbda, dimK):\n\n        if self.opt['CUDA_CBPDN']:\n            Z = cuda.cbpdnmsk(self.D.squeeze(), S[..., 0], W.squeeze(), lmbda,\n                              self.opt['CBPDN'])\n            Z = Z.reshape(self.cri.Nv + (1, 1, self.cri.M,))\n            self.Z[:] = np.asarray(Z, dtype=self.dtype)\n            self.Zf = sl.rfftn(self.Z, self.cri.Nv, self.cri.axisN)\n            self.Sf = sl.rfftn(S.reshape(self.cri.shpS), self.cri.Nv,\n                               self.cri.axisN)\n            self.xstep_itstat = None\n        else:\n            # Create X update object (external representation is expected!)\n            xstep = cbpdn.ConvBPDNMaskDcpl(self.D.squeeze(), S, lmbda, W,\n                                           self.opt['CBPDN'], dimK=dimK,\n                                           dimN=self.cri.dimN)\n            xstep.solve()\n            self.Sf = sl.rfftn(S.reshape(self.cri.shpS), self.cri.Nv,\n                               self.cri.axisN)\n            self.setcoef(xstep.getcoef())\n            self.xstep_itstat = xstep.itstat[-1] if xstep.itstat else None", "response": "Solve CSC problem for training data S."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes dictionary update for training data of preceding .", "response": "def dstep(self, W):\n        \"\"\"Compute dictionary update for training data of preceding\n        :meth:`xstep`.\n        \"\"\"\n\n        # Compute residual X D - S in frequency domain\n        Ryf = sl.inner(self.Zf, self.Df, axis=self.cri.axisM) - self.Sf\n        # Transform to spatial domain, apply mask, and transform back to\n        # frequency domain\n        Ryf[:] = sl.rfftn(W * sl.irfftn(Ryf, self.cri.Nv, self.cri.axisN),\n                          None, self.cri.axisN)\n        # Compute gradient\n        gradf = sl.inner(np.conj(self.Zf), Ryf, axis=self.cri.axisK)\n\n        # If multiple channel signal, single channel dictionary\n        if self.cri.C > 1 and self.cri.Cd == 1:\n            gradf = np.sum(gradf, axis=self.cri.axisC, keepdims=True)\n\n        # Update gradient step\n        self.eta = self.eta_a / (self.j + self.eta_b)\n\n        # Compute gradient descent\n        self.Gf[:] = self.Df - self.eta * gradf\n        self.G = sl.irfftn(self.Gf, self.cri.Nv, self.cri.axisN)\n\n        # Eval proximal operator\n        self.Dprv[:] = self.D\n        self.D[:] = self.Pcn(self.G)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the dict with the dict tree in parameter d.", "response": "def update(self, d):\n        \"\"\"Update the dict with the dict tree in parameter d.\n\n        Parameters\n        ----------\n        d : dict\n          New dict content\n        \"\"\"\n\n        # Call __setitem__ for all keys in d\n        for key in list(d.keys()):\n            self.__setitem__(key, d[key])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(self, key, value):\n\n        # This test necessary to avoid unpickling errors in Python 3\n        if hasattr(self, 'dflt'):\n            # Get corresponding node to self, as determined by pth\n            # attribute, of the defaults dict tree\n            a = self.__class__.getnode(self.dflt, self.pth)\n            # Raise UnknownKeyError exception if key not in corresponding\n            # node of defaults tree\n            if key not in a:\n                raise UnknownKeyError(self.pth + (key,))\n                # Raise InvalidValueError if the key value in the defaults\n                # tree is a dict and the value parameter is not a dict and\n            elif isinstance(a[key], dict) and not isinstance(value, dict):\n                raise InvalidValueError(self.pth + (key,))", "response": "Checks whether the key value pair is allowed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getparent(d, pth):\n\n        c = d\n        for key in pth[:-1]:\n            if not isinstance(c, dict):\n                raise InvalidValueError(c)\n            elif key not in c:\n                raise UnknownKeyError(pth)\n            else:\n                c = c.__getitem__(key)\n        return c", "response": "Get the parent node of a subdict as specified by the key path in\n        pth."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef par_xstep(i):\n    global mp_X\n    global mp_DX\n    YU0f = sl.rfftn(mp_Y0[[i]] - mp_U0[[i]], mp_Nv, mp_axisN)\n    YU1f = sl.rfftn(mp_Y1[mp_grp[i]:mp_grp[i+1]] -\n                    1/mp_alpha*mp_U1[mp_grp[i]:mp_grp[i+1]], mp_Nv, mp_axisN)\n    if mp_Cd == 1:\n        b = np.conj(mp_Df[mp_grp[i]:mp_grp[i+1]]) * YU0f + mp_alpha**2*YU1f\n        Xf = sl.solvedbi_sm(mp_Df[mp_grp[i]:mp_grp[i+1]], mp_alpha**2, b,\n                            mp_cache[i], axis=mp_axisM)\n    else:\n        b = sl.inner(np.conj(mp_Df[mp_grp[i]:mp_grp[i+1]]), YU0f,\n                     axis=mp_C) + mp_alpha**2*YU1f\n        Xf = sl.solvemdbi_ism(mp_Df[mp_grp[i]:mp_grp[i+1]], mp_alpha**2, b,\n                              mp_axisM, mp_axisC)\n    mp_X[mp_grp[i]:mp_grp[i+1]] = sl.irfftn(Xf, mp_Nv,\n                                            mp_axisN)\n    mp_DX[i] = sl.irfftn(sl.inner(mp_Df[mp_grp[i]:mp_grp[i+1]], Xf,\n                                  mp_axisM), mp_Nv, mp_axisN)", "response": "rMinimise Augmented Lagrangian with respect to\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef par_relax_AX(i):\n\n    global mp_X\n    global mp_Xnr\n    global mp_DX\n    global mp_DXnr\n    mp_Xnr[mp_grp[i]:mp_grp[i+1]] = mp_X[mp_grp[i]:mp_grp[i+1]]\n    mp_DXnr[i] = mp_DX[i]\n    if mp_rlx != 1.0:\n        grpind = slice(mp_grp[i], mp_grp[i+1])\n        mp_X[grpind] = mp_rlx * mp_X[grpind] + (1-mp_rlx)*mp_Y1[grpind]\n        mp_DX[i] = mp_rlx*mp_DX[i] + (1-mp_rlx)*mp_Y0[i]", "response": "Parallel implementation of relaxation if option RelaxParam!= 1. 0.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nminimising Augmented Lagrangian with respect to .", "response": "def par_y1step(i):\n    r\"\"\"Minimise Augmented Lagrangian with respect to\n    :math:`\\mathbf{y}_{1,G_i}`, one of the disjoint problems of\n    optimizing :math:`\\mathbf{y}_1`.\n\n    Parameters\n    ----------\n    i : int\n      Index of grouping to update\n    \"\"\"\n\n    global mp_Y1\n    grpind = slice(mp_grp[i], mp_grp[i+1])\n    XU1 = mp_X[grpind] + 1/mp_alpha*mp_U1[grpind]\n    if mp_wl1.shape[mp_axisM] is 1:\n        gamma = mp_lmbda/(mp_alpha**2*mp_rho)*mp_wl1\n    else:\n        gamma = mp_lmbda/(mp_alpha**2*mp_rho)*mp_wl1[grpind]\n    Y1 = sp.prox_l1(XU1, gamma)\n    if mp_NonNegCoef:\n        Y1[Y1 < 0.0] = 0.0\n    if mp_NoBndryCross:\n        for n in range(len(mp_Nv)):\n            Y1[(slice(None),) + (slice(None),)*n +\n               (slice(1-mp_Dshp[n], None),)] = 0.0\n    mp_Y1[mp_grp[i]:mp_grp[i+1]] = Y1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef par_final_stepgrp(i):\n\n    par_y0bstep(i)\n    par_y1step(i)\n    par_u0step(i)\n    par_u1step(i)", "response": "The parallel step grouping of the final iteration in solve."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the components of the residual and stopping thresholds that can be done in parallel.", "response": "def par_compute_residuals(i):\n    \"\"\"Compute components of the residual and stopping thresholds that\n    can be done in parallel.\n\n    Parameters\n    ----------\n    i : int\n      Index of group to compute\n    \"\"\"\n\n    # Compute the residuals in parallel, need to check if the residuals\n    # depend on alpha\n    global mp_ry0\n    global mp_ry1\n    global mp_sy0\n    global mp_sy1\n    global mp_nrmAx\n    global mp_nrmBy\n    global mp_nrmu\n    mp_ry0[i] = np.sum((mp_DXnr[i] - mp_Y0[i])**2)\n    mp_ry1[i] = mp_alpha**2*np.sum((mp_Xnr[mp_grp[i]:mp_grp[i+1]]-\n                                    mp_Y1[mp_grp[i]:mp_grp[i+1]])**2)\n    mp_sy0[i] = np.sum((mp_Y0old[i] - mp_Y0[i])**2)\n    mp_sy1[i] = mp_alpha**2*np.sum((mp_Y1old[mp_grp[i]:mp_grp[i+1]]-\n                                    mp_Y1[mp_grp[i]:mp_grp[i+1]])**2)\n    mp_nrmAx[i] = np.sum(mp_DXnr[i]**2) + mp_alpha**2 * np.sum(\n        mp_Xnr[mp_grp[i]:mp_grp[i+1]]**2)\n    mp_nrmBy[i] = np.sum(mp_Y0[i]**2) + mp_alpha**2 * np.sum(\n        mp_Y1[mp_grp[i]:mp_grp[i+1]]**2)\n    mp_nrmu[i] = np.sum(mp_U0[i]**2) + np.sum(mp_U1[mp_grp[i]:mp_grp[i+1]]**2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts or re - start the optimisation of the object.", "response": "def solve(self):\n        \"\"\"Start (or re-start) optimisation. This method implements the\n        framework for the iterations of an ADMM algorithm.\n\n        If option ``Verbose`` is ``True``, the progress of the\n        optimisation is displayed at every iteration. At termination\n        of this method, attribute :attr:`itstat` is a list of tuples\n        representing statistics of each iteration, unless option\n        ``FastSolve`` is ``True`` and option ``Verbose`` is ``False``.\n\n        Attribute :attr:`timer` is an instance of :class:`.util.Timer`\n        that provides the following labelled timers:\n\n          ``init``: Time taken for object initialisation by\n          :meth:`__init__`\n\n          ``solve``: Total time taken by call(s) to :meth:`solve`\n\n          ``solve_wo_func``: Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics\n\n          ``solve_wo_rsdl`` : Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics as well as time take\n          to compute residuals and implemented ``AutoRho`` mechanism\n        \"\"\"\n\n        global mp_Y0old\n        global mp_Y1old\n\n        self.init_pool()\n\n        fmtstr, nsep = self.display_start()\n\n        # Start solve timer\n        self.timer.start(['solve', 'solve_wo_func', 'solve_wo_rsdl'])\n\n        first_iteration = self.k\n        last_iteration = self.k + self.opt['MaxMainIter'] - 1\n        # Main optimisation iterations\n        for self.k in range(self.k, self.k + self.opt['MaxMainIter']):\n            mp_Y0old[:] = np.copy(mp_Y0)\n            mp_Y1old[:] = np.copy(mp_Y1)\n\n            # Perform the variable updates.\n            if self.k is first_iteration:\n                self.distribute(par_initial_stepgrp, mp_ngrp)\n            y0astep()\n            if self.k is last_iteration:\n                self.distribute(par_final_stepgrp, mp_ngrp)\n            else:\n                self.distribute(par_stepgrp, mp_ngrp)\n\n            # Compute the residual variables\n            self.timer.stop('solve_wo_rsdl')\n            if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n                self.distribute(par_compute_residuals, mp_ngrp)\n                r = np.sqrt(np.sum(mp_ry0) + np.sum(mp_ry1))\n                s = np.sqrt(np.sum(mp_sy0) + np.sum(mp_sy1))\n\n                epri = np.sqrt(self.Nc) * self.opt['AbsStopTol'] + \\\n                  np.max([np.sqrt(np.sum(mp_nrmAx)),\n                          np.sqrt(np.sum(mp_nrmBy))]) * self.opt['RelStopTol']\n\n                edua = np.sqrt(self.Nx) * self.opt['AbsStopTol'] + \\\n                  np.sqrt(np.sum(mp_nrmu)) * self.opt['RelStopTol']\n\n            # Compute and record other iteration statistics and\n            # display iteration stats if Verbose option enabled\n            self.timer.stop(['solve_wo_func', 'solve_wo_rsdl'])\n            if not self.opt['FastSolve']:\n                itst = self.iteration_stats(self.k, r, s, epri, edua)\n                self.itstat.append(itst)\n                self.display_status(fmtstr, itst)\n            self.timer.start(['solve_wo_func', 'solve_wo_rsdl'])\n\n            # Automatic rho adjustment\n            # self.timer.stop('solve_wo_rsdl')\n            # if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n            #     self.update_rho(self.k, r, s)\n            # self.timer.start('solve_wo_rsdl')\n\n            # Call callback function if defined\n            if self.opt['Callback'] is not None:\n                if self.opt['Callback'](self):\n                    break\n\n            # Stop if residual-based stopping tolerances reached\n            if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n                if r < epri and s < edua:\n                    break\n\n        # Increment iteration count\n        self.k += 1\n\n        # Record solve time\n        self.timer.stop(['solve', 'solve_wo_func', 'solve_wo_rsdl'])\n\n        # Print final separator string if Verbose option enabled\n        self.display_end(nsep)\n\n        self.Y = np.moveaxis(mp_Y1, mp_axisM, self.cri.axisM)\n        self.X = np.moveaxis(mp_X, mp_axisM, self.cri.axisM)\n\n        self.terminate_pool()\n\n        return self.getmin()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize multiprocessing pool if necessary.", "response": "def init_pool(self):\n        \"\"\"Initialize multiprocessing pool if necessary.\"\"\"\n\n        # initialize the pool if needed\n        if self.pool is None:\n            if self.nproc > 1:\n                self.pool = mp.Pool(processes=self.nproc)\n            else:\n                self.pool = None\n        else:\n            print('pool already initialized?')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distribute(self, f, n):\n\n        if self.pool is None:\n            return [f(i) for i in range(n)]\n        else:\n            return self.pool.map(f, range(n))", "response": "Distribute the computations amongst the multiprocessing pools\n ArcGIS"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nterminating and close the multiprocessing pool if necessary.", "response": "def terminate_pool(self):\n        \"\"\"Terminate and close the multiprocessing pool if necessary.\"\"\"\n\n        if self.pool is not None:\n            self.pool.terminate()\n            self.pool.join()\n            del(self.pool)\n            self.pool = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef obfn_dfd(self):\n        XF = sl.rfftn(self.obfn_fvar(), mp_Nv, mp_axisN)\n        DX = np.moveaxis(sl.irfftn(sl.inner(mp_Df, XF, mp_axisM),\n                                   mp_Nv, mp_axisN), mp_axisM,\n                         self.cri.axisM)\n        return np.sum((self.W*(DX-self.S))**2)/2.0", "response": "r Compute data fidelity term :math:` ( 1 / 2 ) \\ | W \\ left ( \\ sum_m\n \\ mathbf { d}_m - \\ mathbf { x}_m - \\ mathbf { s } \\ right \\ |_2^2."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nminimises Augmented Lagrangian with respect to respect to y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to :math:`\\mathbf{y}`.\n        If this method is not overridden, the problem is solved without\n        any regularisation other than the option enforcement of\n        non-negativity of the solution and filter boundary crossing\n        supression. When it is overridden, it should be explicitly\n        called at the end of the overriding method.\n        \"\"\"\n\n        if self.opt['NonNegCoef']:\n            self.Y[self.Y < 0.0] = 0.0\n        if self.opt['NoBndryCross']:\n            for n in range(0, self.cri.dimN):\n                self.Y[(slice(None),) * n +\n                       (slice(1 - self.D.shape[n], None),)] = 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obfn_dfd(self):\n\n        Ef = sl.inner(self.Df, self.obfn_fvarf(), axis=self.cri.axisM) - \\\n            self.Sf\n        return sl.rfl2norm2(Ef, self.S.shape, axis=self.cri.axisN) / 2.0", "response": "Compute data fidelity term :math:` ( 1 / 2 ) \\ | sum_m \\ mathbf { d}_m \\ | x_m \\ |_2^2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ystep(self):\n\n        self.Y = sp.prox_l1(self.AX + self.U,\n                            (self.lmbda / self.rho) * self.wl1)\n        super(ConvBPDN, self).ystep()", "response": "Minimise Augmented Lagrangian with respect to\n        y."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_reg(self):\n\n        rl1 = np.linalg.norm((self.wl1 * self.obfn_gvar()).ravel(), 1)\n        return (self.lmbda*rl1, rl1)", "response": "Compute regularisation term and contribution to objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xstep(self):\n\n        self.YU[:] = self.Y - self.U\n\n        b = self.DSf + self.rho*sl.rfftn(self.YU, None, self.cri.axisN)\n        if self.cri.Cd == 1:\n            self.Xf[:] = sl.solvedbi_sm(self.Df, self.mu + self.rho,\n                                        b, self.c, self.cri.axisM)\n        else:\n            self.Xf[:] = sl.solvemdbi_ism(self.Df, self.mu + self.rho, b,\n                                          self.cri.axisM, self.cri.axisC)\n\n        self.X = sl.irfftn(self.Xf, self.cri.Nv, self.cri.axisN)\n\n        if self.opt['LinSolveCheck']:\n            Dop = lambda x: sl.inner(self.Df, x, axis=self.cri.axisM)\n            if self.cri.Cd == 1:\n                DHop = lambda x: np.conj(self.Df) * x\n            else:\n                DHop = lambda x: sl.inner(np.conj(self.Df), x,\n                                          axis=self.cri.axisC)\n            ax = DHop(Dop(self.Xf)) + (self.mu + self.rho)*self.Xf\n            self.xrrs = sl.rrs(ax, b)\n        else:\n            self.xrrs = None", "response": "Minimise Augmented Lagrangian with respect to the\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef obfn_reg(self):\n\n        rl1 = np.linalg.norm((self.wl1 * self.obfn_gvar()).ravel(), 1)\n        rl2 = 0.5*np.linalg.norm(self.obfn_gvar())**2\n        return (self.lmbda*rl1 + self.mu*rl2, rl1, rl2)", "response": "Compute regularisation term and contribution to objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef obfn_reg(self):\n\n        fvf = self.obfn_fvarf()\n        rl1 = np.linalg.norm((self.wl1 * self.obfn_gvar()).ravel(), 1)\n        rgr = sl.rfl2norm2(np.sqrt(self.GHGf*np.conj(fvf)*fvf), self.cri.Nv,\n                           self.cri.axisN)/2.0\n        return (self.lmbda*rl1 + self.mu*rgr, rl1, rgr)", "response": "Compute regularisation term and contribution to objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn initialiser for working variable U.", "response": "def uinit(self, ushape):\n        \"\"\"Return initialiser for working variable U.\"\"\"\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            # NB: still needs to be worked out.\n            return np.zeros(ushape, dtype=self.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ystep(self):\n\n        self.Y = sp.proj_l1(self.AX + self.U, self.gamma,\n                            axis=self.cri.axisN + (self.cri.axisC,\n                                                   self.cri.axisM))\n        super(ConvBPDNProjL1, self).ystep()", "response": "Minimise Augmented Lagrangian with respect to\n        self. y = sp. proj_l1. y"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing components of regularisation function as well as total objective function.", "response": "def eval_objfn(self):\n        \"\"\"Compute components of regularisation function as well as total\n        objective function.\n        \"\"\"\n\n        dfd = self.obfn_dfd()\n        prj = sp.proj_l1(self.obfn_gvar(), self.gamma,\n                         axis=self.cri.axisN + (self.cri.axisC,\n                                                self.cri.axisM))\n        cns = np.linalg.norm(prj - self.obfn_gvar())\n        return (dfd, cns)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ystep(self):\n\n        if self.opt['NonNegCoef'] or self.opt['NoBndryCross']:\n            Y1 = self.block_sep1(self.Y)\n            if self.opt['NonNegCoef']:\n                Y1[Y1 < 0.0] = 0.0\n            if self.opt['NoBndryCross']:\n                for n in range(0, self.cri.dimN):\n                    Y1[(slice(None),)*n +\n                       (slice(1-self.D.shape[n], None),)] = 0.0\n            self.block_sep1(self.Y)[:] = Y1", "response": "Minimise Augmented Lagrangian with respect to the\n            Y."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef relax_AX(self):\n\n        self.AXnr = self.cnst_A(self.X, self.Xf)\n        if self.rlx == 1.0:\n            self.AX = self.AXnr\n        else:\n            if not hasattr(self, 'c0'):\n                self.c0 = self.cnst_c0()\n            if not hasattr(self, 'c1'):\n                self.c1 = self.cnst_c1()\n            alpha = self.rlx\n            self.AX = alpha*self.AXnr + (1-alpha)*self.block_cat(\n                self.var_y0() + self.c0, self.var_y1() + self.c1)", "response": "Implement relaxation if option RelaxParam!= 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nseparating variable into component corresponding to to y_0 in : math:` \\ mathbf { y}_0 in : math:` \\ mathbf { y_1 } \\ ;.", "response": "def block_sep0(self, Y):\n        r\"\"\"Separate variable into component corresponding to\n        :math:`\\mathbf{y}_0` in :math:`\\mathbf{y}\\;\\;`. The method\n        from parent class :class:`.ADMMTwoBlockCnstrnt` is overridden\n        here to allow swapping of C (channel) and M (filter) axes in\n        block 0 so that it can be concatenated on axis M with block\n        1. This is necessary because block 0 has the dimensions of S\n        (N x C x K x 1) while block 1 has the dimensions of X (N x 1 x\n        K x M).\n        \"\"\"\n        if self.y0swapaxes:\n            return np.swapaxes(Y[(slice(None),)*self.blkaxis +\n                                 (slice(0, self.blkidx),)],\n                               self.cri.axisC, self.cri.axisM)\n        else:\n            return super(ConvTwoBlockCnstrnt, self).block_sep0(Y)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef obfn_g0var(self):\n\n        return self.var_y0() if self.opt['AuxVarObj'] else \\\n            self.cnst_A0(None, self.Xf) - self.cnst_c0()", "response": "Variable to be evaluated in computing\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cnst_A0(self, X, Xf=None):\n\n        # This calculation involves non-negligible computational cost\n        # when Xf is None (i.e. the function is not being applied to\n        # self.X).\n        if Xf is None:\n            Xf = sl.rfftn(X, None, self.cri.axisN)\n        return sl.irfftn(sl.inner(self.Df, Xf, axis=self.cri.axisM),\n                         self.cri.Nv, self.cri.axisN)", "response": "r Compute A_0 component of ADMM problem of problem of A_0 constraint."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nminimises Augmented Lagrangian with respect to .", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        AXU = self.AX + self.U\n        Y0 = sp.proj_l2(self.block_sep0(AXU) - self.S, self.epsilon,\n                            axis=self.cri.axisN)\n        Y1 = sp.prox_l1(self.block_sep1(AXU), self.wl1 / self.rho)\n        self.Y = self.block_cat(Y0, Y1)\n\n        super(ConvMinL1InL2Ball, self).ystep()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_g0(self, Y0):\n\n        return np.linalg.norm(sp.proj_l2(Y0, self.epsilon,\n                                         axis=self.cri.axisN) - Y0)", "response": "r Compute g_0 component of ADMM objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_objfn(self):\n\n        g0v = self.obfn_g0(self.obfn_g0var())\n        g1v = self.obfn_g1(self.obfn_g1var())\n        return (g1v, g0v)", "response": "Compute components of regularisation function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ystep(self):\n\n        AXU = self.AX + self.U\n        Y0 = (self.rho*(self.block_sep0(AXU) - self.S)) / \\\n             (self.W**2 + self.rho)\n        Y1 = sp.prox_l1(self.block_sep1(AXU),\n                        (self.lmbda / self.rho) * self.wl1)\n        self.Y = self.block_cat(Y0, Y1)\n\n        super(ConvBPDNMaskDcpl, self).ystep()", "response": "Minimise Augmented Lagrangian with respect to\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef obfn_gvar(self):\n\n        # Get inner cbpdn object gvar\n        gv = self.inner_obfn_gvar().copy()\n        # Set slice corresponding to the coefficient map of the final\n        # filter (the impulse inserted for the AMS method) to zero so\n        # that it does not affect the results (e.g. l1 norm) computed\n        # from this variable by the inner cbpdn object\n        gv[..., -self.cri.Cd:] = 0\n\n        return gv", "response": "This method is inserted into the inner cbpdn object and replacing its own obfn_gvar method with a hook for the AMS method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing components of regularisation function as well as total contribution to objective function.", "response": "def eval_objfn(self):\n        \"\"\"Compute components of regularisation function as well as total\n        contribution to objective function.\n        \"\"\"\n\n        g0v = self.obfn_g0(self.obfn_g0var())\n        g1v = self.obfn_g1(self.obfn_g1var())\n        rgr = sl.rfl2norm2(np.sqrt(self.GHGf * np.conj(self.Xf) * self.Xf),\n                           self.cri.Nv, self.cri.axisN)/2.0\n        obj = g0v + self.lmbda*g1v + self.mu*rgr\n        return (obj, g0v, g1v, rgr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_g0(self, Y0):\n\n        return np.sum(np.abs(self.W * self.obfn_g0var()))", "response": "r Compute g_0 component of ADMM objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating cached c array when rho changes.", "response": "def rhochange(self):\n        \"\"\"Updated cached c array when rho changes.\"\"\"\n\n        if self.opt['HighMemSolve'] and self.cri.Cd == 1:\n            self.c = sl.solvedbd_sm_c(\n                self.Df, np.conj(self.Df),\n                (self.mu / self.rho) * self.GHGf + 1.0, self.cri.axisM)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the solve method of the inner cbpdn object and return the the result.", "response": "def solve(self):\n        \"\"\"Call the solve method of the inner cbpdn object and return the\n        result.\n        \"\"\"\n\n        # Call solve method of inner cbpdn object\n        Xi = self.cbpdn.solve()\n        # Copy attributes from inner cbpdn object\n        self.timer = self.cbpdn.timer\n        self.itstat = self.cbpdn.itstat\n        # Return result of inner cbpdn object\n        return Xi"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreconstructs representation of signal b in signal set X.", "response": "def reconstruct(self, b, X=None):\n        \"\"\"Reconstruct representation of signal b in signal set.\"\"\"\n\n        if X is None:\n            X = self.getcoef()\n        Xf = sl.rfftn(X, None, self.cbpdn.cri.axisN)\n        slc = (slice(None),)*self.dimN + \\\n              (slice(self.chncs[b], self.chncs[b+1]),)\n        Sf = np.sum(self.cbpdn.Df[slc] * Xf, axis=self.cbpdn.cri.axisM)\n        return sl.irfftn(Sf, self.cbpdn.cri.Nv, self.cbpdn.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_nested_class_lookup(cls, nstnm):\n\n    # Check that nstnm is an attribute of cls\n    if nstnm in cls.__dict__:\n        # Get the attribute of cls by its name\n        nst = cls.__dict__[nstnm]\n        # Check that the attribute is a class\n        if isinstance(nst, type):\n            # Get the module in which the outer class is defined\n            mdl = sys.modules[cls.__module__]\n            # Construct an extended name by concatenating inner and outer\n            # names\n            extnm = cls.__name__ + nst.__name__\n            # Allow lookup of the nested class within the module via\n            # its extended name\n            setattr(mdl, extnm, nst)\n            # Change the nested class name to the extended name\n            nst.__name__ = extnm\n    return cls", "response": "Fix name lookup problem that prevents pickling of nested class in the given class by concatenating inner and outer class names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fix_dynamic_class_lookup(cls, pstfx):\n\n    # Extended name for the class that will be added to the module namespace\n    extnm = '_' + cls.__name__ + '_' + pstfx\n    # Get the module in which the dynamic class is defined\n    mdl = sys.modules[cls.__module__]\n    # Allow lookup of the dynamically generated class within the module via\n    # its extended name\n    setattr(mdl, extnm, cls)\n    # Change the dynamically generated class name to the extended name\n    if hasattr(cls, '__qualname__'):\n        cls.__qualname__ = extnm\n    else:\n        cls.__name__ = extnm", "response": "Fix name lookup problem that prevents pickling of dynamically generated classes within the module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solve_status_str(hdrlbl, fmtmap=None, fwdth0=4, fwdthdlt=6,\n                     fprec=2):\n    \"\"\"Construct header and format details for status display of an\n    iterative solver.\n\n    Parameters\n    ----------\n    hdrlbl : tuple of strings\n      Tuple of field header strings\n    fmtmap : dict or None, optional (default None)\n      A dict providing a mapping from field header strings to print\n      format strings, providing a mechanism for fields with print\n      formats that depart from the standard format\n    fwdth0 : int, optional (default 4)\n      Number of characters in first field formatted for integers\n    fwdthdlt : int, optional (default 6)\n      The width of fields formatted for floats is the sum of the value\n      of this parameter and the field precision\n    fprec : int, optional (default 2)\n      Precision of fields formatted for floats\n\n    Returns\n    -------\n    hdrstr : string\n      Complete header string\n    fmtstr : string\n      Complete print formatting string for numeric values\n    nsep : integer\n      Number of characters in separator string\n    \"\"\"\n\n    if fmtmap is None:\n        fmtmap = {}\n    fwdthn = fprec + fwdthdlt\n\n    # Construct a list specifying the format string for each field.\n    # Use format string from fmtmap if specified, otherwise use\n    # a %d specifier with field width fwdth0 for the first field,\n    # or a %e specifier with field width fwdthn and precision\n    # fprec\n    fldfmt = [fmtmap[lbl] if lbl in fmtmap else\n              (('%%%dd' % (fwdth0)) if idx == 0 else\n               (('%%%d.%de' % (fwdthn, fprec))))\n              for idx, lbl in enumerate(hdrlbl)]\n    fmtstr = ('  ').join(fldfmt)\n\n    # Construct a list of field widths for each field by extracting\n    # field widths from field format strings\n    cre = re.compile(r'%-?(\\d+)')\n    fldwid = []\n    for fmt in fldfmt:\n        mtch = cre.match(fmt)\n        if mtch is None:\n            raise ValueError(\"Format string '%s' does not contain field \"\n                             \"width\" % fmt)\n        else:\n            fldwid.append(int(mtch.group(1)))\n\n    # Construct list of field header strings formatted to the\n    # appropriate field width, and join to construct a combined field\n    # header string\n    hdrlst = [('%-*s' % (w, t)) for t, w in zip(hdrlbl, fldwid)]\n    hdrstr = ('  ').join(hdrlst)\n\n    return hdrstr, fmtstr, len(hdrstr)", "response": "Construct a status string for an iterative solver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the dtype attribute of the object.", "response": "def set_dtype(self, opt, dtype):\n        \"\"\"Set the `dtype` attribute. If opt['DataType'] has a value\n        other than None, it overrides the `dtype` parameter of this\n        method. No changes are made if the `dtype` attribute already\n        exists and has a value other than 'None'.\n\n        Parameters\n        ----------\n        opt : :class:`cdict.ConstrainedDict` object\n          Algorithm options\n        dtype : data-type\n          Data type for working variables (overridden by 'DataType' option)\n        \"\"\"\n\n        # Take no action of self.dtype exists and is not None\n        if not hasattr(self, 'dtype') or self.dtype is None:\n            # DataType option overrides explicitly specified data type\n            if opt['DataType'] is None:\n                self.dtype = dtype\n            else:\n                self.dtype = np.dtype(opt['DataType'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets an object attribute by its name.", "response": "def set_attr(self, name, val, dval=None, dtype=None, reset=False):\n        \"\"\"Set an object attribute by its name. The attribute value\n        can be specified as a primary value `val`, and as default\n        value 'dval` that will be used if the primary value is None.\n        This arrangement allows an attribute to be set from an entry\n        in an options object, passed as `val`, while specifying a\n        default value to use, passed as `dval` in the event that the\n        options entry is None. Unless `reset` is True, the attribute\n        is only set if it doesn't exist, or if it exists with value\n        None. This arrangement allows for attributes to be set in\n        both base and derived class initialisers, with the derived\n        class value taking preference.\n\n        Parameters\n        ----------\n        name : string\n          Attribute name\n        val : any\n          Primary attribute value\n        dval : any\n          Default attribute value in case `val` is None\n        dtype : data-type, optional (default None)\n          If the `dtype` parameter is not None, the attribute `name` is\n          set to `val` (which is assumed to be of numeric type) after\n          conversion to the specified type.\n        reset : bool, optional (default False)\n          Flag indicating whether attribute assignment should be\n          conditional on the attribute not existing or having value None.\n          If False, an attribute value other than None will not be\n          overwritten.\n        \"\"\"\n\n        # If `val` is None and `dval` is not None, replace it with dval\n        if dval is not None and val is None:\n            val = dval\n\n        # If dtype is not None, assume val is numeric and convert it to\n        # type dtype\n        if dtype is not None and val is not None:\n            if isinstance(dtype, type):\n                val = dtype(val)\n            else:\n                val = dtype.type(val)\n\n        # Set attribute value depending on reset flag and whether the\n        # attribute exists and is None\n        if reset or not hasattr(self, name) or \\\n           (hasattr(self, name) and getattr(self, name) is None):\n            setattr(self, name, val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the chunk that has to be computed per process.", "response": "def _get_rank_limits(comm, arrlen):\n    \"\"\"Determine the chunk of the grid that has to be computed per\n    process. The grid has been 'flattened' and has arrlen length. The\n    chunk assigned to each process depends on its rank in the MPI\n    communicator.\n\n    Parameters\n    ----------\n    comm : MPI communicator object\n      Describes topology of network: number of processes, rank\n    arrlen : int\n      Number of points in grid search.\n\n    Returns\n    -------\n    begin : int\n      Index, with respect to 'flattened' grid, where the chunk\n      for this process starts.\n    end : int\n      Index, with respect to 'flattened' grid, where the chunk\n      for this process ends.\n    \"\"\"\n\n    rank = comm.Get_rank()  # Id of this process\n    size = comm.Get_size()  # Total number of processes in communicator\n    end = 0\n    # The scan should be done with ints, not floats\n    ranklen = int(arrlen / size)\n    if rank < arrlen % size:\n        ranklen += 1\n    # Compute upper limit based on the sizes covered by the processes\n    # with less rank\n    end = comm.scan(sendobj=ranklen, op=MPI.SUM)\n    begin = end - ranklen\n\n    return (begin, end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a grid search on a specified grid.", "response": "def grid_search(fn, grid, comm=None, mpidtype=None, fmin=True):\n    \"\"\"Perform a grid search for optimal parameters of a specified\n    function. In the simplest case the function returns a float value,\n    and a single optimum value and corresponding parameter values are\n    identified. If the function returns a tuple of values, each of\n    these is taken to define a separate function on the search grid,\n    with optimum function values and corresponding parameter values\n    being identified for each of them. The computation of the function\n    at the grid points is computed in parallel using MPI, as opposed\n    to :func:`.util.grid_search`, which uses :mod:`multiprocessing`\n    for parallelisation.\n\n    The `mpi4py <https://mpi4py.readthedocs.io>`__ package is\n    required for use of the ``mpiutil.grid_search`` function. It is also\n    necessary to run Python with the ``mpiexec`` command; for example,\n    if ``mpiscript.py`` calls this function, use::\n\n      mpiexec -n 8 python mpiscript.py\n\n    to distribute the grid search over 8 processors.\n\n\n    Parameters\n    ----------\n    fn : function\n      Function to be evaluated. It should take a tuple of parameter\n      values as an argument, and return a float value or a tuple of\n      float values.\n    grid : tuple of array_like\n      A tuple providing an array of sample points for each axis of the\n      grid on which the search is to be performed.\n    comm : MPI communicator object, optional (default None)\n      Topology of network (number of processes and rank). If None,\n      ``MPI.COMM_WORLD`` is used.\n    mpidtype : MPI data type, optional (default None)\n      Desired data type for consolidation operations. If None,\n      ``MPI.DOUBLE`` is used\n    fmin : bool, optional (default True)\n      Determine whether optimal function values are selected as minima\n      or maxima. If `fmin` is True then minima are selected.\n\n    Returns\n    -------\n    sprm : ndarray\n      Optimal parameter values on each axis. If `fn` is multi-valued,\n      `sprm` is a matrix with rows corresponding to parameter values\n      and columns corresponding to function values.\n    sfvl : float or ndarray\n      Optimum function value or values\n    fvmx : ndarray\n      Function value(s) on search grid\n    sidx : tuple of int or tuple of ndarray\n      Indices of optimal values on parameter grid\n    \"\"\"\n\n    if comm is None:\n        comm = MPI.COMM_WORLD\n    if mpidtype is None:\n        mpidtype = MPI.DOUBLE\n    fprm = itertools.product(*grid)\n\n    # Distribute computation among processes in MPI communicator\n    afprm = np.asarray(list(fprm))  # Faster to communicate array data\n    iterlen = afprm.shape[0]\n    begin, end = _get_rank_limits(comm, iterlen)\n    rankgrid = (afprm[begin:end, :])\n    rankfval = np.asarray(list(map(fn, rankgrid)))\n\n    if rankfval.ndim == 1:  # Function with a scalar return value\n        fval = np.empty(afprm.shape[0])\n        comm.Allgatherv([rankfval, mpidtype], [fval, mpidtype])\n    else:  # Function with a vector return value\n        # Vector for gathering all the results\n        fval = np.empty([afprm.shape[0], rankfval.shape[1]])\n        # Size of values to collect locally\n        sizeL = np.array(np.prod(np.array(rankfval.shape)))\n        # Number of processes to collect from\n        sizeW = comm.Get_size()\n        # Vector to collect the sizes from each process\n        sizes = np.zeros(sizeW, dtype=np.int)\n        comm.Allgather([sizeL, MPI.INT], [sizes, MPI.INT])\n        # Vector to collect the offsets for each process\n        offsets = np.zeros(sizeW, dtype=np.int)\n        offsets[1:] = np.cumsum(sizes)[:-1]\n        # Collecting variable size of vector return values\n        comm.Allgatherv(rankfval, [fval, sizes, offsets, mpidtype])\n\n\n    # Proceed as regular grid_search (all processes execute this)\n    if fmin:\n        slct = np.argmin\n    else:\n        slct = np.argmax\n\n    if isinstance(fval[0], (tuple, list, np.ndarray)):\n        nfnv = len(fval[0])\n        fvmx = np.reshape(fval, [a.size for a in grid] + [nfnv,])\n        sidx = np.unravel_index(slct(fvmx.reshape((-1, nfnv)), axis=0),\n                                fvmx.shape[0:-1]) + (np.array((range(nfnv))),)\n        sprm = np.array([grid[k][sidx[k]] for k in range(len(grid))])\n        sfvl = tuple(fvmx[sidx])\n    else:\n        fvmx = np.reshape(fval, [a.size for a in grid])\n        sidx = np.unravel_index(slct(fvmx), fvmx.shape)\n        sprm = np.array([grid[k][sidx[k]] for k in range(len(grid))])\n        sfvl = fvmx[sidx]\n\n    return sprm, sfvl, fvmx, sidx"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts or re - start the optimisation of the object with the specified iteration number.", "response": "def solve(self):\n        \"\"\"Start (or re-start) optimisation. This method implements the\n        framework for the iterations of a FISTA algorithm. There is\n        sufficient flexibility in overriding the component methods that\n        it calls that it is usually not necessary to override this method\n        in derived clases.\n\n        If option ``Verbose`` is ``True``, the progress of the\n        optimisation is displayed at every iteration. At termination\n        of this method, attribute :attr:`itstat` is a list of tuples\n        representing statistics of each iteration, unless option\n        ``FastSolve`` is ``True`` and option ``Verbose`` is ``False``.\n\n        Attribute :attr:`timer` is an instance of :class:`.util.Timer`\n        that provides the following labelled timers:\n\n          ``init``: Time taken for object initialisation by\n          :meth:`__init__`\n\n          ``solve``: Total time taken by call(s) to :meth:`solve`\n\n          ``solve_wo_func``: Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics\n\n          ``solve_wo_rsdl`` : Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics as well as time take\n          to compute residuals\n\n          ``solve_wo_btrack`` : Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics as well as time take\n          to compute residuals and implemented ``BackTrack`` mechanism\n        \"\"\"\n\n        # Open status display\n        fmtstr, nsep = self.display_start()\n\n        # Start solve timer\n        self.timer.start(['solve', 'solve_wo_func', 'solve_wo_rsdl',\n                          'solve_wo_btrack'])\n\n        # Main optimisation iterations\n        for self.k in range(self.k, self.k + self.opt['MaxMainIter']):\n\n            # Update record of X from previous iteration\n            self.store_prev()\n\n            # Compute backtracking\n            if self.opt['BackTrack', 'Enabled'] and self.k >= 0:\n                self.timer.stop('solve_wo_btrack')\n                # Compute backtracking\n                self.backtracking()\n                self.timer.start('solve_wo_btrack')\n            else:\n                # Compute just proximal step\n                self.proximal_step()\n                # Update by combining previous iterates\n                self.combination_step()\n\n            # Compute residuals and stopping thresholds\n            self.timer.stop(['solve_wo_rsdl', 'solve_wo_btrack'])\n            if not self.opt['FastSolve']:\n                frcxd, adapt_tol = self.compute_residuals()\n            self.timer.start('solve_wo_rsdl')\n\n            # Compute and record other iteration statistics and\n            # display iteration stats if Verbose option enabled\n            self.timer.stop(['solve_wo_func', 'solve_wo_rsdl',\n                             'solve_wo_btrack'])\n            if not self.opt['FastSolve']:\n                itst = self.iteration_stats(self.k, frcxd)\n                self.itstat.append(itst)\n                self.display_status(fmtstr, itst)\n            self.timer.start(['solve_wo_func', 'solve_wo_rsdl',\n                              'solve_wo_btrack'])\n\n            # Call callback function if defined\n            if self.opt['Callback'] is not None:\n                if self.opt['Callback'](self):\n                    break\n\n            # Stop if residual-based stopping tolerances reached\n            if not self.opt['FastSolve']:\n                if frcxd < adapt_tol:\n                    break\n\n        # Increment iteration count\n        self.k += 1\n\n        # Record solve time\n        self.timer.stop(['solve', 'solve_wo_func', 'solve_wo_rsdl',\n                         'solve_wo_btrack'])\n\n        # Print final separator string if Verbose option enabled\n        self.display_end(nsep)\n\n        return self.getmin()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes proximal update ( gradient descent + regularization ).", "response": "def proximal_step(self, grad=None):\n        \"\"\"Compute proximal update (gradient descent + regularization).\"\"\"\n\n        if grad is None:\n            grad = self.eval_grad()\n\n        V = self.Y - (1. / self.L) * grad\n\n        self.X = self.eval_proxop(V)\n\n        return grad"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild next update by a smart combination of previous updates.", "response": "def combination_step(self):\n        \"\"\"Build next update by a smart combination of previous updates.\n        (standard FISTA :cite:`beck-2009-fast`).\n        \"\"\"\n\n        # Update t step\n        tprv = self.t\n        self.t = 0.5 * float(1. + np.sqrt(1. + 4. * tprv**2))\n\n        # Update Y\n        if not self.opt['FastSolve']:\n            self.Yprv = self.Y.copy()\n        self.Y = self.X + ((tprv - 1.) / self.t) * (self.X - self.Xprv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nestimates step size L by computing a linesearch that computes F <= Q according to the standard FISTA backtracking strategy in :cite - 2009 - fast. This updates variable Y and the auxiliary sequence Y. This updates auxiliary sequence Y and auxiliary sequence Y.", "response": "def standard_backtrack(self):\n        \"\"\"Estimate step size L by computing a linesearch that\n        guarantees that F <= Q according to the standard FISTA\n        backtracking strategy in :cite:`beck-2009-fast`.\n        This also updates variable Y.\n        \"\"\"\n\n        gradY = self.eval_grad()  # Given Y(f), this updates computes gradY(f)\n\n        maxiter = self.L_maxiter\n\n        iterBTrack = 0\n        linesearch = 1\n        while linesearch and iterBTrack < maxiter:\n\n            self.proximal_step(gradY)  # Given gradY(f), L, this updates X(f)\n\n            f = self.obfn_f(self.var_x())\n            Dxy = self.eval_Dxy()\n            Q = self.obfn_f(self.var_y()) + \\\n                self.eval_linear_approx(Dxy, gradY) + \\\n                (self.L / 2.) * np.linalg.norm(Dxy.flatten(), 2)**2\n\n            if f <= Q:\n                linesearch = 0\n            else:\n                self.L *= self.L_gamma_u\n\n            iterBTrack += 1\n\n        self.F = f\n        self.Q = Q\n        self.iterBTrack = iterBTrack\n        # Update auxiliary sequence\n        self.combination_step()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nestimating step size L by computing a linesearch that computes F <= Q according to the robust FISTA - 2017 - robust backtracking strategy in :cite : florea - 2017 - robust.", "response": "def robust_backtrack(self):\n        \"\"\"Estimate step size L by computing a linesearch that\n        guarantees that F <= Q according to the robust FISTA\n        backtracking strategy in :cite:`florea-2017-robust`.\n        This also updates all the supporting variables.\n        \"\"\"\n\n        self.L *= self.L_gamma_d\n        maxiter = self.L_maxiter\n\n        iterBTrack = 0\n        linesearch = 1\n\n        self.store_Yprev()\n        while linesearch and iterBTrack < maxiter:\n\n            t = float(1. + np.sqrt(1. + 4. * self.L * self.Tk)) / (2. * self.L)\n            T = self.Tk + t\n            y = (self.Tk * self.var_xprv() + t * self.ZZ) / T\n            self.update_var_y(y)\n\n            gradY = self.proximal_step()  # Given Y(f), L, this updates X(f)\n\n            f = self.obfn_f(self.var_x())\n            Dxy = self.eval_Dxy()\n            Q = self.obfn_f(self.var_y()) + \\\n                self.eval_linear_approx(Dxy, gradY) + \\\n                (self.L / 2.) * np.linalg.norm(Dxy.flatten(), 2)**2\n\n            if f <= Q:\n                linesearch = 0\n            else:\n                self.L *= self.L_gamma_u\n\n            iterBTrack += 1\n\n        self.Tk = T\n        self.ZZ += (t * self.L * (self.var_x() - self.var_y()))\n\n        self.F = f\n        self.Q = Q\n        self.iterBTrack = iterBTrack"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_residuals(self):\n\n        r = self.rsdl()\n        adapt_tol = self.opt['RelStopTol']\n\n        if self.opt['AutoStop', 'Enabled']:\n            adapt_tol = self.tau0 / (1. + self.k)\n\n        return r, adapt_tol", "response": "Compute residuals and stopping thresholds."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hdrval(cls):\n\n        dict = {'Itn': 'Iter'}\n        dict.update(cls.hdrval_objfun)\n        dict.update({'Rsdl': 'Rsdl', 'F': 'F_Btrack', 'Q': 'Q_Btrack',\n                     'It_Bt': 'IterBTrack', 'L': 'L'})\n\n        return dict", "response": "Construct dictionary mapping display column title to iterationStats entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iteration_stats(self, k, frcxd):\n\n        tk = self.timer.elapsed(self.opt['IterTimer'])\n        tpl = (k,) + self.eval_objfn() + \\\n            (frcxd, self.F, self.Q, self.iterBTrack, self.L) + \\\n            self.itstat_extra() + (tk,)\n        return type(self).IterationStats(*tpl)", "response": "Construct iteration stats record tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval_objfn(self):\n\n        fval = self.obfn_f(self.X)\n        gval = self.obfn_g(self.X)\n        obj = fval + gval\n        return (obj, fval, gval)", "response": "Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the proximal update of the frequency domain.", "response": "def proximal_step(self, gradf=None):\n        \"\"\"Compute proximal update (gradient descent + constraint).\n        Variables are mapped back and forth between input and\n        frequency domains.\n        \"\"\"\n\n        if gradf is None:\n            gradf = self.eval_grad()\n\n        self.Vf[:] = self.Yf - (1. / self.L) * gradf\n        V = sl.irfftn(self.Vf, self.cri.Nv, self.cri.axisN)\n\n        self.X[:] = self.eval_proxop(V)\n        self.Xf = sl.rfftn(self.X, None, self.cri.axisN)\n\n        return gradf"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates auxiliary state by a smart combination of previous updates in the frequency domain.", "response": "def combination_step(self):\n        \"\"\"Update auxiliary state by a smart combination of previous\n        updates in the frequency domain (standard FISTA\n        :cite:`beck-2009-fast`).\n        \"\"\"\n\n        # Update t step\n        tprv = self.t\n        self.t = 0.5 * float(1. + np.sqrt(1. + 4. * tprv**2))\n\n        # Update Y\n        if not self.opt['FastSolve']:\n            self.Yfprv = self.Yf.copy()\n        self.Yf = self.Xf + ((tprv - 1.) / self.t) * (self.Xf - self.Xfprv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mse(vref, vcmp):\n\n    r = np.asarray(vref, dtype=np.float64).ravel()\n    c = np.asarray(vcmp, dtype=np.float64).ravel()\n    return np.mean(np.abs(r - c)**2)", "response": "Compute Mean Squared Error between two images."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute Signal to Noise Ratio of two images.", "response": "def snr(vref, vcmp):\n    \"\"\"\n    Compute Signal to Noise Ratio (SNR) of two images.\n\n    Parameters\n    ----------\n    vref : array_like\n      Reference image\n    vcmp : array_like\n      Comparison image\n\n    Returns\n    -------\n    x : float\n      SNR of `vcmp` with respect to `vref`\n    \"\"\"\n\n    dv = np.var(vref)\n    with np.errstate(divide='ignore'):\n        rt = dv / mse(vref, vcmp)\n    return 10.0 * np.log10(rt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute Peak Signal to Noise Ratio of two images.", "response": "def psnr(vref, vcmp, rng=None):\n    \"\"\"\n    Compute Peak Signal to Noise Ratio (PSNR) of two images. The PSNR\n    calculation defaults to using the less common definition in terms\n    of the actual range (i.e. max minus min) of the reference signal\n    instead of the maximum possible range for the data type\n    (i.e. :math:`2^b-1` for a :math:`b` bit representation).\n\n    Parameters\n    ----------\n    vref : array_like\n      Reference image\n    vcmp : array_like\n      Comparison image\n    rng : None or int, optional (default None)\n      Signal range, either the value to use (e.g. 255 for 8 bit samples) or\n      None, in which case the actual range of the reference signal is used\n\n    Returns\n    -------\n    x : float\n      PSNR of `vcmp` with respect to `vref`\n    \"\"\"\n\n    if rng is None:\n        rng = vref.max() - vref.min()\n    dv = (rng + 0.0)**2\n    with np.errstate(divide='ignore'):\n        rt = dv / mse(vref, vcmp)\n    return 10.0 * np.log10(rt)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef isnr(vref, vdeg, vrst):\n\n    msedeg = mse(vref, vdeg)\n    mserst = mse(vref, vrst)\n    with np.errstate(divide='ignore'):\n        rt = msedeg / mserst\n    return 10.0 * np.log10(rt)", "response": "Compute Improvement Signal to Noise Ratio ( ISNR ) for reference degraded and restored images."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bsnr(vblr, vnsy):\n\n    blrvar = np.var(vblr)\n    nsevar = np.var(vnsy - vblr)\n    with np.errstate(divide='ignore'):\n        rt = blrvar / nsevar\n    return 10.0 * np.log10(rt)", "response": "Compute Blurred Signal to Noise Ratio ( BSNR ) for a blurred and noisy image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pamse(vref, vcmp, rescale=True):\n\n    # Calculate difference, promoting to float if vref and vcmp have integer\n    # dtype\n    emap = np.asarray(vref, dtype=np.float64) - \\\n        np.asarray(vcmp, dtype=np.float64)\n    # Input images in reference code on which this implementation is\n    # based are assumed to be on range [0,...,255].\n    if rescale:\n        emap *= (255.0 / vref.max())\n    sigma = 0.8\n    herr = ndimage.filters.gaussian_filter(emap, sigma)\n    score = np.mean(herr**2)\n    return score", "response": "Compute Perceptual - fidelity Aware Mean Squared Error of the given image and comparison image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gmsd(vref, vcmp, rescale=True, returnMap=False):\n\n    # Input images in reference code on which this implementation is\n    # based are assumed to be on range [0,...,255].\n    if rescale:\n        scl = (255.0 / vref.max())\n    else:\n        scl = np.float32(1.0)\n\n    T = 170.0\n    dwn = 2\n    dx = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]]) / 3.0\n    dy = dx.T\n\n    ukrn = np.ones((2, 2)) / 4.0\n    aveY1 = signal.convolve2d(scl * vref, ukrn, mode='same', boundary='symm')\n    aveY2 = signal.convolve2d(scl * vcmp, ukrn, mode='same', boundary='symm')\n    Y1 = aveY1[0::dwn, 0::dwn]\n    Y2 = aveY2[0::dwn, 0::dwn]\n\n    IxY1 = signal.convolve2d(Y1, dx, mode='same', boundary='symm')\n    IyY1 = signal.convolve2d(Y1, dy, mode='same', boundary='symm')\n    grdMap1 = np.sqrt(IxY1**2 + IyY1**2)\n\n    IxY2 = signal.convolve2d(Y2, dx, mode='same', boundary='symm')\n    IyY2 = signal.convolve2d(Y2, dy, mode='same', boundary='symm')\n    grdMap2 = np.sqrt(IxY2**2 + IyY2**2)\n\n    quality_map = (2*grdMap1*grdMap2 + T) / (grdMap1**2 + grdMap2**2 + T)\n    score = np.std(quality_map)\n\n    if returnMap:\n        return (score, quality_map)\n    else:\n        return score", "response": "Compute the GMSD of the input image with respect to the given reference image and comparison image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConvCnstrMODMaskDcpl(*args, **kwargs):\n\n    # Extract method selection argument or set default\n    if 'method' in kwargs:\n        method = kwargs['method']\n        del kwargs['method']\n    else:\n        method = 'cns'\n\n    # Assign base class depending on method selection argument\n    if method == 'ism':\n        base = ConvCnstrMODMaskDcpl_IterSM\n    elif method == 'cg':\n        base = ConvCnstrMODMaskDcpl_CG\n    elif method == 'cns':\n        base = ConvCnstrMODMaskDcpl_Consensus\n    else:\n        raise ValueError('Unknown ConvCnstrMODMaskDcpl solver method %s'\n                         % method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvCnstrMODMaskDcpl(base):\n        def __init__(self, *args, **kwargs):\n            super(ConvCnstrMODMaskDcpl, self).__init__(*args, **kwargs)\n\n    # Allow pickling of objects of type ConvCnstrMODMaskDcpl\n    _fix_dynamic_class_lookup(ConvCnstrMODMaskDcpl, method)\n\n    # Return object of the nested class type\n    return ConvCnstrMODMaskDcpl(*args, **kwargs)", "response": "A wrapper function that dynamically defines a class derived from the Convolutional Constrained MOD\n    with Mask Decoupling problems and returns an object instantiated with the provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ConvCnstrMODMaskDcplOptions(opt=None, method='cns'):\n\n    # Assign base class depending on method selection argument\n    if method == 'ism':\n        base = ConvCnstrMODMaskDcpl_IterSM.Options\n    elif method == 'cg':\n        base = ConvCnstrMODMaskDcpl_CG.Options\n    elif method == 'cns':\n        base = ConvCnstrMODMaskDcpl_Consensus.Options\n    else:\n        raise ValueError('Unknown ConvCnstrMODMaskDcpl solver method %s'\n                         % method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvCnstrMODMaskDcplOptions(base):\n        def __init__(self, opt):\n            super(ConvCnstrMODMaskDcplOptions, self).__init__(opt)\n\n    # Allow pickling of objects of type ConvCnstrMODMaskDcplOptions\n    _fix_dynamic_class_lookup(ConvCnstrMODMaskDcplOptions, method)\n\n    # Return object of the nested class type\n    return ConvCnstrMODMaskDcplOptions(opt)", "response": "A function that returns an object that can be used to instantiate a new Options class for a specific method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns initialiser for working variable U", "response": "def uinit(self, ushape):\n        \"\"\"Return initialiser for working variable U\"\"\"\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            Ub0 = (self.W**2) * self.block_sep0(self.Y) / self.rho\n            Ub1 = self.block_sep1(self.Y)\n            return self.block_cat(Ub0, Ub1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ystep(self):\n\n        AXU = self.AX + self.U\n        Y0 = (self.rho*(self.block_sep0(AXU) - self.S)) / (self.W**2 +\n                                                           self.rho)\n        Y1 = self.Pcn(self.block_sep1(AXU))\n        self.Y = self.block_cat(Y0, Y1)", "response": "Minimise Augmented Lagrangian with respect to\n        self. Y."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef relax_AX(self):\n\n        self.AXnr = self.cnst_A(self.X, self.Xf)\n        if self.rlx == 1.0:\n            self.AX = self.AXnr\n        else:\n            alpha = self.rlx\n            self.AX = alpha*self.AXnr + (1-alpha)*self.block_cat(\n                self.var_y0() + self.S, self.var_y1())", "response": "Implement relaxation if option RelaxParam!= 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef block_cat(self, Y0, Y1):\n\n        return np.concatenate((np.swapaxes(Y0, self.cri.axisK,\n                                           self.cri.axisM), Y1),\n                              axis=self.blkaxis)", "response": "rConcatenate components corresponding to Y0 and Y1 to form a block of size N."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute components of regularisation function as well as total contribution to objective function.", "response": "def eval_objfn(self):\n        \"\"\"Compute components of regularisation function as well as total\n        contribution to objective function.\n        \"\"\"\n\n        dfd = self.obfn_g0(self.obfn_g0var())\n        cns = self.obfn_g1(self.obfn_g1var())\n        return (dfd, cns)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obfn_g1(self, Y1):\n\n        return np.linalg.norm((self.Pcn(Y1) - Y1))", "response": "r Compute : math : g_1 \\ mathbf { y_1 } component of ADMM objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute dual residual vector.", "response": "def rsdl_s(self, Yprev, Y):\n        \"\"\"Compute dual residual vector.\"\"\"\n\n        return self.rho*np.linalg.norm(self.cnst_AT(self.U))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xstep(self):\n\n        self.YU[:] = self.Y - self.U\n        self.block_sep0(self.YU)[:] += self.S\n        YUf = sl.rfftn(self.YU, None, self.cri.axisN)\n        b = sl.inner(np.conj(self.Zf), self.block_sep0(YUf),\n                     axis=self.cri.axisK) + self.block_sep1(YUf)\n\n        self.Xf[:] = sl.solvemdbi_ism(self.Zf, 1.0, b, self.cri.axisM,\n                                      self.cri.axisK)\n        self.X = sl.irfftn(self.Xf, self.cri.Nv, self.cri.axisN)\n        self.xstep_check(b)", "response": "Minimise Augmented Lagrangian with respect to\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ustep(self):\n\n        super(ConvCnstrMODMaskDcpl_Consensus, self).ustep()\n        self.U1 += self.AX1 - self.Y1 - self.S", "response": "This method is overridden to allow the parent class ystep method to perform the ystep for additional variables introduced in\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef obfn_dfd(self):\n\n        Ef = sl.inner(self.Zf, self.obfn_fvarf(), axis=self.cri.axisM) \\\n          - self.Sf\n        return (np.linalg.norm(self.W * sl.irfftn(Ef, self.cri.Nv,\n                                                  self.cri.axisN))**2) / 2.0", "response": "Compute data fidelity term :math:` ( 1 / 2 ) \\ | W \\ left ( \\ sum_m\n        \\ mathbf { d}_m - \\ mathbf { x}_m - \\ mathbf { s } \\ right ) \\ |_2^2."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the residuals and stopping thresholds for the modification of the class holding the current state of the class.", "response": "def compute_residuals(self):\n        \"\"\"Compute residuals and stopping thresholds. The parent class\n        method is overridden to ensure that the residual calculations\n        include the additional variables introduced in the modification\n        to the baseline algorithm.\n        \"\"\"\n\n        # The full primary residual is straightforward to compute from\n        # the primary residuals for the baseline algorithm and for the\n        # additional variables\n        r0 = self.rsdl_r(self.AXnr, self.Y)\n        r1 = self.AX1nr - self.Y1 - self.S\n        r = np.sqrt(np.sum(r0**2) + np.sum(r1**2))\n\n        # The full dual residual is more complicated to compute than the\n        # full primary residual\n        ATU = self.swapaxes(self.U) + sl.irfftn(\n            np.conj(self.Zf) * sl.rfftn(self.U1, self.cri.Nv, self.cri.axisN),\n            self.cri.Nv, self.cri.axisN)\n        s = self.rho * np.linalg.norm(ATU)\n\n        # The normalisation factor for the full primal residual is also not\n        # straightforward\n        nAX = np.sqrt(np.linalg.norm(self.AXnr)**2 +\n                      np.linalg.norm(self.AX1nr)**2)\n        nY = np.sqrt(np.linalg.norm(self.Y)**2 +\n                     np.linalg.norm(self.Y1)**2)\n        rn = max(nAX, nY, np.linalg.norm(self.S))\n\n        # The normalisation factor for the full dual residual is\n        # straightforward to compute\n        sn = self.rho * np.sqrt(np.linalg.norm(self.U)**2 +\n                                np.linalg.norm(self.U1)**2)\n\n        # Final residual values and stopping tolerances depend on\n        # whether standard or normalised residuals are specified via the\n        # options object\n        if self.opt['AutoRho', 'StdResiduals']:\n            epri = np.sqrt(self.Nc)*self.opt['AbsStopTol'] + \\\n                rn*self.opt['RelStopTol']\n            edua = np.sqrt(self.Nx)*self.opt['AbsStopTol'] + \\\n                sn*self.opt['RelStopTol']\n        else:\n            if rn == 0.0:\n                rn = 1.0\n            if sn == 0.0:\n                sn = 1.0\n            r /= rn\n            s /= sn\n            epri = np.sqrt(self.Nc)*self.opt['AbsStopTol']/rn + \\\n                self.opt['RelStopTol']\n            edua = np.sqrt(self.Nx)*self.opt['AbsStopTol']/sn + \\\n                self.opt['RelStopTol']\n\n        return r, s, epri, edua"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solve(self):\n\n        super(RobustPCA, self).solve()\n        return self.X, self.Y", "response": "Start or re - start optimisation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nminimises Augmented Lagrangian with respect to .", "response": "def xstep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{x}`.\n        \"\"\"\n\n        self.X, self.ss = sp.prox_nuclear(self.S - self.Y - self.U,\n                                          1/self.rho)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ystep(self):\n\n        self.Y = np.asarray(sp.prox_l1(self.S - self.AX - self.U,\n                                       self.lmbda/self.rho), dtype=self.dtype)", "response": "Minimise Augmented Lagrangian with respect to\n        self. az."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes components of objective function as well as total contribution to objective function.", "response": "def eval_objfn(self):\n        \"\"\"Compute components of objective function as well as total\n        contribution to objective function.\n        \"\"\"\n\n        if self.opt['fEvalX']:\n            rnn = np.sum(self.ss)\n        else:\n            rnn = sp.norm_nuclear(self.obfn_fvar())\n        rl1 = np.sum(np.abs(self.obfn_gvar()))\n        cns = np.linalg.norm(self.X + self.Y - self.S)\n        obj = rnn + self.lmbda*rl1\n        return (obj, rnn, rl1, cns)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalising columns of matrix.", "response": "def normalise(v):\n    \"\"\"Normalise columns of matrix.\n\n    Parameters\n    ----------\n    v : array_like\n      Array with columns to be normalised\n\n    Returns\n    -------\n    vnrm : ndarray\n      Normalised array\n    \"\"\"\n\n    vn = np.sqrt(np.sum(v**2, 0))\n    vn[vn == 0] = 1.0\n    return np.asarray(v / vn, dtype=v.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xstep(self):\n\n        self.X = np.asarray(sl.lu_solve_AATI(self.Z, self.rho, self.SZT +\n                            self.rho*(self.Y - self.U), self.lu, self.piv,),\n                            dtype=self.dtype)", "response": "Minimise Augmented Lagrangian with respect to\n        self. X."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rhochange(self):\n\n        self.lu, self.piv = sl.lu_factor(self.Z, self.rho)\n        self.lu = np.asarray(self.lu, dtype=self.dtype)", "response": "Re - factorise matrix when rho changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cupy_wrapper(func):\n\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        args = list(args)\n        for n, a in enumerate(args):\n            if isinstance(a, np.ndarray):\n                args[n] = cp.asarray(a)\n        for k, v in kwargs.items():\n            if isinstance(v, np.ndarray):\n                kwargs[k] = cp.asarray(v)\n        rtn = func(*args, **kwargs)\n        if isinstance(rtn, (list, tuple)):\n            for n, a in enumerate(rtn):\n                if isinstance(a, cp.core.core.ndarray):\n                    rtn[n] = cp.asnumpy(a)\n        else:\n            if isinstance(rtn, cp.core.core.ndarray):\n                rtn = cp.asnumpy(rtn)\n        return rtn\n    return wrapped", "response": "A function that converts numpy ndarray arguments to cupy arrays and convert any cupy arrays returned by the wrapped function into numpy ndarrays."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ndto2d(x, axis=-1):\n\n    # Convert int axis into a tuple\n    if isinstance(axis, int):\n        axis = (axis,)\n    # Handle negative axis indices\n    axis = tuple([k if k >= 0 else x.ndim + k for k in axis])\n    # Complement of axis set on full set of axes of input v\n    caxis = tuple(set(range(x.ndim)) - set(axis))\n    # Permute axes of x (generalised transpose) so that axes over\n    # which operation is to be applied are all at the end\n    prm = caxis + axis\n    xt = np.transpose(x, axes=prm)\n    xts = xt.shape\n    # Reshape into a 2D array with the axes specified by the axis\n    # parameter flattened into an index along rows, and the remaining\n    # axes flattened into an index aalong the columns\n    xtr = xt.reshape((np.product(xts[0:len(caxis)]), -1))\n    # Return reshaped array and a tuple containing the information\n    # necessary to undo the entire operation\n    return xtr, (xts, prm)", "response": "Convert a multi - dimensional array into a 2d array with the axes specified by the axis parameter flattened into an index along the rows and the remaining axes flattened into an index along the columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ndfrom2d(xtr, rsi):\n\n    # Extract components of conversion information tuple\n    xts = rsi[0]\n    prm = rsi[1]\n    # Reshape x to the shape obtained after permuting axes in ndto2d\n    xt = xtr.reshape(xts)\n    # Undo axis permutation performed in ndto2d\n    x = np.transpose(xt, np.argsort(prm))\n    # Return array with shape corresponding to that of the input to ndto2d\n    return x", "response": "Undo the array shape conversion applied by ndto2d returning the input 2D array to its original shape."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nminimise Augmented Lagrangian with respect to . ystep", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\"\"\"\n\n        AXU = self.AX + self.U\n        self.Y[..., 0:-1] = sp.prox_l2(AXU[..., 0:-1], self.mu/self.rho)\n        self.Y[..., -1] = sp.prox_l1(AXU[..., -1],\n                                     (self.lmbda/self.rho) * self.Wl1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_reg(self):\n\n        rl1 = np.linalg.norm((self.Wl1 * self.obfn_g1var()).ravel(), 1)\n        rtv = np.sum(np.sqrt(np.sum(self.obfn_g0var()**2, axis=-1)))\n        return (self.lmbda*rl1 + self.mu*rtv, rl1, rtv)", "response": "Compute regularisation term and contribution to objective\n        function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cnst_A0(self, X, Xf=None):\n\n        if Xf is None:\n            Xf = sl.rfftn(X, axes=self.cri.axisN)\n        return self.Wtv[..., np.newaxis] * sl.irfftn(\n            self.Gf * Xf[..., np.newaxis], self.cri.Nv, axes=self.cri.axisN)", "response": "r Compute A_0 component of ADMM problem problem\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef relax_AX(self):\n\n        # We need to keep the non-relaxed version of AX since it is\n        # required for computation of primal residual r\n        self.AXnr = self.cnst_A(self.X, self.Xf)\n        if self.rlx == 1.0:\n            # If RelaxParam option is 1.0 there is no relaxation\n            self.AX = self.AXnr\n        else:\n            # Avoid calling cnst_c() more than once in case it is expensive\n            # (e.g. due to allocation of a large block of memory)\n            if not hasattr(self, '_cnst_c'):\n                self._cnst_c = self.cnst_c()\n            # Compute relaxed version of AX\n            alpha = self.rlx\n            self.AX = alpha*self.AXnr - (1-alpha)*(self.cnst_B(self.Y) -\n                                                   self._cnst_c)", "response": "Implement relaxation if option RelaxParam!= 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef block_sep1(self, Y):\n\n        Y1 = Y[..., self.cri.M:]\n\n        # If cri.Cd > 1 (multi-channel dictionary), we need to undo the\n        # reshape performed in block_cat\n        if self.cri.Cd > 1:\n            shp = list(Y1.shape)\n            shp[self.cri.axisM] = self.cri.dimN\n            shp[self.cri.axisC] = self.cri.Cd\n            Y1 = Y1.reshape(shp)\n\n        # Axes are swapped here for similar reasons to those\n        # motivating swapping in cbpdn.ConvTwoBlockCnstrnt.block_sep0\n        Y1 = np.swapaxes(Y1[..., np.newaxis], self.cri.axisM, -1)\n\n        return Y1", "response": "Separate variable into component corresponding to Y1 in Y."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef block_cat(self, Y0, Y1):\n\n        # Axes are swapped here for similar reasons to those\n        # motivating swapping in cbpdn.ConvTwoBlockCnstrnt.block_cat\n        Y1sa = np.swapaxes(Y1, self.cri.axisM, -1)[..., 0]\n\n        # If cri.Cd > 1 (multi-channel dictionary) Y0 has a singleton\n        # channel axis but Y1 has a non-singleton channel axis. To make\n        # it possible to concatenate Y0 and Y1, we reshape Y1 by a\n        # partial ravel of axisM and axisC onto axisM.\n        if self.cri.Cd > 1:\n            shp = list(Y1sa.shape)\n            shp[self.cri.axisM] *= shp[self.cri.axisC]\n            shp[self.cri.axisC] = 1\n            Y1sa = Y1sa.reshape(shp)\n\n        return np.concatenate((Y0, Y1sa), axis=self.cri.axisM)", "response": "Concatenate components corresponding to Y0 and Y1 blocks\n        into Y."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nminimises Augmented Lagrangian with respect to .", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\"\"\"\n\n        AXU = self.AX + self.U\n        self.block_sep0(self.Y)[:] = sp.prox_l1(\n            self.block_sep0(AXU), (self.lmbda/self.rho) * self.Wl1)\n        self.block_sep1(self.Y)[:] = sp.prox_l2(\n            self.block_sep1(AXU), self.mu/self.rho, axis=(self.cri.axisC, -1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cnst_A1(self, X, Xf=None):\n\n        if Xf is None:\n            Xf = sl.rfftn(X, axes=self.cri.axisN)\n        return sl.irfftn(sl.inner(\n            self.GDf, Xf[..., np.newaxis], axis=self.cri.axisM), self.cri.Nv,\n                         self.cri.axisN)", "response": "r Compute A_1 component of ADMM problem problem\n            constraint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute A1T component of A1.", "response": "def cnst_A1T(self, Y1):\n        r\"\"\"Compute :math:`A_1^T \\mathbf{y}_1` component of\n        :math:`A^T \\mathbf{y}`. In this case :math:`A_1^T \\mathbf{y}_1 =\n        (\\Gamma_0^T \\;\\; \\Gamma_1^T \\;\\; \\ldots) \\mathbf{y}_1`.\n        \"\"\"\n\n        Y1f = sl.rfftn(Y1, None, axes=self.cri.axisN)\n        return sl.irfftn(np.conj(self.GDf) * Y1f, self.cri.Nv,\n                         self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xstep(self):\n\n        self.X = np.asarray(sl.cho_solve_ATAI(\n            self.D, self.rho, self.DTS + self.rho * (self.Y - self.U),\n            self.lu, self.piv), dtype=self.dtype)\n\n        if self.opt['LinSolveCheck']:\n            b = self.DTS + self.rho * (self.Y - self.U)\n            ax = self.D.T.dot(self.D.dot(self.X)) + self.rho*self.X\n            self.xrrs = sl.rrs(ax, b)\n        else:\n            self.xrrs = None", "response": "Minimise Augmented Lagrangian with respect to the\n            self. X."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_dfd(self):\n\n        return 0.5*np.linalg.norm((self.D.dot(self.obfn_fvar()) - self.S))**2", "response": "Compute data fidelity term : math:` ( 1 / 2 ) \\ | D \\ | S \\ |_2^2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rhochange(self):\n\n        self.lu, self.piv = sl.cho_factor(self.D, self.rho)\n        self.lu = np.asarray(self.lu, dtype=self.dtype)", "response": "Re - factorise matrix when rho changes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ystep(self):\n\n        self.Y = np.asarray(sp.prox_l1(self.AX + self.U,\n                                       (self.lmbda / self.rho) * self.wl1),\n                            dtype=self.dtype)\n        super(BPDN, self).ystep()", "response": "Minimise Augmented Lagrangian with respect to\n        ystep"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nminimise Augmented Lagrangian with respect to self. Y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\"\"\"\n\n        self.Y = np.asarray(sp.prox_l1l2(\n            self.AX + self.U, (self.lmbda / self.rho) * self.wl1,\n            self.mu / self.rho, axis=-1), dtype=self.dtype)\n        GenericBPDN.ystep(self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nminimise Augmented Lagrangian with respect to y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        self.Y = np.asarray(sp.proj_l1(self.AX + self.U, self.gamma, axis=0),\n                            dtype=self.dtype)\n        super(BPDNProjL1, self).ystep()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval_objfn(self):\n\n        dfd = self.obfn_dfd()\n        prj = sp.proj_l1(self.obfn_gvar(), self.gamma, axis=0)\n        cns = np.linalg.norm(prj - self.obfn_gvar())\n        return (dfd, cns)", "response": "Compute components of regularisation function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uinit(self, ushape):\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            U0 = np.sign(self.block_sep0(self.Y)) / self.rho\n            U1 = self.block_sep1(self.Y) - self.S\n            return self.block_cat(U0, U1)", "response": "Return initialiser for working variable U."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xstep(self):\n\n        YU = self.Y - self.U\n        self.X = np.asarray(sl.cho_solve_ATAI(\n            self.D, 1.0, self.block_sep0(YU) +\n            self.D.T.dot(self.block_sep1(YU)), self.lu, self.piv),\n            dtype=self.dtype)", "response": "Minimise Augmented Lagrangian with respect to\n            self. U."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ystep(self):\n\n        AXU = self.AX + self.U\n        Y0 = np.asarray(sp.prox_l1(self.block_sep0(AXU), self.wl1 / self.rho),\n                        dtype=self.dtype)\n        if self.opt['NonNegCoef']:\n            Y0[Y0 < 0.0] = 0.0\n        Y1 = sl.proj_l2ball(self.block_sep1(AXU), self.S, self.epsilon, axes=0)\n        self.Y = self.block_cat(Y0, Y1)", "response": "Minimise Augmented Lagrangian with respect to\n        Y."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eval_objfn(self):\n\n        obj = np.linalg.norm((self.wl1 * self.obfn_g0var()).ravel(), 1)\n        cns = np.linalg.norm(sl.proj_l2ball(\n            self.obfn_g1var(), self.S, self.epsilon, axes=0) -\n            self.obfn_g1var())\n        return (obj, cns)", "response": "r Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef uinit(self, ushape):\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            return (self.Wdf/self.rho)*np.sign(self.Y)", "response": "Return initialiser for working variable U."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xstep(self):\n\n        self.X = sl.idctii(self.Gamma*sl.dctii(self.Y + self.S - self.U,\n                                               axes=self.axes), axes=self.axes)\n        if self.opt['LinSolveCheck']:\n            self.xrrs = sl.rrs(\n                self.X + (self.lmbda/self.rho) *\n                sl.idctii((self.Alpha**2) *\n                          sl.dctii(self.X, axes=self.axes),\n                          axes=self.axes), self.Y + self.S - self.U)\n        else:\n            self.xrrs = None", "response": "Minimise Augmented Lagrangian with respect to\n        self. X."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ystep(self):\n\n        self.Y = sp.prox_l1(self.AX - self.S + self.U, self.Wdf / self.rho)", "response": "Minimise Augmented Lagrangian with respect to\n        self. Y."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\naction to be taken when rho parameter is changed.", "response": "def rhochange(self):\n        \"\"\"Action to be taken when rho parameter is changed.\"\"\"\n\n        self.Gamma = 1.0 / (1.0 + (self.lmbda/self.rho)*(self.Alpha**2))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef obfn_gvar(self):\n\n        if self.opt['gEvalY']:\n            return self.Y\n        else:\n            return self.cnst_A(self.X) - self.cnst_c()", "response": "Variable to be evaluated in computing regularisation term depending on gEvalY option value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_objfn(self):\n\n        gvr = self.obfn_gvar()\n        dfd = np.sum(np.abs(self.Wdf * gvr))\n        reg = 0.5*np.linalg.norm(\n            sl.idctii(self.Alpha*sl.dctii(self.X, axes=self.axes),\n                      axes=self.axes))**2\n        obj = dfd + self.lmbda*reg\n        return (obj, dfd, reg)", "response": "r Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gpu_info():\n\n    GPUInfo = namedtuple('GPUInfo', ['name', 'driver', 'totalmem', 'freemem'])\n    gpus = GPUtil.getGPUs()\n    info = []\n    for g in gpus:\n        info.append(GPUInfo(g.name, g.driver, g.memoryTotal, g.memoryFree))\n    return info", "response": "Return a list of namedtuples representing attributes of each GPU\n    device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gpu_load(wproc=0.5, wmem=0.5):\n\n    GPULoad = namedtuple('GPULoad', ['processor', 'memory', 'weighted'])\n    gpus = GPUtil.getGPUs()\n    load = []\n    for g in gpus:\n        wload = (wproc * g.load + wmem * g.memoryUtil) / (wproc + wmem)\n        load.append(GPULoad(g.load, g.memoryUtil, wload))\n    return load", "response": "Return a list of namedtuples representing the current load for each GPU device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of GPU device ids ordered by increasing weighted average of processor and memory load.", "response": "def device_by_load(wproc=0.5, wmem=0.5):\n    \"\"\"Get a list of GPU device ids ordered by increasing weighted\n    average of processor and memory load.\n    \"\"\"\n\n    gl = gpu_load(wproc=wproc, wmem=wmem)\n    # return np.argsort(np.asarray(gl)[:, -1]).tolist()\n    return [idx for idx, load in sorted(enumerate(\n        [g.weighted for g in gl]), key=(lambda x: x[1]))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect the device with the lowest weighted average of processor and memory load.", "response": "def select_device_by_load(wproc=0.5, wmem=0.5):\n    \"\"\"Set the current device for cupy as the device with the lowest\n    weighted average of processor and memory load.\n    \"\"\"\n\n    ids = device_by_load(wproc=wproc, wmem=wmem)\n    cp.cuda.Device(ids[0]).use()\n    return ids[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the named module without registering it in sys. modules.", "response": "def load_module(name):\n    \"\"\"Load the named module without registering it in ``sys.modules``.\n\n    Parameters\n    ----------\n    name : string\n      Module name\n\n    Returns\n    -------\n    mod : module\n      Loaded module\n    \"\"\"\n\n    spec = importlib.util.find_spec(name)\n    mod = importlib.util.module_from_spec(spec)\n    mod.__spec__ = spec\n    mod.__loader__ = spec.loader\n    spec.loader.exec_module(mod)\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a patched copy of the named module and register it in sys. modules.", "response": "def patch_module(name, pname, pfile=None, attrib=None):\n    \"\"\"Create a patched copy of the named module and register it in\n    ``sys.modules``.\n\n    Parameters\n    ----------\n    name : string\n      Name of source module\n    pname : string\n      Name of patched copy of module\n    pfile : string or None, optional (default None)\n      Value to assign as source file name of patched module\n    attrib : dict or None, optional (default None)\n      Dict of attribute names and values to assign to patched module\n\n    Returns\n    -------\n    mod : module\n      Patched module\n    \"\"\"\n\n    if attrib is None:\n        attrib = {}\n    spec = importlib.util.find_spec(name)\n    spec.name = pname\n    if pfile is not None:\n        spec.origin = pfile\n    spec.loader.name = pname\n    mod = importlib.util.module_from_spec(spec)\n    mod.__spec__ = spec\n    mod.__loader__ = spec.loader\n    sys.modules[pname] = mod\n    spec.loader.exec_module(mod)\n    for k, v in attrib.items():\n        setattr(mod, k, v)\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sporco_cupy_patch_module(name, attrib=None):\n\n    # Patched module name is constructed from source module name\n    # by replacing 'sporco.' with 'sporco.cupy.'\n    pname = re.sub('^sporco.', 'sporco.cupy.', name)\n    # Attribute dict always maps cupy module to 'np' attribute in\n    # patched module\n    if attrib is None:\n        attrib = {}\n    attrib.update({'np': cp})\n    # Create patched module\n    mod = patch_module(name, pname, pfile='patched', attrib=attrib)\n    mod.__spec__.has_location = False\n    return mod", "response": "Create a copy of the named sporco module patch it to replace numpy with cupy and register it in sys. modules."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _list2array(lst):\n\n    if lst and isinstance(lst[0], cp.ndarray):\n        return cp.hstack(lst)\n    else:\n        return cp.asarray(lst)", "response": "Convert a list to a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npatching version of scipy. linalg. complex_dtype.", "response": "def _complex_dtype(dtype):\n    \"\"\"Patched version of :func:`sporco.linalg.complex_dtype`.\"\"\"\n\n    dt = cp.dtype(dtype)\n    if dt == cp.dtype('float128'):\n        return cp.dtype('complex256')\n    elif dt == cp.dtype('float64'):\n        return cp.dtype('complex128')\n    else:\n        return cp.dtype('complex64')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch version of scipy. sparse. fftw. empty_aligned.", "response": "def _pyfftw_empty_aligned(shape, dtype, order='C', n=None):\n    \"\"\"Patched version of :func:`sporco.linalg.`.\"\"\"\n\n    return cp.empty(shape, dtype, order)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npatches version of scipy. linalg. pyfftw_rfftn_empty_aligned.", "response": "def _pyfftw_rfftn_empty_aligned(shape, axes, dtype, order='C', n=None):\n    \"\"\"Patched version of :func:`sporco.linalg.pyfftw_rfftn_empty_aligned`.\n    \"\"\"\n\n    ashp = list(shape)\n    raxis = axes[-1]\n    ashp[raxis] = ashp[raxis] // 2 + 1\n    cdtype = _complex_dtype(dtype)\n    return cp.empty(ashp, cdtype, order)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fftconv(a, b, axes=(0, 1)):\n\n    if cp.isrealobj(a) and cp.isrealobj(b):\n        fft = cp.fft.rfftn\n        ifft = cp.fft.irfftn\n    else:\n        fft = cp.fft.fftn\n        ifft = cp.fft.ifftn\n    dims = cp.maximum(cp.asarray([a.shape[i] for i in axes]),\n                      cp.asarray([b.shape[i] for i in axes]))\n    dims = [int(d) for d in dims]\n    af = fft(a, dims, axes)\n    bf = fft(b, dims, axes)\n    return ifft(af * bf, dims, axes)", "response": "Patched version of scipy. linalg. fftconv."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npatch version of scipy. linalg. inner.", "response": "def _inner(x, y, axis=-1):\n    \"\"\"Patched version of :func:`sporco.linalg.inner`.\"\"\"\n\n    return cp.sum(x * y, axis=axis, keepdims=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _linalg_cho_factor(A, rho, lower=False, check_finite=True):\n\n    N, M = A.shape\n    if N >= M:\n        c, lwr = _cho_factor(\n            A.T.dot(A) + rho * cp.identity(M, dtype=A.dtype), lower=lower,\n            check_finite=check_finite)\n    else:\n        c, lwr = _cho_factor(\n            A.dot(A.T) + rho * cp.identity(N, dtype=A.dtype), lower=lower,\n            check_finite=check_finite)\n    return c, lwr", "response": "Patched version of scipy. linalg. cho_factor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _cho_solve_AATI(A, rho, b, c, lwr, check_finite=True):\n\n    N, M = A.shape\n    if N >= M:\n        x = (b - _cho_solve((c, lwr), b.dot(A).T,\n            check_finite=check_finite).T.dot(A.T)) / rho\n    else:\n        x = _cho_solve((c, lwr), b.T, check_finite=check_finite).T\n    return x", "response": "Patched version of scipy. linalg. cho_solve_AATI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsort a list according to the order of entries in a reference list.", "response": "def sort_by_list_order(sortlist, reflist, reverse=False, fltr=False,\n                       slemap=None):\n    \"\"\"\n    Sort a list according to the order of entries in a reference list.\n\n    Parameters\n    ----------\n    sortlist : list\n      List to be sorted\n    reflist : list\n      Reference list defining sorting order\n    reverse : bool, optional (default False)\n      Flag indicating whether to sort in reverse order\n    fltr : bool, optional (default False)\n      Flag indicating whether to filter `sortlist` to remove any entries\n      that are not in `reflist`\n    slemap : function or None, optional (default None)\n       Function mapping a sortlist entry to the form of an entry in\n       `reflist`\n\n    Returns\n    -------\n    sortedlist : list\n      Sorted (and possibly filtered) version of sortlist\n    \"\"\"\n\n    def keyfunc(entry):\n        if slemap is not None:\n            rle = slemap(entry)\n        if rle in reflist:\n            # Ordering index taken from reflist\n            return reflist.index(rle)\n        else:\n            # Ordering index taken from sortlist, offset\n            # by the length of reflist so that entries\n            # that are not in reflist retain their order\n            # in sortlist\n            return sortlist.index(entry) + len(reflist)\n\n    if fltr:\n        if slemap:\n            sortlist = filter(lambda x: slemap(x) in reflist, sortlist)\n        else:\n            sortlist = filter(lambda x: x in reflist, sortlist)\n\n    return sorted(sortlist, key=keyfunc, reverse=reverse)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of modules in a package or subpackage.", "response": "def get_module_names(filepath, modpath=None, skipunder=True):\n    \"\"\"\n    Get a list of modules in a package/subpackage.\n\n    Parameters\n    ----------\n    filepath : string\n      Filesystem path to the root directory of the package/subpackage\n    modpath : string or None, optional (default None)\n      Name of package or module path (in the form 'a.b.c') to a\n      subpackage\n    skipunder : bool, optional (default True)\n      Flag indicating whether to skip modules with names with an\n      initial underscore\n\n    Returns\n    -------\n    modlist : list\n      List of module names\n    \"\"\"\n\n    if modpath is None:\n        modpath = os.path.split(filepath)[-1]\n\n    modlst = []\n    for ff, name, ispkg in pkgutil.iter_modules([filepath]):\n        if not skipunder or name[0] != '_':\n            if ispkg:\n                sublst = get_module_names(os.path.join(filepath, name),\n                                          modpath + '.' + name,\n                                          skipunder=skipunder)\n                if sublst:\n                    modlst.extend(sublst)\n                else:\n                    modlst.append(modpath + '.' + name)\n            else:\n                modlst.append(modpath + '.' + name)\n\n    return modlst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of module member objects excluding members that are not in the specified module.", "response": "def get_module_members(module, type=None):\n    \"\"\"\n    Get a list of module member objects, excluding members that are\n    imported from other modules that are not submodules of the specified\n    moodule. An attempt is made to sort the list in order of definition\n    in the source file. If the module has an `__all__` attribute, the\n    list is sorted in the same order, and members that are not in the\n    list are filtered out.\n\n    Parameters\n    ----------\n    module : string or module object\n      Module for which member list is to be generated\n    type : inspect predicate function (e.g. inspect.isfunction) or None\n      Restrict returned members to specified type\n\n    Returns\n    -------\n    mbrlst : list\n      List of module members\n    \"\"\"\n\n    # if module argument is a string, try to load the module with the\n    # specified name\n    if isinstance(module, str):\n        module = importlib.import_module(module)\n\n    # Get members in the module\n    members = map(lambda x: x[1], inspect.getmembers(module, type))\n\n    # Filter out members that are not defined in the specified module\n    # or a submodule thereof\n    members = filter(lambda x: module.__name__ in _member_module_name(x),\n                     members)\n\n    if hasattr(module, '__all__'):\n        # If the module has an __all__ attribute, sort the members in the\n        # same order as the entries in __all__, and filter out members\n        # that are not listed in __all__. The slemap parameter of\n        # sort_by_list_order is needed because the list to be sorted\n        # consist of module member ojects, while __all__ is a list of\n        # module name strings.\n        members = sort_by_list_order(members, getattr(module, '__all__'),\n                                     fltr=True, slemap=lambda x: x.__name__)\n    else:\n        # If the module does not have an __all__ attribute, attempt to\n        # sort the members in the order in which they are defined in the\n        # source file(s)\n        members = sorted(members, key=_member_sort_key)\n\n    return members"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of module member classes.", "response": "def get_module_classes(module):\n    \"\"\"\n    Get a list of module member classes.\n\n    Parameters\n    ----------\n    module : string or module object\n      Module for which member list is to be generated\n\n    Returns\n    -------\n    mbrlst : list\n      List of module functions\n    \"\"\"\n\n    clslst = get_module_members(module, type=inspect.isclass)\n    return list(filter(lambda cls: not issubclass(cls, Exception),\n                       clslst))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_module_docs(pkgname, modpath, tmpltpath, outpath):\n\n    dw = DocWriter(outpath, tmpltpath)\n\n    modlst = get_module_names(modpath, pkgname)\n    print('Making api docs:', end='')\n    for modname in modlst:\n\n        # Don't generate docs for cupy or cuda subpackages\n        if 'cupy' in modname or 'cuda' in modname:\n            continue\n\n        try:\n            mod = importlib.import_module(modname)\n        except ModuleNotFoundError:\n            print('Error importing module %s' % modname)\n            continue\n\n        # Skip any virtual modules created by the copy-and-patch\n        # approach in sporco.cupy. These should already have been\n        # skipped due to the test for cupy above.\n        if mod.__file__ == 'patched':\n            continue\n\n        # Construct api docs for the current module if the docs file\n        # does not exist, or if its source file has been updated more\n        # recently than an existing docs file\n        if hasattr(mod, '__path__'):\n            srcpath = mod.__path__[0]\n        else:\n            srcpath = mod.__file__\n        dstpath = os.path.join(outpath, modname + '.rst')\n\n        if is_newer_than(srcpath, dstpath):\n            print(' %s' % modname, end='')\n            dw.write(mod)\n\n    print('')", "response": "Writes the autosummary style documentation for the specified package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the RST source document for generating the docs for the object holding the key - value entry for the object containing the key - value entry for the object containing the key - value entry for the object containing the key - value entry.", "response": "def write(self, module):\n        \"\"\"\n        Write the RST source document for generating the docs for\n        a specified module.\n\n        Parameters\n        ----------\n        module : module object\n          Module for which member list is to be generated\n        \"\"\"\n\n        modname = module.__name__\n\n        # Based on code in generate_autosummary_docs in https://git.io/fxpJS\n        ns = {}\n        ns['members'] = dir(module)\n        ns['functions'] = list(map(lambda x: x.__name__,\n                                   get_module_functions(module)))\n        ns['classes'] = list(map(lambda x: x.__name__,\n                                 get_module_classes(module)))\n        ns['exceptions'] = list(map(lambda x: x.__name__,\n                                    get_module_exceptions(module)))\n        ns['fullname'] = modname\n        ns['module'] = modname\n        ns['objname'] = modname\n        ns['name'] = modname.split('.')[-1]\n        ns['objtype'] = 'module'\n        ns['underline'] = len(modname) * '='\n        rndr = self.template.render(**ns)\n\n        rstfile = os.path.join(self.outpath, modname + '.rst')\n        with open(rstfile, 'w') as f:\n            f.write(rndr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn initialiser for working variable U.", "response": "def uinit(self, ushape):\n        \"\"\"Return initialiser for working variable U.\"\"\"\n\n        if  self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            Yss = np.sqrt(np.sum(self.Y[..., 0:-1]**2, axis=self.S.ndim,\n                                 keepdims=True))\n            U0 = (self.lmbda/self.rho)*sl.zdivide(self.Y[..., 0:-1], Yss)\n            U1 = (1.0 / self.rho)*np.sign(self.Y[..., -1:])\n            return np.concatenate((U0, U1), axis=self.S.ndim)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xstep(self):\n\n        ngsit = 0\n        gsrrs = np.inf\n        YU = self.Y - self.U\n        SYU = self.S + YU[..., -1]\n        YU[..., -1] = 0.0\n        ATYU = self.cnst_AT(YU)\n        while gsrrs > self.opt['GSTol'] and ngsit < self.opt['MaxGSIter']:\n            self.X = self.GaussSeidelStep(\n                SYU, self.X, ATYU, 1.0, self.lcw, 1.0)\n            gsrrs = sl.rrs(\n                self.cnst_AT(self.cnst_A(self.X)),\n                self.cnst_AT(self.cnst_c() - self.cnst_B(self.Y) - self.U)\n            )\n            ngsit += 1\n\n        self.xs = (ngsit, gsrrs)", "response": "Minimise Augmented Lagrangian with respect to\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nminimises Augmented Lagrangian with respect to self. ystep.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        self.Y[..., 0:-1] = sp.prox_l2(\n            self.AX[..., 0:-1] + self.U[..., 0:-1],\n            (self.lmbda/self.rho)*self.Wtvna, axis=self.saxes)\n        self.Y[..., -1] = sp.prox_l1(\n            self.AX[..., -1] + self.U[..., -1] - self.S,\n            (1.0/self.rho)*self.Wdf)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef obfn_gvar(self):\n\n        if self.opt['gEvalY']:\n            return self.Y\n        else:\n            return self.cnst_A(None, self.Xf) - self.cnst_c()", "response": "Variable to be evaluated in computing regularisation term depending on gEvalY option value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cnst_A(self, X, Xf=None):\n\n        if Xf is None:\n            Xf = sl.rfftn(X, axes=self.axes)\n        return sl.irfftn(self.GAf*Xf[..., np.newaxis], self.axsz,\n                         axes=self.axes)", "response": "r Compute A component of ADMM problem of ADMM problem with optional Xf parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cnst_AT(self, X):\n\n        Xf = sl.rfftn(X, axes=self.axes)\n        return np.sum(sl.irfftn(np.conj(self.GAf)*Xf, self.axsz,\n                                axes=self.axes), axis=self.Y.ndim-1)", "response": "r Compute the total number of components of A."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef norm_l0(x, axis=None, eps=0.0):\n\n    nl0 = np.sum(np.abs(x) > eps, axis=axis, keepdims=True)\n    # If the result has a single element, convert it to a scalar\n    if nl0.size == 1:\n        nl0 = nl0.ravel()[0]\n    return nl0", "response": "r Compute the l0 norm of x."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prox_l0(v, alpha):\n\n    return (np.abs(v) >= np.sqrt(2.0 * alpha)) * v", "response": "r Computes the proximal operator of the norm of the anatomical tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef norm_l1(x, axis=None):\n\n    nl1 = np.sum(np.abs(x), axis=axis, keepdims=True)\n    # If the result has a single element, convert it to a scalar\n    if nl1.size == 1:\n        nl1 = nl1.ravel()[0]\n    return nl1", "response": "r Compute the l1 norm of x."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prox_l1(v, alpha):\n\n    if have_numexpr:\n        return ne.evaluate(\n            'where(abs(v)-alpha > 0, where(v >= 0, 1, -1) * (abs(v)-alpha), 0)'\n        )\n    else:\n        return np.sign(v) * (np.clip(np.abs(v) - alpha, 0, float('Inf')))", "response": "r Compute the proximal operator of the \\ ell_1 norm of the array - like object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef norm_2l2(x, axis=None):\n\n    nl2 = np.sum(x**2, axis=axis, keepdims=True)\n    # If the result has a single element, convert it to a scalar\n    if nl2.size == 1:\n        nl2 = nl2.ravel()[0]\n    return nl2", "response": "r Compute the squared 2 norm of x."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _proj_l1_sortsum(v, gamma, axis=None):\n\n    if axis is None and norm_l1(v) <= gamma:\n        return v\n    if axis is not None and axis < 0:\n        axis = v.ndim + axis\n    av = np.abs(v)\n    vs = np.sort(av, axis=axis)\n    if axis is None:\n        N = v.size\n        c = 1.0 / np.arange(1, N + 1, dtype=v.dtype).reshape(v.shape)\n        vs = vs[::-1].reshape(v.shape)\n    else:\n        N = v.shape[axis]\n        ns = [v.shape[k] if k == axis else 1 for k in range(v.ndim)]\n        c = 1.0 / np.arange(1, N + 1, dtype=v.dtype).reshape(ns)\n        vs = vs[(slice(None),) * axis + (slice(None, None, -1),)]\n    t = c * (np.cumsum(vs, axis=axis).reshape(v.shape) - gamma)\n    K = np.sum(vs >= t, axis=axis, keepdims=True)\n    t = (np.sum(vs * (vs >= t), axis=axis, keepdims=True) - gamma) / K\n    t = np.asarray(np.maximum(0, t), dtype=v.dtype)\n    return np.sign(v) * np.where(av > t, av - t, 0)", "response": "r Projection operator of the \\ ell_1 norm. The solution isisometrically computed via the method of duchi - 2008 - efficient."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isfld(xmethod, dmethod, opt):\n\n    fld = ['Iter', 'ObjFun', 'DFid', 'RegL1', 'Cnstr']\n    if xmethod == 'admm':\n        fld.extend(['XPrRsdl', 'XDlRsdl', 'XRho'])\n    else:\n        if opt['CBPDN', 'BackTrack', 'Enabled']:\n            fld.extend(['X_F_Btrack', 'X_Q_Btrack', 'X_ItBt', 'X_L',\n                        'X_Rsdl'])\n        else:\n            fld.extend(['X_L', 'X_Rsdl'])\n    if dmethod != 'fista':\n        fld.extend(['DPrRsdl', 'DDlRsdl', 'DRho'])\n    else:\n        if opt['CCMOD', 'BackTrack', 'Enabled']:\n            fld.extend(['D_F_Btrack', 'D_Q_Btrack', 'D_ItBt', 'D_L',\n                        'D_Rsdl'])\n        else:\n            fld.extend(['D_L', 'D_Rsdl'])\n    fld.append('Time')\n    return fld", "response": "Return argument for IterStatsConfig initialiser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hdrtxt(xmethod, dmethod, opt):\n\n    txt = ['Itn', 'Fnc', 'DFid', u('\u21131'), 'Cnstr']\n    if xmethod == 'admm':\n        txt.extend(['r_X', 's_X', u('\u03c1_X')])\n    else:\n        if opt['CBPDN', 'BackTrack', 'Enabled']:\n            txt.extend(['F_X', 'Q_X', 'It_X', 'L_X'])\n        else:\n            txt.append('L_X')\n    if dmethod != 'fista':\n        txt.extend(['r_D', 's_D', u('\u03c1_D')])\n    else:\n        if opt['CCMOD', 'BackTrack', 'Enabled']:\n            txt.extend(['F_D', 'Q_D', 'It_D', 'L_D'])\n        else:\n            txt.append('L_D')\n    return txt", "response": "Return the header text for the current iteration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hdrmap(xmethod, dmethod, opt):\n\n    hdr = {'Itn': 'Iter', 'Fnc': 'ObjFun', 'DFid': 'DFid',\n           u('\u21131'): 'RegL1', 'Cnstr': 'Cnstr'}\n    if xmethod == 'admm':\n        hdr.update({'r_X': 'XPrRsdl', 's_X': 'XDlRsdl', u('\u03c1_X'): 'XRho'})\n    else:\n        if opt['CBPDN', 'BackTrack', 'Enabled']:\n            hdr.update({'F_X': 'X_F_Btrack', 'Q_X': 'X_Q_Btrack',\n                        'It_X': 'X_ItBt', 'L_X': 'X_L'})\n        else:\n            hdr.update({'L_X': 'X_L'})\n    if dmethod != 'fista':\n        hdr.update({'r_D': 'DPrRsdl', 's_D': 'DDlRsdl', u('\u03c1_D'): 'DRho'})\n    else:\n        if opt['CCMOD', 'BackTrack', 'Enabled']:\n            hdr.update({'F_D': 'D_F_Btrack', 'Q_D': 'D_Q_Btrack',\n                        'It_D': 'D_ItBt', 'L_D': 'D_L'})\n        else:\n            hdr.update({'L_D': 'D_L'})\n    return hdr", "response": "Return a dict of header names to values for iteration stats."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs IterationStats namedtuple from X step and D step object IterationStats namedtuples.", "response": "def iterstats(self, j, t, isx, isd, evl):\n        \"\"\"Construct IterationStats namedtuple from X step and D step\n        IterationStats namedtuples.\n\n        Parameters\n        ----------\n        j : int\n          Iteration number\n        t : float\n          Iteration time\n        isx : namedtuple\n          IterationStats namedtuple from X step object\n        isd : namedtuple\n          IterationStats namedtuple from D step object\n        evl : dict\n          Dict associating result labels with values computed by\n          :meth:`DictLearn.evaluate`\n        \"\"\"\n\n        vlst = []\n        # Iterate over the fields of the IterationStats namedtuple\n        # to be populated with values. If a field name occurs as a\n        # key in the isxmap dictionary, use the corresponding key\n        # value as a field name in the isx namedtuple for the X\n        # step object and append the value of that field as the\n        # next value in the IterationStats namedtuple under\n        # construction. The isdmap dictionary is handled\n        # correspondingly with respect to the isd namedtuple for\n        # the D step object. There are also two reserved field\n        # names, 'Iter' and 'Time', referring respectively to the\n        # iteration number and run time of the dictionary learning\n        # algorithm.\n        for fnm in self.IterationStats._fields:\n            if fnm in self.isxmap:\n                vlst.append(getattr(isx, self.isxmap[fnm]))\n            elif fnm in self.isdmap:\n                vlst.append(getattr(isd, self.isdmap[fnm]))\n            elif fnm in self.evlmap:\n                vlst.append(evl[fnm])\n            elif fnm == 'Iter':\n                vlst.append(j)\n            elif fnm == 'Time':\n                vlst.append(t)\n            else:\n                vlst.append(None)\n\n        return self.IterationStats._make(vlst)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting iteration statistics. Parameters ---------- itst : namedtuple IterationStats namedtuple as returned by :meth:`iterstats`", "response": "def printiterstats(self, itst):\n        \"\"\"Print iteration statistics.\n\n        Parameters\n        ----------\n        itst : namedtuple\n          IterationStats namedtuple as returned by :meth:`iterstats`\n        \"\"\"\n\n        itdsp = tuple([getattr(itst, self.hdrmap[col]) for col in self.hdrtxt])\n        print(self.fmtstr % itdsp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting or re - start optimisation of the derived object.", "response": "def solve(self):\n        \"\"\"Start (or re-start) optimisation. This method implements the\n        framework for the alternation between `X` and `D` updates in a\n        dictionary learning algorithm. There is sufficient flexibility\n        in specifying the two updates that it calls that it is\n        usually not necessary to override this method in derived\n        clases.\n\n        If option ``Verbose`` is ``True``, the progress of the\n        optimisation is displayed at every iteration. At termination\n        of this method, attribute :attr:`itstat` is a list of tuples\n        representing statistics of each iteration.\n\n        Attribute :attr:`timer` is an instance of :class:`.util.Timer`\n        that provides the following labelled timers:\n\n          ``init``: Time taken for object initialisation by\n          :meth:`__init__`\n\n          ``solve``: Total time taken by call(s) to :meth:`solve`\n\n          ``solve_wo_func``: Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics\n\n          ``solve_wo_rsdl`` : Total time taken by call(s) to\n          :meth:`solve`, excluding time taken to compute functional\n          value and related iteration statistics as well as time take\n          to compute residuals and implemented ``AutoRho`` mechanism\n        \"\"\"\n\n        # Print header and separator strings\n        if self.opt['Verbose'] and self.opt['StatusHeader']:\n            self.isc.printheader()\n\n        # Reset timer\n        self.timer.start(['solve', 'solve_wo_eval'])\n\n        # Main optimisation iterations\n        for self.j in range(self.j, self.j + self.opt['MaxMainIter']):\n\n            # X update\n            self.xstep.solve()\n            self.post_xstep()\n\n            # D update\n            self.dstep.solve()\n            self.post_dstep()\n\n            # Evaluate functional\n            self.timer.stop('solve_wo_eval')\n            evl = self.evaluate()\n            self.timer.start('solve_wo_eval')\n\n            # Record elapsed time\n            t = self.timer.elapsed(self.opt['IterTimer'])\n\n            # Extract and record iteration stats\n            xitstat = self.xstep.itstat[-1] if self.xstep.itstat else \\\n                      self.xstep.IterationStats(\n                          *([0.0,] * len(self.xstep.IterationStats._fields)))\n            ditstat = self.dstep.itstat[-1] if self.dstep.itstat else \\\n                      self.dstep.IterationStats(\n                          *([0.0,] * len(self.dstep.IterationStats._fields)))\n            itst = self.isc.iterstats(self.j, t, xitstat, ditstat, evl)\n            self.itstat.append(itst)\n\n            # Display iteration stats if Verbose option enabled\n            if self.opt['Verbose']:\n                self.isc.printiterstats(itst)\n\n            # Call callback function if defined\n            if self.opt['Callback'] is not None:\n                if self.opt['Callback'](self):\n                    break\n\n\n        # Increment iteration count\n        self.j += 1\n\n        # Record solve time\n        self.timer.stop(['solve', 'solve_wo_eval'])\n\n        # Print final separator string if Verbose option enabled\n        if self.opt['Verbose'] and self.opt['StatusHeader']:\n            self.isc.printseparator()\n\n        # Return final dictionary\n        return self.getdict()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef norm_nuclear(X):\n\n    return np.sum(np.linalg.svd(sl.promote16(X), compute_uv=False))", "response": "r Compute the nuclear norm of X."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_module_names(package_path, pattern=\"lazy_*.py*\"):\n  package_contents = glob(os.path.join(package_path[0], pattern))\n  relative_path_names = (os.path.split(name)[1] for name in package_contents)\n  no_ext_names = (os.path.splitext(name)[0] for name in relative_path_names)\n  return sorted(set(no_ext_names))", "response": "Get the names of modules that match the given glob."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of modules from the given package.", "response": "def get_modules(package_name, module_names):\n  \"\"\" List of module objects from the package, keeping the name order. \"\"\"\n  def get_module(name):\n    return __import__(\".\".join([package_name, name]), fromlist=[package_name])\n  return [get_module(name) for name in module_names]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summary_table(pairs, key_header, descr_header=\"Description\", width=78):\n  from .lazy_text import rst_table, small_doc\n  max_width = width - max(len(k) for k, v in pairs)\n  table = [(k, small_doc(v, max_width=max_width)) for k, v in pairs]\n  return rst_table(table, (key_header, descr_header))", "response": "Return a reStructuredText summary table for the given pairs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string joining the docstring with the pairs summary table.", "response": "def docstring_with_summary(docstring, pairs, key_header, summary_type):\n  \"\"\" Return a string joining the docstring with the pairs summary table. \"\"\"\n  return \"\\n\".join(\n    [docstring, \"Summary of {}:\".format(summary_type), \"\"] +\n    summary_table(pairs, key_header) + [\"\"]\n  )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_summary_to_module_docstring(module):\n  pairs = [(name, getattr(module, name)) for name in module.__all__]\n  kws = dict(key_header=\"Name\", summary_type=\"module contents\")\n  module.__doc__ = docstring_with_summary(module.__doc__, pairs, **kws)", "response": "Change the module. doc__ to include a summary table based\n on its contents as declared on module. all."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_package(package_path, package_name, docstring):\n  module_names = get_module_names(package_path)\n  modules = get_modules(package_name, module_names)\n  dunder_all = dunder_all_concat(modules)\n  for module in modules:\n    append_summary_to_module_docstring(module)\n  pairs = list(zip(module_names, modules))\n  kws = dict(key_header=\"Module\", summary_type=\"package modules\")\n  new_docstring = docstring_with_summary(docstring, pairs, **kws)\n  return module_names, dunder_all, new_docstring", "response": "Package initialization, to be called only by ``__init__.py``.\n\n  - Find all module names;\n  - Import all modules (so they're already cached on sys.modules), in\n    the sorting order (this might make difference on cyclic imports);\n  - Update all module docstrings (with the summary of its contents);\n  - Build a module summary for the package docstring.\n\n  Returns\n  -------\n  A 4-length tuple ``(modules, __all__, __doc__)``. The first one can be\n  used by the package to import every module into the main package namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_to_16bit_wave_file(fname, sig, rate):\n  with closing(wave.open(fname, \"wb\")) as wave_file:\n    wave_file.setnchannels(1)\n    wave_file.setsampwidth(2)\n    wave_file.setframerate(rate)\n    for chunk in chunks((clip(sig) * 2 ** 15).map(int), dfmt=\"h\", padval=0):\n      wave_file.writeframes(chunk)", "response": "Save a given signal to file fname as a 16 - bit one - channel wave."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_note_track(env, synth):\n  list_env = list(env)\n  return chain.from_iterable(synth(freq) * list_env for freq in freq_gen())", "response": "Create a new audio track with the given frequencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the unpitched low frequency sound as a list.", "response": "def unpitched_low(dur, idx):\n  \"\"\"\n  Non-harmonic bass/lower frequency sound as a list (due to memoization).\n\n  Parameters\n  ----------\n  dur:\n    Duration, in samples.\n  idx:\n    Zero or one (integer), for a small difference to the sound played.\n\n  Returns\n  -------\n  A list with the synthesized note.\n\n  \"\"\"\n  env = sinusoid(lag2freq(dur * 2)).limit(dur) ** 2\n  freq = 40 + 20 * sinusoid(1000 * Hz, phase=uniform(-pi, pi)) # Hz\n  result = (low_table(freq * Hz) + low_table(freq * 1.1 * Hz)) * env * .5\n  return list(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelay effect by copying data (with Streamix). Parameters ---------- sig: Input signal (an iterable). dur: Duration, in samples. copies: Number of times the signal will be replayed in the given duration. The signal is played copies + 1 times. pamp: The relative remaining amplitude fraction for the next played Stream, based on the idea that total amplitude should sum to 1. Defaults to 0.5.", "response": "def geometric_delay(sig, dur, copies, pamp=.5):\n  \"\"\"\n  Delay effect by copying data (with Streamix).\n\n  Parameters\n  ----------\n  sig:\n    Input signal (an iterable).\n  dur:\n    Duration, in samples.\n  copies:\n    Number of times the signal will be replayed in the given duration. The\n    signal is played copies + 1 times.\n  pamp:\n    The relative remaining amplitude fraction for the next played Stream,\n    based on the idea that total amplitude should sum to 1. Defaults to 0.5.\n\n  \"\"\"\n  out = Streamix()\n  sig = thub(sig, copies + 1)\n  out.add(0, sig * pamp) # Original\n  remain = 1 - pamp\n  for unused in xrange(copies):\n    gain = remain * pamp\n    out.add(dur / copies, sig * gain)\n    remain -= gain\n  return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tostream(func, module_name=None):\n  @wraps(func)\n  def new_func(*args, **kwargs):\n    return Stream(func(*args, **kwargs))\n  if module_name is not None:\n    new_func.__module__ = module_name\n  return new_func", "response": "Decorator to convert the output of a function into a Stream. Useful for generating generator functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef thub(data, n):\n  return StreamTeeHub(data, n) if isinstance(data, Iterable) else data", "response": "Tee or THub auto - copier for working with StreamTeeHubs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef blocks(self, *args, **kwargs):\n    return Stream(blocks(iter(self), *args, **kwargs))", "response": "Returns a new stream with the elements of the sequence in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef take(self, n=None, constructor=list):\n    if n is None:\n      return next(self._data)\n    if isinf(n) and n > 0:\n      return constructor(self._data)\n    if isinstance(n, float):\n      n = rint(n) if n > 0 else 0 # So this works with -inf and nan\n    return constructor(next(self._data) for _ in xrange(n))", "response": "Returns a new container with the first n elements from the Stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self):\n    a, b = it.tee(self._data) # 2 generators, not thread-safe\n    self._data = a\n    return Stream(b)", "response": "Returns a copy of the given stream allowing the calling\n    stream to continue being used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef peek(self, n=None, constructor=list):\n    return self.copy().take(n=n, constructor=constructor)", "response": "Returns the next n items from the Stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Stream with only the first n values.", "response": "def skip(self, n):\n    \"\"\"\n    Throws away the first ``n`` values from the Stream.\n\n    Note\n    ----\n    Performs the evaluation lazily, i.e., the values are thrown away only\n    after requesting the next value.\n\n    \"\"\"\n    def skipper(data):\n      for _ in xrange(int(round(n))):\n        next(data)\n      for el in data:\n        yield el\n\n    self._data = skipper(self._data)\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef limit(self, n):\n    data = self._data\n    self._data = (next(data) for _ in xrange(int(round(n))))\n    return self", "response": "Limit the stream to a certain number of items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend other streams to the end of this stream.", "response": "def append(self, *other):\n    \"\"\"\n    Append self with other stream(s). Chaining this way has the behaviour:\n\n      ``self = Stream(self, *others)``\n\n    \"\"\"\n    self._data = it.chain(self._data, Stream(*other)._data)\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map(self, func):\n    self._data = xmap(func, self._data)\n    return self", "response": "A lazy way to apply the given function to each element in the stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self):\n    if self._iters:\n      a, b = it.tee(self._iters[0])\n      self._iters[0] = a\n      return Stream(b)\n    iter(self)", "response": "Returns a copy of this StreamTeeHub without consuming\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an iterable event to the mixer.", "response": "def add(self, delta, data):\n    \"\"\"\n    Adds (enqueues) an iterable event to the mixer.\n\n    Parameters\n    ----------\n    delta :\n      Time in samples since last added event. This can be zero and can be\n      float. Use \"s\" object from sHz for time conversion.\n    data :\n      Iterable (e.g. a list, a tuple, a Stream) to be \"played\" by the mixer at\n      the given time delta.\n\n    See Also\n    --------\n    sHz :\n      Time in seconds (s) and frequency in hertz (Hz) constants from sample\n      rate in samples/second.\n\n    \"\"\"\n    if delta < 0:\n      raise ValueError(\"Delta time should be always positive\")\n    self._not_playing.append((delta, iter(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accumulate(iterable):\n  \" Return series of accumulated sums. \"\n  iterator = iter(iterable)\n  sum_data = next(iterator)\n  yield sum_data\n  for el in iterator:\n    sum_data += el\n    yield sum_data", "response": "Return series of accumulated sums."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tee(data, n=2):\n  if isinstance(data, (Stream, Iterator)):\n    return tuple(Stream(cp) for cp in it.tee(data, n))\n  else:\n    return tuple(data for unused in xrange(n))", "response": "Tee or T copy to help working with Stream instances and numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef factorial(n):\n  if isinstance(n, float):\n    if n.is_integer():\n      n = int(n)\n  if not isinstance(n, INT_TYPES):\n    raise TypeError(\"Non-integer input (perhaps you need Euler Gamma \"\n                    \"function or Gauss Pi function)\")\n  if n < 0:\n    raise ValueError(\"Input shouldn't be negative\")\n  return reduce(operator.mul,\n                it.takewhile(lambda m: m <= n, it.count(2)),\n                1)", "response": "Factorial function that works with really big numbers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when the mouse is moved or moved to another node", "response": "def on_timer(self, evt):\n    \"\"\"\n    Keep watching the mouse displacement via timer\n    Needed since EVT_MOVE doesn't happen once the mouse gets outside the\n    frame\n    \"\"\"\n    ctrl_is_down = wx.GetKeyState(wx.WXK_CONTROL)\n    ms = wx.GetMouseState()\n\n    # New initialization when keys pressed change\n    if self._key_state != ctrl_is_down:\n      self._key_state = ctrl_is_down\n\n      # Keep state at click\n      self._click_ms_x, self._click_ms_y = ms.x, ms.y\n      self._click_frame_x, self._click_frame_y = self.Position\n      self._click_frame_width, self._click_frame_height = self.ClientSize\n\n      # Avoids refresh when there's no move (stores last mouse state)\n      self._last_ms = ms.x, ms.y\n\n      # Quadrant at click (need to know how to resize)\n      width, height = self.ClientSize\n      self._quad_signal_x = 1 if (self._click_ms_x -\n                                  self._click_frame_x) / width > .5 else -1\n      self._quad_signal_y = 1 if (self._click_ms_y -\n                                  self._click_frame_y) / height > .5 else -1\n\n    # \"Polling watcher\" for mouse left button while it's kept down\n    if ms.leftDown:\n      if self._last_ms != (ms.x, ms.y): # Moved?\n        self._last_ms = (ms.x, ms.y)\n        delta_x = ms.x - self._click_ms_x\n        delta_y = ms.y - self._click_ms_y\n\n        # Resize\n        if ctrl_is_down:\n          # New size\n          new_w = max(MIN_WIDTH, self._click_frame_width +\n                                 2 * delta_x * self._quad_signal_x\n                     )\n          new_h = max(MIN_HEIGHT, self._click_frame_height +\n                                  2 * delta_y * self._quad_signal_y\n                     )\n          self.ClientSize = new_w, new_h\n          self.SendSizeEvent() # Needed for wxGTK\n\n          # Center should be kept\n          center_x = self._click_frame_x + self._click_frame_width / 2\n          center_y = self._click_frame_y + self._click_frame_height / 2\n          self.Position = (center_x - new_w / 2,\n                           center_y - new_h / 2)\n\n          self.Refresh()\n          self.volume_ctrl.value = (new_h * new_w) / 3e5\n\n        # Move the window\n        else:\n          self.Position = (self._click_frame_x + delta_x,\n                           self._click_frame_y + delta_y)\n\n          # Find the new center position\n          x, y = self.Position\n          w, h = self.ClientSize\n          cx, cy = x + w/2, y + h/2\n          self.mod_ctrl.value = 2.5 * cx\n          self.carrier_ctrl.value = 2.5 * cy\n          self.angstep.value = (cx + cy) * pi * 2e-4\n\n      # Since left button is kept down, there should be another one shot\n      # timer event again, without creating many timers like wx.CallLater\n      self._timer.Start(MOUSE_TIMER_WATCH, True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mgl_seq(x):\n  odd_numbers = thub(count(start=1, step=2), 2)\n  return Stream(1, -1) * x ** odd_numbers / odd_numbers", "response": "Returns a sequence of the Madhava - Gregory - Leibniz series."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef atan_mgl(x, n=10):\n  acc = 1 / (1 - z ** -1) # Accumulator filter\n  return acc(mgl_seq(x)).skip(n-1).take()", "response": "Calculates the arctan of x using Madhava - Gregory - Leibniz series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lagrange(pairs):\n  prod = lambda args: reduce(operator.mul, args)\n  xv, yv = xzip(*pairs)\n  return lambda k: sum( yv[j] * prod( (k - rk) / (rj - rk)\n                                      for rk in xv if rj != rk )\n                        for j, rj in enumerate(xv) )", "response": "Waring - Lagrange interpolator function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resample(sig, old=1, new=1, order=3, zero=0.):\n  sig = Stream(sig)\n  threshold = .5 * (order + 1)\n  step = old / new\n  data = deque([zero] * (order + 1), maxlen=order + 1)\n  data.extend(sig.take(rint(threshold)))\n  idx = int(threshold)\n  isig = iter(sig)\n  if isinstance(step, Iterable):\n    step = iter(step)\n    while True:\n      yield lagrange(enumerate(data))(idx)\n      idx += next(step)\n      while idx > threshold:\n        data.append(next(isig))\n        idx -= 1\n  else:\n    while True:\n      yield lagrange(enumerate(data))(idx)\n      idx += step\n      while idx > threshold:\n        data.append(next(isig))\n        idx -= 1", "response": "Resample a signal using Waring - Lagrange interpolators."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef values(self):\n    if self._data:\n      for key in xrange(self.order + 1):\n        yield self[key]", "response": "Returns an array of values for each element in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef terms(self, sort=\"auto\", reverse=False):\n    if sort == \"auto\":\n      sort = self.is_laurent()\n\n    if sort:\n      keys = sorted(self._data, reverse=reverse)\n    elif reverse:\n      keys = reversed(list(self._data))\n    else:\n      keys = self._data\n\n    return ((k, self._data[k]) for k in keys)", "response": "Returns a generator that yields the terms of the Laurent object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_polynomial(self):\n    return all(isinstance(k, INT_TYPES) and k >= 0 for k in self._data)", "response": "Tells whether the sequence is a linear combination of natural powers of x."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order(self):\n    if not self.is_polynomial():\n      raise AttributeError(\"Power needs to be positive integers\")\n    return max(key for key in self._data) if self._data else 0", "response": "Returns the polynomial order of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the polynomial.", "response": "def copy(self, zero=None):\n    \"\"\"\n    Returns a Poly instance with the same terms, but as a \"T\" (tee) copy\n    when they're Stream instances, allowing maths using a polynomial more\n    than once.\n    \"\"\"\n    return Poly(OrderedDict((k, v.copy() if isinstance(v, Stream) else v)\n                            for k, v in iteritems(self._data)),\n                zero=self.zero if zero is None else zero)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef diff(self, n=1):\n    d = self._data\n    for unused in xrange(n):\n      d = OrderedDict((k - 1, k * v) for k, v in iteritems(d) if k != 0)\n    return Poly(d, zero=self.zero)", "response": "Diffusion of the polynomial."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef integrate(self):\n    if -1 in self._data:\n      raise ValueError(\"Unable to integrate term that powers to -1\")\n    return Poly(OrderedDict((k + 1, v / (k + 1))\n                            for k, v in iteritems(self._data)),\n                zero=self.zero)", "response": "Integrate with adding an integration constant."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list with all roots. Needs Numpy.", "response": "def roots(self):\n    \"\"\"\n    Returns a list with all roots. Needs Numpy.\n    \"\"\"\n    import numpy as np\n    return np.roots(list(self.values())[::-1]).tolist()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _exec_eval(data, expr):\n  ns = {}\n  exec(data, ns)\n  return eval(expr, ns)", "response": "Internal function to isolate an exec. Executes data and returns the\n expr evaluation afterwards."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a comb filter for a given time constant and delay.", "response": "def comb(delay, tau=inf):\n  \"\"\"\n  Feedback comb filter for a given time constant (and delay).\n\n    ``y[n] = x[n] + alpha * y[n - delay]``\n\n  Parameters\n  ----------\n  delay :\n    Feedback delay (lag), in number of samples.\n  tau :\n    Time decay (up to ``1/e``, or -8.686 dB), in number of samples, which\n    allows finding ``alpha = e ** (-delay / tau)``. Defaults to ``inf``\n    (infinite), which means alpha = 1.\n\n  Returns\n  -------\n  A ZFilter instance with the comb filter.\n\n  See Also\n  --------\n  freq2lag :\n    Frequency (in rad/sample) to delay (in samples) converter.\n\n  \"\"\"\n  alpha = e ** (-delay / tau)\n  return 1 / (1 - alpha * z ** -delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a resonator filter for the given frequency and bandwidth.", "response": "def resonator(freq, bandwidth):\n  \"\"\"\n  Resonator filter with 2-poles (conjugated pair) and no zeros (constant\n  numerator), with exponential approximation for bandwidth calculation.\n\n  Parameters\n  ----------\n  freq :\n    Resonant frequency in rad/sample (max gain).\n  bandwidth :\n    Bandwidth frequency range in rad/sample following the equation:\n\n      ``R = exp(-bandwidth / 2)``\n\n    where R is the pole amplitude (radius).\n\n  Returns\n  -------\n  A ZFilter object.\n  Gain is normalized to have peak with 0 dB (1.0 amplitude).\n\n  \"\"\"\n  bandwidth = thub(bandwidth, 1)\n  R = exp(-bandwidth * .5)\n  R = thub(R, 5)\n  cost = cos(freq) * (2 * R) / (1 + R ** 2)\n  cost = thub(cost, 2)\n  gain = (1 - R ** 2) * sqrt(1 - cost ** 2)\n  denominator = 1 - 2 * R * cost * z ** -1 + R ** 2 * z ** -2\n  return gain / denominator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntest whether all filters in the list are linear. CascadeFilter and ParallelFilter instances are also linear.", "response": "def is_linear(self):\n    \"\"\"\n    Tests whether all filters in the list are linear. CascadeFilter and\n    ParallelFilter instances are also linear if all filters they group are\n    linear.\n\n    \"\"\"\n    return all(isinstance(filt, LinearFilter) or\n               (hasattr(filt, \"is_linear\") and filt.is_linear())\n               for filt in self.callables)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_lti(self):\n    return self.is_linear() and all(filt.is_lti() for filt in self.callables)", "response": "Tests whether all filters in the list are linear time invariant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting whether all filters in the list are causal.", "response": "def is_causal(self):\n    \"\"\"\n    Tests whether all filters in the list are causal (i.e., no future-data\n    delay in positive ``z`` exponents). Non-linear filters are seem as causal\n    by default. CascadeFilter and ParallelFilter are causal if all the\n    filters they group are causal.\n\n    \"\"\"\n    return all(filt.is_causal() for filt in self.callables\n                                if hasattr(filt, \"is_causal\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the error frequency for a given frequency.", "response": "def erb(freq, Hz=None):\n  \"\"\"\n    ``B. C. J. Moore and B. R. Glasberg, \"Suggested formulae for calculating\n    auditory filter bandwidths and excitation patterns\". J. Acoust. Soc.\n    Am., 74, 1983, pp. 750-753.``\n  \"\"\"\n  if Hz is None:\n    if freq < 7: # Perhaps user tried something up to 2 * pi\n      raise ValueError(\"Frequency out of range.\")\n    Hz = 1\n  fHz = freq / Hz\n  result = 6.23e-6 * fHz ** 2 + 93.39e-3 * fHz + 28.52\n  return result * Hz"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the constants for using the real bandwidth in the aracery filter.", "response": "def gammatone_erb_constants(n):\n  \"\"\"\n  Constants for using the real bandwidth in the gammatone filter, given its\n  order. Returns a pair :math:`(x, y) = (1/a_n, c_n)`.\n\n  Based on equations from:\n\n    ``Holdsworth, J.; Patterson, R.; Nimmo-Smith, I.; Rice, P. Implementing a\n    GammaTone Filter Bank. In: SVOS Final Report, Annex C, Part A: The\n    Auditory Filter Bank. 1988.``\n\n  First returned value is a bandwidth compensation for direct use in the\n  gammatone formula:\n\n  >>> x, y = gammatone_erb_constants(4)\n  >>> central_frequency = 1000\n  >>> round(x, 3)\n  1.019\n  >>> bandwidth = x * erb[\"moore_glasberg_83\"](central_frequency)\n  >>> round(bandwidth, 2)\n  130.52\n\n  Second returned value helps us find the ``3 dB`` bandwidth as:\n\n  >>> x, y = gammatone_erb_constants(4)\n  >>> central_frequency = 1000\n  >>> bandwidth3dB = x * y * erb[\"moore_glasberg_83\"](central_frequency)\n  >>> round(bandwidth3dB, 2)\n  113.55\n\n  \"\"\"\n  tnt = 2 * n - 2\n  return (factorial(n - 1) ** 2 / (pi * factorial(tnt) * 2 ** -tnt),\n          2 * (2 ** (1. / n) - 1) ** .5\n         )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gammatone(freq, bandwidth):\n  A = exp(-bandwidth)\n  cosw = cos(freq)\n  sinw = sin(freq)\n  sig = [1., -1.]\n  coeff = [cosw + s1 * (sqrt(2) + s2) * sinw for s1 in sig for s2 in sig]\n  numerator = [1 - A * c * z ** -1 for c in coeff]\n  denominator = 1 - 2 * A * cosw * z ** -1 + A ** 2 * z ** -2\n\n  filt = CascadeFilter(num / denominator for num in numerator)\n  return CascadeFilter(f / abs(f.freq_response(freq)) for f in filt)", "response": "A function that computes the gammatone filter for a given frequency and bandwidth."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef phon2dB(loudness=None):\n  from scipy.interpolate import UnivariateSpline\n\n  table = phon2dB.iso226.table\n  schema = phon2dB.iso226.schema\n  freqs = [row[schema.index(\"freq\")] for row in table]\n\n  if loudness is None: # Threshold levels\n    spl = [row[schema.index(\"threshold\")] for row in table]\n\n  else: # Curve for a specific phon value\n    def get_pressure_level(freq, alpha, loudness_base, threshold):\n      return 10 / alpha * math.log10(\n        4.47e-3 * (10 ** (.025 * loudness) - 1.14) +\n        (.4 * 10 ** ((threshold + loudness_base) / 10 - 9)) ** alpha\n      ) - loudness_base + 94\n\n    spl = [get_pressure_level(**dict(xzip(schema, args))) for args in table]\n\n  interpolator = UnivariateSpline(freqs, spl, s=0)\n  interpolator_low = UnivariateSpline([-30] + freqs, [1e3] + spl, s=0)\n  interpolator_high = UnivariateSpline(freqs + [32000], spl + [1e3], s=0)\n\n  @elementwise(\"freq\", 0)\n  def freq2dB_spl(freq):\n    if freq < 20:\n      return interpolator_low(freq).tolist()\n    if freq > 12500:\n      return interpolator_high(freq).tolist()\n    return interpolator(freq).tolist()\n  return freq2dB_spl", "response": "This function returns the value of the Hint\n from the original frequency in hertz."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate all window and wsymm strategies", "response": "def _generate_window_strategies():\n  \"\"\" Create all window and wsymm strategies \"\"\"\n  for wnd_dict in window._content_generation_table:\n    names = wnd_dict[\"names\"]\n    sname = wnd_dict[\"sname\"] = names[0]\n    wnd_dict.setdefault(\"params_def\", \"\")\n    for sdict in [window, wsymm]:\n      docs_dict = window._doc_kwargs(symm = sdict is wsymm, **wnd_dict)\n      decorators = [format_docstring(**docs_dict), sdict.strategy(*names)]\n      ns = dict(pi=pi, sin=sin, cos=cos, xrange=xrange, __name__=__name__)\n      exec(sdict._code_template.format(**wnd_dict), ns, ns)\n      reduce(lambda func, dec: dec(func), decorators, ns[sname])\n      if not wnd_dict.get(\"distinct\", True):\n        wsymm[sname] = window[sname]\n        break\n    wsymm[sname].periodic = window[sname].periodic = window[sname]\n    wsymm[sname].symm = window[sname].symm = wsymm[sname]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef acorr(blk, max_lag=None):\n  if max_lag is None:\n    max_lag = len(blk) - 1\n  return [sum(blk[n] * blk[n + tau] for n in xrange(len(blk) - tau))\n          for tau in xrange(max_lag + 1)]", "response": "Calculates the autocorrelation of a given 1 - D block sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the covariance matrix of a given 1 - D block sequence.", "response": "def lag_matrix(blk, max_lag=None):\n  \"\"\"\n  Finds the lag matrix for a given 1-D block sequence.\n\n  Parameters\n  ----------\n  blk :\n    An iterable with well-defined length. Don't use this function with Stream\n    objects!\n  max_lag :\n    The size of the result, the lags you'd need. Defaults to ``len(blk) - 1``,\n    the maximum lag that doesn't create fully zeroed matrices.\n\n  Returns\n  -------\n  The covariance matrix as a list of lists. Each cell (i, j) contains the sum\n  of ``blk[n - i] * blk[n - j]`` elements for all n that allows such without\n  padding the given block.\n\n  \"\"\"\n  if max_lag is None:\n    max_lag = len(blk) - 1\n  elif max_lag >= len(blk):\n    raise ValueError(\"Block length should be higher than order\")\n\n  return [[sum(blk[n - i] * blk[n - j] for n in xrange(max_lag, len(blk))\n              ) for i in xrange(max_lag + 1)\n          ] for j in xrange(max_lag + 1)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dft(blk, freqs, normalize=True):\n  dft_data = (sum(xn * cexp(-1j * n * f) for n, xn in enumerate(blk))\n                                         for f in freqs)\n  if normalize:\n    lblk = len(blk)\n    return [v / lblk for v in dft_data]\n  return list(dft_data)", "response": "Complex non - optimized Discrete Fourier Transform\n\n"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterator over the zero crossing of the given sequence.", "response": "def zcross(seq, hysteresis=0, first_sign=0):\n  \"\"\"\n  Zero-crossing stream.\n\n  Parameters\n  ----------\n  seq :\n    Any iterable to be used as input for the zero crossing analysis\n  hysteresis :\n    Crossing exactly zero might happen many times too fast due to high\n    frequency oscilations near zero. To avoid this, you can make two\n    threshold limits for the zero crossing detection: ``hysteresis`` and\n    ``-hysteresis``. Defaults to zero (0), which means no hysteresis and only\n    one threshold.\n  first_sign :\n    Optional argument with the sign memory from past. Gets the sig from any\n    signed number. Defaults to zero (0), which means \"any\", and the first sign\n    will be the first one found in data.\n\n  Returns\n  -------\n  A Stream instance that outputs 1 for each crossing detected, 0 otherwise.\n\n  \"\"\"\n  neg_hyst = -hysteresis\n  seq_iter = iter(seq)\n\n  # Gets the first sign\n  if first_sign == 0:\n    last_sign = 0\n    for el in seq_iter:\n      yield 0\n      if (el > hysteresis) or (el < neg_hyst): # Ignores hysteresis region\n        last_sign = -1 if el < 0 else 1 # Define the first sign\n        break\n  else:\n    last_sign = -1 if first_sign < 0 else 1\n\n  # Finds the full zero-crossing sequence\n  for el in seq_iter: # Keep the same iterator (needed for non-generators)\n    if el * last_sign < neg_hyst:\n      last_sign = -1 if el < 0 else 1\n      yield 1\n    else:\n      yield 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove average This is the only strategy that uses a ``collections.deque`` object instead of a ZFilter instance. Fast, but without extra capabilites such as a frequency response plotting method. Parameters ---------- size : Data block window size. Should be an integer. Returns ------- A callable that accepts two parameters: a signal ``sig`` and the starting memory element ``zero`` that behaves like the ``LinearFilter.__call__`` arguments. The output from that callable is a Stream instance, and has no decimation applied. See Also -------- envelope : Signal envelope (time domain) strategies.", "response": "def maverage(size):\n  \"\"\"\n  Moving average\n\n  This is the only strategy that uses a ``collections.deque`` object\n  instead of a ZFilter instance. Fast, but without extra capabilites such\n  as a frequency response plotting method.\n\n  Parameters\n  ----------\n  size :\n    Data block window size. Should be an integer.\n\n  Returns\n  -------\n  A callable that accepts two parameters: a signal ``sig`` and the starting\n  memory element ``zero`` that behaves like the ``LinearFilter.__call__``\n  arguments. The output from that callable is a Stream instance, and has\n  no decimation applied.\n\n  See Also\n  --------\n  envelope :\n    Signal envelope (time domain) strategies.\n\n  \"\"\"\n  size_inv = 1. / size\n\n  @tostream\n  def maverage_filter(sig, zero=0.):\n    data = deque((zero * size_inv for _ in xrange(size)), maxlen=size)\n    mean_value = zero\n    for el in sig:\n      mean_value -= data.popleft()\n      new_value = el * size_inv\n      data.append(new_value)\n      mean_value += new_value\n      yield mean_value\n\n  return maverage_filter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclipping a signal up to a lower and a higher limit.", "response": "def clip(sig, low=-1., high=1.):\n  \"\"\"\n  Clips the signal up to both a lower and a higher limit.\n\n  Parameters\n  ----------\n  sig :\n    The signal to be clipped, be it a Stream instance, a list or any iterable.\n  low, high :\n    Lower and higher clipping limit, \"saturating\" the input to them. Defaults\n    to -1.0 and 1.0, respectively. These can be None when needed one-sided\n    clipping. When both limits are set to None, the output will be a Stream\n    that yields exactly the ``sig`` input data.\n\n  Returns\n  -------\n  Clipped signal as a Stream instance.\n\n  \"\"\"\n  if low is None:\n    if high is None:\n      return Stream(sig)\n    return Stream(el if el < high else high for el in sig)\n  if high is None:\n    return Stream(el if el > low else low for el in sig)\n  if high < low:\n    raise ValueError(\"Higher clipping limit is smaller than lower one\")\n  return Stream(high if el > high else\n                (low if el < low else el) for el in sig)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unwrap(sig, max_delta=pi, step=2*pi):\n  idata = iter(sig)\n  d0 = next(idata)\n  yield d0\n  delta = d0 - d0 # Get the zero (e.g., integer, float) from data\n  for d1 in idata:\n    d_diff = d1 - d0\n    if abs(d_diff) > max_delta:\n      delta += - d_diff + min((d_diff) % step,\n                              (d_diff) % -step, key=lambda x: abs(x))\n    yield d1 + delta\n    d0 = d1", "response": "Unwraps a signal into a Stream of adjacency steps."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef amdf(lag, size):\n  filt = (1 - z ** -lag).linearize()\n\n  @tostream\n  def amdf_filter(sig, zero=0.):\n    return maverage(size)(abs(filt(sig, zero=zero)), zero=zero)\n\n  return amdf_filter", "response": "A non - linear filter for a given frequency and a fixed lag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverlaps - add algorithm using lists instead of Numpy arrays.", "response": "def overlap_add(blk_sig, size=None, hop=None, wnd=None, normalize=True):\n  \"\"\"\n  Overlap-add algorithm using lists instead of Numpy arrays. The behavior\n  is the same to the ``overlap_add.numpy`` strategy, besides the data types.\n  \"\"\"\n  # Finds the size from data, if needed\n  if size is None:\n    blk_sig = Stream(blk_sig)\n    size = len(blk_sig.peek())\n  if hop is None:\n    hop = size\n\n  # Find the window to be applied, resulting on a list or None\n  if wnd is not None:\n    if callable(wnd) and not isinstance(wnd, Stream):\n      wnd = wnd(size)\n    if isinstance(wnd, Iterable):\n      wnd = list(wnd)\n    else:\n      raise TypeError(\"Window should be an iterable or a callable\")\n\n  # Normalization to the [-1; 1] range\n  if normalize:\n    if wnd:\n      steps = Stream(wnd).map(abs).blocks(hop).map(tuple)\n      gain = max(xmap(sum, xzip(*steps)))\n      if gain: # If gain is zero, normalization couldn't have any effect\n        wnd[:] = (w / gain for w in wnd)\n    else:\n      wnd = [1 / ceil(size / hop)] * size\n\n  # Window application\n  if wnd:\n    mul = operator.mul\n    if len(wnd) != size:\n      raise ValueError(\"Incompatible window size\")\n    wnd = wnd + [0.] # Allows detecting when block size is wrong\n    blk_sig = (xmap(mul, wnd, blk) for blk in blk_sig)\n\n  # Overlap-add algorithm\n  add = operator.add\n  mem = [0.] * size\n  s_h = size - hop\n  for blk in xmap(iter, blk_sig):\n    mem[:s_h] = xmap(add, mem[hop:], blk)\n    mem[s_h:] = blk # Remaining elements\n    if len(mem) != size:\n      raise ValueError(\"Wrong block size or declared\")\n    for el in mem[:hop]:\n      yield el\n  for el in mem[hop:]: # No more blocks, finish yielding the last one\n    yield el"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stft(func=None, **kwparams):\n  # Using as a decorator or to \"replicate\" this function with other defaults\n  if func is None:\n    cfi = chain.from_iterable\n    mix_dict = lambda *dicts: dict(cfi(iteritems(d) for d in dicts))\n    result = lambda f=None, **new_kws: stft(f, **mix_dict(kwparams, new_kws))\n    return result\n\n  # Using directly\n  @tostream\n  @wraps(func)\n  def wrapper(sig, **kwargs):\n    kws = kwparams.copy()\n    kws.update(kwargs)\n\n    if \"size\" not in kws:\n      raise TypeError(\"Missing 'size' argument\")\n    if \"hop\" in kws and kws[\"hop\"] > kws[\"size\"]:\n      raise ValueError(\"Hop value can't be higher than size\")\n\n    blk_params = {\"size\": kws.pop(\"size\")}\n    blk_params[\"hop\"] = kws.pop(\"hop\", None)\n    ola_params = blk_params.copy() # Size and hop\n\n    blk_params[\"wnd\"] = kws.pop(\"wnd\", None)\n    ola = kws.pop(\"ola\", overlap_add)\n\n    class NotSpecified(object):\n      pass\n    for name in [\"transform\", \"inverse_transform\", \"before\", \"after\"]:\n      blk_params[name] = kws.pop(name, NotSpecified)\n\n    for k, v in kws.items():\n      if k.startswith(\"ola_\"):\n        if ola is not None:\n          ola_params[k[len(\"ola_\"):]] = v\n        else:\n          raise TypeError(\"Extra '{}' argument with no overlap-add \"\n                          \"strategy\".format(k))\n      else:\n        raise TypeError(\"Unknown '{}' extra argument\".format(k))\n\n    def blk_gen(size, hop, wnd, transform, inverse_transform, before, after):\n      if transform is NotSpecified:\n        from numpy.fft import rfft as transform\n      if inverse_transform is NotSpecified:\n        from numpy.fft import irfft as inverse_transform\n      if before is NotSpecified:\n        from numpy.fft import ifftshift as before\n      if after is NotSpecified:\n        from numpy.fft import fftshift as after\n\n      # Find the right windowing function to be applied\n      if callable(wnd) and not isinstance(wnd, Stream):\n        wnd = wnd(size)\n      if isinstance(wnd, Iterable):\n        wnd = list(wnd)\n        if len(wnd) != size:\n          raise ValueError(\"Incompatible window size\")\n      elif wnd is not None:\n        raise TypeError(\"Window should be an iterable or a callable\")\n\n      # Pad size lambdas\n      trans = transform and (lambda blk: transform(blk, size))\n      itrans = inverse_transform and (lambda blk:\n                                        inverse_transform(blk, size))\n\n      # Continuation style calling\n      funcs = [f for f in [before, trans, func, itrans, after]\n                 if f is not None]\n      process = lambda blk: reduce(lambda data, f: f(data), funcs, blk)\n\n      if wnd is None:\n        for blk in Stream(sig).blocks(size=size, hop=hop):\n          yield process(blk)\n      else:\n        blk_with_wnd = wnd[:]\n        mul = operator.mul\n        for blk in Stream(sig).blocks(size=size, hop=hop):\n          blk_with_wnd[:] = xmap(mul, blk, wnd)\n          yield process(blk_with_wnd)\n\n    if ola is None:\n      return blk_gen(**blk_params)\n    else:\n      return ola(blk_gen(**blk_params), **ola_params)\n\n  return wrapper", "response": "This is a simple short - time Fourier transform block processor. It is used to create a short - time Fourier transform block processor for the signal and a phase - vocoder for the signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stft(func=None, **kwparams):\n  from numpy.fft import fft, ifft\n  return stft.base(transform=fft, inverse_transform=ifft)(func, **kwparams)", "response": "Return a new STFT object with the same parameters as the original function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stft(func=None, **kwparams):\n  from numpy.fft import fft, ifft\n  ifft_r = lambda *args: ifft(*args).real\n  return stft.base(transform=fft, inverse_transform=ifft_r)(func, **kwparams)", "response": "Short Time Fourier Transform for real data keeping the full FFT block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchunking generator based on the struct module (Python standard library). Low-level data blockenizer for homogeneous data as a generator, to help writing an iterable into a file. The dfmt should be one char, chosen from the ones in link: `<http://docs.python.org/library/struct.html#format-characters>`_ Useful examples (integer are signed, use upper case for unsigned ones): - \"b\" for 8 bits (1 byte) integer - \"h\" for 16 bits (2 bytes) integer - \"i\" for 32 bits (4 bytes) integer - \"f\" for 32 bits (4 bytes) float (default) - \"d\" for 64 bits (8 bytes) float (double) Byte order follows native system defaults. Other options are in the site: `<http://docs.python.org/library/struct.html#struct-alignment>`_ They are: - \"<\" means little-endian - \">\" means big-endian Note ---- Default chunk size can be accessed (and changed) via chunks.size.", "response": "def chunks(seq, size=None, dfmt=\"f\", byte_order=None, padval=0.):\n  \"\"\"\n  Chunk generator based on the struct module (Python standard library).\n\n  Low-level data blockenizer for homogeneous data as a generator, to help\n  writing an iterable into a file.\n  The dfmt should be one char, chosen from the ones in link:\n\n    `<http://docs.python.org/library/struct.html#format-characters>`_\n\n  Useful examples (integer are signed, use upper case for unsigned ones):\n\n  - \"b\" for 8 bits (1 byte) integer\n  - \"h\" for 16 bits (2 bytes) integer\n  - \"i\" for 32 bits (4 bytes) integer\n  - \"f\" for 32 bits (4 bytes) float (default)\n  - \"d\" for 64 bits (8 bytes) float (double)\n\n  Byte order follows native system defaults. Other options are in the site:\n\n    `<http://docs.python.org/library/struct.html#struct-alignment>`_\n\n  They are:\n\n  - \"<\" means little-endian\n  - \">\" means big-endian\n\n  Note\n  ----\n  Default chunk size can be accessed (and changed) via chunks.size.\n\n  \"\"\"\n  if size is None:\n    size = chunks.size\n  dfmt = str(size) + dfmt\n  if byte_order is None:\n    struct_string = dfmt\n  else:\n    struct_string = byte_order + dfmt\n  s = struct.Struct(struct_string)\n  for block in blocks(seq, size, padval=padval):\n    yield s.pack(*block)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nchunk generator based on the array module (Python standard library). See chunk.struct for more help. This strategy uses array.array (random access by indexing management) instead of struct.Struct and blocks/deque (circular queue appending) from the chunks.struct strategy. Hint ---- Try each one to find the faster one for your machine, and chooses the default one by assigning ``chunks.default = chunks.strategy_name``. It'll be the one used by the AudioIO/AudioThread playing mechanism. Note ---- The ``dfmt`` symbols for arrays might differ from structs' defaults.", "response": "def chunks(seq, size=None, dfmt=\"f\", byte_order=None, padval=0.):\n  \"\"\"\n  Chunk generator based on the array module (Python standard library).\n\n  See chunk.struct for more help. This strategy uses array.array (random access\n  by indexing management) instead of struct.Struct and blocks/deque (circular\n  queue appending) from the chunks.struct strategy.\n\n  Hint\n  ----\n  Try each one to find the faster one for your machine, and chooses\n  the default one by assigning ``chunks.default = chunks.strategy_name``.\n  It'll be the one used by the AudioIO/AudioThread playing mechanism.\n\n  Note\n  ----\n  The ``dfmt`` symbols for arrays might differ from structs' defaults.\n\n  \"\"\"\n  if size is None:\n    size = chunks.size\n  chunk = array.array(dfmt, xrange(size))\n  idx = 0\n\n  for el in seq:\n    chunk[idx] = el\n    idx += 1\n    if idx == size:\n      yield chunk.tostring()\n      idx = 0\n\n  if idx != 0:\n    for idx in xrange(idx, size):\n      chunk[idx] = padval\n    yield chunk.tostring()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close(self):\n    with self.halting: # Avoid simultaneous \"close\" threads\n\n      if not self.finished:  # Ignore all \"close\" calls, but the first,\n        self.finished = True # and any call to play would raise ThreadError\n\n        # Closes all playing AudioThread instances\n        while True:\n          with self.lock: # Ensure there's no other thread messing around\n            try:\n              thread = self._threads[0] # Needless to say: pop = deadlock\n            except IndexError: # Empty list\n              break # No more threads\n\n          if not self.wait:\n            thread.stop()\n          thread.join()\n\n        # Closes all recording RecStream instances\n        while self._recordings:\n          recst = self._recordings[-1]\n          recst.stop()\n          recst.take(inf) # Ensure it'll be closed\n\n        # Finishes\n        assert not self._pa._streams # No stream should survive\n        self._pa.terminate()", "response": "Closes the audio interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play(self, audio, **kwargs):\n    with self.lock:\n      if self.finished:\n        raise threading.ThreadError(\"Trying to play an audio stream while \"\n                                    \"halting the AudioIO manager object\")\n      new_thread = AudioThread(self, audio, **kwargs)\n      self._threads.append(new_thread)\n      new_thread.start()\n      return new_thread", "response": "Start a new thread playing the given audio stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrecording audio from device into a Stream.", "response": "def record(self, chunk_size = None,\n                   dfmt = \"f\",\n                   channels = 1,\n                   rate = DEFAULT_SAMPLE_RATE,\n                   **kwargs\n            ):\n    \"\"\"\n    Records audio from device into a Stream.\n\n    Parameters\n    ----------\n    chunk_size :\n      Number of samples per chunk (block sent to device).\n    dfmt :\n      Format, as in chunks(). Default is \"f\" (Float32).\n    channels :\n      Channels in audio stream (serialized).\n    rate :\n      Sample rate (same input used in sHz).\n\n    Returns\n    -------\n    Endless Stream instance that gather data from the audio input device.\n    \"\"\"\n    if chunk_size is None:\n      chunk_size = chunks.size\n\n    if hasattr(self, \"api\"):\n      kwargs.setdefault(\"input_device_index\", self.api[\"defaultInputDevice\"])\n\n    channels = kwargs.pop(\"nchannels\", channels) # Backwards compatibility\n\n    input_stream = RecStream(self,\n                             self._pa.open(format=_STRUCT2PYAUDIO[dfmt],\n                                           channels=channels,\n                                           rate=rate,\n                                           frames_per_buffer=chunk_size,\n                                           input=True,\n                                           **kwargs),\n                             chunk_size,\n                             dfmt\n                            )\n    self._recordings.append(input_stream)\n    return input_stream"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n    # From now on, it's multi-thread. Let the force be with them.\n    st = self.stream._stream\n\n    for chunk in chunks(self.audio,\n                        size=self.chunk_size*self.nchannels,\n                        dfmt=self.dfmt):\n      #Below is a faster way to call:\n      #  self.stream.write(chunk, self.chunk_size)\n      self.write_stream(st, chunk, self.chunk_size, False)\n      if not self.go.is_set():\n        self.stream.stop_stream()\n        if self.halting:\n          break\n        self.go.wait()\n        self.stream.start_stream()\n\n    # Finished playing! Destructor-like step: let's close the thread\n    with self.lock:\n      if self in self.device_manager._threads: # If not already closed\n        self.stream.close()\n        self.device_manager.thread_finished(self)", "response": "Plays the audio and writes it to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self):\n    with self.lock:\n      self.halting = True\n      self.go.clear()", "response": "Stops the playing thread and closes the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a note string name returns its MIDI pitch number.", "response": "def str2midi(note_string):\n  \"\"\"\n  Given a note string name (e.g. \"Bb4\"), returns its MIDI pitch number.\n  \"\"\"\n  if note_string == \"?\":\n    return nan\n  data = note_string.strip().lower()\n  name2delta = {\"c\": -9, \"d\": -7, \"e\": -5, \"f\": -4, \"g\": -2, \"a\": 0, \"b\": 2}\n  accident2delta = {\"b\": -1, \"#\": 1, \"x\": 2}\n  accidents = list(it.takewhile(lambda el: el in accident2delta, data[1:]))\n  octave_delta = int(data[len(accidents) + 1:]) - 4\n  return (MIDI_A4 +\n          name2delta[data[0]] + # Name\n          sum(accident2delta[ac] for ac in accidents) + # Accident\n          12 * octave_delta # Octave\n         )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the MIDI pitch number given a frequency in Hz.", "response": "def freq2midi(freq):\n  \"\"\"\n  Given a frequency in Hz, returns its MIDI pitch number.\n  \"\"\"\n  result = 12 * (log2(freq) - log2(FREQ_A4)) + MIDI_A4\n  return nan if isinstance(result, complex) else result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef midi2str(midi_number, sharp=True):\n  if isinf(midi_number) or isnan(midi_number):\n    return \"?\"\n  num = midi_number - (MIDI_A4 - 4 * 12 - 9)\n  note = (num + .5) % 12 - .5\n  rnote = int(round(note))\n  error = note - rnote\n  octave = str(int(round((num - note) / 12.)))\n  if sharp:\n    names = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n  else:\n    names = [\"C\", \"Db\", \"D\", \"Eb\", \"E\", \"F\", \"Gb\", \"G\", \"Ab\", \"A\", \"Bb\", \"B\"]\n  names = names[rnote] + octave\n  if abs(error) < 1e-4:\n    return names\n  else:\n    err_sig = \"+\" if error > 0 else \"-\"\n    err_str = err_sig + str(round(100 * abs(error), 2)) + \"%\"\n    return names + err_str", "response": "Given a MIDI pitch number returns its note string name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of octaves related to the given frequency.", "response": "def octaves(freq, fmin=20., fmax=2e4):\n  \"\"\"\n  Given a frequency and a frequency range, returns all frequencies in that\n  range that is an integer number of octaves related to the given frequency.\n\n  Parameters\n  ----------\n  freq :\n    Frequency, in any (linear) unit.\n  fmin, fmax :\n    Frequency range, in the same unit of ``freq``. Defaults to 20.0 and\n    20,000.0, respectively.\n\n  Returns\n  -------\n  A list of frequencies, in the same unit of ``freq`` and in ascending order.\n\n  Examples\n  --------\n  >>> from audiolazy import octaves, sHz\n  >>> octaves(440.)\n  [27.5, 55.0, 110.0, 220.0, 440.0, 880.0, 1760.0, 3520.0, 7040.0, 14080.0]\n  >>> octaves(440., fmin=3000)\n  [3520.0, 7040.0, 14080.0]\n  >>> Hz = sHz(44100)[1] # Conversion unit from sample rate\n  >>> freqs = octaves(440 * Hz, fmin=300 * Hz, fmax = 1000 * Hz) # rad/sample\n  >>> len(freqs) # Number of octaves\n  2\n  >>> [round(f, 6) for f in freqs] # Values in rad/sample\n  [0.062689, 0.125379]\n  >>> [round(f / Hz, 6) for f in freqs] # Values in Hz\n  [440.0, 880.0]\n\n  \"\"\"\n  # Input validation\n  if any(f <= 0 for f in (freq, fmin, fmax)):\n    raise ValueError(\"Frequencies have to be positive\")\n\n  # If freq is out of range, avoid range extension\n  while freq < fmin:\n    freq *= 2\n  while freq > fmax:\n    freq /= 2\n  if freq < fmin: # Gone back and forth\n    return []\n\n  # Finds the range for a valid input\n  return list(it.takewhile(lambda x: x > fmin,\n                           (freq * 2 ** harm for harm in it.count(0, -1))\n                          ))[::-1] \\\n       + list(it.takewhile(lambda x: x < fmax,\n                           (freq * 2 ** harm for harm in it.count(1))\n                          ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pseudo_import(fname):\n  is_d_import = lambda n: isinstance(n, ast.Name) and n.id == \"__import__\"\n  is_assign = lambda n: isinstance(n, ast.Assign)\n  is_valid = lambda n: is_assign(n) and not any(map(is_d_import, ast.walk(n)))\n  with open(fname, \"r\") as f:\n    astree = ast.parse(f.read(), filename=fname)\n  astree.body = [node for node in astree.body if is_valid(node)]\n  return locals_from_exec(compile(astree, fname, mode=\"exec\"))", "response": "Return a dict from assignments in the file without __import__."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_rst_and_process(fname, line_process=lambda line: line):\n  with open(fname, \"r\") as f:\n    data = f.read().splitlines()\n  first_idx = next(idx for idx, line in enumerate(data) if line.strip())\n  if data[first_idx].strip() == \"..\":\n    next_idx = first_idx + 1\n    first_idx = next(idx for idx, line in enumerate(data[next_idx:], next_idx)\n                         if line.strip() and not line.startswith(\" \"))\n  return \"\\n\".join(map(line_process, data[first_idx:]))", "response": "Read a reStructuredText file and process each line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delay(sig):\n  smix = Streamix()\n  sig = thub(sig, 3) # Auto-copy 3 times (remove this line if using feedback)\n  smix.add(0, sig)\n  # To get a feedback delay, use \"smix.copy()\" below instead of both \"sig\"\n  smix.add(280 * ms, .1 * sig) # You can also try other constants\n  smix.add(220 * ms, .1 * sig)\n  return smix", "response": "Simple feedforward delay effect"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef note2snd(pitch, quarters):\n  dur = quarters * quarter_dur\n  if pitch is None:\n    return zeros(dur)\n  freq = str2freq(pitch) * Hz\n  return synth(freq, dur)", "response": "Returns an audio Stream object for a single note."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_full_name(prefix, suffix=\"rst\"):\n  return os.path.join(os.path.split(__file__)[0],\n                      os.path.extsep.join([prefix, suffix]))", "response": "Returns the full path to a file name relative to the script location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a RST file with the given prefix into the script file location.", "response": "def save_to_rst(prefix, data):\n  \"\"\"\n  Saves a RST file with the given prefix into the script file location.\n\n  \"\"\"\n  with open(find_full_name(prefix), \"w\") as rst_file:\n    rst_file.write(full_gpl_for_rst)\n    rst_file.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_random_choral(log=True):\n  choral_file = corpus.getBachChorales()[random.randint(0, 399)]\n  choral = corpus.parse(choral_file)\n  if log:\n    print(\"Chosen choral:\", choral.metadata.title)\n  return choral", "response": "Gets a random choral from the J. S. Bach chorals corpus."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert Music21 data into a Stream object.", "response": "def m21_to_stream(score, synth=ks_synth, beat=90, fdur=2., pad_dur=.5,\n                  rate=lz.DEFAULT_SAMPLE_RATE):\n  \"\"\"\n  Converts Music21 data to a Stream object.\n\n  Parameters\n  ----------\n  score :\n    A Music21 data, usually a music21.stream.Score instance.\n  synth :\n    A function that receives a frequency as input and should yield a Stream\n    instance with the note being played.\n  beat :\n    The BPM (beats per minute) value to be used in playing.\n  fdur :\n    Relative duration of a fermata. For example, 1.0 ignores the fermata, and\n    2.0 (default) doubles its duration.\n  pad_dur :\n    Duration in seconds, but not multiplied by ``s``, to be used as a\n    zero-padding ending event (avoids clicks at the end when playing).\n  rate :\n    The sample rate, given in samples per second.\n\n  \"\"\"\n  # Configuration\n  s, Hz = lz.sHz(rate)\n  step = 60. / beat * s\n\n  # Creates a score from the music21 data\n  score = reduce(operator.concat,\n                 [[(pitch.frequency * Hz, # Note\n                    note.offset * step, # Starting time\n                    note.quarterLength * step, # Duration\n                    Fermata in note.expressions) for pitch in note.pitches]\n                                                 for note in score.flat.notes]\n                )\n\n  # Mix all notes into song\n  song = lz.Streamix()\n  last_start = 0\n  for freq, start, dur, has_fermata in score:\n    delta = start - last_start\n    if has_fermata:\n      delta *= 2\n    song.add(delta, synth(freq).limit(dur))\n    last_start = start\n\n  # Zero-padding and finishing\n  song.add(dur + pad_dur * s, lz.Stream([]))\n  return song"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndesigns a simple lowpass filter with a single - polar filter.", "response": "def design_z_filter_single_pole(filt_str, max_gain_freq):\n  \"\"\"\n  Finds the coefficients for a simple lowpass/highpass filter.\n\n  This function just prints the coefficient values, besides the given\n  filter equation and its power gain. There's 3 constraints used to find the\n  coefficients:\n\n  1. The G value is defined by the max gain of 1 (0 dB) imposed at a\n     specific frequency\n  2. The R value is defined by the 50% power cutoff frequency given in\n     rad/sample.\n  3. Filter should be stable (-1 < R < 1)\n\n  Parameters\n  ----------\n  filt_str :\n    Filter equation as a string using the G, R, w and z values.\n  max_gain_freq :\n    A value of zero (DC) or pi (Nyquist) to ensure the max gain as 1 (0 dB).\n\n  Note\n  ----\n  The R value is evaluated only at pi/4 rad/sample to find whether -1 < R < 1,\n  and the max gain is assumed to be either 0 or pi, using other values might\n  fail.\n  \"\"\"\n  print(\"H(z) = \" + filt_str) # Avoids printing as \"1/z\"\n  filt = sympify(filt_str, dict(G=G, R=R, w=w, z=z))\n  print()\n\n  # Finds the power magnitude equation for the filter\n  freq_resp = filt.subs(z, exp(I * w))\n  frr, fri = freq_resp.as_real_imag()\n  power_resp = fcompose(expand_complex, cancel, trigsimp)(frr ** 2 + fri ** 2)\n  pprint(Eq(Symbol(\"Power\"), power_resp))\n  print()\n\n  # Finds the G value given the max gain value of 1 at the DC or Nyquist\n  # frequency. As exp(I*pi) is -1 and exp(I*0) is 1, we can use freq_resp\n  # (without \"abs\") instead of power_resp.\n  Gsolutions = factor(solve(Eq(freq_resp.subs(w, max_gain_freq), 1), G))\n  assert len(Gsolutions) == 1\n  pprint(Eq(G, Gsolutions[0]))\n  print()\n\n  # Finds the unconstrained R values for a given cutoff frequency\n  power_resp_no_G = power_resp.subs(G, Gsolutions[0])\n  half_power_eq = Eq(power_resp_no_G, S.Half)\n  Rsolutions = solve(half_power_eq, R)\n\n  # Constraining -1 < R < 1 when w = pi/4 (although the constraint is general)\n  Rsolutions_stable = [el for el in Rsolutions if -1 < el.subs(w, pi/4) < 1]\n  assert len(Rsolutions_stable) == 1\n\n  # Constraining w to the [0;pi] range, so |sin(w)| = sin(w)\n  Rsolution = Rsolutions_stable[0].subs(abs(sin(w)), sin(w))\n  pprint(Eq(R, Rsolution))\n\n  # More information about the pole (or -pole)\n  print(\"\\n  ** Alternative way to write R **\\n\")\n  if has_sqrt(Rsolution):\n    x = Symbol(\"x\") # A helper symbol\n    xval = sum(el for el in Rsolution.args if not has_sqrt(el))\n    pprint(Eq(x, xval))\n    print()\n    pprint(Eq(R, expand(Rsolution.subs(xval, x))))\n  else:\n    # That's also what would be found in a bilinear transform with prewarping\n    pprint(Eq(R, Rsolution.rewrite(tan).cancel())) # Not so nice numerically\n\n    # See whether the R denominator can be zeroed\n    for root in solve(fraction(Rsolution)[1], w):\n      if 0 <= root <= pi:\n        power_resp_r = fcompose(expand, cancel)(power_resp_no_G.subs(w, root))\n        Rsolutions_r = solve(Eq(power_resp_r, S.Half), R)\n        assert len(Rsolutions_r) == 1\n        print(\"\\nDenominator is zero for this value of \" + pretty(w))\n        pprint(Eq(w, root))\n        pprint(Eq(R, Rsolutions_r[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multiplication_formatter(power, value, symbol):\n  if isinstance(value, float):\n    if value.is_integer():\n      value = rint(value) # Hides \".0\" when possible\n    else:\n      value = \"{:g}\".format(value)\n  if power != 0:\n    suffix = \"\" if power == 1 else \"^{p}\".format(p=power)\n    if value == 1:\n      return \"{0}{1}\".format(symbol, suffix)\n    if value == -1:\n      return \"-{0}{1}\".format(symbol, suffix)\n    return \"{v} * {0}{1}\".format(symbol, suffix, v=value)\n  else:\n    return str(value)", "response": "Formats a value for a single element of the\n."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pair_strings_sum_formatter(a, b):\n  if b[:1] == \"-\":\n    return \"{0} - {1}\".format(a, b[1:])\n  return \"{0} + {1}\".format(a, b)", "response": "Formats the sum of two strings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef float_str(value, order=\"pprpr\", size=[4, 5, 3, 6, 4],\n              after=False, max_denominator=1000000):\n  \"\"\"\n  Pretty string from int/float.\n\n  \"Almost\" automatic string formatter for integer fractions, fractions of\n  :math:`\\pi` and float numbers with small number of digits.\n\n  Outputs a representation among ``float_str.pi``, ``float_str.frac`` (without\n  a symbol) strategies, as well as the usual float representation. The\n  formatter is chosen by counting the resulting length, trying each one in the\n  given ``order`` until one gets at most the given ``size`` limit parameter as\n  its length.\n\n  Parameters\n  ----------\n  value :\n    A float number or an iterable with floats.\n  order :\n    A string that gives the order to try formatting. Each char should be:\n\n    - ``\"p\"`` for pi formatter (``float_str.pi``);\n    - ``\"r\"`` for ratio without symbol (``float_str.frac``);\n    - ``\"f\"`` for the float usual base 10 decimal representation.\n\n    Defaults to ``\"pprpr\"``. If no trial has the desired size, returns the\n    float representation.\n  size :\n    The max size allowed for each formatting in the ``order``, respectively.\n    Defaults to ``[4, 5, 3, 6, 4]``.\n  after :\n    Chooses the place where the :math:`\\pi` symbol should appear, when such\n    formatter apply. If ``True``, that's the end of the string. If ``False``,\n    that's in between the numerator and the denominator, before the slash.\n    Defaults to ``False``.\n  max_denominator :\n    The data in ``value`` is rounded following the limit given by this\n    parameter when trying to represent it as a fraction/ratio.\n    Defaults to the integer 1,000,000 (one million).\n\n  Returns\n  -------\n  A string with the number written into.\n\n  Note\n  ----\n  You probably want to keep ``max_denominator`` high to avoid rounding.\n\n  \"\"\"\n  if len(order) != len(size):\n    raise ValueError(\"Arguments 'order' and 'size' should have the same size\")\n\n  str_data = {\n    \"p\": float_str.pi(value, after=after, max_denominator=max_denominator),\n    \"r\": float_str.frac(value, max_denominator=max_denominator),\n    \"f\": elementwise(\"v\", 0)(lambda v: \"{0:g}\".format(v))(value)\n  }\n\n  sizes = {k: len(v) for k, v in iteritems(str_data)}\n  sizes[\"p\"] = max(1, sizes[\"p\"] - len(float_str.pi_symbol) + 1)\n\n  for char, max_size in xzip(order, size):\n    if sizes[char] <= max_size:\n      return str_data[char]\n  return str_data[\"f\"]", "response": "Pretty string from int and float."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstringing formatter for fractions of :math:`\\pi`. Alike the rational_formatter, but fixed to the symbol string ``float_str.pi_symbol`` and value ``float_str.pi_value`` (both can be changed, if needed), mainly intended for direct use with MatPlotLib labels. Examples -------- >>> float_str.pi_symbol = \"pi\" # Just for printing sake >>> float_str.pi(pi / 2) 'pi/2' >>> float_str.pi(pi * .333333333333333) 'pi/3' >>> float_str.pi(pi * .222222222222222) '2pi/9' >>> float_str.pi_symbol = \" PI\" # With the space >>> float_str.pi(pi / 2, after=True) '1/2 PI' >>> float_str.pi(pi * .333333333333333, after=True) '1/3 PI' >>> float_str.pi(pi * .222222222222222, after=True) '2/9 PI' See Also -------- float_str.frac : Float to string conversion, perhaps with a symbol as a multiplier.", "response": "def float_str(value, after=False, max_denominator=1000000):\n  \"\"\"\n  String formatter for fractions of :math:`\\pi`.\n\n  Alike the rational_formatter, but fixed to the symbol string\n  ``float_str.pi_symbol`` and value ``float_str.pi_value`` (both can be\n  changed, if needed), mainly intended for direct use with MatPlotLib labels.\n\n  Examples\n  --------\n  >>> float_str.pi_symbol = \"pi\" # Just for printing sake\n  >>> float_str.pi(pi / 2)\n  'pi/2'\n  >>> float_str.pi(pi * .333333333333333)\n  'pi/3'\n  >>> float_str.pi(pi * .222222222222222)\n  '2pi/9'\n  >>> float_str.pi_symbol = \" PI\" # With the space\n  >>> float_str.pi(pi / 2, after=True)\n  '1/2 PI'\n  >>> float_str.pi(pi * .333333333333333, after=True)\n  '1/3 PI'\n  >>> float_str.pi(pi * .222222222222222, after=True)\n  '2/9 PI'\n\n  See Also\n  --------\n  float_str.frac :\n    Float to string conversion, perhaps with a symbol as a multiplier.\n\n  \"\"\"\n  return float_str.frac(value, symbol_str=float_str.pi_symbol,\n                        symbol_value=float_str.pi_value, after=after,\n                        max_denominator=max_denominator)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a reStructuredText simple table from a list of strings.", "response": "def rst_table(data, schema=None):\n  \"\"\"\n  Creates a reStructuredText simple table (list of strings) from a list of\n  lists.\n  \"\"\"\n  # Process multi-rows (replaced by rows with empty columns when needed)\n  pdata = []\n  for row in data:\n    prow = [el if isinstance(el, list) else [el] for el in row]\n    pdata.extend(pr for pr in xzip_longest(*prow, fillvalue=\"\"))\n\n  # Find the columns sizes\n  sizes = [max(len(\"{0}\".format(el)) for el in column)\n           for column in xzip(*pdata)]\n  sizes = [max(size, len(sch)) for size, sch in xzip(sizes, schema)]\n\n  # Creates the title and border rows\n  if schema is None:\n    schema = pdata[0]\n    pdata = pdata[1:]\n  border = \" \".join(\"=\" * size for size in sizes)\n  titles = \" \".join(\"{1:^{0}}\".format(*pair)\n                    for pair in xzip(sizes, schema))\n\n  # Creates the full table and returns\n  rows = [border, titles, border]\n  rows.extend(\" \".join(\"{1:<{0}}\".format(*pair)\n                       for pair in xzip(sizes, row))\n              for row in pdata)\n  rows.append(border)\n  return rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef small_doc(obj, indent=\"\", max_width=80):\n  if not getattr(obj, \"__doc__\", False):\n    data = [el.strip() for el in str(obj).splitlines()]\n    if len(data) == 1:\n      if data[0].startswith(\"<audiolazy.lazy_\"): # Instance\n        data = data[0].split(\"0x\", -1)[0] + \"0x...>\" # Hide its address\n      else:\n        data = \"\".join([\"``\", data[0], \"``\"])\n    else:\n      data = \" \".join(data)\n\n  # No docstring\n  elif (not obj.__doc__) or (obj.__doc__.strip() == \"\"):\n    data = \"\\ * * * * ...no docstring... * * * * \\ \"\n\n  # Docstring\n  else:\n    data = (el.strip() for el in obj.__doc__.strip().splitlines())\n    data = \" \".join(it.takewhile(lambda el: el != \"\", data))\n\n  # Ensure max_width (word wrap)\n  max_width -= len(indent)\n  result = []\n  for word in data.split():\n    if len(word) <= max_width:\n      if result:\n        if len(result[-1]) + len(word) + 1 <= max_width:\n          word = \" \".join([result.pop(), word])\n        result.append(word)\n      else:\n        result = [word]\n    else: # Splits big words\n      result.extend(\"\".join(w) for w in blocks(word, max_width, padval=\"\"))\n\n  # Apply indentation and finishes\n  return [indent + el for el in result]", "response": "Find a useful small doc representation of an object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef meta(*bases, **kwargs):\n  metaclass = kwargs.get(\"metaclass\", type)\n  if not bases:\n    bases = (object,)\n  class NewMeta(type):\n    def __new__(mcls, name, mbases, namespace):\n      if name:\n        return metaclass.__new__(metaclass, name, bases, namespace)\n      return super(NewMeta, mcls).__new__(mcls, \"\", mbases, {})\n  return NewMeta(\"\", tuple(), {})", "response": "A metaclass for a given set of bases."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modulo_counter(start=0., modulo=256., step=1.):\n  if isinstance(start, collections.Iterable):\n    lastp = 0.\n    c = 0.\n    if isinstance(step, collections.Iterable):\n      if isinstance(modulo, collections.Iterable):\n        for p, m, s in xzip(start, modulo, step):\n          c += p - lastp\n          c = c % m % m\n          yield c\n          c += s\n          lastp = p\n      else:\n        for p, s in xzip(start, step):\n          c += p - lastp\n          c = c % modulo % modulo\n          yield c\n          c += s\n          lastp = p\n    else:\n      if isinstance(modulo, collections.Iterable):\n        for p, m in xzip(start, modulo):\n          c += p - lastp\n          c = c % m % m\n          yield c\n          c += step\n          lastp = p\n      else: # Only start is iterable. This should be optimized!\n        if step == 0:\n          for p in start:\n            yield p % modulo % modulo\n        else:\n          steps = int(modulo / step)\n          if steps > 1:\n            n = 0\n            for p in start:\n              c += p - lastp\n              yield (c + n * step) % modulo % modulo\n              lastp = p\n              n += 1\n              if n == steps:\n                n = 0\n                c = (c + steps * step) % modulo % modulo\n          else:\n            for p in start:\n              c += p - lastp\n              c = c % modulo % modulo\n              yield c\n              c += step\n              lastp = p\n  else:\n    c = start\n    if isinstance(step, collections.Iterable):\n      if isinstance(modulo, collections.Iterable):\n        for m, s in xzip(modulo, step):\n          c = c % m % m\n          yield c\n          c += s\n      else: # Only step is iterable. This should be optimized!\n        for s in step:\n          c = c % modulo % modulo\n          yield c\n          c += s\n    else:\n      if isinstance(modulo, collections.Iterable):\n        for m in modulo:\n          c = c % m % m\n          yield c\n          c += step\n      else: # None is iterable\n        if step == 0:\n          c = start % modulo % modulo\n          while True:\n            yield c\n        else:\n          steps = int(modulo / step)\n          if steps > 1:\n            n = 0\n            while True:\n              yield (c + n * step) % modulo % modulo\n              n += 1\n              if n == steps:\n                n = 0\n                c = (c + steps * step) % modulo % modulo\n          else:\n            while True:\n              c = c % modulo % modulo\n              yield c\n              c += step", "response": "Yields the lazy endless counter stream with the given modulo."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an ones stream generator.", "response": "def ones(dur=None):\n  \"\"\"\n  Ones stream generator.\n  You may multiply your endless stream by this to enforce an end to it.\n\n  Parameters\n  ----------\n  dur :\n    Duration, in number of samples; endless if not given.\n\n  Returns\n  -------\n  Stream that repeats \"1.0\" during a given time duration (if any) or\n  endlessly.\n\n  \"\"\"\n  if dur is None or (isinf(dur) and dur > 0):\n    while True:\n      yield 1.0\n  for x in xrange(int(.5 + dur)):\n    yield 1.0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zeros(dur=None):\n  if dur is None or (isinf(dur) and dur > 0):\n    while True:\n      yield 0.0\n  for x in xrange(int(.5 + dur)):\n    yield 0.0", "response": "Returns a generator that yields zeroes for all the samples in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwhiting noise stream generator. Parameters ---------- dur : Duration, in number of samples; endless if not given (or None). low, high : Lower and higher limits. Defaults to the [-1; 1] range. Returns ------- Stream yielding random numbers between -1 and 1.", "response": "def white_noise(dur=None, low=-1., high=1.):\n  \"\"\"\n  White noise stream generator.\n\n  Parameters\n  ----------\n  dur :\n    Duration, in number of samples; endless if not given (or None).\n  low, high :\n    Lower and higher limits. Defaults to the [-1; 1] range.\n\n  Returns\n  -------\n  Stream yielding random numbers between -1 and 1.\n\n  \"\"\"\n  if dur is None or (isinf(dur) and dur > 0):\n    while True:\n      yield random.uniform(low, high)\n  for x in xrange(rint(dur)):\n    yield random.uniform(low, high)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gauss_noise(dur=None, mu=0., sigma=1.):\n  if dur is None or (isinf(dur) and dur > 0):\n    while True:\n      yield random.gauss(mu, sigma)\n  for x in xrange(rint(dur)):\n    yield random.gauss(mu, sigma)", "response": "Generates Gaussian - distributed random numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an impulse stream generator.", "response": "def impulse(dur=None, one=1., zero=0.):\n  \"\"\"\n  Impulse stream generator.\n\n  Parameters\n  ----------\n  dur :\n    Duration, in number of samples; endless if not given.\n\n  Returns\n  -------\n  Stream that repeats \"0.0\" during a given time duration (if any) or\n  endlessly, but starts with one (and only one) \"1.0\".\n\n  \"\"\"\n  if dur is None or (isinf(dur) and dur > 0):\n    yield one\n    while True:\n      yield zero\n  elif dur >= .5:\n    num_samples = int(dur - .5)\n    yield one\n    for x in xrange(num_samples):\n      yield zero"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef karplus_strong(freq, tau=2e4, memory=white_noise):\n  return comb.tau(2 * pi / freq, tau).linearize()(zeros(), memory=memory)", "response": "Karplus - Strong digitar synthesis algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new table lookup instance by using a harmonics dictionary with a partial key.", "response": "def harmonize(self, harmonics_dict):\n    \"\"\"\n    Returns a \"harmonized\" table lookup instance by using a \"harmonics\"\n    dictionary with {partial: amplitude} terms, where all \"partial\" keys have\n    to be integers.\n    \"\"\"\n    data = sum(cycle(self.table[::partial+1]) * amplitude\n               for partial, amplitude in iteritems(harmonics_dict))\n    return TableLookup(data.take(len(self)), cycles=self.cycles)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize the current table to be a single value.", "response": "def normalize(self):\n    \"\"\"\n    Returns a new table with values ranging from -1 to 1, reaching at least\n    one of these, unless there's no data.\n    \"\"\"\n    max_abs = max(self.table, key=abs)\n    if max_abs == 0:\n      raise ValueError(\"Can't normalize zeros\")\n    return self / max_abs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strategy(self, *names, **kwargs):\n    def decorator(func):\n      keep_name = kwargs.pop(\"keep_name\", False)\n      if kwargs:\n        key = next(iter(kwargs))\n        raise TypeError(\"Unknown keyword argument '{}'\".format(key))\n      if not keep_name:\n        func.__name__ = str(names[0])\n      self[names] = func\n      return self\n    return decorator", "response": "This method creates a new strategy dictionary that can be used to add two or more key items to a new order - ordered list of key items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_sphinx(out_type, build_dir = \"build\"):\n  sphinx_string = sphinx_template.format(build_dir=build_dir,\n                                         out_type=out_type)\n  if sphinx.main(shlex.split(sphinx_string)) != 0:\n    raise RuntimeError(\"Something went wrong while building '{0}'\"\n                       .format(out_type))\n  if out_type in make_target:\n    make_string = make_template.format(build_dir=build_dir,\n                                       out_type=out_type,\n                                       make_param=make_target[out_type])\n    call(shlex.split(make_string))", "response": "Call the sphinx - build for the given output type and make when there is a make target."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef taylor(f, n=2, **kwargs):\n  return sum(Stream(f.series(n=None, **kwargs)).limit(n))", "response": "Taylor - Mclaurin polynomial aproximation for the given function f."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef toeplitz(vect):\n  return [[vect[abs(i-j)] for i in xrange(len(vect))]\n                          for j in xrange(len(vect))]", "response": "Find the toeplitz matrix given its first line and column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsolve the Yule - Walker linear system of equations.", "response": "def levinson_durbin(acdata, order=None):\n  \"\"\"\n  Solve the Yule-Walker linear system of equations.\n\n  They're given by:\n\n  .. math::\n\n    R . a = r\n\n  where :math:`R` is a simmetric Toeplitz matrix where each element are lags\n  from the given autocorrelation list. :math:`R` and :math:`r` are defined\n  (Python indexing starts with zero and slices don't include the last\n  element):\n\n  .. math::\n\n    R[i][j] = acdata[abs(j - i)]\n\n    r = acdata[1 : order + 1]\n\n  Parameters\n  ----------\n  acdata :\n    Autocorrelation lag list, commonly the ``acorr`` function output.\n  order :\n    The order of the resulting ZFilter object. Defaults to\n    ``len(acdata) - 1``.\n\n  Returns\n  -------\n  A FIR filter, as a ZFilter object. The mean squared error over the given\n  data (variance of the white noise) is in its \"error\" attribute.\n\n  See Also\n  --------\n  acorr:\n    Calculate the autocorrelation of a given block.\n  lpc :\n    Calculate the Linear Predictive Coding (LPC) coefficients.\n  parcor :\n    Partial correlation coefficients (PARCOR), or reflection coefficients,\n    relative to the lattice implementation of a filter, obtained by reversing\n    the Levinson-Durbin algorithm.\n\n  Examples\n  --------\n  >>> data = [2, 2, 0, 0, -1, -1, 0, 0, 1, 1]\n  >>> acdata = acorr(data)\n  >>> acdata\n  [12, 6, 0, -3, -6, -3, 0, 2, 4, 2]\n  >>> ldfilt = levinson_durbin(acorr(data), 3)\n  >>> ldfilt\n  1 - 0.625 * z^-1 + 0.25 * z^-2 + 0.125 * z^-3\n  >>> ldfilt.error # Squared! See lpc for more information about this\n  7.875\n\n  Notes\n  -----\n  The Levinson-Durbin algorithm used to solve the equations needs\n  :math:`O(order^2)` floating point operations.\n\n  \"\"\"\n  if order is None:\n    order = len(acdata) - 1\n  elif order >= len(acdata):\n    acdata = Stream(acdata).append(0).take(order + 1)\n\n  # Inner product for filters based on above statistics\n  def inner(a, b): # Be careful, this depends on acdata !!!\n    return sum(acdata[abs(i-j)] * ai * bj\n               for i, ai in enumerate(a.numlist)\n               for j, bj in enumerate(b.numlist)\n              )\n\n  try:\n    A = ZFilter(1)\n    for m in xrange(1, order + 1):\n      B = A(1 / z) * z ** -m\n      A -= inner(A, z ** -m) / inner(B, B) * B\n  except ZeroDivisionError:\n    raise ParCorError(\"Can't find next PARCOR coefficient\")\n\n  A.error = inner(A, A)\n  return A"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the Linear Predictive Coding (LPC) coefficients as a ZFilter object, the analysis whitening filter. This implementation uses the autocorrelation method, using the Levinson-Durbin algorithm or Numpy pseudo-inverse for linear system solving, when needed. Parameters ---------- blk : An iterable with well-defined length. Don't use this function with Stream objects! order : The order of the resulting ZFilter object. Defaults to ``len(blk) - 1``. Returns ------- A FIR filter, as a ZFilter object. The mean squared error over the given block is in its \"error\" attribute. Hint ---- See ``lpc.kautocor`` example, which should apply equally for this strategy. See Also -------- levinson_durbin : Levinson-Durbin algorithm for solving Yule-Walker equations (Toeplitz matrix linear system). lpc.nautocor: LPC coefficients from linear system solved with Numpy pseudo-inverse. lpc.kautocor: LPC coefficients obtained with Levinson-Durbin algorithm.", "response": "def lpc(blk, order=None):\n  \"\"\"\n  Find the Linear Predictive Coding (LPC) coefficients as a ZFilter object,\n  the analysis whitening filter. This implementation uses the autocorrelation\n  method, using the Levinson-Durbin algorithm or Numpy pseudo-inverse for\n  linear system solving, when needed.\n\n  Parameters\n  ----------\n  blk :\n    An iterable with well-defined length. Don't use this function with Stream\n    objects!\n  order :\n    The order of the resulting ZFilter object. Defaults to ``len(blk) - 1``.\n\n  Returns\n  -------\n  A FIR filter, as a ZFilter object. The mean squared error over the given\n  block is in its \"error\" attribute.\n\n  Hint\n  ----\n  See ``lpc.kautocor`` example, which should apply equally for this strategy.\n\n  See Also\n  --------\n  levinson_durbin :\n    Levinson-Durbin algorithm for solving Yule-Walker equations (Toeplitz\n    matrix linear system).\n  lpc.nautocor:\n    LPC coefficients from linear system solved with Numpy pseudo-inverse.\n  lpc.kautocor:\n    LPC coefficients obtained with Levinson-Durbin algorithm.\n\n  \"\"\"\n  if order < 100:\n    return lpc.nautocor(blk, order)\n  try:\n    return lpc.kautocor(blk, order)\n  except ParCorError:\n    return lpc.nautocor(blk, order)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the Linear Predictive Coding (LPC) coefficients as a ZFilter object, the analysis whitening filter. This implementation uses the autocorrelation method, using numpy.linalg.pinv as a linear system solver. Parameters ---------- blk : An iterable with well-defined length. Don't use this function with Stream objects! order : The order of the resulting ZFilter object. Defaults to ``len(blk) - 1``. Returns ------- A FIR filter, as a ZFilter object. The mean squared error over the given block is in its \"error\" attribute. Hint ---- See ``lpc.kautocor`` example, which should apply equally for this strategy. See Also -------- lpc.autocor: LPC coefficients by using one of the autocorrelation method strategies. lpc.kautocor: LPC coefficients obtained with Levinson-Durbin algorithm.", "response": "def lpc(blk, order=None):\n  \"\"\"\n  Find the Linear Predictive Coding (LPC) coefficients as a ZFilter object,\n  the analysis whitening filter. This implementation uses the autocorrelation\n  method, using numpy.linalg.pinv as a linear system solver.\n\n  Parameters\n  ----------\n  blk :\n    An iterable with well-defined length. Don't use this function with Stream\n    objects!\n  order :\n    The order of the resulting ZFilter object. Defaults to ``len(blk) - 1``.\n\n  Returns\n  -------\n  A FIR filter, as a ZFilter object. The mean squared error over the given\n  block is in its \"error\" attribute.\n\n  Hint\n  ----\n  See ``lpc.kautocor`` example, which should apply equally for this strategy.\n\n  See Also\n  --------\n  lpc.autocor:\n    LPC coefficients by using one of the autocorrelation method strategies.\n  lpc.kautocor:\n    LPC coefficients obtained with Levinson-Durbin algorithm.\n\n  \"\"\"\n  from numpy import matrix\n  from numpy.linalg import pinv\n  acdata = acorr(blk, order)\n  coeffs = pinv(toeplitz(acdata[:-1])) * -matrix(acdata[1:]).T\n  coeffs = coeffs.T.tolist()[0]\n  filt = 1  + sum(ai * z ** -i for i, ai in enumerate(coeffs, 1))\n  filt.error = acdata[0] + sum(a * c for a, c in xzip(acdata[1:], coeffs))\n  return filt"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the Linear Predictive Coding (LPC) coefficients as a ZFilter object, the analysis whitening filter. This implementation uses the covariance method, assuming a zero-mean stochastic process, using numpy.linalg.pinv as a linear system solver.", "response": "def lpc(blk, order=None):\n  \"\"\"\n  Find the Linear Predictive Coding (LPC) coefficients as a ZFilter object,\n  the analysis whitening filter. This implementation uses the covariance\n  method, assuming a zero-mean stochastic process, using numpy.linalg.pinv\n  as a linear system solver.\n\n  \"\"\"\n  from numpy import matrix\n  from numpy.linalg import pinv\n\n  lagm = lag_matrix(blk, order)\n  phi = matrix(lagm)\n  psi = phi[1:, 0]\n  coeffs = pinv(phi[1:, 1:]) * -psi\n  coeffs = coeffs.T.tolist()[0]\n  filt = 1  + sum(ai * z ** -i for i, ai in enumerate(coeffs, 1))\n  filt.error = phi[0, 0] + sum(a * c for a, c in xzip(lagm[0][1:], coeffs))\n  return filt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the Linear Predictive Coding (LPC) coefficients as a ZFilter object, the analysis whitening filter. This implementation is based on the covariance method, assuming a zero-mean stochastic process, finding the coefficients iteratively and greedily like the lattice implementation in Levinson-Durbin algorithm, although the lag matrix found from the given block don't have to be toeplitz. Slow, but this strategy don't need NumPy.", "response": "def lpc(blk, order=None):\n  \"\"\"\n  Find the Linear Predictive Coding (LPC) coefficients as a ZFilter object,\n  the analysis whitening filter. This implementation is based on the\n  covariance method, assuming a zero-mean stochastic process, finding\n  the coefficients iteratively and greedily like the lattice implementation\n  in Levinson-Durbin algorithm, although the lag matrix found from the given\n  block don't have to be toeplitz. Slow, but this strategy don't need NumPy.\n\n  \"\"\"\n  # Calculate the covariance for each lag pair\n  phi = lag_matrix(blk, order)\n  order = len(phi) - 1\n\n  # Inner product for filters based on above statistics\n  def inner(a, b):\n    return sum(phi[i][j] * ai * bj\n               for i, ai in enumerate(a.numlist)\n               for j, bj in enumerate(b.numlist)\n              )\n\n  A = ZFilter(1)\n  B = [z ** -1]\n  beta = [inner(B[0], B[0])]\n\n  m = 1\n  while True:\n    try:\n      k = -inner(A, z ** -m) / beta[m - 1] # Last one is really a PARCOR coeff\n    except ZeroDivisionError:\n      raise ZeroDivisionError(\"Can't find next coefficient\")\n    if k >= 1 or k <= -1:\n      raise ValueError(\"Unstable filter\")\n    A += k * B[m - 1]\n\n    if m >= order:\n      A.error = inner(A, A)\n      return A\n\n    gamma = [inner(z ** -(m + 1), B[q]) / beta[q] for q in xrange(m)]\n    B.append(z ** -(m + 1) - sum(gamma[q] * B[q] for q in xrange(m)))\n    beta.append(inner(B[m], B[m]))\n    m += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parcor_stable(filt):\n  try:\n    return all(abs(k) < 1 for k in parcor(ZFilter(filt.denpoly)))\n  except ParCorError:\n    return False", "response": "Tests whether the given filter is stable by using the partial\n correlation coefficients."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lsf(fir_filt):\n  den = fir_filt.denominator\n  if len(den) != 1:\n    raise ValueError(\"Filter has feedback\")\n  elif den[0] != 1: # So we don't have to worry with the denominator anymore\n    fir_filt /= den[0]\n\n  from numpy import roots\n  rev_filt = ZFilter(fir_filt.numerator[::-1]) * z ** -1\n  P = fir_filt + rev_filt\n  Q = fir_filt - rev_filt\n  roots_p = roots(P.numerator[::-1])\n  roots_q = roots(Q.numerator[::-1])\n  lsf_p = sorted(phase(roots_p))\n  lsf_q = sorted(phase(roots_q))\n  return reduce(operator.concat, xzip(*sorted([lsf_p, lsf_q])), tuple())", "response": "Find the Line Spectral Frequencies from a given LinearFilter object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lsf_stable(filt):\n  lsf_data = lsf(ZFilter(filt.denpoly))\n  return all(a < b for a, b in blocks(lsf_data, size=2, hop=1))", "response": "Tests whether the given filter is stable by using the Line Spectral Frequencies of the given filter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit underlined blocks with indentation.", "response": "def splitter(lines, sep=\"-=\", keep_idx=False):\n  \"\"\"\n  Splits underlined blocks without indentation (reStructuredText pattern).\n\n  Parameters\n  ----------\n  lines :\n    A list of strings\n  sep :\n    Underline symbols. A line with only such symbols will be seen as a\n    underlined one.\n  keep_idx :\n    If False (default), the function returns a collections.OrderedDict. Else,\n    returns a\n    list of index pairs\n\n  Returns\n  -------\n  A collections.OrderedDict instance where a block with underlined key like\n  ``\"Key\\\\n===\"`` and a list of lines following will have the item (key, list\n  of lines), in the order that they appeared in the lists input. Empty keys\n  gets an order numbering, and might happen for example after a ``\"----\"``\n  separator. The values (lists of lines) don't include the key nor its\n  underline, and is also stripped/trimmed as lines (i.e., there's no empty\n  line as the first and last list items, but first and last line may start/end\n  with whitespaces).\n\n  \"\"\"\n  separators = audiolazy.Stream(\n                 idx - 1 for idx, el in enumerate(lines)\n                         if all(char in sep for char in el)\n                         and len(el) > 0\n               ).append([len(lines)])\n  first_idx = separators.copy().take()\n  blk_data = OrderedDict()\n\n  empty_count = iter(audiolazy.count(1))\n  next_empty = lambda: \"--Empty--{0}--\".format(next(empty_count))\n\n  if first_idx != 0:\n    blk_data[next_empty()] = lines[:first_idx]\n\n  for idx1, idx2 in separators.blocks(size=2, hop=1):\n    name = lines[idx1].strip() if lines[idx1].strip() != \"\" else next_empty()\n    blk_data[name] = lines[idx1+2 : idx2]\n\n  # Strips the empty lines\n  for name in blk_data:\n    while blk_data[name][-1].strip() == \"\":\n      blk_data[name].pop()\n    while blk_data[name][0].strip() == \"\":\n      blk_data[name] = blk_data[name][1:]\n\n  return blk_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a name to get Sphinx reStructuredText internal references like an object name.", "response": "def audiolazy_namer(name):\n  \"\"\"\n  Process a name to get Sphinx reStructuredText internal references like\n  ``:obj:`name <audiolazy.lazy_something.name>``` for a given name string,\n  specific for AudioLazy.\n\n  \"\"\"\n  sp_name = name.split(\".\")\n  try:\n\n    # Find the audiolazy module name\n    data = getattr(audiolazy, sp_name[0])\n    if isinstance(data, audiolazy.StrategyDict):\n      module_name = data.default.__module__\n    else:\n      module_name = data.__module__\n      if not module_name.startswith(\"audiolazy\"): # Decorated math, cmath, ...\n        del module_name\n        for mname in audiolazy.__modules__:\n          if sp_name[0] in getattr(audiolazy, mname).__all__:\n            module_name = \"audiolazy.\" + mname\n            break\n\n    # Now gets the referenced item\n    location = \".\".join([module_name] + sp_name)\n    for sub_name in sp_name[1:]:\n      data = getattr(data, sub_name)\n\n    # Finds the role to be used for referencing\n    type_dict = OrderedDict([\n      (audiolazy.StrategyDict, \"obj\"),\n      (Exception, \"exc\"),\n      (types.MethodType, \"meth\"),\n      (types.FunctionType, \"func\"),\n      (types.ModuleType, \"mod\"),\n      (property, \"attr\"),\n      (type, \"class\"),\n    ])\n    role = [v for k, v in iteritems(type_dict) if isinstance(data, k)][0]\n\n  # Not found\n  except AttributeError:\n    return \":obj:`{0}`\".format(name)\n\n  # Found!\n  else:\n    return \":{0}:`{1} <{2}>`\".format(role, name, location)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pre_processor(app, what, name, obj, options, lines,\n                  namer=lambda name: \":obj:`{0}`\".format(name)):\n  \"\"\"\n  Callback preprocessor function for docstrings.\n  Converts data from Spyder pattern to Sphinx, using a ``namer`` function\n  that defaults to ``lambda name: \":obj:`{0}`\".format(name)`` (specific for\n  ``.. seealso::``).\n\n  \"\"\"\n  # Duplication removal\n  if what == \"module\": # For some reason, summary appears twice\n    idxs = [idx for idx, el in enumerate(lines) if el.startswith(\"Summary\")]\n    if len(idxs) >= 2:\n      del lines[idxs.pop():] # Remove the last summary\n    if len(idxs) >= 1:\n      lines.insert(idxs[-1] + 1, \"\")\n      if obj is audiolazy.lazy_math:\n        lines.insert(idxs[-1] + 1, \".. tabularcolumns:: cl\")\n      else:\n        lines.insert(idxs[-1] + 1, \".. tabularcolumns:: CJ\")\n      lines.insert(idxs[-1] + 1, \"\")\n\n  # Real docstring format pre-processing\n  result = []\n  for name, blk in iteritems(splitter(lines)):\n    nlower =  name.lower()\n\n    if nlower == \"parameters\":\n      starters = audiolazy.Stream(idx for idx, el in enumerate(blk)\n                                      if len(el) > 0\n                                      and not el.startswith(\" \")\n                                 ).append([len(blk)])\n      for idx1, idx2 in starters.blocks(size=2, hop=1):\n        param_data = \" \".join(b.strip() for b in blk[idx1:idx2])\n        param, expl = param_data.split(\":\", 1)\n        if \",\" in param:\n          param = param.strip()\n          if not param[0] in (\"(\", \"[\", \"<\", \"{\"):\n            param = \"[{0}]\".format(param)\n        while \",\" in param:\n          fparam, param = param.split(\",\", 1)\n          result.append(\":param {0}: {1}\".format(fparam.strip(), \"\\.\\.\\.\"))\n        result.append(\":param {0}: {1}\".format(param.strip(), expl.strip()))\n\n    elif nlower == \"returns\":\n      result.append(\":returns: \" + \" \".join(blk))\n\n    elif nlower in (\"note\", \"warning\", \"hint\"):\n      result.append(\".. {0}::\".format(nlower))\n      result.extend(\"  \" + el for el in blk)\n\n    elif nlower == \"examples\":\n      result.append(\"**Examples**:\")\n      result.extend(\"  \" + el for el in blk)\n\n    elif nlower == \"see also\":\n      result.append(\".. seealso::\")\n      for el in blk:\n        if el.endswith(\":\"):\n          result.append(\"\") # Skip a line\n           # Sphinx may need help here to find some object locations\n          refs = [namer(f.strip()) for f in el[:-1].split(\",\")]\n          result.append(\"  \" + \", \".join(refs))\n        else:\n          result.append(\"  \" + el)\n\n    else: # Unkown block name, perhaps the starting one (empty)\n      result.extend(blk)\n\n    # Skip a line after each block\n    result.append(\"\")\n\n  # Replace lines with the processed data while keeping the actual lines id\n  del lines[:]\n  lines.extend(result)", "response": "Callback preprocessor function for Sphinx pattern pre - processing."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether to skip the object chooser function.", "response": "def should_skip(app, what, name, obj, skip, options):\n  \"\"\"\n  Callback object chooser function for docstring documentation.\n\n  \"\"\"\n  if name in [\"__doc__\", \"__module__\", \"__dict__\", \"__weakref__\",\n               \"__abstractmethods__\"\n              ] or name.startswith(\"_abc_\"):\n    return True\n  return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(app):\n  app.connect('autodoc-process-docstring',\n              lambda *args: pre_processor(*args, namer=audiolazy_namer))\n  app.connect('autodoc-skip-member', should_skip)", "response": "Setups the autodoc - process - docstring and should_skip functions to be\n"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_name_generator_recursive(path):\n  for name in os.listdir(path):\n    full_name = os.path.join(path, name)\n    if os.path.isdir(full_name):\n      for new_name in file_name_generator_recursive(full_name):\n        yield new_name\n    else:\n      yield full_name", "response": "Generator function for filenames given a directory path name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of the newest file given an iterable of file names.", "response": "def newest_file(file_iterable):\n  \"\"\"\n  Returns the name of the newest file given an iterable of file names.\n\n  \"\"\"\n  return max(file_iterable, key=lambda fname: os.path.getmtime(fname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enbw(wnd):\n  return sum(el ** 2 for el in wnd) / sum(wnd) ** 2 * len(wnd)", "response": "Equivalent Noise Bandwidth in bins."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the overlap correlation percent for the given overlap hop in samples.", "response": "def overlap_correlation(wnd, hop):\n  \"\"\" Overlap correlation percent for the given overlap hop in samples. \"\"\"\n  return sum(wnd * Stream(wnd).skip(hop)) / sum(el ** 2 for el in wnd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_xdb_bin(wnd, power=.5, res=1500):\n  spectrum = dB20(rfft(wnd, res * len(wnd)))\n  root_at_xdb = spectrum - spectrum[0] - dB10(power)\n  return next(i for i, el in enumerate(zcross(root_at_xdb)) if el) / res", "response": "Find the x - dB cutoff frequency bin index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_peaks(blk, neighbors=2):\n  size = 1 + 2 * neighbors\n  pairs = enumerate(Stream(blk).blocks(size=size, hop=1).map(list), neighbors)\n  for idx, nbhood in pairs:\n    center = nbhood.pop(neighbors)\n    if all(center >= el for el in nbhood):\n      yield idx\n      next(pairs) # Skip ones we already know can't be peaks\n      next(pairs)", "response": "Get all peaks in a block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hsll(wnd, res=20, neighbors=2):\n  spectrum = dB20(rfft(wnd, res * len(wnd)))\n  first_peak = next(get_peaks(spectrum, neighbors=neighbors))\n  return max(spectrum[first_peak:]) - spectrum[0]", "response": "HSL - Lobe - Level estimate of a given window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsiding Lobe Fall Off (dB/oct). Finds the side lobe peak fall off numerically in dB/octave by using the ``scipy.optimize.fmin`` function. Hint ---- Originally, Harris rounded the results he found to a multiple of -6, you can use the AudioLazy ``rint`` function for that: ``rint(falloff, 6)``. Parameters ---------- res : Zero-padding factor. 1 for no zero-padding, 2 for twice the length, etc.. neighbors : Number of neighbors needed by ``get_peaks`` to define a peak. max_miss : Maximum percent of peaks that might be missed when approximating them by a line. start_delta : Minimum acceptable value for an orthogonal deviation from the approximation line to include a peak.", "response": "def slfo(wnd, res=50, neighbors=2, max_miss=.7, start_delta=1e-4):\n  \"\"\"\n  Side Lobe Fall Off (dB/oct).\n\n  Finds the side lobe peak fall off numerically in dB/octave by using the\n  ``scipy.optimize.fmin`` function.\n\n  Hint\n  ----\n  Originally, Harris rounded the results he found to a multiple of -6, you can\n  use the AudioLazy ``rint`` function for that: ``rint(falloff, 6)``.\n\n  Parameters\n  ----------\n  res :\n    Zero-padding factor. 1 for no zero-padding, 2 for twice the length, etc..\n  neighbors :\n    Number of neighbors needed by ``get_peaks`` to define a peak.\n  max_miss :\n    Maximum percent of peaks that might be missed when approximating them\n    by a line.\n  start_delta :\n    Minimum acceptable value for an orthogonal deviation from the\n    approximation line to include a peak.\n  \"\"\"\n  # Finds all side lobe peaks, to find the \"best\" line for it afterwards\n  spectrum = dB20(rfft(wnd, res * len(wnd)))\n  peak_indices = list(get_peaks(spectrum, neighbors=neighbors))\n  log2_peak_indices = np.log2(peak_indices) # Base 2 ensures result in dB/oct\n  peaks = spectrum[peak_indices]\n  npeaks = len(peak_indices)\n\n  # This length (actually, twice the length) is the \"weight\" of each peak\n  lengths = np.array([0] + (1 - z **-2)(log2_peak_indices).skip(2).take(inf) +\n                     [0]) # Extreme values weights to zero\n  max_length = sum(lengths)\n\n  # First guess for the polynomial \"a*x + b\" is at the center\n  idx = np.searchsorted(log2_peak_indices,\n                        .5 * (log2_peak_indices[-1] + log2_peak_indices[0]))\n  a = ((peaks[idx+1] - peaks[idx]) /\n       (log2_peak_indices[idx+1] - log2_peak_indices[idx]))\n  b = peaks[idx] - a * log2_peak_indices[idx]\n\n  # Scoring for the optimization function\n  def score(vect, show=False):\n    a, b = vect\n    h = start_delta * (1 + a ** 2) ** .5 # Vertical deviation\n\n    while True:\n      pdelta = peaks - (a * log2_peak_indices + b)\n      peaks_idx_included = np.nonzero((pdelta < h) & (pdelta > -h))\n      missing = npeaks - len(peaks_idx_included[0])\n      if missing < npeaks * max_miss:\n        break\n      h *= 2\n\n    pdelta_included = pdelta[peaks_idx_included]\n    real_delta = max(pdelta_included) - min(pdelta_included)\n    total_length = sum(lengths[peaks_idx_included])\n\n    if show: # For debug\n      print(real_delta, len(peaks_idx_included[0]))\n\n    return -total_length / max_length + 4 * real_delta ** .5\n\n  a, b = so.fmin(score, [a, b], xtol=1e-12, ftol=1e-12, disp=False)\n\n#  # For Debug only\n#  score([a, b], show=True)\n#  plt.figure()\n#  plt.plot(log2_peak_indices, peaks, \"x-\")\n#  plt.plot(log2_peak_indices, a * log2_peak_indices + b)\n#  plt.show()\n\n  return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rint(x, step=1):\n  div, mod = divmod(x, step)\n  err = min(step / 10., .1)\n  result = div * step\n  if x > 0:\n    result += err\n  elif x < 0:\n    result -= err\n  if (operator.ge if x >= 0 else operator.gt)(2 * mod, step):\n    result += step\n  return int(result)", "response": "Round to integer.\n\n  Parameters\n  ----------\n  x :\n    Input number (integer or float) to be rounded.\n  step :\n    Quantization level (defaults to 1). If set to 2, the output will be the\n    \"best\" even number.\n\n  Result\n  ------\n  The step multiple nearest to x. When x is exactly halfway between two\n  possible outputs, it'll result the one farthest to zero."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zero_pad(seq, left=0, right=0, zero=0.):\n  for unused in xrange(left):\n    yield zero\n  for item in seq:\n    yield item\n  for unused in xrange(right):\n    yield zero", "response": "Returns a generator that pads a sequence with samples equals to zero."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef elementwise(name=\"\", pos=None):\n  if (name == \"\") and (pos is None):\n    pos = 0\n  def elementwise_decorator(func):\n    \"\"\"\n    Element-wise decorator for functions known to have 1 input and 1\n    output be applied directly on iterables. When made to work with more\n    than 1 input, all \"secondary\" parameters will the same in all\n    function calls (i.e., they will not even be a copy).\n\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n\n      # Find the possibly Iterable argument\n      positional = (pos is not None) and (pos < len(args))\n      arg = args[pos] if positional else kwargs[name]\n\n      if isinstance(arg, Iterable) and not isinstance(arg, STR_TYPES):\n        if positional:\n          data = (func(*(args[:pos] + (x,) + args[pos+1:]),\n                       **kwargs)\n                  for x in arg)\n        else:\n          data = (func(*args,\n                       **dict(it.chain(iteritems(kwargs), [(name, x)])))\n                  for x in arg)\n\n        # Generators should still return generators\n        if isinstance(arg, SOME_GEN_TYPES):\n          return data\n\n        # Cast to numpy array or matrix, if needed, without actually\n        # importing its package\n        type_arg = type(arg)\n        try:\n          is_numpy = type_arg.__module__ == \"numpy\"\n        except AttributeError:\n          is_numpy = False\n        if is_numpy:\n          np_type = {\"ndarray\": sys.modules[\"numpy\"].array,\n                     \"matrix\": sys.modules[\"numpy\"].mat\n                    }[type_arg.__name__]\n          return np_type(list(data))\n\n        # If it's a Stream, let's use the Stream constructor\n        from .lazy_stream import Stream\n        if issubclass(type_arg, Stream):\n          return Stream(data)\n\n        # Tuple, list, set, dict, deque, etc.. all falls here\n        return type_arg(data)\n\n      return func(*args, **kwargs) # wrapper returned value\n    return wrapper # elementwise_decorator returned value\n  return elementwise_decorator", "response": "A function - based auto - map decorator that can be used to create a new object of type tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef almost_eq(a, b, bits=32, tol=1, ignore_type=True, pad=0.):\n  if not (ignore_type or type(a) == type(b)):\n    return False\n  is_it_a = isinstance(a, Iterable)\n  is_it_b = isinstance(b, Iterable)\n  if is_it_a != is_it_b:\n    return False\n  if is_it_a:\n    return all(almost_eq.bits(ai, bi, bits, tol, ignore_type)\n               for ai, bi in xzip_longest(a, b, fillvalue=pad))\n  significand = {32: 23, 64: 52, 80: 63, 128: 112\n                }[bits] # That doesn't include the sign bit\n  power = tol - significand - 1\n  return abs(a - b) <= 2 ** power * abs(a + b)", "response": "A simple comparison of two iterables with a bit - length of a and b."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef almost_eq(a, b, max_diff=1e-7, ignore_type=True, pad=0.):\n  if not (ignore_type or type(a) == type(b)):\n    return False\n  is_it_a = isinstance(a, Iterable)\n  is_it_b = isinstance(b, Iterable)\n  if is_it_a != is_it_b:\n    return False\n  if is_it_a:\n    return all(almost_eq.diff(ai, bi, max_diff, ignore_type)\n               for ai, bi in xzip_longest(a, b, fillvalue=pad))\n  return abs(a - b) <= max_diff", "response": "A simple almost equal version of almost_eq."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cached(func):\n  class Cache(dict):\n    def __missing__(self, key):\n      result = self[key] = func(*key)\n      return result\n  cache = Cache()\n  f = wraps(func)(lambda *key: cache[key])\n  f.cache = cache\n  return f", "response": "A decorator for functions that have keyword arguments returning a dictionary mapping the arguments tuple to the resulting function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a generator that returns a tuple with the source text and index if requested otherwise returns the original string and the indices where the datetime string was located in the text.", "response": "def find_dates(text, source=False, index=False, strict=False, base_date=None):\n    \"\"\"\n    Extract datetime strings from text\n\n    :param text:\n        A string that contains one or more natural language or literal\n        datetime strings\n    :type text: str|unicode\n    :param source:\n        Return the original string segment\n    :type source: boolean\n    :param index:\n        Return the indices where the datetime string was located in text\n    :type index: boolean\n    :param strict:\n        Only return datetimes with complete date information. For example:\n        `July 2016` of `Monday` will not return datetimes.\n        `May 16, 2015` will return datetimes.\n    :type strict: boolean\n    :param base_date:\n        Set a default base datetime when parsing incomplete dates\n    :type base_date: datetime\n\n    :return: Returns a generator that produces :mod:`datetime.datetime` objects,\n        or a tuple with the source text and index, if requested\n    \"\"\"\n    date_finder = DateFinder(base_date=base_date)\n    return date_finder.find_dates(text, source=source, index=index, strict=strict)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_and_replace(self, date_string, captures):\n        # add timezones to replace\n        cloned_replacements = copy.copy(REPLACEMENTS)  # don't mutate\n        for tz_string in captures.get(\"timezones\", []):\n            cloned_replacements.update({tz_string: \" \"})\n\n        date_string = date_string.lower()\n        for key, replacement in cloned_replacements.items():\n            # we really want to match all permutations of the key surrounded by whitespace chars except one\n            # for example: consider the key = 'to'\n            # 1. match 'to '\n            # 2. match ' to'\n            # 3. match ' to '\n            # but never match r'(\\s|)to(\\s|)' which would make 'october' > 'ocber'\n            date_string = re.sub(\n                r\"(^|\\s)\" + key + r\"(\\s|$)\",\n                replacement,\n                date_string,\n                flags=re.IGNORECASE,\n            )\n\n        return date_string, self._pop_tz_string(sorted(captures.get(\"timezones\", [])))", "response": "Find and replace the date_string with the captures."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a naive datetime and add dateutil. tz. tzinfo object to the datetime object", "response": "def _add_tzinfo(self, datetime_obj, tz_string):\n        \"\"\"\n        take a naive datetime and add dateutil.tz.tzinfo object\n\n        :param datetime_obj: naive datetime object\n        :return: datetime object with tzinfo\n        \"\"\"\n        if datetime_obj is None:\n            return None\n\n        tzinfo_match = tz.gettz(tz_string)\n        return datetime_obj.replace(tzinfo=tzinfo_match)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans text for possible datetime strings and extracts them", "response": "def extract_date_strings(self, text, strict=False):\n        \"\"\"\n        Scans text for possible datetime strings and extracts them\n        :param strict: Strict mode will only return dates sourced with day, month, and year\n        \"\"\"\n\n        # Try to find ranges first\n        range_strings = list()\n        found_range = False\n        for range_match in RANGE_REGEX.finditer(text):\n            # Parse datetime 1 and datetime 2 recursively\n            range_captures = range_match.capturesdict()\n            dt1 = range_captures.get(\"dt1\", [])\n            dt2 = range_captures.get(\"dt2\", [])\n\n            for dt1_str in dt1:\n                range_strings.extend(self.extract_date_strings(dt1_str, strict=strict))\n\n            for dt2_str in dt2:\n                range_strings.extend(self.extract_date_strings(dt2_str, strict=strict))\n\n            found_range = True\n\n        for range_string in range_strings:\n            yield range_string\n\n        # Try to match regular datetimes if no ranges have been found\n        if not found_range:\n            for match in DATE_REGEX.finditer(text):\n                match_str = match.group(0)\n                indices = match.span(0)\n\n                ## Get individual group matches\n                captures = match.capturesdict()\n                # time = captures.get('time')\n                digits = captures.get(\"digits\")\n                # digits_modifiers = captures.get('digits_modifiers')\n                # days = captures.get('days')\n                months = captures.get(\"months\")\n                # timezones = captures.get('timezones')\n                # delimiters = captures.get('delimiters')\n                # time_periods = captures.get('time_periods')\n                # extra_tokens = captures.get('extra_tokens')\n\n                if strict:\n                    complete = False\n                    if len(digits) == 3:  # 12-05-2015\n                        complete = True\n                    elif (len(months) == 1) and (\n                        len(digits) == 2\n                    ):  # 19 February 2013 year 09:10\n                        complete = True\n\n                    if not complete:\n                        continue\n\n                ## sanitize date string\n                ## replace unhelpful whitespace characters with single whitespace\n                match_str = re.sub(r\"[\\n\\t\\s\\xa0]+\", \" \", match_str)\n                match_str = match_str.strip(STRIP_CHARS)\n\n                ## Save sanitized source string\n                yield match_str, indices, captures"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninstalling a colored terminal output for Python s logging module.", "response": "def install(level=None, **kw):\n    \"\"\"\n    Enable colored terminal output for Python's :mod:`logging` module.\n\n    :param level: The default logging level (an integer or a string with a\n                  level name, defaults to :data:`DEFAULT_LOG_LEVEL`).\n    :param logger: The logger to which the stream handler should be attached (a\n                   :class:`~logging.Logger` object, defaults to the root logger).\n    :param fmt: Set the logging format (a string like those accepted by\n                :class:`~logging.Formatter`, defaults to\n                :data:`DEFAULT_LOG_FORMAT`).\n    :param datefmt: Set the date/time format (a string, defaults to\n                    :data:`DEFAULT_DATE_FORMAT`).\n    :param style: One of the characters ``%``, ``{`` or ``$`` (defaults to\n                  :data:`DEFAULT_FORMAT_STYLE`). See the documentation of the\n                  :class:`python3:logging.Formatter` class in Python 3.2+. On\n                  older Python versions only ``%`` is supported.\n    :param milliseconds: :data:`True` to show milliseconds like :mod:`logging`\n                         does by default, :data:`False` to hide milliseconds\n                         (the default is :data:`False`, see `#16`_).\n    :param level_styles: A dictionary with custom level styles (defaults to\n                         :data:`DEFAULT_LEVEL_STYLES`).\n    :param field_styles: A dictionary with custom field styles (defaults to\n                         :data:`DEFAULT_FIELD_STYLES`).\n    :param stream: The stream where log messages should be written to (a\n                   file-like object). This defaults to :data:`None` which\n                   means :class:`StandardErrorHandler` is used.\n    :param isatty: :data:`True` to use a :class:`ColoredFormatter`,\n                   :data:`False` to use a normal :class:`~logging.Formatter`\n                   (defaults to auto-detection using\n                   :func:`~humanfriendly.terminal.terminal_supports_colors()`).\n    :param reconfigure: If :data:`True` (the default) multiple calls to\n                        :func:`coloredlogs.install()` will each override\n                        the previous configuration.\n    :param use_chroot: Refer to :class:`HostNameFilter`.\n    :param programname: Refer to :class:`ProgramNameFilter`.\n    :param syslog: If :data:`True` then :func:`.enable_system_logging()` will\n                   be called without arguments (defaults to :data:`False`). The\n                   `syslog` argument may also be a number or string, in this\n                   case it is assumed to be a logging level which is passed on\n                   to :func:`.enable_system_logging()`.\n\n    The :func:`coloredlogs.install()` function is similar to\n    :func:`logging.basicConfig()`, both functions take a lot of optional\n    keyword arguments but try to do the right thing by default:\n\n    1. If `reconfigure` is :data:`True` (it is by default) and an existing\n       :class:`~logging.StreamHandler` is found that is connected to either\n       :data:`~sys.stdout` or :data:`~sys.stderr` the handler will be removed.\n       This means that first calling :func:`logging.basicConfig()` and then\n       calling :func:`coloredlogs.install()` will replace the stream handler\n       instead of adding a duplicate stream handler. If `reconfigure` is\n       :data:`False` and an existing handler is found no further steps are\n       taken (to avoid installing a duplicate stream handler).\n\n    2. A :class:`~logging.StreamHandler` is created and connected to the stream\n       given by the `stream` keyword argument (:data:`sys.stderr` by\n       default). The stream handler's level is set to the value of the `level`\n       keyword argument.\n\n    3. A :class:`ColoredFormatter` is created if the `isatty` keyword argument\n       allows it (or auto-detection allows it), otherwise a normal\n       :class:`~logging.Formatter` is created. The formatter is initialized\n       with the `fmt` and `datefmt` keyword arguments (or their computed\n       defaults).\n\n    4. :func:`HostNameFilter.install()` and :func:`ProgramNameFilter.install()`\n       are called to enable the use of additional fields in the log format.\n\n    5. If the logger's level is too restrictive it is relaxed (refer to `notes\n       about log levels`_ for details).\n\n    6. The formatter is added to the handler and the handler is added to the\n       logger.\n\n    .. _#16: https://github.com/xolox/python-coloredlogs/issues/16\n    \"\"\"\n    logger = kw.get('logger') or logging.getLogger()\n    reconfigure = kw.get('reconfigure', True)\n    stream = kw.get('stream', None)\n    style = check_style(kw.get('style') or DEFAULT_FORMAT_STYLE)\n    # Get the log level from an argument, environment variable or default and\n    # convert the names of log levels to numbers to enable numeric comparison.\n    if level is None:\n        level = os.environ.get('COLOREDLOGS_LOG_LEVEL', DEFAULT_LOG_LEVEL)\n    level = level_to_number(level)\n    # Remove any existing stream handler that writes to stdout or stderr, even\n    # if the stream handler wasn't created by coloredlogs because multiple\n    # stream handlers (in the same hierarchy) writing to stdout or stderr would\n    # create duplicate output.  `None' is a synonym for the possibly dynamic\n    # value of the stderr attribute of the sys module.\n    match_streams = ([sys.stdout, sys.stderr]\n                     if stream in [sys.stdout, sys.stderr, None]\n                     else [stream])\n    match_handler = lambda handler: match_stream_handler(handler, match_streams)\n    handler, logger = replace_handler(logger, match_handler, reconfigure)\n    # Make sure reconfiguration is allowed or not relevant.\n    if not (handler and not reconfigure):\n        # Make it easy to enable system logging.\n        syslog_enabled = kw.get('syslog')\n        # We ignore the value `None' because it means the caller didn't opt in\n        # to system logging and `False' because it means the caller explicitly\n        # opted out of system logging.\n        #\n        # We never enable system logging on Windows because it is my impression\n        # that SysLogHandler isn't intended to be used on Windows; I've had\n        # reports of coloredlogs spewing extremely verbose errno 10057 warning\n        # messages to the console (once for each log message I suppose).\n        if syslog_enabled not in (None, False) and not WINDOWS:\n            from coloredlogs.syslog import enable_system_logging\n            if syslog_enabled is True:\n                # If the caller passed syslog=True then we leave the choice of\n                # default log level up to the coloredlogs.syslog module.\n                enable_system_logging()\n            else:\n                # Values other than (None, True, False) are assumed to\n                # represent a logging level for system logging.\n                enable_system_logging(level=syslog_enabled)\n        # Figure out whether we can use ANSI escape sequences.\n        use_colors = kw.get('isatty', None)\n        if use_colors or use_colors is None:\n            if NEED_COLORAMA:\n                try:\n                    # On Windows we can only use ANSI escape\n                    # sequences if Colorama is available.\n                    import colorama\n                    colorama.init()\n                    use_colors = True\n                except ImportError:\n                    # If Colorama isn't available then we specifically\n                    # shouldn't emit ANSI escape sequences!\n                    use_colors = False\n            elif use_colors is None:\n                # Auto-detect terminal support on other platforms.\n                use_colors = terminal_supports_colors(stream)\n        # Create a stream handler.\n        handler = logging.StreamHandler(stream) if stream else StandardErrorHandler()\n        handler.setLevel(level)\n        # Prepare the arguments to the formatter, allowing the caller to\n        # customize the values of `fmt', `datefmt' and `style' as desired.\n        formatter_options = dict(fmt=kw.get('fmt'), datefmt=kw.get('datefmt'))\n        # Only pass the `style' argument to the formatter when the caller\n        # provided an alternative logging format style. This prevents\n        # TypeError exceptions on Python versions before 3.2.\n        if style != DEFAULT_FORMAT_STYLE:\n            formatter_options['style'] = style\n        # Come up with a default log format?\n        if not formatter_options['fmt']:\n            # Use the log format defined by the environment variable\n            # $COLOREDLOGS_LOG_FORMAT or fall back to the default.\n            formatter_options['fmt'] = os.environ.get('COLOREDLOGS_LOG_FORMAT') or DEFAULT_LOG_FORMAT\n        # If the caller didn't specify a date/time format we'll use the format\n        # defined by the environment variable $COLOREDLOGS_DATE_FORMAT (or fall\n        # back to the default).\n        if not formatter_options['datefmt']:\n            formatter_options['datefmt'] = os.environ.get('COLOREDLOGS_DATE_FORMAT') or DEFAULT_DATE_FORMAT\n        # Python's logging module shows milliseconds by default through special\n        # handling in the logging.Formatter.formatTime() method [1]. Because\n        # coloredlogs always defines a `datefmt' it bypasses this special\n        # handling, which is fine because ever since publishing coloredlogs\n        # I've never needed millisecond precision ;-). However there are users\n        # of coloredlogs that do want milliseconds to be shown [2] so we\n        # provide a shortcut to make it easy.\n        #\n        # [1] https://stackoverflow.com/questions/6290739/python-logging-use-milliseconds-in-time-format\n        # [2] https://github.com/xolox/python-coloredlogs/issues/16\n        if kw.get('milliseconds'):\n            parser = FormatStringParser(style=style)\n            if not (parser.contains_field(formatter_options['fmt'], 'msecs') or\n                    '%f' in formatter_options['datefmt']):\n                pattern = parser.get_pattern('asctime')\n                replacements = {'%': '%(msecs)03d', '{': '{msecs:03}', '$': '${msecs}'}\n                formatter_options['fmt'] = pattern.sub(\n                    r'\\g<0>,' + replacements[style],\n                    formatter_options['fmt'],\n                )\n        # Do we need to make %(hostname) available to the formatter?\n        HostNameFilter.install(\n            fmt=formatter_options['fmt'],\n            handler=handler,\n            style=style,\n            use_chroot=kw.get('use_chroot', True),\n        )\n        # Do we need to make %(programname) available to the formatter?\n        ProgramNameFilter.install(\n            fmt=formatter_options['fmt'],\n            handler=handler,\n            programname=kw.get('programname'),\n            style=style,\n        )\n        # Inject additional formatter arguments specific to ColoredFormatter?\n        if use_colors:\n            for name, environment_name in (('field_styles', 'COLOREDLOGS_FIELD_STYLES'),\n                                           ('level_styles', 'COLOREDLOGS_LEVEL_STYLES')):\n                value = kw.get(name)\n                if value is None:\n                    # If no styles have been specified we'll fall back\n                    # to the styles defined by the environment variable.\n                    environment_value = os.environ.get(environment_name)\n                    if environment_value is not None:\n                        value = parse_encoded_styles(environment_value)\n                if value is not None:\n                    formatter_options[name] = value\n        # Create a (possibly colored) formatter.\n        formatter_type = ColoredFormatter if use_colors else BasicFormatter\n        handler.setFormatter(formatter_type(**formatter_options))\n        # Adjust the level of the selected logger.\n        adjust_level(logger, level)\n        # Install the stream handler.\n        logger.addHandler(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating a logging format style.", "response": "def check_style(value):\n    \"\"\"\n    Validate a logging format style.\n\n    :param value: The logging format style to validate (any value).\n    :returns: The logging format character (a string of one character).\n    :raises: :exc:`~exceptions.ValueError` when the given style isn't supported.\n\n    On Python 3.2+ this function accepts the logging format styles ``%``, ``{``\n    and ``$`` while on older versions only ``%`` is accepted (because older\n    Python versions don't support alternative logging format styles).\n    \"\"\"\n    if sys.version_info[:2] >= (3, 2):\n        if value not in FORMAT_STYLE_PATTERNS:\n            msg = \"Unsupported logging format style! (%r)\"\n            raise ValueError(format(msg, value))\n    elif value != DEFAULT_FORMAT_STYLE:\n        msg = \"Format string styles other than %r require Python 3.2+!\"\n        raise ValueError(msg, DEFAULT_FORMAT_STYLE)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef increase_verbosity():\n    defined_levels = sorted(set(find_defined_levels().values()))\n    current_index = defined_levels.index(get_level())\n    selected_index = max(0, current_index - 1)\n    set_level(defined_levels[selected_index])", "response": "Increase the verbosity of the root handler by one defined level."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrease_verbosity():\n    defined_levels = sorted(set(find_defined_levels().values()))\n    current_index = defined_levels.index(get_level())\n    selected_index = min(current_index + 1, len(defined_levels) - 1)\n    set_level(defined_levels[selected_index])", "response": "Decrease the verbosity of the root handler by one defined level."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the logging level of the root handler.", "response": "def get_level():\n    \"\"\"\n    Get the logging level of the root handler.\n\n    :returns: The logging level of the root handler (an integer) or\n              :data:`DEFAULT_LOG_LEVEL` (if no root handler exists).\n    \"\"\"\n    handler, logger = find_handler(logging.getLogger(), match_stream_handler)\n    return handler.level if handler else DEFAULT_LOG_LEVEL"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the logging level of the root handler.", "response": "def set_level(level):\n    \"\"\"\n    Set the logging level of the root handler.\n\n    :param level: The logging level to filter on (an integer or string).\n\n    If no root handler exists yet this automatically calls :func:`install()`.\n    \"\"\"\n    handler, logger = find_handler(logging.getLogger(), match_stream_handler)\n    if handler and logger:\n        # Change the level of the existing handler.\n        handler.setLevel(level_to_number(level))\n        # Adjust the level of the selected logger.\n        adjust_level(logger, level)\n    else:\n        # Create a new handler with the given level.\n        install(level=level)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nincreasing a logger s verbosity up to the requested level.", "response": "def adjust_level(logger, level):\n    \"\"\"\n    Increase a logger's verbosity up to the requested level.\n\n    :param logger: The logger to change (a :class:`~logging.Logger` object).\n    :param level: The log level to enable (a string or number).\n\n    This function is used by functions like :func:`install()`,\n    :func:`increase_verbosity()` and :func:`.enable_system_logging()` to adjust\n    a logger's level so that log messages up to the requested log level are\n    propagated to the configured output handler(s).\n\n    It uses :func:`logging.Logger.getEffectiveLevel()` to check whether\n    `logger` propagates or swallows log messages of the requested `level` and\n    sets the logger's level to the requested level if it would otherwise\n    swallow log messages.\n\n    Effectively this function will \"widen the scope of logging\" when asked to\n    do so but it will never \"narrow the scope of logging\". This is because I am\n    convinced that filtering of log messages should (primarily) be decided by\n    handlers.\n    \"\"\"\n    level = level_to_number(level)\n    if logger.getEffectiveLevel() > level:\n        logger.setLevel(level)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the defined logging levels.", "response": "def find_defined_levels():\n    \"\"\"\n    Find the defined logging levels.\n\n    :returns: A dictionary with level names as keys and integers as values.\n\n    Here's what the result looks like by default (when\n    no custom levels or level names have been defined):\n\n    >>> find_defined_levels()\n    {'NOTSET': 0,\n     'DEBUG': 10,\n     'INFO': 20,\n     'WARN': 30,\n     'WARNING': 30,\n     'ERROR': 40,\n     'FATAL': 50,\n     'CRITICAL': 50}\n    \"\"\"\n    defined_levels = {}\n    for name in dir(logging):\n        if name.isupper():\n            value = getattr(logging, name)\n            if isinstance(value, int):\n                defined_levels[name] = value\n    return defined_levels"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef level_to_number(value):\n    if is_string(value):\n        try:\n            defined_levels = find_defined_levels()\n            value = defined_levels[value.upper()]\n        except KeyError:\n            # Don't fail on unsupported log levels.\n            value = DEFAULT_LOG_LEVEL\n    return value", "response": "Coerce a logging level name to a number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_level_aliases():\n    mapping = collections.defaultdict(list)\n    for name, value in find_defined_levels().items():\n        mapping[value].append(name)\n    aliases = {}\n    for value, names in mapping.items():\n        if len(names) > 1:\n            names = sorted(names, key=lambda n: len(n))\n            canonical_name = names.pop()\n            for alias in names:\n                aliases[alias] = canonical_name\n    return aliases", "response": "Find log level names which are aliases of each other."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_encoded_styles(text, normalize_key=None):\n    parsed_styles = {}\n    for assignment in split(text, ';'):\n        name, _, styles = assignment.partition('=')\n        target = parsed_styles.setdefault(name, {})\n        for token in split(styles, ','):\n            # When this code was originally written, setting background colors\n            # wasn't supported yet, so there was no need to disambiguate\n            # between the text color and background color. This explains why\n            # a color name or number implies setting the text color (for\n            # backwards compatibility).\n            if token.isdigit():\n                target['color'] = int(token)\n            elif token in ANSI_COLOR_CODES:\n                target['color'] = token\n            elif '=' in token:\n                name, _, value = token.partition('=')\n                if name in ('color', 'background'):\n                    if value.isdigit():\n                        target[name] = int(value)\n                    elif value in ANSI_COLOR_CODES:\n                        target[name] = value\n            else:\n                target[token] = True\n    return parsed_styles", "response": "Parses the text styles encoded in a string into a nested dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_hostname(use_chroot=True):\n    for chroot_file in CHROOT_FILES:\n        try:\n            with open(chroot_file) as handle:\n                first_line = next(handle)\n                name = first_line.strip()\n                if name:\n                    return name\n        except Exception:\n            pass\n    return socket.gethostname()", "response": "Find the hostname to include in log messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nselect a suitable program name to embed in log messages.", "response": "def find_program_name():\n    \"\"\"\n    Select a suitable program name to embed in log messages.\n\n    :returns: One of the following strings (in decreasing order of preference):\n\n              1. The base name of the currently running Python program or\n                 script (based on the value at index zero of :data:`sys.argv`).\n              2. The base name of the Python executable (based on\n                 :data:`sys.executable`).\n              3. The string 'python'.\n    \"\"\"\n    # Gotcha: sys.argv[0] is '-c' if Python is started with the -c option.\n    return ((os.path.basename(sys.argv[0]) if sys.argv and sys.argv[0] != '-c' else '') or\n            (os.path.basename(sys.executable) if sys.executable else '') or\n            'python')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare to replace a handler in a node.", "response": "def replace_handler(logger, match_handler, reconfigure):\n    \"\"\"\n    Prepare to replace a handler.\n\n    :param logger: Refer to :func:`find_handler()`.\n    :param match_handler: Refer to :func:`find_handler()`.\n    :param reconfigure: :data:`True` if an existing handler should be replaced,\n                        :data:`False` otherwise.\n    :returns: A tuple of two values:\n\n              1. The matched :class:`~logging.Handler` object or :data:`None`\n                 if no handler was matched.\n              2. The :class:`~logging.Logger` to which the matched handler was\n                 attached or the logger given to :func:`replace_handler()`.\n    \"\"\"\n    handler, other_logger = find_handler(logger, match_handler)\n    if handler and other_logger and reconfigure:\n        # Remove the existing handler from the logger that its attached to\n        # so that we can install a new handler that behaves differently.\n        other_logger.removeHandler(handler)\n        # Switch to the logger that the existing handler was attached to so\n        # that reconfiguration doesn't narrow the scope of logging.\n        logger = other_logger\n    return handler, logger"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a handler in the propagation tree of a given logger.", "response": "def find_handler(logger, match_handler):\n    \"\"\"\n    Find a (specific type of) handler in the propagation tree of a logger.\n\n    :param logger: The logger to check (a :class:`~logging.Logger` object).\n    :param match_handler: A callable that receives a :class:`~logging.Handler`\n                          object and returns :data:`True` to match a handler or\n                          :data:`False` to skip that handler and continue\n                          searching for a match.\n    :returns: A tuple of two values:\n\n              1. The matched :class:`~logging.Handler` object or :data:`None`\n                 if no handler was matched.\n              2. The :class:`~logging.Logger` object to which the handler is\n                 attached or :data:`None` if no handler was matched.\n\n    This function finds a logging handler (of the given type) attached to a\n    logger or one of its parents (see :func:`walk_propagation_tree()`). It uses\n    the undocumented :class:`~logging.Logger.handlers` attribute to find\n    handlers attached to a logger, however it won't raise an exception if the\n    attribute isn't available. The advantages of this approach are:\n\n    - This works regardless of whether :mod:`coloredlogs` attached the handler\n      or other Python code attached the handler.\n\n    - This will correctly recognize the situation where the given logger has no\n      handlers but :attr:`~logging.Logger.propagate` is enabled and the logger\n      has a parent logger that does have a handler attached.\n    \"\"\"\n    for logger in walk_propagation_tree(logger):\n        for handler in getattr(logger, 'handlers', []):\n            if match_handler(handler):\n                return handler, logger\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_stream_handler(handler, streams=[]):\n    return (isinstance(handler, logging.StreamHandler) and\n            getattr(handler, 'stream') in (streams or (sys.stdout, sys.stderr)))", "response": "Determines if the given handler is a logging. StreamHandler and if it is a logging. StreamHandler and if it is a logging. StreamHandler and if it is a logging. StreamHandler and if it is a logging. StreamHandler and the streams are given the function returns True otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef walk_propagation_tree(logger):\n    while isinstance(logger, logging.Logger):\n        # Yield the logger to our caller.\n        yield logger\n        # Check if the logger has propagation enabled.\n        if logger.propagate:\n            # Continue with the parent logger. We use getattr() because the\n            # `parent' attribute isn't documented so properly speaking we\n            # shouldn't break if it's not available.\n            logger = getattr(logger, 'parent', None)\n        else:\n            # The propagation chain stops here.\n            logger = None", "response": "Walks through the propagation hierarchy of the given logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the date and time of a log record.", "response": "def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Format the date/time of a log record.\n\n        :param record: A :class:`~logging.LogRecord` object.\n        :param datefmt: A date/time format string (defaults to :data:`DEFAULT_DATE_FORMAT`).\n        :returns: The formatted date/time (a string).\n\n        This method overrides :func:`~logging.Formatter.formatTime()` to set\n        `datefmt` to :data:`DEFAULT_DATE_FORMAT` when the caller hasn't\n        specified a date format.\n\n        When `datefmt` contains the token ``%f`` it will be replaced by the\n        value of ``%(msecs)03d`` (refer to issue `#45`_ for use cases).\n        \"\"\"\n        # The default value of the following argument is defined here so\n        # that Sphinx doesn't embed the default value in the generated\n        # documentation (because the result is awkward to read).\n        datefmt = datefmt or DEFAULT_DATE_FORMAT\n        # Replace %f with the value of %(msecs)03d.\n        if '%f' in datefmt:\n            datefmt = datefmt.replace('%f', '%03d' % record.msecs)\n        # Delegate the actual date/time formatting to the base formatter.\n        return logging.Formatter.formatTime(self, record, datefmt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrewrite a logging format string to inject ANSI escape sequences.", "response": "def colorize_format(self, fmt, style=DEFAULT_FORMAT_STYLE):\n        \"\"\"\n        Rewrite a logging format string to inject ANSI escape sequences.\n\n        :param fmt: The log format string.\n        :param style: One of the characters ``%``, ``{`` or ``$`` (defaults to\n                      :data:`DEFAULT_FORMAT_STYLE`).\n        :returns: The logging format string with ANSI escape sequences.\n\n        This method takes a logging format string like the ones you give to\n        :class:`logging.Formatter` and processes it as follows:\n\n        1. First the logging format string is separated into formatting\n           directives versus surrounding text (according to the given `style`).\n\n        2. Then formatting directives and surrounding text are grouped\n           based on whitespace delimiters (in the surrounding text).\n\n        3. For each group styling is selected as follows:\n\n           1. If the group contains a single formatting directive that has\n              a style defined then the whole group is styled accordingly.\n\n           2. If the group contains multiple formatting directives that\n              have styles defined then each formatting directive is styled\n              individually and surrounding text isn't styled.\n\n        As an example consider the default log format (:data:`DEFAULT_LOG_FORMAT`)::\n\n         %(asctime)s %(hostname)s %(name)s[%(process)d] %(levelname)s %(message)s\n\n        The default field styles (:data:`DEFAULT_FIELD_STYLES`) define a style for the\n        `name` field but not for the `process` field, however because both fields\n        are part of the same whitespace delimited token they'll be highlighted\n        together in the style defined for the `name` field.\n        \"\"\"\n        result = []\n        parser = FormatStringParser(style=style)\n        for group in parser.get_grouped_pairs(fmt):\n            applicable_styles = [self.nn.get(self.field_styles, token.name) for token in group if token.name]\n            if sum(map(bool, applicable_styles)) == 1:\n                # If exactly one (1) field style is available for the group of\n                # tokens then all of the tokens will be styled the same way.\n                # This provides a limited form of backwards compatibility with\n                # the (intended) behavior of coloredlogs before the release of\n                # version 10.\n                result.append(ansi_wrap(\n                    ''.join(token.text for token in group),\n                    **next(s for s in applicable_styles if s)\n                ))\n            else:\n                for token in group:\n                    text = token.text\n                    if token.name:\n                        field_styles = self.nn.get(self.field_styles, token.name)\n                        if field_styles:\n                            text = ansi_wrap(text, **field_styles)\n                    result.append(text)\n        return ''.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format(self, record):\n        style = self.nn.get(self.level_styles, record.levelname)\n        # After the introduction of the `Empty' class it was reported in issue\n        # 33 that format() can be called when `Empty' has already been garbage\n        # collected. This explains the (otherwise rather out of place) `Empty\n        # is not None' check in the following `if' statement. The reasoning\n        # here is that it's much better to log a message without formatting\n        # then to raise an exception ;-).\n        #\n        # For more details refer to issue 33 on GitHub:\n        # https://github.com/xolox/python-coloredlogs/issues/33\n        if style and Empty is not None:\n            # Due to the way that Python's logging module is structured and\n            # documented the only (IMHO) clean way to customize its behavior is\n            # to change incoming LogRecord objects before they get to the base\n            # formatter. However we don't want to break other formatters and\n            # handlers, so we copy the log record.\n            #\n            # In the past this used copy.copy() but as reported in issue 29\n            # (which is reproducible) this can cause deadlocks. The following\n            # Python voodoo is intended to accomplish the same thing as\n            # copy.copy() without all of the generalization and overhead that\n            # we don't need for our -very limited- use case.\n            #\n            # For more details refer to issue 29 on GitHub:\n            # https://github.com/xolox/python-coloredlogs/issues/29\n            copy = Empty()\n            copy.__class__ = (\n                self.log_record_factory()\n                if self.log_record_factory is not None\n                else logging.LogRecord\n            )\n            copy.__dict__.update(record.__dict__)\n            copy.msg = ansi_wrap(coerce_string(record.msg), **style)\n            record = copy\n        # Delegate the remaining formatting to the base formatter.\n        return logging.Formatter.format(self, record)", "response": "Apply level - specific styling to log records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef install(cls, handler, fmt=None, use_chroot=True, style=DEFAULT_FORMAT_STYLE):\n        if fmt:\n            parser = FormatStringParser(style=style)\n            if not parser.contains_field(fmt, 'hostname'):\n                return\n        handler.addFilter(cls(use_chroot))", "response": "Install the class NameFilter on a log handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the programname filter on the given handler.", "response": "def install(cls, handler, fmt, programname=None, style=DEFAULT_FORMAT_STYLE):\n        \"\"\"\n        Install the :class:`ProgramNameFilter` (only if needed).\n\n        :param fmt: The log format string to check for ``%(programname)``.\n        :param style: One of the characters ``%``, ``{`` or ``$`` (defaults to\n                      :data:`DEFAULT_FORMAT_STYLE`).\n        :param handler: The logging handler on which to install the filter.\n        :param programname: Refer to :func:`__init__()`.\n\n        If `fmt` is given the filter will only be installed if `fmt` uses the\n        ``programname`` field. If `fmt` is not given the filter is installed\n        unconditionally.\n        \"\"\"\n        if fmt:\n            parser = FormatStringParser(style=style)\n            if not parser.contains_field(fmt, 'programname'):\n                return\n        handler.addFilter(cls(programname))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngroup the results of :func:`get_pairs()` separated by whitespace. :param format_string: The logging format string. :returns: A list of lists of :class:`FormatStringToken` objects.", "response": "def get_grouped_pairs(self, format_string):\n        \"\"\"\n        Group the results of :func:`get_pairs()` separated by whitespace.\n\n        :param format_string: The logging format string.\n        :returns: A list of lists of :class:`FormatStringToken` objects.\n        \"\"\"\n        # Step 1: Split simple tokens (without a name) into\n        # their whitespace parts and non-whitespace parts.\n        separated = []\n        pattern = re.compile(r'(\\s+)')\n        for token in self.get_pairs(format_string):\n            if token.name:\n                separated.append(token)\n            else:\n                separated.extend(\n                    FormatStringToken(name=None, text=text)\n                    for text in pattern.split(token.text) if text\n                )\n        # Step 2: Group tokens together based on whitespace.\n        current_group = []\n        grouped_pairs = []\n        for token in separated:\n            if token.text.isspace():\n                if current_group:\n                    grouped_pairs.append(current_group)\n                grouped_pairs.append([token])\n                current_group = []\n            else:\n                current_group.append(token)\n        if current_group:\n            grouped_pairs.append(current_group)\n        return grouped_pairs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a compiled regular expression that matches a formatting directive that references the given field name.", "response": "def get_pattern(self, field_name):\n        \"\"\"\n        Get a regular expression to match a formatting directive that references the given field name.\n\n        :param field_name: The name of the field to match (a string).\n        :returns: A compiled regular expression object.\n        \"\"\"\n        return re.compile(self.raw_pattern.replace(r'\\w+', field_name), re.VERBOSE)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_tokens(self, format_string):\n        return [t for t in self.tokenize_pattern.split(format_string) if t]", "response": "Tokenize a logging format string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_name(self, name):\n        name = name.lower()\n        if name in self.aliases:\n            name = self.aliases[name]\n        return name", "response": "Normalizes a field or level name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing the keys of a dictionary using self. normalize_name.", "response": "def normalize_keys(self, value):\n        \"\"\"\n        Normalize the keys of a dictionary using :func:`normalize_name()`.\n\n        :param value: The dictionary to normalize.\n        :returns: A dictionary with normalized keys.\n        \"\"\"\n        return dict((self.normalize_name(k), v) for k, v in value.items())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef demonstrate_colored_logging():\n    # Determine the available logging levels and order them by numeric value.\n    decorated_levels = []\n    defined_levels = coloredlogs.find_defined_levels()\n    normalizer = coloredlogs.NameNormalizer()\n    for name, level in defined_levels.items():\n        if name != 'NOTSET':\n            item = (level, normalizer.normalize_name(name))\n            if item not in decorated_levels:\n                decorated_levels.append(item)\n    ordered_levels = sorted(decorated_levels)\n    # Initialize colored output to the terminal, default to the most\n    # verbose logging level but enable the user the customize it.\n    coloredlogs.install(level=os.environ.get('COLOREDLOGS_LOG_LEVEL', ordered_levels[0][1]))\n    # Print some examples with different timestamps.\n    for level, name in ordered_levels:\n        log_method = getattr(logger, name, None)\n        if log_method:\n            log_method(\"message with level %s (%i)\", name, level)\n            time.sleep(DEMO_DELAY)", "response": "Interactively demonstrate the coloredlogs package."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    actions = []\n    try:\n        # Parse the command line arguments.\n        options, arguments = getopt.getopt(sys.argv[1:], 'cdh', [\n            'convert', 'to-html', 'demo', 'help',\n        ])\n        # Map command line options to actions.\n        for option, value in options:\n            if option in ('-c', '--convert', '--to-html'):\n                actions.append(functools.partial(convert_command_output, *arguments))\n                arguments = []\n            elif option in ('-d', '--demo'):\n                actions.append(demonstrate_colored_logging)\n            elif option in ('-h', '--help'):\n                usage(__doc__)\n                return\n            else:\n                assert False, \"Programming error: Unhandled option!\"\n        if not actions:\n            usage(__doc__)\n            return\n    except Exception as e:\n        warning(\"Error: %s\", e)\n        sys.exit(1)\n    for function in actions:\n        function()", "response": "Command line interface for the coloredlogs program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_command_output(*command):\n    captured_output = capture(command)\n    converted_output = convert(captured_output)\n    if connected_to_terminal():\n        fd, temporary_file = tempfile.mkstemp(suffix='.html')\n        with open(temporary_file, 'w') as handle:\n            handle.write(converted_output)\n        webbrowser.open(temporary_file)\n    elif captured_output and not captured_output.isspace():\n        output(converted_output)", "response": "Command line interface for coloredlogs - to - html."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning an external command and returns the output of the command.", "response": "def capture(command, encoding='UTF-8'):\n    \"\"\"\n    Capture the output of an external command as if it runs in an interactive terminal.\n\n    :param command: The command name and its arguments (a list of strings).\n    :param encoding: The encoding to use to decode the output (a string).\n    :returns: The output of the command.\n\n    This function runs an external command under ``script`` (emulating an\n    interactive terminal) to capture the output of the command as if it was\n    running in an interactive terminal (including ANSI escape sequences).\n    \"\"\"\n    with open(os.devnull, 'wb') as dev_null:\n        # We start by invoking the `script' program in a form that is supported\n        # by the Linux implementation [1] but fails command line validation on\n        # the MacOS (BSD) implementation [2]: The command is specified using\n        # the -c option and the typescript file is /dev/null.\n        #\n        # [1] http://man7.org/linux/man-pages/man1/script.1.html\n        # [2] https://developer.apple.com/legacy/library/documentation/Darwin/Reference/ManPages/man1/script.1.html\n        command_line = ['script', '-qc', ' '.join(map(pipes.quote, command)), '/dev/null']\n        script = subprocess.Popen(command_line, stdout=subprocess.PIPE, stderr=dev_null)\n        stdout, stderr = script.communicate()\n        if script.returncode == 0:\n            # If `script' succeeded we assume that it understood our command line\n            # invocation which means it's the Linux implementation (in this case\n            # we can use standard output instead of a temporary file).\n            output = stdout.decode(encoding)\n        else:\n            # If `script' failed we assume that it didn't understand our command\n            # line invocation which means it's the MacOS (BSD) implementation\n            # (in this case we need a temporary file because the command line\n            # interface requires it).\n            fd, temporary_file = tempfile.mkstemp(prefix='coloredlogs-', suffix='-capture.txt')\n            try:\n                command_line = ['script', '-q', temporary_file] + list(command)\n                subprocess.Popen(command_line, stdout=dev_null, stderr=dev_null).wait()\n                with codecs.open(temporary_file, 'r', encoding) as handle:\n                    output = handle.read()\n            finally:\n                os.unlink(temporary_file)\n            # On MacOS when standard input is /dev/null I've observed\n            # the captured output starting with the characters '^D':\n            #\n            #   $ script -q capture.txt echo example </dev/null\n            #   example\n            #   $ xxd capture.txt\n            #   00000000: 5e44 0808 6578 616d 706c 650d 0a         ^D..example..\n            #\n            # I'm not sure why this is here, although I suppose it has to do\n            # with ^D in caret notation signifying end-of-file [1]. What I do\n            # know is that this is an implementation detail that callers of the\n            # capture() function shouldn't be bothered with, so we strip it.\n            #\n            # [1] https://en.wikipedia.org/wiki/End-of-file\n            if output.startswith(b'^D'):\n                output = output[2:]\n    # Clean up backspace and carriage return characters and the 'erase line'\n    # ANSI escape sequence and return the output as a Unicode string.\n    return u'\\n'.join(clean_terminal_output(output))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting text with ANSI escape sequences to HTML.", "response": "def convert(text, code=True, tabsize=4):\n    \"\"\"\n    Convert text with ANSI escape sequences to HTML.\n\n    :param text: The text with ANSI escape sequences (a string).\n    :param code: Whether to wrap the returned HTML fragment in a\n                 ``<code>...</code>`` element (a boolean, defaults\n                 to :data:`True`).\n    :param tabsize: Refer to :func:`str.expandtabs()` for details.\n    :returns: The text converted to HTML (a string).\n    \"\"\"\n    output = []\n    in_span = False\n    compatible_text_styles = {\n        # The following ANSI text styles have an obvious mapping to CSS.\n        ANSI_TEXT_STYLES['bold']: {'font-weight': 'bold'},\n        ANSI_TEXT_STYLES['strike_through']: {'text-decoration': 'line-through'},\n        ANSI_TEXT_STYLES['underline']: {'text-decoration': 'underline'},\n    }\n    for token in TOKEN_PATTERN.split(text):\n        if token.startswith(('http://', 'https://', 'www.')):\n            url = token if '://' in token else ('http://' + token)\n            token = u'<a href=\"%s\" style=\"color:inherit\">%s</a>' % (html_encode(url), html_encode(token))\n        elif token.startswith(ANSI_CSI):\n            ansi_codes = token[len(ANSI_CSI):-1].split(';')\n            if all(c.isdigit() for c in ansi_codes):\n                ansi_codes = list(map(int, ansi_codes))\n            # First we check for a reset code to close the previous <span>\n            # element. As explained on Wikipedia [1] an absence of codes\n            # implies a reset code as well: \"No parameters at all in ESC[m acts\n            # like a 0 reset code\".\n            # [1] https://en.wikipedia.org/wiki/ANSI_escape_code#CSI_sequences\n            if in_span and (0 in ansi_codes or not ansi_codes):\n                output.append('</span>')\n                in_span = False\n            # Now we're ready to generate the next <span> element (if any) in\n            # the knowledge that we're emitting opening <span> and closing\n            # </span> tags in the correct order.\n            styles = {}\n            is_faint = (ANSI_TEXT_STYLES['faint'] in ansi_codes)\n            is_inverse = (ANSI_TEXT_STYLES['inverse'] in ansi_codes)\n            while ansi_codes:\n                number = ansi_codes.pop(0)\n                # Try to match a compatible text style.\n                if number in compatible_text_styles:\n                    styles.update(compatible_text_styles[number])\n                    continue\n                # Try to extract a text and/or background color.\n                text_color = None\n                background_color = None\n                if 30 <= number <= 37:\n                    # 30-37 sets the text color from the eight color palette.\n                    text_color = EIGHT_COLOR_PALETTE[number - 30]\n                elif 40 <= number <= 47:\n                    # 40-47 sets the background color from the eight color palette.\n                    background_color = EIGHT_COLOR_PALETTE[number - 40]\n                elif 90 <= number <= 97:\n                    # 90-97 sets the text color from the high-intensity eight color palette.\n                    text_color = BRIGHT_COLOR_PALETTE[number - 90]\n                elif 100 <= number <= 107:\n                    # 100-107 sets the background color from the high-intensity eight color palette.\n                    background_color = BRIGHT_COLOR_PALETTE[number - 100]\n                elif number in (38, 39) and len(ansi_codes) >= 2 and ansi_codes[0] == 5:\n                    # 38;5;N is a text color in the 256 color mode palette,\n                    # 39;5;N is a background color in the 256 color mode palette.\n                    try:\n                        # Consume the 5 following 38 or 39.\n                        ansi_codes.pop(0)\n                        # Consume the 256 color mode color index.\n                        color_index = ansi_codes.pop(0)\n                        # Set the variable to the corresponding HTML/CSS color.\n                        if number == 38:\n                            text_color = EXTENDED_COLOR_PALETTE[color_index]\n                        elif number == 39:\n                            background_color = EXTENDED_COLOR_PALETTE[color_index]\n                    except (ValueError, IndexError):\n                        pass\n                # Apply the 'faint' or 'inverse' text style\n                # by manipulating the selected color(s).\n                if text_color and is_inverse:\n                    # Use the text color as the background color and pick a\n                    # text color that will be visible on the resulting\n                    # background color.\n                    background_color = text_color\n                    text_color = select_text_color(*parse_hex_color(text_color))\n                if text_color and is_faint:\n                    # Because I wasn't sure how to implement faint colors\n                    # based on normal colors I looked at how gnome-terminal\n                    # (my terminal of choice) handles this and it appears\n                    # to just pick a somewhat darker color.\n                    text_color = '#%02X%02X%02X' % tuple(\n                        max(0, n - 40) for n in parse_hex_color(text_color)\n                    )\n                if text_color:\n                    styles['color'] = text_color\n                if background_color:\n                    styles['background-color'] = background_color\n            if styles:\n                token = '<span style=\"%s\">' % ';'.join(k + ':' + v for k, v in sorted(styles.items()))\n                in_span = True\n            else:\n                token = ''\n        else:\n            token = html_encode(token)\n        output.append(token)\n    html = ''.join(output)\n    html = encode_whitespace(html, tabsize)\n    if code:\n        html = '<code>%s</code>' % html\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode_whitespace(text, tabsize=4):\n    # Convert Windows line endings (CR+LF) to UNIX line endings (LF).\n    text = text.replace('\\r\\n', '\\n')\n    # Convert UNIX line endings (LF) to HTML line endings (<br>).\n    text = text.replace('\\n', '<br>\\n')\n    # Convert tabs to spaces.\n    text = text.expandtabs(tabsize)\n    # Convert leading spaces (that is to say spaces at the start of the string\n    # and/or directly after a line ending) into non-breaking spaces, otherwise\n    # HTML rendering engines will simply ignore these spaces.\n    text = re.sub(INDENT_PATTERN, encode_whitespace_cb, text)\n    # The conversion of leading spaces we just did misses a corner case where a\n    # line starts with an HTML tag but the first visible text is a space. Web\n    # browsers seem to ignore these spaces, so we need to convert them.\n    text = re.sub(TAG_INDENT_PATTERN, r'\\1&nbsp;', text)\n    # Convert runs of multiple spaces into non-breaking spaces to avoid HTML\n    # rendering engines from visually collapsing runs of spaces into a single\n    # space. We specifically don't replace single spaces for several reasons:\n    # 1. We'd break the HTML emitted by convert() by replacing spaces\n    #    inside HTML elements (for example the spaces that separate\n    #    element names from attribute names).\n    # 2. If every single space is replaced by a non-breaking space,\n    #    web browsers perform awkwardly unintuitive word wrapping.\n    # 3. The HTML output would be bloated for no good reason.\n    text = re.sub(' {2,}', encode_whitespace_cb, text)\n    return text", "response": "Encodes whitespace in the given text into HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef html_encode(text):\n    text = text.replace('&', '&amp;')\n    text = text.replace('<', '&lt;')\n    text = text.replace('>', '&gt;')\n    text = text.replace('\"', '&quot;')\n    return text", "response": "Encode characters with a special meaning as HTML."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_hex_color(value):\n    if value.startswith('#'):\n        value = value[1:]\n    if len(value) == 3:\n        return (\n            int(value[0] * 2, 16),\n            int(value[1] * 2, 16),\n            int(value[2] * 2, 16),\n        )\n    elif len(value) == 6:\n        return (\n            int(value[0:2], 16),\n            int(value[2:4], 16),\n            int(value[4:6], 16),\n        )\n    else:\n        raise ValueError()", "response": "Parses a CSS color in hexadecimal notation into its R G B components."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enable_system_logging(programname=None, fmt=None, logger=None, reconfigure=True, **kw):\n    # Provide defaults for omitted arguments.\n    programname = programname or find_program_name()\n    logger = logger or logging.getLogger()\n    fmt = fmt or DEFAULT_LOG_FORMAT\n    level = level_to_number(kw.get('level', DEFAULT_LOG_LEVEL))\n    # Check whether system logging is already enabled.\n    handler, logger = replace_handler(logger, match_syslog_handler, reconfigure)\n    # Make sure reconfiguration is allowed or not relevant.\n    if not (handler and not reconfigure):\n        # Create a system logging handler.\n        handler = connect_to_syslog(**kw)\n        # Make sure the handler was successfully created.\n        if handler:\n            # Enable the use of %(programname)s.\n            ProgramNameFilter.install(handler=handler, fmt=fmt, programname=programname)\n            # Connect the formatter, handler and logger.\n            handler.setFormatter(logging.Formatter(fmt))\n            logger.addHandler(handler)\n            # Adjust the level of the selected logger.\n            adjust_level(logger, level)\n    return handler", "response": "Enables system logging for the given programname."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_to_syslog(address=None, facility=None, level=None):\n    if not address:\n        address = find_syslog_address()\n    if facility is None:\n        facility = logging.handlers.SysLogHandler.LOG_USER\n    if level is None:\n        level = DEFAULT_LOG_LEVEL\n    for socktype in socket.SOCK_RAW, socket.SOCK_STREAM, None:\n        kw = dict(facility=facility, address=address)\n        if socktype is not None:\n            kw['socktype'] = socktype\n        try:\n            handler = logging.handlers.SysLogHandler(**kw)\n        except (IOError, TypeError):\n            # The socktype argument was added in Python 2.7 and its use will raise a\n            # TypeError exception on Python 2.6. IOError is a superclass of socket.error\n            # (since Python 2.6) which can be raised if the system logging daemon is\n            # unavailable.\n            pass\n        else:\n            handler.setLevel(level_to_number(level))\n            return handler", "response": "Connect to the system logging daemon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the most suitable destination for system log messages.", "response": "def find_syslog_address():\n    \"\"\"\n    Find the most suitable destination for system log messages.\n\n    :returns: The pathname of a log device (a string) or an address/port tuple as\n              supported by :class:`~logging.handlers.SysLogHandler`.\n\n    On Mac OS X this prefers :data:`LOG_DEVICE_MACOSX`, after that :data:`LOG_DEVICE_UNIX`\n    is checked for existence. If both of these device files don't exist the default used\n    by :class:`~logging.handlers.SysLogHandler` is returned.\n    \"\"\"\n    if sys.platform == 'darwin' and os.path.exists(LOG_DEVICE_MACOSX):\n        return LOG_DEVICE_MACOSX\n    elif os.path.exists(LOG_DEVICE_UNIX):\n        return LOG_DEVICE_UNIX\n    else:\n        return 'localhost', logging.handlers.SYSLOG_UDP_PORT"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating screenshots from shell scripts.", "response": "def generate_screenshots():\n    \"\"\"Generate screenshots from shell scripts.\"\"\"\n    this_script = os.path.abspath(__file__)\n    this_directory = os.path.dirname(this_script)\n    repository = os.path.join(this_directory, os.pardir)\n    examples_directory = os.path.join(repository, 'docs', 'examples')\n    images_directory = os.path.join(repository, 'docs', 'images')\n    for shell_script in sorted(glob.glob(os.path.join(examples_directory, '*.sh'))):\n        basename, extension = os.path.splitext(os.path.basename(shell_script))\n        image_file = os.path.join(images_directory, '%s.png' % basename)\n        logger.info(\"Generating %s by running %s ..\",\n                    format_path(image_file),\n                    format_path(shell_script))\n        command_line = [sys.executable, __file__, shell_script]\n        random_title = random_string(25)\n        # Generate the urxvt command line.\n        urxvt_command = [\n            'urxvt',\n            # Enforce a default geometry.\n            '-geometry', '98x30',\n            # Set the text and background color.\n            '-fg', TEXT_COLOR,\n            '-bg', BACKGROUND_COLOR,\n            # Set the font name and pixel size.\n            '-fn', 'xft:%s:pixelsize=%i' % (FONT_NAME, FONT_SIZE),\n            # Set the window title.\n            '-title', random_title,\n            # Hide scrollbars.\n            '+sb',\n        ]\n        if which('qtile-run'):\n            # I've been using tiling window managers for years now, at the\n            # moment 'qtile' is my window manager of choice. It requires the\n            # following special handling to enable the 'urxvt' window to float,\n            # which in turn enables it to respect the '--geometry' option.\n            urxvt_command.insert(0, 'qtile-run')\n            urxvt_command.insert(1, '-f')\n        # Apply the Ubuntu color scheme to urxvt.\n        for index, css_color in enumerate(EIGHT_COLOR_PALETTE):\n            urxvt_command.extend(('--color%i' % index, css_color))\n        # Add the command that should run inside the terminal.\n        urxvt_command.extend(('-e', 'sh', '-c', 'setterm -cursor off; %s' % quote(command_line)))\n        # Launch urxvt.\n        execute(*urxvt_command, async=True)\n        # Make sure we close the urxvt window.\n        try:\n            # Wait for urxvt to start up. If I were to improve this I could\n            # instead wait for the creation of a file by interpret_script().\n            time.sleep(10)\n            # Take a screen shot of the window using ImageMagick.\n            execute('import', '-window', random_title, image_file)\n            # Auto-trim the screen shot, then give it a 5px border.\n            execute('convert', image_file, '-trim',\n                    '-bordercolor', BACKGROUND_COLOR,\n                    '-border', '5', image_file)\n        finally:\n            execute('wmctrl', '-c', random_title)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpret_script(shell_script):\n    with CaptureOutput() as capturer:\n        shell = subprocess.Popen(['bash', '-'], stdin=subprocess.PIPE)\n        with open(shell_script) as handle:\n            for line in handle:\n                sys.stdout.write(ansi_wrap('$', color='green') + ' ' + line)\n                sys.stdout.flush()\n                shell.stdin.write(line)\n                shell.stdin.flush()\n            shell.stdin.close()\n        time.sleep(12)\n        # Get the text that was shown in the terminal.\n        captured_output = capturer.get_text()\n    # Store the text that was shown in the terminal.\n    filename, extension = os.path.splitext(shell_script)\n    transcript_file = '%s.txt' % filename\n    logger.info(\"Updating %s ..\", format_path(transcript_file))\n    with open(transcript_file, 'w') as handle:\n        handle.write(ansi_strip(captured_output))", "response": "Interprets a shell script and stores the text that was shown in the terminal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the version number from a Python module.", "response": "def get_version(*args):\n    \"\"\"Extract the version number from a Python module.\"\"\"\n    contents = get_contents(*args)\n    metadata = dict(re.findall('__([a-z]+)__ = [\\'\"]([^\\'\"]+)', contents))\n    return metadata['version']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd conditional dependencies for Windows when creating source distributions.", "response": "def get_install_requires():\n    \"\"\"Add conditional dependencies for Windows (when creating source distributions).\"\"\"\n    install_requires = get_requirements('requirements.txt')\n    if 'bdist_wheel' not in sys.argv:\n        if sys.platform == 'win32':\n            install_requires.append('colorama')\n    return sorted(install_requires)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets requirements from pip requirement files.", "response": "def get_requirements(*args):\n    \"\"\"Get requirements from pip requirement files.\"\"\"\n    requirements = set()\n    with open(get_absolute_path(*args)) as handle:\n        for line in handle:\n            # Strip comments.\n            line = re.sub(r'^#.*|\\s#.*', '', line)\n            # Ignore empty lines\n            if line and not line.isspace():\n                requirements.add(re.sub(r'\\s+', '', line))\n    return sorted(requirements)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef have_environment_marker_support():\n    try:\n        from pkg_resources import parse_version\n        from setuptools import __version__\n        return parse_version(__version__) >= parse_version('0.7.2')\n    except Exception:\n        return False", "response": "Check whether setuptools has support for PEP - 426 environment marker support."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_pth_directory():\n    return ('/' if 'bdist_wheel' in sys.argv\n            else os.path.relpath(distutils.sysconfig.get_python_lib(), sys.prefix))", "response": "Determines the correct directory pathname for installing. pth files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flask_ctx_get_request_id():\n    from flask import _app_ctx_stack as stack  # We do not support < Flask 0.9\n\n    if stack.top is None:\n        raise ExecutedOutsideContext()\n\n    g_object_attr = stack.top.app.config['LOG_REQUEST_ID_G_OBJECT_ATTRIBUTE']\n    return g.get(g_object_attr, None)", "response": "Get request id from flask s G object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs the HTTP event.", "response": "def _log_http_event(response):\n        \"\"\"\n        It will create a log event as werkzeug but at the end of request holding the request-id\n\n        Intended usage is a handler of Flask.after_request\n        :return: The same response object\n        \"\"\"\n        logger.info(\n            '{ip} - - \"{method} {path} {status_code}\"'.format(\n                ip=request.remote_addr,\n                method=request.method,\n                path=request.path,\n                status_code=response.status_code)\n        )\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_fetcher(self, ctx_fetcher):\n        if ctx_fetcher not in self.ctx_fetchers:\n            self.ctx_fetchers.append(ctx_fetcher)", "response": "Register another context - specialized fetcher that will return the id or raise ExecutedOutsideContext"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the amazon ELB trace id from current Flask request context", "response": "def amazon_elb_trace_id():\n    \"\"\"\n    Get the amazon ELB trace id from current Flask request context\n    :return: The found Trace-ID or None if not found\n    :rtype: str | None\n    \"\"\"\n    amazon_request_id = request.headers.get('X-Amzn-Trace-Id', '')\n    trace_id_params = dict(x.split('=') if '=' in x else (x, None) for x in amazon_request_id.split(';'))\n    if 'Self' in trace_id_params:\n        return trace_id_params['Self']\n    if 'Root' in trace_id_params:\n        return trace_id_params['Root']\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef auto_parser(parsers=(x_request_id, x_correlation_id, amazon_elb_trace_id)):\n\n    for parser in parsers:\n        request_id = parser()\n        if request_id is not None:\n            return request_id\n\n    return None", "response": "Try all known parsers and return the first found id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_before_publish_insert_request_id_header(headers, **kwargs):\n    if _CELERY_X_HEADER not in headers:\n        request_id = current_request_id()\n        headers[_CELERY_X_HEADER] = request_id\n        logger.debug(\"Forwarding request_id '{}' to the task consumer.\".format(request_id))", "response": "This function is meant to be used as a signal processor for before_task_publish."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generic_add(a, b):\n    logger.debug('Called generic_add({}, {})'.format(a, b))\n    return a + b", "response": "Simple function to add two numbers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of seconds since the epoch from the values of the message keys date_key and time_key.", "response": "def from_grib_date_time(message, date_key='dataDate', time_key='dataTime', epoch=DEFAULT_EPOCH):\n    # type: (T.Mapping, str, str, datetime.datetime) -> int\n    \"\"\"\n    Return the number of seconds since the ``epoch`` from the values of the ``message`` keys,\n    using datetime.total_seconds().\n\n    :param message: the target GRIB message\n    :param date_key: the date key, defaults to \"dataDate\"\n    :param time_key: the time key, defaults to \"dataTime\"\n    :param epoch: the reference datetime\n    \"\"\"\n    date = message[date_key]\n    time = message[time_key]\n    hour = time // 100\n    minute = time % 100\n    year = date // 10000\n    month = date // 100 % 100\n    day = date % 100\n    data_datetime = datetime.datetime(year, month, day, hour, minute)\n    # Python 2 compatible timestamp implementation without timezone hurdle\n    # see: https://docs.python.org/3/library/datetime.html#datetime.datetime.timestamp\n    return int((data_datetime - epoch).total_seconds())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_valid_time(time, step):\n    # type: (np.ndarray, np.ndarray) -> T.Tuple[T.Tuple[str, ...], np.ndarray]\n    \"\"\"\n    Return dimensions and data of the valid_time corresponding to the given ``time`` and ``step``.\n    The data is seconds from the same epoch as ``time`` and may have one or two dimensions.\n\n    :param time: given in seconds from an epoch, as returned by ``from_grib_date_time``\n    :param step: given in hours, as returned by ``from_grib_step``\n    \"\"\"\n    step_s = step * 3600\n    if len(time.shape) == 0 and len(step.shape) == 0:\n        data = time + step_s\n        dims = ()  # type: T.Tuple[str, ...]\n    elif len(time.shape) > 0 and len(step.shape) == 0:\n        data = time + step_s\n        dims = ('time',)\n    elif len(time.shape) == 0 and len(step.shape) > 0:\n        data = time + step_s\n        dims = ('step',)\n    else:\n        data = time[:, None] + step_s[None, :]\n        dims = ('time', 'step')\n    return dims, data", "response": "Builds the dimensions and data of the valid_time corresponding to the given time and step."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a GRIB file as a cfgrib. Dataset.", "response": "def open_file(path, grib_errors='warn', **kwargs):\n    \"\"\"Open a GRIB file as a ``cfgrib.Dataset``.\"\"\"\n    if 'mode' in kwargs:\n        warnings.warn(\"the `mode` keyword argument is ignored and deprecated\", FutureWarning)\n        kwargs.pop('mode')\n    stream = messages.FileStream(path, message_class=cfmessage.CfMessage, errors=grib_errors)\n    return Dataset(*build_dataset_components(stream, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef canonical_dataarray_to_grib(\n        data_var, file, grib_keys={}, default_grib_keys=DEFAULT_GRIB_KEYS, **kwargs\n):\n    # type: (T.IO[bytes], xr.DataArray, T.Dict[str, T.Any], T.Dict[str, T.Any], T.Any) -> None\n    \"\"\"\n    Write a ``xr.DataArray`` in *canonical* form to a GRIB file.\n    \"\"\"\n    # validate Dataset keys, DataArray names, and attr keys/values\n    detected_keys, suggested_keys = detect_grib_keys(data_var, default_grib_keys, grib_keys)\n    merged_grib_keys = merge_grib_keys(grib_keys, detected_keys, suggested_keys)\n\n    if 'gridType' not in merged_grib_keys:\n        raise ValueError(\"required grib_key 'gridType' not passed nor auto-detected\")\n\n    template_message = make_template_message(merged_grib_keys, **kwargs)\n\n    coords_names, data_var = expand_dims(data_var)\n\n    header_coords_values = [data_var.coords[name].values.tolist() for name in coords_names]\n    for items in itertools.product(*header_coords_values):\n        select = {n: v for n, v in zip(coords_names, items)}\n        field_values = data_var.sel(**select).values.flat[:]\n\n        # Missing values handling\n        invalid_field_values = np.logical_not(np.isfinite(field_values))\n\n        # There's no need to save a message full of missing values\n        if invalid_field_values.all():\n            continue\n\n        missing_value = merged_grib_keys.get('missingValue', 9999)\n        field_values[invalid_field_values] = missing_value\n\n        message = cfgrib.CfMessage.from_message(template_message)\n        for coord_name, coord_value in zip(coords_names, items):\n            if coord_name in ALL_TYPE_OF_LEVELS:\n                coord_name = 'level'\n            message[coord_name] = coord_value\n\n        # OPTIMIZE: convert to list because Message.message_set doesn't support np.ndarray\n        message['values'] = field_values.tolist()\n\n        message.write(file)", "response": "Write a xr. DataArray in canonical form to a GRIB file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a dataset in canonical form to a GRIB file.", "response": "def canonical_dataset_to_grib(dataset, path, mode='wb', no_warn=False, grib_keys={}, **kwargs):\n    # type: (xr.Dataset, str, str, bool, T.Dict[str, T.Any] T.Any) -> None\n    \"\"\"\n    Write a ``xr.Dataset`` in *canonical* form to a GRIB file.\n    \"\"\"\n    if not no_warn:\n        warnings.warn(\"GRIB write support is experimental, DO NOT RELY ON IT!\", FutureWarning)\n\n    # validate Dataset keys, DataArray names, and attr keys/values\n    xr.backends.api._validate_dataset_names(dataset)\n    xr.backends.api._validate_attrs(dataset)\n\n    real_grib_keys = {k[5:]: v for k, v in dataset.attrs.items() if k[:5] == 'GRIB_'}\n    real_grib_keys.update(grib_keys)\n\n    with open(path, mode=mode) as file:\n        for data_var in dataset.data_vars.values():\n            canonical_dataarray_to_grib(data_var, file, grib_keys=real_grib_keys, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_dataset(path, **kwargs):\n    # type: (str, T.Any) -> xr.Dataset\n    \"\"\"\n    Return a ``xr.Dataset`` with the requested ``backend_kwargs`` from a GRIB file.\n    \"\"\"\n    if 'engine' in kwargs and kwargs['engine'] != 'cfgrib':\n        raise ValueError(\"only engine=='cfgrib' is supported\")\n    kwargs['engine'] = 'cfgrib'\n    return xr.backends.api.open_dataset(path, **kwargs)", "response": "Open a GRIB file and return a xr. Dataset object with the requested backend_kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open_datasets(path, backend_kwargs={}, no_warn=False, **kwargs):\n    # type: (str, T.Dict[str, T.Any], bool, T.Any) -> T.List[xr.Dataset]\n    \"\"\"\n    Open a GRIB file groupping incompatible hypercubes to different datasets via simple heuristics.\n    \"\"\"\n    if not no_warn:\n        warnings.warn(\"open_datasets is an experimental API, DO NOT RELY ON IT!\", FutureWarning)\n\n    fbks = []\n    datasets = []\n    try:\n        datasets.append(open_dataset(path, backend_kwargs=backend_kwargs, **kwargs))\n    except DatasetBuildError as ex:\n        fbks.extend(ex.args[2])\n    # NOTE: the recursive call needs to stay out of the exception handler to avoid showing\n    #   to the user a confusing error message due to exception chaining\n    for fbk in fbks:\n        bks = backend_kwargs.copy()\n        bks['filter_by_keys'] = fbk\n        datasets.extend(open_datasets(path, backend_kwargs=bks, no_warn=True, **kwargs))\n    return datasets", "response": "Open a GRIB file groupping incompatible hypercubes to different datasets via simple heuristics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef codes_get_size(handle, key):\n    # type: (cffi.FFI.CData, str) -> int\n    \"\"\"\n    Get the number of coded value from a key.\n    If several keys of the same name are present, the total sum is returned.\n\n    :param bytes key: the keyword to get the size of\n\n    :rtype: int\n    \"\"\"\n    size = ffi.new('size_t *')\n    _codes_get_size(handle, key.encode(ENC), size)\n    return size[0]", "response": "Get the number of coded value from a key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the length of the string representation of the key.", "response": "def codes_get_string_length(handle, key):\n    # type: (cffi.FFI.CData, str) -> int\n    \"\"\"\n    Get the length of the string representation of the key.\n    If several keys of the same name are present, the maximum length is returned.\n\n    :param bytes key: the keyword to get the string representation size of.\n\n    :rtype: int\n    \"\"\"\n    size = ffi.new('size_t *')\n    _codes_get_length(handle, key.encode(ENC), size)\n    return size[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef codes_get_bytes_array(handle, key, size):\n    # type: (cffi.FFI.CData, str, int) -> T.List[int]\n    \"\"\"\n    Get unsigned chars array values from a key.\n\n    :param bytes key: the keyword whose value(s) are to be extracted\n\n    :rtype: List(int)\n    \"\"\"\n    values = ffi.new('unsigned char[]', size)\n    size_p = ffi.new('size_t *', size)\n    _codes_get_bytes(handle, key.encode(ENC), values, size_p)\n    return list(values)", "response": "Get unsigned chars array values from a key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets long array values from a key.", "response": "def codes_get_long_array(handle, key, size):\n    # type: (cffi.FFI.CData, str, int) -> T.List[int]\n    \"\"\"\n    Get long array values from a key.\n\n    :param bytes key: the keyword whose value(s) are to be extracted\n\n    :rtype: List(int)\n    \"\"\"\n    values = ffi.new('long[]', size)\n    size_p = ffi.new('size_t *', size)\n    _codes_get_long_array(handle, key.encode(ENC), values, size_p)\n    return list(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets double array values from a key.", "response": "def codes_get_double_array(handle, key, size):\n    # type: (cffi.FFI.CData, str, int) -> T.List[float]\n    \"\"\"\n    Get double array values from a key.\n\n    :param bytes key: the keyword whose value(s) are to be extracted\n\n    :rtype: T.List(float)\n    \"\"\"\n    values = ffi.new('double[]', size)\n    size_p = ffi.new('size_t *', size)\n    _codes_get_double_array(handle, key.encode(ENC), values, size_p)\n    return list(values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef codes_get_string_array(handle, key, size, length=None):\n    # type: (cffi.FFI.CData, bytes, int, int) -> T.List[bytes]\n    \"\"\"\n    Get string array values from a key.\n\n    :param bytes key: the keyword whose value(s) are to be extracted\n\n    :rtype: T.List[bytes]\n    \"\"\"\n    if length is None:\n        length = codes_get_string_length(handle, key)\n    values_keepalive = [ffi.new('char[]', length) for _ in range(size)]\n    values = ffi.new('char*[]', values_keepalive)\n    size_p = ffi.new('size_t *', size)\n    _codes_get_string_array(handle, key.encode(ENC), values, size_p)\n    return [ffi.string(values[i]).decode(ENC) for i in range(size_p[0])]", "response": "Get string array values from a key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the last string element from a key.", "response": "def codes_get_string(handle, key, length=None):\n    # type: (cffi.FFI.CData, str, int) -> str\n    \"\"\"\n    Get string element from a key.\n    It may or may not fail in case there are more than one key in a message.\n    Outputs the last element.\n\n    :param bytes key: the keyword to select the value of\n    :param bool strict: flag to select if the method should fail in case of\n        more than one key in single message\n\n    :rtype: bytes\n    \"\"\"\n    if length is None:\n        length = codes_get_string_length(handle, key)\n    values = ffi.new('char[]', length)\n    length_p = ffi.new('size_t *', length)\n    _codes_get_string = check_return(lib.codes_get_string)\n    _codes_get_string(handle, key.encode(ENC), values, length_p)\n    return ffi.string(values, length_p[0]).decode(ENC)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the API version.", "response": "def codes_get_api_version():\n    \"\"\"\n    Get the API version.\n\n    Returns the version of the API as a string in the format \"major.minor.revision\".\n    \"\"\"\n    ver = lib.codes_get_api_version()\n    patch = ver % 100\n    ver = ver // 100\n    minor = ver % 100\n    major = ver // 100\n\n    return \"%d.%d.%d\" % (major, minor, patch)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef codes_write(handle, outfile):\n    # type: (cffi.FFI.CData, T.BinaryIO) -> None\n    \"\"\"\n    Write a coded message to a file. If the file does not exist, it is created.\n\n    :param str path: (optional) the path to the GRIB file;\n        defaults to the one of the open index.\n    \"\"\"\n    mess = ffi.new('const void **')\n    mess_len = ffi.new('size_t*')\n    codes_get_message = check_return(lib.codes_get_message)\n    codes_get_message(handle, mess, mess_len)\n    message = ffi.buffer(mess[0], size=mess_len[0])\n    outfile.write(message)", "response": "Writes a coded message to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if an object is iterable.", "response": "def is_iterable(obj):\n    \"\"\"\n    Are we being asked to look up a list of things, instead of a single thing?\n    We check for the `__iter__` attribute so that this can cover types that\n    don't have to be known by this module, such as NumPy arrays.\n\n    Strings, however, should be considered as atomic values to look up, not\n    iterables. The same goes for tuples, since they are immutable and therefore\n    valid entries.\n\n    We don't need to check for the Python 2 `unicode` type, because it doesn't\n    have an `__iter__` attribute anyway.\n    \"\"\"\n    return (\n        hasattr(obj, \"__iter__\")\n        and not isinstance(obj, str)\n        and not isinstance(obj, tuple)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, sequence):\n        item_index = None\n        try:\n            for item in sequence:\n                item_index = self.add(item)\n        except TypeError:\n            raise ValueError(\n                \"Argument needs to be an iterable, got %s\" % type(sequence)\n            )\n        return item_index", "response": "Update the set with the given iterable sequence and return the index of the last element inserted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves and return the last element from the set. Raises KeyError if the set is empty.", "response": "def pop(self):\n        \"\"\"\n        Remove and return the last element from the set.\n\n        Raises KeyError if the set is empty.\n\n        Example:\n            >>> oset = OrderedSet([1, 2, 3])\n            >>> oset.pop()\n            3\n        \"\"\"\n        if not self.items:\n            raise KeyError(\"Set is empty\")\n\n        elem = self.items[-1]\n        del self.items[-1]\n        del self.map[elem]\n        return elem"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncombines all unique items.", "response": "def union(self, *sets):\n        \"\"\"\n        Combines all unique items.\n        Each items order is defined by its first appearance.\n\n        Example:\n            >>> oset = OrderedSet.union(OrderedSet([3, 1, 4, 1, 5]), [1, 3], [2, 0])\n            >>> print(oset)\n            OrderedSet([3, 1, 4, 5, 2, 0])\n            >>> oset.union([8, 9])\n            OrderedSet([3, 1, 4, 5, 2, 0, 8, 9])\n            >>> oset | {10}\n            OrderedSet([3, 1, 4, 5, 2, 0, 10])\n        \"\"\"\n        cls = self.__class__ if isinstance(self, OrderedSet) else OrderedSet\n        containers = map(list, it.chain([self], sets))\n        items = it.chain.from_iterable(containers)\n        return cls(items)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn elements in common between all sets.", "response": "def intersection(self, *sets):\n        \"\"\"\n        Returns elements in common between all sets. Order is defined only\n        by the first set.\n\n        Example:\n            >>> oset = OrderedSet.intersection(OrderedSet([0, 1, 2, 3]), [1, 2, 3])\n            >>> print(oset)\n            OrderedSet([1, 2, 3])\n            >>> oset.intersection([2, 4, 5], [1, 2, 3, 4])\n            OrderedSet([2])\n            >>> oset.intersection()\n            OrderedSet([1, 2, 3])\n        \"\"\"\n        cls = self.__class__ if isinstance(self, OrderedSet) else OrderedSet\n        if sets:\n            common = set.intersection(*map(set, sets))\n            items = (item for item in self if item in common)\n        else:\n            items = self\n        return cls(items)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef difference(self, *sets):\n        cls = self.__class__\n        if sets:\n            other = set.union(*map(set, sets))\n            items = (item for item in self if item not in other)\n        else:\n            items = self\n        return cls(items)", "response": "Returns all elements that are in this set but not the others."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef issubset(self, other):\n        if len(self) > len(other):  # Fast check for obvious cases\n            return False\n        return all(item in other for item in self)", "response": "Report whether this set contains another set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef issuperset(self, other):\n        if len(self) < len(other):  # Fast check for obvious cases\n            return False\n        return all(item in self for item in other)", "response": "Report whether this set contains another set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef symmetric_difference(self, other):\n        cls = self.__class__ if isinstance(self, OrderedSet) else OrderedSet\n        diff1 = cls(self).difference(other)\n        diff2 = cls(other).difference(self)\n        return diff1.union(diff2)", "response": "Return the symmetric difference of two OrderedSets as a new set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_items(self, items):\n        self.items = items\n        self.map = {item: idx for (idx, item) in enumerate(items)}", "response": "Update the items list of this OrderedSet with a new one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef difference_update(self, *sets):\n        items_to_remove = set()\n        for other in sets:\n            items_to_remove |= set(other)\n        self._update_items([item for item in self.items if item not in items_to_remove])", "response": "Update this OrderedSet to remove items from one or more other sets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating this OrderedSet to keep only items in another set preserving their order in this set.", "response": "def intersection_update(self, other):\n        \"\"\"\n        Update this OrderedSet to keep only items in another set, preserving\n        their order in this set.\n\n        Example:\n            >>> this = OrderedSet([1, 4, 3, 5, 7])\n            >>> other = OrderedSet([9, 7, 1, 3, 2])\n            >>> this.intersection_update(other)\n            >>> print(this)\n            OrderedSet([1, 3, 7])\n        \"\"\"\n        other = set(other)\n        self._update_items([item for item in self.items if item in other])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef symmetric_difference_update(self, other):\n        items_to_add = [item for item in other if item not in self]\n        items_to_remove = set(other)\n        self._update_items(\n            [item for item in self.items if item not in items_to_remove] + items_to_add\n        )", "response": "Update this OrderedSet to remove items from other set then add items from this set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise an exception if there was an error. Otherwise do nothing.", "response": "def validate_response(self):\n        \"\"\"Raises an exception if there was an error. Otherwise, do nothing.\n\n        Clients should handle these errors, since these require custom handling\n        to properly resolve.\n        \"\"\"\n        if self.is_success():\n            return\n\n        # Handle the error if we have any information\n        if self.details:\n            error = self.details.get('error', None)\n\n            if error == PushResponse.ERROR_DEVICE_NOT_REGISTERED:\n                raise DeviceNotRegisteredError(self)\n            elif error == PushResponse.ERROR_MESSAGE_TOO_BIG:\n                raise MessageTooBigError(self)\n            elif error == PushResponse.ERROR_MESSAGE_RATE_EXCEEDED:\n                raise MessageRateExceededError(self)\n\n        # No known error information, so let's raise a generic error.\n        raise PushResponseError(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_exponent_push_token(cls, token):\n        import six\n\n        return (\n            isinstance(token, six.string_types) and\n            token.startswith('ExponentPushToken'))", "response": "Returns True if the token is an Exponent push token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending push notifications to the server and return the unique ID of the message.", "response": "def _publish_internal(self, push_messages):\n        \"\"\"Send push notifications\n\n        The server will validate any type of syntax errors and the client will\n        raise the proper exceptions for the user to handle.\n\n        Each notification is of the form:\n        {\n          'to': 'ExponentPushToken[xxx]',\n          'body': 'This text gets display in the notification',\n          'badge': 1,\n          'data': {'any': 'json object'},\n        }\n\n        Args:\n            push_messages: An array of PushMessage objects.\n        \"\"\"\n        # Delayed import because this file is immediately read on install, and\n        # the requests library may not be installed yet.\n        import requests\n\n        response = requests.post(\n            self.host + self.api_url + '/push/send',\n            data=json.dumps([pm.get_payload() for pm in push_messages]),\n            headers={\n                'accept': 'application/json',\n                'accept-encoding': 'gzip, deflate',\n                'content-type': 'application/json',\n            }\n        )\n\n        # Let's validate the response format first.\n        try:\n            response_data = response.json()\n        except ValueError:\n            # The response isn't json. First, let's attempt to raise a normal\n            # http error. If it's a 200, then we'll raise our own error.\n            response.raise_for_status()\n\n            raise PushServerError('Invalid server response', response)\n\n        # If there are errors with the entire request, raise an error now.\n        if 'errors' in response_data:\n            raise PushServerError(\n                'Request failed',\n                response,\n                response_data=response_data,\n                errors=response_data['errors'])\n\n        # We expect the response to have a 'data' field with the responses.\n        if 'data' not in response_data:\n            raise PushServerError(\n                'Invalid server response',\n                response,\n                response_data=response_data)\n\n        # Use the requests library's built-in exceptions for any remaining 4xx\n        # and 5xx errors.\n        response.raise_for_status()\n\n        # Sanity check the response\n        if len(push_messages) != len(response_data['data']):\n            raise PushServerError(\n                ('Mismatched response length. Expected %d %s but only '\n                 'received %d' % (\n                     len(push_messages),\n                     'receipt' if len(push_messages) == 1 else 'receipts',\n                     len(response_data['data']))),\n                response,\n                response_data=response_data)\n\n        # At this point, we know it's a 200 and the response format is correct.\n        # Now let's parse the responses per push notification.\n        receipts = []\n        for i, receipt in enumerate(response_data['data']):\n            receipts.append(PushResponse(\n                push_message=push_messages[i],\n                # If there is no status, assume error.\n                status=receipt.get('status', PushResponse.ERROR_STATUS),\n                message=receipt.get('message', ''),\n                details=receipt.get('details', None)))\n\n        return receipts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_line(line, sep=os.linesep):\n\n    try:\n        return line.strip(sep)\n    except TypeError:\n        return line.decode('utf-8').strip(sep)", "response": "Removes occurrence of character sep from a line of text\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string buffer for key - value pairs and returns a dictionary containing all the keys and values for that key.", "response": "def get_dict_from_buffer(buf, keys=['DISTNAME', 'MAJOR',\n                                    'MINOR', 'PATCHLEVEL',\n                                    'PYTHON',\n                                    'MIN_PYTHON_MAJOR',\n                                    'MIN_PYTHON_MINOR',\n                                    'MIN_NUMPY_MAJOR',\n                                    'MIN_NUMPY_MINOR']):\n    \"\"\"\n    Parses a string buffer for key-val pairs for the supplied keys.\n\n    Returns: Python dictionary with all the keys (all keys in buffer\n             if None is passed for keys) with the values being a list\n             corresponding to each key.\n    \n    Note: Return dict will contain all keys supplied (if not None).\n          If any key was not found in the buffer, then the value for\n          that key will be [] such that dict[key] does not produce\n          a KeyError.\n\n    Slightly modified from:\n    \"http://stackoverflow.com/questions/5323703/regex-how-to-\"\\\n    \"match-sequence-of-key-value-pairs-at-end-of-string\n\n    \"\"\"\n\n\n    pairs = dict()\n    if keys is None:\n        keys = \"\\S+\"\n        regex = re.compile(r'''\n        \\n            # all key-value pairs are on separate lines\n        \\s*           # there might be some leading spaces\n        (             # start group to return\n        (?:{0}\\s*)    # placeholder for tags to detect '\\S+' == all\n        \\s*:*=\\s*     # optional spaces, optional colon, = , optional spaces\n        .*            # the value\n        )             # end group to return\n        '''.format(keys), re.VERBOSE)\n        validate = False\n    else:\n        keys = [k.strip() for k in keys]\n        regex = re.compile(r'''\n        \\n            # all key-value pairs are on separate lines\n        \\s*           # there might be some leading spaces\n        (             # start group to return\n        (?:{0}\\s*)    # placeholder for tags to detect '\\S+' == all\n        \\s*:*=\\s*     # optional spaces, optional colon, = , optional spaces\n        .*            # the value\n        )             # end group to return\n        '''.format('|'.join(keys)), re.VERBOSE)\n        validate = True\n        for k in keys:\n            pairs[k] = []\n\n    matches = regex.findall(buf)\n    for match in matches:\n        key, val = match.split('=', 1)\n\n        # remove colon and leading/trailing whitespace from key\n        key = (strip_line(key, ':')).strip()\n\n        # remove newline and leading/trailing whitespace from value\n        val = (strip_line(val)).strip()\n        if validate and key not in keys:\n            msg = \"regex produced incorrect match. regex pattern = {0} \"\\\n                  \"claims key = [{1}] while original set of search keys \"\\\n                  \"= {2}\".format(regex.pattern, key, '|'.join(keys))\n            raise AssertionError(msg)\n        pairs.setdefault(key, []).append(val)\n\n    return pairs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing first line in buf matching key with replacement. Optionally writes out this new buffer into outfile.", "response": "def replace_first_key_in_makefile(buf, key, replacement, outfile=None):\n    '''\n    Replaces first line in 'buf' matching 'key' with 'replacement'.\n    Optionally, writes out this new buffer into 'outfile'.\n\n    Returns: Buffer after replacement has been done\n    '''\n\n    regexp = re.compile(r'''\n    \\n\\s*           # there might be some leading spaces\n    (               # start group to return\n    (?:{0}\\s*)      # placeholder for tags to detect '\\S+' == all\n    \\s*:*=\\s*       # optional spaces, optional colon, = , optional spaces\n    .*              # the value\n    )               # end group to return\n    '''.format(key), re.VERBOSE)\n    matches = regexp.findall(buf)\n    if matches is None:\n        msg = \"Could not find key = {0} in the provided buffer. \"\\\n              \"Pattern used = {1}\".format(key, regexp.pattern)\n        raise ValueError(msg)\n\n    # Only replace the first occurence\n    newbuf = regexp.sub(replacement, buf, count=1)\n    if outfile is not None:\n        write_text_file(outfile, newbuf)\n\n    return newbuf"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_packages():\n    '''\n    Custom setup for Corrfunc package.\n\n    Optional: Set compiler via 'CC=/path/to/compiler' or\n              'CC /path/to/compiler' or 'CC = /path/to/compiler'\n              All the CC options are removed from sys.argv after\n              being parsed.\n    '''\n\n    # protect the user in case they run python setup.py not from root directory\n    src_path = dirname(abspath(sys.argv[0]))\n    old_path = os.getcwd()\n    os.chdir(src_path)\n    sys.path.insert(0, src_path)\n\n    # create a list of the python extensions\n    python_dirs = [\"theory/python_bindings\",\n                   \"mocks/python_bindings\"]\n    extensions = generate_extensions(python_dirs)\n\n    # check requirement for extensions and set the compiler if specified\n    # in command-line\n    common_dict = requirements_check()\n\n    # Some command options require headers/libs to be generated\n    # so that the following dirs_patters supplies them.\n    if install_required():\n        from distutils.sysconfig import get_config_var\n        if get_config_var('SHLIB_EXT') != '\".so\"' and version_info[0] == 2:\n            msg = \"The extensions all get the `.so` automatically. \"\\\n                  \"However, python expects the extension to be `{0}`\"\\\n                  .format(get_config_var('SHLIB_EXT'))\n            raise ValueError(msg)\n        \n        # global variable compiler is set if passed in\n        # command-line\n        extra_string = ''\n        if compiler != '':\n            extra_string = 'CC={0}'.format(compiler)\n\n        command = \"make libs {0}\".format(extra_string)\n        run_command(command)\n        \n    else:\n        # not installing. Check if creating source distribution\n        # in that case run distclean to delete auto-generated C\n        # files\n        if 'sdist' in sys.argv:\n            command = \"make distclean\"\n            run_command(command)\n            \n\n    # find all the data-files required.\n    # Now the lib + associated header files have been generated\n    # and put in lib/ and include/\n    # This step must run after ``make install``\n    dirs_patterns = {'theory/tests/data': ['*.ff', '*.txt',\n                                              '*.txt.gz', '*.dat'],\n                     'mocks/tests/data': ['*.ff', '*.txt',\n                                             '*.txt.gz', '*.dat'],\n                     'theory/tests': ['Mr19*', 'bins*', 'cmass*'],\n                     'mocks/tests': ['Mr19*', 'bins*', 'angular_bins*'],\n                     'include': ['count*.h'],\n                     'lib': ['libcount*.a']\n                     }\n    data_files = []\n    for d in dirs_patterns:\n        patterns = dirs_patterns[d]\n        f = recursive_glob(d, patterns)\n        data_files.extend(f)\n\n    # change them to be relative to package dir rather than root\n    data_files = [\"../{0}\".format(d) for d in data_files]\n    long_description = read_text_file('README.rst')\n    min_np_major = int(common_dict['MIN_NUMPY_MAJOR'][0])\n    min_np_minor = int(common_dict['MIN_NUMPY_MINOR'][0])\n\n    # All book-keeping is done.\n    # base_url = \"https://github.com/manodeep/Corrfunc\"\n    classifiers = ['Development Status :: 4 - Beta',\n                   'Intended Audience :: Developers',\n                   'Intended Audience :: Science/Research',\n                   'License :: OSI Approved :: MIT License',\n                   'Natural Language :: English',\n                   'Operating System :: POSIX',\n                   'Programming Language :: C',\n                   'Programming Language :: Python',\n                   'Programming Language :: Python :: 2',\n                   'Programming Language :: Python :: 2.7',\n                   'Programming Language :: Python :: 3',\n                   'Programming Language :: Python :: 3.4',\n                   'Programming Language :: Python :: 3.5',\n                   'Programming Language :: Python :: 3.6']\n    metadata = dict(\n            name=projectname,\n            version=version,\n            author='Manodeep Sinha',\n            author_email='manodeep@gmail.com',\n            maintainer='Manodeep Sinha',\n            maintainer_email='manodeep@gmail.com',\n            url=base_url,\n            download_url='{0}/archive/{1}-{2}.tar.gz'.format(\n                    base_url, projectname, version),\n            description='Blazing fast correlation functions on the CPU',\n            long_description=long_description,\n            classifiers=classifiers,\n            license='MIT',\n            # Solaris might work, Windows will almost certainly not work\n            platforms=[\"Linux\", \"Mac OSX\", \"Unix\"],\n            keywords=['correlation functions', 'simulations',\n                      'surveys', 'galaxies'],\n            provides=[projectname],\n            packages=find_packages(),\n            ext_package=projectname,\n            ext_modules=extensions,\n            package_data={'': data_files},\n            include_package_data=True,\n            setup_requires=['setuptools',\n                            'numpy>={0}.{1}'.format(min_np_major,\n                                                    min_np_minor)],\n            install_requires=['numpy>={0}.{1}'.format(min_np_major,\n                                                      min_np_minor),\n                              'future',\n                              'wurlitzer'],\n            python_requires='>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4',\n            zip_safe=False,\n            cmdclass={'build_ext': BuildExtSubclass})\n\n    # Now the actual setup\n    try:\n        setup(**metadata)\n    finally:\n        del sys.path[0]\n        os.chdir(old_path)\n\n    return", "response": "Custom setup for Corrfunc package."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a file under python3 with encoding encoding.", "response": "def read_text_file(filename, encoding=\"utf-8\"):\n    \"\"\"\n    Reads a file under python3 with encoding (default UTF-8).\n    Also works under python2, without encoding.\n    Uses the EAFP (https://docs.python.org/2/glossary.html#term-eafp)\n    principle.\n    \"\"\"\n    try:\n        with open(filename, 'r', encoding) as f:\n            r = f.read()\n    except TypeError:\n        with open(filename, 'r') as f:\n            r = f.read()\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stderr_redirected(to=os.devnull):\n    fd = sys.stderr.fileno()\n\n    # assert that Python and C stdio write using the same file descriptor\n    # assert libc.fileno(ctypes.c_void_p.in_dll(libc, \"stderr\")) == fd == 1\n    \n    def _redirect_stderr(to):\n        sys.stderr.close()  # + implicit flush()\n        os.dup2(to.fileno(), fd)  # fd writes to 'to' file\n        sys.stderr = os.fdopen(fd, 'w')  # Python writes to fd\n\n    with os.fdopen(os.dup(fd), 'w') as old_stderr:\n        with open(to, 'w') as file:\n            _redirect_stderr(to=file)\n        try:\n            yield  # allow code to be run with the redirected stderr\n        finally:\n            _redirect_stderr(to=old_stderr)", "response": "A context manager that redirects stderr to the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading in the file filename and returns a numpy array of the timings.", "response": "def read_file(filename):\n    \"\"\"\n    Reads in the file I created manually (by recompiling and adding timers)\n    \n    Not used any more but left for historical reasons (the first 'speedup'\n    plots were generated with this function)\n    \"\"\"\n    dtype = np.dtype([('same_cell', np.int32),\n                      ('N1', np.int),\n                      ('N2', np.int),\n                      ('time', np.float)\n                      ])\n    if pd is not None:\n        timings = pd.read_csv(filename, header=None,\n                              engine=\"c\",\n                              dtype={'same_cell': np.int32,\n                                     'N1': np.int,\n                                     'N2': np.int,\n                                     'time': np.float},\n                              index_col=None,\n                              names=['same_cell', 'N1', 'N2', 'time'],\n                              delim_whitespace=True)\n    else:\n        timings = np.loadtxt(filename, dtype=dtype)\n    return timings"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef settings_to_cmd_args(settings_dict):\n    args = ['mysql']\n    db = settings_dict['OPTIONS'].get('db', settings_dict['NAME'])\n    user = settings_dict['OPTIONS'].get('user', settings_dict['USER'])\n    passwd = settings_dict['OPTIONS'].get('passwd', settings_dict['PASSWORD'])\n    host = settings_dict['OPTIONS'].get('host', settings_dict['HOST'])\n    port = settings_dict['OPTIONS'].get('port', settings_dict['PORT'])\n    cert = settings_dict['OPTIONS'].get('ssl', {}).get('ca')\n    defaults_file = settings_dict['OPTIONS'].get('read_default_file')\n    # Seems to be no good way to set sql_mode with CLI.\n\n    if defaults_file:\n        args += [\"--defaults-file=%s\" % defaults_file]\n    if user:\n        args += [\"--user=%s\" % user]\n    if passwd:\n        args += [\"--password=%s\" % passwd]\n    if host:\n        if '/' in host:\n            args += [\"--socket=%s\" % host]\n        else:\n            args += [\"--host=%s\" % host]\n    if port:\n        args += [\"--port=%s\" % port]\n    if cert:\n        args += [\"--ssl-ca=%s\" % cert]\n    if db:\n        args += [db]\n    return args", "response": "Converts django settings dictionary to a list of commandline arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a query and returns its fingerprint", "response": "def pt_fingerprint(query):\n    \"\"\"\n    Takes a query (in a string) and returns its 'fingerprint'\n    \"\"\"\n    if not have_program('pt-fingerprint'):  # pragma: no cover\n        raise OSError(\"pt-fingerprint doesn't appear to be installed\")\n\n    thread = PTFingerprintThread.get_thread()\n    thread.in_queue.put(query)\n    return thread.out_queue.get()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name of the index that exists on field_names.", "response": "def index_name(model, *field_names, **kwargs):\n    \"\"\"\n    Returns the name of the index existing on field_names, or raises KeyError\n    if no such index exists.\n    \"\"\"\n    if not len(field_names):\n        raise ValueError(\"At least one field name required\")\n    using = kwargs.pop('using', DEFAULT_DB_ALIAS)\n    if len(kwargs):\n        raise ValueError(\"The only supported keyword argument is 'using'\")\n\n    existing_fields = {field.name: field for field in model._meta.fields}\n    fields = [existing_fields[name] for name in field_names\n              if name in existing_fields]\n\n    if len(fields) != len(field_names):\n        unfound_names = set(field_names) - {field.name for field in fields}\n        raise ValueError(\"Fields do not exist: \" + \",\".join(unfound_names))\n    column_names = tuple(field.column for field in fields)\n    list_sql = get_list_sql(column_names)\n\n    with connections[using].cursor() as cursor:\n        cursor.execute(\n            \"\"\"SELECT `INDEX_NAME`, `SEQ_IN_INDEX`, `COLUMN_NAME`\n               FROM INFORMATION_SCHEMA.STATISTICS\n               WHERE TABLE_SCHEMA = DATABASE() AND\n                     TABLE_NAME = %s AND\n                     COLUMN_NAME IN {list_sql}\n               ORDER BY `INDEX_NAME`, `SEQ_IN_INDEX` ASC\n            \"\"\".format(list_sql=list_sql),\n            (model._meta.db_table,) + column_names,\n        )\n        indexes = defaultdict(list)\n        for index_name, _, column_name in cursor.fetchall():\n            indexes[index_name].append(column_name)\n\n    indexes_by_columns = {tuple(v): k for k, v in indexes.items()}\n    try:\n        return indexes_by_columns[column_names]\n    except KeyError:\n        raise KeyError(\"There is no index on (\" + \",\".join(field_names) + \")\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the weighted average rate of the record set based on the average rate of the record set.", "response": "def update(self, n, t):\n        \"\"\"\n        Update weighted average rate.  Param n is generic; it's how many of\n        whatever the caller is doing (rows, checksums, etc.).  Param s is how\n        long this n took, in seconds (hi-res or not).\n\n        Parameters:\n            n - Number of operations (rows, etc.)\n            t - Amount of time in seconds that n took\n\n        Returns:\n            n adjusted to meet target_t based on weighted decaying avg rate\n        \"\"\"\n        if self.avg_n and self.avg_t:\n            self.avg_n = (self.avg_n * self.weight) + n\n            self.avg_t = (self.avg_t * self.weight) + t\n        else:\n            self.avg_n = n\n            self.avg_t = t\n\n        new_n = int(self.avg_rate * self.target_t)\n        return new_n"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify_sql(sql, add_comments, add_hints, add_index_hints):\n    match = query_start_re.match(sql)\n    if not match:\n        # We don't understand what kind of query this is, don't rewrite it\n        return sql\n\n    tokens = [match.group('keyword')]\n    comments = match.group('comments').strip()\n    if comments:\n        tokens.append(comments)\n\n    # Inject comments after all existing comments\n    for comment in add_comments:\n        tokens.append('/*{}*/'.format(comment))\n\n    # Don't bother with SELECT rewrite rules on non-SELECT queries\n    if tokens[0] == \"SELECT\":\n\n        for group_name, hint_set in SELECT_HINTS.items():\n\n            try:\n                # Take the last hint we were told to add from this hint_set\n                to_add = [hint for hint in add_hints if hint in hint_set][-1]\n                tokens.append(to_add)\n            except IndexError:\n                # We weren't told to add any, so just add any hint from this\n                # set that was already there\n                existing = match.group(group_name)\n                if existing is not None:\n                    tokens.append(existing.rstrip())\n\n    # Maybe rewrite the remainder of the statement for index hints\n    remainder = sql[match.end():]\n\n    if tokens[0] == \"SELECT\" and add_index_hints:\n        for index_hint in add_index_hints:\n            remainder = modify_sql_index_hints(remainder, *index_hint)\n\n    # Join everything\n    tokens.append(remainder)\n    return ' '.join(tokens)", "response": "Parse the SQL statement and modify the SQL structure of the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreverse of Django s default_key_func i. e. undoing", "response": "def default_reverse_key_func(full_key):\n    \"\"\"\n    Reverse of Django's default_key_func, i.e. undoing:\n\n        def default_key_func(key, key_prefix, version):\n            return '%s:%s:%s' % (key_prefix, version, key)\n    \"\"\"\n    match = reverse_key_re.match(full_key)\n    return match.group(3), match.group(1), int(match.group(2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_key(self, key):\n        if len(key) > 250:\n            raise ValueError(\n                \"Cache key is longer than the maxmimum 250 characters: {}\"\n                .format(key),\n            )\n        return super(MySQLCache, self).validate_key(key)", "response": "Validate that the key is a valid MySQL key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(self, obj):\n        if self._is_valid_mysql_bigint(obj):\n            return obj, 'i'\n\n        value = pickle.dumps(obj, pickle.HIGHEST_PROTOCOL)\n        value_type = 'p'\n        if (\n            self._compress_min_length\n            and len(value) >= self._compress_min_length\n        ):\n            value = zlib.compress(value, self._compress_level)\n            value_type = 'z'\n        return value, value_type", "response": "Takes a Python object and return it as a tuple value value_type blob and one - char code for what type it is."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a value blob and its value_type one - char code and convert it back to a python object.", "response": "def decode(self, value, value_type):\n        \"\"\"\n        Take a value blob and its value_type one-char code and convert it back\n        to a python object\n        \"\"\"\n        if value_type == 'i':\n            return int(value)\n\n        if value_type == 'z':\n            value = zlib.decompress(value)\n            value_type = 'p'\n\n        if value_type == 'p':\n            return pickle.loads(force_bytes(value))\n\n        raise ValueError(\n            \"Unknown value_type '{}' read from the cache table.\"\n            .format(value_type),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef label(self, string):\n        if '*/' in string:\n            raise ValueError(\"Bad label - cannot be embedded in SQL comment\")\n        return self.extra(where=[\"/*QueryRewrite':label={}*/1\".format(string)])", "response": "Adds an arbitrary user - defined comment that will appear after the query was\n        generated and will be used to identify where the query was was\n        generated etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_index_value(self, kwargs):\n        if len(kwargs) == 0:\n            return None, None\n        elif len(kwargs) > 1:\n            raise ValueError(\"You can't pass more than one value expression, \"\n                             \"you passed {}\".format(\",\".join(kwargs.keys())))\n\n        name, value = list(kwargs.items())[0]\n\n        if not name.startswith('value'):\n            raise ValueError(\"The keyword arg {} is not valid for this \"\n                             \"function\".format(name))\n\n        if name == 'value':\n            return ('=', value)\n\n        if not name.startswith('value__'):\n            raise ValueError(\"The keyword arg {} is not valid for this \"\n                             \"function\".format(name))\n\n        operator = name[name.find('__') + 2:]\n        try:\n            return (self._operator_values[operator], value)\n        except KeyError:\n            raise ValueError(\n                \"The operator {op} is not valid for index value matching. \"\n                \"Valid operators are {valid}\"\n                .format(\n                    op=operator,\n                    valid=\",\".join(self._operator_values.keys()),\n                ),\n            )", "response": "Parse the HANDLER - supported subset of django s __ expression syntax"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the WHERE clause from the ORM output so we can use it in a HANDLER queries.", "response": "def _extract_where(cls, queryset):\n        \"\"\"\n        Was this a queryset with filters/excludes/expressions set? If so,\n        extract the WHERE clause from the ORM output so we can use it in the\n        handler queries.\n        \"\"\"\n        if not cls._is_simple_query(queryset.query):\n            raise ValueError(\"This QuerySet's WHERE clause is too complex to \"\n                             \"be used in a HANDLER\")\n\n        sql, params = queryset.query.sql_with_params()\n        where_pos = sql.find('WHERE ')\n        if where_pos != -1:\n            # Cut the query to extract just its WHERE clause\n            where_clause = sql[where_pos:]\n            # Replace absolute table.column references with relative ones\n            # since that is all HANDLER can work with\n            # This is a bit flakey - if you inserted extra SQL with extra() or\n            # an expression or something it might break.\n            where_clause, _ = cls.absolute_col_re.subn(r\"\\1\", where_clause)\n            return (where_clause, params)\n        else:\n            return (\"\", ())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_simple_query(cls, query):\n        return (\n            not query.low_mark\n            and not query.high_mark\n            and not query.select\n            and not query.group_by\n            and not query.distinct\n            and not query.order_by\n            and len(query.alias_map) <= 1\n        )", "response": "Check if the query is a simple query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit output of SHOW CREATE TABLE into column_types", "response": "def parse_create_table(sql):\n    \"\"\"\n    Split output of SHOW CREATE TABLE into {column: column_spec}\n    \"\"\"\n    column_types = {}\n    for line in sql.splitlines()[1:]:  # first line = CREATE TABLE\n        sline = line.strip()\n\n        if not sline.startswith('`'):\n            # We've finished parsing the columns\n            break\n\n        bits = sline.split('`')\n        assert len(bits) == 3\n        column_name = bits[1]\n        column_spec = bits[2].lstrip().rstrip(',')\n\n        column_types[column_name] = column_spec\n    return column_types"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_names(self, names):\n        if names is None:\n            return []\n\n        table_names = OrderedDict()  # Preserve order and ignore duplicates\n        while len(names):\n            name = names.pop(0)\n            if hasattr(name, '_meta'):\n                if name._meta.abstract:\n                    raise ValueError(\"Can't lock abstract model {}\"\n                                     .format(name.__name__))\n\n                table_names[name._meta.db_table] = True\n                # Include all parent models - the keys are the model classes\n                if name._meta.parents:\n                    names.extend(name._meta.parents.keys())\n            else:\n                table_names[name] = True\n        return table_names.keys()", "response": "Convert a list of models or tables into a list of table names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator which yields all frames from the animation sequence for the given sequence.", "response": "def animate(self, seq_name):\n        \"\"\"\n        Returns a generator which \"executes\" an animation sequence for the given\n        ``seq_name``, inasmuch as the next frame for the given animation is\n        yielded when requested.\n\n        :param seq_name: The name of a previously defined animation sequence.\n        :type seq_name: str\n        :returns: A generator that yields all frames from the animation\n            sequence.\n        :raises AttributeError: If the ``seq_name`` is unknown.\n        \"\"\"\n        while True:\n            index = 0\n            anim = getattr(self.animations, seq_name)\n            speed = anim.speed if hasattr(anim, \"speed\") else 1\n            num_frames = len(anim.frames)\n            while index < num_frames:\n                frame = anim.frames[int(index)]\n                index += speed\n\n                if isinstance(frame, int):\n                    yield self[frame]\n                else:\n                    for subseq_frame in self.animate(frame):\n                        yield subseq_frame\n\n            if not hasattr(anim, \"next\"):\n                break\n\n            seq_name = anim.next"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the effective frame rate for a specific no - atom set.", "response": "def effective_FPS(self):\n        \"\"\"\n        Calculates the effective frames-per-second - this should largely\n        correlate to the desired FPS supplied in the constructor, but no\n        guarantees are given.\n\n        :returns: The effective frame rate.\n        :rtype: float\n        \"\"\"\n        if self.start_time is None:\n            self.start_time = 0\n        elapsed = monotonic() - self.start_time\n        return self.called / elapsed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an image cropped to the boundaries specified by size.", "response": "def image(self, size):\n        \"\"\"\n        :param size: The width, height of the image composition.\n        :type size: tuple\n        :returns: An image, cropped to the boundaries specified\n            by ``size``.\n        :rtype: PIL.Image.Image\n        \"\"\"\n        assert(size[0])\n        assert(size[1])\n        return self._image.crop(box=self._crop_box(size))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrefreshing the background image of all the images in the current calendar.", "response": "def refresh(self):\n        \"\"\"\n        Clears the composition and renders all the images\n        taking into account their position and offset.\n        \"\"\"\n        self._clear()\n        for img in self.composed_images:\n            self._background_image.paste(img.image(self._device.size),\n                                         img.position)\n        self._background_image.crop(box=self._device.bounding_box)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clear(self):\n        draw = ImageDraw.Draw(self._background_image)\n        draw.rectangle(self._device.bounding_box,\n                       fill=\"black\")\n        del draw", "response": "Helper that clears the composition."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef redraw_required(self, image):\n        self.bounding_box = ImageChops.difference(self.image, image).getbbox()\n        if self.bounding_box is not None:\n            self.image = image.copy()\n            return True\n        else:\n            return False", "response": "Determines if a redraw is required for the current image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inflate_bbox(self):\n        left, top, right, bottom = self.bounding_box\n        self.bounding_box = (\n            left & 0xFFFC,\n            top,\n            right if right % 4 == 0 else (right & 0xFFFC) + 0x04,\n            bottom)\n\n        return self.bounding_box", "response": "Inflate the left and right edges of the bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the image data for the current entry point.", "response": "def getdata(self):\n        \"\"\"\n        A sequence of pixel data relating to the changes that occurred\n        since the last time :py:func:`redraw_required` was last called.\n\n        :returns: A sequence of pixels or ``None``.\n        :rtype: iterable\n        \"\"\"\n        if self.bounding_box:\n            return self.image.crop(self.bounding_box).getdata()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the bounding box of the entity at the given xy.", "response": "def calc_bounds(xy, entity):\n    \"\"\"\n    For an entity with width and height attributes, determine\n    the bounding box if were positioned at ``(x, y)``.\n    \"\"\"\n    left, top = xy\n    right, bottom = left + entity.width, top + entity.height\n    return [left, top, right, bottom]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_hotspot(self, hotspot, xy):\n        (x, y) = xy\n        assert(0 <= x <= self.width - hotspot.width)\n        assert(0 <= y <= self.height - hotspot.height)\n\n        # TODO: should it check to see whether hotspots overlap each other?\n        # Is sensible to _allow_ them to overlap?\n        self._hotspots.append((hotspot, xy))", "response": "Add the hotspot at x y."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the specified hotspot at the specified xy.", "response": "def remove_hotspot(self, hotspot, xy):\n        \"\"\"\n        Remove the hotspot at ``(x, y)``: Any previously rendered image where\n        the hotspot was placed is erased from the backing image, and will be\n        \"undrawn\" the next time the virtual device is refreshed. If the\n        specified hotspot is not found for ``(x, y)``, a ``ValueError`` is\n        raised.\n        \"\"\"\n        self._hotspots.remove((hotspot, xy))\n        eraser = Image.new(self.mode, hotspot.size)\n        self._backing_image.paste(eraser, xy)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_overlapping_viewport(self, hotspot, xy):\n        l1, t1, r1, b1 = calc_bounds(xy, hotspot)\n        l2, t2, r2, b2 = calc_bounds(self._position, self._device)\n        return range_overlap(l1, r1, l2, r2) and range_overlap(t1, b1, t2, b2)", "response": "Checks to see if the viewport is at least partially visible according to the hotspot at position xy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self):\n        self._cx, self._cy = (0, 0)\n        self._canvas.rectangle(self._device.bounding_box,\n                               fill=self.default_bgcolor)\n        self.flush()", "response": "Clears the display and resets the cursor position to 0."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting the supplied text to the device scrolling where necessary.", "response": "def println(self, text=\"\"):\n        \"\"\"\n        Prints the supplied text to the device, scrolling where necessary.\n        The text is always followed by a newline.\n\n        :param text: The text to print.\n        :type text: str\n        \"\"\"\n        if self.word_wrap:\n            # find directives in complete text\n            directives = ansi_color.find_directives(text, self)\n\n            # strip ansi from text\n            clean_text = ansi_color.strip_ansi_codes(text)\n\n            # wrap clean text\n            clean_lines = self.tw.wrap(clean_text)\n\n            # print wrapped text\n            index = 0\n            for line in clean_lines:\n                line_length = len(line)\n                y = 0\n                while y < line_length:\n                    method, args = directives[index]\n                    if method == self.putch:\n                        y += 1\n                    method(*args)\n                    index += 1\n                self.newline()\n        else:\n            self.puts(text)\n            self.newline()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef puts(self, text):\n        for method, args in ansi_color.find_directives(text, self):\n            method(*args)", "response": "Prints the supplied text to the device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef putch(self, char):\n        if char == '\\r':\n            self.carriage_return()\n\n        elif char == '\\n':\n            self.newline()\n\n        elif char == '\\b':\n            self.backspace()\n\n        elif char == '\\t':\n            self.tab()\n\n        else:\n            w = self.font.getsize(char)[0]\n            if self._cx + w >= self._device.width:\n                self.newline()\n\n            self.erase()\n            self._canvas.text((self._cx, self._cy),\n                              text=char,\n                              font=self.font,\n                              fill=self._fgcolor)\n\n            self._cx += w\n            if self.animate:\n                self.flush()", "response": "Prints the specific character in the current screen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadvancing the cursor position to the next soft tabstop.", "response": "def tab(self):\n        \"\"\"\n        Advances the cursor position to the next (soft) tabstop.\n        \"\"\"\n        soft_tabs = self.tabstop - ((self._cx // self._cw) % self.tabstop)\n        for _ in range(soft_tabs):\n            self.putch(\" \")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadvances the cursor position ot the left hand side and to the next available line.", "response": "def newline(self):\n        \"\"\"\n        Advances the cursor position ot the left hand side, and to the next\n        line. If the cursor is on the lowest line, the displayed contents are\n        scrolled, causing the top line to be lost.\n        \"\"\"\n        self.carriage_return()\n\n        if self._cy + (2 * self._ch) >= self._device.height:\n            # Simulate a vertical scroll\n            copy = self._backing_image.crop((0, self._ch, self._device.width,\n                self._device.height))\n            self._backing_image.paste(copy, (0, 0))\n            self._canvas.rectangle((0, copy.height, self._device.width,\n                self._device.height), fill=self.default_bgcolor)\n        else:\n            self._cy += self._ch\n\n        self.flush()\n        if self.animate:\n            time.sleep(0.2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the cursor one place to the left erasing the character at the current position.", "response": "def backspace(self):\n        \"\"\"\n        Moves the cursor one place to the left, erasing the character at the\n        current position. Cannot move beyond column zero, nor onto the\n        previous line.\n        \"\"\"\n        if self._cx + self._cw >= 0:\n            self.erase()\n            self._cx -= self._cw\n\n        self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef erase(self):\n        bounds = (self._cx, self._cy, self._cx + self._cw, self._cy + self._ch)\n        self._canvas.rectangle(bounds, fill=self._bgcolor)", "response": "Erases the contents of the current cursor position without moving the cursor s position."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset(self):\n        self._fgcolor = self.default_fgcolor\n        self._bgcolor = self.default_bgcolor", "response": "Resets foreground and background color values back to the original\n        when initialised."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreverses the foreground and background colors of the current object.", "response": "def reverse_colors(self):\n        \"\"\"\n        Flips the foreground and background colors.\n        \"\"\"\n        self._bgcolor, self._fgcolor = self._fgcolor, self._bgcolor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the last displayed image to the list of savepoints.", "response": "def savepoint(self):\n        \"\"\"\n        Copies the last displayed image.\n        \"\"\"\n        if self._last_image:\n            self._savepoints.append(self._last_image)\n            self._last_image = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restore(self, drop=0):\n        assert(drop >= 0)\n        while drop > 0:\n            self._savepoints.pop()\n            drop -= 1\n\n        img = self._savepoints.pop()\n        self.display(img)", "response": "Restores the last savepoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text(self, value):\n        self._text_buffer = observable(mutable_string(value),\n            observer=self._flush)", "response": "Updates the seven - segment display with the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_task(self, func, *args, **kargs):\n        self.tasks.put((func, args, kargs))", "response": "Add a task to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign attributes such as width height size and bounding_box correctly oriented from the supplied parameters.", "response": "def capabilities(self, width, height, rotate, mode=\"1\"):\n        \"\"\"\n        Assigns attributes such as ``width``, ``height``, ``size`` and\n        ``bounding_box`` correctly oriented from the supplied parameters.\n\n        :param width: The device width.\n        :type width: int\n        :param height: The device height.\n        :type height: int\n        :param rotate: An integer value of 0 (default), 1, 2 or 3 only, where 0 is\n            no rotation, 1 is rotate 90\u00b0 clockwise, 2 is 180\u00b0 rotation and 3\n            represents 270\u00b0 rotation.\n        :type rotate: int\n        :param mode: The supported color model, one of ``\"1\"``, ``\"RGB\"`` or\n            ``\"RGBA\"`` only.\n        :type mode: str\n        \"\"\"\n        assert mode in (\"1\", \"RGB\", \"RGBA\")\n        assert rotate in (0, 1, 2, 3)\n        self._w = width\n        self._h = height\n        self.width = width if rotate % 2 == 0 else height\n        self.height = height if rotate % 2 == 0 else width\n        self.size = (self.width, self.height)\n        self.bounding_box = (0, 0, self.width - 1, self.height - 1)\n        self.rotate = rotate\n        self.mode = mode\n        self.persist = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear the device memory.", "response": "def clear(self):\n        \"\"\"\n        Initializes the device memory with an empty (blank) image.\n        \"\"\"\n        self.display(Image.new(self.mode, self.size))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding a preprocessing facility which is overridden whereby the supplied image is rotated according to the device s rotate capability.", "response": "def preprocess(self, image):\n        \"\"\"\n        Provides a preprocessing facility (which may be overridden) whereby the supplied image is\n        rotated according to the device's rotate capability. If this method is\n        overridden, it is important to call the ``super`` method.\n\n        :param image: An image to pre-process.\n        :type image: PIL.Image.Image\n        :returns: A new processed image.\n        :rtype: PIL.Image.Image\n        \"\"\"\n        if self.rotate == 0:\n            return image\n\n        angle = self.rotate * -90\n        return image.rotate(angle, expand=True).crop((0, 0, self._w, self._h))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the size of the text in a sequence of 8 - character blocks.", "response": "def textsize(txt, font=None):\n    \"\"\"\n    Calculates the bounding box of the text, as drawn in the specified font.\n    This method is most useful for when the\n    :py:class:`~luma.core.legacy.font.proportional` wrapper is used.\n\n    :param txt: The text string to calculate the bounds for\n    :type txt: str\n    :param font: The font (from :py:mod:`luma.core.legacy.font`) to use.\n    \"\"\"\n    font = font or DEFAULT_FONT\n    src = [c for ascii_code in txt for c in font[ord(ascii_code)]]\n    return (len(src), 8)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef text(draw, xy, txt, fill=None, font=None):\n    font = font or DEFAULT_FONT\n    x, y = xy\n    for ch in txt:\n        for byte in font[ord(ch)]:\n            for j in range(8):\n                if byte & 0x01 > 0:\n                    draw.point((x, y + j), fill=fill)\n\n                byte >>= 1\n            x += 1", "response": "Draw a text on the node with the given xy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_message(device, msg, y_offset=0, fill=None, font=None,\n                 scroll_delay=0.03):\n    \"\"\"\n    Scrolls a message right-to-left across the devices display.\n\n    :param device: The device to scroll across.\n    :param msg: The text message to display (must be ASCII only).\n    :type msg: str\n    :param y_offset: The row to use to display the text.\n    :type y_offset: int\n    :param fill: The fill color to use (standard Pillow color name or RGB\n        tuple).\n    :param font: The font (from :py:mod:`luma.core.legacy.font`) to use.\n    :param scroll_delay: The number of seconds to delay between scrolling.\n    :type scroll_delay: float\n    \"\"\"\n    fps = 0 if scroll_delay == 0 else 1.0 / scroll_delay\n    regulator = framerate_regulator(fps)\n    font = font or DEFAULT_FONT\n    with canvas(device) as draw:\n        w, h = textsize(msg, font)\n\n    x = device.width\n    virtual = viewport(device, width=w + x + x, height=device.height)\n\n    with canvas(virtual) as draw:\n        text(draw, (x, y_offset), msg, font=font, fill=fill)\n\n    i = 0\n    while i <= w + x:\n        with regulator:\n            virtual.set_position((i, 0))\n            i += 1", "response": "Displays a message on the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef command(self, *cmd):\n        assert(len(cmd) <= 32)\n\n        try:\n            self._bus.write_i2c_block_data(self._addr, self._cmd_mode,\n                                           list(cmd))\n        except (IOError, OSError) as e:\n            if e.errno in [errno.EREMOTEIO, errno.EIO]:\n                # I/O error\n                raise luma.core.error.DeviceNotFoundError(\n                    'I2C device not found on address: 0x{0:02X}'.format(self._addr))\n            else:  # pragma: no cover\n                raise", "response": "Sends a command or sequence of commands through to the I\u00b2C address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a data byte or sequence of data bytes to the I\u00b2C address.", "response": "def data(self, data):\n        \"\"\"\n        Sends a data byte or sequence of data bytes to the I\u00b2C address.\n        If the bus is in managed mode backed by smbus2, the i2c_rdwr\n        method will be used to avoid having to send in chunks.\n        For SMBus devices the maximum allowed in one transaction is\n        32 bytes, so if data is larger than this, it is sent in chunks.\n\n        :param data: A data sequence.\n        :type data: list, bytearray\n        \"\"\"\n        if self._managed:\n            self._bus.i2c_rdwr(self._i2c_msg_write(self._addr, [self._data_mode] + data))\n        else:\n            i = 0\n            n = len(data)\n            write = self._bus.write_i2c_block_data\n            while i < n:\n                write(self._addr, self._data_mode, list(data[i:i + 32]))\n                i += 32"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_str(text):\n    prog = re.compile(r'^\\033\\[(\\d+(;\\d+)*)m', re.UNICODE)\n\n    while text != \"\":\n        result = prog.match(text)\n        if result:\n            for code in result.group(1).split(\";\"):\n                directive = valid_attributes.get(int(code), None)\n                if directive:\n                    yield directive\n            n = len(result.group(0))\n            text = text[n:]\n        else:\n            yield [\"putch\", text[0]]\n            text = text[1:]", "response": "Parses an ASCII string of characters and yields a list of directives that are used to create a new node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind directives on class klass in string text.", "response": "def find_directives(text, klass):\n    \"\"\"\n    Find directives on class ``klass`` in string ``text``.\n\n    Returns list of ``(method, args)`` tuples.\n\n    .. versionadded:: 0.9.0\n\n    :param text: String containing directives.\n    :type text: str\n    :type klass: object\n    :rtype: list\n    \"\"\"\n    directives = []\n    for directive in parse_str(text):\n        method = klass.__getattribute__(directive[0])\n        args = directive[1:]\n        directives.append((method, args))\n    return directives"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contrast(self, level):\n        assert(0 <= level <= 255)\n        self.command(self._const.SETCONTRAST, level)", "response": "Switches the display contrast to the desired level in the range 0 - 255."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattempts to switch the device off or put into low power mode (this helps prolong the life of the device), clear the screen and close resources associated with the underlying serial interface. If :py:attr:`persist` is ``True``, the device will not be switched off. This is a managed function, which is called when the python processs is being shutdown, so shouldn't usually need be called directly in application code.", "response": "def cleanup(self):\n        \"\"\"\n        Attempt to switch the device off or put into low power mode (this\n        helps prolong the life of the device), clear the screen and close\n        resources associated with the underlying serial interface.\n\n        If :py:attr:`persist` is ``True``, the device will not be switched off.\n\n        This is a managed function, which is called when the python processs\n        is being shutdown, so shouldn't usually need be called directly in\n        application code.\n        \"\"\"\n        if not self.persist:\n            self.hide()\n            self.clear()\n        self._serial_interface.cleanup()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay the image for later use.", "response": "def display(self, image):\n        \"\"\"\n        Takes a :py:mod:`PIL.Image` and makes a copy of it for later\n        use/inspection.\n\n        :param image: Image to display.\n        :type image: PIL.Image.Image\n        \"\"\"\n        assert(image.size == self.size)\n\n        self.image = self.preprocess(image).copy()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_choices(module_name):\n    try:\n        module = importlib.import_module(module_name)\n        if hasattr(module, '__all__'):\n            return module.__all__\n        else:\n            return [name for name, _ in inspect.getmembers(module, inspect.isclass)\n                    if name != \"device\"]\n    except ImportError:\n        return []", "response": "Retrieve members from module_name s __all__ list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting library name for display type.", "response": "def get_library_for_display_type(display_type):\n    \"\"\"\n    Get library name for ``display_type``, e.g. ``ssd1306`` should return\n    ``oled``.\n\n    .. versionadded:: 1.2.0\n\n    :param display_type: Display type, e.g. ``ssd1306``.\n    :type display_type: str\n    :rtype: str or None\n    \"\"\"\n    display_types = get_display_types()\n    for key in display_types.keys():\n        if display_type in display_types[key]:\n            return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_library_version(module_name):\n    try:\n        module = importlib.import_module('luma.' + module_name)\n        if hasattr(module, '__version__'):\n            return module.__version__\n        else:\n            return None\n    except ImportError:\n        return None", "response": "Get version number from module_name s __version__ attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets ordered dict containing available display types from available luma sub - projects.", "response": "def get_display_types():\n    \"\"\"\n    Get ordered dict containing available display types from available luma\n    sub-projects.\n\n    :rtype: collections.OrderedDict\n    \"\"\"\n    display_types = OrderedDict()\n    for namespace in get_supported_libraries():\n        display_types[namespace] = get_choices('luma.{0}.device'.format(\n            namespace))\n\n    return display_types"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of available transformers.", "response": "def get_transformer_choices():\n    \"\"\"\n    :rtype: list\n    \"\"\"\n    from luma.emulator.render import transformer\n    return [fn for fn in dir(transformer) if fn[0:2] != \"__\"]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_config(path):\n    args = []\n    with open(path, 'r') as fp:\n        for line in fp.readlines():\n            if line.strip() and not line.startswith(\"#\"):\n                args.append(line.replace(\"\\n\", \"\"))\n\n    return args", "response": "Load device configuration from file path and return list with parsed lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating and return a new object containing the current display.", "response": "def create_device(args, display_types=None):\n    \"\"\"\n    Create and return device.\n\n    :type args: object\n    :type display_types: dict\n    \"\"\"\n    device = None\n    if display_types is None:\n        display_types = get_display_types()\n\n    if args.display in display_types.get('oled'):\n        import luma.oled.device\n        Device = getattr(luma.oled.device, args.display)\n        Serial = getattr(make_serial(args), args.interface)\n        device = Device(Serial(), **vars(args))\n\n    elif args.display in display_types.get('lcd'):\n        import luma.lcd.device\n        import luma.lcd.aux\n        Device = getattr(luma.lcd.device, args.display)\n        spi = make_serial(args).spi()\n        device = Device(spi, **vars(args))\n        luma.lcd.aux.backlight(gpio=spi._gpio, gpio_LIGHT=args.gpio_backlight, active_low=args.backlight_active == \"low\").enable(True)\n\n    elif args.display in display_types.get('led_matrix'):\n        import luma.led_matrix.device\n        from luma.core.interface.serial import noop\n        Device = getattr(luma.led_matrix.device, args.display)\n        spi = make_serial(args, gpio=noop()).spi()\n        device = Device(serial_interface=spi, **vars(args))\n\n    elif args.display in display_types.get('emulator'):\n        import luma.emulator.device\n        Device = getattr(luma.emulator.device, args.display)\n        device = Device(**vars(args))\n\n    return device"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return command - line argument parser.", "response": "def create_parser(description):\n    \"\"\"\n    Create and return command-line argument parser.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=description,\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\n    display_types = get_display_types()\n    display_choices = [display for k, v in display_types.items() for display in v]\n    interface_types = get_interface_types()\n    framebuffer_choices = get_choices('luma.core.framebuffer')\n    rotation_choices = [0, 1, 2, 3]\n    block_orientation_choices = [0, 90, -90, 180]\n    color_choices = ['1', 'RGB', 'RGBA']\n\n    general_group = parser.add_argument_group('General')\n    general_group.add_argument('--config', '-f', type=str, help='Load configuration settings from a file')\n    general_group.add_argument('--display', '-d', type=str, default=display_choices[0], help='Display type, supports real devices or emulators. Allowed values are: {0}'.format(', '.join(display_choices)), choices=display_choices, metavar='DISPLAY')\n    general_group.add_argument('--width', type=int, default=128, help='Width of the device in pixels')\n    general_group.add_argument('--height', type=int, default=64, help='Height of the device in pixels')\n    general_group.add_argument('--rotate', '-r', type=int, default=0, help='Rotation factor. Allowed values are: {0}'.format(', '.join([str(x) for x in rotation_choices])), choices=rotation_choices, metavar='ROTATION')\n    general_group.add_argument('--interface', '-i', type=str, default=interface_types[0], help='Serial interface type. Allowed values are: {0}'.format(', '.join(interface_types)), choices=interface_types, metavar='INTERFACE')\n\n    i2c_group = parser.add_argument_group('I2C')\n    i2c_group.add_argument('--i2c-port', type=int, default=1, help='I2C bus number')\n    i2c_group.add_argument('--i2c-address', type=str, default='0x3C', help='I2C display address')\n\n    spi_group = parser.add_argument_group('SPI')\n    spi_group.add_argument('--spi-port', type=int, default=0, help='SPI port number')\n    spi_group.add_argument('--spi-device', type=int, default=0, help='SPI device')\n    spi_group.add_argument('--spi-bus-speed', type=int, default=8000000, help='SPI max bus speed (Hz)')\n    spi_group.add_argument('--spi-cs-high', type=bool, default=False, help='SPI chip select is high')\n    spi_group.add_argument('--spi-transfer-size', type=int, default=4096, help='SPI bus max transfer unit (bytes)')\n\n    gpio_group = parser.add_argument_group('GPIO')\n    gpio_group.add_argument('--gpio', type=str, default=None, help='Alternative RPi.GPIO compatible implementation (SPI devices only)')\n    gpio_group.add_argument('--gpio-mode', type=str, default=None, help='Alternative pin mapping mode (SPI devices only)')\n    gpio_group.add_argument('--gpio-data-command', type=int, default=24, help='GPIO pin for D/C RESET (SPI devices only)')\n    gpio_group.add_argument('--gpio-reset', type=int, default=25, help='GPIO pin for RESET (SPI devices only)')\n    gpio_group.add_argument('--gpio-backlight', type=int, default=18, help='GPIO pin for backlight (PCD8544, ST7735 devices only)')\n\n    misc_group = parser.add_argument_group('Misc')\n    misc_group.add_argument('--block-orientation', type=int, default=0, help='Fix 90\u00b0 phase error (MAX7219 LED matrix only). Allowed values are: {0}'.format(', '.join([str(x) for x in block_orientation_choices])), choices=block_orientation_choices, metavar='ORIENTATION')\n    misc_group.add_argument('--mode', type=str, default='RGB', help='Colour mode (SSD1322, SSD1325 and emulator only). Allowed values are: {0}'.format(', '.join(color_choices)), choices=color_choices, metavar='MODE')\n    misc_group.add_argument('--framebuffer', type=str, default=framebuffer_choices[0], help='Framebuffer implementation (SSD1331, SSD1322, ST7735 displays only). Allowed values are: {0}'.format(', '.join(framebuffer_choices)), choices=framebuffer_choices, metavar='FRAMEBUFFER')\n    misc_group.add_argument('--bgr', dest='bgr', action='store_true', help='Set if LCD pixels laid out in BGR (ST7735 displays only).')\n    misc_group.set_defaults(bgr=False)\n    misc_group.add_argument('--h-offset', type=int, default=0, help='Horizontal offset (in pixels) of screen to display memory (ST7735 displays only)')\n    misc_group.add_argument('--v-offset', type=int, default=0, help='Vertical offset (in pixels) of screen to display memory (ST7735 displays only)')\n    misc_group.add_argument('--backlight-active', type=str, default='low', help='Set to \\\"low\\\" if LCD backlight is active low, else \\\"high\\\" otherwise (PCD8544, ST7735 displays only). Allowed values are: low, high', choices=[\"low\", \"high\"], metavar='VALUE')\n\n    if len(display_types['emulator']) > 0:\n        transformer_choices = get_transformer_choices()\n\n        emulator_group = parser.add_argument_group('Emulator')\n        emulator_group.add_argument('--transform', type=str, default='scale2x', help='Scaling transform to apply (emulator only). Allowed values are: {0}'.format(', '.join(transformer_choices)), choices=transformer_choices, metavar='TRANSFORM')\n        emulator_group.add_argument('--scale', type=int, default=2, help='Scaling factor to apply (emulator only)')\n        emulator_group.add_argument('--duration', type=float, default=0.01, help='Animation frame duration (gifanim emulator only)')\n        emulator_group.add_argument('--loop', type=int, default=0, help='Repeat loop, zero=forever (gifanim emulator only)')\n        emulator_group.add_argument('--max-frames', type=int, help='Maximum frames to record (gifanim emulator only)')\n\n    try:  # pragma: no cover\n        import argcomplete\n        argcomplete.autocomplete(parser)\n    except ImportError:\n        pass\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninteracting with process : Send data to stdin and read data from stdout and stderr until end - of - file is reached.", "response": "def communicate(self, input=None):\n        \"\"\"Interact with process: Send data to stdin.  Read data from\n        stdout and stderr, until end-of-file is reached.  Wait for\n        process to terminate.  The optional input argument should be a\n        string to be sent to the child process, or None, if no data\n        should be sent to the child.\n\n        communicate() returns a tuple (stdout, stderr).\"\"\"\n\n        # Optimization: If we are only using one pipe, or no pipe at\n        # all, using select() or threads is unnecessary.\n        if [self.stdin, self.stdout, self.stderr].count(None) >= 2:\n            stdout = None\n            stderr = None\n            if self.stdin:\n                if input:\n                    try:\n                        self.stdin.write(input)\n                    except IOError as e:\n                        if e.errno != errno.EPIPE and e.errno != errno.EINVAL:\n                            raise\n                self.stdin.close()\n            elif self.stdout:\n                stdout = _eintr_retry_call(self.stdout.read)\n                self.stdout.close()\n            elif self.stderr:\n                stderr = _eintr_retry_call(self.stderr.read)\n                self.stderr.close()\n            self.wait()\n            return (stdout, stderr)\n\n        return self._communicate(input)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge two dictionaries d1 with values from d2.", "response": "def merge_dict(d1, d2):\n    \"\"\"\n    Modifies d1 in-place to contain values from d2.  If any value\n    in d1 is a dictionary (or dict-like), *and* the corresponding\n    value in d2 is also a dictionary, then merge them in-place.\n    \"\"\"\n    for k,v2 in d2.items():\n        v1 = d1.get(k) # returns None if v1 has no value for this key\n        if ( isinstance(v1, collections.Mapping) and\n             isinstance(v2, collections.Mapping) ):\n            merge_dict(v1, v2)\n        else:\n            d1[k] = v2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new particle to the list of available particle objects.", "response": "def add_particle(\n        self,\n        pos=(0, 0, 0),\n        charge=1e-6,\n        mass=1e-3,\n        radius=0.005,\n        color=None,\n        vel=(0, 0, 0),\n        fixed=False,\n        negligible=False,\n    ):\n        \"\"\" Adds a new particle with specified properties (in SI units) \"\"\"\n        color = color or len(self.particles)  # assigned or default color number\n\n        p = Particle(pos, charge, mass, radius, color, vel, fixed, negligible)\n        self.particles.append(p)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simulate(self):\n        # Main simulation loop\n        for i in range(self.iterations):\n            for a in self.particles:\n                if a.fixed:\n                    continue\n                ftot = vector(0, 0, 0)  # total force acting on particle a\n                for b in self.particles:\n                    if a.negligible and b.negligible or a == b:\n                        continue\n                    ab = a.pos - b.pos\n                    ftot += ((K_COULOMB * a.charge * b.charge) / mag2(ab)) * versor(ab)\n                a.vel += ftot / a.mass * self.dt  # update velocity and position of a\n                a.pos += a.vel * self.dt\n                a.vtk_actor.pos(a.pos)\n            if vp:\n                vp.show(zoom=1.2)\n                vp.camera.Azimuth(0.1)", "response": "Runs the particle simulation. Simulates one time step, dt, of the particle motion.\n            Calculates the force between each pair of particles and updates particles' motion accordingly"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a 2D scalar bar for the specified actor.", "response": "def addScalarBar(actor=None, c=None, title=\"\", horizontal=False, vmin=None, vmax=None):\n    \"\"\"Add a 2D scalar bar for the specified actor.\n\n    If `actor` is ``None`` will add it to the last actor in ``self.actors``.\n\n    .. hint:: |mesh_bands| |mesh_bands.py|_\n    \"\"\"\n    vp = settings.plotter_instance\n    \n    if actor is None:\n        actor = vp.lastActor()\n        \n    if not hasattr(actor, \"mapper\"):\n        colors.printc(\"~times Error in addScalarBar: input is not a Actor.\", c=1)\n        return None\n\n    if vp and vp.renderer and actor.scalarbar_actor:\n        vp.renderer.RemoveActor(actor.scalarbar)\n            \n\n    lut = actor.mapper.GetLookupTable()\n    if not lut:\n        return None\n    vtkscalars = actor.poly.GetPointData().GetScalars()\n    if vtkscalars is None:\n        vtkscalars = actor.poly.GetCellData().GetScalars()\n    if not vtkscalars:\n        return None\n    \n    rng = list(vtkscalars.GetRange())\n    if vmin:\n        rng[0] = vmin\n    if vmin:\n        rng[1] = vmax\n    actor.mapper.SetScalarRange(rng)\n\n    if c is None:\n        if vp.renderer:  # automatic black or white\n            c = (0.9, 0.9, 0.9)\n            if numpy.sum(vp.renderer.GetBackground()) > 1.5:\n                c = (0.1, 0.1, 0.1)\n        else:\n            c = \"k\"\n\n    c = colors.getColor(c)\n    sb = vtk.vtkScalarBarActor()\n    sb.SetLookupTable(lut)\n    if title:\n        titprop = vtk.vtkTextProperty()\n        titprop.BoldOn()\n        titprop.ItalicOff()\n        titprop.ShadowOff()\n        titprop.SetColor(c)\n        titprop.SetVerticalJustificationToTop()\n        sb.SetTitle(title)\n        sb.SetVerticalTitleSeparation(15)\n        sb.SetTitleTextProperty(titprop)\n\n    if vtk.vtkVersion().GetVTKMajorVersion() > 7:\n        sb.UnconstrainedFontSizeOn()\n        sb.FixedAnnotationLeaderLineColorOff()\n        sb.DrawAnnotationsOn()\n        sb.DrawTickLabelsOn()\n    sb.SetMaximumNumberOfColors(512)\n\n    if horizontal:\n        sb.SetOrientationToHorizontal()\n        sb.SetNumberOfLabels(4)\n        sb.SetTextPositionToSucceedScalarBar()\n        sb.SetPosition(0.8, 0.05)\n        sb.SetMaximumWidthInPixels(1000)\n        sb.SetMaximumHeightInPixels(50)\n    else:\n        sb.SetNumberOfLabels(10)\n        sb.SetTextPositionToPrecedeScalarBar()\n        sb.SetPosition(0.87, 0.05)\n        sb.SetMaximumWidthInPixels(80)\n        sb.SetMaximumHeightInPixels(500)\n\n    sctxt = sb.GetLabelTextProperty()\n    sctxt.SetColor(c)\n    sctxt.SetShadow(0)\n    sctxt.SetFontFamily(0)\n    sctxt.SetItalic(0)\n    sctxt.SetBold(0)\n    sctxt.SetFontSize(12)\n    if not vp.renderer:\n        save_int = vp.interactive\n        vp.show(interactive=0)\n        vp.interactive = save_int\n    sb.PickableOff()\n    vp.renderer.AddActor(sb)\n    vp.scalarbars.append(sb)\n    actor.scalarbar_actor = sb\n    vp.renderer.Render()\n    return sb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addScalarBar3D(\n    obj=None,\n    at=0,\n    pos=(0, 0, 0),\n    normal=(0, 0, 1),\n    sx=0.1,\n    sy=2,\n    nlabels=9,\n    ncols=256,\n    cmap=None,\n    c=None,\n    alpha=1,\n):\n    \"\"\"Draw a 3D scalar bar.\n\n    ``obj`` input can be:\n        - a list of numbers,\n        - a list of two numbers in the form `(min, max)`,\n        - a ``vtkActor`` already containing a set of scalars associated to vertices or cells,\n        - if ``None`` the last actor in the list of actors will be used.\n\n    .. hint:: |scalbar| |mesh_coloring.py|_\n    \"\"\"\n    from vtk.util.numpy_support import vtk_to_numpy, numpy_to_vtk\n\n    vp = settings.plotter_instance\n    if c is None:  # automatic black or white\n        c = (0.8, 0.8, 0.8)\n        if numpy.sum(colors.getColor(vp.backgrcol)) > 1.5:\n            c = (0.2, 0.2, 0.2)\n    c = colors.getColor(c)\n    \n    gap = 0.4  # space btw nrs and scale\n    vtkscalars_name = \"\"\n    if obj is None:\n        obj = vp.lastActor()\n    if isinstance(obj, vtk.vtkActor):\n        poly = obj.GetMapper().GetInput()\n        vtkscalars = poly.GetPointData().GetScalars()\n        if vtkscalars is None:\n            vtkscalars = poly.GetCellData().GetScalars()\n        if vtkscalars is None:\n            print(\"Error in addScalarBar3D: actor has no scalar array.\", [obj])\n            exit()\n        npscalars = vtk_to_numpy(vtkscalars)\n        vmin, vmax = numpy.min(npscalars), numpy.max(npscalars)\n        vtkscalars_name = vtkscalars.GetName().split(\"_\")[-1]\n    elif utils.isSequence(obj):\n        vmin, vmax = numpy.min(obj), numpy.max(obj)\n        vtkscalars_name = \"jet\"\n    else:\n        print(\"Error in addScalarBar3D(): input must be vtkActor or list.\", type(obj))\n        exit()\n\n    if cmap is None:\n        cmap = vtkscalars_name\n\n    # build the color scale part\n    scale = shapes.Grid([-sx * gap, 0, 0], c=c, alpha=alpha, sx=sx, sy=sy, resx=1, resy=ncols)\n    scale.GetProperty().SetRepresentationToSurface()\n    cscals = scale.cellCenters()[:, 1]\n\n    def _cellColors(scale, scalars, cmap, alpha):\n        mapper = scale.GetMapper()\n        cpoly = mapper.GetInput()\n        n = len(scalars)\n        lut = vtk.vtkLookupTable()\n        lut.SetNumberOfTableValues(n)\n        lut.Build()\n        for i in range(n):\n            r, g, b = colors.colorMap(i, cmap, 0, n)\n            lut.SetTableValue(i, r, g, b, alpha)\n        arr = numpy_to_vtk(numpy.ascontiguousarray(scalars), deep=True)\n        vmin, vmax = numpy.min(scalars), numpy.max(scalars)\n        mapper.SetScalarRange(vmin, vmax)\n        mapper.SetLookupTable(lut)\n        mapper.ScalarVisibilityOn()\n        cpoly.GetCellData().SetScalars(arr)\n\n    _cellColors(scale, cscals, cmap, alpha)\n\n    # build text\n    nlabels = numpy.min([nlabels, ncols])\n    tlabs = numpy.linspace(vmin, vmax, num=nlabels, endpoint=True)\n    tacts = []\n    prec = (vmax - vmin) / abs(vmax + vmin) * 2\n    prec = int(3 + abs(numpy.log10(prec + 1)))\n    for i, t in enumerate(tlabs):\n        tx = utils.precision(t, prec)\n        y = -sy / 1.98 + sy * i / (nlabels - 1)\n        a = shapes.Text(tx, pos=[sx * gap, y, 0], s=sy / 50, c=c, alpha=alpha, depth=0)\n        a.PickableOff()\n        tacts.append(a)\n    sact = Assembly([scale] + tacts)\n    nax = numpy.linalg.norm(normal)\n    if nax:\n        normal = numpy.array(normal) / nax\n    theta = numpy.arccos(normal[2])\n    phi = numpy.arctan2(normal[1], normal[0])\n    sact.RotateZ(phi * 57.3)\n    sact.RotateY(theta * 57.3)\n    sact.SetPosition(pos)\n    if not vp.renderers[at]:\n        save_int = vp.interactive\n        vp.show(interactive=0)\n        vp.interactive = save_int\n    vp.renderers[at].AddActor(sact)\n    vp.renderers[at].Render()\n    sact.PickableOff()\n    vp.scalarbars.append(sact)\n    if isinstance(obj, Actor):\n        obj.scalarbar_actor = sact\n    return sact", "response": "Draw a 3D scalar bar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addSlider2D(sliderfunc, xmin, xmax, value=None, pos=4, s=.04,\n                title='', c=None, showValue=True):\n    \"\"\"Add a slider widget which can call an external custom function.\n\n    :param sliderfunc: external function to be called by the widget\n    :param float xmin:  lower value\n    :param float xmax:  upper value\n    :param float value: current value\n    :param list pos:  position corner number: horizontal [1-4] or vertical [11-14]\n                        it can also be specified by corners coordinates [(x1,y1), (x2,y2)]\n    :param str title: title text\n    :param bool showValue:  if true current value is shown\n\n    .. hint:: |sliders| |sliders.py|_\n    \"\"\"\n    vp = settings.plotter_instance\n    if c is None:  # automatic black or white\n        c = (0.8, 0.8, 0.8)\n        if numpy.sum(colors.getColor(vp.backgrcol)) > 1.5:\n            c = (0.2, 0.2, 0.2)\n    c = colors.getColor(c)\n\n    if value is None or value < xmin:\n        value = xmin\n\n    sliderRep = vtk.vtkSliderRepresentation2D()\n    sliderRep.SetMinimumValue(xmin)\n    sliderRep.SetMaximumValue(xmax)\n    sliderRep.SetValue(value)\n    sliderRep.SetSliderLength(0.015)\n    sliderRep.SetSliderWidth(0.025)\n    sliderRep.SetEndCapLength(0.0015)\n    sliderRep.SetEndCapWidth(0.0125)\n    sliderRep.SetTubeWidth(0.0075)\n    sliderRep.GetPoint1Coordinate().SetCoordinateSystemToNormalizedDisplay()\n    sliderRep.GetPoint2Coordinate().SetCoordinateSystemToNormalizedDisplay()\n    if utils.isSequence(pos):\n        sliderRep.GetPoint1Coordinate().SetValue(pos[0][0], pos[0][1])\n        sliderRep.GetPoint2Coordinate().SetValue(pos[1][0], pos[1][1])\n    elif pos == 1:  # top-left horizontal\n        sliderRep.GetPoint1Coordinate().SetValue(0.04, 0.96)\n        sliderRep.GetPoint2Coordinate().SetValue(0.45, 0.96)\n    elif pos == 2:\n        sliderRep.GetPoint1Coordinate().SetValue(0.55, 0.96)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.96)\n    elif pos == 3:\n        sliderRep.GetPoint1Coordinate().SetValue(0.04, 0.04)\n        sliderRep.GetPoint2Coordinate().SetValue(0.45, 0.04)\n    elif pos == 4:  # bottom-right\n        sliderRep.GetPoint1Coordinate().SetValue(0.55, 0.04)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.04)\n    elif pos == 5:  # bottom margin horizontal\n        sliderRep.GetPoint1Coordinate().SetValue(0.04, 0.04)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.04)\n    elif pos == 11:  # top-left vertical\n        sliderRep.GetPoint1Coordinate().SetValue(0.04, 0.54)\n        sliderRep.GetPoint2Coordinate().SetValue(0.04, 0.9)\n    elif pos == 12:\n        sliderRep.GetPoint1Coordinate().SetValue(0.96, 0.54)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.9)\n    elif pos == 13:\n        sliderRep.GetPoint1Coordinate().SetValue(0.04, 0.1)\n        sliderRep.GetPoint2Coordinate().SetValue(0.04, 0.54)\n    elif pos == 14:  # bottom-right vertical\n        sliderRep.GetPoint1Coordinate().SetValue(0.96, 0.1)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.54)\n    elif pos == 15:  # right margin vertical\n        sliderRep.GetPoint1Coordinate().SetValue(0.96, 0.1)\n        sliderRep.GetPoint2Coordinate().SetValue(0.96, 0.9)\n\n    if showValue:\n        if isinstance(xmin, int) and isinstance(xmax, int):\n            frm = \"%0.0f\"\n        else:\n            frm = \"%0.1f\"\n        sliderRep.SetLabelFormat(frm)  # default is '%0.3g'\n        sliderRep.GetLabelProperty().SetShadow(0)\n        sliderRep.GetLabelProperty().SetBold(0)\n        sliderRep.GetLabelProperty().SetOpacity(0.6)\n        sliderRep.GetLabelProperty().SetColor(c)\n        if isinstance(pos, int) and pos > 10:\n            sliderRep.GetLabelProperty().SetOrientation(90)\n    else:\n        sliderRep.ShowSliderLabelOff()\n    sliderRep.GetTubeProperty().SetColor(c)\n    sliderRep.GetTubeProperty().SetOpacity(0.6)\n    sliderRep.GetSliderProperty().SetColor(c)\n    sliderRep.GetSelectedProperty().SetColor(0.8, 0, 0)\n    sliderRep.GetCapProperty().SetColor(c)\n\n    if title:\n        sliderRep.SetTitleText(title)\n        sliderRep.SetTitleHeight(0.012)\n        sliderRep.GetTitleProperty().SetShadow(0)\n        sliderRep.GetTitleProperty().SetColor(c)\n        sliderRep.GetTitleProperty().SetOpacity(0.6)\n        sliderRep.GetTitleProperty().SetBold(0)\n        if not utils.isSequence(pos):\n            if isinstance(pos, int) and pos > 10:\n                sliderRep.GetTitleProperty().SetOrientation(90)\n        else:\n            if abs(pos[0][0] - pos[1][0]) < 0.1:\n                sliderRep.GetTitleProperty().SetOrientation(90)\n\n    sliderWidget = vtk.vtkSliderWidget()\n    sliderWidget.SetInteractor(vp.interactor)\n    sliderWidget.SetAnimationModeToJump()\n    sliderWidget.SetRepresentation(sliderRep)\n    sliderWidget.AddObserver(\"InteractionEvent\", sliderfunc)\n    sliderWidget.EnabledOn()\n    vp.sliders.append([sliderWidget, sliderfunc])\n    return sliderWidget", "response": "Add a slider widget which can call an external function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addSlider3D(\n    sliderfunc,\n    pos1,\n    pos2,\n    xmin,\n    xmax,\n    value=None,\n    s=0.03,\n    title=\"\",\n    rotation=0,\n    c=None,\n    showValue=True,\n):\n    \"\"\"Add a 3D slider widget which can call an external custom function.\n\n    :param sliderfunc: external function to be called by the widget\n    :param list pos1: first position coordinates\n    :param list pos2: second position coordinates\n    :param float xmin:  lower value\n    :param float xmax:  upper value\n    :param float value: initial value\n    :param float s: label scaling factor\n    :param str title: title text\n    :param c: slider color\n    :param float rotation: title rotation around slider axis\n    :param bool showValue: if True current value is shown\n\n    .. hint:: |sliders3d| |sliders3d.py|_\n    \"\"\"\n    vp = settings.plotter_instance\n    if c is None:  # automatic black or white\n        c = (0.8, 0.8, 0.8)\n        if numpy.sum(colors.getColor(vp.backgrcol)) > 1.5:\n            c = (0.2, 0.2, 0.2)\n    else:\n        c = colors.getColor(c)\n\n    if value is None or value < xmin:\n        value = xmin\n\n    t = 1.5 / numpy.sqrt(utils.mag(numpy.array(pos2) - pos1))  # better norm\n\n    sliderRep = vtk.vtkSliderRepresentation3D()\n    sliderRep.SetMinimumValue(xmin)\n    sliderRep.SetValue(value)\n    sliderRep.SetMaximumValue(xmax)\n\n    sliderRep.GetPoint1Coordinate().SetCoordinateSystemToWorld()\n    sliderRep.GetPoint2Coordinate().SetCoordinateSystemToWorld()\n    sliderRep.GetPoint1Coordinate().SetValue(pos2)\n    sliderRep.GetPoint2Coordinate().SetValue(pos1)\n\n    sliderRep.SetSliderWidth(0.03 * t)\n    sliderRep.SetTubeWidth(0.01 * t)\n    sliderRep.SetSliderLength(0.04 * t)\n    sliderRep.SetSliderShapeToCylinder()\n    sliderRep.GetSelectedProperty().SetColor(1, 0, 0)\n    sliderRep.GetSliderProperty().SetColor(numpy.array(c) / 2)\n    sliderRep.GetCapProperty().SetOpacity(0)\n\n    sliderRep.SetRotation(rotation)\n\n    if not showValue:\n        sliderRep.ShowSliderLabelOff()\n\n    sliderRep.SetTitleText(title)\n    sliderRep.SetTitleHeight(s * t)\n    sliderRep.SetLabelHeight(s * t * 0.85)\n\n    sliderRep.GetTubeProperty()\n    sliderRep.GetTubeProperty().SetColor(c)\n\n    sliderWidget = vtk.vtkSliderWidget()\n    sliderWidget.SetInteractor(vp.interactor)\n    sliderWidget.SetRepresentation(sliderRep)\n    sliderWidget.SetAnimationModeToJump()\n    sliderWidget.AddObserver(\"InteractionEvent\", sliderfunc)\n    sliderWidget.EnabledOn()\n    vp.sliders.append([sliderWidget, sliderfunc])\n    return sliderWidget", "response": "Add a 3D slider widget which can call an external function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addButton(\n    fnc,\n    states=(\"On\", \"Off\"),\n    c=(\"w\", \"w\"),\n    bc=(\"dg\", \"dr\"),\n    pos=(20, 40),\n    size=24,\n    font=\"arial\",\n    bold=False,\n    italic=False,\n    alpha=1,\n    angle=0,\n):\n    \"\"\"Add a button to the renderer window.\n    \n    :param list states: a list of possible states ['On', 'Off']\n    :param c:      a list of colors for each state\n    :param bc:     a list of background colors for each state\n    :param pos:    2D position in pixels from left-bottom corner\n    :param size:   size of button font\n    :param str font:   font type (arial, courier, times)\n    :param bool bold:   bold face (False)\n    :param bool italic: italic face (False)\n    :param float alpha:  opacity level\n    :param float angle:  anticlockwise rotation in degrees\n\n    .. hint:: |buttons| |buttons.py|_\n    \"\"\"\n    vp = settings.plotter_instance\n    if not vp.renderer:\n        colors.printc(\"~timesError: Use addButton() after rendering the scene.\", c=1)\n        return\n    import vtkplotter.vtkio as vtkio\n    bu = vtkio.Button(fnc, states, c, bc, pos, size, font, bold, italic, alpha, angle)\n    vp.renderer.AddActor2D(bu.actor)\n    vp.window.Render()\n    vp.buttons.append(bu)\n    return bu", "response": "Adds a button to the renderer window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a cutter tool to the current object.", "response": "def addCutterTool(actor):\n    \"\"\"Create handles to cut away parts of a mesh.\n\n    .. hint:: |cutter| |cutter.py|_\n    \"\"\"\n    if isinstance(actor, vtk.vtkVolume):\n        return _addVolumeCutterTool(actor)\n    elif isinstance(actor, vtk.vtkImageData):\n        from vtkplotter import Volume\n        return _addVolumeCutterTool(Volume(actor))\n\n    vp = settings.plotter_instance\n    if not vp.renderer:\n        save_int = vp.interactive\n        vp.show(interactive=0)\n        vp.interactive = save_int\n\n    vp.clickedActor = actor\n    if hasattr(actor, \"polydata\"):\n        apd = actor.polydata()\n    else:\n        apd = actor.GetMapper().GetInput()\n\n    planes = vtk.vtkPlanes()\n    planes.SetBounds(apd.GetBounds())\n\n    clipper = vtk.vtkClipPolyData()\n    clipper.GenerateClipScalarsOff()\n    clipper.SetInputData(apd)\n    clipper.SetClipFunction(planes)\n    clipper.InsideOutOn()\n    clipper.GenerateClippedOutputOn()\n\n    act0Mapper = vtk.vtkPolyDataMapper()  # the part which stays\n    act0Mapper.SetInputConnection(clipper.GetOutputPort())\n    act0 = Actor()\n    act0.SetMapper(act0Mapper)\n    act0.GetProperty().SetColor(actor.GetProperty().GetColor())\n    act0.GetProperty().SetOpacity(1)\n\n    act1Mapper = vtk.vtkPolyDataMapper()  # the part which is cut away\n    act1Mapper.SetInputConnection(clipper.GetClippedOutputPort())\n    act1 = vtk.vtkActor()\n    act1.SetMapper(act1Mapper)\n    act1.GetProperty().SetOpacity(0.02)\n    act1.GetProperty().SetRepresentationToWireframe()\n    act1.VisibilityOn()\n\n    vp.renderer.AddActor(act0)\n    vp.renderer.AddActor(act1)\n    vp.renderer.RemoveActor(actor)\n\n    def SelectPolygons(vobj, event):\n        vobj.GetPlanes(planes)\n\n    boxWidget = vtk.vtkBoxWidget()\n    boxWidget.OutlineCursorWiresOn()\n    boxWidget.GetSelectedOutlineProperty().SetColor(1, 0, 1)\n    boxWidget.GetOutlineProperty().SetColor(0.1, 0.1, 0.1)\n    boxWidget.GetOutlineProperty().SetOpacity(0.8)\n    boxWidget.SetPlaceFactor(1.05)\n    boxWidget.SetInteractor(vp.interactor)\n    boxWidget.SetInputData(apd)\n    boxWidget.PlaceWidget()\n    boxWidget.AddObserver(\"InteractionEvent\", SelectPolygons)\n    boxWidget.On()\n\n    vp.cutterWidget = boxWidget\n    vp.clickedActor = act0\n    ia = vp.actors.index(actor)\n    vp.actors[ia] = act0\n\n    colors.printc(\"Mesh Cutter Tool:\", c=\"m\", invert=1)\n    colors.printc(\"  Move gray handles to cut away parts of the mesh\", c=\"m\")\n    colors.printc(\"  Press X to save file to: clipped.vtk\", c=\"m\")\n\n    vp.interactor.Start()\n    boxWidget.Off()\n    vp.widgets.append(boxWidget)\n\n    vp.interactor.Start()  # allow extra interaction\n\n    return act0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addIcon(iconActor, pos=3, size=0.08):\n    vp = settings.plotter_instance\n    if not vp.renderer:\n        colors.printc(\"~lightningWarning: Use addIcon() after first rendering the scene.\", c=3)\n        save_int = vp.interactive\n        vp.show(interactive=0)\n        vp.interactive = save_int\n    widget = vtk.vtkOrientationMarkerWidget()\n    widget.SetOrientationMarker(iconActor)\n    widget.SetInteractor(vp.interactor)\n    if utils.isSequence(pos):\n        widget.SetViewport(pos[0] - size, pos[1] - size, pos[0] + size, pos[1] + size)\n    else:\n        if pos < 2:\n            widget.SetViewport(0, 1 - 2 * size, size * 2, 1)\n        elif pos == 2:\n            widget.SetViewport(1 - 2 * size, 1 - 2 * size, 1, 1)\n        elif pos == 3:\n            widget.SetViewport(0, 0, size * 2, size * 2)\n        elif pos == 4:\n            widget.SetViewport(1 - 2 * size, 0, 1, size * 2)\n    widget.EnabledOn()\n    widget.InteractiveOff()\n    vp.widgets.append(widget)\n    if iconActor in vp.actors:\n        vp.actors.remove(iconActor)\n    return widget", "response": "Add an inset icon into the same renderer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addAxes(axtype=None, c=None):\n    vp = settings.plotter_instance\n    if axtype is not None:\n        vp.axes = axtype  # overrride\n\n    r = vp.renderers.index(vp.renderer)\n\n    if not vp.axes:\n        return\n\n    if c is None:  # automatic black or white\n        c = (0.9, 0.9, 0.9)\n        if numpy.sum(vp.renderer.GetBackground()) > 1.5:\n            c = (0.1, 0.1, 0.1)\n\n    if not vp.renderer:\n        return\n\n    if vp.axes_exist[r]:\n        return\n\n    # calculate max actors bounds\n    bns = []\n    for a in vp.actors:\n        if a and a.GetPickable():\n            b = a.GetBounds()\n            if b:\n                bns.append(b)\n    if len(bns):\n        max_bns = numpy.max(bns, axis=0)\n        min_bns = numpy.min(bns, axis=0)\n        vbb = (min_bns[0], max_bns[1], min_bns[2], max_bns[3], min_bns[4], max_bns[5])\n    else:\n        vbb = vp.renderer.ComputeVisiblePropBounds()\n        max_bns = vbb\n        min_bns = vbb\n    sizes = (max_bns[1] - min_bns[0], max_bns[3] - min_bns[2], max_bns[5] - min_bns[4])\n\n\n    ############################################################\n    if vp.axes == 1 or vp.axes == True:  # gray grid walls\n        nd = 4  # number of divisions in the smallest axis\n        off = -0.04  # label offset\n        step = numpy.min(sizes) / nd\n        if not step:\n            # bad proportions, use vtkCubeAxesActor\n            vp.addAxes(axtype=8, c=c)\n            vp.axes = 1\n            return\n\n        rx, ry, rz = numpy.rint(sizes / step).astype(int)\n        if max([rx / ry, ry / rx, rx / rz, rz / rx, ry / rz, rz / ry]) > 15:\n            # bad proportions, use vtkCubeAxesActor\n            vp.addAxes(axtype=8, c=c)\n            vp.axes = 1\n            return\n\n        gxy = shapes.Grid(pos=(0.5, 0.5, 0), normal=[0, 0, 1], bc=None, resx=rx, resy=ry)\n        gxz = shapes.Grid(pos=(0.5, 0, 0.5), normal=[0, 1, 0], bc=None, resx=rz, resy=rx)\n        gyz = shapes.Grid(pos=(0, 0.5, 0.5), normal=[1, 0, 0], bc=None, resx=rz, resy=ry)\n        gxy.alpha(0.06).wire(False).color(c).lineWidth(1)\n        gxz.alpha(0.04).wire(False).color(c).lineWidth(1)\n        gyz.alpha(0.04).wire(False).color(c).lineWidth(1)\n\n        xa = shapes.Line([0, 0, 0], [1, 0, 0], c=c, lw=1)\n        ya = shapes.Line([0, 0, 0], [0, 1, 0], c=c, lw=1)\n        za = shapes.Line([0, 0, 0], [0, 0, 1], c=c, lw=1)\n\n        xt, yt, zt, ox, oy, oz = [None] * 6\n        if vp.xtitle:\n            xtitle = vp.xtitle\n            if min_bns[0] <= 0 and max_bns[1] > 0:  # mark x origin\n                ox = shapes.Cube([-min_bns[0] / sizes[0], 0, 0], side=0.008, c=c)\n            if len(vp.xtitle) == 1:  # add axis length info\n                xtitle = vp.xtitle + \" /\" + utils.precision(sizes[0], 4)\n            wpos = [1 - (len(vp.xtitle) + 1) / 40, off, 0]\n            xt = shapes.Text(xtitle, pos=wpos, normal=(0, 0, 1),\n                             s=0.025, c=c, justify=\"bottom-right\")\n\n        if vp.ytitle:\n            if min_bns[2] <= 0 and max_bns[3] > 0:  # mark y origin\n                oy = shapes.Cube([0, -min_bns[2] / sizes[1], 0], side=0.008, c=c)\n            yt = shapes.Text(vp.ytitle, pos=(0, 0, 0), normal=(0, 0, 1),\n                             s=0.025, c=c, justify=\"bottom-right\")\n            if len(vp.ytitle) == 1:\n                wpos = [off, 1 - (len(vp.ytitle) + 1) / 40, 0]\n                yt.pos(wpos)\n            else:\n                wpos = [off * 0.7, 1 - (len(vp.ytitle) + 1) / 40, 0]\n                yt.rotateZ(90).pos(wpos)\n\n        if vp.ztitle:\n            if min_bns[4] <= 0 and max_bns[5] > 0:  # mark z origin\n                oz = shapes.Cube([0, 0, -min_bns[4] / sizes[2]], side=0.008, c=c)\n            zt = shapes.Text(vp.ztitle, pos=(0, 0, 0), normal=(1, -1, 0),\n                             s=0.025, c=c, justify=\"bottom-right\")\n            if len(vp.ztitle) == 1:\n                wpos = [off * 0.6, off * 0.6, 1 - (len(vp.ztitle) + 1) / 40]\n                zt.rotate(90, (1, -1, 0)).pos(wpos)\n            else:\n                wpos = [off * 0.3, off * 0.3, 1 - (len(vp.ztitle) + 1) / 40]\n                zt.rotate(180, (1, -1, 0)).pos(wpos)\n\n        acts = [gxy, gxz, gyz, xa, ya, za, xt, yt, zt, ox, oy, oz]\n        for a in acts:\n            if a:\n                a.PickableOff()\n        aa = Assembly(acts)\n        aa.pos(min_bns[0], min_bns[2], min_bns[4])\n        aa.SetScale(sizes)\n        aa.PickableOff()\n        vp.renderer.AddActor(aa)\n        vp.axes_exist[r] = aa\n\n    elif vp.axes == 2 or vp.axes == 3:\n        vbb = vp.renderer.ComputeVisiblePropBounds()  # to be double checked\n        xcol, ycol, zcol = \"db\", \"dg\", \"dr\"\n        s = 1\n        alpha = 1\n        centered = False\n        x0, x1, y0, y1, z0, z1 = vbb\n        dx, dy, dz = x1 - x0, y1 - y0, z1 - z0\n        aves = numpy.sqrt(dx * dx + dy * dy + dz * dz) / 2\n        x0, x1 = min(x0, 0), max(x1, 0)\n        y0, y1 = min(y0, 0), max(y1, 0)\n        z0, z1 = min(z0, 0), max(z1, 0)\n\n        if vp.axes == 3:\n            if x1 > 0:\n                x0 = 0\n            if y1 > 0:\n                y0 = 0\n            if z1 > 0:\n                z0 = 0\n\n        dx, dy, dz = x1 - x0, y1 - y0, z1 - z0\n        acts = []\n        if x0 * x1 <= 0 or y0 * z1 <= 0 or z0 * z1 <= 0:  # some ranges contain origin\n            zero = shapes.Sphere(r=aves / 120 * s, c=\"k\", alpha=alpha, res=10)\n            acts += [zero]\n\n        if len(vp.xtitle) and dx > aves/100:\n            xl = shapes.Cylinder([[x0, 0, 0], [x1, 0, 0]], r=aves/250*s, c=xcol, alpha=alpha)\n            xc = shapes.Cone(pos=[x1, 0, 0], c=xcol, alpha=alpha,\n                             r=aves/100*s, height=aves/25*s, axis=[1, 0, 0], res=10)\n            wpos = [x1-(len(vp.xtitle)+1)*aves/40*s, -aves/25*s, 0]  # aligned to arrow tip\n            if centered:\n                wpos = [(x0 + x1) / 2 - len(vp.xtitle) / 2 * aves / 40 * s, -aves / 25 * s, 0]\n            xt = shapes.Text(vp.xtitle, pos=wpos, normal=(0, 0, 1), s=aves / 40 * s, c=xcol)\n            acts += [xl, xc, xt]\n\n        if len(vp.ytitle) and dy > aves/100:\n            yl = shapes.Cylinder([[0, y0, 0], [0, y1, 0]], r=aves/250*s, c=ycol, alpha=alpha)\n            yc = shapes.Cone(pos=[0, y1, 0], c=ycol, alpha=alpha,\n                             r=aves/100*s, height=aves/25*s, axis=[0, 1, 0], res=10)\n            wpos = [-aves/40*s, y1-(len(vp.ytitle)+1)*aves/40*s, 0]\n            if centered:\n                wpos = [-aves / 40 * s, (y0 + y1) / 2 - len(vp.ytitle) / 2 * aves / 40 * s, 0]\n            yt = shapes.Text(vp.ytitle, pos=(0, 0, 0), normal=(0, 0, 1), s=aves / 40 * s, c=ycol)\n            yt.rotate(90, [0, 0, 1]).pos(wpos)\n            acts += [yl, yc, yt]\n\n        if len(vp.ztitle) and dz > aves/100:\n            zl = shapes.Cylinder([[0, 0, z0], [0, 0, z1]], r=aves/250*s, c=zcol, alpha=alpha)\n            zc = shapes.Cone(pos=[0, 0, z1], c=zcol, alpha=alpha,\n                             r=aves/100*s, height=aves/25*s, axis=[0, 0, 1], res=10)\n            wpos = [-aves/50*s, -aves/50*s, z1 - (len(vp.ztitle)+1)*aves/40*s]\n            if centered:\n                wpos = [-aves/50*s, -aves/50*s, (z0+z1)/2-len(vp.ztitle)/2*aves/40*s]\n            zt = shapes.Text(vp.ztitle, pos=(0,0,0), normal=(1, -1, 0), s=aves/40*s, c=zcol)\n            zt.rotate(180, (1, -1, 0)).pos(wpos)\n            acts += [zl, zc, zt]\n        for a in acts:\n            a.PickableOff()\n        ass = Assembly(acts)\n        ass.PickableOff()\n        vp.renderer.AddActor(ass)\n        vp.axes_exist[r] = ass\n\n    elif vp.axes == 4:\n        axact = vtk.vtkAxesActor()\n        axact.SetShaftTypeToCylinder()\n        axact.SetCylinderRadius(0.03)\n        axact.SetXAxisLabelText(vp.xtitle)\n        axact.SetYAxisLabelText(vp.ytitle)\n        axact.SetZAxisLabelText(vp.ztitle)\n        axact.GetXAxisShaftProperty().SetColor(0, 0, 1)\n        axact.GetZAxisShaftProperty().SetColor(1, 0, 0)\n        axact.GetXAxisTipProperty().SetColor(0, 0, 1)\n        axact.GetZAxisTipProperty().SetColor(1, 0, 0)\n        bc = numpy.array(vp.renderer.GetBackground())\n        if numpy.sum(bc) < 1.5:\n            lc = (1, 1, 1)\n        else:\n            lc = (0, 0, 0)\n        axact.GetXAxisCaptionActor2D().GetCaptionTextProperty().BoldOff()\n        axact.GetYAxisCaptionActor2D().GetCaptionTextProperty().BoldOff()\n        axact.GetZAxisCaptionActor2D().GetCaptionTextProperty().BoldOff()\n        axact.GetXAxisCaptionActor2D().GetCaptionTextProperty().ItalicOff()\n        axact.GetYAxisCaptionActor2D().GetCaptionTextProperty().ItalicOff()\n        axact.GetZAxisCaptionActor2D().GetCaptionTextProperty().ItalicOff()\n        axact.GetXAxisCaptionActor2D().GetCaptionTextProperty().ShadowOff()\n        axact.GetYAxisCaptionActor2D().GetCaptionTextProperty().ShadowOff()\n        axact.GetZAxisCaptionActor2D().GetCaptionTextProperty().ShadowOff()\n        axact.GetXAxisCaptionActor2D().GetCaptionTextProperty().SetColor(lc)\n        axact.GetYAxisCaptionActor2D().GetCaptionTextProperty().SetColor(lc)\n        axact.GetZAxisCaptionActor2D().GetCaptionTextProperty().SetColor(lc)\n        axact.PickableOff()\n        icn = addIcon(axact, size=0.1)\n        vp.axes_exist[r] = icn\n\n    elif vp.axes == 5:\n        axact = vtk.vtkAnnotatedCubeActor()\n        axact.GetCubeProperty().SetColor(0.75, 0.75, 0.75)\n        axact.SetTextEdgesVisibility(0)\n        axact.SetFaceTextScale(0.4)\n        axact.GetXPlusFaceProperty().SetColor(colors.getColor(\"b\"))\n        axact.GetXMinusFaceProperty().SetColor(colors.getColor(\"db\"))\n        axact.GetYPlusFaceProperty().SetColor(colors.getColor(\"g\"))\n        axact.GetYMinusFaceProperty().SetColor(colors.getColor(\"dg\"))\n        axact.GetZPlusFaceProperty().SetColor(colors.getColor(\"r\"))\n        axact.GetZMinusFaceProperty().SetColor(colors.getColor(\"dr\"))\n        axact.PickableOff()\n        icn = addIcon(axact, size=0.06)\n        vp.axes_exist[r] = icn\n\n    elif vp.axes == 6:\n        ocf = vtk.vtkOutlineCornerFilter()\n        ocf.SetCornerFactor(0.1)\n        largestact, sz = None, -1\n        for a in vp.actors:\n            if a.GetPickable():\n                b = a.GetBounds()\n                d = max(b[1]-b[0], b[3]-b[2], b[5]-b[4])\n                if sz < d:\n                    largestact = a\n                    sz = d\n        if isinstance(largestact, Assembly):\n            ocf.SetInputData(largestact.getActor(0).GetMapper().GetInput())\n        else:\n            ocf.SetInputData(largestact.polydata())\n        ocf.Update()\n        ocMapper = vtk.vtkHierarchicalPolyDataMapper()\n        ocMapper.SetInputConnection(0, ocf.GetOutputPort(0))\n        ocActor = vtk.vtkActor()\n        ocActor.SetMapper(ocMapper)\n        bc = numpy.array(vp.renderer.GetBackground())\n        if numpy.sum(bc) < 1.5:\n            lc = (1, 1, 1)\n        else:\n            lc = (0, 0, 0)\n        ocActor.GetProperty().SetColor(lc)\n        ocActor.PickableOff()\n        vp.renderer.AddActor(ocActor)\n        vp.axes_exist[r] = ocActor\n\n    elif vp.axes == 7:\n        # draws a simple ruler at the bottom of the window\n        ls = vtk.vtkLegendScaleActor()\n        ls.RightAxisVisibilityOff()\n        ls.TopAxisVisibilityOff()\n        ls.LegendVisibilityOff()\n        ls.LeftAxisVisibilityOff()\n        ls.GetBottomAxis().SetNumberOfMinorTicks(1)\n        ls.GetBottomAxis().GetProperty().SetColor(c)\n        ls.GetBottomAxis().GetLabelTextProperty().SetColor(c)\n        ls.GetBottomAxis().GetLabelTextProperty().BoldOff()\n        ls.GetBottomAxis().GetLabelTextProperty().ItalicOff()\n        ls.GetBottomAxis().GetLabelTextProperty().ShadowOff()\n        ls.PickableOff()\n        vp.renderer.AddActor(ls)\n        vp.axes_exist[r] = ls\n\n    elif vp.axes == 8:\n        ca = vtk.vtkCubeAxesActor()\n        ca.SetBounds(vbb)\n        if vp.camera:\n            ca.SetCamera(vp.camera)\n        else:\n            ca.SetCamera(vp.renderer.GetActiveCamera())\n        ca.GetXAxesLinesProperty().SetColor(c)\n        ca.GetYAxesLinesProperty().SetColor(c)\n        ca.GetZAxesLinesProperty().SetColor(c)\n        for i in range(3):\n            ca.GetLabelTextProperty(i).SetColor(c)\n            ca.GetTitleTextProperty(i).SetColor(c)\n        ca.SetTitleOffset(5)\n        ca.SetFlyMode(3)\n        ca.SetXTitle(vp.xtitle)\n        ca.SetYTitle(vp.ytitle)\n        ca.SetZTitle(vp.ztitle)\n        if vp.xtitle == \"\":\n            ca.SetXAxisVisibility(0)\n            ca.XAxisLabelVisibilityOff()\n        if vp.ytitle == \"\":\n            ca.SetYAxisVisibility(0)\n            ca.YAxisLabelVisibilityOff()\n        if vp.ztitle == \"\":\n            ca.SetZAxisVisibility(0)\n            ca.ZAxisLabelVisibilityOff()\n        ca.PickableOff()\n        vp.renderer.AddActor(ca)\n        vp.axes_exist[r] = ca\n        return\n\n    elif vp.axes == 9:\n        src = vtk.vtkCubeSource()\n        src.SetXLength(vbb[1] - vbb[0])\n        src.SetYLength(vbb[3] - vbb[2])\n        src.SetZLength(vbb[5] - vbb[4])\n        src.Update()\n        ca = Actor(src.GetOutput(), c=c, alpha=0.5, wire=1)\n        ca.pos((vbb[0] + vbb[1]) / 2, (vbb[3] + vbb[2]) / 2, (vbb[5] + vbb[4]) / 2)\n        ca.PickableOff()\n        vp.renderer.AddActor(ca)\n        vp.axes_exist[r] = ca\n\n    elif vp.axes == 10:\n        x0 = (vbb[0] + vbb[1]) / 2, (vbb[3] + vbb[2]) / 2, (vbb[5] + vbb[4]) / 2\n        rx, ry, rz = (vbb[1]-vbb[0])/2, (vbb[3]-vbb[2])/2, (vbb[5]-vbb[4])/2\n        rm = max(rx, ry, rz)\n        xc = shapes.Disc(x0, (0,0,1), r1=rm, r2=rm, c='lr', bc=None, res=1, resphi=72)\n        yc = shapes.Disc(x0, (0,1,0), r1=rm, r2=rm, c='lg', bc=None, res=1, resphi=72)\n        zc = shapes.Disc(x0, (1,0,0), r1=rm, r2=rm, c='lb', bc=None, res=1, resphi=72)\n        xc.clean().alpha(0.2).wire().lineWidth(2.5).PickableOff()\n        yc.clean().alpha(0.2).wire().lineWidth(2.5).PickableOff()\n        zc.clean().alpha(0.2).wire().lineWidth(2.5).PickableOff()\n        ca = xc + yc + zc        \n        ca.PickableOff()\n        vp.renderer.AddActor(ca)\n        vp.axes_exist[r] = ca\n\n    else:\n        colors.printc('~bomb Keyword axes must be in range [0-10].', c=1)\n        colors.printc('''\n  ~target Available axes types:\n  0 = no axes,\n  1 = draw three gray grid walls\n  2 = show cartesian axes from (0,0,0)\n  3 = show positive range of cartesian axes from (0,0,0)\n  4 = show a triad at bottom left\n  5 = show a cube at bottom left\n  6 = mark the corners of the bounding box\n  7 = draw a simple ruler at the bottom of the window\n  8 = show the vtkCubeAxesActor object\n  9 = show the bounding box outline\n  10 = show three circles representing the maximum bounding box\n  ''', c=1, bold=0)\n    \n    if not vp.axes_exist[r]:\n        vp.axes_exist[r] = True\n    return", "response": "Draw axes on scene."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if input is iterable.", "response": "def isSequence(arg):\n    \"\"\"Check if input is iterable.\"\"\"\n    if hasattr(arg, \"strip\"):\n        return False\n    if hasattr(arg, \"__getslice__\"):\n        return True\n    if hasattr(arg, \"__iter__\"):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflattens out a list.", "response": "def flatten(list_to_flatten):\n    \"\"\"Flatten out a list.\"\"\"\n\n    def genflatten(lst):\n        for elem in lst:\n            if isinstance(elem, (list, tuple)):\n                for x in flatten(elem):\n                    yield x\n            else:\n                yield elem\n\n    return list(genflatten(list_to_flatten))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsort in place a given list of humans expect.", "response": "def humansort(l):\n    \"\"\"Sort in place a given list the way humans expect.\n\n    E.g. ['file11', 'file1'] -> ['file1', 'file11']\n    \"\"\"\n    import re\n\n    def alphanum_key(s):\n        # Turn a string into a list of string and number chunks.\n        # e.g. \"z23a\" -> [\"z\", 23, \"a\"]\n        def tryint(s):\n            if s.isdigit():\n                return int(s)\n            return s\n\n        return [tryint(c) for c in re.split(\"([0-9]+)\", s)]\n\n    l.sort(key=alphanum_key)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninterpolates linearly variable x in rangeX onto rangeY.", "response": "def lin_interp(x, rangeX, rangeY):\n    \"\"\"\n    Interpolate linearly variable x in rangeX onto rangeY.\n    \"\"\"\n    s = (x - rangeX[0]) / mag(rangeX[1] - rangeX[0])\n    y = rangeY[0] * (1 - s) + rangeY[1] * s\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vector(x, y=None, z=0.0):\n    if y is None:  # assume x is already [x,y,z]\n        return np.array(x, dtype=np.float64)\n    return np.array([x, y, z], dtype=np.float64)", "response": "Return a 3D numpy array representing a vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the unit vector. Input can be a list of vectors.", "response": "def versor(v):\n    \"\"\"Return the unit vector. Input can be a list of vectors.\"\"\"\n    if isinstance(v[0], np.ndarray):\n        return np.divide(v, mag(v)[:, None])\n    else:\n        return v / mag(v)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mag(z):\n    if isinstance(z[0], np.ndarray):\n        return np.array(list(map(np.linalg.norm, z)))\n    else:\n        return np.linalg.norm(z)", "response": "Get the magnitude of a vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string representation of x formatted with precision p.", "response": "def precision(x, p):\n    \"\"\"\n    Returns a string representation of `x` formatted with precision `p`.\n\n    Based on the webkit javascript implementation taken \n    `from here <https://code.google.com/p/webkit-mirror/source/browse/JavaScriptCore/kjs/number_object.cpp>`_,\n    and implemented by `randlet <https://github.com/randlet/to-precision>`_.\n    \"\"\"\n    import math\n\n    x = float(x)\n\n    if x == 0.0:\n        return \"0.\" + \"0\" * (p - 1)\n\n    out = []\n    if x < 0:\n        out.append(\"-\")\n        x = -x\n\n    e = int(math.log10(x))\n    tens = math.pow(10, e - p + 1)\n    n = math.floor(x / tens)\n\n    if n < math.pow(10, p - 1):\n        e = e - 1\n        tens = math.pow(10, e - p + 1)\n        n = math.floor(x / tens)\n\n    if abs((n + 1.0) * tens - x) <= abs(n * tens - x):\n        n = n + 1\n\n    if n >= math.pow(10, p):\n        n = n / 10.0\n        e = e + 1\n\n    m = \"%.*g\" % (p, n)\n    if e < -2 or e >= p:\n        out.append(m[0])\n        if p > 1:\n            out.append(\".\")\n            out.extend(m[1:p])\n        out.append(\"e\")\n        if e > 0:\n            out.append(\"+\")\n        out.append(str(e))\n    elif e == (p - 1):\n        out.append(m)\n    elif e >= 0:\n        out.append(m[: e + 1])\n        if e + 1 < len(m):\n            out.append(\".\")\n            out.extend(m[e + 1 :])\n    else:\n        out.append(\"0.\")\n        out.extend([\"0\"] * -(e + 1))\n        out.append(m)\n    return \"\".join(out)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if a point is inside a triangle defined by 3 points in space.", "response": "def pointIsInTriangle(p, p1, p2, p3):\n    \"\"\"\n    Return True if a point is inside (or above/below) a triangle defined by 3 points in space.\n    \"\"\"\n    p = np.array(p)\n    u = np.array(p2) - p1\n    v = np.array(p3) - p1\n    n = np.cross(u, v)\n    w = p - p1\n    ln = np.dot(n, n)\n    if not ln:\n        return True  # degenerate triangle\n    gamma = (np.dot(np.cross(u, w), n)) / ln\n    beta = (np.dot(np.cross(w, v), n)) / ln\n    alpha = 1 - gamma - beta\n    if 0 < alpha < 1 and 0 < beta < 1 and 0 < gamma < 1:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the distance of a point to a line defined by p1 and p2.", "response": "def pointToLineDistance(p, p1, p2):\n    \"\"\"Compute the distance of a point to a line (not the segment) defined by `p1` and `p2`.\"\"\"\n    d = np.sqrt(vtk.vtkLine.DistanceToLine(p, p1, p2))\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cart2spher(x, y, z):\n    hxy = np.hypot(x, y)\n    r = np.hypot(hxy, z)\n    theta = np.arctan2(z, hxy)\n    phi = np.arctan2(y, x)\n    return r, theta, phi", "response": "Cartesian to Spherical coordinate conversion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cart2pol(x, y):\n    theta = np.arctan2(y, x)\n    rho = np.hypot(x, y)\n    return theta, rho", "response": "Cartesian to Polar coordinates conversion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pol2cart(theta, rho):\n    x = rho * np.cos(theta)\n    y = rho * np.sin(theta)\n    return x, y", "response": "Polar to Cartesian coordinates conversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isIdentity(M, tol=1e-06):\n    for i in [0, 1, 2, 3]:\n        for j in [0, 1, 2, 3]:\n            e = M.GetElement(i, j)\n            if i == j:\n                if np.abs(e - 1) > tol:\n                    return False\n            elif np.abs(e) > tol:\n                return False\n    return True", "response": "Check if vtkMatrix4x4 is Identity."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints information about a vtk object.", "response": "def printInfo(obj):\n    \"\"\"Print information about a vtk object.\"\"\"\n\n    def printvtkactor(actor, tab=\"\"):\n\n        if not actor.GetPickable():\n            return\n\n        if hasattr(actor, \"polydata\"):\n            poly = actor.polydata()\n        else:\n            poly = actor.GetMapper().GetInput()\n        pro = actor.GetProperty()\n        pos = actor.GetPosition()\n        bnds = actor.GetBounds()\n        col = pro.GetColor()\n        colr = precision(col[0], 3)\n        colg = precision(col[1], 3)\n        colb = precision(col[2], 3)\n        alpha = pro.GetOpacity()\n        npt = poly.GetNumberOfPoints()\n        ncl = poly.GetNumberOfCells()\n\n        print(tab, end=\"\")\n        colors.printc(\"vtkActor\", c=\"g\", bold=1, invert=1, dim=1, end=\" \")\n\n        if hasattr(actor, \"_legend\") and actor._legend:\n            colors.printc(\"legend: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(actor._legend, c=\"g\", bold=0)\n        else:\n            print()\n\n        if hasattr(actor, \"filename\") and actor.filename:\n            colors.printc(tab + \"           file: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(actor.filename, c=\"g\", bold=0)\n\n        colors.printc(tab + \"          color: \", c=\"g\", bold=1, end=\"\")\n        if actor.GetMapper().GetScalarVisibility():\n            colors.printc(\"defined by point or cell data\", c=\"g\", bold=0)\n        else:\n            colors.printc(colors.getColorName(col) + ', rgb=('+colr+', '\n                          + colg+', '+colb+'), alpha='+str(alpha), c='g', bold=0)\n\n            if actor.GetBackfaceProperty():\n                bcol = actor.GetBackfaceProperty().GetDiffuseColor()\n                bcolr = precision(bcol[0], 3)\n                bcolg = precision(bcol[1], 3)\n                bcolb = precision(bcol[2], 3)\n                colors.printc(tab+'     back color: ', c='g', bold=1, end='')\n                colors.printc(colors.getColorName(bcol) + ', rgb=('+bcolr+', '\n                              + bcolg+', ' + bcolb+')', c='g', bold=0)\n\n        colors.printc(tab + \"         points: \", c=\"g\", bold=1, end=\"\")\n        colors.printc(npt, c=\"g\", bold=0)\n\n        colors.printc(tab + \"          cells: \", c=\"g\", bold=1, end=\"\")\n        colors.printc(ncl, c=\"g\", bold=0)\n\n        colors.printc(tab + \"       position: \", c=\"g\", bold=1, end=\"\")\n        colors.printc(pos, c=\"g\", bold=0)\n\n        if hasattr(actor, \"polydata\"):\n            colors.printc(tab + \"     c. of mass: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(actor.centerOfMass(), c=\"g\", bold=0)\n\n            colors.printc(tab + \"      ave. size: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(precision(actor.averageSize(), 4), c=\"g\", bold=0)\n\n            colors.printc(tab + \"     diag. size: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(actor.diagonalSize(), c=\"g\", bold=0)\n\n            colors.printc(tab + \"           area: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(precision(actor.area(), 8), c=\"g\", bold=0)\n\n            colors.printc(tab + \"         volume: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(precision(actor.volume(), 8), c=\"g\", bold=0)\n\n        colors.printc(tab + \"         bounds: \", c=\"g\", bold=1, end=\"\")\n        bx1, bx2 = precision(bnds[0], 3), precision(bnds[1], 3)\n        colors.printc(\"x=(\" + bx1 + \", \" + bx2 + \")\", c=\"g\", bold=0, end=\"\")\n        by1, by2 = precision(bnds[2], 3), precision(bnds[3], 3)\n        colors.printc(\" y=(\" + by1 + \", \" + by2 + \")\", c=\"g\", bold=0, end=\"\")\n        bz1, bz2 = precision(bnds[4], 3), precision(bnds[5], 3)\n        colors.printc(\" z=(\" + bz1 + \", \" + bz2 + \")\", c=\"g\", bold=0)\n\n        arrtypes = dict()\n        arrtypes[vtk.VTK_UNSIGNED_CHAR] = \"VTK_UNSIGNED_CHAR\"\n        arrtypes[vtk.VTK_UNSIGNED_INT] = \"VTK_UNSIGNED_INT\"\n        arrtypes[vtk.VTK_FLOAT] = \"VTK_FLOAT\"\n        arrtypes[vtk.VTK_DOUBLE] = \"VTK_DOUBLE\"\n\n        if poly.GetPointData():\n            ptdata = poly.GetPointData()\n            for i in range(ptdata.GetNumberOfArrays()):\n                name = ptdata.GetArrayName(i)\n                if name:\n                    colors.printc(tab + \"     point data: \", c=\"g\", bold=1, end=\"\")\n                    try:\n                        tt = arrtypes[ptdata.GetArray(i).GetDataType()]\n                        colors.printc(\"name=\" + name, \"type=\" + tt, c=\"g\", bold=0)\n                    except:\n                        tt = ptdata.GetArray(i).GetDataType()\n                        colors.printc(\"name=\" + name, \"type=\", tt, c=\"g\", bold=0)\n\n        if poly.GetCellData():\n            cldata = poly.GetCellData()\n            for i in range(cldata.GetNumberOfArrays()):\n                name = cldata.GetArrayName(i)\n                if name:\n                    colors.printc(tab + \"      cell data: \", c=\"g\", bold=1, end=\"\")\n                    try:\n                        tt = arrtypes[cldata.GetArray(i).GetDataType()]\n                        colors.printc(\"name=\" + name, \"type=\" + tt, c=\"g\", bold=0)\n                    except:\n                        tt = cldata.GetArray(i).GetDataType()\n                        colors.printc(\"name=\" + name, \"type=\", tt, c=\"g\", bold=0)\n\n    if not obj:\n        return\n\n    elif isinstance(obj, vtk.vtkActor):\n        colors.printc(\"_\" * 60, c=\"g\", bold=0)\n        printvtkactor(obj)\n\n    elif isinstance(obj, vtk.vtkAssembly):\n        colors.printc(\"_\" * 60, c=\"g\", bold=0)\n        colors.printc(\"vtkAssembly\", c=\"g\", bold=1, invert=1, end=\" \")\n        if hasattr(obj, \"_legend\"):\n            colors.printc(\"legend: \", c=\"g\", bold=1, end=\"\")\n            colors.printc(obj._legend, c=\"g\", bold=0)\n        else:\n            print()\n\n        pos = obj.GetPosition()\n        bnds = obj.GetBounds()\n        colors.printc(\"          position: \", c=\"g\", bold=1, end=\"\")\n        colors.printc(pos, c=\"g\", bold=0)\n\n        colors.printc(\"            bounds: \", c=\"g\", bold=1, end=\"\")\n        bx1, bx2 = precision(bnds[0], 3), precision(bnds[1], 3)\n        colors.printc(\"x=(\" + bx1 + \", \" + bx2 + \")\", c=\"g\", bold=0, end=\"\")\n        by1, by2 = precision(bnds[2], 3), precision(bnds[3], 3)\n        colors.printc(\" y=(\" + by1 + \", \" + by2 + \")\", c=\"g\", bold=0, end=\"\")\n        bz1, bz2 = precision(bnds[4], 3), precision(bnds[5], 3)\n        colors.printc(\" z=(\" + bz1 + \", \" + bz2 + \")\", c=\"g\", bold=0)\n\n        cl = vtk.vtkPropCollection()\n        obj.GetActors(cl)\n        cl.InitTraversal()\n        for i in range(obj.GetNumberOfPaths()):\n            act = vtk.vtkActor.SafeDownCast(cl.GetNextProp())\n            if isinstance(act, vtk.vtkActor):\n                printvtkactor(act, tab=\"     \")\n\n    elif hasattr(obj, \"interactor\"):  # dumps Plotter info\n        axtype = {\n            0: \"(no axes)\",\n            1: \"(three gray grid walls)\",\n            2: \"(cartesian axes from origin\",\n            3: \"(positive range of cartesian axes from origin\",\n            4: \"(axes triad at bottom left)\",\n            5: \"(oriented cube at bottom left)\",\n            6: \"(mark the corners of the bounding box)\",\n            7: \"(ruler at the bottom of the window)\",\n            8: \"(the vtkCubeAxesActor object)\",\n            9: \"(the bounding box outline)\",\n            10: \"(circles of maximum bounding box range)\",\n        }\n        bns, totpt = [], 0\n        for a in obj.actors:\n            b = a.GetBounds()\n            if a.GetBounds() is not None:\n                if isinstance(a, vtk.vtkActor):\n                    totpt += a.GetMapper().GetInput().GetNumberOfPoints()\n                bns.append(b)\n        if len(bns) == 0:\n            return\n        acts = obj.getActors()\n        colors.printc(\"_\" * 60, c=\"c\", bold=0)\n        colors.printc(\"Plotter\", invert=1, dim=1, c=\"c\", end=\" \")\n        otit = obj.title\n        if not otit:\n            otit = None\n        colors.printc(\"   title:\", otit, bold=0, c=\"c\")\n        colors.printc(\" active renderer:\", obj.renderers.index(obj.renderer), bold=0, c=\"c\")\n        colors.printc(\"   nr. of actors:\", len(acts), bold=0, c=\"c\", end=\"\")\n        colors.printc(\" (\" + str(totpt), \"vertices)\", bold=0, c=\"c\")\n        max_bns = np.max(bns, axis=0)\n        min_bns = np.min(bns, axis=0)\n        colors.printc(\"      max bounds: \", c=\"c\", bold=0, end=\"\")\n        bx1, bx2 = precision(min_bns[0], 3), precision(max_bns[1], 3)\n        colors.printc(\"x=(\" + bx1 + \", \" + bx2 + \")\", c=\"c\", bold=0, end=\"\")\n        by1, by2 = precision(min_bns[2], 3), precision(max_bns[3], 3)\n        colors.printc(\" y=(\" + by1 + \", \" + by2 + \")\", c=\"c\", bold=0, end=\"\")\n        bz1, bz2 = precision(min_bns[4], 3), precision(max_bns[5], 3)\n        colors.printc(\" z=(\" + bz1 + \", \" + bz2 + \")\", c=\"c\", bold=0)\n        colors.printc(\"       axes type:\", obj.axes, axtype[obj.axes], bold=0, c=\"c\")\n\n        for a in obj.actors:\n            if a.GetBounds() is not None:\n                if isinstance(a, vtk.vtkVolume):  # dumps Volume info\n                    img = a.GetMapper().GetDataSetInput()\n                    colors.printc('_'*60, c='b', bold=0)\n                    colors.printc('Volume', invert=1, dim=1, c='b')\n                    colors.printc('      scalar range:',\n                                  np.round(img.GetScalarRange(), 4), c='b', bold=0)\n                    bnds = a.GetBounds()\n                    colors.printc(\"            bounds: \", c=\"b\", bold=0, end=\"\")\n                    bx1, bx2 = precision(bnds[0], 3), precision(bnds[1], 3)\n                    colors.printc(\"x=(\" + bx1 + \", \" + bx2 + \")\", c=\"b\", bold=0, end=\"\")\n                    by1, by2 = precision(bnds[2], 3), precision(bnds[3], 3)\n                    colors.printc(\" y=(\" + by1 + \", \" + by2 + \")\", c=\"b\", bold=0, end=\"\")\n                    bz1, bz2 = precision(bnds[4], 3), precision(bnds[5], 3)\n                    colors.printc(\" z=(\" + bz1 + \", \" + bz2 + \")\", c=\"b\", bold=0)\n\n        colors.printc(\" Click actor and press i for Actor info.\", c=\"c\")\n\n    else:\n        colors.printc(\"_\" * 60, c=\"g\", bold=0)\n        colors.printc(obj, c=\"g\")\n        colors.printc(type(obj), c=\"g\", invert=1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngroup values of a list into bands of equal value. :param int numberOfBands: number of bands, a positive integer > 2. :return: a binned list of the same length as the input.", "response": "def makeBands(inputlist, numberOfBands):\n    \"\"\"\n    Group values of a list into bands of equal value.\n\n    :param int numberOfBands: number of bands, a positive integer > 2.\n    :return: a binned list of the same length as the input.\n    \"\"\"\n    if numberOfBands < 2:\n        return inputlist\n    vmin = np.min(inputlist)\n    vmax = np.max(inputlist)\n    bb = np.linspace(vmin, vmax, numberOfBands, endpoint=0)\n    dr = bb[1] - bb[0]\n    bb += dr / 2\n    tol = dr / 2 * 1.001\n\n    newlist = []\n    for s in inputlist:\n        for b in bb:\n            if abs(s - b) < tol:\n                newlist.append(b)\n                break\n\n    return np.array(newlist)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow the objects in a new object.", "response": "def show(*actors, **options\n#    at=None,\n#    shape=(1, 1),\n#    N=None,\n#    pos=(0, 0),\n#    size=\"auto\",\n#    screensize=\"auto\",\n#    title=\"\",\n#    bg=\"blackboard\",\n#    bg2=None,\n#    axes=4,\n#    infinity=False,\n#    verbose=True,\n#    interactive=None,\n#    offscreen=False,\n#    resetcam=True,\n#    zoom=None,\n#    viewup=\"\",\n#    azimuth=0,\n#    elevation=0,\n#    roll=0,\n#    interactorStyle=0,\n#    newPlotter=False,\n#    depthpeeling=False,\n#    q=False,\n):\n    \"\"\"\n    Create on the fly an instance of class ``Plotter`` and show the object(s) provided.\n\n    Allowed input objects are: ``filename``, ``vtkPolyData``, ``vtkActor``, \n    ``vtkActor2D``, ``vtkImageActor``, ``vtkAssembly`` or ``vtkVolume``.\n\n    If filename is given, its type is guessed based on its extension.\n    Supported formats are: \n    `vtu, vts, vtp, ply, obj, stl, 3ds, xml, neutral, gmsh, pcd, xyz, txt, byu,\n    tif, slc, vti, mhd, png, jpg`.\n\n    :param bool newPlotter: if set to `True`, a call to ``show`` will instantiate\n        a new ``Plotter`` object (a new window) instead of reusing the first created.\n        See e.g.: |readVolumeAsIsoSurface.py|_\n    :return: the current ``Plotter`` class instance.\n\n    .. note:: With multiple renderers, keyword ``at`` can become a `list`, e.g.\n\n        .. code-block:: python\n        \n            from vtkplotter import *\n            s = Sphere()\n            c = Cube()\n            p = Paraboloid()\n            show(s, c, at=[0, 1], shape=(3,1))\n            show(p, at=2, interactive=True)\n            #\n            # is equivalent to:\n            vp = Plotter(shape=(3,1))\n            s = Sphere()\n            c = Cube()\n            p = Paraboloid()\n            vp.show(s, at=0)\n            vp.show(p, at=1)\n            vp.show(c, at=2, interactive=True)\n    \"\"\"\n    at = options.pop(\"at\", None)\n    shape = options.pop(\"shape\", (1, 1))\n    N = options.pop(\"N\", None)\n    pos = options.pop(\"pos\", (0, 0))\n    size = options.pop(\"size\", \"auto\")\n    screensize = options.pop(\"screensize\", \"auto\")\n    title = options.pop(\"title\", \"\")\n    bg = options.pop(\"bg\", \"blackboard\")\n    bg2 = options.pop(\"bg2\", None)\n    axes = options.pop(\"axes\", 4)\n    infinity = options.pop(\"infinity\", False)\n    verbose = options.pop(\"verbose\", True)\n    interactive = options.pop(\"interactive\", None)\n    offscreen = options.pop(\"offscreen\", False)\n    resetcam = options.pop(\"resetcam\", True)\n    zoom = options.pop(\"zoom\", None)\n    viewup = options.pop(\"viewup\", \"\")\n    azimuth = options.pop(\"azimuth\", 0)\n    elevation = options.pop(\"elevation\", 0)\n    roll = options.pop(\"roll\", 0)\n    interactorStyle = options.pop(\"interactorStyle\", 0)\n    newPlotter = options.pop(\"newPlotter\", False)\n    depthpeeling = options.pop(\"depthpeeling\", False)\n    q = options.pop(\"q\", False)\n\n    if len(actors) == 0:\n        actors = None\n    elif len(actors) == 1:\n        actors = actors[0]\n    else:\n        actors = utils.flatten(actors)\n\n    if settings.plotter_instance and newPlotter == False:\n        vp = settings.plotter_instance\n    else:\n        if utils.isSequence(at):\n            if not utils.isSequence(actors):\n                colors.printc(\"~times show() Error: input must be a list.\", c=1)\n                exit()\n            if len(at) != len(actors):\n                colors.printc(\"~times show() Error: lists 'input' and 'at', must have equal lengths.\", c=1)\n                exit()\n            if len(at) > 1 and (shape == (1, 1) and N == None):\n                N = max(at) + 1\n        elif at is None and (N or shape != (1, 1)):\n            if not utils.isSequence(actors):\n                colors.printc('~times show() Error: N or shape is set, but input is not a sequence.', c=1)\n                colors.printc('              you may need to specify e.g. at=0', c=1)\n                exit()\n            at = range(len(actors))\n\n        vp = Plotter(\n            shape=shape,\n            N=N,\n            pos=pos,\n            size=size,\n            screensize=screensize,\n            title=title,\n            bg=bg,\n            bg2=bg2,\n            axes=axes,\n            infinity=infinity,\n            depthpeeling=depthpeeling,\n            verbose=verbose,\n            interactive=interactive,\n            offscreen=offscreen,\n        )\n\n    if utils.isSequence(at):\n        for i, a in enumerate(actors):\n            vp.show(\n                a,\n                at=i,\n                zoom=zoom,\n                resetcam=resetcam,\n                viewup=viewup,\n                azimuth=azimuth,\n                elevation=elevation,\n                roll=roll,\n                interactive=interactive,\n                interactorStyle=interactorStyle,\n                q=q,\n            )\n        vp.interactor.Start()\n    else:\n        vp.show(\n            actors,\n            at=at,\n            zoom=zoom,\n            resetcam=resetcam,\n            viewup=viewup,\n            azimuth=azimuth,\n            elevation=elevation,\n            roll=roll,\n            interactive=interactive,\n            interactorStyle=interactorStyle,\n            q=q,\n        )\n\n    return vp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(actor=()):\n    if not settings.plotter_instance:\n        return\n    settings.plotter_instance.clear(actor)\n    return settings.plotter_instance", "response": "Clear the current actor or list of actors from the current rendering window."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plotMatrix(M, title='matrix', continuous=True, cmap='Greys'):\n    import matplotlib.pyplot as plt\n    import matplotlib as mpl\n    from mpl_toolkits.axes_grid1 import make_axes_locatable\n    \n    M    = numpy.array(M)\n    m,n  = numpy.shape(M)\n    M    = M.round(decimals=2)\n\n    fig  = plt.figure()\n    ax   = fig.add_subplot(111)\n    cmap = mpl.cm.get_cmap(cmap)\n    if not continuous:\n        unq  = numpy.unique(M)\n    im      = ax.imshow(M, cmap=cmap, interpolation='None')\n    divider = make_axes_locatable(ax)\n    cax     = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    dim     = r'$%i \\times %i$ ' % (m,n)\n    ax.set_title(dim + title)\n    ax.axis('off')\n    cb = plt.colorbar(im, cax=cax)\n    if not continuous:\n       cb.set_ticks(unq)\n       cb.set_ticklabels(unq)\n    plt.show()", "response": "Plots a matrix using matplotlib."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a vtkActor from a file directory or vtkPolyData object.", "response": "def load(\n        self,\n        inputobj,\n        c=\"gold\",\n        alpha=1,\n        wire=False,\n        bc=None,\n        texture=None,\n        smoothing=None,\n        threshold=None,\n        connectivity=False,\n    ):\n        \"\"\"\n        Returns a ``vtkActor`` from reading a file, directory or ``vtkPolyData``.\n\n        :param c: color in RGB format, hex, symbol or name\n        :param alpha:   transparency (0=invisible)\n        :param wire:    show surface as wireframe\n        :param bc:      backface color of internal surface\n        :param texture: any png/jpg file can be used as texture\n\n        For volumetric data (tiff, slc, vti files):\n\n        :param smoothing:    gaussian filter to smooth vtkImageData\n        :param threshold:    value to draw the isosurface\n        :param bool connectivity: if True only keeps the largest portion of the polydata\n        \"\"\"\n        acts = vtkio.load(inputobj, c, alpha, wire, bc, texture, smoothing, threshold, connectivity)\n        if utils.isSequence(acts):\n            self.actors += acts\n        else:\n            self.actors.append(acts)\n        return acts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getVolumes(self, obj=None, renderer=None):\n        if renderer is None:\n            renderer = self.renderer\n        elif isinstance(renderer, int):\n                renderer = self.renderers.index(renderer)\n        else:\n            return []\n        \n        if obj is None or isinstance(obj, int):\n            if obj is None:\n                acs = renderer.GetVolumes()\n            elif obj >= len(self.renderers):\n                colors.printc(\"~timesError in getVolumes: non existing renderer\", obj, c=1)\n                return []\n            else:\n                acs = self.renderers[obj].GetVolumes()\n            vols = []\n            acs.InitTraversal()\n            for i in range(acs.GetNumberOfItems()):\n                a = acs.GetNextItem()\n                if a.GetPickable():\n                    r = self.renderers.index(renderer)\n                    if a == self.axes_exist[r]:\n                        continue\n                    vols.append(a)\n            return vols", "response": "Returns the list of rendered Volumes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of actors in a given renderer.", "response": "def getActors(self, obj=None, renderer=None):\n        \"\"\"\n        Return an actors list.\n\n        If ``obj`` is:\n            ``None``, return actors of current renderer\n\n            ``int``, return actors in given renderer number\n\n            ``vtkAssembly`` return the contained actors\n\n            ``string``, return actors matching legend name\n\n        :param int,vtkRenderer renderer: specify which renederer to look into.\n        \"\"\"\n        if renderer is None:\n            renderer = self.renderer\n        elif isinstance(renderer, int):\n                renderer = self.renderers.index(renderer)\n        else:\n            return []\n\n        if obj is None or isinstance(obj, int):\n            if obj is None:\n                acs = renderer.GetActors()\n            elif obj >= len(self.renderers):\n                colors.printc(\"~timesError in getActors: non existing renderer\", obj, c=1)\n                return []\n            else:\n                acs = self.renderers[obj].GetActors()\n            actors = []\n            acs.InitTraversal()\n            for i in range(acs.GetNumberOfItems()):\n                a = acs.GetNextItem()\n                if a.GetPickable():\n                    r = self.renderers.index(renderer)\n                    if a == self.axes_exist[r]:\n                        continue\n                    actors.append(a)\n            return actors\n\n        elif isinstance(obj, vtk.vtkAssembly):\n            cl = vtk.vtkPropCollection()\n            obj.GetActors(cl)\n            actors = []\n            cl.InitTraversal()\n            for i in range(obj.GetNumberOfPaths()):\n                act = vtk.vtkActor.SafeDownCast(cl.GetNextProp())\n                if act.GetPickable():\n                    actors.append(act)\n            return actors\n\n        elif isinstance(obj, str):  # search the actor by the legend name\n            actors = []\n            for a in self.actors:\n                if hasattr(a, \"_legend\") and obj in a._legend:\n                    actors.append(a)\n            return actors\n\n        elif isinstance(obj, vtk.vtkActor):\n            return [obj]\n\n        if self.verbose:\n            colors.printc(\"~lightning Warning in getActors: unexpected input type\", obj, c=1)\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend input object to the internal list of actors to be shown.", "response": "def add(self, actors):\n        \"\"\"Append input object to the internal list of actors to be shown.\n\n        :return: returns input actor for possible concatenation.\n        \"\"\"\n        if utils.isSequence(actors):\n            for a in actors:\n                if a not in self.actors:\n                    self.actors.append(a)\n            return None\n        else:\n            self.actors.append(actors)\n            return actors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove the camera to the new position and returns a new vtkCamera object that is at the new position and the new fraction.", "response": "def moveCamera(self, camstart, camstop, fraction):\n        \"\"\"\n        Takes as input two ``vtkCamera`` objects and returns a\n        new ``vtkCamera`` that is at an intermediate position:\n\n        fraction=0 -> camstart,  fraction=1 -> camstop.\n\n        Press ``shift-C`` key in interactive mode to dump a python snipplet\n        of parameters for the current camera view.\n        \"\"\"\n        if isinstance(fraction, int):\n            colors.printc(\"~lightning Warning in moveCamera(): fraction should not be an integer\", c=1)\n        if fraction > 1:\n            colors.printc(\"~lightning Warning in moveCamera(): fraction is > 1\", c=1)\n        cam = vtk.vtkCamera()\n        cam.DeepCopy(camstart)\n        p1 = numpy.array(camstart.GetPosition())\n        f1 = numpy.array(camstart.GetFocalPoint())\n        v1 = numpy.array(camstart.GetViewUp())\n        c1 = numpy.array(camstart.GetClippingRange())\n        s1 = camstart.GetDistance()\n\n        p2 = numpy.array(camstop.GetPosition())\n        f2 = numpy.array(camstop.GetFocalPoint())\n        v2 = numpy.array(camstop.GetViewUp())\n        c2 = numpy.array(camstop.GetClippingRange())\n        s2 = camstop.GetDistance()\n        cam.SetPosition(p2 * fraction + p1 * (1 - fraction))\n        cam.SetFocalPoint(f2 * fraction + f1 * (1 - fraction))\n        cam.SetViewUp(v2 * fraction + v1 * (1 - fraction))\n        cam.SetDistance(s2 * fraction + s1 * (1 - fraction))\n        cam.SetClippingRange(c2 * fraction + c1 * (1 - fraction))\n        self.camera = cam\n        save_int = self.interactive\n        self.show(resetcam=0, interactive=0)\n        self.interactive = save_int"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a source of light from a set of unique items.", "response": "def light(\n        self,\n        pos=(1, 1, 1),\n        fp=(0, 0, 0),\n        deg=25,\n        diffuse=\"y\",\n        ambient=\"r\",\n        specular=\"b\",\n        showsource=False,\n    ):\n        \"\"\"\n        Generate a source of light placed at pos, directed to focal point fp.\n\n        :param fp: focal Point, if this is a ``vtkActor`` use its position.\n        :type fp: vtkActor, list\n        :param deg: aperture angle of the light source\n        :param showsource: if `True`, will show a vtk representation\n                            of the source of light as an extra actor\n\n        .. hint:: |lights.py|_\n        \"\"\"\n        if isinstance(fp, vtk.vtkActor):\n            fp = fp.GetPosition()\n        light = vtk.vtkLight()\n        light.SetLightTypeToSceneLight()\n        light.SetPosition(pos)\n        light.SetPositional(1)\n        light.SetConeAngle(deg)\n        light.SetFocalPoint(fp)\n        light.SetDiffuseColor(colors.getColor(diffuse))\n        light.SetAmbientColor(colors.getColor(ambient))\n        light.SetSpecularColor(colors.getColor(specular))\n        save_int = self.interactive\n        self.show(interactive=0)\n        self.interactive = save_int\n        if showsource:\n            lightActor = vtk.vtkLightActor()\n            lightActor.SetLight(light)\n            self.renderer.AddViewProp(lightActor)\n            self.renderer.AddLight(light)\n        return light"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addScalarBar(self, actor=None, c=None, title=\"\", horizontal=False, vmin=None, vmax=None):\n        return addons.addScalarBar(actor, c, title, horizontal, vmin, vmax)", "response": "Add a 2D scalar bar for the specified actor."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw a 3D scalar bar.", "response": "def addScalarBar3D(\n        self,\n        obj=None,\n        at=0,\n        pos=(0, 0, 0),\n        normal=(0, 0, 1),\n        sx=0.1,\n        sy=2,\n        nlabels=9,\n        ncols=256,\n        cmap=None,\n        c=None,\n        alpha=1,\n    ):\n        \"\"\"Draw a 3D scalar bar.\n\n        ``obj`` input can be:\n            - a list of numbers,\n            - a list of two numbers in the form `(min, max)`,\n            - a ``vtkActor`` already containing a set of scalars associated to vertices or cells,\n            - if ``None`` the last actor in the list of actors will be used.\n\n        .. hint:: |scalbar| |mesh_coloring.py|_\n        \"\"\"\n        return addons.addScalarBar3D(obj, at, pos, normal, sx, sy, nlabels, ncols, cmap, c, alpha)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addSlider2D(\n        self, sliderfunc, xmin, xmax, value=None, pos=4, s=0.04, title=\"\", c=None, showValue=True\n    ):\n        \"\"\"Add a slider widget which can call an external custom function.\n\n        :param sliderfunc: external function to be called by the widget\n        :param float xmin:  lower value\n        :param float xmax:  upper value\n        :param float value: current value\n        :param list pos:  position corner number: horizontal [1-4] or vertical [11-14]\n                            it can also be specified by corners coordinates [(x1,y1), (x2,y2)]\n        :param str title: title text\n        :param bool showValue:  if true current value is shown\n\n        .. hint:: |sliders| |sliders.py|_\n        \"\"\"\n        return addons.addSlider2D(sliderfunc, xmin, xmax, value, pos, s, title, c, showValue)", "response": "Add a slider widget which can call an external function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a slider widget which can call an external function.", "response": "def addSlider3D(\n        self,\n        sliderfunc,\n        pos1,\n        pos2,\n        xmin,\n        xmax,\n        value=None,\n        s=0.03,\n        title=\"\",\n        rotation=0,\n        c=None,\n        showValue=True,\n    ):\n        \"\"\"Add a 3D slider widget which can call an external custom function.\n\n        :param sliderfunc: external function to be called by the widget\n        :param list pos1: first position coordinates\n        :param list pos2: second position coordinates\n        :param float xmin:  lower value\n        :param float xmax:  upper value\n        :param float value: initial value\n        :param float s: label scaling factor\n        :param str title: title text\n        :param c: slider color\n        :param float rotation: title rotation around slider axis\n        :param bool showValue: if True current value is shown\n\n        .. hint:: |sliders3d| |sliders3d.py|_\n        \"\"\"\n        return addons.addSlider3D(\n            sliderfunc, pos1, pos2, xmin, xmax, value, s, title, rotation, c, showValue\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addButton(\n        self,\n        fnc,\n        states=(\"On\", \"Off\"),\n        c=(\"w\", \"w\"),\n        bc=(\"dg\", \"dr\"),\n        pos=(20, 40),\n        size=24,\n        font=\"arial\",\n        bold=False,\n        italic=False,\n        alpha=1,\n        angle=0,\n    ):\n        \"\"\"Add a button to the renderer window.\n        \n        :param list states: a list of possible states ['On', 'Off']\n        :param c:      a list of colors for each state\n        :param bc:     a list of background colors for each state\n        :param pos:    2D position in pixels from left-bottom corner\n        :param size:   size of button font\n        :param str font:   font type (arial, courier, times)\n        :param bool bold:   bold face (False)\n        :param bool italic: italic face (False)\n        :param float alpha:  opacity level\n        :param float angle:  anticlockwise rotation in degrees\n\n        .. hint:: |buttons| |buttons.py|_\n        \"\"\"\n        return addons.addButton(fnc, states, c, bc, pos, size, font, bold, italic, alpha, angle)", "response": "Add a button to the renderer window."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addIcon(self, iconActor, pos=3, size=0.08):\n        return addons.addIcon(iconActor, pos, size)", "response": "Add an inset icon mesh into the same renderer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows a list of actors.", "response": "def show(\n        self,\n        *actors, **options\n#        at=None,\n#        axes=None,\n#        c=None,\n#        alpha=None,\n#        wire=False,\n#        bc=None,\n#        resetcam=True,\n#        zoom=False,\n#        interactive=None,\n#        rate=None,\n#        viewup=\"\",\n#        azimuth=0,\n#        elevation=0,\n#        roll=0,\n#        interactorStyle=0,\n#        q=False,\n    ):\n        \"\"\"\n        Render a list of actors.\n\n        Allowed input objects are: ``filename``, ``vtkPolyData``, ``vtkActor``,\n        ``vtkActor2D``, ``vtkImageActor``, ``vtkAssembly`` or ``vtkVolume``.\n\n        If filename is given, its type is guessed based on its extension.\n        Supported formats are:\n        `vtu, vts, vtp, ply, obj, stl, 3ds, xml, neutral, gmsh, pcd, xyz, txt, byu,\n        tif, slc, vti, mhd, png, jpg`.\n\n        :param int at: number of the renderer to plot to, if more than one exists\n        :param int axes: set the type of axes to be shown\n\n              - 0,  no axes,\n              - 1,  draw three gray grid walls\n              - 2,  show cartesian axes from (0,0,0)\n              - 3,  show positive range of cartesian axes from (0,0,0)\n              - 4,  show a triad at bottom left\n              - 5,  show a cube at bottom left\n              - 6,  mark the corners of the bounding box\n              - 7,  draw a simple ruler at the bottom of the window\n              - 8,  show the ``vtkCubeAxesActor`` object,\n              - 9,  show the bounding box outLine,\n              - 10, show three circles representing the maximum bounding box\n\n        :param c:     surface color, in rgb, hex or name formats\n        :param bc:    set a color for the internal surface face\n        :param bool wire:  show actor in wireframe representation\n        :param float azimuth/elevation/roll:  move camera accordingly\n        :param str viewup:  either ['x', 'y', 'z'] or a vector to set vertical direction\n        :param bool resetcam:  re-adjust camera position to fit objects\n        :param bool interactive:  pause and interact with window (True)\n            or continue execution (False)\n        :param float rate:  maximum rate of `show()` in Hertz\n        :param int interactorStyle: set the type of interaction\n\n            - 0, TrackballCamera\n            - 1, TrackballActor\n            - 2, JoystickCamera\n            - 3, Unicam\n            - 4, Flight\n            - 5, RubberBand3D\n            - 6, RubberBandZoom\n\n        :param bool q:  force program to quit after `show()` command returns.\n        \"\"\"\n        at = options.pop(\"at\", None)\n        axes = options.pop(\"axes\", None)\n        c = options.pop(\"c\", None)\n        alpha = options.pop(\"alpha\", None)\n        wire = options.pop(\"wire\", False)\n        bc = options.pop(\"bc\", None)\n        resetcam = options.pop(\"resetcam\", True)\n        zoom = options.pop(\"zoom\", False)\n        interactive = options.pop(\"interactive\", None)\n        rate = options.pop(\"rate\", None)\n        viewup = options.pop(\"viewup\", \"\")\n        azimuth = options.pop(\"azimuth\", 0)\n        elevation = options.pop(\"elevation\", 0)\n        roll = options.pop(\"roll\", 0)\n        interactorStyle = options.pop(\"interactorStyle\", 0)\n        q = options.pop(\"q\", False)\n\n        if self.offscreen:\n            interactive = False\n            self.interactive = False\n\n        def scan(wannabeacts):\n            scannedacts = []\n            if not utils.isSequence(wannabeacts):\n                wannabeacts = [wannabeacts]\n            for a in wannabeacts:  # scan content of list\n                if isinstance(a, vtk.vtkActor):\n                    scannedacts.append(a)\n                    if hasattr(a, 'trail') and a.trail and not a.trail in self.actors:\n                        scannedacts.append(a.trail)\n                elif isinstance(a, vtk.vtkAssembly):\n                    scannedacts.append(a)\n                    if a.trail and not a.trail in self.actors:\n                        scannedacts.append(a.trail)\n                elif isinstance(a, vtk.vtkActor2D):\n                    if isinstance(a, vtk.vtkCornerAnnotation):\n                        for a2 in settings.collectable_actors:\n                            if isinstance(a2, vtk.vtkCornerAnnotation):\n                                if at in a2.renderedAt: # remove old message\n                                    self.removeActor(a2)\n                        scannedacts.append(a)\n                elif isinstance(a, vtk.vtkImageActor):\n                    scannedacts.append(a)\n                elif isinstance(a, vtk.vtkVolume):\n                    scannedacts.append(a)\n                elif isinstance(a, vtk.vtkImageData):\n                    scannedacts.append(Volume(a))\n                elif isinstance(a, vtk.vtkPolyData):\n                    scannedacts.append(Actor(a, c, alpha, wire, bc))\n                elif isinstance(a, str):  # assume a filepath was given\n                    out = vtkio.load(a, c, alpha, wire, bc)\n                    if isinstance(out, str):\n                        colors.printc(\"~times File not found:\", out, c=1)\n                        scannedacts.append(None)\n                    else:\n                        scannedacts.append(out)\n                elif \"dolfin\" in str(type(a)):  # assume a dolfin.Mesh object\n                    from vtkplotter.dolfin import MeshActor\n                    out = MeshActor(a, c=c, alpha=alpha, wire=True, bc=bc)\n                    scannedacts.append(out)\n                elif a is None:\n                    pass\n                elif isinstance(a, vtk.vtkUnstructuredGrid):\n                    gf = vtk.vtkGeometryFilter()\n                    gf.SetInputData(a)\n                    gf.Update()\n                    scannedacts.append(Actor(gf.GetOutput(), c, alpha, wire, bc))\n                elif isinstance(a, vtk.vtkStructuredGrid):\n                    gf = vtk.vtkGeometryFilter()\n                    gf.SetInputData(a)\n                    gf.Update()\n                    scannedacts.append(Actor(gf.GetOutput(), c, alpha, wire, bc))\n                elif isinstance(a, vtk.vtkRectilinearGrid):\n                    gf = vtk.vtkRectilinearGridGeometryFilter()\n                    gf.SetInputData(a)\n                    gf.Update()\n                    scannedacts.append(Actor(gf.GetOutput(), c, alpha, wire, bc))\n                elif isinstance(a, vtk.vtkMultiBlockDataSet):\n                    for i in range(a.GetNumberOfBlocks()):\n                        b =  a.GetBlock(i)\n                        if isinstance(b, vtk.vtkPolyData):\n                            scannedacts.append(Actor(b, c, alpha, wire, bc))\n                        elif isinstance(b, vtk.vtkImageData):\n                            scannedacts.append(Volume(b))\n                else:\n                    colors.printc(\"~!? Cannot understand input in show():\", type(a), c=1)\n                    scannedacts.append(None)\n            return scannedacts\n\n        if len(actors) == 0:\n            actors = None\n        elif len(actors) == 1:\n            actors = actors[0]\n        else:\n            actors = utils.flatten(actors)\n\n        if actors is not None:\n            self.actors = []\n            actors2show = scan(actors)\n            for a in actors2show:\n                if a not in self.actors:\n                    self.actors.append(a)\n        else:\n            actors2show = scan(self.actors)\n            self.actors = list(actors2show)\n\n        if axes is not None:\n            self.axes = axes\n\n        if interactive is not None:\n            self.interactive = interactive\n\n        if at is None and len(self.renderers) > 1:\n            # in case of multiple renderers a call to show w/o specifing\n            # at which renderer will just render the whole thing and return\n            if self.interactor:\n                if zoom:\n                    self.camera.Zoom(zoom)\n                self.interactor.Render()\n                if self.interactive:\n                    self.interactor.Start()\n                return\n\n        if at is None:\n            at = 0\n\n        if at < len(self.renderers):\n            self.renderer = self.renderers[at]\n        else:\n            colors.printc(\"~times Error in show(): wrong renderer index\", at, c=1)\n            return\n\n        if not self.camera:\n            self.camera = self.renderer.GetActiveCamera()\n\n        self.camera.SetParallelProjection(self.infinity)\n\n        if self.camThickness:\n            self.camera.SetThickness(self.camThickness)\n\n        if self.sharecam:\n            for r in self.renderers:\n                r.SetActiveCamera(self.camera)\n\n        if len(self.renderers) == 1:\n            self.renderer.SetActiveCamera(self.camera)\n\n        # rendering\n        for ia in actors2show:  # add the actors that are not already in scene\n            if ia:\n                if isinstance(ia, vtk.vtkVolume):\n                    self.renderer.AddVolume(ia)\n                else:\n                    self.renderer.AddActor(ia)\n                if hasattr(ia, 'renderedAt'):\n                    ia.renderedAt.add(at)\n            else:\n                colors.printc(\"~lightning Warning: Invalid actor in actors list, skip.\", c=5)\n\n        # remove the ones that are not in actors2show\n        for ia in self.getActors(at):\n            if ia not in actors2show:\n                self.renderer.RemoveActor(ia)\n                if hasattr(ia, 'renderedAt'):\n                    ia.renderedAt.discard(at)\n            \n        for c in self.scalarbars:\n            self.renderer.RemoveActor(c)\n            if hasattr(c, 'renderedAt'):\n                c.renderedAt.discard(at)\n      \n        if self.axes is not None:\n            addons.addAxes()\n\n        addons.addLegend()\n\n        if self.showFrame and len(self.renderers) > 1:\n            addons.addFrame()\n\n        if resetcam or self.initializedIren == False:\n            self.renderer.ResetCamera()\n\n        if not self.initializedIren and self.interactor:\n            self.initializedIren = True\n            self.interactor.Initialize()\n            self.interactor.RemoveObservers(\"CharEvent\")\n\n            if self.verbose and self.interactive:\n                docs.onelinetip()\n\n        self.initializedPlotter = True\n\n        if zoom:\n            self.camera.Zoom(zoom)\n        if azimuth:\n            self.camera.Azimuth(azimuth)\n        if elevation:\n            self.camera.Elevation(elevation)\n        if roll:\n            self.camera.Roll(roll)\n\n        if len(viewup):\n            if viewup == \"x\":\n                viewup = [1, 0, 0]\n            elif viewup == \"y\":\n                viewup = [0, 1, 0]\n            elif viewup == \"z\":\n                viewup = [0, 0, 1]\n                self.camera.Azimuth(60)\n                self.camera.Elevation(30)\n            self.camera.Azimuth(0.01)  # otherwise camera gets locked\n            self.camera.SetViewUp(viewup)\n\n        self.renderer.ResetCameraClippingRange()\n\n        self.window.Render()\n\n        scbflag = False\n        for a in self.actors:\n            if (\n                hasattr(a, \"scalarbar\")\n                and a.scalarbar is not None\n                and utils.isSequence(a.scalarbar)\n            ):\n                if len(a.scalarbar) == 5:  # addScalarBar\n                    s1, s2, s3, s4, s5 = a.scalarbar\n                    sb = addons.addScalarBar(a, s1, s2, s3, s4, s5)\n                    scbflag = True\n                    a.scalarbar = sb  # save scalarbar actor\n                elif len(a.scalarbar) == 10:  # addScalarBar3D\n                    s0, s1, s2, s3, s4, s5, s6, s7, s8 = a.scalarbar\n                    sb = addons.addScalarBar3D(a, at, s0, s1, s2, s3, s4, s5, s6, s7, s8)\n                    scbflag = True\n                    a.scalarbar = sb  # save scalarbar actor\n        if scbflag:\n            self.window.Render()\n\n        if settings.allowInteraction and not self.offscreen:\n            self.allowInteraction()\n\n        if settings.interactorStyle is not None:\n            interactorStyle = settings.interactorStyle\n\n        if interactorStyle == 0 or interactorStyle == \"TrackballCamera\":\n            pass  # do nothing\n        elif interactorStyle == 1 or interactorStyle == \"TrackballActor\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleTrackballActor())\n        elif interactorStyle == 2 or interactorStyle == \"JoystickCamera\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleJoystickCamera())\n        elif interactorStyle == 3 or interactorStyle == \"Unicam\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleUnicam())\n        elif interactorStyle == 4 or interactorStyle == \"Flight\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleFlight())\n        elif interactorStyle == 5 or interactorStyle == \"RubberBand3D\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleRubberBand3D())\n        elif interactorStyle == 6 or interactorStyle == \"RubberBandZoom\":\n            self.interactor.SetInteractorStyle(vtk.vtkInteractorStyleRubberBandZoom())\n\n        if self.interactor and self.interactive:\n            self.interactor.Start()\n\n        if rate:\n            if self.clock is None:  # set clock and limit rate\n                self._clockt0 = time.time()\n                self.clock = 0.0\n            else:\n                t = time.time() - self._clockt0\n                elapsed = t - self.clock\n                mint = 1.0 / rate\n                if elapsed < mint:\n                    time.sleep(mint - elapsed)\n                self.clock = time.time() - self._clockt0\n\n        if q:  # gracefully exit\n            if self.verbose:\n                print(\"q flag set to True. Exit.\")\n            sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef removeActor(self, a):\n        if not self.initializedPlotter:\n            save_int = self.interactive\n            self.show(interactive=0)\n            self.interactive = save_int\n            return\n        if self.renderer:\n            self.renderer.RemoveActor(a)\n            if hasattr(a, 'renderedAt'):\n                ir = self.renderers.index(self.renderer)\n                a.renderedAt.discard(ir)\n        if a in self.actors:\n            i = self.actors.index(a)\n            del self.actors[i]", "response": "Remove actor from current renderer or actor index from current renderer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete specified list of actors by default delete all.", "response": "def clear(self, actors=()):\n        \"\"\"Delete specified list of actors, by default delete all.\"\"\"\n        if not utils.isSequence(actors):\n            actors = [actors]\n        if len(actors):\n            for a in actors:\n                self.removeActor(a)\n        else:\n            for a in settings.collectable_actors:\n                self.removeActor(a)\n            settings.collectable_actors = []\n            self.actors = []\n            for a in self.getActors():\n                self.renderer.RemoveActor(a)\n            for a in self.getVolumes():\n                self.renderer.RemoveVolume(a)\n            for s in self.sliders:\n                s.EnabledOff()\n            for b in self.buttons:\n                self.renderer.RemoveActor(b)\n            for w in self.widgets:\n                w.EnabledOff()\n            for c in self.scalarbars:\n                self.renderer.RemoveActor(c)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninterpolating linearly the two sets of sph harm. coeeficients.", "response": "def morph(clm1, clm2, t, lmax):\n    \"\"\"Interpolate linearly the two sets of sph harm. coeeficients.\"\"\"\n    clm = (1 - t) * clm1 + t * clm2\n    grid_reco = clm.expand(lmax=lmax)  # cut \"high frequency\" components\n    agrid_reco = grid_reco.to_array()\n    pts = []\n    for i, longs in enumerate(agrid_reco):\n        ilat = grid_reco.lats()[i]\n        for j, value in enumerate(longs):\n            ilong = grid_reco.lons()[j]\n            th = (90 - ilat) / 57.3\n            ph = ilong / 57.3\n            r = value + rbias\n            p = np.array([sin(th) * cos(ph), sin(th) * sin(ph), cos(th)]) * r\n            pts.append(p)\n    return pts"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a point ``Actor`` for a list of points. :param float r: point radius. :param c: color name, number, or list of [R,G,B] colors of same length as plist. :type c: int, str, list :param float alpha: transparency in range [0,1].", "response": "def MeshPoints(*inputobj, **options):\n    \"\"\"\n    Build a point ``Actor`` for a list of points.\n\n    :param float r: point radius.\n    :param c: color name, number, or list of [R,G,B] colors of same length as plist.\n    :type c: int, str, list\n    :param float alpha: transparency in range [0,1].\n    \"\"\"\n    r = options.pop(\"r\", 5)\n    c = options.pop(\"c\", \"gray\")\n    alpha = options.pop(\"alpha\", 1)\n\n    mesh, u = _inputsort(inputobj)\n    plist = mesh.coordinates()\n    if u:\n        u_values = np.array([u(p) for p in plist])\n    if len(plist[0]) == 2:  # coords are 2d.. not good..\n        plist = np.insert(plist, 2, 0, axis=1)  # make it 3d\n    if len(plist[0]) == 1:  # coords are 1d.. not good..\n        plist = np.insert(plist, 1, 0, axis=1)  # make it 3d\n        plist = np.insert(plist, 2, 0, axis=1)\n\n    actor = shapes.Points(plist, r=r, c=c, alpha=alpha)\n\n    actor.mesh = mesh\n    if u:\n        actor.u = u\n        if len(u_values.shape) == 2:\n            if u_values.shape[1] in [2, 3]:  # u_values is 2D or 3D\n                actor.u_values = u_values\n                dispsizes = utils.mag(u_values)\n        else:  # u_values is 1D\n            dispsizes = u_values\n        actor.addPointScalars(dispsizes, \"u_values\")\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef MeshLines(*inputobj, **options):\n    scale = options.pop(\"scale\", 1)\n    lw = options.pop(\"lw\", 1)\n    c = options.pop(\"c\", None)\n    alpha = options.pop(\"alpha\", 1)\n\n    mesh, u = _inputsort(inputobj)\n    startPoints = mesh.coordinates()\n    u_values = np.array([u(p) for p in mesh.coordinates()])\n    if not utils.isSequence(u_values[0]):\n        printc(\"~times Error: cannot show Lines for 1D scalar values!\", c=1)\n        exit()\n    endPoints = mesh.coordinates() + u_values\n    if u_values.shape[1] == 2:  # u_values is 2D\n        u_values = np.insert(u_values, 2, 0, axis=1)  # make it 3d\n        startPoints = np.insert(startPoints, 2, 0, axis=1)  # make it 3d\n        endPoints = np.insert(endPoints, 2, 0, axis=1)  # make it 3d\n\n    actor = shapes.Lines(\n        startPoints, endPoints, scale=scale, lw=lw, c=c, alpha=alpha\n    )\n\n    actor.mesh = mesh\n    actor.u = u\n    actor.u_values = u_values\n    return actor", "response": "A function that builds the Line segments between two lists of points startPoints and endPoints."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef MeshArrows(*inputobj, **options):\n    s = options.pop(\"s\", None)\n    scale = options.pop(\"scale\", 1)\n    c = options.pop(\"c\", \"gray\")\n    alpha = options.pop(\"alpha\", 1)\n    res = options.pop(\"res\", 12)\n\n    mesh, u = _inputsort(inputobj)\n    startPoints = mesh.coordinates()\n    u_values = np.array([u(p) for p in mesh.coordinates()])\n    if not utils.isSequence(u_values[0]):\n        printc(\"~times Error: cannot show Arrows for 1D scalar values!\", c=1)\n        exit()\n    endPoints = mesh.coordinates() + u_values\n    if u_values.shape[1] == 2:  # u_values is 2D\n        u_values = np.insert(u_values, 2, 0, axis=1)  # make it 3d\n        startPoints = np.insert(startPoints, 2, 0, axis=1)  # make it 3d\n        endPoints = np.insert(endPoints, 2, 0, axis=1)  # make it 3d\n\n    actor = shapes.Arrows(\n        startPoints, endPoints, s=s, scale=scale, c=c, alpha=alpha, res=res\n    )\n    actor.mesh = mesh\n    actor.u = u\n    actor.u_values = u_values\n    return actor", "response": "Build arrows representing displacements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mergeActors(actors, tol=0):\n    polylns = vtk.vtkAppendPolyData()\n    for a in actors:\n        polylns.AddInputData(a.polydata())\n    polylns.Update()\n    pd = polylns.GetOutput()\n    return Actor(pd)", "response": "Merge the input objects into a single actor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isosurface(image, smoothing=0, threshold=None, connectivity=False):\n    if smoothing:\n        smImg = vtk.vtkImageGaussianSmooth()\n        smImg.SetDimensionality(3)\n        smImg.SetInputData(image)\n        smImg.SetStandardDeviations(smoothing, smoothing, smoothing)\n        smImg.Update()\n        image = smImg.GetOutput()\n\n    scrange = image.GetScalarRange()\n    if scrange[1] > 1e10:\n        print(\"Warning, high scalar range detected:\", scrange)\n\n    cf = vtk.vtkContourFilter()\n    cf.SetInputData(image)\n    cf.UseScalarTreeOn()\n    cf.ComputeScalarsOn()\n\n    if utils.isSequence(threshold):\n        cf.SetNumberOfContours(len(threshold))\n        for i, t in enumerate(threshold):\n            cf.SetValue(i, t)\n        cf.Update()\n    else:\n        if not threshold:\n            threshold = (2 * scrange[0] + scrange[1]) / 3.0\n        cf.SetValue(0, threshold)\n        cf.Update()\n\n    clp = vtk.vtkCleanPolyData()\n    clp.SetInputConnection(cf.GetOutputPort())\n    clp.Update()\n    poly = clp.GetOutput()\n\n    if connectivity:\n        conn = vtk.vtkPolyDataConnectivityFilter()\n        conn.SetExtractionModeToLargestRegion()\n        conn.SetInputData(poly)\n        conn.Update()\n        poly = conn.GetOutput()\n\n    a = Actor(poly, c=None).phong()\n    a.mapper.SetScalarRange(scrange[0], scrange[1])\n    return a", "response": "Return a vtkActor representing the isosurface extracted from a vtkImageData object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show(\n        self,\n        at=None,\n        shape=(1, 1),\n        N=None,\n        pos=(0, 0),\n        size=\"auto\",\n        screensize=\"auto\",\n        title=\"\",\n        bg=\"blackboard\",\n        bg2=None,\n        axes=4,\n        infinity=False,\n        verbose=True,\n        interactive=None,\n        offscreen=False,\n        resetcam=True,\n        zoom=None,\n        viewup=\"\",\n        azimuth=0,\n        elevation=0,\n        roll=0,\n        interactorStyle=0,\n        newPlotter=False,\n        depthpeeling=False,\n        q=False,\n    ):\n        \"\"\"\n        Create on the fly an instance of class ``Plotter`` or use the last existing one to\n        show one single object.\n\n        Allowed input objects are: ``Actor`` or ``Volume``.\n\n        This is meant as a shortcut. If more than one object needs to be visualised\n        please use the syntax `show([actor1, actor2,...], options)`.\n\n        :param bool newPlotter: if set to `True`, a call to ``show`` will instantiate\n            a new ``Plotter`` object (a new window) instead of reusing the first created.\n            See e.g.: |readVolumeAsIsoSurface.py|_\n        :return: the current ``Plotter`` class instance.\n\n        .. note:: E.g.:\n\n            >>> from vtkplotter import *\n            >>> s = Sphere()\n            >>> s.show(at=1, N=2)\n            >>> c = Cube()\n            >>> c.show(at=0, interactive=True)\n        \"\"\"\n        from vtkplotter.plotter import show\n\n        return show(\n            self,\n            at=at,\n            shape=shape,\n            N=N,\n            pos=pos,\n            size=size,\n            screensize=screensize,\n            title=title,\n            bg=bg,\n            bg2=bg2,\n            axes=axes,\n            infinity=infinity,\n            verbose=verbose,\n            interactive=interactive,\n            offscreen=offscreen,\n            resetcam=resetcam,\n            zoom=zoom,\n            viewup=viewup,\n            azimuth=azimuth,\n            elevation=elevation,\n            roll=roll,\n            interactorStyle=interactorStyle,\n            newPlotter=newPlotter,\n            depthpeeling=depthpeeling,\n            q=q,\n        )", "response": "Show the current object in the current plotter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting or get actor legend text.", "response": "def legend(self, txt=None):\n        \"\"\"Set/get ``Actor`` legend text.\n\n        :param str txt: legend text.\n\n        Size and positions can be modified by setting attributes\n        ``Plotter.legendSize``, ``Plotter.legendBC`` and ``Plotter.legendPos``.\n\n        .. hint:: |fillholes.py|_\n        \"\"\"\n        if txt:\n            self._legend = txt\n        else:\n            return self._legend\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addPos(self, dp_x=None, dy=None, dz=None):\n        p = np.array(self.GetPosition())\n        if dz is None:  # assume dp_x is of the form (x,y,z)\n            self.SetPosition(p + dp_x)\n        else:\n            self.SetPosition(p + [dp_x, dy, dz])\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Add vector to current actor position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset or get actor position along x axis.", "response": "def x(self, position=None):\n        \"\"\"Set/Get actor position along x axis.\"\"\"\n        p = self.GetPosition()\n        if position is None:\n            return p[0]\n        self.SetPosition(position, p[1], p[2])\n        if self.trail:\n            self.updateTrail()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset or get actor position along y axis.", "response": "def y(self, position=None):\n        \"\"\"Set/Get actor position along y axis.\"\"\"\n        p = self.GetPosition()\n        if position is None:\n            return p[1]\n        self.SetPosition(p[0], position, p[2])\n        if self.trail:\n            self.updateTrail()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef z(self, position=None):\n        p = self.GetPosition()\n        if position is None:\n            return p[2]\n        self.SetPosition(p[0], p[1], position)\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Set the actor s position along z axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrotates the actor around an arbitrary axis passing through axis_point.", "response": "def rotate(self, angle, axis=(1, 0, 0), axis_point=(0, 0, 0), rad=False):\n        \"\"\"Rotate ``Actor`` around an arbitrary `axis` passing through `axis_point`.\"\"\"\n        if rad:\n            anglerad = angle\n        else:\n            anglerad = angle / 57.29578\n        axis = utils.versor(axis)\n        a = np.cos(anglerad / 2)\n        b, c, d = -axis * np.sin(anglerad / 2)\n        aa, bb, cc, dd = a * a, b * b, c * c, d * d\n        bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n        R = np.array(\n            [\n                [aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n                [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n                [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc],\n            ]\n        )\n        rv = np.dot(R, self.GetPosition() - np.array(axis_point)) + axis_point\n\n        if rad:\n            angle *= 57.29578\n        # this vtk method only rotates in the origin of the actor:\n        self.RotateWXYZ(angle, axis[0], axis[1], axis[2])\n        self.SetPosition(rv)\n        if self.trail:\n            self.updateTrail()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rotateX(self, angle, axis_point=(0, 0, 0), rad=False):\n        if rad:\n            angle *= 57.29578\n        self.RotateX(angle)\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Rotate around x - axis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rotateY(self, angle, axis_point=(0, 0, 0), rad=False):\n        if rad:\n            angle *= 57.29578\n        self.RotateY(angle)\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Rotate around y - axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rotateZ(self, angle, axis_point=(0, 0, 0), rad=False):\n        if rad:\n            angle *= 57.29578\n        self.RotateZ(angle)\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Rotate around z - axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets or get actor orientation.", "response": "def orientation(self, newaxis=None, rotation=0, rad=False):\n        \"\"\"\n        Set/Get actor orientation.\n\n        :param rotation: If != 0 rotate actor around newaxis.\n        :param rad: set to True if angle is in radians.\n\n        .. hint:: |gyroscope2| |gyroscope2.py|_\n        \"\"\"\n        if rad:\n            rotation *= 57.29578\n        initaxis = utils.versor(self.top - self.base)\n        if newaxis is None:\n            return initaxis\n        newaxis = utils.versor(newaxis)\n        pos = np.array(self.GetPosition())\n        crossvec = np.cross(initaxis, newaxis)\n        angle = np.arccos(np.dot(initaxis, newaxis))\n        T = vtk.vtkTransform()\n        T.PostMultiply()\n        T.Translate(-pos)\n        if rotation:\n            T.RotateWXYZ(rotation, initaxis)\n        T.RotateWXYZ(angle * 57.29578, crossvec)\n        T.Translate(pos)\n        self.SetUserMatrix(T.GetMatrix())\n        if self.trail:\n            self.updateTrail()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset or get actor s scaling factor.", "response": "def scale(self, s=None):\n        \"\"\"Set/get actor's scaling factor.\n\n        :param s: scaling factor(s).\n        :type s: float, list\n\n        .. note:: if `s==(sx,sy,sz)` scale differently in the three coordinates.\"\"\"\n        if s is None:\n            return np.array(self.GetScale())\n        self.SetScale(s)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef time(self, t=None):\n        if t is None:\n            return self._time\n        self._time = t\n        return self", "response": "Set or get actor s absolute time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a trailing line to the actor.", "response": "def addTrail(self, offset=None, maxlength=None, n=25, c=None, alpha=None, lw=1):\n        \"\"\"Add a trailing line to actor.\n\n        :param offset: set an offset vector from the object center.\n        :param maxlength: length of trailing line in absolute units\n        :param n: number of segments to control precision\n        :param lw: line width of the trail\n\n        .. hint:: |trail| |trail.py|_\n        \"\"\"\n        if maxlength is None:\n            maxlength = self.diagonalSize() * 20\n            if maxlength == 0:\n                maxlength = 1\n\n        if self.trail is None:\n            pos = self.GetPosition()\n            self.trailPoints = [None] * n\n            self.trailSegmentSize = maxlength / n\n            self.trailOffset = offset\n\n            ppoints = vtk.vtkPoints()  # Generate the polyline\n            poly = vtk.vtkPolyData()\n            ppoints.SetData(numpy_to_vtk([pos] * n))\n            poly.SetPoints(ppoints)\n            lines = vtk.vtkCellArray()\n            lines.InsertNextCell(n)\n            for i in range(n):\n                lines.InsertCellPoint(i)\n            poly.SetPoints(ppoints)\n            poly.SetLines(lines)\n            mapper = vtk.vtkPolyDataMapper()\n\n            if c is None:\n                if hasattr(self, \"GetProperty\"):\n                    col = self.GetProperty().GetColor()\n                else:\n                    col = (0.1, 0.1, 0.1)\n            else:\n                col = colors.getColor(c)\n\n            if alpha is None:\n                alpha = 1\n                if hasattr(self, \"GetProperty\"):\n                    alpha = self.GetProperty().GetOpacity()\n\n            mapper.SetInputData(poly)\n            tline = Actor()\n            tline.SetMapper(mapper)\n            tline.GetProperty().SetColor(col)\n            tline.GetProperty().SetOpacity(alpha)\n            tline.GetProperty().SetLineWidth(lw)\n            self.trail = tline  # holds the vtkActor\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef box(self):\n        b = self.GetBounds()\n        from vtkplotter.shapes import Box\n        pos = (b[0]+b[1])/2, (b[3]+b[2])/2, (b[5]+b[4])/2\n        length, width, height = b[1]-b[0], b[3]-b[2], b[5]-b[4]\n        oa = Box(pos, length, width, height, c='gray').wire()\n        if isinstance(self.GetProperty(), vtk.vtkProperty):\n            oa.SetProperty(self.GetProperty())\n        return oa", "response": "Return the bounding box as a new Actor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets or get pickable property of actor.", "response": "def pickable(self, value=None):\n        \"\"\"Set/get pickable property of actor.\"\"\"\n        if value is None:\n            return self.GetPickable()\n        else:\n            self.SetPickable(value)\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updateMesh(self, polydata):\n        self.poly = polydata\n        self.mapper.SetInputData(polydata)\n        self.mapper.Modified()\n        return self", "response": "Update the polygonal mesh of the actor with the new data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addScalarBar(self, c=None, title=\"\", horizontal=False, vmin=None, vmax=None):\n        # book it, it will be created by Plotter.show() later\n        self.scalarbar = [c, title, horizontal, vmin, vmax]\n        return self", "response": "Add a 2D scalar bar to actor.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrawing a 3D scalar bar to actor.", "response": "def addScalarBar3D(\n        self,\n        pos=(0, 0, 0),\n        normal=(0, 0, 1),\n        sx=0.1,\n        sy=2,\n        nlabels=9,\n        ncols=256,\n        cmap=None,\n        c=\"k\",\n        alpha=1,\n    ):\n        \"\"\"\n        Draw a 3D scalar bar to actor.\n\n        .. hint:: |mesh_coloring| |mesh_coloring.py|_\n        \"\"\"\n        # book it, it will be created by Plotter.show() later\n        self.scalarbar = [pos, normal, sx, sy, nlabels, ncols, cmap, c, alpha]\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning a texture to actor from image file or predefined texture name.", "response": "def texture(self, name, scale=1, falsecolors=False, mapTo=1):\n        \"\"\"Assign a texture to actor from image file or predefined texture name.\"\"\"\n        import os\n\n        if mapTo == 1:\n            tmapper = vtk.vtkTextureMapToCylinder()\n        elif mapTo == 2:\n            tmapper = vtk.vtkTextureMapToSphere()\n        elif mapTo == 3:\n            tmapper = vtk.vtkTextureMapToPlane()\n\n        tmapper.SetInputData(self.polydata(False))\n        if mapTo == 1:\n            tmapper.PreventSeamOn()\n\n        xform = vtk.vtkTransformTextureCoords()\n        xform.SetInputConnection(tmapper.GetOutputPort())\n        xform.SetScale(scale, scale, scale)\n        if mapTo == 1:\n            xform.FlipSOn()\n        xform.Update()\n\n        mapper = vtk.vtkDataSetMapper()\n        mapper.SetInputConnection(xform.GetOutputPort())\n        mapper.ScalarVisibilityOff()\n\n        fn = settings.textures_path + name + \".jpg\"\n        if os.path.exists(name):\n            fn = name\n        elif not os.path.exists(fn):\n            colors.printc(\"~sad Texture\", name, \"not found in\", settings.textures_path, c=\"r\")\n            colors.printc(\"~target Available textures:\", c=\"m\", end=\" \")\n            for ff in os.listdir(settings.textures_path):\n                colors.printc(ff.split(\".\")[0], end=\" \", c=\"m\")\n            print()\n            return\n\n        jpgReader = vtk.vtkJPEGReader()\n        jpgReader.SetFileName(fn)\n        atext = vtk.vtkTexture()\n        atext.RepeatOn()\n        atext.EdgeClampOff()\n        atext.InterpolateOn()\n        if falsecolors:\n            atext.MapColorScalarsThroughLookupTableOn()\n        atext.SetInputConnection(jpgReader.GetOutputPort())\n        self.GetProperty().SetColor(1, 1, 1)\n        self.SetMapper(mapper)\n        self.SetTexture(atext)\n        self.Modified()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getPoint(self, i):\n        poly = self.polydata(True)\n        p = [0, 0, 0]\n        poly.GetPoints().GetPoint(i, p)\n        return np.array(p)", "response": "Retrieve specific i - th point coordinates in mesh."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setPoint(self, i, p):\n        poly = self.polydata(False)\n        poly.GetPoints().SetPoint(i, p)\n        poly.GetPoints().Modified()\n        # reset actor to identity matrix position/rotation:\n        self.PokeMatrix(vtk.vtkMatrix4x4())\n        return self", "response": "Set specific i - th point coordinates in mesh."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of vertex coordinates of the input mesh.", "response": "def getPoints(self, transformed=True, copy=True):\n        \"\"\"\n        Return the list of vertex coordinates of the input mesh.\n        Same as `actor.coordinates()`.\n\n        :param bool transformed: if `False` ignore any previous trasformation\n            applied to the mesh.\n        :param bool copy: if `False` return the reference to the points\n            so that they can be modified in place.\n        \"\"\"\n        return self.coordinates(transformed, copy)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset specific points in a mesh.", "response": "def setPoints(self, pts):\n        \"\"\"\n        Set specific points coordinates in mesh. Input is a python list.\n        Actor transformation is reset to its mesh position/orientation.\n\n        :param list pts: new coordinates of mesh vertices.\n        \"\"\"\n        vpts = vtk.vtkPoints()\n        vpts.SetData(numpy_to_vtk(pts, deep=True))\n        self.poly.SetPoints(vpts)\n        self.poly.GetPoints().Modified()\n        # reset actor to identity matrix position/rotation:\n        self.PokeMatrix(vtk.vtkMatrix4x4())\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef computeNormals(self):\n        poly = self.polydata(False)\n        pnormals = poly.GetPointData().GetNormals()\n        cnormals = poly.GetCellData().GetNormals()\n        if pnormals and cnormals:\n            return self\n\n        pdnorm = vtk.vtkPolyDataNormals()\n        pdnorm.SetInputData(poly)\n        pdnorm.ComputePointNormalsOn()\n        pdnorm.ComputeCellNormalsOn()\n        pdnorm.FlipNormalsOff()\n        pdnorm.ConsistencyOn()\n        pdnorm.Update()\n        return self.updateMesh(pdnorm.GetOutput())", "response": "Compute cell and vertex normals for the actor s mesh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset or get actor s transparency. Same as actor. opacity.", "response": "def alpha(self, opacity=None):\n        \"\"\"Set/get actor's transparency. Same as `actor.opacity()`.\"\"\"\n        if opacity is None:\n            return self.GetProperty().GetOpacity()\n\n        self.GetProperty().SetOpacity(opacity)\n        bfp = self.GetBackfaceProperty()\n        if bfp:\n            if opacity < 1:\n                self._bfprop = bfp\n                self.SetBackfaceProperty(None)\n            else:\n                self.SetBackfaceProperty(self._bfprop)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting actor s representation as wireframe or solid surface. Same as wireframe ( default is False.", "response": "def wire(self, wireframe=True):\n        \"\"\"Set actor's representation as wireframe or solid surface. Same as `wireframe()`.\"\"\"\n        if wireframe:\n            self.GetProperty().SetRepresentationToWireframe()\n        else:\n            self.GetProperty().SetRepresentationToSurface()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pointSize(self, s=None):\n        if s is not None:\n            if isinstance(self, vtk.vtkAssembly):\n                cl = vtk.vtkPropCollection()\n                self.GetActors(cl)\n                cl.InitTraversal()\n                a = vtk.vtkActor.SafeDownCast(cl.GetNextProp())\n                a.GetProperty().SetRepresentationToPoints()\n                a.GetProperty().SetPointSize(s)\n            else:\n                self.GetProperty().SetRepresentationToPoints()\n                self.GetProperty().SetPointSize(s)\n        else:\n            return self.GetProperty().GetPointSize()\n        return self", "response": "Set or get actor s point size of vertices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef color(self, c=False):\n        if c is False:\n            return np.array(self.GetProperty().GetColor())\n        elif c is None:\n            self.GetMapper().ScalarVisibilityOn()\n            return self\n        else:\n            self.GetMapper().ScalarVisibilityOff()\n            self.GetProperty().SetColor(colors.getColor(c))\n            return self", "response": "Sets the color of the actor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets actor s backface color. bc is the color to use for the actor.", "response": "def backColor(self, bc=None):\n        \"\"\"\n        Set/get actor's backface color.\n        \"\"\"\n        backProp = self.GetBackfaceProperty()\n\n        if bc is None:\n            if backProp:\n                return backProp.GetDiffuseColor()\n            return None\n\n        if self.GetProperty().GetOpacity() < 1:\n            colors.printc(\"~noentry backColor(): only active for alpha=1\", c=\"y\")\n            return self\n\n        if not backProp:\n            backProp = vtk.vtkProperty()\n\n        backProp.SetDiffuseColor(colors.getColor(bc))\n        backProp.SetOpacity(self.GetProperty().GetOpacity())\n        self.SetBackfaceProperty(backProp)\n        self.GetMapper().ScalarVisibilityOff()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lineWidth(self, lw=None):\n        if lw is not None:\n            if lw == 0:\n                self.GetProperty().EdgeVisibilityOff()\n                return\n            self.GetProperty().EdgeVisibilityOn()\n            self.GetProperty().SetLineWidth(lw)\n        else:\n            return self.GetProperty().GetLineWidth()\n        return self", "response": "Set or get width of mesh edges. Same as lw ()."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean(self, tol=None):\n        poly = self.polydata(False)\n        cleanPolyData = vtk.vtkCleanPolyData()\n        cleanPolyData.PointMergingOn()\n        cleanPolyData.ConvertLinesToPointsOn()\n        cleanPolyData.ConvertPolysToLinesOn()\n        cleanPolyData.SetInputData(poly)\n        if tol:\n            cleanPolyData.SetTolerance(tol)\n        cleanPolyData.Update()\n        return self.updateMesh(cleanPolyData.GetOutput())", "response": "Cleans the actor s polydata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the average size of a mesh. This is the mean of the vertex distances from the center of mass.", "response": "def averageSize(self):\n        \"\"\"Calculate the average size of a mesh.\n        This is the mean of the vertex distances from the center of mass.\"\"\"\n        cm = self.centerOfMass()\n        coords = self.coordinates(copy=False)\n        if not len(coords):\n            return 0\n        s, c = 0.0, 0.0\n        n = len(coords)\n        step = int(n / 10000.0) + 1\n        for i in np.arange(0, n, step):\n            s += utils.mag(coords[i] - cm)\n            c += 1\n        return s / c"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the length of the diagonal of actor bounding box.", "response": "def diagonalSize(self):\n        \"\"\"Get the length of the diagonal of actor bounding box.\"\"\"\n        b = self.polydata().GetBounds()\n        return np.sqrt((b[1] - b[0]) ** 2 + (b[3] - b[2]) ** 2 + (b[5] - b[4]) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the maximum dimension in x y or z of the actor bounding box.", "response": "def maxBoundSize(self):\n        \"\"\"Get the maximum dimension in x, y or z of the actor bounding box.\"\"\"\n        b = self.polydata(True).GetBounds()\n        return max(abs(b[1] - b[0]), abs(b[3] - b[2]), abs(b[5] - b[4]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef centerOfMass(self):\n        cmf = vtk.vtkCenterOfMass()\n        cmf.SetInputData(self.polydata(True))\n        cmf.Update()\n        c = cmf.GetCenter()\n        return np.array(c)", "response": "Return the center of mass of actor."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets or set the volume occupied by actor.", "response": "def volume(self, value=None):\n        \"\"\"Get/set the volume occupied by actor.\"\"\"\n        mass = vtk.vtkMassProperties()\n        mass.SetGlobalWarningDisplay(0)\n        mass.SetInputData(self.polydata())\n        mass.Update()\n        v = mass.GetVolume()\n        if value is not None:\n            if not v:\n                colors.printc(\"~bomb Volume is zero: cannot rescale.\", c=1, end=\"\")\n                colors.printc(\" Consider adding actor.triangle()\", c=1)\n                return self\n            self.scale(value / v)\n            return self\n        else:\n            return v"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef area(self, value=None):\n        mass = vtk.vtkMassProperties()\n        mass.SetGlobalWarningDisplay(0)\n        mass.SetInputData(self.polydata())\n        mass.Update()\n        ar = mass.GetSurfaceArea()\n        if value is not None:\n            if not ar:\n                colors.printc(\"~bomb Area is zero: cannot rescale.\", c=1, end=\"\")\n                colors.printc(\" Consider adding actor.triangle()\", c=1)\n                return self\n            self.scale(value / ar)\n            return self\n        else:\n            return ar", "response": "Get or set the surface area of the actor."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the closest point on a mesh given from the input point pt.", "response": "def closestPoint(self, pt, N=1, radius=None, returnIds=False):\n        \"\"\"\n        Find the closest point on a mesh given from the input point `pt`.\n\n        :param int N: if greater than 1, return a list of N ordered closest points.\n        :param float radius: if given, get all points within that radius.\n        :param bool returnIds: return points IDs instead of point coordinates.\n\n        .. hint:: |fitplanes.py|_\n\n            |align1| |align1.py|_\n\n            |quadratic_morphing| |quadratic_morphing.py|_\n\n        .. note:: The appropriate kd-tree search locator is built on the fly and cached for speed.\n        \"\"\"\n        poly = self.polydata(True)\n\n        if N > 1 or radius:\n            plocexists = self.point_locator\n            if not plocexists or (plocexists and self.point_locator is None):\n                point_locator = vtk.vtkPointLocator()\n                point_locator.SetDataSet(poly)\n                point_locator.BuildLocator()\n                self.point_locator = point_locator\n\n            vtklist = vtk.vtkIdList()\n            if N > 1:\n                self.point_locator.FindClosestNPoints(N, pt, vtklist)\n            else:\n                self.point_locator.FindPointsWithinRadius(radius, pt, vtklist)\n            if returnIds:\n                return [int(vtklist.GetId(k)) for k in range(vtklist.GetNumberOfIds())]\n            else:\n                trgp = []\n                for i in range(vtklist.GetNumberOfIds()):\n                    trgp_ = [0, 0, 0]\n                    vi = vtklist.GetId(i)\n                    poly.GetPoints().GetPoint(vi, trgp_)\n                    trgp.append(trgp_)\n                return np.array(trgp)\n\n        clocexists = self.cell_locator\n        if not clocexists or (clocexists and self.cell_locator is None):\n            cell_locator = vtk.vtkCellLocator()\n            cell_locator.SetDataSet(poly)\n            cell_locator.BuildLocator()\n            self.cell_locator = cell_locator\n\n        trgp = [0, 0, 0]\n        cid = vtk.mutable(0)\n        dist2 = vtk.mutable(0)\n        subid = vtk.mutable(0)\n        self.cell_locator.FindClosestPoint(pt, trgp, cid, subid, dist2)\n        if returnIds:\n            return int(cid)\n        else:\n            return np.array(trgp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distanceToMesh(self, actor, signed=False, negate=False):\n        '''\n        Computes the (signed) distance from one mesh to another.\n        \n        .. hint:: |distance2mesh| |distance2mesh.py|_\n        '''\n        poly1 = self.polydata()\n        poly2 = actor.polydata()\n        df = vtk.vtkDistancePolyDataFilter()\n        df.SetInputData(0, poly1)\n        df.SetInputData(1, poly2)\n        if signed:\n            df.SignedDistanceOn()\n        if negate:\n            df.NegateDistanceOn()\n        df.Update()\n        \n        scals = df.GetOutput().GetPointData().GetScalars()\n        poly1.GetPointData().AddArray(scals)\n\n        poly1.GetPointData().SetActiveScalars(scals.GetName())\n        rng = scals.GetRange()\n        self.mapper.SetScalarRange(rng[0], rng[1])\n        self.mapper.ScalarVisibilityOn()\n        return self", "response": "Computes the distance between two meshes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone(self, transformed=True):\n        poly = self.polydata(transformed=transformed)\n        polyCopy = vtk.vtkPolyData()\n        polyCopy.DeepCopy(poly)\n\n        cloned = Actor()\n        cloned.poly = polyCopy\n        cloned.mapper.SetInputData(polyCopy)\n        cloned.mapper.SetScalarVisibility(self.mapper.GetScalarVisibility())\n        pr = vtk.vtkProperty()\n        pr.DeepCopy(self.GetProperty())\n        cloned.SetProperty(pr)\n        return cloned", "response": "Clone a vtkActor and make an exact copy of it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply this transformation to the polygonal mesh not to the actor s transformation which is reset.", "response": "def transformMesh(self, transformation):\n        \"\"\"\n        Apply this transformation to the polygonal `mesh`,\n        not to the actor's transformation, which is reset.\n\n        :param transformation: ``vtkTransform`` or ``vtkMatrix4x4`` object.\n        \"\"\"\n        if isinstance(transformation, vtk.vtkMatrix4x4):\n            tr = vtk.vtkTransform()\n            tr.SetMatrix(transformation)\n            transformation = tr\n\n        tf = vtk.vtkTransformPolyDataFilter()\n\n        tf.SetTransform(transformation)\n        tf.SetInputData(self.polydata())\n        tf.Update()\n        self.PokeMatrix(vtk.vtkMatrix4x4())  # identity\n        return self.updateMesh(tf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize the actor s center of mass at origin and scale its average size to unit.", "response": "def normalize(self):\n        \"\"\"\n        Shift actor's center of mass at origin and scale its average size to unit.\n        \"\"\"\n        cm = self.centerOfMass()\n        coords = self.coordinates()\n        if not len(coords):\n            return\n        pts = coords - cm\n        xyz2 = np.sum(pts * pts, axis=0)\n        scale = 1 / np.sqrt(np.sum(xyz2) / len(pts))\n        t = vtk.vtkTransform()\n        t.Scale(scale, scale, scale)\n        t.Translate(-cm)\n        tf = vtk.vtkTransformPolyDataFilter()\n        tf.SetInputData(self.poly)\n        tf.SetTransform(t)\n        tf.Update()\n        return self.updateMesh(tf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mirror(self, axis=\"x\"):\n        poly = self.polydata(transformed=True)\n        polyCopy = vtk.vtkPolyData()\n        polyCopy.DeepCopy(poly)\n\n        sx, sy, sz = 1, 1, 1\n        dx, dy, dz = self.GetPosition()\n        if axis.lower() == \"x\":\n            sx = -1\n        elif axis.lower() == \"y\":\n            sy = -1\n        elif axis.lower() == \"z\":\n            sz = -1\n        elif axis.lower() == \"n\":\n            pass\n        else:\n            colors.printc(\"~times Error in mirror(): mirror must be set to x, y, z or n.\", c=1)\n            raise RuntimeError()\n\n        if axis != \"n\":\n            for j in range(polyCopy.GetNumberOfPoints()):\n                p = [0, 0, 0]\n                polyCopy.GetPoint(j, p)\n                polyCopy.GetPoints().SetPoint(\n                    j,\n                    p[0] * sx - dx * (sx - 1),\n                    p[1] * sy - dy * (sy - 1),\n                    p[2] * sz - dz * (sz - 1),\n                )\n        rs = vtk.vtkReverseSense()\n        rs.SetInputData(polyCopy)\n        rs.ReverseNormalsOn()\n        rs.Update()\n        polyCopy = rs.GetOutput()\n\n        pdnorm = vtk.vtkPolyDataNormals()\n        pdnorm.SetInputData(polyCopy)\n        pdnorm.ComputePointNormalsOn()\n        pdnorm.ComputeCellNormalsOn()\n        pdnorm.FlipNormalsOff()\n        pdnorm.ConsistencyOn()\n        pdnorm.Update()\n        return self.updateMesh(pdnorm.GetOutput())", "response": "Mirror the actor s polydata along one of the cartesian axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shrink(self, fraction=0.85):\n        poly = self.polydata(True)\n        shrink = vtk.vtkShrinkPolyData()\n        shrink.SetInputData(poly)\n        shrink.SetShrinkFactor(fraction)\n        shrink.Update()\n        return self.updateMesh(shrink.GetOutput())", "response": "Shrink the triangle polydata in the representation of the input mesh."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stretch(self, q1, q2):\n        if self.base is None:\n            colors.printc('~times Error in stretch(): Please define vectors \\\n                          actor.base and actor.top at creation. Exit.', c='r')\n            exit(0)\n\n        p1, p2 = self.base, self.top\n        q1, q2, z = np.array(q1), np.array(q2), np.array([0, 0, 1])\n        plength = np.linalg.norm(p2 - p1)\n        qlength = np.linalg.norm(q2 - q1)\n        T = vtk.vtkTransform()\n        T.PostMultiply()\n        T.Translate(-p1)\n        cosa = np.dot(p2 - p1, z) / plength\n        n = np.cross(p2 - p1, z)\n        T.RotateWXYZ(np.arccos(cosa) * 57.3, n)\n\n        T.Scale(1, 1, qlength / plength)\n\n        cosa = np.dot(q2 - q1, z) / qlength\n        n = np.cross(q2 - q1, z)\n        T.RotateWXYZ(-np.arccos(cosa) * 57.3, n)\n        T.Translate(q1)\n\n        self.SetUserMatrix(T.GetMatrix())\n        if self.trail:\n            self.updateTrail()\n        return self", "response": "Stretch actor between points q1 and q2. Mesh is not affected."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cutWithPlane(self, origin=(0, 0, 0), normal=(1, 0, 0), showcut=False):\n        if normal is \"x\":\n            normal = (1,0,0)\n        elif normal is \"y\":\n            normal = (0,1,0)\n        elif normal is \"z\":\n            normal = (0,0,1)\n        plane = vtk.vtkPlane()\n        plane.SetOrigin(origin)\n        plane.SetNormal(normal)\n\n        self.computeNormals()\n        poly = self.polydata()\n        clipper = vtk.vtkClipPolyData()\n        clipper.SetInputData(poly)\n        clipper.SetClipFunction(plane)\n        if showcut:\n            clipper.GenerateClippedOutputOn()\n        else:\n            clipper.GenerateClippedOutputOff()\n        clipper.GenerateClipScalarsOff()\n        clipper.SetValue(0)\n        clipper.Update()\n\n        self.updateMesh(clipper.GetOutput())\n\n        if showcut:\n            c = self.GetProperty().GetColor()\n            cpoly = clipper.GetClippedOutput()\n            restActor = Actor(cpoly, c=c, alpha=0.05, wire=1)\n            restActor.SetUserMatrix(self.GetMatrix())\n            asse = Assembly([self, restActor])\n            self = asse\n            return asse\n        else:\n            return self", "response": "Takes a vtkActor and cuts it with a plane defined by a point and a normal."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncuts an actor with another vtkPolyData or actor.", "response": "def cutWithMesh(self, mesh, invert=False):\n        \"\"\"\n        Cut an ``Actor`` mesh with another ``vtkPolyData`` or ``Actor``.\n\n        :param bool invert: if True return cut off part of actor.\n\n        .. hint:: |cutWithMesh| |cutWithMesh.py|_\n\n            |cutAndCap| |cutAndCap.py|_\n        \"\"\"\n        if isinstance(mesh, vtk.vtkPolyData):\n            polymesh = mesh\n        if isinstance(mesh, Actor):\n            polymesh = mesh.polydata()\n        else:\n            polymesh = mesh.GetMapper().GetInput()\n        poly = self.polydata()\n\n        # Create an array to hold distance information\n        signedDistances = vtk.vtkFloatArray()\n        signedDistances.SetNumberOfComponents(1)\n        signedDistances.SetName(\"SignedDistances\")\n\n        # implicit function that will be used to slice the mesh\n        ippd = vtk.vtkImplicitPolyDataDistance()\n        ippd.SetInput(polymesh)\n\n        # Evaluate the signed distance function at all of the grid points\n        for pointId in range(poly.GetNumberOfPoints()):\n            p = poly.GetPoint(pointId)\n            signedDistance = ippd.EvaluateFunction(p)\n            signedDistances.InsertNextValue(signedDistance)\n\n        # add the SignedDistances to the grid\n        poly.GetPointData().SetScalars(signedDistances)\n\n        # use vtkClipDataSet to slice the grid with the polydata\n        clipper = vtk.vtkClipPolyData()\n        clipper.SetInputData(poly)\n        if invert:\n            clipper.InsideOutOff()\n        else:\n            clipper.InsideOutOn()\n        clipper.SetValue(0.0)\n        clipper.Update()\n        return self.updateMesh(clipper.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a cap on a clipped actor or caps sharp edges.", "response": "def cap(self, returnCap=False):\n        \"\"\"\n        Generate a \"cap\" on a clipped actor, or caps sharp edges.\n\n        .. hint:: |cutAndCap| |cutAndCap.py|_\n        \"\"\"\n        poly = self.polydata(True)\n\n        fe = vtk.vtkFeatureEdges()\n        fe.SetInputData(poly)\n        fe.BoundaryEdgesOn()\n        fe.FeatureEdgesOff()\n        fe.NonManifoldEdgesOff()\n        fe.ManifoldEdgesOff()\n        fe.Update()\n\n        stripper = vtk.vtkStripper()\n        stripper.SetInputData(fe.GetOutput())\n        stripper.Update()\n\n        boundaryPoly = vtk.vtkPolyData()\n        boundaryPoly.SetPoints(stripper.GetOutput().GetPoints())\n        boundaryPoly.SetPolys(stripper.GetOutput().GetLines())\n\n        tf = vtk.vtkTriangleFilter()\n        tf.SetInputData(boundaryPoly)\n        tf.Update()\n\n        if returnCap:\n            return Actor(tf.GetOutput())\n        else:\n            polyapp = vtk.vtkAppendPolyData()\n            polyapp.AddInputData(poly)\n            polyapp.AddInputData(tf.GetOutput())\n            polyapp.Update()\n            return self.updateMesh(polyapp.GetOutput()).clean()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new vtkObject containing a vtkThreshold object that applies a threshold criterion to the given array of scalars.", "response": "def threshold(self, scalars, vmin=None, vmax=None, useCells=False):\n        \"\"\"\n        Extracts cells where scalar value satisfies threshold criterion.\n\n        :param scalars: name of the scalars array.\n        :type scalars: str, list\n        :param float vmin: minimum value of the scalar\n        :param float vmax: maximum value of the scalar\n        :param bool useCells: if `True`, assume array scalars refers to cells.\n\n        .. hint:: |mesh_threshold| |mesh_threshold.py|_\n        \"\"\"\n        if utils.isSequence(scalars):\n            self.addPointScalars(scalars, \"threshold\")\n            scalars = \"threshold\"\n        elif self.scalars(scalars) is None:\n            colors.printc(\"~times No scalars found with name\", scalars, c=1)\n            exit()\n\n        thres = vtk.vtkThreshold()\n        thres.SetInputData(self.poly)\n\n        if useCells:\n            asso = vtk.vtkDataObject.FIELD_ASSOCIATION_CELLS\n        else:\n            asso = vtk.vtkDataObject.FIELD_ASSOCIATION_POINTS\n        thres.SetInputArrayToProcess(0, 0, 0, asso, scalars)\n\n        if vmin is None and vmax is not None:\n            thres.ThresholdByLower(vmax)\n        elif vmax is None and vmin is not None:\n            thres.ThresholdByUpper(vmin)\n        else:\n            thres.ThresholdBetween(vmin, vmax)\n        thres.Update()\n\n        gf = vtk.vtkGeometryFilter()\n        gf.SetInputData(thres.GetOutput())\n        gf.Update()\n        return self.updateMesh(gf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert actor polygons and strips to triangles.", "response": "def triangle(self, verts=True, lines=True):\n        \"\"\"\n        Converts actor polygons and strips to triangles.\n        \"\"\"\n        tf = vtk.vtkTriangleFilter()\n        tf.SetPassLines(lines)\n        tf.SetPassVerts(verts)\n        tf.SetInputData(self.poly)\n        tf.Update()\n        return self.updateMesh(tf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mapCellsToPoints(self):\n        c2p = vtk.vtkCellDataToPointData()\n        c2p.SetInputData(self.polydata(False))\n        c2p.Update()\n        return self.updateMesh(c2p.GetOutput())", "response": "Transform cell data into point data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mapPointsToCells(self):\n        p2c = vtk.vtkPointDataToCellData()\n        p2c.SetInputData(self.polydata(False))\n        p2c.Update()\n        return self.updateMesh(p2c.GetOutput())", "response": "Map point data to cells."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets individual point colors by providing a list of scalar values and a color map.", "response": "def pointColors(self, scalars, cmap=\"jet\", alpha=1, bands=None, vmin=None, vmax=None):\n        \"\"\"\n        Set individual point colors by providing a list of scalar values and a color map.\n        `scalars` can be a string name of the ``vtkArray``.\n\n        :param cmap: color map scheme to transform a real number into a color.\n        :type cmap: str, list, vtkLookupTable, matplotlib.colors.LinearSegmentedColormap\n        :param alpha: mesh transparency. Can be a ``list`` of values one for each vertex.\n        :type alpha: float, list\n        :param int bands: group scalars in this number of bins, typically to form bands or stripes.\n        :param float vmin: clip scalars to this minimum value\n        :param float vmax: clip scalars to this maximum value\n\n        .. hint:: |mesh_coloring| |mesh_coloring.py|_\n\n            |mesh_alphas| |mesh_alphas.py|_\n\n            |mesh_bands| |mesh_bands.py|_\n\n            |mesh_custom| |mesh_custom.py|_\n        \"\"\"\n        poly = self.polydata(False)\n\n        if isinstance(scalars, str):  # if a name is passed\n            scalars = vtk_to_numpy(poly.GetPointData().GetArray(scalars))\n\n        n = len(scalars)\n        useAlpha = False\n        if n != poly.GetNumberOfPoints():\n            colors.printc('~times pointColors Error: nr. of scalars != nr. of points',\n                          n, poly.GetNumberOfPoints(), c=1)\n        if utils.isSequence(alpha):\n            useAlpha = True\n            if len(alpha) > n:\n                colors.printc('~times pointColors Error: nr. of scalars < nr. of alpha values',\n                              n, len(alpha), c=1)\n                exit()\n        if bands:\n            scalars = utils.makeBands(scalars, bands)\n\n        if vmin is None:\n            vmin = np.min(scalars)\n        if vmax is None:\n            vmax = np.max(scalars)\n\n        lut = vtk.vtkLookupTable()  # build the look-up table\n\n        if utils.isSequence(cmap):\n            sname = \"pointColors_custom\"\n            lut.SetNumberOfTableValues(len(cmap))\n            lut.Build()\n            for i, c in enumerate(cmap):\n                col = colors.getColor(c)\n                r, g, b = col\n                if useAlpha:\n                    lut.SetTableValue(i, r, g, b, alpha[i])\n                else:\n                    lut.SetTableValue(i, r, g, b, alpha)\n\n        elif isinstance(cmap, vtk.vtkLookupTable):\n            sname = \"pointColors_lut\"\n            lut = cmap\n\n        else:\n            if isinstance(cmap, str):\n                sname = \"pointColors_\" + cmap\n            else:\n                sname = \"pointColors\"\n            lut.SetNumberOfTableValues(512)\n            lut.Build()\n            for i in range(512):\n                r, g, b = colors.colorMap(i, cmap, 0, 512)\n                if useAlpha:\n                    idx = int(i / 512 * len(alpha))\n                    lut.SetTableValue(i, r, g, b, alpha[idx])\n                else:\n                    lut.SetTableValue(i, r, g, b, alpha)\n\n        arr = numpy_to_vtk(np.ascontiguousarray(scalars), deep=True)\n        arr.SetName(sname)\n        self.mapper.SetScalarRange(vmin, vmax)\n        self.mapper.SetLookupTable(lut)\n        self.mapper.ScalarVisibilityOn()\n        poly.GetPointData().SetScalars(arr)\n        poly.GetPointData().SetActiveScalars(sname)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addPointScalars(self, scalars, name):\n        poly = self.polydata(False)\n        if len(scalars) != poly.GetNumberOfPoints():\n            colors.printc('~times pointScalars Error: Number of scalars != nr. of points',\n                          len(scalars), poly.GetNumberOfPoints(), c=1)\n            exit()\n        arr = numpy_to_vtk(np.ascontiguousarray(scalars), deep=True)\n        arr.SetName(name)\n        poly.GetPointData().AddArray(arr)\n        poly.GetPointData().SetActiveScalars(name)\n        self.mapper.SetScalarRange(np.min(scalars), np.max(scalars))\n        self.mapper.ScalarVisibilityOn()\n        return self", "response": "Add point scalars to the actor s polydata assigning it a name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addCellScalars(self, scalars, name):\n        poly = self.polydata(False)\n        if isinstance(scalars, str):\n            scalars = vtk_to_numpy(poly.GetPointData().GetArray(scalars))\n\n        if len(scalars) != poly.GetNumberOfCells():\n            colors.printc(\"~times Number of scalars != nr. of cells\", c=1)\n            exit()\n        arr = numpy_to_vtk(np.ascontiguousarray(scalars), deep=True)\n        arr.SetName(name)\n        poly.GetCellData().AddArray(arr)\n        poly.GetCellData().SetActiveScalars(name)\n        self.mapper.SetScalarRange(np.min(scalars), np.max(scalars))\n        self.mapper.ScalarVisibilityOn()\n        return self", "response": "Adds cell scalars to the actor s polydata assigning it a name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a point vector field to the actor s polydata assigning it a name.", "response": "def addPointVectors(self, vectors, name):\n        \"\"\"\n        Add a point vector field to the actor's polydata assigning it a name.\n        \"\"\"\n        poly = self.polydata(False)\n        if len(vectors) != poly.GetNumberOfPoints():\n            colors.printc('~times addPointVectors Error: Number of vectors != nr. of points',\n                          len(vectors), poly.GetNumberOfPoints(), c=1)\n            exit()\n        arr = vtk.vtkDoubleArray()\n        arr.SetNumberOfComponents(3)\n        arr.SetName(name)\n        for v in vectors:\n            arr.InsertNextTuple(v)\n        poly.GetPointData().AddArray(arr)\n        poly.GetPointData().SetActiveVectors(name)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addIDs(self, asfield=False):\n        ids = vtk.vtkIdFilter()\n        ids.SetInputData(self.poly)\n        ids.PointIdsOn()\n        ids.CellIdsOn()\n        if asfield:\n            ids.FieldDataOn()\n        else:\n            ids.FieldDataOff()\n        ids.Update()\n        return self.updateMesh(ids.GetOutput())", "response": "Generate point and cell ids."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addCurvatureScalars(self, method=0, lut=None):\n        curve = vtk.vtkCurvatures()\n        curve.SetInputData(self.poly)\n        curve.SetCurvatureType(method)\n        curve.Update()\n        self.poly = curve.GetOutput()\n\n        scls = self.poly.GetPointData().GetScalars().GetRange()\n        print(\"curvature(): scalar range is\", scls)\n\n        self.mapper.SetInputData(self.poly)\n        if lut:\n            self.mapper.SetLookupTable(lut)\n            self.mapper.SetUseLookupTableScalarRange(1)\n        self.mapper.Update()\n        self.Modified()\n        self.mapper.ScalarVisibilityOn()\n        return self", "response": "Build an actor that contains the color coded surface\n        curvature calculated in three different ways."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scalars(self, name_or_idx=None, datatype=\"point\"):\n        poly = self.polydata(False)\n\n        if name_or_idx is None:  # get mode behaviour\n            ncd = poly.GetCellData().GetNumberOfArrays()\n            npd = poly.GetPointData().GetNumberOfArrays()\n            nfd = poly.GetFieldData().GetNumberOfArrays()\n            arrs = []\n            for i in range(npd):\n                print(i, \"PointData\", poly.GetPointData().GetArrayName(i))\n                arrs.append([\"PointData\", poly.GetPointData().GetArrayName(i)])\n            for i in range(ncd):\n                print(i, \"CellData\", poly.GetCellData().GetArrayName(i))\n                arrs.append([\"CellData\", poly.GetCellData().GetArrayName(i)])\n            for i in range(nfd):\n                print(i, \"FieldData\", poly.GetFieldData().GetArrayName(i))\n                arrs.append([\"FieldData\", poly.GetFieldData().GetArrayName(i)])\n            return arrs\n        else:  # set mode\n            if \"point\" in datatype.lower():\n                data = poly.GetPointData()\n            elif \"cell\" in datatype.lower():\n                data = poly.GetCellData()\n            elif \"field\" in datatype.lower():\n                data = poly.GetFieldData()\n            else:\n                colors.printc(\"~times Error in scalars(): unknown datatype\", datatype, c=1)\n                exit()\n\n            if isinstance(name_or_idx, int):\n                name = data.GetArrayName(name_or_idx)\n                if name is None:\n                    return None\n                data.SetActiveScalars(name)\n                return vtk_to_numpy(data.GetArray(name))\n            elif isinstance(name_or_idx, str):\n                arr = data.GetArray(name_or_idx)\n                if arr is None:\n                    return None\n                data.SetActiveScalars(name_or_idx)\n                return vtk_to_numpy(arr)\n\n            return None", "response": "Retrieve point or cell scalars using array name or index number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincreasing the number of vertices of a surface mesh.", "response": "def subdivide(self, N=1, method=0):\n        \"\"\"Increase the number of vertices of a surface mesh.\n\n        :param int N: number of subdivisions.\n        :param int method: Loop(0), Linear(1), Adaptive(2), Butterfly(3)\n\n        .. hint:: |tutorial_subdivide| |tutorial.py|_\n        \"\"\"\n        triangles = vtk.vtkTriangleFilter()\n        triangles.SetInputData(self.polydata())\n        triangles.Update()\n        originalMesh = triangles.GetOutput()\n        if method == 0:\n            sdf = vtk.vtkLoopSubdivisionFilter()\n        elif method == 1:\n            sdf = vtk.vtkLinearSubdivisionFilter()\n        elif method == 2:\n            sdf = vtk.vtkAdaptiveSubdivisionFilter()\n        elif method == 3:\n            sdf = vtk.vtkButterflySubdivisionFilter()\n        else:\n            colors.printc(\"~times Error in subdivide: unknown method.\", c=\"r\")\n            exit()\n        if method != 2:\n            sdf.SetNumberOfSubdivisions(N)\n        sdf.SetInputData(originalMesh)\n        sdf.Update()\n        return self.updateMesh(sdf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds gaussian noise to the actor.", "response": "def addGaussNoise(self, sigma):\n        \"\"\"\n        Add gaussian noise.\n\n        :param float sigma: sigma is expressed in percent of the diagonal size of actor.\n        \n        :Example:\n            .. code-block:: python\n            \n                from vtkplotter import Sphere\n                \n                Sphere().addGaussNoise(1.0).show()\n        \"\"\"\n        sz = self.diagonalSize()\n        pts = self.coordinates()\n        n = len(pts)\n        ns = np.random.randn(n, 3) * sigma * sz / 100\n        vpts = vtk.vtkPoints()\n        vpts.SetNumberOfPoints(n)\n        vpts.SetData(numpy_to_vtk(pts + ns, deep=True))\n        self.poly.SetPoints(vpts)\n        self.poly.GetPoints().Modified()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smoothLaplacian(self, niter=15, relaxfact=0.1, edgeAngle=15, featureAngle=60):\n        poly = self.poly\n        cl = vtk.vtkCleanPolyData()\n        cl.SetInputData(poly)\n        cl.Update()\n        smoothFilter = vtk.vtkSmoothPolyDataFilter()\n        smoothFilter.SetInputData(cl.GetOutput())\n        smoothFilter.SetNumberOfIterations(niter)\n        smoothFilter.SetRelaxationFactor(relaxfact)\n        smoothFilter.SetEdgeAngle(edgeAngle)\n        smoothFilter.SetFeatureAngle(featureAngle)\n        smoothFilter.BoundarySmoothingOn()\n        smoothFilter.FeatureEdgeSmoothingOn()\n        smoothFilter.GenerateErrorScalarsOn()\n        smoothFilter.Update()\n        return self.updateMesh(smoothFilter.GetOutput())", "response": "Adjust the mesh point positions using Laplacian smoothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smoothWSinc(self, niter=15, passBand=0.1, edgeAngle=15, featureAngle=60):\n        poly = self.poly\n        cl = vtk.vtkCleanPolyData()\n        cl.SetInputData(poly)\n        cl.Update()\n        smoothFilter = vtk.vtkWindowedSincPolyDataFilter()\n        smoothFilter.SetInputData(cl.GetOutput())\n        smoothFilter.SetNumberOfIterations(niter)\n        smoothFilter.SetEdgeAngle(edgeAngle)\n        smoothFilter.SetFeatureAngle(featureAngle)\n        smoothFilter.SetPassBand(passBand)\n        smoothFilter.NormalizeCoordinatesOn()\n        smoothFilter.NonManifoldSmoothingOn()\n        smoothFilter.FeatureEdgeSmoothingOn()\n        smoothFilter.BoundarySmoothingOn()\n        smoothFilter.Update()\n        return self.updateMesh(smoothFilter.GetOutput())", "response": "Adjust the mesh point positions using the Windowed Sinc function interpolation kernel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fillHoles(self, size=None):\n        fh = vtk.vtkFillHolesFilter()\n        if not size:\n            mb = self.maxBoundSize()\n            size = mb / 10\n        fh.SetHoleSize(size)\n        fh.SetInputData(self.poly)\n        fh.Update()\n        return self.updateMesh(fh.GetOutput())", "response": "Identifies and fills holes in input mesh."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, filename=\"mesh.vtk\", binary=True):\n        import vtkplotter.vtkio as vtkio\n\n        return vtkio.write(self, filename, binary)", "response": "Write actor s current transformation in its current transformation to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalAt(self, i):\n        normals = self.polydata(True).GetPointData().GetNormals()\n        return np.array(normals.GetTuple(i))", "response": "Return the normal vector at vertex point i."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves vertex normals as a numpy array.", "response": "def normals(self, cells=False):\n        \"\"\"Retrieve vertex normals as a numpy array.\n\n        :params bool cells: if `True` return cell normals.\n        \"\"\"\n        if cells:\n            vtknormals = self.polydata(True).GetCellData().GetNormals()\n        else:\n            vtknormals = self.polydata(True).GetPointData().GetNormals()\n        return vtk_to_numpy(vtknormals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the vtkPolyData of an actor.", "response": "def polydata(self, transformed=True):\n        \"\"\"\n        Returns the ``vtkPolyData`` of an ``Actor``.\n\n        .. note:: If ``transformed=True`` returns a copy of polydata that corresponds\n            to the current actor's position in space.\n\n        .. hint:: |quadratic_morphing| |quadratic_morphing.py|_\n        \"\"\"\n        if not transformed:\n            if not self.poly:\n                self.poly = self.GetMapper().GetInput()  # cache it for speed\n            return self.poly\n        M = self.GetMatrix()\n        if utils.isIdentity(M):\n            if not self.poly:\n                self.poly = self.GetMapper().GetInput()  # cache it for speed\n            return self.poly\n        # if identity return the original polydata\n        # otherwise make a copy that corresponds to\n        # the actual position in space of the actor\n        transform = vtk.vtkTransform()\n        transform.SetMatrix(M)\n        tp = vtk.vtkTransformPolyDataFilter()\n        tp.SetTransform(transform)\n        tp.SetInputData(self.poly)\n        tp.Update()\n        return tp.GetOutput()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of vertex coordinates of the input mesh. Same as actor. getPoints.", "response": "def coordinates(self, transformed=True, copy=True):\n        \"\"\"\n        Return the list of vertex coordinates of the input mesh. Same as `actor.getPoints()`.\n\n        :param bool transformed: if `False` ignore any previous trasformation applied to the mesh.\n        :param bool copy: if `False` return the reference to the points\n            so that they can be modified in place.\n\n        .. hint:: |align1.py|_\n        \"\"\"\n        poly = self.polydata(transformed)\n        if copy:\n            return np.array(vtk_to_numpy(poly.GetPoints().GetData()))\n        else:\n            return vtk_to_numpy(poly.GetPoints().GetData())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move(self, u_function):\n        if self.mesh:\n            self.u = u_function\n            delta = [u_function(p) for p in self.mesh.coordinates()]\n            movedpts = self.mesh.coordinates() + delta\n            self.polydata(False).GetPoints().SetData(numpy_to_vtk(movedpts))\n            self.poly.GetPoints().Modified()\n            self.u_values = delta\n        else:\n            colors.printc(\"Warning: calling move() but actor.mesh is\", self.mesh, c=3)\n        return self", "response": "Move a mesh by using an external function which prescribes the displacement\n            at any point in space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current user transformation for the actor.", "response": "def getTransform(self):\n        \"\"\"\n        Check if ``info['transform']`` exists and returns it.\n        Otherwise return current user transformation\n        (where the actor is currently placed).\n        \"\"\"\n        if \"transform\" in self.info.keys():\n            T = self.info[\"transform\"]\n            return T\n        else:\n            T = self.GetMatrix()\n            tr = vtk.vtkTransform()\n            tr.SetMatrix(T)\n            return tr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the actor s transform position and orientation wrt to its polygonal mesh.", "response": "def setTransform(self, T):\n        \"\"\"\n        Transform actor position and orientation wrt to its polygonal mesh,\n        which remains unmodified.\n        \"\"\"\n        if isinstance(T, vtk.vtkMatrix4x4):\n            self.SetUserMatrix(T)\n        else:\n            try:\n                self.SetUserTransform(T)\n            except TypeError:\n                colors.printc('~time Error in setTransform(): consider transformPolydata() instead.', c=1)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isInside(self, point, tol=0.0001):\n        poly = self.polydata(True)\n        points = vtk.vtkPoints()\n        points.InsertNextPoint(point)\n        pointsPolydata = vtk.vtkPolyData()\n        pointsPolydata.SetPoints(points)\n        sep = vtk.vtkSelectEnclosedPoints()\n        sep.SetTolerance(tol)\n        sep.CheckSurfaceOff()\n        sep.SetInputData(pointsPolydata)\n        sep.SetSurfaceData(poly)\n        sep.Update()\n        return sep.IsInside(0)", "response": "Return True if point is inside a polydata closed surface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of points that are inside a polydata closed surface.", "response": "def insidePoints(self, points, invert=False, tol=1e-05):\n        \"\"\"\n        Return the sublist of points that are inside a polydata closed surface.\n        \n        .. hint:: |pca| |pca.py|_\n        \"\"\"\n        poly = self.polydata(True)\n        # check if the stl file is closed\n        \n        #featureEdge = vtk.vtkFeatureEdges()\n        #featureEdge.FeatureEdgesOff()\n        #featureEdge.BoundaryEdgesOn()\n        #featureEdge.NonManifoldEdgesOn()\n        #featureEdge.SetInputData(poly)\n        #featureEdge.Update()\n        #openEdges = featureEdge.GetOutput().GetNumberOfCells()\n        #if openEdges != 0:\n        #    colors.printc(\"~lightning Warning: polydata is not a closed surface\", c=5)\n\n        vpoints = vtk.vtkPoints()\n        vpoints.SetData(numpy_to_vtk(points, deep=True))\n        pointsPolydata = vtk.vtkPolyData()\n        pointsPolydata.SetPoints(vpoints)\n        sep = vtk.vtkSelectEnclosedPoints()\n        sep.SetTolerance(tol)\n        sep.SetInputData(pointsPolydata)\n        sep.SetSurfaceData(poly)\n        sep.Update()\n\n        mask1, mask2 = [], []\n        for i, p in enumerate(points):\n            if sep.IsInside(i):\n                mask1.append(p)\n            else:\n                mask2.append(p)\n        if invert:\n            return mask2\n        else:\n            return mask1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cellCenters(self):\n        vcen = vtk.vtkCellCenters()\n        vcen.SetInputData(self.polydata(True))\n        vcen.Update()\n        return vtk_to_numpy(vcen.GetOutput().GetPoints().GetData())", "response": "Get the list of cell centers of the mesh surface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef boundaries(self, boundaryEdges=True, featureAngle=65, nonManifoldEdges=True):\n        fe = vtk.vtkFeatureEdges()\n        fe.SetInputData(self.polydata())\n        fe.SetBoundaryEdges(boundaryEdges)\n        \n        if featureAngle:\n            fe.FeatureEdgesOn()\n            fe.SetFeatureAngle(featureAngle)\n        else:\n            fe.FeatureEdgesOff()\n        \n        fe.SetNonManifoldEdges(nonManifoldEdges)\n        fe.ColoringOff()\n        fe.Update()\n        return Actor(fe.GetOutput(), c=\"p\").lw(5)", "response": "Returns an Actor that shows the boundary lines of an input mesh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all vertices connected to an input vertex specified by its index.", "response": "def connectedVertices(self, index, returnIds=False):\n        \"\"\"Find all vertices connected to an input vertex specified by its index.\n\n        :param bool returnIds: return vertex IDs instead of vertex coordinates.\n\n        .. hint:: |connVtx| |connVtx.py|_\n        \"\"\"\n        mesh = self.polydata()\n\n        cellIdList = vtk.vtkIdList()\n        mesh.GetPointCells(index, cellIdList)\n\n        idxs = []\n        for i in range(cellIdList.GetNumberOfIds()):\n            pointIdList = vtk.vtkIdList()\n            mesh.GetCellPoints(cellIdList.GetId(i), pointIdList)\n            for j in range(pointIdList.GetNumberOfIds()):\n                idj = pointIdList.GetId(j)\n                if idj == index:\n                    continue\n                if idj in idxs:\n                    continue\n                idxs.append(idj)\n\n        if returnIds:\n            return idxs\n        else:\n            trgp = []\n            for i in idxs:\n                p = [0, 0, 0]\n                mesh.GetPoints().GetPoint(i, p)\n                trgp.append(p)\n            return np.array(trgp)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connectedCells(self, index, returnIds=False):\n        \n        # Find all cells connected to point index\n        dpoly = self.polydata()\n        cellPointIds = vtk.vtkIdList()\n        dpoly.GetPointCells(index, cellPointIds)\n    \n        ids = vtk.vtkIdTypeArray()\n        ids.SetNumberOfComponents(1)\n        rids = []\n        for k in range(cellPointIds.GetNumberOfIds()):\n            cid = cellPointIds.GetId(k)\n            ids.InsertNextValue(cid)\n            rids.append(int(cid))\n        if returnIds:\n            return rids\n           \n        selectionNode = vtk.vtkSelectionNode()\n        selectionNode.SetFieldType(vtk.vtkSelectionNode.CELL)\n        selectionNode.SetContentType(vtk.vtkSelectionNode.INDICES)\n        selectionNode.SetSelectionList(ids)\n        selection = vtk.vtkSelection()\n        selection.AddNode(selectionNode)\n        extractSelection = vtk.vtkExtractSelection()\n        extractSelection.SetInputData(0, dpoly)\n        extractSelection.SetInputData(1, selection)\n        extractSelection.Update()\n        gf = vtk.vtkGeometryFilter()\n        gf.SetInputData(extractSelection.GetOutput())\n        gf.Update()\n        return Actor(gf.GetOutput()).lw(1)", "response": "Find all cellls connected to an input vertex specified by its index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intersectWithLine(self, p0, p1):\n        if not self.line_locator:\n            line_locator = vtk.vtkOBBTree()\n            line_locator.SetDataSet(self.polydata(True))\n            line_locator.BuildLocator()\n            self.line_locator = line_locator\n\n        intersectPoints = vtk.vtkPoints()\n        intersection = [0, 0, 0]\n        self.line_locator.IntersectWithLine(p0, p1, intersectPoints, None)\n        pts = []\n        for i in range(intersectPoints.GetNumberOfPoints()):\n            intersectPoints.GetPoint(i, intersection)\n            pts.append(list(intersection))\n        return pts", "response": "Return the list of points intersecting the actor \n        along the segment defined by two points p0 and p1."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getActors(self):\n        cl = vtk.vtkPropCollection()\n        self.GetActors(cl)\n        self.actors = []\n        cl.InitTraversal()\n        for i in range(self.GetNumberOfPaths()):\n            act = vtk.vtkActor.SafeDownCast(cl.GetNextProp())\n            if act.GetPickable():\n                self.actors.append(act)\n        return self.actors", "response": "Unpack a list of vtkActor objects from a vtkAssembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the maximum diagonal size of the Actors of the Assembly.", "response": "def diagonalSize(self):\n        \"\"\"Return the maximum diagonal size of the ``Actors`` of the ``Assembly``.\"\"\"\n        szs = [a.diagonalSize() for a in self.actors]\n        return np.max(szs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset actor s transparency.", "response": "def alpha(self, a=None):\n        \"\"\"Set/get actor's transparency.\"\"\"\n        if a is not None:\n            self.GetProperty().SetOpacity(a)\n            return self\n        else:\n            return self.GetProperty().GetOpacity()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef crop(self, top=None, bottom=None, right=None, left=None):\n        extractVOI = vtk.vtkExtractVOI()\n        extractVOI.SetInputData(self.GetInput())\n        extractVOI.IncludeBoundaryOn()\n\n        d = self.GetInput().GetDimensions()\n        bx0, bx1, by0, by1 = 0, d[0]-1, 0, d[1]-1\n        if left is not None:   bx0 = int((d[0]-1)*left)\n        if right is not None:  bx1 = int((d[0]-1)*(1-right))\n        if bottom is not None: by0 = int((d[1]-1)*bottom)\n        if top is not None:    by1 = int((d[1]-1)*(1-top))\n        extractVOI.SetVOI(bx0, bx1, by0, by1, 0, 0)\n        extractVOI.Update()\n        img = extractVOI.GetOutput()\n        #img.SetOrigin(-bx0, -by0, 0)\n        self.GetMapper().SetInputData(img)\n        self.GetMapper().Modified()\n        return self", "response": "Crop image.\n        \n        :param float top: fraction to crop from the top margin\n        :param float bottom: fraction to crop from the bottom margin\n        :param float left: fraction to crop from the left margin\n        :param float right: fraction to crop from the right margin"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef threshold(self, vmin=None, vmax=None, replaceWith=None):\n        th = vtk.vtkImageThreshold()\n        th.SetInputData(self.image)\n        \n        if vmin is not None and vmax is not None:\n            th.ThresholdBetween(vmin, vmax)\n        elif vmin is not None:\n            th.ThresholdByUpper(vmin)\n        elif vmax is not None:\n            th.ThresholdByLower(vmax)       \n\n        if replaceWith:\n            th.ReplaceOutOn()\n            th.SetOutValue(replaceWith)\n        th.Update()\n        \n        self.image = th.GetOutput()\n        self.mapper.SetInputData(self.image)\n        self.mapper.Modified()\n        return self", "response": "Binary or continuous volume thresholding."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getVoxelsScalar(self, vmin=None, vmax=None):\n        nx, ny, nz = self.image.GetDimensions()\n        \n        voxdata = np.zeros([nx, ny, nz])\n        lsx = range(nx)\n        lsy = range(ny)\n        lsz = range(nz)\n        renorm = vmin is not None and vmax is not None\n        for i in lsx:\n            for j in lsy:\n                for k in lsz:\n                    s = self.image.GetScalarComponentAsFloat(i, j, k, 0)\n                    if renorm:\n                        s = (s - vmin) / (vmax - vmin)\n                    voxdata[i, j, k] = s\n        return voxdata", "response": "Return voxel content as a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(\n    inputobj,\n    c=\"gold\",\n    alpha=None,\n    wire=False,\n    bc=None,\n    texture=None,\n    smoothing=None,\n    threshold=None,\n    connectivity=False,\n):\n    \"\"\"\n    Returns a ``vtkActor`` from reading a file, directory or ``vtkPolyData``.\n\n    :param c: color in RGB format, hex, symbol or name\n    :param alpha:   transparency (0=invisible)\n    :param wire:    show surface as wireframe\n    :param bc:      backface color of internal surface\n    :param texture: any png/jpg file can be used as texture\n\n    For volumetric data (tiff, slc, vti files):\n\n    :param smoothing:    gaussian filter to smooth vtkImageData\n    :param threshold:    value to draw the isosurface\n    :param connectivity: if True only keeps the largest portion of the polydata\n    \"\"\"\n    if alpha is None:\n        alpha = 1\n\n    if isinstance(inputobj, vtk.vtkPolyData):\n        a = Actor(inputobj, c, alpha, wire, bc, texture)\n        if inputobj and inputobj.GetNumberOfPoints() == 0:\n            colors.printc(\"~lightning Warning: actor has zero points.\", c=5)\n        return a\n\n    acts = []\n    if isinstance(inputobj, list):\n        flist = inputobj\n    else:\n        import glob\n        flist = sorted(glob.glob(inputobj))\n\n    for fod in flist:\n        if os.path.isfile(fod):\n            if fod.endswith(\".vtm\"):\n                acts += loadMultiBlockData(fod, unpack=True)\n            else:\n                a = _loadFile(fod, c, alpha, wire, bc, texture,\n                              smoothing, threshold, connectivity)\n                acts.append(a)\n        elif os.path.isdir(fod):\n            acts = _loadDir(fod, c, alpha, wire, bc, texture,\n                            smoothing, threshold, connectivity)\n    if not len(acts):\n        colors.printc(\"~times Error in load(): cannot find\", inputobj, c=1)\n        return None\n\n    if len(acts) == 1:\n        return acts[0]\n    else:\n        return acts", "response": "Loads a single actor from a file directory or vtkPolyData object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadPolyData(filename):\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadPolyData: Cannot find\", filename, c=1)\n        return None\n    fl = filename.lower()\n    if   fl.endswith(\".vtk\"):\n        reader = vtk.vtkPolyDataReader()\n    elif fl.endswith(\".ply\"):\n        reader = vtk.vtkPLYReader()\n    elif fl.endswith(\".obj\"):\n        reader = vtk.vtkOBJReader()\n    elif fl.endswith(\".stl\"):\n        reader = vtk.vtkSTLReader()\n    elif fl.endswith(\".byu\") or fl.endswith(\".g\"):\n        reader = vtk.vtkBYUReader()\n    elif fl.endswith(\".vtp\"):\n        reader = vtk.vtkXMLPolyDataReader()\n    elif fl.endswith(\".vts\"):\n        reader = vtk.vtkXMLStructuredGridReader()\n    elif fl.endswith(\".vtu\"):\n        reader = vtk.vtkXMLUnstructuredGridReader()\n    elif fl.endswith(\".txt\"):\n        reader = vtk.vtkParticleReader()  # (x y z scalar)\n    elif fl.endswith(\".xyz\"):\n        reader = vtk.vtkParticleReader()\n    else:\n        reader = vtk.vtkDataReader()\n    reader.SetFileName(filename)\n    if fl.endswith(\".vts\"):  # structured grid\n        reader.Update()\n        gf = vtk.vtkStructuredGridGeometryFilter()\n        gf.SetInputConnection(reader.GetOutputPort())\n        gf.Update()\n        poly = gf.GetOutput()\n    elif fl.endswith(\".vtu\"):  # unstructured grid\n        reader.Update()\n        gf = vtk.vtkGeometryFilter()\n        gf.SetInputConnection(reader.GetOutputPort())\n        gf.Update()\n        poly = gf.GetOutput()\n    else:\n        try:\n            reader.Update()\n            poly = reader.GetOutput()\n        except:\n            poly = None\n\n    if not poly:\n        return None\n\n    cleanpd = vtk.vtkCleanPolyData()\n    cleanpd.SetInputData(poly)\n    cleanpd.Update()\n    return cleanpd.GetOutput()", "response": "Load a file and return a vtkPolyData object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadXMLGenericData(filename):  # not tested\n    reader = vtk.vtkXMLGenericDataObjectReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    return Actor(reader.GetOutput())", "response": "Read any type of data encoded in XML format. Return an Actor object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadStructuredPoints(filename):\n    reader = vtk.vtkStructuredPointsReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    gf = vtk.vtkImageDataGeometryFilter()\n    gf.SetInputConnection(reader.GetOutputPort())\n    gf.Update()\n    return Actor(gf.GetOutput())", "response": "Load a vtkStructuredPoints object from file and return an Actor object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a vtkStructuredGrid object from file and return a vtkActor object.", "response": "def loadStructuredGrid(filename):  # not tested\n    \"\"\"Load a ``vtkStructuredGrid`` object from file and return a ``Actor(vtkActor)`` object.\"\"\"\n    reader = vtk.vtkStructuredGridReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    gf = vtk.vtkStructuredGridGeometryFilter()\n    gf.SetInputConnection(reader.GetOutputPort())\n    gf.Update()\n    return Actor(gf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a vtkunStructuredGrid object from file and return a vtkActor object.", "response": "def loadUnStructuredGrid(filename):  # not tested\n    \"\"\"Load a ``vtkunStructuredGrid`` object from file and return a ``Actor(vtkActor)`` object.\"\"\"\n    reader = vtk.vtkUnstructuredGridReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    gf = vtk.vtkUnstructuredGridGeometryFilter()\n    gf.SetInputConnection(reader.GetOutputPort())\n    gf.Update()\n    return Actor(gf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a vtkRectilinearGrid object from file and return a vtkActor object.", "response": "def loadRectilinearGrid(filename):  # not tested\n    \"\"\"Load a ``vtkRectilinearGrid`` object from file and return a ``Actor(vtkActor)`` object.\"\"\"\n    reader = vtk.vtkRectilinearGridReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    gf = vtk.vtkRectilinearGridGeometryFilter()\n    gf.SetInputConnection(reader.GetOutputPort())\n    gf.Update()\n    return Actor(gf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load3DS(filename):\n    renderer = vtk.vtkRenderer()\n    renWin = vtk.vtkRenderWindow()\n    renWin.AddRenderer(renderer)\n\n    importer = vtk.vtk3DSImporter()\n    importer.SetFileName(filename)\n    importer.ComputeNormalsOn()\n    importer.SetRenderWindow(renWin)\n    importer.Update()\n\n    actors = renderer.GetActors()  # vtkActorCollection\n    acts = []\n    for i in range(actors.GetNumberOfItems()):\n        a = actors.GetItemAsObject(i)\n        acts.append(a)\n    del renWin\n    return Assembly(acts)", "response": "Load an Assembly from a 3DS file format. Return an Assembly object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadOFF(filename, c=\"gold\", alpha=1, wire=False, bc=None):\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadOFF: Cannot find\", filename, c=1)\n        return None\n\n    f = open(filename, \"r\")\n    lines = f.readlines()\n    f.close()\n\n    vertices = []\n    faces = []\n    NumberOfVertices = None\n    i = -1\n    for text in lines:\n        if len(text) == 0:\n            continue\n        if text == '\\n':\n            continue\n        if \"#\" in text:\n            continue\n        if \"OFF\" in text:\n            continue\n\n        ts = text.split()\n        n = len(ts)\n\n        if not NumberOfVertices and n > 1:\n            NumberOfVertices, NumberOfFaces = int(ts[0]), int(ts[1])\n            continue\n        i += 1\n\n        if i < NumberOfVertices and n == 3:\n            x, y, z = float(ts[0]), float(ts[1]), float(ts[2])\n            vertices.append([x, y, z])\n\n        ids = []\n        if NumberOfVertices <= i < (NumberOfVertices + NumberOfFaces + 1) and n > 2:\n            ids += [int(x) for x in ts[1:]]\n            faces.append(ids)\n\n    return Actor(buildPolyData(vertices, faces), c, alpha, wire, bc)", "response": "Read OFF file format."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a Fenics / Dolfin file format. Return an Actor object.", "response": "def loadDolfin(filename, c=\"gold\", alpha=0.5, wire=None, bc=None):\n    \"\"\"Reads a `Fenics/Dolfin` file format. Return an ``Actor(vtkActor)`` object.\"\"\"\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadDolfin: Cannot find\", filename, c=1)\n        return None\n    import xml.etree.ElementTree as et\n\n    if filename.endswith(\".gz\"):\n        import gzip\n\n        inF = gzip.open(filename, \"rb\")\n        outF = open(\"/tmp/filename.xml\", \"wb\")\n        outF.write(inF.read())\n        outF.close()\n        inF.close()\n        tree = et.parse(\"/tmp/filename.xml\")\n    else:\n        tree = et.parse(filename)\n    coords, connectivity = [], []\n    for mesh in tree.getroot():\n        for elem in mesh:\n            for e in elem.findall(\"vertex\"):\n                x = float(e.get(\"x\"))\n                y = float(e.get(\"y\"))\n                ez = e.get(\"z\")\n                if ez is None:\n                    coords.append([x, y])\n                else:\n                    z = float(ez)\n                    coords.append([x, y, z])\n\n            tets = elem.findall(\"tetrahedron\")\n            if not len(tets):\n                tris = elem.findall(\"triangle\")\n                for e in tris:\n                    v0 = int(e.get(\"v0\"))\n                    v1 = int(e.get(\"v1\"))\n                    v2 = int(e.get(\"v2\"))\n                    connectivity.append([v0, v1, v2])\n            else:\n                for e in tets:\n                    v0 = int(e.get(\"v0\"))\n                    v1 = int(e.get(\"v1\"))\n                    v2 = int(e.get(\"v2\"))\n                    v3 = int(e.get(\"v3\"))\n                    connectivity.append([v0, v1, v2, v3])\n\n    poly = buildPolyData(coords, connectivity)\n    return Actor(poly, c, alpha, True, bc)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a Neutral tetrahedral file format. Return an Actor object.", "response": "def loadNeutral(filename, c=\"gold\", alpha=1, wire=False, bc=None):\n    \"\"\"Reads a `Neutral` tetrahedral file format. Return an ``Actor(vtkActor)`` object.\"\"\"\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadNeutral: Cannot find\", filename, c=1)\n        return None\n\n    coords, connectivity = convertNeutral2Xml(filename)\n    poly = buildPolyData(coords, connectivity, indexOffset=0)\n    return Actor(poly, c, alpha, wire, bc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a gmesh file format. Return an Actor object.", "response": "def loadGmesh(filename, c=\"gold\", alpha=1, wire=False, bc=None):\n    \"\"\"Reads a `gmesh` file format. Return an ``Actor(vtkActor)`` object.\"\"\"\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadGmesh: Cannot find\", filename, c=1)\n        return None\n\n    f = open(filename, \"r\")\n    lines = f.readlines()\n    f.close()\n\n    nnodes = 0\n    index_nodes = 0\n    for i, line in enumerate(lines):\n        if \"$Nodes\" in line:\n            index_nodes = i + 1\n            nnodes = int(lines[index_nodes])\n            break\n    node_coords = []\n    for i in range(index_nodes + 1, index_nodes + 1 + nnodes):\n        cn = lines[i].split()\n        node_coords.append([float(cn[1]), float(cn[2]), float(cn[3])])\n\n    nelements = 0\n    index_elements = 0\n    for i, line in enumerate(lines):\n        if \"$Elements\" in line:\n            index_elements = i + 1\n            nelements = int(lines[index_elements])\n            break\n    elements = []\n    for i in range(index_elements + 1, index_elements + 1 + nelements):\n        ele = lines[i].split()\n        elements.append([int(ele[-3]), int(ele[-2]), int(ele[-1])])\n\n    poly = buildPolyData(node_coords, elements, indexOffset=1)\n\n    return Actor(poly, c, alpha, wire, bc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadPCD(filename, c=\"gold\", alpha=1):\n    if not os.path.exists(filename):\n        colors.printc(\"~noentry Error in loadPCD: Cannot find file\", filename, c=1)\n        return None\n    f = open(filename, \"r\")\n    lines = f.readlines()\n    f.close()\n    start = False\n    pts = []\n    N, expN = 0, 0\n    for text in lines:\n        if start:\n            if N >= expN:\n                break\n            l = text.split()\n            pts.append([float(l[0]), float(l[1]), float(l[2])])\n            N += 1\n        if not start and \"POINTS\" in text:\n            expN = int(text.split()[1])\n        if not start and \"DATA ascii\" in text:\n            start = True\n    if expN != N:\n        colors.printc(\"~!? Mismatch in pcd file\", expN, len(pts), c=\"red\")\n    src = vtk.vtkPointSource()\n    src.SetNumberOfPoints(len(pts))\n    src.Update()\n    poly = src.GetOutput()\n    for i, p in enumerate(pts):\n        poly.GetPoints().SetPoint(i, p)\n    if not poly:\n        colors.printc(\"~noentry Unable to load\", filename, c=\"red\")\n        return False\n    actor = Actor(poly, colors.getColor(c), alpha)\n    actor.GetProperty().SetPointSize(4)\n    return actor", "response": "Load a vtkActor from a point cloud file format. Return an actor object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads and return a vtkImageData object from file.", "response": "def loadImageData(filename, spacing=()):\n    \"\"\"Read and return a ``vtkImageData`` object from file.\"\"\"\n    if not os.path.isfile(filename):\n        colors.printc(\"~noentry File not found:\", filename, c=1)\n        return None\n\n    if \".tif\" in filename.lower():\n        reader = vtk.vtkTIFFReader()\n    elif \".slc\" in filename.lower():\n        reader = vtk.vtkSLCReader()\n        if not reader.CanReadFile(filename):\n            colors.printc(\"~prohibited Sorry bad slc file \" + filename, c=1)\n            exit(1)\n    elif \".vti\" in filename.lower():\n        reader = vtk.vtkXMLImageDataReader()\n    elif \".mhd\" in filename.lower():\n        reader = vtk.vtkMetaImageReader()\n    reader.SetFileName(filename)\n    reader.Update()\n    image = reader.GetOutput()\n    if len(spacing) == 3:\n        image.SetSpacing(spacing[0], spacing[1], spacing[2])\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load2Dimage(filename, alpha=1):\n    fl = filename.lower()\n    if \".png\" in fl:\n        picr = vtk.vtkPNGReader()\n    elif \".jpg\" in fl or \".jpeg\" in fl:\n        picr = vtk.vtkJPEGReader()\n    elif \".bmp\" in fl:\n        picr = vtk.vtkBMPReader()\n        picr.Allow8BitBMPOff()\n    else:\n        colors.printc(\"~times File must end with png, bmp or jp(e)g\", c=1)\n        exit(1)\n    picr.SetFileName(filename)\n    picr.Update()\n    vactor = ImageActor()  # vtk.vtkImageActor()\n    vactor.SetInputData(picr.GetOutput())\n    if alpha is None:\n        alpha = 1\n    vactor.SetOpacity(alpha)\n    return vactor", "response": "Read a JPEG or PNG image from file. Return an Actor object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a vtk object to a file.", "response": "def write(objct, fileoutput, binary=True):\n    \"\"\"\n    Write 3D object to file.\n\n    Possile extensions are:\n        - vtk, vti, ply, obj, stl, byu, vtp, xyz, tif, png, bmp.\n    \"\"\"\n    obj = objct\n    if isinstance(obj, Actor):\n        obj = objct.polydata(True)\n    elif isinstance(obj, vtk.vtkActor):\n        obj = objct.GetMapper().GetInput()\n\n    fr = fileoutput.lower()\n    if \".vtk\" in fr:\n        w = vtk.vtkPolyDataWriter()\n    elif \".ply\" in fr:\n        w = vtk.vtkPLYWriter()\n    elif \".stl\" in fr:\n        w = vtk.vtkSTLWriter()\n    elif \".vtp\" in fr:\n        w = vtk.vtkXMLPolyDataWriter()\n    elif \".vtm\" in fr:\n        g = vtk.vtkMultiBlockDataGroupFilter()\n        for ob in objct:\n            g.AddInputData(ob)\n        g.Update()\n        mb = g.GetOutputDataObject(0)\n        wri = vtk.vtkXMLMultiBlockDataWriter()\n        wri.SetInputData(mb)\n        wri.SetFileName(fileoutput)\n        wri.Write()\n        return mb\n    elif \".xyz\" in fr:\n        w = vtk.vtkSimplePointsWriter()\n    elif \".byu\" in fr or fr.endswith(\".g\"):\n        w = vtk.vtkBYUWriter()\n    elif \".obj\" in fr:\n        w = vtk.vtkOBJExporter()\n        w.SetFilePrefix(fileoutput.replace(\".obj\", \"\"))\n        colors.printc(\"~target Please use write(vp.window)\", c=3)\n        w.SetInputData(obj)\n        w.Update()\n        colors.printc(\"~save Saved file: \" + fileoutput, c=\"g\")\n        return objct\n    elif \".tif\" in fr:\n        w = vtk.vtkTIFFWriter()\n        w.SetFileDimensionality(len(obj.GetDimensions()))\n    elif \".vti\" in fr:\n        w = vtk.vtkXMLImageDataWriter()\n    elif \".png\" in fr:\n        w = vtk.vtkPNGWriter()\n    elif \".jpg\" in fr:\n        w = vtk.vtkJPEGWriter()\n    elif \".bmp\" in fr:\n        w = vtk.vtkBMPWriter()\n    else:\n        colors.printc(\"~noentry Unknown format\", fileoutput, \"file not saved.\", c=\"r\")\n        return objct\n\n    try:\n        if not \".tif\" in fr and not \".vti\" in fr:\n            if binary and not \".tif\" in fr and not \".vti\" in fr:\n                w.SetFileTypeToBinary()\n            else:\n                w.SetFileTypeToASCII()\n        w.SetInputData(obj)\n        w.SetFileName(fileoutput)\n        w.Write()\n        colors.printc(\"~save Saved file: \" + fileoutput, c=\"g\")\n    except Exception as e:\n        colors.printc(\"~noentry Error saving: \" + fileoutput, \"\\n\", e, c=\"r\")\n    return objct"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert Neutral file format to Dolfin XML.", "response": "def convertNeutral2Xml(infile, outfile=None):\n    \"\"\"Convert Neutral file format to Dolfin XML.\"\"\"\n\n    f = open(infile, \"r\")\n    lines = f.readlines()\n    f.close()\n\n    ncoords = int(lines[0])\n    fdolf_coords = []\n    for i in range(1, ncoords + 1):\n        x, y, z = lines[i].split()\n        fdolf_coords.append([float(x), float(y), float(z)])\n\n    ntets = int(lines[ncoords + 1])\n    idolf_tets = []\n    for i in range(ncoords + 2, ncoords + ntets + 2):\n        text = lines[i].split()\n        v0, v1, v2, v3 = text[1], text[2], text[3], text[4]\n        idolf_tets.append([int(v0) - 1, int(v1) - 1, int(v2) - 1, int(v3) - 1])\n\n    if outfile:  # write dolfin xml\n        outF = open(outfile, \"w\")\n        outF.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n        outF.write('<dolfin xmlns:dolfin=\"http://www.fenicsproject.org\">\\n')\n        outF.write('  <mesh celltype=\"tetrahedron\" dim=\"3\">\\n')\n\n        outF.write('    <vertices size=\"' + str(ncoords) + '\">\\n')\n        for i in range(ncoords):\n            x, y, z = fdolf_coords[i]\n            outF.write('      <vertex index=\"'+str(i)\n                       + '\" x=\"'+str(x)+'\" y=\"'+str(y)+'\" z=\"'+str(z)+'\"/>\\n')\n        outF.write('    </vertices>\\n')\n\n        outF.write('    <cells size=\"' + str(ntets) + '\">\\n')\n        for i in range(ntets):\n            v0, v1, v2, v3 = idolf_tets[i]\n            outF.write('      <tetrahedron index=\"'+str(i)\n                       + '\" v0=\"'+str(v0)+'\" v1=\"'+str(v1)+'\" v2=\"'+str(v2)+'\" v3=\"'+str(v3)+'\"/>\\n')\n        outF.write('    </cells>\\n')\n\n        outF.write(\"  </mesh>\\n\")\n        outF.write(\"</dolfin>\\n\")\n        outF.close()\n    return fdolf_coords, idolf_tets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buildPolyData(vertices, faces=None, indexOffset=0):\n\n    if not utils.isSequence(vertices):  # assume a dolfin.Mesh\n        faces = vertices.cells()\n        vertices = vertices.coordinates()\n\n    sourcePoints = vtk.vtkPoints()\n    sourcePolygons = vtk.vtkCellArray()\n    sourceVertices = vtk.vtkCellArray()\n    isgt2 = len(vertices[0]) > 2\n    is1 = len(vertices[0]) == 1\n    for pt in vertices:\n        if isgt2:\n            aid = sourcePoints.InsertNextPoint(pt[0], pt[1], pt[2])\n        elif is1:\n            aid = sourcePoints.InsertNextPoint(pt[0], 0, 0)\n        else:\n            aid = sourcePoints.InsertNextPoint(pt[0], pt[1], 0)\n            \n        if faces is None:\n            sourceVertices.InsertNextCell(1)\n            sourceVertices.InsertCellPoint(aid)\n        \n    if faces is not None:\n        showbar = False\n        if len(faces) > 25000:\n            showbar = True\n            pb = ProgressBar(0, len(faces), ETA=False)\n        for f in faces:\n            n = len(f)\n            if n == 4:\n                ele0 = vtk.vtkTriangle()\n                ele1 = vtk.vtkTriangle()\n                ele2 = vtk.vtkTriangle()\n                ele3 = vtk.vtkTriangle()\n                f0, f1, f2, f3 = f\n                if indexOffset:  # for speed..\n                    ele0.GetPointIds().SetId(0, f0 - indexOffset)\n                    ele0.GetPointIds().SetId(1, f1 - indexOffset)\n                    ele0.GetPointIds().SetId(2, f2 - indexOffset)\n\n                    ele1.GetPointIds().SetId(0, f0 - indexOffset)\n                    ele1.GetPointIds().SetId(1, f1 - indexOffset)\n                    ele1.GetPointIds().SetId(2, f3 - indexOffset)\n\n                    ele2.GetPointIds().SetId(0, f1 - indexOffset)\n                    ele2.GetPointIds().SetId(1, f2 - indexOffset)\n                    ele2.GetPointIds().SetId(2, f3 - indexOffset)\n\n                    ele3.GetPointIds().SetId(0, f2 - indexOffset)\n                    ele3.GetPointIds().SetId(1, f3 - indexOffset)\n                    ele3.GetPointIds().SetId(2, f0 - indexOffset)\n                else:\n                    ele0.GetPointIds().SetId(0, f0)\n                    ele0.GetPointIds().SetId(1, f1)\n                    ele0.GetPointIds().SetId(2, f2)\n\n                    ele1.GetPointIds().SetId(0, f0)\n                    ele1.GetPointIds().SetId(1, f1)\n                    ele1.GetPointIds().SetId(2, f3)\n\n                    ele2.GetPointIds().SetId(0, f1)\n                    ele2.GetPointIds().SetId(1, f2)\n                    ele2.GetPointIds().SetId(2, f3)\n\n                    ele3.GetPointIds().SetId(0, f2)\n                    ele3.GetPointIds().SetId(1, f3)\n                    ele3.GetPointIds().SetId(2, f0)\n\n                sourcePolygons.InsertNextCell(ele0)\n                sourcePolygons.InsertNextCell(ele1)\n                sourcePolygons.InsertNextCell(ele2)\n                sourcePolygons.InsertNextCell(ele3)\n\n            elif n == 3:\n                ele = vtk.vtkTriangle()\n                for i in range(3):\n                    ele.GetPointIds().SetId(i, f[i] - indexOffset)\n                sourcePolygons.InsertNextCell(ele)\n\n            else:\n                ele = vtk.vtkPolygon()\n                ele.GetPointIds().SetNumberOfIds(n)\n                for i in range(n):\n                    ele.GetPointIds().SetId(i, f[i] - indexOffset)\n                sourcePolygons.InsertNextCell(ele)\n            if showbar:\n                pb.print(\"converting mesh..\")\n\n    poly = vtk.vtkPolyData()\n    poly.SetPoints(sourcePoints)\n    if faces is None:\n        poly.SetVerts(sourceVertices)\n    else:\n        poly.SetPolys(sourcePolygons)\n        \n    return poly", "response": "Build a vtkPolyData object from a list of vertices and faces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave a screenshot of the current rendering window.", "response": "def screenshot(filename=\"screenshot.png\"):\n    \"\"\"\n    Save a screenshot of the current rendering window.\n    \"\"\"\n    if not settings.plotter_instance.window:\n        colors.printc('~bomb screenshot(): Rendering window is not present, skip.', c=1)\n        return\n    w2if = vtk.vtkWindowToImageFilter()\n    w2if.ShouldRerenderOff()\n    w2if.SetInput(settings.plotter_instance.window)\n    w2if.ReadFrontBufferOff()  # read from the back buffer\n    w2if.Update()\n    pngwriter = vtk.vtkPNGWriter()\n    pngwriter.SetFileName(filename)\n    pngwriter.SetInputConnection(w2if.GetOutputPort())\n    pngwriter.Write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds frame to current video.", "response": "def addFrame(self):\n        \"\"\"Add frame to current video.\"\"\"\n        fr = \"/tmp/vpvid/\" + str(len(self.frames)) + \".png\"\n        screenshot(fr)\n        self.frames.append(fr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pause(self, pause=0):\n        fr = self.frames[-1]\n        n = int(self.fps * pause)\n        for i in range(n):\n            fr2 = \"/tmp/vpvid/\" + str(len(self.frames)) + \".png\"\n            self.frames.append(fr2)\n            os.system(\"cp -f %s %s\" % (fr, fr2))", "response": "Insert a pause in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        if self.duration:\n            _fps = len(self.frames) / float(self.duration)\n            colors.printc(\"Recalculated video FPS to\", round(_fps, 3), c=\"yellow\")\n        else:\n            _fps = int(_fps)\n        self.name = self.name.split('.')[0]+'.mp4'\n        out = os.system(\"ffmpeg -loglevel panic -y -r \" + str(_fps)\n                        + \" -i /tmp/vpvid/%01d.png \"+self.name)\n        if out:\n            colors.printc(\"ffmpeg returning error\", c=1)\n        colors.printc(\"~save Video saved as\", self.name, c=\"green\")\n        return", "response": "Render the video and write to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the status of the button.", "response": "def status(self, s=None):\n        \"\"\"\n        Set/Get the status of the button.\n        \"\"\"\n        if s is None:\n            return self.states[self._status]\n        if isinstance(s, str):\n            s = self.states.index(s)\n        self._status = s\n        self.textproperty.SetLineOffset(self.offset)\n        self.actor.SetInput(self.spacer + self.states[s] + self.spacer)\n        s = s % len(self.colors)  # to avoid mismatch\n        self.textproperty.SetColor(colors.getColor(self.colors[s]))\n        bcc = numpy.array(colors.getColor(self.bcolors[s]))\n        self.textproperty.SetBackgroundColor(bcc)\n        if self.showframe:\n            self.textproperty.FrameOn()\n            self.textproperty.SetFrameWidth(self.framewidth)\n            self.textproperty.SetFrameColor(numpy.sqrt(bcc))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nswitch the status of the current locale to the next defined status in states list.", "response": "def switch(self):\n        \"\"\"\n        Change/cycle button status to the next defined status in states list.\n        \"\"\"\n        self._status = (self._status + 1) % len(self.states)\n        self.status(self._status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_fields(u, u_old, v_old, a_old):\n\n    # Get vectors (references)\n    u_vec, u0_vec  = u.vector(), u_old.vector()\n    v0_vec, a0_vec = v_old.vector(), a_old.vector()\n\n    # use update functions using vector arguments\n    a_vec = update_a(u_vec, u0_vec, v0_vec, a0_vec, ufl=False)\n    v_vec = update_v(a_vec, u0_vec, v0_vec, a0_vec, ufl=False)\n\n    # Update (u_old <- u)\n    v_old.vector()[:], a_old.vector()[:] = v_vec, a_vec\n    u_old.vector()[:] = u.vector()", "response": "Update fields at the end of each time step."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_project(v, V, u=None):\n    dv = TrialFunction(V)\n    v_ = TestFunction(V)\n    a_proj = inner(dv, v_)*dx\n    b_proj = inner(v, v_)*dx\n    solver = LocalSolver(a_proj, b_proj)\n    solver.factorize()\n    if u is None:\n        u = Function(V)\n        solver.solve_local_rhs(u)\n        return u\n    else:\n        solver.solve_local_rhs(u)\n        return", "response": "Element - wise projection using LocalSolver"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a simple point actor.", "response": "def Point(pos=(0, 0, 0), r=12, c=\"red\", alpha=1):\n    \"\"\"Create a simple point actor.\"\"\"\n    if len(pos) == 2:\n        pos = (pos[0], pos[1], 0)\n    actor = Points([pos], r, c, alpha)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Points(plist, r=5, c=\"gray\", alpha=1):\n\n    def _colorPoints(plist, cols, r, alpha):\n        n = len(plist)\n        if n > len(cols):\n            colors.printc(\"~times Error: mismatch in colorPoints()\", n, len(cols), c=1)\n            exit()\n        if n != len(cols):\n            colors.printc(\"~lightning Warning: mismatch in colorPoints()\", n, len(cols))\n        src = vtk.vtkPointSource()\n        src.SetNumberOfPoints(n)\n        src.Update()\n        vgf = vtk.vtkVertexGlyphFilter()\n        vgf.SetInputData(src.GetOutput())\n        vgf.Update()\n        pd = vgf.GetOutput()\n        ucols = vtk.vtkUnsignedCharArray()\n        ucols.SetNumberOfComponents(3)\n        ucols.SetName(\"pointsRGB\")\n        for i in range(len(plist)):\n            c = np.array(colors.getColor(cols[i])) * 255\n            ucols.InsertNextTuple3(c[0], c[1], c[2])\n        pd.GetPoints().SetData(numpy_to_vtk(plist, deep=True))\n        pd.GetPointData().SetScalars(ucols)\n        actor = Actor(pd, c, alpha)\n        actor.mapper.ScalarVisibilityOn()\n        actor.GetProperty().SetInterpolationToFlat()\n        actor.GetProperty().SetPointSize(r)\n        settings.collectable_actors.append(actor)\n        return actor\n\n    n = len(plist)\n    if n == 0:\n        return None\n    elif n == 3:  # assume plist is in the format [all_x, all_y, all_z]\n        if utils.isSequence(plist[0]) and len(plist[0]) > 3:\n            plist = list(zip(plist[0], plist[1], plist[2]))\n    elif n == 2:  # assume plist is in the format [all_x, all_y, 0]\n        if utils.isSequence(plist[0]) and len(plist[0]) > 3:\n            plist = list(zip(plist[0], plist[1], [0] * len(plist[0])))\n\n    if utils.isSequence(c) and len(c) > 3:\n        actor = _colorPoints(plist, c, r, alpha)\n        settings.collectable_actors.append(actor)\n        return actor\n    ################\n\n    n = len(plist)  # refresh\n    sourcePoints = vtk.vtkPoints()\n    sourceVertices = vtk.vtkCellArray()\n    is3d = len(plist[0]) > 2\n    if is3d:  # its faster\n        for pt in plist:\n            aid = sourcePoints.InsertNextPoint(pt)\n            sourceVertices.InsertNextCell(1)\n            sourceVertices.InsertCellPoint(aid)\n    else:\n        for pt in plist:\n            aid = sourcePoints.InsertNextPoint(pt[0], pt[1], 0)\n            sourceVertices.InsertNextCell(1)\n            sourceVertices.InsertCellPoint(aid)\n\n    pd = vtk.vtkPolyData()\n    pd.SetPoints(sourcePoints)\n    pd.SetVerts(sourceVertices)\n    if n == 1:  # passing just one point\n        pd.GetPoints().SetPoint(0, [0, 0, 0])\n    else:\n        pd.GetPoints().SetData(numpy_to_vtk(plist, deep=True))\n    actor = Actor(pd, c, alpha)\n    actor.GetProperty().SetPointSize(r)\n    if n == 1:\n        actor.SetPosition(plist[0])\n\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a list of points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Glyph(actor, glyphObj, orientationArray=\"\", \n          scaleByVectorSize=False, c=None, alpha=1):\n    \"\"\"\n    At each vertex of a mesh, another mesh - a `'glyph'` - is shown with\n    various orientation options and coloring.\n    \n    Color can be specfied as a colormap which maps the size of the orientation\n    vectors in `orientationArray`.\n    \n    :param orientationArray: list of vectors, ``vtkAbstractArray``\n        or the name of an already existing points array.\n    :type orientationArray: list, str, vtkAbstractArray\n    :param bool scaleByVectorSize: glyph mesh is scaled by the size of\n        the vectors.\n    \n    .. hint:: |glyphs| |glyphs.py|_\n    \n        |glyphs_arrow| |glyphs_arrow.py|_\n    \"\"\"\n    cmap = None\n    # user passing a color map to map orientationArray sizes\n    if c in list(colors._mapscales.keys()):\n        cmap = c\n        c = None\n    \n    # user is passing an array of point colors\n    if utils.isSequence(c) and len(c) > 3:\n        ucols = vtk.vtkUnsignedCharArray()\n        ucols.SetNumberOfComponents(3)\n        ucols.SetName(\"glyphRGB\")\n        for col in c:\n            cl = colors.getColor(col)\n            ucols.InsertNextTuple3(cl[0]*255, cl[1]*255, cl[2]*255)\n        actor.polydata().GetPointData().SetScalars(ucols)\n        c = None\n\n    if isinstance(glyphObj, Actor):\n        glyphObj = glyphObj.clean().polydata()\n\n    gly = vtk.vtkGlyph3D()\n    gly.SetInputData(actor.polydata())\n    gly.SetSourceData(glyphObj)\n    gly.SetColorModeToColorByScalar()\n\n    if orientationArray != \"\":\n        gly.OrientOn()\n        gly.SetScaleFactor(1)\n\n        if scaleByVectorSize:\n            gly.SetScaleModeToScaleByVector()\n        else:\n            gly.SetScaleModeToDataScalingOff()\n\n        if orientationArray == \"normals\" or orientationArray == \"Normals\":\n            gly.SetVectorModeToUseNormal()\n        elif isinstance(orientationArray, vtk.vtkAbstractArray):\n            actor.GetMapper().GetInput().GetPointData().AddArray(orientationArray)\n            actor.GetMapper().GetInput().GetPointData().SetActiveVectors(\"glyph_vectors\")\n            gly.SetInputArrayToProcess(0, 0, 0, 0, \"glyph_vectors\")\n            gly.SetVectorModeToUseVector()\n        elif utils.isSequence(orientationArray):  # passing a list\n            actor.addPointVectors(orientationArray, \"glyph_vectors\")\n            gly.SetInputArrayToProcess(0, 0, 0, 0, \"glyph_vectors\")\n        else:  # passing a name\n            gly.SetInputArrayToProcess(0, 0, 0, 0, orientationArray)\n            gly.SetVectorModeToUseVector()\n        if cmap:\n            gly.SetColorModeToColorByVector ()\n        else:\n            gly.SetColorModeToColorByScalar ()\n\n\n    gly.Update()\n    pd = gly.GetOutput()\n\n    actor = Actor(pd, c, alpha)\n    \n    if cmap:\n        lut = vtk.vtkLookupTable()\n        lut.SetNumberOfTableValues(512)\n        lut.Build()\n        for i in range(512):\n            r, g, b = colors.colorMap(i, cmap, 0, 512)\n            lut.SetTableValue(i, r, g, b, 1)\n        actor.mapper.SetLookupTable(lut)\n        actor.mapper.ScalarVisibilityOn()\n        actor.mapper.SetScalarModeToUsePointData()    \n        rng = pd.GetPointData().GetScalars().GetRange()\n        actor.mapper.SetScalarRange(rng[0], rng[1])\n\n    actor.GetProperty().SetInterpolationToFlat()\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Create a new glyph in a mesh."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a line between points p0 and p1.", "response": "def Line(p0, p1=None, lw=1, c=\"r\", alpha=1, dotted=False):\n    \"\"\"\n    Build the line segment between points `p0` and `p1`.\n    If `p0` is a list of points returns the line connecting them.\n    A 2D set of coords can also be passed as p0=[x..], p1=[y..].\n\n    :param lw: line width.\n    :param c: color name, number, or list of [R,G,B] colors.\n    :type c: int, str, list\n    :param float alpha: transparency in range [0,1].\n    :param bool dotted: draw a dotted line\n    \"\"\"\n    # detect if user is passing a 2D ist of points as p0=xlist, p1=ylist:\n    if len(p0) > 3:\n        if not utils.isSequence(p0[0]) and not utils.isSequence(p1[0]) and len(p0)==len(p1):\n            # assume input is 2D xlist, ylist\n            p0 = list(zip(p0, p1))\n            p1 = None\n    \n    # detect if user is passing a list of points:\n    if utils.isSequence(p0[0]):\n        ppoints = vtk.vtkPoints()  # Generate the polyline\n        dim = len((p0[0]))\n        if dim == 2:\n            for i, p in enumerate(p0):\n                ppoints.InsertPoint(i, p[0], p[1], 0)\n        else:\n            ppoints.SetData(numpy_to_vtk(p0, deep=True))\n        lines = vtk.vtkCellArray()  # Create the polyline.\n        lines.InsertNextCell(len(p0))\n        for i in range(len(p0)):\n            lines.InsertCellPoint(i)\n        poly = vtk.vtkPolyData()\n        poly.SetPoints(ppoints)\n        poly.SetLines(lines)\n    else:  # or just 2 points to link\n        lineSource = vtk.vtkLineSource()\n        lineSource.SetPoint1(p0)\n        lineSource.SetPoint2(p1)\n        lineSource.Update()\n        poly = lineSource.GetOutput()\n\n    actor = Actor(poly, c, alpha)\n    actor.GetProperty().SetLineWidth(lw)\n    if dotted:\n        actor.GetProperty().SetLineStipplePattern(0xF0F0)\n        actor.GetProperty().SetLineStippleRepeatFactor(1)\n    actor.base = np.array(p0)\n    actor.top = np.array(p1)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Lines(startPoints, endPoints=None, scale=1, lw=1, c=None, alpha=1, dotted=False):\n    if endPoints is not None:\n        startPoints = list(zip(startPoints, endPoints))\n\n    polylns = vtk.vtkAppendPolyData()\n    for twopts in startPoints:\n        lineSource = vtk.vtkLineSource()\n        lineSource.SetPoint1(twopts[0])\n\n        if scale != 1:\n            vers = (np.array(twopts[1]) - twopts[0]) * scale\n            pt2 = np.array(twopts[0]) + vers\n        else:\n            pt2 = twopts[1]\n\n        lineSource.SetPoint2(pt2)\n        polylns.AddInputConnection(lineSource.GetOutputPort())\n    polylns.Update()\n\n    actor = Actor(polylns.GetOutput(), c, alpha)\n    actor.GetProperty().SetLineWidth(lw)\n    if dotted:\n        actor.GetProperty().SetLineStipplePattern(0xF0F0)\n        actor.GetProperty().SetLineStippleRepeatFactor(1)\n\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a line segment between two lists of points startPoints and endPoints."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a tube along the line defined by a set of points.", "response": "def Tube(points, r=1, c=\"r\", alpha=1, res=12):\n    \"\"\"Build a tube along the line defined by a set of points.\n\n    :param r: constant radius or list of radii.\n    :type r: float, list\n    :param c: constant color or list of colors for each point.\n    :type c: float, list\n    \n    .. hint:: |ribbon| |ribbon.py|_\n    \n        |tube| |tube.py|_\n    \"\"\"\n    ppoints = vtk.vtkPoints()  # Generate the polyline\n    ppoints.SetData(numpy_to_vtk(points, deep=True))\n    lines = vtk.vtkCellArray()\n    lines.InsertNextCell(len(points))\n    for i in range(len(points)):\n        lines.InsertCellPoint(i)\n    polyln = vtk.vtkPolyData()\n    polyln.SetPoints(ppoints)\n    polyln.SetLines(lines)\n\n    tuf = vtk.vtkTubeFilter()\n    tuf.CappingOn()\n    tuf.SetNumberOfSides(res)\n    tuf.SetInputData(polyln)\n    if utils.isSequence(r):\n        arr = numpy_to_vtk(np.ascontiguousarray(r), deep=True)\n        arr.SetName(\"TubeRadius\")\n        polyln.GetPointData().AddArray(arr)\n        polyln.GetPointData().SetActiveScalars(\"TubeRadius\")\n        tuf.SetVaryRadiusToVaryRadiusByAbsoluteScalar()\n    else:\n        tuf.SetRadius(r)\n\n    usingColScals = False\n    if utils.isSequence(c) and len(c) != 3:\n        usingColScals = True\n        cc = vtk.vtkUnsignedCharArray()\n        cc.SetName(\"TubeColors\")\n        cc.SetNumberOfComponents(3)\n        cc.SetNumberOfTuples(len(c))\n        for i, ic in enumerate(c):\n            r, g, b = colors.getColor(ic)\n            cc.InsertTuple3(i, int(255 * r), int(255 * g), int(255 * b))\n        polyln.GetPointData().AddArray(cc)\n        c = None\n\n    tuf.Update()\n    polytu = tuf.GetOutput()\n\n    actor = Actor(polytu, c=c, alpha=alpha, computeNormals=0)\n    actor.phong()\n    if usingColScals:\n        actor.mapper.SetScalarModeToUsePointFieldData()\n        actor.mapper.ScalarVisibilityOn()\n        actor.mapper.SelectColorArray(\"TubeColors\")\n        actor.mapper.Modified()\n\n    actor.base = np.array(points[0])\n    actor.top = np.array(points[-1])\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Ribbon(line1, line2, c=\"m\", alpha=1, res=(200, 5)):\n    if isinstance(line1, Actor):\n        line1 = line1.coordinates()\n    if isinstance(line2, Actor):\n        line2 = line2.coordinates()\n\n    ppoints1 = vtk.vtkPoints()  # Generate the polyline1\n    ppoints1.SetData(numpy_to_vtk(line1, deep=True))\n    lines1 = vtk.vtkCellArray()\n    lines1.InsertNextCell(len(line1))\n    for i in range(len(line1)):\n        lines1.InsertCellPoint(i)\n    poly1 = vtk.vtkPolyData()\n    poly1.SetPoints(ppoints1)\n    poly1.SetLines(lines1)\n\n    ppoints2 = vtk.vtkPoints()  # Generate the polyline2\n    ppoints2.SetData(numpy_to_vtk(line2, deep=True))\n    lines2 = vtk.vtkCellArray()\n    lines2.InsertNextCell(len(line2))\n    for i in range(len(line2)):\n        lines2.InsertCellPoint(i)\n    poly2 = vtk.vtkPolyData()\n    poly2.SetPoints(ppoints2)\n    poly2.SetLines(lines2)\n\n    # build the lines\n    lines1 = vtk.vtkCellArray()\n    lines1.InsertNextCell(poly1.GetNumberOfPoints())\n    for i in range(poly1.GetNumberOfPoints()):\n        lines1.InsertCellPoint(i)\n\n    polygon1 = vtk.vtkPolyData()\n    polygon1.SetPoints(ppoints1)\n    polygon1.SetLines(lines1)\n\n    lines2 = vtk.vtkCellArray()\n    lines2.InsertNextCell(poly2.GetNumberOfPoints())\n    for i in range(poly2.GetNumberOfPoints()):\n        lines2.InsertCellPoint(i)\n\n    polygon2 = vtk.vtkPolyData()\n    polygon2.SetPoints(ppoints2)\n    polygon2.SetLines(lines2)\n\n    mergedPolyData = vtk.vtkAppendPolyData()\n    mergedPolyData.AddInputData(polygon1)\n    mergedPolyData.AddInputData(polygon2)\n    mergedPolyData.Update()\n\n    rsf = vtk.vtkRuledSurfaceFilter()\n    rsf.CloseSurfaceOff()\n    rsf.SetRuledModeToResample()\n    rsf.SetResolution(res[0], res[1])\n    rsf.SetInputData(mergedPolyData.GetOutput())\n    rsf.Update()\n    actor = Actor(rsf.GetOutput(), c=c, alpha=alpha)\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Connect two lines to generate the surface inbetween."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FlatArrow(line1, line2, c=\"m\", alpha=1, tipSize=1, tipWidth=1):\n    if isinstance(line1, Actor):\n        line1 = line1.coordinates()\n    if isinstance(line2, Actor):\n        line2 = line2.coordinates()\n        \n    sm1, sm2 = np.array(line1[-1]), np.array(line2[-1])\n\n    v = (sm1-sm2)/3*tipWidth\n    p1 = sm1+v\n    p2 = sm2-v\n    pm1 = (sm1+sm2)/2\n    pm2 = (np.array(line1[-2])+np.array(line2[-2]))/2\n    pm12 = pm1-pm2\n    tip = pm12/np.linalg.norm(pm12)*np.linalg.norm(v)*3*tipSize/tipWidth + pm1\n    \n    line1.append(p1)\n    line1.append(tip)\n    line2.append(p2)\n    line2.append(tip)\n    resm = max(100, len(line1))\n    \n    actor = Ribbon(line1, line2, alpha=alpha, c=c, res=(resm, 1)).phong()\n    settings.collectable_actors.pop()\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a 2D arrow in 3D space by joining two close lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a 3D arrow from startPoint to endPoint.", "response": "def Arrow(startPoint, endPoint, s=None, c=\"r\", alpha=1, res=12):\n    \"\"\"\n    Build a 3D arrow from `startPoint` to `endPoint` of section size `s`,\n    expressed as the fraction of the window size.\n    \n    .. note:: If ``s=None`` the arrow is scaled proportionally to its length,\n              otherwise it represents the fraction of the window size.\n              \n    |OrientedArrow|\n    \"\"\"\n    axis = np.array(endPoint) - np.array(startPoint)\n    length = np.linalg.norm(axis)\n    if length:\n        axis = axis / length\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    arr = vtk.vtkArrowSource()\n    arr.SetShaftResolution(res)\n    arr.SetTipResolution(res)\n    if s:\n        sz = 0.02\n        arr.SetTipRadius(sz)\n        arr.SetShaftRadius(sz / 1.75)\n        arr.SetTipLength(sz * 15)\n    arr.Update()\n    t = vtk.vtkTransform()\n    t.RotateZ(phi * 57.3)\n    t.RotateY(theta * 57.3)\n    t.RotateY(-90)  # put it along Z\n    if s:\n        sz = 800.0 * s\n        t.Scale(length, sz, sz)\n    else:\n        t.Scale(length, length, length)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(arr.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n\n    actor = Actor(tf.GetOutput(), c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(startPoint)\n    actor.DragableOff()\n    actor.PickableOff()\n    actor.base = np.array(startPoint)\n    actor.top = np.array(endPoint)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Arrows(startPoints, endPoints=None, s=None, scale=1, c=\"r\", alpha=1, res=12):\n    startPoints = np.array(startPoints)\n    if endPoints is None:\n        strt = startPoints[:,0]\n        endPoints = startPoints[:,1]\n        startPoints = strt\n    \n    arr = vtk.vtkArrowSource()\n    arr.SetShaftResolution(res)\n    arr.SetTipResolution(res)\n    if s:\n        sz = 0.02 * s\n        arr.SetTipRadius(sz*2)\n        arr.SetShaftRadius(sz)\n        arr.SetTipLength(sz * 10)\n    arr.Update()\n    pts = Points(startPoints)\n    orients = (endPoints - startPoints) * scale\n    arrg = Glyph(pts, arr.GetOutput(), \n                 orientationArray=orients, scaleByVectorSize=True, \n                 c=c, alpha=alpha)\n    settings.collectable_actors.append(arrg)\n    return arrg", "response": "Build arrows between two lists of points startPoints and endPoints."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Polygon(pos=(0, 0, 0), normal=(0, 0, 1), nsides=6, r=1, c=\"coral\",\n            bc=\"darkgreen\", lw=1, alpha=1, followcam=False):\n    \"\"\"\n    Build a 2D polygon of `nsides` of radius `r` oriented as `normal`.\n\n    :param followcam: if `True` the text will auto-orient itself to the active camera.\n        A ``vtkCamera`` object can also be passed.\n    :type followcam: bool, vtkCamera\n    \n    |Polygon|\n    \"\"\"\n    ps = vtk.vtkRegularPolygonSource()\n    ps.SetNumberOfSides(nsides)\n    ps.SetRadius(r)\n    ps.SetNormal(-np.array(normal))\n    ps.Update()\n\n    tf = vtk.vtkTriangleFilter()\n    tf.SetInputConnection(ps.GetOutputPort())\n    tf.Update()\n\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputConnection(tf.GetOutputPort())\n    if followcam:\n        actor = vtk.vtkFollower()\n        if isinstance(followcam, vtk.vtkCamera):\n            actor.SetCamera(followcam)\n        else:\n            actor.SetCamera(settings.plotter_instance.camera)\n    else:\n        actor = Actor()\n\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(colors.getColor(c))\n    actor.GetProperty().SetOpacity(alpha)\n    actor.GetProperty().SetLineWidth(lw)\n    actor.GetProperty().SetInterpolationToFlat()\n    if bc:  # defines a specific color for the backface\n        backProp = vtk.vtkProperty()\n        backProp.SetDiffuseColor(colors.getColor(bc))\n        backProp.SetOpacity(alpha)\n        actor.SetBackfaceProperty(backProp)\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a 2D polygon of the specified radius r oriented as normal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Rectangle(p1=(0, 0, 0), p2=(2, 1, 0), c=\"k\", bc=\"dg\", lw=1, alpha=1, texture=None):\n    p1 = np.array(p1)\n    p2 = np.array(p2)\n    pos = (p1 + p2) / 2\n    length = abs(p2[0] - p1[0])\n    height = abs(p2[1] - p1[1])\n    return Plane(pos, [0, 0, -1], length, height, c, bc, alpha, texture)", "response": "Build a rectangle in the xy plane identified by two corner points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a 2D disc of internal radius r1 and outer radius r2 oriented perpendicular to normal.", "response": "def Disc(\n    pos=(0, 0, 0),\n    normal=(0, 0, 1),\n    r1=0.5,\n    r2=1,\n    c=\"coral\",\n    bc=\"darkgreen\",\n    lw=1,\n    alpha=1,\n    res=12,\n    resphi=None,\n):\n    \"\"\"\n    Build a 2D disc of internal radius `r1` and outer radius `r2`,\n    oriented perpendicular to `normal`.\n    \n    |Disk|\n    \"\"\"\n    ps = vtk.vtkDiskSource()\n    ps.SetInnerRadius(r1)\n    ps.SetOuterRadius(r2)\n    ps.SetRadialResolution(res)\n    if not resphi:\n        resphi = 6 * res\n    ps.SetCircumferentialResolution(resphi)\n    ps.Update()\n\n    axis = np.array(normal) / np.linalg.norm(normal)\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(ps.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n\n    pd = tf.GetOutput()\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputData(pd)\n\n    actor = Actor()  # vtk.vtkActor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetColor(colors.getColor(c))\n    actor.GetProperty().SetOpacity(alpha)\n    actor.GetProperty().SetLineWidth(lw)\n    actor.GetProperty().SetInterpolationToFlat()\n    if bc:  # defines a specific color for the backface\n        backProp = vtk.vtkProperty()\n        backProp.SetDiffuseColor(colors.getColor(bc))\n        backProp.SetOpacity(alpha)\n        actor.SetBackfaceProperty(backProp)\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a sphere at position pos of radius r.", "response": "def Sphere(pos=(0, 0, 0), r=1, c=\"r\", alpha=1, res=24):\n    \"\"\"Build a sphere at position `pos` of radius `r`.\n    \n    |Sphere|\n    \"\"\"\n    ss = vtk.vtkSphereSource()\n    ss.SetRadius(r)\n    ss.SetThetaResolution(2 * res)\n    ss.SetPhiResolution(res)\n    ss.Update()\n    pd = ss.GetOutput()\n    actor = Actor(pd, c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Spheres(centers, r=1, c=\"r\", alpha=1, res=8):\n\n    cisseq = False\n    if utils.isSequence(c):\n        cisseq = True\n\n    if cisseq:\n        if len(centers) > len(c):\n            colors.printc(\"~times Mismatch in Spheres() colors\", len(centers), len(c), c=1)\n            exit()\n        if len(centers) != len(c):\n            colors.printc(\"~lightningWarning: mismatch in Spheres() colors\", len(centers), len(c))\n\n    risseq = False\n    if utils.isSequence(r):\n        risseq = True\n\n    if risseq:\n        if len(centers) > len(r):\n            colors.printc(\"times Mismatch in Spheres() radius\", len(centers), len(r), c=1)\n            exit()\n        if len(centers) != len(r):\n            colors.printc(\"~lightning Warning: mismatch in Spheres() radius\", len(centers), len(r))\n    if cisseq and risseq:\n        colors.printc(\"~noentry Limitation: c and r cannot be both sequences.\", c=1)\n        exit()\n\n    src = vtk.vtkSphereSource()\n    if not risseq:\n        src.SetRadius(r)\n    src.SetPhiResolution(res)\n    src.SetThetaResolution(2 * res)\n    src.Update()\n\n    psrc = vtk.vtkPointSource()\n    psrc.SetNumberOfPoints(len(centers))\n    psrc.Update()\n    pd = psrc.GetOutput()\n    vpts = pd.GetPoints()\n\n    glyph = vtk.vtkGlyph3D()\n    glyph.SetSourceConnection(src.GetOutputPort())\n\n    if cisseq:\n        glyph.SetColorModeToColorByScalar()\n        ucols = vtk.vtkUnsignedCharArray()\n        ucols.SetNumberOfComponents(3)\n        ucols.SetName(\"colors\")\n        for i, p in enumerate(centers):\n            vpts.SetPoint(i, p)\n            cx, cy, cz = colors.getColor(c[i])\n            ucols.InsertNextTuple3(cx * 255, cy * 255, cz * 255)\n        pd.GetPointData().SetScalars(ucols)\n        glyph.ScalingOff()\n    elif risseq:\n        glyph.SetScaleModeToScaleByScalar()\n        urads = vtk.vtkFloatArray()\n        urads.SetName(\"scales\")\n        for i, p in enumerate(centers):\n            vpts.SetPoint(i, p)\n            urads.InsertNextValue(r[i])\n        pd.GetPointData().SetScalars(urads)\n    else:\n        for i, p in enumerate(centers):\n            vpts.SetPoint(i, p)\n\n    glyph.SetInputData(pd)\n    glyph.Update()\n\n    mapper = vtk.vtkPolyDataMapper()\n    mapper.SetInputData(glyph.GetOutput())\n\n    actor = Actor()\n    actor.SetMapper(mapper)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.GetProperty().SetOpacity(alpha)\n    if cisseq:\n        mapper.ScalarVisibilityOn()\n    else:\n        mapper.ScalarVisibilityOff()\n        actor.GetProperty().SetColor(colors.getColor(c))\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a set of spheres at the given centers of radius r."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a textured actor representing the Earth.", "response": "def Earth(pos=(0, 0, 0), r=1, lw=1):\n    \"\"\"Build a textured actor representing the Earth.\n\n    .. hint:: |geodesic| |geodesic.py|_\n    \"\"\"\n    import os\n\n    tss = vtk.vtkTexturedSphereSource()\n    tss.SetRadius(r)\n    tss.SetThetaResolution(72)\n    tss.SetPhiResolution(36)\n    earthMapper = vtk.vtkPolyDataMapper()\n    earthMapper.SetInputConnection(tss.GetOutputPort())\n    earthActor = Actor(c=\"w\")\n    earthActor.SetMapper(earthMapper)\n    atext = vtk.vtkTexture()\n    pnmReader = vtk.vtkPNMReader()\n    cdir = os.path.dirname(__file__)\n    if cdir == \"\":\n        cdir = \".\"\n    fn = settings.textures_path + \"earth.ppm\"\n    pnmReader.SetFileName(fn)\n    atext.SetInputConnection(pnmReader.GetOutputPort())\n    atext.InterpolateOn()\n    earthActor.SetTexture(atext)\n    if not lw:\n        earthActor.SetPosition(pos)\n        return earthActor\n    es = vtk.vtkEarthSource()\n    es.SetRadius(r / 0.995)\n    earth2Mapper = vtk.vtkPolyDataMapper()\n    earth2Mapper.SetInputConnection(es.GetOutputPort())\n    earth2Actor = Actor()  # vtk.vtkActor()\n    earth2Actor.SetMapper(earth2Mapper)\n    earth2Mapper.ScalarVisibilityOff()\n    earth2Actor.GetProperty().SetLineWidth(lw)\n    ass = Assembly([earthActor, earth2Actor])\n    ass.SetPosition(pos)\n    settings.collectable_actors.append(ass)\n    return ass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a 3D ellipsoid centered at position pos.", "response": "def Ellipsoid(pos=(0, 0, 0), axis1=(1, 0, 0), axis2=(0, 2, 0), axis3=(0, 0, 3),\n              c=\"c\", alpha=1, res=24):\n    \"\"\"\n    Build a 3D ellipsoid centered at position `pos`.\n    \n    .. note:: `axis1` and `axis2` are only used to define sizes and one azimuth angle.\n    \n    |projectsphere|\n    \"\"\"\n    elliSource = vtk.vtkSphereSource()\n    elliSource.SetThetaResolution(res)\n    elliSource.SetPhiResolution(res)\n    elliSource.Update()\n    l1 = np.linalg.norm(axis1)\n    l2 = np.linalg.norm(axis2)\n    l3 = np.linalg.norm(axis3)\n    axis1 = np.array(axis1) / l1\n    axis2 = np.array(axis2) / l2\n    axis3 = np.array(axis3) / l3\n    angle = np.arcsin(np.dot(axis1, axis2))\n    theta = np.arccos(axis3[2])\n    phi = np.arctan2(axis3[1], axis3[0])\n\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.Scale(l1, l2, l3)\n    t.RotateX(angle * 57.3)\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(elliSource.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n\n    actor = Actor(pd, c=c, alpha=alpha)\n    actor.GetProperty().BackfaceCullingOn()\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(pos)\n    actor.base = -np.array(axis1) / 2 + pos\n    actor.top = np.array(axis1) / 2 + pos\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a grid plane.", "response": "def Grid(\n    pos=(0, 0, 0),\n    normal=(0, 0, 1),\n    sx=1,\n    sy=1,\n    c=\"g\",\n    bc=\"darkgreen\",\n    lw=1,\n    alpha=1,\n    resx=10,\n    resy=10,\n):\n    \"\"\"Return a grid plane.\n\n    .. hint:: |brownian2D| |brownian2D.py|_\n    \"\"\"\n    ps = vtk.vtkPlaneSource()\n    ps.SetResolution(resx, resy)\n    ps.Update()\n    poly0 = ps.GetOutput()\n    t0 = vtk.vtkTransform()\n    t0.Scale(sx, sy, 1)\n    tf0 = vtk.vtkTransformPolyDataFilter()\n    tf0.SetInputData(poly0)\n    tf0.SetTransform(t0)\n    tf0.Update()\n    poly = tf0.GetOutput()\n    axis = np.array(normal) / np.linalg.norm(normal)\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(poly)\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n    actor = Actor(pd, c=c, bc=bc, alpha=alpha)\n    actor.GetProperty().SetRepresentationToWireframe()\n    actor.GetProperty().SetLineWidth(lw)\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw a plane of size sx and sy oriented perpendicular to vector normal.", "response": "def Plane(pos=(0, 0, 0), normal=(0, 0, 1), sx=1, sy=None, c=\"g\", bc=\"darkgreen\",\n          alpha=1, texture=None):\n    \"\"\"\n    Draw a plane of size `sx` and `sy` oriented perpendicular to vector `normal`\n    and so that it passes through point `pos`.\n\n    |Plane| \n    \"\"\"\n    if sy is None:\n        sy = sx\n    ps = vtk.vtkPlaneSource()\n    ps.SetResolution(1, 1)\n    tri = vtk.vtkTriangleFilter()\n    tri.SetInputConnection(ps.GetOutputPort())\n    tri.Update()\n    poly = tri.GetOutput()\n    axis = np.array(normal) / np.linalg.norm(normal)\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.Scale(sx, sy, 1)\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(poly)\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n    actor = Actor(pd, c=c, bc=bc, alpha=alpha, texture=texture)\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Box(pos=(0, 0, 0), length=1, width=2, height=3, normal=(0, 0, 1),\n        c=\"g\", alpha=1, texture=None):\n    \"\"\"\n    Build a box of dimensions `x=length, y=width and z=height` oriented along vector `normal`.\n\n    .. hint:: |aspring| |aspring.py|_\n    \"\"\"\n    src = vtk.vtkCubeSource()\n    src.SetXLength(length)\n    src.SetYLength(width)\n    src.SetZLength(height)\n    src.Update()\n    poly = src.GetOutput()\n\n    axis = np.array(normal) / np.linalg.norm(normal)\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(poly)\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n\n    actor = Actor(pd, c, alpha, texture=texture)\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a non - overlapping box."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Cube(pos=(0, 0, 0), side=1, normal=(0, 0, 1), c=\"g\", alpha=1, texture=None):\n    return Box(pos, side, side, side, normal, c, alpha, texture)", "response": "Build a cube of size side oriented along vector normal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Spring(\n    startPoint=(0, 0, 0),\n    endPoint=(1, 0, 0),\n    coils=20,\n    r=0.1,\n    r2=None,\n    thickness=None,\n    c=\"grey\",\n    alpha=1,\n):\n    \"\"\"\n    Build a spring of specified nr of `coils` between `startPoint` and `endPoint`.\n\n    :param int coils: number of coils\n    :param float r: radius at start point\n    :param float r2: radius at end point\n    :param float thickness: thickness of the coil section\n\n    .. hint:: |aspring| |aspring.py|_\n    \"\"\"\n    diff = endPoint - np.array(startPoint)\n    length = np.linalg.norm(diff)\n    if not length:\n        return None\n    if not r:\n        r = length / 20\n    trange = np.linspace(0, length, num=50 * coils)\n    om = 6.283 * (coils - 0.5) / length\n    if not r2:\n        r2 = r\n    pts = []\n    for t in trange:\n        f = (length - t) / length\n        rd = r * f + r2 * (1 - f)\n        pts.append([rd * np.cos(om * t), rd * np.sin(om * t), t])\n\n    pts = [[0, 0, 0]] + pts + [[0, 0, length]]\n    diff = diff / length\n    theta = np.arccos(diff[2])\n    phi = np.arctan2(diff[1], diff[0])\n    sp = Line(pts).polydata(False)\n    t = vtk.vtkTransform()\n    t.RotateZ(phi * 57.3)\n    t.RotateY(theta * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(sp)\n    tf.SetTransform(t)\n    tf.Update()\n    tuf = vtk.vtkTubeFilter()\n    tuf.SetNumberOfSides(12)\n    tuf.CappingOn()\n    tuf.SetInputData(tf.GetOutput())\n    if not thickness:\n        thickness = r / 10\n    tuf.SetRadius(thickness)\n    tuf.Update()\n    poly = tuf.GetOutput()\n    actor = Actor(poly, c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(startPoint)\n    actor.base = np.array(startPoint)\n    actor.top = np.array(endPoint)\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a spring of specified nr of coils between startPoint and endPoint."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a cylinder with specified height and radius r centered at pos.", "response": "def Cylinder(pos=(0, 0, 0), r=1, height=1, axis=(0, 0, 1), c=\"teal\", alpha=1, res=24):\n    \"\"\"\n    Build a cylinder of specified height and radius `r`, centered at `pos`.\n\n    If `pos` is a list of 2 Points, e.g. `pos=[v1,v2]`, build a cylinder with base\n    centered at `v1` and top at `v2`.\n    \n    |Cylinder|\n    \"\"\"\n\n    if utils.isSequence(pos[0]):  # assume user is passing pos=[base, top]\n        base = np.array(pos[0])\n        top = np.array(pos[1])\n        pos = (base + top) / 2\n        height = np.linalg.norm(top - base)\n        axis = top - base\n        axis = utils.versor(axis)\n    else:\n        axis = utils.versor(axis)\n        base = pos - axis * height / 2\n        top = pos + axis * height / 2\n\n    cyl = vtk.vtkCylinderSource()\n    cyl.SetResolution(res)\n    cyl.SetRadius(r)\n    cyl.SetHeight(height)\n    cyl.Update()\n\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateX(90)  # put it along Z\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(cyl.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n\n    actor = Actor(pd, c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(pos)\n    actor.base = base + pos\n    actor.top = top + pos\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a cone centered at pos.", "response": "def Cone(pos=(0, 0, 0), r=1, height=3, axis=(0, 0, 1), c=\"dg\", alpha=1, res=48):\n    \"\"\"\n    Build a cone of specified radius `r` and `height`, centered at `pos`.\n    \n    |Cone|\n    \"\"\"\n    con = vtk.vtkConeSource()\n    con.SetResolution(res)\n    con.SetRadius(r)\n    con.SetHeight(height)\n    con.SetDirection(axis)\n    con.Update()\n    actor = Actor(con.GetOutput(), c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(pos)\n    v = utils.versor(axis) * height / 2\n    actor.base = pos - v\n    actor.top = pos + v\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Pyramid(pos=(0, 0, 0), s=1, height=1, axis=(0, 0, 1), c=\"dg\", alpha=1):\n    return Cone(pos, s, height, axis, c, alpha, 4)", "response": "Build a pyramid of specified base size s and height centered at pos."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a torus of specified outer radius r centered at pos.", "response": "def Torus(pos=(0, 0, 0), r=1, thickness=0.1, axis=(0, 0, 1), c=\"khaki\", alpha=1, res=30):\n    \"\"\"\n    Build a torus of specified outer radius `r` internal radius `thickness`, centered at `pos`.\n\n    .. hint:: |gas| |gas.py|_\n    \"\"\"\n    rs = vtk.vtkParametricTorus()\n    rs.SetRingRadius(r)\n    rs.SetCrossSectionRadius(thickness)\n    pfs = vtk.vtkParametricFunctionSource()\n    pfs.SetParametricFunction(rs)\n    pfs.SetUResolution(res * 3)\n    pfs.SetVResolution(res)\n    pfs.Update()\n\n    nax = np.linalg.norm(axis)\n    if nax:\n        axis = np.array(axis) / nax\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(pfs.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n\n    actor = Actor(pd, c, alpha)\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Paraboloid(pos=(0, 0, 0), r=1, height=1, axis=(0, 0, 1), c=\"cyan\", alpha=1, res=50):\n    quadric = vtk.vtkQuadric()\n    quadric.SetCoefficients(1, 1, 0, 0, 0, 0, 0, 0, height / 4, 0)\n    # F(x,y,z) = a0*x^2 + a1*y^2 + a2*z^2\n    #         + a3*x*y + a4*y*z + a5*x*z\n    #         + a6*x   + a7*y   + a8*z  +a9\n    sample = vtk.vtkSampleFunction()\n    sample.SetSampleDimensions(res, res, res)\n    sample.SetImplicitFunction(quadric)\n\n    contours = vtk.vtkContourFilter()\n    contours.SetInputConnection(sample.GetOutputPort())\n    contours.GenerateValues(1, 0.01, 0.01)\n    contours.Update()\n\n    axis = np.array(axis) / np.linalg.norm(axis)\n    theta = np.arccos(axis[2])\n    phi = np.arctan2(axis[1], axis[0])\n    t = vtk.vtkTransform()\n    t.PostMultiply()\n    t.RotateY(theta * 57.3)\n    t.RotateZ(phi * 57.3)\n    t.Scale(r, r, r)\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(contours.GetOutput())\n    tf.SetTransform(t)\n    tf.Update()\n    pd = tf.GetOutput()\n\n    actor = Actor(pd, c, alpha).flipNormals()\n    actor.GetProperty().SetInterpolationToPhong()\n    actor.mapper.ScalarVisibilityOff()\n    actor.SetPosition(pos)\n    settings.collectable_actors.append(actor)\n    return actor", "response": "Build a paraboloid of specified height and radius r centered at pos."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a ``vtkActor`` that shows a 3D text. :param pos: position in 3D space, if an integer is passed [1,8], a 2D text is placed in one of the 4 corners: 1, bottom-left 2, bottom-right 3, top-left 4, top-right 5, bottom-middle 6, middle-right 7, middle-left 8, top-middle :type pos: list, int :param float s: size of text. :param float depth: text thickness. :param str justify: text justification (bottom-left, bottom-right, top-left, top-right, centered). :param bg: background color of corner annotations. Only applies of `pos` is ``int``. :param str font: either `arial`, `courier` or `times`. Only applies of `pos` is ``int``. :param followcam: if `True` the text will auto-orient itself to the active camera. A ``vtkCamera`` object can also be passed. :type followcam: bool, vtkCamera .. hint:: |colorcubes| |colorcubes.py|_ |markpoint| |markpoint.py|_ |annotations.py|_ Read a text file and shows it in the rendering window.", "response": "def Text(\n    txt,\n    pos=3,\n    normal=(0, 0, 1),\n    s=1,\n    depth=0.1,\n    justify=\"bottom-left\",\n    c=None,\n    alpha=1,\n    bc=None,\n    bg=None,\n    font=\"courier\",\n    followcam=False,\n):\n    \"\"\"\n    Returns a ``vtkActor`` that shows a 3D text.\n\n    :param pos: position in 3D space,\n                if an integer is passed [1,8], \n                a 2D text is placed in one of the 4 corners:\n                    \n                    1, bottom-left\n                    2, bottom-right\n                    3, top-left\n                    4, top-right\n                    5, bottom-middle\n                    6, middle-right\n                    7, middle-left\n                    8, top-middle\n                    \n    :type pos: list, int\n    :param float s: size of text.\n    :param float depth: text thickness.\n    :param str justify: text justification\n        (bottom-left, bottom-right, top-left, top-right, centered).\n    :param bg: background color of corner annotations. Only applies of `pos` is ``int``.\n    :param str font: either `arial`, `courier` or `times`. Only applies of `pos` is ``int``.\n    :param followcam: if `True` the text will auto-orient itself to the active camera.\n        A ``vtkCamera`` object can also be passed.\n    :type followcam: bool, vtkCamera\n    \n    .. hint:: |colorcubes| |colorcubes.py|_\n    \n        |markpoint| |markpoint.py|_\n\n        |annotations.py|_ Read a text file and shows it in the rendering window.\n    \"\"\"\n    if c is None: # automatic black or white\n        if settings.plotter_instance and settings.plotter_instance.renderer:\n            c = (0.9, 0.9, 0.9)\n            if np.sum(settings.plotter_instance.renderer.GetBackground()) > 1.5:\n                c = (0.1, 0.1, 0.1)\n        else:\n            c = (0.6, 0.6, 0.6)\n\n    if isinstance(pos, int):\n        if pos > 8:\n            pos = 8\n        if pos < 1:\n            pos = 1\n      \n        ca = vtk.vtkCornerAnnotation()\n        ca.SetNonlinearFontScaleFactor(s / 3)\n        ca.SetText(pos - 1, str(txt))\n\n        ca.PickableOff()\n        cap = ca.GetTextProperty()\n        cap.SetColor(colors.getColor(c))\n        if font.lower() == \"courier\":\n            cap.SetFontFamilyToCourier()\n        elif font.lower() == \"times\":\n            cap.SetFontFamilyToTimes()\n        else:\n            cap.SetFontFamilyToArial()\n        if bg:\n            bgcol = colors.getColor(bg)\n            cap.SetBackgroundColor(bgcol)\n            cap.SetBackgroundOpacity(alpha * 0.5)\n            cap.SetFrameColor(bgcol)\n            cap.FrameOn()\n\n        setattr(ca, 'renderedAt', set())\n        settings.collectable_actors.append(ca)\n        return ca\n\n    tt = vtk.vtkVectorText()\n    tt.SetText(str(txt))\n    tt.Update()\n    ttmapper = vtk.vtkPolyDataMapper()\n    if followcam:\n        depth = 0\n        normal = (0, 0, 1)\n    if depth:\n        extrude = vtk.vtkLinearExtrusionFilter()\n        extrude.SetInputConnection(tt.GetOutputPort())\n        extrude.SetExtrusionTypeToVectorExtrusion()\n        extrude.SetVector(0, 0, 1)\n        extrude.SetScaleFactor(depth)\n        ttmapper.SetInputConnection(extrude.GetOutputPort())\n    else:\n        ttmapper.SetInputConnection(tt.GetOutputPort())\n    if followcam:\n        ttactor = vtk.vtkFollower()\n        if isinstance(followcam, vtk.vtkCamera):\n            ttactor.SetCamera(followcam)\n        else:\n            ttactor.SetCamera(settings.plotter_instance.camera)\n    else:\n        ttactor = Actor()\n    ttactor.SetMapper(ttmapper)\n    ttactor.GetProperty().SetColor(colors.getColor(c))\n    ttmapper.Update()\n\n    bb = tt.GetOutput().GetBounds()\n    dx, dy = (bb[1] - bb[0]) / 2 * s, (bb[3] - bb[2]) / 2 * s\n    cm = np.array([(bb[1] + bb[0]) / 2, (bb[3] + bb[2]) / 2, (bb[5] + bb[4]) / 2]) * s\n    shift = -cm\n    if \"cent\" in justify:\n        pass\n    elif \"bottom-left\" in justify:\n        shift += np.array([dx, dy, 0])\n    elif \"top-left\" in justify:\n        shift += np.array([dx, -dy, 0])\n    elif \"bottom-right\" in justify:\n        shift += np.array([-dx, dy, 0])\n    elif \"top-right\" in justify:\n        shift += np.array([-dx, -dy, 0])\n    else:\n        colors.printc(\"~lightning Text(): Unknown justify type\", justify, c=1)\n\n    ttactor.GetProperty().SetOpacity(alpha)\n\n    nax = np.linalg.norm(normal)\n    if nax:\n        normal = np.array(normal) / nax\n    theta = np.arccos(normal[2])\n    phi = np.arctan2(normal[1], normal[0])\n    ttactor.SetScale(s, s, s)\n    ttactor.RotateZ(phi * 57.3)\n    ttactor.RotateY(theta * 57.3)\n    ttactor.SetPosition(pos + shift)\n    if bc:  # defines a specific color for the backface\n        backProp = vtk.vtkProperty()\n        backProp.SetDiffuseColor(colors.getColor(bc))\n        backProp.SetOpacity(alpha)\n        ttactor.SetBackfaceProperty(backProp)\n    ttactor.PickableOff()\n    settings.collectable_actors.append(ttactor)\n    return ttactor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender a single LaTeX file.", "response": "def Latex(\n    formula,\n    pos=(0, 0, 0),\n    normal=(0, 0, 1),\n    c='k',\n    s=1,\n    bg=None,\n    alpha=1,\n    res=30,\n    usetex=False,\n    fromweb=False,\n):\n    \"\"\"\n    Render Latex formulas.\n    \n    :param str formula: latex text string\n    :param list pos: position coordinates in space\n    :param list normal: normal to the plane of the image\n    :param c: face color\n    :param bg: background color box\n    :param int res: dpi resolution\n    :param bool usetex: use latex compiler of matplotlib\n    :param fromweb: retrieve the latex image from online server (codecogs)\n    \n    .. hint:: |latex| |latex.py|_\n    \"\"\"\n    try:\n\n    #def _Latex(formula, pos, normal, c, s, bg, alpha, res, usetex, fromweb):\n    \n        def build_img_web(formula, tfile):\n            import requests\n            if c == 'k':\n                ct = 'Black'\n            else:\n                ct = 'White'\n            wsite = 'http://latex.codecogs.com/png.latex'\n            try:\n                r = requests.get(wsite+'?\\dpi{100} \\huge \\color{'+ct+'} ' + formula)\n                f = open(tfile, 'wb')\n                f.write(r.content)\n                f.close()\n            except requests.exceptions.ConnectionError:\n                colors.printc('Latex error. Web site unavailable?', wsite, c=1)\n                return None            \n    \n        def build_img_plt(formula, tfile):\n            import matplotlib.pyplot as plt\n    \n            plt.rc('text', usetex=usetex)\n    \n            formula1 = '$'+formula+'$'        \n            plt.axis('off')\n            col = colors.getColor(c)\n            if bg:\n                bx = dict(boxstyle=\"square\", ec=col, fc=colors.getColor(bg))\n            else:\n                bx = None\n            plt.text(0.5, 0.5, formula1,\n                     size=res,\n                     color=col,\n                     alpha=alpha,\n                     ha=\"center\",\n                     va=\"center\",\n                     bbox=bx)\n            plt.savefig('_lateximg.png', format='png',\n                        transparent=True, bbox_inches='tight', pad_inches=0)\n            plt.close()\n    \n        if fromweb:\n            build_img_web(formula, '_lateximg.png')\n        else:\n            build_img_plt(formula, '_lateximg.png')\n        \n        from vtkplotter.actors import ImageActor\n\n        picr = vtk.vtkPNGReader()\n        picr.SetFileName('_lateximg.png')\n        picr.Update()\n        vactor = ImageActor()\n        vactor.SetInputData(picr.GetOutput())\n        vactor.alpha(alpha)\n        b = vactor.GetBounds()\n        xm, ym = (b[1]+b[0])/200*s, (b[3]+b[2])/200*s\n        vactor.SetOrigin(-xm, -ym, 0)\n        nax = np.linalg.norm(normal)\n        if nax:\n            normal = np.array(normal) / nax\n        theta = np.arccos(normal[2])\n        phi = np.arctan2(normal[1], normal[0])\n        vactor.SetScale(0.25/res*s, 0.25/res*s, 0.25/res*s)\n        vactor.RotateZ(phi * 57.3)\n        vactor.RotateY(theta * 57.3)\n        vactor.SetPosition(pos)\n        try:\n            import os\n            os.unlink('_lateximg.png')\n        except FileNotFoundError:\n            pass\n        return vactor\n\n    except:\n        colors.printc('Error in Latex()\\n', formula, c=1)\n        colors.printc(' latex or dvipng not installed?', c=1)\n        colors.printc(' Try: usetex=False' , c=1)\n        colors.printc(' Try: sudo apt install dvipng' , c=1)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a color or list of colors to r g b format from many input formats.", "response": "def getColor(rgb=None, hsv=None):\n    \"\"\"\n    Convert a color or list of colors to (r,g,b) format from many input formats.\n\n    :param bool hsv: if set to `True`, rgb is assumed as (hue, saturation, value).\n\n    Example:\n         - RGB    = (255, 255, 255), corresponds to white\n         - rgb    = (1,1,1) is white\n         - hex    = #FFFF00 is yellow\n         - string = 'white'\n         - string = 'w' is white nickname\n         - string = 'dr' is darkred\n         - int    =  7 picks color nr. 7 in a predefined color list\n         - int    = -7 picks color nr. 7 in a different predefined list\n\n    .. hint:: |colorcubes| |colorcubes.py|_\n    \"\"\"\n    #recursion, return a list if input is list of colors:\n    if _isSequence(rgb) and len(rgb) > 3:\n        seqcol = []\n        for sc in rgb:\n            seqcol.append(getColor(sc))\n        return seqcol\n    \n    if str(rgb).isdigit():\n        rgb = int(rgb)\n\n    if hsv:\n        c = hsv2rgb(hsv)\n    else:\n        c = rgb\n\n    if _isSequence(c):\n        if c[0] <= 1 and c[1] <= 1 and c[2] <= 1:\n            return c  # already rgb\n        else:\n            if len(c) == 3:\n                return list(np.array(c) / 255.0)  # RGB\n            else:\n                return (c[0] / 255.0, c[1] / 255.0, c[2] / 255.0, c[3])  # RGBA\n\n    elif isinstance(c, str):  # is string\n        c = c.replace(\",\", \" \").replace(\"/\", \" \").replace(\"alpha=\", \"\")\n        c = c.replace(\"grey\", \"gray\")\n        c = c.split()[0]  # ignore possible opacity float inside string\n        if 0 < len(c) < 3:  # single/double letter color\n            if c.lower() in color_nicks.keys():\n                c = color_nicks[c.lower()]\n            else:\n                print(\"Unknow color nickname:\", c)\n                print(\"Available abbreviations:\", color_nicks)\n                return (0.5, 0.5, 0.5)\n\n        if c.lower() in colors.keys():  # matplotlib name color\n            c = colors[c.lower()]\n        else:  # vtk name color\n            namedColors = vtk.vtkNamedColors()\n            rgba = [0, 0, 0, 0]\n            namedColors.GetColor(c, rgba)\n            return list(np.array(rgba[0:3]) / 255.0)\n\n        if \"#\" in c:  # hex to rgb\n            h = c.lstrip(\"#\")\n            rgb255 = list(int(h[i : i + 2], 16) for i in (0, 2, 4))\n            rgbh = np.array(rgb255) / 255.0\n            if np.sum(rgbh) > 3:\n                print(\"Error in getColor(): Wrong hex color\", c)\n                return (0.5, 0.5, 0.5)\n            return tuple(rgbh)\n\n    elif isinstance(c, int):  # color number\n        if c >= 0:\n            return colors1[c % 10]\n        else:\n            return colors2[-c % 10]\n\n    elif isinstance(c, float):\n        if c >= 0:\n            return colors1[int(c) % 10]\n        else:\n            return colors2[int(-c) % 10]\n\n    #print(\"Unknown color:\", c)\n    return (0.5, 0.5, 0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getColorName(c):\n    c = np.array(getColor(c))  # reformat to rgb\n    mdist = 99.0\n    kclosest = \"\"\n    for key in colors.keys():\n        ci = np.array(getColor(key))\n        d = np.linalg.norm(c - ci)\n        if d < mdist:\n            mdist = d\n            kclosest = str(key)\n    return kclosest", "response": "Find the name of a color."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps a real value in range vmin vmax to a color map.", "response": "def colorMap(value, name=\"jet\", vmin=None, vmax=None):\n    \"\"\"Map a real value in range [vmin, vmax] to a (r,g,b) color scale.\n\n    :param value: scalar value to transform into a color\n    :type value: float, list\n    :param name: color map name\n    :type name: str, matplotlib.colors.LinearSegmentedColormap\n\n    :return: (r,g,b) color, or a list of (r,g,b) colors.\n\n    .. note:: Available color maps:\n\n        |colormaps|\n\n    .. tip:: Can also use directly a matplotlib color map:\n\n        :Example:\n            .. code-block:: python\n            \n                from vtkplotter import colorMap\n                import matplotlib.cm as cm\n                print( colorMap(0.2, cm.flag, 0, 1) )\n                \n                (1.0, 0.809016994374948, 0.6173258487801733)\n    \"\"\"\n    if not _mapscales:\n        print(\"-------------------------------------------------------------------\")\n        print(\"WARNING : cannot import matplotlib.cm (colormaps will show up gray).\")\n        print(\"Try e.g.: sudo apt-get install python3-matplotlib\")\n        print(\"     or : pip install matplotlib\")\n        print(\"     or : build your own map (see example in basic/mesh_custom.py).\")\n        return (0.5, 0.5, 0.5)\n\n    if isinstance(name, matplotlib.colors.LinearSegmentedColormap):\n        mp = name\n    else:\n        if name in _mapscales.keys():\n            mp = _mapscales[name]\n        else:\n            print(\"Error in colorMap():\", name, \"\\navaliable maps =\", sorted(_mapscales.keys()))\n            exit(0)\n\n    if _isSequence(value):\n        values = np.array(value)\n        if vmin is None:\n            vmin = np.min(values)\n        if vmax is None:\n            vmax = np.max(values)\n        values = np.clip(values, vmin, vmax)\n        values -= vmin\n        values /= vmax - vmin\n        cols = []\n        mp = _mapscales[name]\n        for v in values:\n            cols.append(mp(v)[0:3])\n        return np.array(cols)\n    else:\n        value -= vmin\n        value /= vmax - vmin\n        if value > 0.999:\n            value = 0.999\n        elif value < 0:\n            value = 0\n        return mp(value)[0:3]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makePalette(color1, color2, N, hsv=True):\n    if hsv:\n        color1 = rgb2hsv(color1)\n        color2 = rgb2hsv(color2)\n    c1 = np.array(getColor(color1))\n    c2 = np.array(getColor(color2))\n    cols = []\n    for f in np.linspace(0, 1, N - 1, endpoint=True):\n        c = c1 * (1 - f) + c2 * f\n        if hsv:\n            c = np.array(hsv2rgb(c))\n        cols.append(c)\n    return cols", "response": "Generate N colors starting from color1 to color2 by linear interpolation HSV in or RGB spaces."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeLUTfromCTF(sclist, N=None):\n    ctf = vtk.vtkColorTransferFunction()\n    ctf.SetColorSpaceToDiverging()\n\n    for sc in sclist:\n        scalar, col = sc\n        r, g, b = getColor(col)\n        ctf.AddRGBPoint(scalar, r, g, b)\n\n    if N is None:\n        N = len(sclist)\n\n    lut = vtk.vtkLookupTable()\n    lut.SetNumberOfTableValues(N)\n    lut.Build()\n\n    for i in range(N):\n        rgb = list(ctf.GetColor(float(i) / N)) + [1]\n        lut.SetTableValue(i, rgb)\n\n    return lut", "response": "Create a color map from a list of colors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kelvin2rgb(temperature):\n    # range check\n    if temperature < 1000:\n        temperature = 1000\n    elif temperature > 40000:\n        temperature = 40000\n\n    tmp_internal = temperature / 100.0\n\n    # red\n    if tmp_internal <= 66:\n        red = 255\n    else:\n        tmp_red = 329.698727446 * np.power(tmp_internal - 60, -0.1332047592)\n        if tmp_red < 0:\n            red = 0\n        elif tmp_red > 255:\n            red = 255\n        else:\n            red = tmp_red\n\n    # green\n    if tmp_internal <= 66:\n        tmp_green = 99.4708025861 * np.log(tmp_internal) - 161.1195681661\n        if tmp_green < 0:\n            green = 0\n        elif tmp_green > 255:\n            green = 255\n        else:\n            green = tmp_green\n    else:\n        tmp_green = 288.1221695283 * np.power(tmp_internal - 60, -0.0755148492)\n        if tmp_green < 0:\n            green = 0\n        elif tmp_green > 255:\n            green = 255\n        else:\n            green = tmp_green\n\n    # blue\n    if tmp_internal >= 66:\n        blue = 255\n    elif tmp_internal <= 19:\n        blue = 0\n    else:\n        tmp_blue = 138.5177312231 * np.log(tmp_internal - 10) - 305.0447927307\n        if tmp_blue < 0:\n            blue = 0\n        elif tmp_blue > 255:\n            blue = 255\n        else:\n            blue = tmp_blue\n\n    return [red / 255, green / 255, blue / 255]", "response": "Converts from Kelvin temperature to an RGB color."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting to terminal in colors.", "response": "def printc(*strings, **keys):\n    \"\"\"\n    Print to terminal in colors. (python3 only).\n\n    Available colors are:\n        black, red, green, yellow, blue, magenta, cyan, white.\n\n    :param c: foreground color ['']\n    :param bc: background color ['']\n    :param hidden: do not show text [False]\n    :param bold: boldface [True]\n    :param blink: blinking text [False]\n    :param underline: underline text [False]\n    :param dim: make text look dimmer [False]\n    :param invert: invert background anf forward colors [False]\n    :param box: print a box with specified text character ['']\n    :param flush: flush buffer after printing [True]\n    :param end: end character to be printed [return]\n\n    :Example:\n        .. code-block:: python\n\n            from vtkplotter.colors import printc\n            printc('anything', c='red', bold=False, end='' )\n            printc('anything', 455.5, vtkObject, c='green')\n            printc(299792.48, c=4) # 4 is blue\n            \n    .. hint::  |colorprint.py|_ \n\n        |colorprint|\n    \"\"\"\n\n    end = keys.pop(\"end\", \"\\n\")\n    flush = keys.pop(\"flush\", True)\n\n    if not _terminal_has_colors or sys.version_info[0]<3:\n        for s in strings:\n            if \"~\" in str(s):  # \"in\" for some reasons changes s\n                for k in emoji.keys():\n                    if k in s:\n                        s = s.replace(k, '')\n            print(s, end=' ')\n        print(end=end)\n        if flush:\n            sys.stdout.flush()\n        return\n\n    c = keys.pop(\"c\", None)  # hack to be compatible with python2\n    bc = keys.pop(\"bc\", None)\n    hidden = keys.pop(\"hidden\", False)\n    bold = keys.pop(\"bold\", True)\n    blink = keys.pop(\"blink\", False)\n    underline = keys.pop(\"underline\", False)\n    dim = keys.pop(\"dim\", False)\n    invert = keys.pop(\"invert\", False)\n    box = keys.pop(\"box\", \"\")\n    \n    if c is True:\n        c = 'green'\n    elif c is False:\n        c = 'red'\n\n    try:\n        txt = str()\n        ns = len(strings) - 1\n        separator = \" \"\n        offset = 0\n        for i, s in enumerate(strings):\n            if i == ns:\n                separator = \"\"\n                \n            #txt += str(s) + separator\n            if \"~\" in str(s):  # \"in\" for some reasons changes s\n                for k in emoji.keys():\n                    if k in str(s):\n                        s = s.replace(k, emoji[k])\n                        offset += 1\n            txt += str(s) + separator\n\n        if c:\n            if isinstance(c, int):\n                cf = abs(c) % 8\n            elif isinstance(c, str):\n                cf = _terminal_cols[c.lower()]\n            else:\n                print(\"Error in printc(): unknown color c=\", c)\n                exit()\n        if bc:\n            if isinstance(bc, int):\n                cb = abs(bc) % 8\n            elif isinstance(bc, str):\n                cb = _terminal_cols[bc.lower()]\n            else:\n                print(\"Error in printc(): unknown color c=\", c)\n                exit()\n\n        special, cseq = \"\", \"\"\n        if hidden:\n            special += \"\\x1b[8m\"\n            box = \"\"\n        else:\n            if c:\n                cseq += \"\\x1b[\" + str(30 + cf) + \"m\"\n            if bc:\n                cseq += \"\\x1b[\" + str(40 + cb) + \"m\"\n            if underline and not box:\n                special += \"\\x1b[4m\"\n            if dim:\n                special += \"\\x1b[2m\"\n            if invert:\n                special += \"\\x1b[7m\"\n            if bold:\n                special += \"\\x1b[1m\"\n            if blink:\n                special += \"\\x1b[5m\"\n\n        if box and not (\"\\n\" in txt):\n            if len(box) > 1:\n                box = box[0]\n            if box in [\"_\", \"=\", \"-\", \"+\", \"~\"]:\n                boxv = \"|\"\n            else:\n                boxv = box\n\n            if box == \"_\" or box == \".\":\n                outtxt = special + cseq + \" \" + box * (len(txt) + offset + 2) + \" \\n\"\n                outtxt += boxv + \" \" * (len(txt) + 2) + boxv + \"\\n\"\n            else:\n                outtxt = special + cseq + box * (len(txt) + offset + 4) + \"\\n\"\n\n            outtxt += boxv + \" \" + txt + \" \" + boxv + \"\\n\"\n\n            if box == \"_\":\n                outtxt += \"|\" + box * (len(txt) + offset + 2) + \"|\" + \"\\x1b[0m\" + end\n            else:\n                outtxt += box * (len(txt) + offset + 4) + \"\\x1b[0m\" + end\n\n            sys.stdout.write(outtxt)\n        else:\n            sys.stdout.write(special + cseq + txt + \"\\x1b[0m\" + end)\n    \n    except:\n        print(*strings, end=end)\n\n    if flush:\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef printHistogram(data, bins=10, height=10, logscale=False, minbin=0,\n                   horizontal=False, char=u\"\\U00002589\",\n                   c=None, bold=True, title='Histogram'):\n    \"\"\"\n    Ascii histogram printing.\n\n    :param int bins: number of histogram bins\n    :param int height: height of the histogram in character units\n    :param bool logscale: use logscale for frequencies\n    :param int minbin: ignore bins before minbin\n    :param bool horizontal: show histogram horizontally\n    :param str char: character to be used\n    :param str,int c: ascii color\n    :param bool char: use boldface\n    :param str title: histogram title\n    \n    :Example:\n        .. code-block:: python\n        \n            from vtkplotter import printHistogram\n            import numpy as np\n            d = np.random.normal(size=1000)\n            printHistogram(d, c='blue', logscale=True, title='my scalars')\n            printHistogram(d, c=1, horizontal=1)\n\n        |printhisto|\n    \"\"\"\n    # Adapted from http://pyinsci.blogspot.com/2009/10/ascii-histograms.html\n    \n    if not horizontal: # better aspect ratio\n        bins *= 2\n    \n    isimg = isinstance(data, vtk.vtkImageData)\n    isvol = isinstance(data, vtk.vtkVolume)\n    if isimg or isvol:\n        if isvol:\n            img = data.image\n        else:\n            img = data\n        dims = img.GetDimensions()\n        nvx = min(100000, dims[0]*dims[1]*dims[2])\n        idxs = np.random.randint(0, min(dims), size=(nvx, 3))\n        data = []\n        for ix, iy, iz in idxs:\n            d = img.GetScalarComponentAsFloat(ix, iy, iz, 0)\n            data.append(d)\n    elif isinstance(data, vtk.vtkActor):\n        arr = data.polydata().GetPointData().GetScalars()\n        if not arr:\n            arr = data.polydata().GetCellData().GetScalars()\n            if not arr:\n                return\n            \n        from vtk.util.numpy_support import vtk_to_numpy\n        data = vtk_to_numpy(arr)\n\n    h = np.histogram(data, bins=bins)\n\n    if minbin:\n        hi = h[0][minbin:-1]\n    else:\n        hi = h[0]\n    \n    if sys.version_info[0] < 3 and char == u\"\\U00002589\":\n        char = \"*\" # python2 hack\n    if char == u\"\\U00002589\" and horizontal:\n        char = u\"\\U00002586\"\n\n    entrs = \"\\t(entries=\" + str(len(data)) + \")\"\n    if logscale:\n        h0 = np.log10(hi+1)\n        maxh0 = int(max(h0)*100)/100\n        title = '(logscale) ' + title + entrs\n    else:\n        h0 = hi\n        maxh0 = max(h0)\n        title = title + entrs\n\n    def _v():\n        his = \"\"\n        if title:\n            his += title +\"\\n\"\n        bars = h0 / maxh0 * height\n        for l in reversed(range(1, height + 1)):\n            line = \"\"\n            if l == height:\n                line = \"%s \" % maxh0\n            else:\n                line = \"   |\" + \" \" * (len(str(maxh0))-3)\n            for c in bars:\n                if c >= np.ceil(l):\n                    line += char\n                else:\n                    line += \" \"\n            line += \"\\n\"\n            his += line\n        his += \"%.2f\" % h[1][0] + \".\" * (bins) + \"%.2f\" % h[1][-1] + \"\\n\"\n        return his\n\n    def _h():\n        his = \"\"\n        if title:\n            his += title +\"\\n\"\n        xl = [\"%.2f\" % n for n in h[1]]\n        lxl = [len(l) for l in xl]\n        bars = h0 / maxh0 * height\n        his += \" \" * int(max(bars) + 2 + max(lxl)) + \"%s\\n\" % maxh0\n        for i, c in enumerate(bars):\n            line = (xl[i] + \" \" * int(max(lxl) - lxl[i]) + \"| \" + char * int(c) + \"\\n\")\n            his += line\n        return his\n\n    if horizontal:\n        height *= 2\n        printc(_h(), c=c, bold=bold)\n    else:\n        printc(_v(), c=c, bold=bold)", "response": "Print histogram of data in ascii character units."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geometry(obj):\n    gf = vtk.vtkGeometryFilter()\n    gf.SetInputData(obj)\n    gf.Update()\n    return gf.GetOutput()", "response": "Returns a copy of the input object with a geometry filter applied."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an actor that can be used to interact with a spline.", "response": "def spline(points, smooth=0.5, degree=2, s=2, c=\"b\", alpha=1.0, nodes=False, res=20):\n    \"\"\"\n    Return an ``Actor`` for a spline so that it does not necessarly pass exactly throught all points.\n\n    :param float smooth: smoothing factor. 0 = interpolate points exactly. 1 = average point positions.\n    :param int degree: degree of the spline (1<degree<5)\n    :param bool nodes: if `True`, show also the input points.\n\n    .. hint:: |tutorial_spline| |tutorial.py|_\n    \"\"\"\n    from scipy.interpolate import splprep, splev\n\n    Nout = len(points) * res  # Number of points on the spline\n    points = np.array(points)\n\n    minx, miny, minz = np.min(points, axis=0)\n    maxx, maxy, maxz = np.max(points, axis=0)\n    maxb = max(maxx - minx, maxy - miny, maxz - minz)\n    smooth *= maxb / 2  # must be in absolute units\n\n    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n    tckp, _ = splprep([x, y, z], task=0, s=smooth, k=degree)  # find the knots\n    # evaluate spLine, including interpolated points:\n    xnew, ynew, znew = splev(np.linspace(0, 1, Nout), tckp)\n\n    ppoints = vtk.vtkPoints()  # Generate the polyline for the spline\n    profileData = vtk.vtkPolyData()\n    ppoints.SetData(numpy_to_vtk(list(zip(xnew, ynew, znew)), deep=True))\n    lines = vtk.vtkCellArray()  # Create the polyline\n    lines.InsertNextCell(Nout)\n    for i in range(Nout):\n        lines.InsertCellPoint(i)\n    profileData.SetPoints(ppoints)\n    profileData.SetLines(lines)\n    actline = Actor(profileData, c=c, alpha=alpha)\n    actline.GetProperty().SetLineWidth(s)\n    if nodes:\n        actnodes = vs.Points(points, r=5, c=c, alpha=alpha)\n        ass = Assembly([actline, actnodes])\n        return ass\n    else:\n        return actline"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xyplot(points, title=\"\", c=\"b\", corner=1, lines=False):\n    c = vc.getColor(c)  # allow different codings\n    array_x = vtk.vtkFloatArray()\n    array_y = vtk.vtkFloatArray()\n    array_x.SetNumberOfTuples(len(points))\n    array_y.SetNumberOfTuples(len(points))\n    for i, p in enumerate(points):\n        array_x.InsertValue(i, p[0])\n        array_y.InsertValue(i, p[1])\n    field = vtk.vtkFieldData()\n    field.AddArray(array_x)\n    field.AddArray(array_y)\n    data = vtk.vtkDataObject()\n    data.SetFieldData(field)\n    plot = vtk.vtkXYPlotActor()\n    plot.AddDataObjectInput(data)\n    plot.SetDataObjectXComponent(0, 0)\n    plot.SetDataObjectYComponent(0, 1)\n    plot.SetXValuesToValue()\n    plot.SetXTitle(title)\n    plot.SetYTitle(\"\")\n    plot.ExchangeAxesOff()\n    plot.PlotPointsOn()\n    if not lines:\n        plot.PlotLinesOff()\n    plot.GetProperty().SetPointSize(5)\n    plot.GetProperty().SetLineWidth(2)\n    plot.SetNumberOfXLabels(3)  # not working\n    plot.GetProperty().SetColor(0, 0, 0)\n    plot.GetProperty().SetOpacity(0.7)\n    plot.SetPlotColor(0, c[0], c[1], c[2])\n    tprop = plot.GetAxisLabelTextProperty()\n    tprop.SetColor(0, 0, 0)\n    tprop.SetOpacity(0.7)\n    tprop.SetFontFamily(0)\n    tprop.BoldOff()\n    tprop.ItalicOff()\n    tprop.ShadowOff()\n    tprop.SetFontSize(3)  # not working\n    plot.SetAxisTitleTextProperty(tprop)\n    plot.SetAxisLabelTextProperty(tprop)\n    plot.SetTitleTextProperty(tprop)\n    if corner == 1:\n        plot.GetPositionCoordinate().SetValue(0.0, 0.8, 0)\n    if corner == 2:\n        plot.GetPositionCoordinate().SetValue(0.7, 0.8, 0)\n    if corner == 3:\n        plot.GetPositionCoordinate().SetValue(0.0, 0.0, 0)\n    if corner == 4:\n        plot.GetPositionCoordinate().SetValue(0.7, 0.0, 0)\n    plot.GetPosition2Coordinate().SetValue(0.3, 0.2, 0)\n    return plot", "response": "Return a vtkXYPlotActor that is a plot of x versus y."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef histogram(values, bins=10, vrange=None, title=\"\", c=\"g\", corner=1, lines=True):\n    fs, edges = np.histogram(values, bins=bins, range=vrange)\n    pts = []\n    for i in range(len(fs)):\n        pts.append([(edges[i] + edges[i + 1]) / 2, fs[i]])\n    return xyplot(pts, title, c, corner, lines)", "response": "Build a 2D histogram from a list of values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new object that represents the function at x y.", "response": "def fxy(\n    z=\"sin(3*x)*log(x-y)/3\",\n    x=(0, 3),\n    y=(0, 3),\n    zlimits=(None, None),\n    showNan=True,\n    zlevels=10,\n    wire=False,\n    c=\"b\",\n    bc=\"aqua\",\n    alpha=1,\n    texture=\"paper\",\n    res=100,\n):\n    \"\"\"\n    Build a surface representing the function :math:`f(x,y)` specified as a string\n    or as a reference to an external function.\n\n    :param float x: x range of values.\n    :param float y: y range of values.\n    :param float zlimits: limit the z range of the independent variable.\n    :param int zlevels: will draw the specified number of z-levels contour lines.\n    :param bool showNan: show where the function does not exist as red points.\n    :param bool wire: show surface as wireframe.\n\n    .. hint:: |fxy| |fxy.py|_\n\n        Function is: :math:`f(x,y)=\\sin(3x) \\cdot \\log(x-y)/3` in range :math:`x=[0,3], y=[0,3]`.\n    \"\"\"\n    if isinstance(z, str):\n        try:\n            z = z.replace(\"math.\", \"\").replace(\"np.\", \"\")\n            namespace = locals()\n            code = \"from math import*\\ndef zfunc(x,y): return \" + z\n            exec(code, namespace)\n            z = namespace[\"zfunc\"]\n        except:\n            vc.printc(\"Syntax Error in fxy()\", c=1)\n            return None\n\n    ps = vtk.vtkPlaneSource()\n    ps.SetResolution(res, res)\n    ps.SetNormal([0, 0, 1])\n    ps.Update()\n    poly = ps.GetOutput()\n    dx = x[1] - x[0]\n    dy = y[1] - y[0]\n    todel, nans = [], []\n\n    if zlevels:\n        tf = vtk.vtkTriangleFilter()\n        tf.SetInputData(poly)\n        tf.Update()\n        poly = tf.GetOutput()\n\n    for i in range(poly.GetNumberOfPoints()):\n        px, py, _ = poly.GetPoint(i)\n        xv = (px + 0.5) * dx + x[0]\n        yv = (py + 0.5) * dy + y[0]\n        try:\n            zv = z(xv, yv)\n            poly.GetPoints().SetPoint(i, [xv, yv, zv])\n        except:\n            todel.append(i)\n            nans.append([xv, yv, 0])\n\n    if len(todel):\n        cellIds = vtk.vtkIdList()\n        poly.BuildLinks()\n\n        for i in todel:\n            poly.GetPointCells(i, cellIds)\n            for j in range(cellIds.GetNumberOfIds()):\n                poly.DeleteCell(cellIds.GetId(j))  # flag cell\n\n        poly.RemoveDeletedCells()\n        cl = vtk.vtkCleanPolyData()\n        cl.SetInputData(poly)\n        cl.Update()\n        poly = cl.GetOutput()\n\n    if not poly.GetNumberOfPoints():\n        vc.printc(\"Function is not real in the domain\", c=1)\n        return None\n\n    if zlimits[0]:\n        tmpact1 = Actor(poly)\n        a = tmpact1.cutWithPlane((0, 0, zlimits[0]), (0, 0, 1))\n        poly = a.polydata()\n    if zlimits[1]:\n        tmpact2 = Actor(poly)\n        a = tmpact2.cutWithPlane((0, 0, zlimits[1]), (0, 0, -1))\n        poly = a.polydata()\n\n    if c is None:\n        elev = vtk.vtkElevationFilter()\n        elev.SetInputData(poly)\n        elev.Update()\n        poly = elev.GetOutput()\n\n    actor = Actor(poly, c=c, bc=bc, alpha=alpha, wire=wire, texture=texture)\n    acts = [actor]\n    if zlevels:\n        elevation = vtk.vtkElevationFilter()\n        elevation.SetInputData(poly)\n        bounds = poly.GetBounds()\n        elevation.SetLowPoint(0, 0, bounds[4])\n        elevation.SetHighPoint(0, 0, bounds[5])\n        elevation.Update()\n        bcf = vtk.vtkBandedPolyDataContourFilter()\n        bcf.SetInputData(elevation.GetOutput())\n        bcf.SetScalarModeToValue()\n        bcf.GenerateContourEdgesOn()\n        bcf.GenerateValues(zlevels, elevation.GetScalarRange())\n        bcf.Update()\n        zpoly = bcf.GetContourEdgesOutput()\n        zbandsact = Actor(zpoly, c=\"k\", alpha=alpha)\n        zbandsact.GetProperty().SetLineWidth(1.5)\n        acts.append(zbandsact)\n\n    if showNan and len(todel):\n        bb = actor.GetBounds()\n        zm = (bb[4] + bb[5]) / 2\n        nans = np.array(nans) + [0, 0, zm]\n        nansact = vs.Points(nans, c=\"red\", alpha=alpha / 2)\n        acts.append(nansact)\n\n    if len(acts) > 1:\n        asse = Assembly(acts)\n        return asse\n    else:\n        return actor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef histogram2D(xvalues, yvalues, bins=12, norm=1, c=\"g\", alpha=1, fill=False):\n    xmin, xmax = np.min(xvalues), np.max(xvalues)\n    ymin, ymax = np.min(yvalues), np.max(yvalues)\n    dx, dy = xmax - xmin, ymax - ymin\n\n    if xmax - xmin < ymax - ymin:\n        n = bins\n        m = np.rint(dy / dx * n / 1.2 + 0.5).astype(int)\n    else:\n        m = bins\n        n = np.rint(dx / dy * m * 1.2 + 0.5).astype(int)\n\n    src = vtk.vtkPointSource()\n    src.SetNumberOfPoints(len(xvalues))\n    src.Update()\n    pointsPolydata = src.GetOutput()\n\n    values = list(zip(xvalues, yvalues))\n    zs = [[0.0]] * len(values)\n    values = np.append(values, zs, axis=1)\n\n    pointsPolydata.GetPoints().SetData(numpy_to_vtk(values, deep=True))\n    cloud = Actor(pointsPolydata)\n\n    c1 = vc.getColor(c)\n    c2 = np.array(c1) * 0.7\n    r = 0.47 / n * 1.2 * dx\n\n    hexs, binmax = [], 0\n    for i in range(n + 3):\n        for j in range(m + 2):\n            cyl = vtk.vtkCylinderSource()\n            cyl.SetResolution(6)\n            cyl.CappingOn()\n            cyl.SetRadius(0.5)\n            cyl.SetHeight(0.1)\n            cyl.Update()\n            t = vtk.vtkTransform()\n            if not i % 2:\n                p = (i / 1.33, j / 1.12, 0)\n                c = c1\n            else:\n                p = (i / 1.33, j / 1.12 + 0.443, 0)\n                c = c2\n            q = (p[0] / n * 1.2 * dx + xmin, p[1] / m * dy + ymin, 0)\n            ids = cloud.closestPoint(q, radius=r, returnIds=True)\n            ne = len(ids)\n            if fill:\n                t.Translate(p[0], p[1], ne / 2)\n                t.Scale(1, 1, ne * 5)\n            else:\n                t.Translate(p[0], p[1], ne)\n            t.RotateX(90)  # put it along Z\n            tf = vtk.vtkTransformPolyDataFilter()\n            tf.SetInputData(cyl.GetOutput())\n            tf.SetTransform(t)\n            tf.Update()\n            h = Actor(tf.GetOutput(), c=c, alpha=alpha)\n            h.PickableOff()\n            hexs.append(h)\n            if ne > binmax:\n                binmax = ne\n\n    asse = Assembly(hexs)\n    asse.SetScale(1 / n * 1.2 * dx, 1 / m * dy, norm / binmax * (dx + dy) / 4)\n    asse.SetPosition(xmin, ymin, 0)\n    return asse", "response": "Build a 2D hexagonal histogram from a list of x and y values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delaunay2D(plist, mode='xy', tol=None):\n    pd = vtk.vtkPolyData()\n    vpts = vtk.vtkPoints()\n    vpts.SetData(numpy_to_vtk(plist, deep=True))\n    pd.SetPoints(vpts)\n    delny = vtk.vtkDelaunay2D()\n    delny.SetInputData(pd)\n    if tol:\n        delny.SetTolerance(tol)\n    if mode=='fit':\n        delny.SetProjectionPlaneMode(vtk.VTK_BEST_FITTING_PLANE)\n    delny.Update()\n    return Actor(delny.GetOutput())", "response": "Create a 2D mesh from points in the XY plane."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating 3D Delaunay triangulation of input points.", "response": "def delaunay3D(dataset, alpha=0, tol=None, boundary=True):\n        \"\"\"Create 3D Delaunay triangulation of input points.\"\"\"\n        deln = vtk.vtkDelaunay3D()\n        deln.SetInputData(dataset)\n        deln.SetAlpha(alpha)\n        if tol:\n            deln.SetTolerance(tol)\n        deln.SetBoundingTriangulation(boundary)\n        deln.Update()\n        return deln.GetOutput()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalLines(actor, ratio=1, c=(0.6, 0.6, 0.6), alpha=0.8):\n    maskPts = vtk.vtkMaskPoints()\n    maskPts.SetOnRatio(ratio)\n    maskPts.RandomModeOff()\n    actor = actor.computeNormals()\n    src = actor.polydata()\n    maskPts.SetInputData(src)\n    arrow = vtk.vtkLineSource()\n    arrow.SetPoint1(0, 0, 0)\n    arrow.SetPoint2(0.75, 0, 0)\n    glyph = vtk.vtkGlyph3D()\n    glyph.SetSourceConnection(arrow.GetOutputPort())\n    glyph.SetInputConnection(maskPts.GetOutputPort())\n    glyph.SetVectorModeToUseNormal()\n    b = src.GetBounds()\n    sc = max([b[1] - b[0], b[3] - b[2], b[5] - b[4]]) / 20.0\n    glyph.SetScaleFactor(sc)\n    glyph.OrientOn()\n    glyph.Update()\n    glyphActor = Actor(glyph.GetOutput(), c=vc.getColor(c), alpha=alpha)\n    glyphActor.mapper.SetScalarModeToUsePointFieldData()\n    glyphActor.PickableOff()\n    prop = vtk.vtkProperty()\n    prop.DeepCopy(actor.GetProperty())\n    glyphActor.SetProperty(prop)\n    return glyphActor", "response": "Generates a vtkActor that draws the normals at vertices shown as lines."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extractLargestRegion(actor):\n    conn = vtk.vtkConnectivityFilter()\n    conn.SetExtractionModeToLargestRegion()\n    conn.ScalarConnectivityOff()\n    poly = actor.GetMapper().GetInput()\n    conn.SetInputData(poly)\n    conn.Update()\n    epoly = conn.GetOutput()\n    eact = Actor(epoly)\n    pr = vtk.vtkProperty()\n    pr.DeepCopy(actor.GetProperty())\n    eact.SetProperty(pr)\n    return eact", "response": "Keep only the largest connected part of a mesh and discard all the smaller pieces."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef alignLandmarks(source, target, rigid=False):\n    lmt = vtk.vtkLandmarkTransform()\n    ss = source.polydata().GetPoints()\n    st = target.polydata().GetPoints()\n    if source.N() != target.N():\n        vc.printc('~times Error in alignLandmarks(): Source and Target with != nr of points!',\n                  source.N(), target.N(), c=1)\n        exit()\n    lmt.SetSourceLandmarks(ss)\n    lmt.SetTargetLandmarks(st)\n    if rigid:\n        lmt.SetModeToRigidBody()\n    lmt.Update()\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetInputData(source.polydata())\n    tf.SetTransform(lmt)\n    tf.Update()\n    actor = Actor(tf.GetOutput())\n    actor.info[\"transform\"] = lmt\n    pr = vtk.vtkProperty()\n    pr.DeepCopy(source.GetProperty())\n    actor.SetProperty(pr)\n    return actor", "response": "Return a new actor that aligns source and target landmarks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alignICP(source, target, iters=100, rigid=False):\n    if isinstance(source, Actor):\n        source = source.polydata()\n    if isinstance(target, Actor):\n        target = target.polydata()\n\n    icp = vtk.vtkIterativeClosestPointTransform()\n    icp.SetSource(source)\n    icp.SetTarget(target)\n    icp.SetMaximumNumberOfIterations(iters)\n    if rigid:\n        icp.GetLandmarkTransform().SetModeToRigidBody()\n    icp.StartByMatchingCentroidsOn()\n    icp.Update()\n    icpTransformFilter = vtk.vtkTransformPolyDataFilter()\n    icpTransformFilter.SetInputData(source)\n    icpTransformFilter.SetTransform(icp)\n    icpTransformFilter.Update()\n    poly = icpTransformFilter.GetOutput()\n    actor = Actor(poly)\n\n    # actor.info['transform'] = icp.GetLandmarkTransform() # not working!\n    # do it manually...\n    sourcePoints = vtk.vtkPoints()\n    targetPoints = vtk.vtkPoints()\n    for i in range(10):\n        p1 = [0, 0, 0]\n        source.GetPoints().GetPoint(i, p1)\n        sourcePoints.InsertNextPoint(p1)\n        p2 = [0, 0, 0]\n        poly.GetPoints().GetPoint(i, p2)\n        targetPoints.InsertNextPoint(p2)\n\n    # Setup the transform\n    landmarkTransform = vtk.vtkLandmarkTransform()\n    landmarkTransform.SetSourceLandmarks(sourcePoints)\n    landmarkTransform.SetTargetLandmarks(targetPoints)\n    if rigid:\n        landmarkTransform.SetModeToRigidBody()\n    actor.info[\"transform\"] = landmarkTransform\n\n    return actor", "response": "Return a copy of source actor which is aligned to target actor through the Iterative Closest Point algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an Assembly of aligned source actors with the Procrustes algorithm.", "response": "def alignProcrustes(sources, rigid=False):\n    \"\"\"\n    Return an ``Assembly`` of aligned source actors with\n    the `Procrustes` algorithm. The output ``Assembly`` is normalized in size.\n\n    `Procrustes` algorithm takes N set of points and aligns them in a least-squares sense\n    to their mutual mean. The algorithm is iterated until convergence,\n    as the mean must be recomputed after each alignment.\n\n    :param bool rigid: if `True` scaling is disabled.\n\n    .. hint:: |align3| |align3.py|_\n    \"\"\"\n    group = vtk.vtkMultiBlockDataGroupFilter()\n    for source in sources:\n        if sources[0].N() != source.N():\n            vc.printc(\"~times Procrustes error in align():\", c=1)\n            vc.printc(\" sources have different nr of points\", c=1)\n            exit(0)\n        group.AddInputData(source.polydata())\n    procrustes = vtk.vtkProcrustesAlignmentFilter()\n    procrustes.StartFromCentroidOn()\n    procrustes.SetInputConnection(group.GetOutputPort())\n    if rigid:\n        procrustes.GetLandmarkTransform().SetModeToRigidBody()\n    procrustes.Update()\n\n    acts = []\n    for i, s in enumerate(sources):\n        poly = procrustes.GetOutput().GetBlock(i)\n        actor = Actor(poly)\n        actor.SetProperty(s.GetProperty())\n        acts.append(actor)\n    assem = Assembly(acts)\n    assem.info[\"transform\"] = procrustes.GetLandmarkTransform()\n    return assem"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fitLine(points, c=\"orange\", lw=1):\n    data = np.array(points)\n    datamean = data.mean(axis=0)\n    uu, dd, vv = np.linalg.svd(data - datamean)\n    vv = vv[0] / np.linalg.norm(vv[0])\n    # vv contains the first principal component, i.e. the direction\n    # vector of the best fit line in the least squares sense.\n    xyz_min = points.min(axis=0)\n    xyz_max = points.max(axis=0)\n    a = np.linalg.norm(xyz_min - datamean)\n    b = np.linalg.norm(xyz_max - datamean)\n    p1 = datamean - a * vv\n    p2 = datamean + b * vv\n    l = vs.Line(p1, p2, c=c, lw=lw, alpha=1)\n    l.info[\"slope\"] = vv\n    l.info[\"center\"] = datamean\n    l.info[\"variances\"] = dd\n    return l", "response": "Fits a line through points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fitPlane(points, c=\"g\", bc=\"darkgreen\"):\n    data = np.array(points)\n    datamean = data.mean(axis=0)\n    res = np.linalg.svd(data - datamean)\n    dd, vv = res[1], res[2]\n    xyz_min = points.min(axis=0)\n    xyz_max = points.max(axis=0)\n    s = np.linalg.norm(xyz_max - xyz_min)\n    n = np.cross(vv[0], vv[1])\n    pla = vs.Plane(datamean, n, s, s, c, bc)\n    pla.info[\"normal\"] = n\n    pla.info[\"center\"] = datamean\n    pla.info[\"variance\"] = dd[2]\n    return pla", "response": "Fits a plane to a set of points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fitSphere(coords):\n    coords = np.array(coords)\n    n = len(coords)\n    A = np.zeros((n, 4))\n    A[:, :-1] = coords * 2\n    A[:, 3] = 1\n    f = np.zeros((n, 1))\n    x = coords[:, 0]\n    y = coords[:, 1]\n    z = coords[:, 2]\n    f[:, 0] = x * x + y * y + z * z\n    C, residue, rank, sv = np.linalg.lstsq(A, f)  # solve AC=f\n    if rank < 4:\n        return None\n    t = (C[0] * C[0]) + (C[1] * C[1]) + (C[2] * C[2]) + C[3]\n    radius = np.sqrt(t)[0]\n    center = np.array([C[0][0], C[1][0], C[2][0]])\n    if len(residue):\n        residue = np.sqrt(residue[0]) / n\n    else:\n        residue = 0\n    s = vs.Sphere(center, radius, c=\"r\", alpha=1).wire(1)\n    s.info[\"radius\"] = radius\n    s.info[\"center\"] = center\n    s.info[\"residue\"] = residue\n    return s", "response": "Fits a sphere to a set of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pcaEllipsoid(points, pvalue=0.95, pcaAxes=False):\n    try:\n        from scipy.stats import f\n    except ImportError:\n        vc.printc(\"~times Error in Ellipsoid(): scipy not installed. Skip.\", c=1)\n        return None\n    if isinstance(points, vtk.vtkActor):\n        points = points.coordinates()\n    if len(points) == 0:\n        return None\n    P = np.array(points, ndmin=2, dtype=float)\n    cov = np.cov(P, rowvar=0)  # covariance matrix\n    U, s, R = np.linalg.svd(cov)  # singular value decomposition\n    p, n = s.size, P.shape[0]\n    fppf = f.ppf(pvalue, p, n-p)*(n-1)*p*(n+1)/n/(n-p)  # f % point function\n    ua, ub, uc = np.sqrt(s*fppf)*2  # semi-axes (largest first)\n    center = np.mean(P, axis=0)    # centroid of the hyperellipsoid\n    sphericity = (  ((ua-ub)/(ua+ub))**2\n                  + ((ua-uc)/(ua+uc))**2\n                  + ((ub-uc)/(ub+uc))**2)/3. * 4.\n    elliSource = vtk.vtkSphereSource()\n    elliSource.SetThetaResolution(48)\n    elliSource.SetPhiResolution(48)\n    matri = vtk.vtkMatrix4x4()\n    matri.DeepCopy((R[0][0] * ua, R[1][0] * ub, R[2][0] * uc, center[0],\n                    R[0][1] * ua, R[1][1] * ub, R[2][1] * uc, center[1],\n                    R[0][2] * ua, R[1][2] * ub, R[2][2] * uc, center[2], 0, 0, 0, 1))\n    vtra = vtk.vtkTransform()\n    vtra.SetMatrix(matri)\n    ftra = vtk.vtkTransformFilter()\n    ftra.SetTransform(vtra)\n    ftra.SetInputConnection(elliSource.GetOutputPort())\n    ftra.Update()\n    actor_elli = Actor(ftra.GetOutput(), \"c\", 0.5)\n    actor_elli.GetProperty().BackfaceCullingOn()\n    actor_elli.GetProperty().SetInterpolationToPhong()\n    if pcaAxes:\n        axs = []\n        for ax in ([1, 0, 0], [0, 1, 0], [0, 0, 1]):\n            l = vtk.vtkLineSource()\n            l.SetPoint1([0, 0, 0])\n            l.SetPoint2(ax)\n            l.Update()\n            t = vtk.vtkTransformFilter()\n            t.SetTransform(vtra)\n            t.SetInputData(l.GetOutput())\n            t.Update()\n            axs.append(Actor(t.GetOutput(), \"c\", 0.5).lineWidth(3))\n        finact = Assembly([actor_elli] + axs)\n    else:\n        finact = actor_elli\n    finact.info[\"sphericity\"] = sphericity\n    finact.info[\"va\"] = ua\n    finact.info[\"vb\"] = ub\n    finact.info[\"vc\"] = uc\n    return finact", "response": "Show the oriented PCA ellipsoid that contains fraction pvalue of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef smoothMLS3D(actors, neighbours=10):\n    from scipy.spatial import KDTree\n\n    coords4d = []\n    for a in actors:  # build the list of 4d coordinates\n        coords3d = a.coordinates()\n        n = len(coords3d)\n        pttimes = [[a.time()]] * n\n        coords4d += np.append(coords3d, pttimes, axis=1).tolist()\n\n    avedt = float(actors[-1].time() - actors[0].time()) / len(actors)\n    print(\"Average time separation between actors dt =\", round(avedt, 3))\n\n    coords4d = np.array(coords4d)\n    newcoords4d = []\n    kd = KDTree(coords4d, leafsize=neighbours)\n    suggest = \"\"\n\n    pb = vio.ProgressBar(0, len(coords4d))\n    for i in pb.range():\n        mypt = coords4d[i]\n\n        # dr = np.sqrt(3*dx**2+dt**2)\n        # iclosest = kd.query_ball_Point(mypt, r=dr)\n        # dists, iclosest = kd.query(mypt, k=None, distance_upper_bound=dr)\n        dists, iclosest = kd.query(mypt, k=neighbours)\n        closest = coords4d[iclosest]\n\n        nc = len(closest)\n        if nc >= neighbours and nc > 5:\n            m = np.linalg.lstsq(closest, [1.0] * nc)[0]  # needs python3\n            vers = m / np.linalg.norm(m)\n            hpcenter = np.mean(closest, axis=0)  # hyperplane center\n            dist = np.dot(mypt - hpcenter, vers)\n            projpt = mypt - dist * vers\n            newcoords4d.append(projpt)\n\n            if not i % 1000:  # work out some stats\n                v = np.std(closest, axis=0)\n                vx = round((v[0] + v[1] + v[2]) / 3, 3)\n                suggest = \"data suggest dt=\" + str(vx)\n\n        pb.print(suggest)\n    newcoords4d = np.array(newcoords4d)\n\n    ctimes = newcoords4d[:, 3]\n    ccoords3d = np.delete(newcoords4d, 3, axis=1)  # get rid of time\n    act = vs.Points(ccoords3d)\n    act.pointColors(ctimes, cmap=\"jet\")  # use a colormap to associate a color to time\n    return act", "response": "Smooth a list of actors in a 4D structure using a Moving Least Squares 3D algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsmoothing an actor or points with a Moving Least Squares variant.", "response": "def smoothMLS2D(actor, f=0.2, decimate=1, recursive=0, showNPlanes=0):\n    \"\"\"\n    Smooth actor or points with a `Moving Least Squares` variant.\n    The list ``actor.info['variances']`` contains the residue calculated for each point.\n    Input actor's polydata is modified.\n\n    :param f: smoothing factor - typical range is [0,2].\n    :param decimate: decimation factor (an integer number).\n    :param recursive: move points while algorithm proceedes.\n    :param showNPlanes: build an actor showing the fitting plane for N random points.\n\n    .. hint:: |mesh_smoothers| |mesh_smoothers.py|_\n\n        |moving_least_squares2D| |moving_least_squares2D.py|_\n\n        |recosurface| |recosurface.py|_\n    \"\"\"\n    coords = actor.coordinates()\n    ncoords = len(coords)\n    Ncp = int(ncoords * f / 100)\n    nshow = int(ncoords / decimate)\n    if showNPlanes:\n        ndiv = int(nshow / showNPlanes * decimate)\n\n    if Ncp < 5:\n        vc.printc(\"~target Please choose a fraction higher than \" + str(f), c=1)\n        Ncp = 5\n    print(\"smoothMLS: Searching #neighbours, #pt:\", Ncp, ncoords)\n\n    poly = actor.GetMapper().GetInput()\n    vpts = poly.GetPoints()\n    locator = vtk.vtkPointLocator()\n    locator.SetDataSet(poly)\n    locator.BuildLocator()\n    vtklist = vtk.vtkIdList()\n    variances, newsurf, acts = [], [], []\n    pb = vio.ProgressBar(0, ncoords)\n    for i, p in enumerate(coords):\n        pb.print(\"smoothing...\")\n        if i % decimate:\n            continue\n\n        locator.FindClosestNPoints(Ncp, p, vtklist)\n        points = []\n        for j in range(vtklist.GetNumberOfIds()):\n            trgp = [0, 0, 0]\n            vpts.GetPoint(vtklist.GetId(j), trgp)\n            points.append(trgp)\n        if len(points) < 5:\n            continue\n\n        points = np.array(points)\n        pointsmean = points.mean(axis=0)  # plane center\n        uu, dd, vv = np.linalg.svd(points - pointsmean)\n        a, b, c = np.cross(vv[0], vv[1])  # normal\n        d, e, f = pointsmean  # plane center\n        x, y, z = p\n        t = a * d - a * x + b * e - b * y + c * f - c * z  # /(a*a+b*b+c*c)\n        newp = [x + t * a, y + t * b, z + t * c]\n        variances.append(dd[2])\n        newsurf.append(newp)\n        if recursive:\n            vpts.SetPoint(i, newp)\n\n        if showNPlanes and not i % ndiv:\n            plane = fitPlane(points).alpha(0.3)  # fitting plane\n            iapts = vs.Points(points)  # blue points\n            acts += [plane, iapts]\n\n    if decimate == 1 and not recursive:\n        for i in range(ncoords):\n            vpts.SetPoint(i, newsurf[i])\n\n    actor.info[\"variances\"] = np.array(variances)\n\n    if showNPlanes:\n        apts = vs.Points(newsurf, c=\"r 0.6\", r=2)\n        ass = Assembly([apts] + acts)\n        return ass  # NB: a demo actor is returned\n\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsmooth an actor or points with a Moving Least Squares variant.", "response": "def smoothMLS1D(actor, f=0.2, showNLines=0):\n    \"\"\"\n    Smooth actor or points with a `Moving Least Squares` variant.\n    The list ``actor.info['variances']`` contain the residue calculated for each point.\n    Input actor's polydata is modified.\n\n    :param float f: smoothing factor - typical range is [0,2].\n    :param int showNLines: build an actor showing the fitting line for N random points.\n\n    .. hint:: |moving_least_squares1D| |moving_least_squares1D.py|_\n\n        |skeletonize| |skeletonize.py|_\n    \"\"\"\n    coords = actor.coordinates()\n    ncoords = len(coords)\n    Ncp = int(ncoords * f / 10)\n    nshow = int(ncoords)\n    if showNLines:\n        ndiv = int(nshow / showNLines)\n\n    if Ncp < 3:\n        vc.printc(\"~target Please choose a fraction higher than \" + str(f), c=1)\n        Ncp = 3\n\n    poly = actor.GetMapper().GetInput()\n    vpts = poly.GetPoints()\n    locator = vtk.vtkPointLocator()\n    locator.SetDataSet(poly)\n    locator.BuildLocator()\n    vtklist = vtk.vtkIdList()\n    variances, newline, acts = [], [], []\n    for i, p in enumerate(coords):\n\n        locator.FindClosestNPoints(Ncp, p, vtklist)\n        points = []\n        for j in range(vtklist.GetNumberOfIds()):\n            trgp = [0, 0, 0]\n            vpts.GetPoint(vtklist.GetId(j), trgp)\n            points.append(trgp)\n        if len(points) < 2:\n            continue\n\n        points = np.array(points)\n        pointsmean = points.mean(axis=0)  # plane center\n        uu, dd, vv = np.linalg.svd(points - pointsmean)\n        newp = np.dot(p - pointsmean, vv[0]) * vv[0] + pointsmean\n        variances.append(dd[1] + dd[2])\n        newline.append(newp)\n\n        if showNLines and not i % ndiv:\n            fline = fitLine(points, lw=4)  # fitting plane\n            iapts = vs.Points(points)  # blue points\n            acts += [fline, iapts]\n\n    for i in range(ncoords):\n        vpts.SetPoint(i, newline[i])\n\n    if showNLines:\n        apts = vs.Points(newline, c=\"r 0.6\", r=2)\n        ass = Assembly([apts] + acts)\n        return ass  # NB: a demo actor is returned\n\n    actor.info[\"variances\"] = np.array(variances)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef booleanOperation(actor1, operation, actor2, c=None, alpha=1,\n                     wire=False, bc=None, texture=None):\n    \"\"\"Volumetric union, intersection and subtraction of surfaces.\n\n    :param str operation: allowed operations: ``'plus'``, ``'intersect'``, ``'minus'``.\n\n    .. hint:: |boolean| |boolean.py|_\n    \"\"\"\n    bf = vtk.vtkBooleanOperationPolyDataFilter()\n    poly1 = actor1.computeNormals().polydata()\n    poly2 = actor2.computeNormals().polydata()\n    if operation.lower() == \"plus\" or operation.lower() == \"+\":\n        bf.SetOperationToUnion()\n    elif operation.lower() == \"intersect\":\n        bf.SetOperationToIntersection()\n    elif operation.lower() == \"minus\" or operation.lower() == \"-\":\n        bf.SetOperationToDifference()\n        bf.ReorientDifferenceCellsOn()\n    bf.SetInputData(0, poly1)\n    bf.SetInputData(1, poly2)\n    bf.Update()\n    actor = Actor(bf.GetOutput(), c, alpha, wire, bc, texture)\n    return actor", "response": "Returns a new actor with the same normal and the same normal."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nintersect two surfaces and return a line actor.", "response": "def surfaceIntersection(actor1, actor2, tol=1e-06, lw=3):\n    \"\"\"Intersect 2 surfaces and return a line actor.\n\n    .. hint:: |surfIntersect.py|_\n    \"\"\"\n    bf = vtk.vtkIntersectionPolyDataFilter()\n    poly1 = actor1.GetMapper().GetInput()\n    poly2 = actor2.GetMapper().GetInput()\n    bf.SetInputData(0, poly1)\n    bf.SetInputData(1, poly2)\n    bf.Update()\n    actor = Actor(bf.GetOutput(), \"k\", 1)\n    actor.GetProperty().SetLineWidth(lw)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a vtkImageData and probes its scalars at the specified points in space.", "response": "def probePoints(img, pts):\n    \"\"\"\n    Takes a ``vtkImageData`` and probes its scalars at the specified points in space.\n    \"\"\"\n    src = vtk.vtkProgrammableSource()\n    def readPoints():\n        output = src.GetPolyDataOutput()\n        points = vtk.vtkPoints()\n        for p in pts:\n            x, y, z = p\n            points.InsertNextPoint(x, y, z)\n        output.SetPoints(points)\n\n        cells = vtk.vtkCellArray()\n        cells.InsertNextCell(len(pts))\n        for i in range(len(pts)):\n            cells.InsertCellPoint(i)\n        output.SetVerts(cells)\n\n    src.SetExecuteMethod(readPoints)\n    src.Update()\n    probeFilter = vtk.vtkProbeFilter()\n    probeFilter.SetSourceData(img)\n    probeFilter.SetInputConnection(src.GetOutputPort())\n    probeFilter.Update()\n\n    pact = Actor(probeFilter.GetOutput(), c=None)  # ScalarVisibilityOn\n    pact.mapper.SetScalarRange(img.GetScalarRange())\n    return pact"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef probeLine(img, p1, p2, res=100):\n    line = vtk.vtkLineSource()\n    line.SetResolution(res)\n    line.SetPoint1(p1)\n    line.SetPoint2(p2)\n    probeFilter = vtk.vtkProbeFilter()\n    probeFilter.SetSourceData(img)\n    probeFilter.SetInputConnection(line.GetOutputPort())\n    probeFilter.Update()\n\n    lact = Actor(probeFilter.GetOutput(), c=None)  # ScalarVisibilityOn\n    lact.mapper.SetScalarRange(img.GetScalarRange())\n    return lact", "response": "Takes a vtkImageData and probes its scalars along a line defined by 2 points p1 and p2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef probePlane(img, origin=(0, 0, 0), normal=(1, 0, 0)):\n    plane = vtk.vtkPlane()\n    plane.SetOrigin(origin)\n    plane.SetNormal(normal)\n\n    planeCut = vtk.vtkCutter()\n    planeCut.SetInputData(img)\n    planeCut.SetCutFunction(plane)\n    planeCut.Update()\n    cutActor = Actor(planeCut.GetOutput(), c=None)  # ScalarVisibilityOn\n    cutActor.mapper.SetScalarRange(img.GetPointData().GetScalars().GetRange())\n    return cutActor", "response": "Takes a vtkImageData and probes its scalars on a plane."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef imageOperation(image1, operation, image2=None):\n    op = operation.lower()\n\n    if op in [\"median\"]:\n        mf = vtk.vtkImageMedian3D()\n        mf.SetInputData(image1)\n        mf.Update()\n        return mf.GetOutput()\n    elif op in [\"mag\"]:\n        mf = vtk.vtkImageMagnitude()\n        mf.SetInputData(image1)\n        mf.Update()\n        return mf.GetOutput()\n    elif op in [\"dot\", \"dotproduct\"]:\n        mf = vtk.vtkImageDotProduct()\n        mf.SetInput1Data(image1)\n        mf.SetInput2Data(image2)\n        mf.Update()\n        return mf.GetOutput()\n    elif op in [\"grad\", \"gradient\"]:\n        mf = vtk.vtkImageGradient()\n        mf.SetDimensionality(3)\n        mf.SetInputData(image1)\n        mf.Update()\n        return mf.GetOutput()\n    elif op in [\"div\", \"divergence\"]:\n        mf = vtk.vtkImageDivergence()\n        mf.SetInputData(image1)\n        mf.Update()\n        return mf.GetOutput()\n    elif op in [\"laplacian\"]:\n        mf = vtk.vtkImageLaplacian()\n        mf.SetDimensionality(3)\n        mf.SetInputData(image1)\n        mf.Update()\n        return mf.GetOutput()\n\n    mat = vtk.vtkImageMathematics()\n    mat.SetInput1Data(image1)\n    K = None\n    if image2:\n        if isinstance(image2, vtk.vtkImageData):\n            mat.SetInput2Data(image2)\n        else:  # assume image2 is a constant value\n            K = image2\n            mat.SetConstantK(K)\n            mat.SetConstantC(K)\n\n    if op in [\"+\", \"add\", \"plus\"]:\n        if K:\n            mat.SetOperationToAddConstant()\n        else:\n            mat.SetOperationToAdd()\n\n    elif op in [\"-\", \"subtract\", \"minus\"]:\n        if K:\n            mat.SetConstantC(-K)\n            mat.SetOperationToAddConstant()\n        else:\n            mat.SetOperationToSubtract()\n\n    elif op in [\"*\", \"multiply\", \"times\"]:\n        if K:\n            mat.SetOperationToMultiplyByK()\n        else:\n            mat.SetOperationToMultiply()\n\n    elif op in [\"/\", \"divide\"]:\n        if K:\n            mat.SetConstantK(1.0 / K)\n            mat.SetOperationToMultiplyByK()\n        else:\n            mat.SetOperationToDivide()\n\n    elif op in [\"1/x\", \"invert\"]:\n        mat.SetOperationToInvert()\n    elif op in [\"sin\"]:\n        mat.SetOperationToSin()\n    elif op in [\"cos\"]:\n        mat.SetOperationToCos()\n    elif op in [\"exp\"]:\n        mat.SetOperationToExp()\n    elif op in [\"log\"]:\n        mat.SetOperationToLog()\n    elif op in [\"abs\"]:\n        mat.SetOperationToAbsoluteValue()\n    elif op in [\"**2\", \"square\"]:\n        mat.SetOperationToSquare()\n    elif op in [\"sqrt\", \"sqr\"]:\n        mat.SetOperationToSquareRoot()\n    elif op in [\"min\"]:\n        mat.SetOperationToMin()\n    elif op in [\"max\"]:\n        mat.SetOperationToMax()\n    elif op in [\"atan\"]:\n        mat.SetOperationToATAN()\n    elif op in [\"atan2\"]:\n        mat.SetOperationToATAN2()\n    else:\n        vc.printc(\"~times Error in imageOperation: unknown operation\", operation, c=1)\n        exit()\n    mat.Update()\n    return mat.GetOutput()", "response": "Performs a set of operations with a set of image data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreconstructs a new object from a set of points.", "response": "def recoSurface(points, bins=256):\n    \"\"\"\n    Surface reconstruction from a scattered cloud of points.\n\n    :param int bins: number of voxels in x, y and z.\n\n    .. hint:: |recosurface| |recosurface.py|_\n    \"\"\"\n\n    if isinstance(points, vtk.vtkActor):\n        points = points.coordinates()\n    N = len(points)\n    if N < 50:\n        print(\"recoSurface: Use at least 50 points.\")\n        return None\n    points = np.array(points)\n\n    ptsSource = vtk.vtkPointSource()\n    ptsSource.SetNumberOfPoints(N)\n    ptsSource.Update()\n    vpts = ptsSource.GetOutput().GetPoints()\n    for i, p in enumerate(points):\n        vpts.SetPoint(i, p)\n    polyData = ptsSource.GetOutput()\n\n    distance = vtk.vtkSignedDistance()\n    f = 0.1\n    x0, x1, y0, y1, z0, z1 = polyData.GetBounds()\n    distance.SetBounds(x0-(x1-x0)*f, x1+(x1-x0)*f,\n                       y0-(y1-y0)*f, y1+(y1-y0)*f,\n                       z0-(z1-z0)*f, z1+(z1-z0)*f)\n    if polyData.GetPointData().GetNormals():\n        distance.SetInputData(polyData)\n    else:\n        normals = vtk.vtkPCANormalEstimation()\n        normals.SetInputData(polyData)\n        normals.SetSampleSize(int(N / 50))\n        normals.SetNormalOrientationToGraphTraversal()\n        distance.SetInputConnection(normals.GetOutputPort())\n        print(\"Recalculating normals for\", N, \"Points, sample size=\", int(N / 50))\n\n    b = polyData.GetBounds()\n    diagsize = np.sqrt((b[1] - b[0]) ** 2 + (b[3] - b[2]) ** 2 + (b[5] - b[4]) ** 2)\n    radius = diagsize / bins * 5\n    distance.SetRadius(radius)\n    distance.SetDimensions(bins, bins, bins)\n    distance.Update()\n\n    print(\"Calculating mesh from points with R =\", radius)\n    surface = vtk.vtkExtractSurface()\n    surface.SetRadius(radius * 0.99)\n    surface.HoleFillingOn()\n    surface.ComputeNormalsOff()\n    surface.ComputeGradientsOff()\n    surface.SetInputConnection(distance.GetOutputPort())\n    surface.Update()\n    return Actor(surface.GetOutput(), \"gold\", 1, 0, \"tomato\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cluster(points, radius):\n    if isinstance(points, vtk.vtkActor):\n        poly = points.GetMapper().GetInput()\n    else:\n        src = vtk.vtkPointSource()\n        src.SetNumberOfPoints(len(points))\n        src.Update()\n        vpts = src.GetOutput().GetPoints()\n        for i, p in enumerate(points):\n            vpts.SetPoint(i, p)\n        poly = src.GetOutput()\n\n    cluster = vtk.vtkEuclideanClusterExtraction()\n    cluster.SetInputData(poly)\n    cluster.SetExtractionModeToAllClusters()\n    cluster.SetRadius(radius)\n    cluster.ColorClustersOn()\n    cluster.Update()\n\n    idsarr = cluster.GetOutput().GetPointData().GetArray(\"ClusterId\")\n    Nc = cluster.GetNumberOfExtractedClusters()\n\n    sets = [[] for i in range(Nc)]\n    for i, p in enumerate(points):\n        sets[idsarr.GetValue(i)].append(p)\n\n    acts = []\n    for i, aset in enumerate(sets):\n        acts.append(vs.Points(aset, c=i))\n\n    actor = Assembly(acts)\n\n    actor.info[\"clusters\"] = sets\n    print(\"Nr. of extracted clusters\", Nc)\n    if Nc > 10:\n        print(\"First ten:\")\n    for i in range(Nc):\n        if i > 9:\n            print(\"...\")\n            break\n        print(\"Cluster #\" + str(i) + \",  N =\", len(sets[i]))\n    print(\"Access individual clusters through attribute: actor.cluster\")\n    return actor", "response": "Cluster a set of points in space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove outliers from a cloud of points within a specified radius.", "response": "def removeOutliers(points, radius):\n    \"\"\"\n    Remove outliers from a cloud of points within the specified `radius` search.\n\n    .. hint:: |clustering| |clustering.py|_\n    \"\"\"\n    isactor = False\n    if isinstance(points, vtk.vtkActor):\n        isactor = True\n        poly = points.GetMapper().GetInput()\n    else:\n        src = vtk.vtkPointSource()\n        src.SetNumberOfPoints(len(points))\n        src.Update()\n        vpts = src.GetOutput().GetPoints()\n        for i, p in enumerate(points):\n            vpts.SetPoint(i, p)\n        poly = src.GetOutput()\n\n    removal = vtk.vtkRadiusOutlierRemoval()\n    removal.SetInputData(poly)\n    removal.SetRadius(radius)\n    removal.SetNumberOfNeighbors(5)\n    removal.GenerateOutliersOff()\n    removal.Update()\n    rpoly = removal.GetOutput()\n    print(\"# of removed outlier points: \",\n          removal.GetNumberOfPointsRemoved(), '/', poly.GetNumberOfPoints())\n    outpts = []\n    for i in range(rpoly.GetNumberOfPoints()):\n        outpts.append(list(rpoly.GetPoint(i)))\n    outpts = np.array(outpts)\n    if not isactor:\n        return outpts\n\n    actor = vs.Points(outpts)\n    return actor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a nonlinear warp transform defined by a set of source and target landmarks.", "response": "def thinPlateSpline(actor, sourcePts, targetPts, userFunctions=(None, None)):\n    \"\"\"\n    `Thin Plate Spline` transformations describe a nonlinear warp transform defined by a set\n    of source and target landmarks. Any point on the mesh close to a source landmark will\n    be moved to a place close to the corresponding target landmark.\n    The points in between are interpolated smoothly using Bookstein's Thin Plate Spline algorithm.\n\n    Transformation object is saved in ``actor.info['transform']``.\n\n    :param userFunctions: You must supply both the function\n        and its derivative with respect to r.\n\n    .. hint:: |thinplate| |thinplate.py|_\n\n        |thinplate_grid| |thinplate_grid.py|_\n\n        |thinplate_morphing| |thinplate_morphing.py|_\n\n        |interpolateField| |interpolateField.py|_\n    \"\"\"\n    ns = len(sourcePts)\n    ptsou = vtk.vtkPoints()\n    ptsou.SetNumberOfPoints(ns)\n    for i in range(ns):\n        ptsou.SetPoint(i, sourcePts[i])\n\n    nt = len(sourcePts)\n    if ns != nt:\n        vc.printc(\"~times thinPlateSpline Error: #source != #target points\", ns, nt, c=1)\n        exit()\n\n    pttar = vtk.vtkPoints()\n    pttar.SetNumberOfPoints(nt)\n    for i in range(ns):\n        pttar.SetPoint(i, targetPts[i])\n\n    transform = vtk.vtkThinPlateSplineTransform()\n    transform.SetBasisToR()\n    if userFunctions[0]:\n        transform.SetBasisFunction(userFunctions[0])\n        transform.SetBasisDerivative(userFunctions[1])\n    transform.SetSigma(1)\n    transform.SetSourceLandmarks(ptsou)\n    transform.SetTargetLandmarks(pttar)\n\n    tfa = transformFilter(actor.polydata(), transform)\n    tfa.info[\"transform\"] = transform\n    return tfa"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a vtkActor and return a new object.", "response": "def transformFilter(actor, transformation):\n    \"\"\"\n    Transform a ``vtkActor`` and return a new object.\n    \"\"\"\n    tf = vtk.vtkTransformPolyDataFilter()\n    tf.SetTransform(transformation)\n    prop = None\n    if isinstance(actor, vtk.vtkPolyData):\n        tf.SetInputData(actor)\n    else:\n        tf.SetInputData(actor.polydata())\n        prop = vtk.vtkProperty()\n        prop.DeepCopy(actor.GetProperty())\n    tf.Update()\n\n    tfa = Actor(tf.GetOutput())\n    if prop:\n        tfa.SetProperty(prop)\n    return tfa"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef meshQuality(actor, measure=6):\n\n    mesh = actor.GetMapper().GetInput()\n\n    qf = vtk.vtkMeshQuality()\n    qf.SetInputData(mesh)\n    qf.SetTriangleQualityMeasure(measure)\n    qf.SaveCellQualityOn()\n    qf.Update()\n\n    pd = vtk.vtkPolyData()\n    pd.ShallowCopy(qf.GetOutput())\n\n    qactor = Actor(pd, c=None, alpha=1)\n    qactor.mapper.SetScalarRange(pd.GetScalarRange())\n    return qactor", "response": "Return a vtkActor that calculates the cell quality of the elements of a triangular mesh."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract and/or segments points from a point cloud based on geometric distance measures (e.g., proximity, normal alignments, etc.) and optional measures such as scalar range. The default operation is to segment the points into \"connected\" regions where the connection is determined by an appropriate distance measure. Each region is given a region id. Optionally, the filter can output the largest connected region of points; a particular region (via id specification); those regions that are seeded using a list of input point ids; or the region of points closest to a specified position. The key parameter of this filter is the radius defining a sphere around each point which defines a local neighborhood: any other points in the local neighborhood are assumed connected to the point. Note that the radius is defined in absolute terms. Other parameters are used to further qualify what it means to be a neighboring point. For example, scalar range and/or point normals can be used to further constrain the neighborhood. Also the extraction mode defines how the filter operates. By default, all regions are extracted but it is possible to extract particular regions; the region closest to a seed point; seeded regions; or the largest region found while processing. By default, all regions are extracted. On output, all points are labeled with a region number. However note that the number of input and output points may not be the same: if not extracting all regions then the output size may be less than the input size. :param float radius: radius variable specifying a local sphere used to define local point neighborhood :param int mode: - 0, Extract all regions - 1, Extract point seeded regions - 2, Extract largest region - 3, Test specified regions - 4, Extract all regions with scalar connectivity - 5, Extract point seeded regions :param list regions: a list of non-negative regions id to extract :param list vrange: scalar range to use to extract points based on scalar connectivity :param list seeds: a list of non-negative point seed ids :param list angle: points are connected if the angle between their normals is within this angle threshold (expressed in degrees).", "response": "def connectedPoints(actor, radius, mode=0, regions=(), vrange=(0,1), seeds=(), angle=0):\n    \"\"\"\n    Extracts and/or segments points from a point cloud based on geometric distance measures \n    (e.g., proximity, normal alignments, etc.) and optional measures such as scalar range. \n    The default operation is to segment the points into \"connected\" regions where the connection\n    is determined by an appropriate distance measure. Each region is given a region id. \n    \n    Optionally, the filter can output the largest connected region of points; a particular region\n    (via id specification); those regions that are seeded using a list of input point ids;\n    or the region of points closest to a specified position.\n\n    The key parameter of this filter is the radius defining a sphere around each point which defines\n    a local neighborhood: any other points in the local neighborhood are assumed connected to the point.\n    Note that the radius is defined in absolute terms.\n\n    Other parameters are used to further qualify what it means to be a neighboring point.\n    For example, scalar range and/or point normals can be used to further constrain the neighborhood.\n    Also the extraction mode defines how the filter operates.\n    By default, all regions are extracted but it is possible to extract particular regions;\n    the region closest to a seed point; seeded regions; or the largest region found while processing.\n    By default, all regions are extracted.\n\n    On output, all points are labeled with a region number.\n    However note that the number of input and output points may not be the same:\n    if not extracting all regions then the output size may be less than the input size.\n    \n    :param float radius: radius variable specifying a local sphere used to define local point neighborhood\n    :param int mode: \n    \n        - 0,  Extract all regions\n        - 1,  Extract point seeded regions\n        - 2,  Extract largest region\n        - 3,  Test specified regions\n        - 4,  Extract all regions with scalar connectivity\n        - 5,  Extract point seeded regions\n    \n    :param list regions: a list of non-negative regions id to extract\n    :param list vrange: scalar range to use to extract points based on scalar connectivity\n    :param list seeds: a list of non-negative point seed ids\n    :param list angle: points are connected if the angle between their normals is \n        within this angle threshold (expressed in degrees).\n    \"\"\"\n    # https://vtk.org/doc/nightly/html/classvtkConnectedPointsFilter.html\n    cpf = vtk.vtkConnectedPointsFilter()\n    cpf.SetInputData(actor.polydata())\n    cpf.SetRadius(radius)\n    if   mode == 0: # Extract all regions\n        pass\n        \n    elif mode == 1: # Extract point seeded regions\n        cpf.SetExtractionModeToPointSeededRegions()\n        for s in seeds:\n            cpf.AddSeed(s)\n        \n    elif mode == 2: # Test largest region\n        cpf.SetExtractionModeToLargestRegion()\n     \n    elif mode == 3: # Test specified regions\n        cpf.SetExtractionModeToSpecifiedRegions()\n        for r in regions:\n            cpf.AddSpecifiedRegion(r)\n    \n    elif mode == 4: # Extract all regions with scalar connectivity\n        cpf.SetExtractionModeToLargestRegion()\n        cpf.ScalarConnectivityOn()\n        cpf.SetScalarRange(vrange[0], vrange[1])\n    \n    elif mode == 5: # Extract point seeded regions\n        cpf.SetExtractionModeToLargestRegion()\n        cpf.ScalarConnectivityOn()\n        cpf.SetScalarRange(vrange[0], vrange[1])\n        cpf.AlignedNormalsOn()\n        cpf.SetNormalAngle(angle)\n    \n    cpf.Update()   \n\n    return Actor(cpf.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef splitByConnectivity(actor, maxdepth=100):\n    actor.addIDs()\n    pd = actor.polydata()\n    cf = vtk.vtkConnectivityFilter()\n    cf.SetInputData(pd)\n    cf.SetExtractionModeToAllRegions()\n    cf.ColorRegionsOn()\n    cf.Update()\n    cpd = cf.GetOutput()\n    a = Actor(cpd)\n    alist = []\n\n    for t in range(max(a.scalars(\"RegionId\")) - 1):\n        if t == maxdepth:\n            break\n        suba = a.clone().threshold(\"RegionId\", t - 0.1, t + 0.1)\n        area = suba.area()\n        alist.append([suba, area])\n\n    alist.sort(key=lambda x: x[1])\n    alist.reverse()\n    blist = []\n    for i, l in enumerate(alist):\n        l[0].color(i + 1)\n        l[0].mapper.ScalarVisibilityOff()\n        blist.append(l[0])\n    return blist", "response": "Split a mesh by connectivity and order the pieces by increasing area."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new actor with points generated at a specified distance.", "response": "def pointSampler(actor, distance=None):\n    \"\"\"\n    Algorithm to generate points the specified distance apart.\n    \"\"\"\n    poly = actor.polydata(True)\n\n    pointSampler = vtk.vtkPolyDataPointSampler()\n    if not distance:\n        distance = actor.diagonalSize() / 100.0\n    pointSampler.SetDistance(distance)\n    #    pointSampler.GenerateVertexPointsOff()\n    #    pointSampler.GenerateEdgePointsOff()\n    #    pointSampler.GenerateVerticesOn()\n    #    pointSampler.GenerateInteriorPointsOn()\n    pointSampler.SetInputData(poly)\n    pointSampler.Update()\n\n    uactor = Actor(pointSampler.GetOutput())\n    prop = vtk.vtkProperty()\n    prop.DeepCopy(actor.GetProperty())\n    uactor.SetProperty(prop)\n    return uactor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef geodesic(actor, start, end):\n\n    dijkstra = vtk.vtkDijkstraGraphGeodesicPath()\n\n    if vu.isSequence(start):\n        cc = actor.coordinates()\n        pa = vs.Points(cc)\n        start = pa.closestPoint(start, returnIds=True)\n        end = pa.closestPoint(end, returnIds=True)\n        dijkstra.SetInputData(pa.polydata())\n    else:\n        dijkstra.SetInputData(actor.polydata())\n\n    dijkstra.SetStartVertex(start)\n    dijkstra.SetEndVertex(end)\n    dijkstra.Update()\n\n    weights = vtk.vtkDoubleArray()\n    dijkstra.GetCumulativeWeights(weights)\n\n    length = weights.GetMaxId() + 1\n    arr = np.zeros(length)\n    for i in range(length):\n        arr[i] = weights.GetTuple(i)[0]\n\n    dactor = Actor(dijkstra.GetOutput())\n    prop = vtk.vtkProperty()\n    prop.DeepCopy(actor.GetProperty())\n    prop.SetLineWidth(3)\n    prop.SetOpacity(1)\n    dactor.SetProperty(prop)\n    dactor.info[\"CumulativeWeights\"] = arr\n    return dactor", "response": "A simple geodesic path algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convexHull(actor_or_list, alphaConstant=0):\n    if vu.isSequence(actor_or_list):\n        actor = vs.Points(actor_or_list)\n    else:\n        actor = actor_or_list\n    apoly = actor.clean().polydata()\n\n    triangleFilter = vtk.vtkTriangleFilter()\n    triangleFilter.SetInputData(apoly)\n    triangleFilter.Update()\n    poly = triangleFilter.GetOutput()\n\n    delaunay = vtk.vtkDelaunay3D()  # Create the convex hull of the pointcloud\n    if alphaConstant:\n        delaunay.SetAlpha(alphaConstant)\n    delaunay.SetInputData(poly)\n    delaunay.Update()\n\n    surfaceFilter = vtk.vtkDataSetSurfaceFilter()\n    surfaceFilter.SetInputConnection(delaunay.GetOutputPort())\n    surfaceFilter.Update()\n\n    chuact = Actor(surfaceFilter.GetOutput())\n    return chuact", "response": "Create a convex hull of a 3D mesh."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef actor2ImageData(actor, spacing=(1, 1, 1)):\n    # https://vtk.org/Wiki/VTK/Examples/Cxx/PolyData/PolyDataToImageData\n    pd = actor.polydata()\n\n    whiteImage = vtk.vtkImageData()\n    bounds = pd.GetBounds()\n\n    whiteImage.SetSpacing(spacing)\n\n    # compute dimensions\n    dim = [0, 0, 0]\n    for i in [0, 1, 2]:\n        dim[i] = int(np.ceil((bounds[i * 2 + 1] - bounds[i * 2]) / spacing[i]))\n    whiteImage.SetDimensions(dim)\n    whiteImage.SetExtent(0, dim[0] - 1, 0, dim[1] - 1, 0, dim[2] - 1)\n\n    origin = [0, 0, 0]\n    origin[0] = bounds[0] + spacing[0] / 2\n    origin[1] = bounds[2] + spacing[1] / 2\n    origin[2] = bounds[4] + spacing[2] / 2\n    whiteImage.SetOrigin(origin)\n    whiteImage.AllocateScalars(vtk.VTK_UNSIGNED_CHAR, 1)\n\n    # fill the image with foreground voxels:\n    inval = 255\n    count = whiteImage.GetNumberOfPoints()\n    for i in range(count):\n        whiteImage.GetPointData().GetScalars().SetTuple1(i, inval)\n\n    # polygonal data --> image stencil:\n    pol2stenc = vtk.vtkPolyDataToImageStencil()\n    pol2stenc.SetInputData(pd)\n    pol2stenc.SetOutputOrigin(origin)\n    pol2stenc.SetOutputSpacing(spacing)\n    pol2stenc.SetOutputWholeExtent(whiteImage.GetExtent())\n    pol2stenc.Update()\n\n    # cut the corresponding white image and set the background:\n    outval = 0\n    imgstenc = vtk.vtkImageStencil()\n    imgstenc.SetInputData(whiteImage)\n    imgstenc.SetStencilConnection(pol2stenc.GetOutputPort())\n    imgstenc.ReverseStencilOff()\n    imgstenc.SetBackgroundValue(outval)\n    imgstenc.Update()\n    return imgstenc.GetOutput()", "response": "Convert a mesh it into volume representation as vtkImageData"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signedDistance(actor, maxradius=0.5, bounds=(0, 1, 0, 1, 0, 1), dims=(10, 10, 10)):\n    dist = vtk.vtkSignedDistance()\n    dist.SetInputData(actor.polydata(True))\n    dist.SetRadius(maxradius)\n    dist.SetBounds(bounds)\n    dist.SetDimensions(dims)\n    dist.Update()\n    return Volume(dist.GetOutput())", "response": "Return a volume that is a signed distance of the actor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates zero crossing isosurface from truncated distance volume.", "response": "def extractSurface(image, radius=0.5):\n    \"\"\"\n    ``vtkExtractSurface`` filter. Input is a ``vtkImageData``.\n    Generate zero-crossing isosurface from truncated signed distance volume.\n    \"\"\"\n    fe = vtk.vtkExtractSurface()\n    fe.SetInputData(image)\n    fe.SetRadius(radius)\n    fe.Update()\n    return Actor(fe.GetOutput())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef projectSphereFilter(actor):\n    poly = actor.polydata()\n    psf = vtk.vtkProjectSphereFilter()\n    psf.SetInputData(poly)\n    psf.Update()\n    a = Actor(psf.GetOutput())\n    return a", "response": "Project a spherical - like object onto a plane."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interpolateToImageData(actor, kernel='shepard', radius=None, \n                           bounds=None, nullValue=None,\n                           dims=(20,20,20)):\n    \"\"\"\n    Generate a voxel dataset (vtkImageData) by interpolating a scalar\n    which is only known on a scattered set of points or mesh.\n    Available interpolation kernels are: shepard, gaussian, voronoi, linear.\n    \n    :param str kernel: interpolation kernel type [shepard]\n    :param float radius: radius of the local search\n    :param list bounds: bounding box of the output vtkImageData object\n    :param list dims: dimensions of the output vtkImageData object\n    :param float nullValue: value to be assigned to invalid points\n    \"\"\"\n        \n    output = actor.polydata()\n    \n    # Create a probe volume\n    probe = vtk.vtkImageData()\n    probe.SetDimensions(dims)\n    if bounds is None:\n        bounds = output.GetBounds()    \n    probe.SetOrigin(bounds[0],bounds[2],bounds[4])\n    probe.SetSpacing((bounds[1]-bounds[0])/(dims[0]-1),\n                     (bounds[3]-bounds[2])/(dims[1]-1),\n                     (bounds[5]-bounds[4])/(dims[2]-1))\n    \n    if radius is None:\n        radius = min(bounds[1]-bounds[0], bounds[3]-bounds[2], bounds[5]-bounds[4])/3\n\n    locator = vtk.vtkPointLocator()\n    locator.SetDataSet(output)\n    locator.BuildLocator()\n\n    if kernel == 'shepard':\n        kern = vtk.vtkShepardKernel()\n        kern.SetPowerParameter(2)\n        kern.SetRadius(radius)\n    elif kernel == 'gaussian':\n        kern = vtk.vtkGaussianKernel()\n        kern.SetRadius(radius)\n    elif kernel == 'voronoi':\n        kern = vtk.vtkVoronoiKernel()\n    elif kernel == 'linear':        \n        kern = vtk.vtkLinearKernel()\n        kern.SetRadius(radius)\n    else:\n        print('Error in interpolateToImageData, available kernels are:')\n        print(' [shepard, gaussian, voronoi, linear]')\n        exit()\n\n    interpolator = vtk.vtkPointInterpolator()\n    interpolator.SetInputData(probe)\n    interpolator.SetSourceData(output)\n    interpolator.SetKernel(kern)\n    interpolator.SetLocator(locator)\n    if nullValue is not None:\n        interpolator.SetNullValue(nullValue)\n    else:\n        interpolator.SetNullPointsStrategyToClosestPoint()\n    interpolator.Update()\n    return interpolator.GetOutput()", "response": "Interpolate a vtkImageData object to a set of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_func_full_args(func):\n    if six.PY2:\n        argspec = inspect.getargspec(func)\n        args = argspec.args[1:]  # ignore 'self'\n        defaults = argspec.defaults or []\n        # Split args into two lists depending on whether they have default value\n        no_default = args[:len(args) - len(defaults)]\n        with_default = args[len(args) - len(defaults):]\n        # Join the two lists and combine it with default values\n        args = [(arg,) for arg in no_default] + zip(with_default, defaults)\n        # Add possible *args and **kwargs and prepend them with '*' or '**'\n        varargs = [('*' + argspec.varargs,)] if argspec.varargs else []\n        kwargs = [('**' + argspec.keywords,)] if argspec.keywords else []\n        return args + varargs + kwargs\n\n    sig = inspect.signature(func)\n    args = []\n    for arg_name, param in sig.parameters.items():\n        name = arg_name\n        # Ignore 'self'\n        if name == 'self':\n            continue\n        if param.kind == inspect.Parameter.VAR_POSITIONAL:\n            name = '*' + name\n        elif param.kind == inspect.Parameter.VAR_KEYWORD:\n            name = '**' + name\n        if param.default != inspect.Parameter.empty:\n            args.append((name, param.default))\n        else:\n            args.append((name,))\n    return args", "response": "Returns a list of tuples that are the full arguments of the function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if function func accepts positional arguments *args.", "response": "def func_accepts_var_args(func):\n    \"\"\"\n    Return True if function 'func' accepts positional arguments *args.\n    \"\"\"\n    if six.PY2:\n        return inspect.getargspec(func)[1] is not None\n\n    return any(\n        p for p in inspect.signature(func).parameters.values()\n        if p.kind == p.VAR_POSITIONAL\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n        if self._with_discovery:\n            # Start the server to listen to new devices\n            self.upnp.server.set_spawn(2)\n            self.upnp.server.start()\n        if self._with_subscribers:\n            # Start the server to listen to events\n            self.registry.server.set_spawn(2)\n            self.registry.server.start()", "response": "Start the server necessary to receive information from the current state of the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndiscovering devices in the environment.", "response": "def discover(self, seconds=2):\n        \"\"\"\n        Discover devices in the environment.\n\n        @param seconds: Number of seconds to broadcast requests.\n        @type seconds: int\n        \"\"\"\n        log.info(\"Discovering devices\")\n        with gevent.Timeout(seconds, StopBroadcasting) as timeout:\n            try:\n                try:\n                    while True:\n                        self.upnp.broadcast()\n                        gevent.sleep(1)\n                except Exception as e:\n                    raise StopBroadcasting(e)\n            except StopBroadcasting:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_state(self, force_update=False):\n        if force_update or self._state is None:\n            return int(self.basicevent.GetBinaryState()['BinaryState'])\n        return self._state", "response": "Returns 0 if off 1 if on."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef receiver(signal, **kwargs):\n    def _decorator(func):\n        if isinstance(signal, (list, tuple)):\n            for s in signal:\n                s.connect(func, **kwargs)\n        else:\n            signal.connect(func, **kwargs)\n        return func\n    return _decorator", "response": "A decorator for connecting receivers to the specified signal or list of signals. Used by passing in signal or list of signals and keyword arguments to connect to the available objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a signal from sender to all connected receivers.", "response": "def send(self, sender, **named):\n        \"\"\"\n        Send signal from sender to all connected receivers.\n\n        If any receiver raises an error, the error propagates back through send,\n        terminating the dispatch loop. So it's possible that all receivers\n        won't be called if an error is raised.\n\n        Arguments:\n\n            sender\n                The sender of the signal. Either a specific object or None.\n\n            named\n                Named arguments which will be passed to receivers.\n\n        Returns a list of tuple pairs [(receiver, response), ... ].\n        \"\"\"\n        responses = []\n        if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n            return responses\n\n        for receiver in self._live_receivers(sender):\n            response = receiver(signal=self, sender=sender, **named)\n            responses.append((receiver, response))\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a signal from sender to all connected receivers catching errors and returning a list of tuples.", "response": "def send_robust(self, sender, **named):\n        \"\"\"\n        Send signal from sender to all connected receivers catching errors.\n\n        Arguments:\n\n            sender\n                The sender of the signal. Can be any python object (normally one\n                registered with a connect if you actually want something to\n                occur).\n\n            named\n                Named arguments which will be passed to receivers. These\n                arguments must be a subset of the argument names defined in\n                providing_args.\n\n        Return a list of tuple pairs [(receiver, response), ... ]. May raise\n        DispatcherKeyError.\n\n        If any receiver raises an error (specifically any subclass of\n        Exception), the error instance is returned as the result for that\n        receiver. The traceback is always attached to the error at\n        ``__traceback__``.\n        \"\"\"\n        responses = []\n        if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n            return responses\n\n        # Call each receiver with whatever arguments it can accept.\n        # Return a list of tuple pairs [(receiver, response), ... ].\n        for receiver in self._live_receivers(sender):\n            try:\n                response = receiver(signal=self, sender=sender, **named)\n            except Exception as err:\n                if not hasattr(err, '__traceback__'):\n                    err.__traceback__ = sys.exc_info()[2]\n                responses.append((receiver, err))\n            else:\n                responses.append((receiver, response))\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _live_receivers(self, sender):\n        receivers = None\n        if self.use_caching and not self._dead_receivers:\n            receivers = self.sender_receivers_cache.get(sender)\n            # We could end up here with NO_RECEIVERS even if we do check this case in\n            # .send() prior to calling _live_receivers() due to concurrent .send() call.\n            if receivers is NO_RECEIVERS:\n                return []\n        if receivers is None:\n            with self.lock:\n                self._clear_dead_receivers()\n                senderkey = _make_id(sender)\n                receivers = []\n                for (receiverkey, r_senderkey), receiver in self.receivers:\n                    if r_senderkey == NONE_ID or r_senderkey == senderkey:\n                        receivers.append(receiver)\n                if self.use_caching:\n                    if not receivers:\n                        self.sender_receivers_cache[sender] = NO_RECEIVERS\n                    else:\n                        # Note, we must cache the weakref versions.\n                        self.sender_receivers_cache[sender] = receivers\n        non_weak_receivers = []\n        for receiver in receivers:\n            if isinstance(receiver, weakref.ReferenceType):\n                # Dereference the weak reference.\n                receiver = receiver()\n                if receiver is not None:\n                    non_weak_receivers.append(receiver)\n            else:\n                non_weak_receivers.append(receiver)\n        return non_weak_receivers", "response": "Filter sequence of receivers to get resolved live receivers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, sender, **named):\n        responses = []\n        if not self.receivers:\n            return responses\n\n        sender_id = _make_id(sender)\n        if sender_id not in self.sender_status:\n            self.sender_status[sender_id] = {}\n\n        if self.sender_status[sender_id] == named:\n            return responses\n\n        self.sender_status[sender_id] = named\n\n        for receiver in self._live_receivers(sender_id):\n            response = receiver(signal=self, sender=sender, **named)\n            responses.append((receiver, response))\n        return responses", "response": "Send a signal from sender to all connected receivers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the state of this device to on or off.", "response": "def set_state(self, state):\n        \"\"\"\n        Set the state of this device to on or off.\n        \"\"\"\n        self.basicevent.SetBinaryState(BinaryState=int(state))\n        self._state = int(state)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef blink(self, delay=1):\n        self.toggle()\n        gevent.spawn_later(delay, self.toggle)", "response": "Blink the switch once and then again after a delay."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef server(self):\n        server = getattr(self, \"_server\", None)\n        if server is None:\n            server = WSGIServer(('', self.port), self._handle, log=None)\n            self._server = server\n        return server", "response": "Returns a WSGIServer instance that will listen for responses."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_state(self, force_update=False):\n        # The base implementation using GetBinaryState doesn't work for Maker (always returns 0).\n        # So pull the switch state from the atrributes instead\n        if force_update or self._state is None:\n            return(int(self.maker_attribs.get('switchstate',0)))\n        return self._state", "response": "Returns 0 if off 1 if on and 1 if on."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a DatagramServer instance bound to the bind socket.", "response": "def server(self):\n        \"\"\"\n        UDP server to listen for responses.\n        \"\"\"\n        server = getattr(self, \"_server\", None)\n        if server is None:\n            log.debug(\"Binding datagram server to %s\", self.bind)\n            server = DatagramServer(self.bind, self._response_received)\n            self._server = server\n        return server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef broadcast(self):\n        log.debug(\"Broadcasting M-SEARCH to %s:%s\", self.mcast_ip, self.mcast_port)\n        request = '\\r\\n'.join((\"M-SEARCH * HTTP/1.1\",\n                               \"HOST:{mcast_ip}:{mcast_port}\",\n                               \"ST:upnp:rootdevice\",\n                               \"MX:2\",\n                               'MAN:\"ssdp:discover\"',\n                               \"\", \"\")).format(**self.__dict__)\n        self.server.sendto(request.encode(), (self.mcast_ip, self.mcast_port))", "response": "Send a multicast M - SEARCH request to the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a requests. request function in case of ConnectionError and returns the result.", "response": "def retry_with_delay(f, delay=60):\n    \"\"\"\n    Retry the wrapped requests.request function in case of ConnectionError.\n    Optionally limit the number of retries or set the delay between retries.\n    \"\"\"\n    @wraps(f)\n    def inner(*args, **kwargs):\n        kwargs['timeout'] = 5\n        remaining = get_retries() + 1\n        while remaining:\n            remaining -= 1\n            try:\n                return f(*args, **kwargs)\n            except (requests.ConnectionError, requests.Timeout):\n                if not remaining:\n                    raise\n                gevent.sleep(delay)\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef registerPlexObject(cls):\n    etype = getattr(cls, 'STREAMTYPE', cls.TYPE)\n    ehash = '%s.%s' % (cls.TAG, etype) if etype else cls.TAG\n    if ehash in PLEXOBJECTS:\n        raise Exception('Ambiguous PlexObject definition %s(tag=%s, type=%s) with %s' %\n            (cls.__name__, cls.TAG, etype, PLEXOBJECTS[ehash].__name__))\n    PLEXOBJECTS[ehash] = cls\n    return cls", "response": "Register a new PlexObject class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cast(func, value):\n    if value is not None:\n        if func == bool:\n            return bool(int(value))\n        elif func in (int, float):\n            try:\n                return func(value)\n            except ValueError:\n                return float('nan')\n        return func(value)\n    return value", "response": "Casts the specified value to the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a query string that includes all the arguments in the dictionary.", "response": "def joinArgs(args):\n    \"\"\" Returns a query string (uses for HTTP URLs) where only the value is URL encoded.\n        Example return value: '?genre=action&type=1337'.\n\n        Parameters:\n            args (dict): Arguments to include in query string.\n    \"\"\"\n    if not args:\n        return ''\n    arglist = []\n    for key in sorted(args, key=lambda x: x.lower()):\n        value = compat.ustr(args[key])\n        arglist.append('%s=%s' % (key, compat.quote(value)))\n    return '?%s' % '&'.join(arglist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rget(obj, attrstr, default=None, delim='.'):  # pragma: no cover\n    try:\n        parts = attrstr.split(delim, 1)\n        attr = parts[0]\n        attrstr = parts[1] if len(parts) == 2 else None\n        if isinstance(obj, dict):\n            value = obj[attr]\n        elif isinstance(obj, list):\n            value = obj[int(attr)]\n        elif isinstance(obj, tuple):\n            value = obj[int(attr)]\n        elif isinstance(obj, object):\n            value = getattr(obj, attr)\n        if attrstr:\n            return rget(value, attrstr, default, delim)\n        return value\n    except:  # noqa: E722\n        return default", "response": "Returns the value at the specified attrstr location within a nexted tree of available keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the integer value of the library string type.", "response": "def searchType(libtype):\n    \"\"\" Returns the integer value of the library string type.\n\n        Parameters:\n            libtype (str): LibType to lookup (movie, show, season, episode, artist, album, track,\n                                              collection)\n        Raises:\n            :class:`plexapi.exceptions.NotFound`: Unknown libtype\n    \"\"\"\n    libtype = compat.ustr(libtype)\n    if libtype in [compat.ustr(v) for v in SEARCHTYPES.values()]:\n        return libtype\n    if SEARCHTYPES.get(libtype) is not None:\n        return SEARCHTYPES[libtype]\n    raise NotFound('Unknown libtype: %s' % libtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef threaded(callback, listargs):\n    threads, results = [], []\n    job_is_done_event = Event()\n    for args in listargs:\n        args += [results, len(results)]\n        results.append(None)\n        threads.append(Thread(target=callback, args=args, kwargs=dict(job_is_done_event=job_is_done_event)))\n        threads[-1].setDaemon(True)\n        threads[-1].start()\n    while not job_is_done_event.is_set():\n        if all([not t.is_alive() for t in threads]):\n            break\n        time.sleep(0.05)\n\n    return [r for r in results if r is not None]", "response": "This function is used to run a callback function in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef toDatetime(value, format=None):\n    if value and value is not None:\n        if format:\n            value = datetime.strptime(value, format)\n        else:\n            # https://bugs.python.org/issue30684\n            # And platform support for before epoch seems to be flaky.\n            # TODO check for others errors too.\n            if int(value) == 0:\n                value = 86400\n            value = datetime.fromtimestamp(int(value))\n    return value", "response": "Converts a value to a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a comma delimited string to a list of strings.", "response": "def toList(value, itemcast=None, delim=','):\n    \"\"\" Returns a list of strings from the specified value.\n\n        Parameters:\n            value (str): comma delimited string to convert to list.\n            itemcast (func): Function to cast each list item to (default str).\n            delim (str): string delimiter (optional; default ',').\n    \"\"\"\n    value = value or ''\n    itemcast = itemcast or str\n    return [itemcast(item) for item in value.split(delim) if item != '']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef downloadSessionImages(server, filename=None, height=150, width=150,\n                          opacity=100, saturation=100):  # pragma: no cover\n    \"\"\" Helper to download a bif image or thumb.url from plex.server.sessions.\n\n       Parameters:\n           filename (str): default to None,\n           height (int): Height of the image.\n           width (int): width of the image.\n           opacity (int): Opacity of the resulting image (possibly deprecated).\n           saturation (int): Saturating of the resulting image.\n\n       Returns:\n            {'hellowlol': {'filepath': '<filepath>', 'url': 'http://<url>'},\n            {'<username>': {filepath, url}}, ...\n    \"\"\"\n    info = {}\n    for media in server.sessions():\n        url = None\n        for part in media.iterParts():\n            if media.thumb:\n                url = media.thumb\n            if part.indexes:  # always use bif images if available.\n                url = '/library/parts/%s/indexes/%s/%s' % (part.id, part.indexes.lower(), media.viewOffset)\n        if url:\n            if filename is None:\n                prettyname = media._prettyfilename()\n                filename = 'session_transcode_%s_%s_%s' % (media.usernames[0], prettyname, int(time.time()))\n            url = server.transcodeImage(url, height, width, opacity, saturation)\n            filepath = download(url, filename=filename)\n            info['username'] = {'filepath': filepath, 'url': url}\n    return info", "response": "Download a bif image or thumb. url from plex. server. sessions.\nAudience"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a file from a URL.", "response": "def download(url, token, filename=None, savepath=None, session=None, chunksize=4024,\n             unpack=False, mocked=False, showstatus=False):\n    \"\"\" Helper to download a thumb, videofile or other media item. Returns the local\n        path to the downloaded file.\n\n       Parameters:\n            url (str): URL where the content be reached.\n            token (str): Plex auth token to include in headers.\n            filename (str): Filename of the downloaded file, default None.\n            savepath (str): Defaults to current working dir.\n            chunksize (int): What chunksize read/write at the time.\n            mocked (bool): Helper to do evertything except write the file.\n            unpack (bool): Unpack the zip file.\n            showstatus(bool): Display a progressbar.\n\n        Example:\n            >>> download(a_episode.getStreamURL(), a_episode.location)\n            /path/to/file\n    \"\"\"\n\n    from plexapi import log\n    # fetch the data to be saved\n    session = session or requests.Session()\n    headers = {'X-Plex-Token': token}\n    response = session.get(url, headers=headers, stream=True)\n    # make sure the savepath directory exists\n    savepath = savepath or os.getcwd()\n    compat.makedirs(savepath, exist_ok=True)\n\n    # try getting filename from header if not specified in arguments (used for logs, db)\n    if not filename and response.headers.get('Content-Disposition'):\n        filename = re.findall(r'filename=\\\"(.+)\\\"', response.headers.get('Content-Disposition'))\n        filename = filename[0] if filename[0] else None\n\n    filename = os.path.basename(filename)\n    fullpath = os.path.join(savepath, filename)\n    # append file.ext from content-type if not already there\n    extension = os.path.splitext(fullpath)[-1]\n    if not extension:\n        contenttype = response.headers.get('content-type')\n        if contenttype and 'image' in contenttype:\n            fullpath += contenttype.split('/')[1]\n\n    # check this is a mocked download (testing)\n    if mocked:\n        log.debug('Mocked download %s', fullpath)\n        return fullpath\n\n    # save the file to disk\n    log.info('Downloading: %s', fullpath)\n    if showstatus:  # pragma: no cover\n        total = int(response.headers.get('content-length', 0))\n        bar = tqdm(unit='B', unit_scale=True, total=total, desc=filename)\n\n    with open(fullpath, 'wb') as handle:\n        for chunk in response.iter_content(chunk_size=chunksize):\n            handle.write(chunk)\n            if showstatus:\n                bar.update(len(chunk))\n\n    if showstatus:  # pragma: no cover\n        bar.close()\n    # check we want to unzip the contents\n    if fullpath.endswith('zip') and unpack:\n        with zipfile.ZipFile(fullpath, 'r') as handle:\n            handle.extractall(savepath)\n\n    return fullpath"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getMyPlexAccount(opts=None):  # pragma: no cover\n    from plexapi import CONFIG\n    from plexapi.myplex import MyPlexAccount\n    # 1. Check command-line options\n    if opts and opts.username and opts.password:\n        print('Authenticating with Plex.tv as %s..' % opts.username)\n        return MyPlexAccount(opts.username, opts.password)\n    # 2. Check Plexconfig (environment variables and config.ini)\n    config_username = CONFIG.get('auth.myplex_username')\n    config_password = CONFIG.get('auth.myplex_password')\n    if config_username and config_password:\n        print('Authenticating with Plex.tv as %s..' % config_username)\n        return MyPlexAccount(config_username, config_password)\n    # 3. Prompt for username and password on the command line\n    username = input('What is your plex.tv username: ')\n    password = getpass('What is your plex.tv password: ')\n    print('Authenticating with Plex.tv as %s..' % username)\n    return MyPlexAccount(username, password)", "response": "Helper function to get a MyPlex Account instance by checking the options and Plexconfig. ini and Plex."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef choose(msg, items, attr):  # pragma: no cover\n    # Return the first item if there is only one choice\n    if len(items) == 1:\n        return items[0]\n    # Print all choices to the command line\n    print()\n    for index, i in enumerate(items):\n        name = attr(i) if callable(attr) else getattr(i, attr)\n        print('  %s: %s' % (index, name))\n    print()\n    # Request choice from the user\n    while True:\n        try:\n            inp = input('%s: ' % msg)\n            if any(s in inp for s in (':', '::', '-')):\n                idx = slice(*map(lambda x: int(x.strip()) if x.strip() else None, inp.split(':')))\n                return items[idx]\n            else:\n                return items[int(inp)]\n\n        except (ValueError, IndexError):\n            pass", "response": "Command line helper to display a list of choices from the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_server(account, servername=None):\n    servers = servers = [s for s in account.resources() if 'server' in s.provides]\n    # If servername specified find and return it\n    if servername is not None:\n        for server in servers:\n            if server.name == servername:\n                return server.connect()\n        raise SystemExit('Unknown server name: %s' % servername)\n    # If servername not specified; allow user to choose\n    return utils.choose('Choose a Server', servers, 'name').connect()", "response": "Find and return a PlexServer object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore_watched(plex, opts):\n    with open(opts.filepath, 'r') as handle:\n        source = json.load(handle)\n    # Find the differences\n    differences = defaultdict(lambda: dict())\n    for section in _iter_sections(plex, opts):\n        print('Finding differences in %s..' % section.title)\n        skey = section.title.lower()\n        for item in _iter_items(section):\n            ikey = _item_key(item)\n            sval = source.get(skey,{}).get(ikey)\n            if sval is None:\n                raise SystemExit('%s not found' % ikey)\n            if (sval is not None and item.isWatched != sval) and (not opts.watchedonly or sval):\n                differences[skey][ikey] = {'isWatched':sval, 'item':item}\n    print('Applying %s differences to destination' % len(differences))\n    import pprint; pprint.pprint(differences)", "response": "Restore watched status from the specified filepath."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when websocket message is recieved.", "response": "def _onMessage(self, ws, message):\n        \"\"\" Called when websocket message is recieved. \"\"\"\n        try:\n            data = json.loads(message)['NotificationContainer']\n            log.debug('Alert: %s %s %s', *data)\n            if self._callback:\n                self._callback(data)\n        except Exception as err:  # pragma: no cover\n            log.error('AlertListener Msg Error: %s', err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loadData(self, data):\n        self._data = data\n        for elem in data:\n            id = utils.lowerFirst(elem.attrib['id'])\n            if id in self._settings:\n                self._settings[id]._loadData(elem)\n                continue\n            self._settings[id] = Setting(self._server, elem, self._initpath)", "response": "Load attribute values from Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all(self):\n        return list(v for id, v in sorted(self._settings.items()))", "response": "Returns a list of all settings available."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the setting with the specified id.", "response": "def get(self, id):\n        \"\"\" Return the :class:`~plexapi.settings.Setting` object with the specified id. \"\"\"\n        id = utils.lowerFirst(id)\n        if id in self._settings:\n            return self._settings[id]\n        raise NotFound('Invalid setting id: %s' % id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of lists for all the key - value pairs grouped by setting group.", "response": "def groups(self):\n        \"\"\" Returns a dict of lists for all :class:`~plexapi.settings.Setting`\n            objects grouped by setting group.\n        \"\"\"\n        groups = defaultdict(list)\n        for setting in self.all():\n            groups[setting.group].append(setting)\n        return dict(groups)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave any outstanding settnig changes to the PlexServer.", "response": "def save(self):\n        \"\"\" Save any outstanding settnig changes to the :class:`~plexapi.server.PlexServer`. This\n            performs a full reload() of Settings after complete.\n        \"\"\"\n        params = {}\n        for setting in self.all():\n            if setting._setValue:\n                log.info('Saving PlexServer setting %s = %s' % (setting.id, setting._setValue))\n                params[setting.id] = quote(setting._setValue)\n        if not params:\n            raise BadRequest('No setting have been modified.')\n        querystr = '&'.join(['%s=%s' % (k, v) for k, v in params.items()])\n        url = '%s?%s' % (self.key, querystr)\n        self._server.query(url, self._server._session.put)\n        self.reload()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload attribute values from Plex XML response.", "response": "def _loadData(self, data):\n        \"\"\" Load attribute values from Plex XML response. \"\"\"\n        self._setValue = None\n        self.id = data.attrib.get('id')\n        self.label = data.attrib.get('label')\n        self.summary = data.attrib.get('summary')\n        self.type = data.attrib.get('type')\n        self.default = self._cast(data.attrib.get('default'))\n        self.value = self._cast(data.attrib.get('value'))\n        self.hidden = utils.cast(bool, data.attrib.get('hidden'))\n        self.advanced = utils.cast(bool, data.attrib.get('advanced'))\n        self.group = data.attrib.get('group')\n        self.enumValues = self._getEnumValues(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncast the specifief value to the type of this setting.", "response": "def _cast(self, value):\n        \"\"\" Cast the specifief value to the type of this setting. \"\"\"\n        if self.type != 'text':\n            value = utils.cast(self.TYPES.get(self.type)['cast'], value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of dictionary of valis values for this setting.", "response": "def _getEnumValues(self, data):\n        \"\"\" Returns a list of dictionary of valis value for this setting. \"\"\"\n        enumstr = data.attrib.get('enumValues')\n        if not enumstr:\n            return None\n        if ':' in enumstr:\n            return {self._cast(k): v for k, v in [kv.split(':') for kv in enumstr.split('|')]}\n        return enumstr.split('|')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a new value for this object.", "response": "def set(self, value):\n        \"\"\" Set a new value for this setitng. NOTE: You must call plex.settings.save() for before\n            any changes to setting values are persisted to the :class:`~plexapi.server.PlexServer`.\n        \"\"\"\n        # check a few things up front\n        if not isinstance(value, self.TYPES[self.type]['type']):\n            badtype = type(value).__name__\n            raise BadRequest('Invalid value for %s: a %s is required, not %s' % (self.id, self.type, badtype))\n        if self.enumValues and value not in self.enumValues:\n            raise BadRequest('Invalid value for %s: %s not in %s' % (self.id, value, list(self.enumValues)))\n        # store value off to the side until we call settings.save()\n        tostr = self.TYPES[self.type]['tostr']\n        self._setValue = tostr(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _loadData(self, data):\n        self._data = data\n        self.allowCameraUpload = cast(bool, data.attrib.get('allowCameraUpload'))\n        self.allowChannelAccess = cast(bool, data.attrib.get('allowChannelAccess'))\n        self.allowMediaDeletion = cast(bool, data.attrib.get('allowMediaDeletion'))\n        self.allowSharing = cast(bool, data.attrib.get('allowSharing'))\n        self.allowSync = cast(bool, data.attrib.get('allowSync'))\n        self.backgroundProcessing = cast(bool, data.attrib.get('backgroundProcessing'))\n        self.certificate = cast(bool, data.attrib.get('certificate'))\n        self.companionProxy = cast(bool, data.attrib.get('companionProxy'))\n        self.diagnostics = utils.toList(data.attrib.get('diagnostics'))\n        self.eventStream = cast(bool, data.attrib.get('eventStream'))\n        self.friendlyName = data.attrib.get('friendlyName')\n        self.hubSearch = cast(bool, data.attrib.get('hubSearch'))\n        self.machineIdentifier = data.attrib.get('machineIdentifier')\n        self.multiuser = cast(bool, data.attrib.get('multiuser'))\n        self.myPlex = cast(bool, data.attrib.get('myPlex'))\n        self.myPlexMappingState = data.attrib.get('myPlexMappingState')\n        self.myPlexSigninState = data.attrib.get('myPlexSigninState')\n        self.myPlexSubscription = cast(bool, data.attrib.get('myPlexSubscription'))\n        self.myPlexUsername = data.attrib.get('myPlexUsername')\n        self.ownerFeatures = utils.toList(data.attrib.get('ownerFeatures'))\n        self.photoAutoTag = cast(bool, data.attrib.get('photoAutoTag'))\n        self.platform = data.attrib.get('platform')\n        self.platformVersion = data.attrib.get('platformVersion')\n        self.pluginHost = cast(bool, data.attrib.get('pluginHost'))\n        self.readOnlyLibraries = cast(int, data.attrib.get('readOnlyLibraries'))\n        self.requestParametersInCookie = cast(bool, data.attrib.get('requestParametersInCookie'))\n        self.streamingBrainVersion = data.attrib.get('streamingBrainVersion')\n        self.sync = cast(bool, data.attrib.get('sync'))\n        self.transcoderActiveVideoSessions = int(data.attrib.get('transcoderActiveVideoSessions', 0))\n        self.transcoderAudio = cast(bool, data.attrib.get('transcoderAudio'))\n        self.transcoderLyrics = cast(bool, data.attrib.get('transcoderLyrics'))\n        self.transcoderPhoto = cast(bool, data.attrib.get('transcoderPhoto'))\n        self.transcoderSubtitles = cast(bool, data.attrib.get('transcoderSubtitles'))\n        self.transcoderVideo = cast(bool, data.attrib.get('transcoderVideo'))\n        self.transcoderVideoBitrates = utils.toList(data.attrib.get('transcoderVideoBitrates'))\n        self.transcoderVideoQualities = utils.toList(data.attrib.get('transcoderVideoQualities'))\n        self.transcoderVideoResolutions = utils.toList(data.attrib.get('transcoderVideoResolutions'))\n        self.updatedAt = utils.toDatetime(data.attrib.get('updatedAt'))\n        self.updater = cast(bool, data.attrib.get('updater'))\n        self.version = data.attrib.get('version')\n        self.voiceSearch = cast(bool, data.attrib.get('voiceSearch'))", "response": "Load the attributes from the Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict containing base headers for all requests to the server.", "response": "def _headers(self, **kwargs):\n        \"\"\" Returns dict containing base headers for all requests to the server. \"\"\"\n        headers = BASE_HEADERS.copy()\n        if self._token:\n            headers['X-Plex-Token'] = self._token\n        headers.update(kwargs)\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef library(self):\n        if not self._library:\n            try:\n                data = self.query(Library.key)\n                self._library = Library(self, data)\n            except BadRequest:\n                data = self.query('/library/sections/')\n                # Only the owner has access to /library\n                # so just return the library without the data.\n                return Library(self, data)\n        return self._library", "response": "Return the Library object for this user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all server settings.", "response": "def settings(self):\n        \"\"\" Returns a list of all server settings. \"\"\"\n        if not self._settings:\n            data = self.query(Settings.key)\n            self._settings = Settings(self, data)\n        return self._settings"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Account object this server belongs to.", "response": "def account(self):\n        \"\"\" Returns the :class:`~plexapi.server.Account` object this server belongs to. \"\"\"\n        data = self.query(Account.key)\n        return Account(self, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a : class : ~plexapi. myplex. MyPlexAccount object using the same token to access this server.", "response": "def myPlexAccount(self):\n        \"\"\" Returns a :class:`~plexapi.myplex.MyPlexAccount` object using the same\n            token to access this server. If you are not the owner of this PlexServer\n            you're likley to recieve an authentication error calling this.\n        \"\"\"\n        if self._myPlexAccount is None:\n            from plexapi.myplex import MyPlexAccount\n            self._myPlexAccount = MyPlexAccount(token=self._token)\n        return self._myPlexAccount"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the client ports from myPlex", "response": "def _myPlexClientPorts(self):\n        \"\"\" Sometimes the PlexServer does not properly advertise port numbers required\n            to connect. This attemps to look up device port number from plex.tv.\n            See issue #126: Make PlexServer.clients() more user friendly.\n              https://github.com/pkkid/python-plexapi/issues/126\n        \"\"\"\n        try:\n            ports = {}\n            account = self.myPlexAccount()\n            for device in account.devices():\n                if device.connections and ':' in device.connections[0][6:]:\n                    ports[device.clientIdentifier] = device.connections[0].split(':')[-1]\n            return ports\n        except Exception as err:\n            log.warning('Unable to fetch client ports from myPlex: %s', err)\n            return ports"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clients(self):\n        items = []\n        ports = None\n        for elem in self.query('/clients'):\n            port = elem.attrib.get('port')\n            if not port:\n                log.warning('%s did not advertise a port, checking plex.tv.', elem.attrib.get('name'))\n                ports = self._myPlexClientPorts() if ports is None else ports\n                port = ports.get(elem.attrib.get('machineIdentifier'))\n            baseurl = 'http://%s:%s' % (elem.attrib['host'], port)\n            items.append(PlexClient(baseurl=baseurl, server=self,\n                                    token=self._token, data=elem, connect=False))\n\n        return items", "response": "Returns a list of all PlexClient objects connected to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the client with the specified name.", "response": "def client(self, name):\n        \"\"\" Returns the :class:`~plexapi.client.PlexClient` that matches the specified name.\n\n            Parameters:\n                name (str): Name of the client to return.\n\n            Raises:\n                :class:`plexapi.exceptions.NotFound`: Unknown client name\n        \"\"\"\n        for client in self.clients():\n            if client and client.title == name:\n                return client\n\n        raise NotFound('Unknown client name: %s' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createPlaylist(self, title, items=None, section=None, limit=None, smart=None, **kwargs):\n        return Playlist.create(self, title, items=items, limit=limit, section=section, smart=smart, **kwargs)", "response": "Creates and returns a new playlist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading databases. Parameters: savepath (str): Defaults to current working dir. unpack (bool): Unpack the zip file.", "response": "def downloadDatabases(self, savepath=None, unpack=False):\n        \"\"\" Download databases.\n\n            Parameters:\n                savepath (str): Defaults to current working dir.\n                unpack (bool): Unpack the zip file.\n        \"\"\"\n        url = self.url('/diagnostics/databases')\n        filepath = utils.download(url, self._token, None, savepath, self._session, unpack=unpack)\n        return filepath"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_for_update(self, force=True, download=False):\n        part = '/updater/check?download=%s' % (1 if download else 0)\n        if force:\n            self.query(part, method=self._session.put)\n        releases = self.fetchItems('/updater/status')\n        if len(releases):\n            return releases[0]", "response": "Checks if a release is available for update."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling the newest version of Plex Media Server.", "response": "def installUpdate(self):\n        \"\"\" Install the newest version of Plex Media Server. \"\"\"\n        # We can add this but dunno how useful this is since it sometimes\n        # requires user action using a gui.\n        part = '/updater/apply'\n        release = self.check_for_update(force=True, download=True)\n        if release and release.version != self.version:\n            # figure out what method this is..\n            return self.query(part, method=self._session.put)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, query, mediatype=None, limit=None):\n        results = []\n        params = {'query': query}\n        if mediatype:\n            params['section'] = utils.SEARCHTYPES[mediatype]\n        if limit:\n            params['limit'] = limit\n        key = '/hubs/search?%s' % urlencode(params)\n        for hub in self.fetchItems(key, Hub):\n            results += hub.items\n        return results", "response": "Search for items in the Kurosawa library."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart a new alert listener that will be notified when a new message is recieved.", "response": "def startAlertListener(self, callback=None):\n        \"\"\" Creates a websocket connection to the Plex Server to optionally recieve\n            notifications. These often include messages from Plex about media scans\n            as well as updates to currently running Transcode Sessions.\n\n            NOTE: You need websocket-client installed in order to use this feature.\n            >> pip install websocket-client\n\n            Parameters:\n                callback (func): Callback function to call on recieved messages.\n\n            raises:\n                :class:`plexapi.exception.Unsupported`: Websocket-client not installed.\n        \"\"\"\n        notifier = AlertListener(self, callback)\n        notifier.start()\n        return notifier"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL for a transcoded image from the specified media object.", "response": "def transcodeImage(self, media, height, width, opacity=100, saturation=100):\n        \"\"\" Returns the URL for a transcoded image from the specified media object.\n            Returns None if no media specified (needed if user tries to pass thumb\n            or art directly).\n\n            Parameters:\n                height (int): Height to transcode the image to.\n                width (int): Width to transcode the image to.\n                opacity (int): Opacity of the resulting image (possibly deprecated).\n                saturation (int): Saturating of the resulting image.\n        \"\"\"\n        if media:\n            transcode_url = '/photo/:/transcode?height=%s&width=%s&opacity=%s&saturation=%s&url=%s' % (\n                height, width, opacity, saturation, media)\n            return self.url(transcode_url, includeToken=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a URL string with proper token argument.", "response": "def url(self, key, includeToken=None):\n        \"\"\" Build a URL string with proper token argument.  Token will be appended to the URL\n            if either includeToken is True or CONFIG.log.show_secrets is 'true'.\n        \"\"\"\n        if self._token and (includeToken or self._showSecrets):\n            delim = '&' if '?' in key else '?'\n            return '%s%s%sX-Plex-Token=%s' % (self._baseurl, key, delim, self._token)\n        return '%s%s' % (self._baseurl, key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _loadData(self, data):\n        self._data = data\n        self.listType = 'video'\n        self.addedAt = utils.toDatetime(data.attrib.get('addedAt'))\n        self.key = data.attrib.get('key', '')\n        self.lastViewedAt = utils.toDatetime(data.attrib.get('lastViewedAt'))\n        self.librarySectionID = data.attrib.get('librarySectionID')\n        self.ratingKey = utils.cast(int, data.attrib.get('ratingKey'))\n        self.summary = data.attrib.get('summary')\n        self.thumb = data.attrib.get('thumb')\n        self.title = data.attrib.get('title')\n        self.titleSort = data.attrib.get('titleSort', self.title)\n        self.type = data.attrib.get('type')\n        self.updatedAt = utils.toDatetime(data.attrib.get('updatedAt'))\n        self.viewCount = utils.cast(int, data.attrib.get('viewCount', 0))", "response": "Load the attributes from the Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the first thumbnail url starting on the most specific thumbnail for that item.", "response": "def thumbUrl(self):\n        \"\"\" Return the first first thumbnail url starting on\n            the most specific thumbnail for that item.\n        \"\"\"\n        thumb = self.firstAttr('thumb', 'parentThumb', 'granparentThumb')\n        return self._server.url(thumb, includeToken=True) if thumb else None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef artUrl(self):\n        art = self.firstAttr('art', 'grandparentArt')\n        return self._server.url(art, includeToken=True) if art else None", "response": "Return the first art url starting on the most specific for that item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url(self, part):\n        return self._server.url(part, includeToken=True) if part else None", "response": "Returns the full url for something. Typically used for getting a specific image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef markWatched(self):\n        key = '/:/scrobble?key=%s&identifier=com.plexapp.plugins.library' % self.ratingKey\n        self._server.query(key)\n        self.reload()", "response": "Mark video as watched."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync(self, videoQuality, client=None, clientId=None, limit=None, unwatched=False, title=None):\n\n        from plexapi.sync import SyncItem, Policy, MediaSettings\n\n        myplex = self._server.myPlexAccount()\n        sync_item = SyncItem(self._server, None)\n        sync_item.title = title if title else self._defaultSyncTitle()\n        sync_item.rootTitle = self.title\n        sync_item.contentType = self.listType\n        sync_item.metadataType = self.METADATA_TYPE\n        sync_item.machineIdentifier = self._server.machineIdentifier\n\n        section = self._server.library.sectionByID(self.librarySectionID)\n\n        sync_item.location = 'library://%s/item/%s' % (section.uuid, quote_plus(self.key))\n        sync_item.policy = Policy.create(limit, unwatched)\n        sync_item.mediaSettings = MediaSettings.createVideo(videoQuality)\n\n        return myplex.sync(sync_item, client=client, clientId=clientId)", "response": "Add current video to the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of all base X - Plex - * headers for session requests.", "response": "def reset_base_headers():\n    \"\"\" Convenience function returns a dict of all base X-Plex-* headers for session requests. \"\"\"\n    import plexapi\n    return {\n        'X-Plex-Platform': plexapi.X_PLEX_PLATFORM,\n        'X-Plex-Platform-Version': plexapi.X_PLEX_PLATFORM_VERSION,\n        'X-Plex-Provides': plexapi.X_PLEX_PROVIDES,\n        'X-Plex-Product': plexapi.X_PLEX_PRODUCT,\n        'X-Plex-Version': plexapi.X_PLEX_VERSION,\n        'X-Plex-Device': plexapi.X_PLEX_DEVICE,\n        'X-Plex-Device-Name': plexapi.X_PLEX_DEVICE_NAME,\n        'X-Plex-Client-Identifier': plexapi.X_PLEX_IDENTIFIER,\n        'X-Plex-Sync-Version': '2',\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, key, default=None, cast=None):\n        try:\n            # First: check environment variable is set\n            envkey = 'PLEXAPI_%s' % key.upper().replace('.', '_')\n            value = os.environ.get(envkey)\n            if value is None:\n                # Second: check the config file has attr\n                section, name = key.lower().split('.')\n                value = self.data.get(section, {}).get(name, default)\n            return cast(value) if cast else value\n        except:  # noqa: E722\n            return default", "response": "Returns the specified configuration value or default if not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all configuration values as a dictionary.", "response": "def _asDict(self):\n        \"\"\" Returns all configuration values as a dictionary. \"\"\"\n        config = defaultdict(dict)\n        for section in self._sections:\n            for name, value in self._sections[section].items():\n                if name != '__name__':\n                    config[section.lower()][name.lower()] = value\n        return dict(config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _loadData(self, data):\n        self._data = data\n        self.codec = data.attrib.get('codec')\n        self.codecID = data.attrib.get('codecID')\n        self.id = cast(int, data.attrib.get('id'))\n        self.index = cast(int, data.attrib.get('index', '-1'))\n        self.language = data.attrib.get('language')\n        self.languageCode = data.attrib.get('languageCode')\n        self.selected = cast(bool, data.attrib.get('selected', '0'))\n        self.streamType = cast(int, data.attrib.get('streamType'))\n        self.type = cast(int, data.attrib.get('streamType'))", "response": "Load the attributes from the Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the attributes from the Plex XML response.", "response": "def _loadData(self, data):\n        \"\"\" Load attribute values from Plex XML response. \"\"\"\n        self._data = data\n        self.id = cast(int, data.attrib.get('id'))\n        self.role = data.attrib.get('role')\n        self.tag = data.attrib.get('tag')\n        # additional attributes only from hub search\n        self.key = data.attrib.get('key')\n        self.librarySectionID = cast(int, data.attrib.get('librarySectionID'))\n        self.librarySectionTitle = data.attrib.get('librarySectionTitle')\n        self.librarySectionType = data.attrib.get('librarySectionType')\n        self.tagType = cast(int, data.attrib.get('tagType'))\n        self.thumb = data.attrib.get('thumb')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef items(self, *args, **kwargs):\n        if not self.key:\n            raise BadRequest('Key is not defined for this tag: %s' % self.tag)\n        return self.fetchItems(self.key)", "response": "Return the list of items within this tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning : class : plexapi. MyPlexResource with server of current item.", "response": "def server(self):\n        \"\"\" Returns :class:`plexapi.myplex.MyPlexResource` with server of current item. \"\"\"\n        server = [s for s in self._server.resources() if s.clientIdentifier == self.machineIdentifier]\n        if len(server) == 0:\n            raise NotFound('Unable to find server with uuid %s' % self.machineIdentifier)\n        return server[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getMedia(self):\n        server = self.server().connect()\n        key = '/sync/items/%s' % self.id\n        return server.fetchItems(key)", "response": "Returns a list of playable items which belong to this sync item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks the file as downloaded within a SyncItem.", "response": "def markDownloaded(self, media):\n        \"\"\" Mark the file as downloaded (by the nature of Plex it will be marked as downloaded within\n            any SyncItem where it presented).\n\n            Parameters:\n                media (base.Playable): the media to be marked as downloaded.\n        \"\"\"\n        url = '/sync/%s/item/%s/downloaded' % (self.clientIdentifier, media.ratingKey)\n        media._server.query(url, method=requests.put)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving current SyncItem from SyncList", "response": "def delete(self):\n        \"\"\" Removes current SyncItem \"\"\"\n        url = SyncList.key.format(clientId=self.clientIdentifier)\n        url += '/' + str(self.id)\n        self._server.query(url, self._server._session.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new video object based on provided video quality value.", "response": "def createVideo(videoQuality):\n        \"\"\" Returns a :class:`~plexapi.sync.MediaSettings` object, based on provided video quality value.\n\n            Parameters:\n                videoQuality (int): idx of quality of the video, one of VIDEO_QUALITY_* values defined in this module.\n\n            Raises:\n                :class:`plexapi.exceptions.BadRequest`: when provided unknown video quality.\n        \"\"\"\n        if videoQuality == VIDEO_QUALITY_ORIGINAL:\n            return MediaSettings('', '', '')\n        elif videoQuality < len(VIDEO_QUALITIES['bitrate']):\n            return MediaSettings(VIDEO_QUALITIES['bitrate'][videoQuality],\n                                 VIDEO_QUALITIES['videoQuality'][videoQuality],\n                                 VIDEO_QUALITIES['videoResolution'][videoQuality])\n        else:\n            raise BadRequest('Unexpected video quality')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a synchronized photo object based on provided video quality value.", "response": "def createPhoto(resolution):\n        \"\"\" Returns a :class:`~plexapi.sync.MediaSettings` object, based on provided photo quality value.\n\n            Parameters:\n                resolution (str): maximum allowed resolution for synchronized photos, see PHOTO_QUALITY_* values in the\n                                  module.\n\n            Raises:\n                :class:`plexapi.exceptions.BadRequest` when provided unknown video quality.\n        \"\"\"\n        if resolution in PHOTO_QUALITIES:\n            return MediaSettings(photoQuality=PHOTO_QUALITIES[resolution], photoResolution=resolution)\n        else:\n            raise BadRequest('Unexpected photo quality')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(limit=None, unwatched=False):\n        scope = 'all'\n        if limit is None:\n            limit = 0\n        else:\n            scope = 'count'\n\n        return Policy(scope, unwatched, limit)", "response": "Creates a new object for provided options and automatically sets proper scope and limit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _clean(self, value):\n        if value:\n            value = str(value).replace('/library/metadata/', '')\n            value = value.replace('/children', '')\n            return value.replace(' ', '-')[:20]", "response": "Clean attr value for display in __repr__."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a single item based on the PLEXOBJECTS.", "response": "def _buildItem(self, elem, cls=None, initpath=None):\n        \"\"\" Factory function to build objects based on registered PLEXOBJECTS. \"\"\"\n        # cls is specified, build the object and return\n        initpath = initpath or self._initpath\n        if cls is not None:\n            return cls(self._server, elem, initpath)\n        # cls is not specified, try looking it up in PLEXOBJECTS\n        etype = elem.attrib.get('type', elem.attrib.get('streamType'))\n        ehash = '%s.%s' % (elem.tag, etype) if etype else elem.tag\n        ecls = utils.PLEXOBJECTS.get(ehash, utils.PLEXOBJECTS.get(elem.tag))\n        # log.debug('Building %s as %s', elem.tag, ecls.__name__)\n        if ecls is not None:\n            return ecls(self._server, elem, initpath)\n        raise UnknownType(\"Unknown library type <%s type='%s'../>\" % (elem.tag, etype))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _buildItemOrNone(self, elem, cls=None, initpath=None):\n        try:\n            return self._buildItem(elem, cls, initpath)\n        except UnknownType:\n            return None", "response": "Calls _buildItem but returns\n            None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the specified key and returns the first item with the specified tag and attributes.", "response": "def fetchItem(self, ekey, cls=None, **kwargs):\n        \"\"\" Load the specified key to find and build the first item with the\n            specified tag and attrs. If no tag or attrs are specified then\n            the first item in the result set is returned.\n\n            Parameters:\n                ekey (str or int): Path in Plex to fetch items from. If an int is passed\n                    in, the key will be translated to /library/metadata/<key>. This allows\n                    fetching an item only knowing its key-id.\n                cls (:class:`~plexapi.base.PlexObject`): If you know the class of the\n                    items to be fetched, passing this in will help the parser ensure\n                    it only returns those items. By default we convert the xml elements\n                    with the best guess PlexObjects based on tag and type attrs.\n                etag (str): Only fetch items with the specified tag.\n                **kwargs (dict): Optionally add attribute filters on the items to fetch. For\n                    example, passing in viewCount=0 will only return matching items. Filtering\n                    is done before the Python objects are built to help keep things speedy.\n                    Note: Because some attribute names are already used as arguments to this\n                    function, such as 'tag', you may still reference the attr tag byappending\n                    an underscore. For example, passing in _tag='foobar' will return all items\n                    where tag='foobar'. Also Note: Case very much matters when specifying kwargs\n                    -- Optionally, operators can be specified by append it\n                    to the end of the attribute name for more complex lookups. For example,\n                    passing in viewCount__gte=0 will return all items where viewCount >= 0.\n                    Available operations include:\n\n                    * __contains: Value contains specified arg.\n                    * __endswith: Value ends with specified arg.\n                    * __exact: Value matches specified arg.\n                    * __exists (bool): Value is or is not present in the attrs.\n                    * __gt: Value is greater than specified arg.\n                    * __gte: Value is greater than or equal to specified arg.\n                    * __icontains: Case insensative value contains specified arg.\n                    * __iendswith: Case insensative value ends with specified arg.\n                    * __iexact: Case insensative value matches specified arg.\n                    * __in: Value is in a specified list or tuple.\n                    * __iregex: Case insensative value matches the specified regular expression.\n                    * __istartswith: Case insensative value starts with specified arg.\n                    * __lt: Value is less than specified arg.\n                    * __lte: Value is less than or equal to specified arg.\n                    * __regex: Value matches the specified regular expression.\n                    * __startswith: Value starts with specified arg.\n        \"\"\"\n        if isinstance(ekey, int):\n            ekey = '/library/metadata/%s' % ekey\n        for elem in self._server.query(ekey):\n            if self._checkAttrs(elem, **kwargs):\n                return self._buildItem(elem, cls, ekey)\n        clsname = cls.__name__ if cls else 'None'\n        raise NotFound('Unable to find elem: cls=%s, attrs=%s' % (clsname, kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the specified key to find and build all items with the specified tag and attrs.", "response": "def fetchItems(self, ekey, cls=None, **kwargs):\n        \"\"\" Load the specified key to find and build all items with the specified tag\n            and attrs. See :func:`~plexapi.base.PlexObject.fetchItem` for more details\n            on how this is used.\n        \"\"\"\n        data = self._server.query(ekey)\n        items = self.findItems(data, cls, ekey, **kwargs)\n        librarySectionID = data.attrib.get('librarySectionID')\n        if librarySectionID:\n            for item in items:\n                item.librarySectionID = librarySectionID\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef findItems(self, data, cls=None, initpath=None, **kwargs):\n        # filter on cls attrs if specified\n        if cls and cls.TAG and 'tag' not in kwargs:\n            kwargs['etag'] = cls.TAG\n        if cls and cls.TYPE and 'type' not in kwargs:\n            kwargs['type'] = cls.TYPE\n        # loop through all data elements to find matches\n        items = []\n        for elem in data:\n            if self._checkAttrs(elem, **kwargs):\n                item = self._buildItemOrNone(elem, cls, initpath)\n                if item is not None:\n                    items.append(item)\n        return items", "response": "Load the specified data to find and build all items with the specified tag\n            and attrs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the first attribute in attrs that is not None.", "response": "def firstAttr(self, *attrs):\n        \"\"\" Return the first attribute in attrs that is not None. \"\"\"\n        for attr in attrs:\n            value = self.__dict__.get(attr)\n            if value is not None:\n                return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reload(self, key=None):\n        key = key or self._details_key or self.key\n        if not key:\n            raise Unsupported('Cannot reload an object not built from a URL.')\n        self._initpath = key\n        data = self._server.query(key)\n        self._loadData(data[0])\n        return self", "response": "Reload the data for this object from self. key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting an object. Parameters: kwargs (dict): Dict of settings to edit. Example: {'type': 1, 'id': movie.ratingKey, 'collection[0].tag.tag': 'Super', 'collection.locked': 0}", "response": "def edit(self, **kwargs):\n        \"\"\" Edit an object.\n\n            Parameters:\n                kwargs (dict): Dict of settings to edit.\n\n            Example:\n                {'type': 1,\n                 'id': movie.ratingKey,\n                 'collection[0].tag.tag': 'Super',\n                 'collection.locked': 0}\n        \"\"\"\n        if 'id' not in kwargs:\n            kwargs['id'] = self.ratingKey\n        if 'type' not in kwargs:\n            kwargs['type'] = utils.searchType(self.type)\n\n        part = '/library/sections/%s/all?%s' % (self.librarySectionID,\n                                                urlencode(kwargs))\n        self._server.query(part, method=self._server._session.put)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _edit_tags(self, tag, items, locked=True, remove=False):\n        if not isinstance(items, list):\n            items = [items]\n        value = getattr(self, tag + 's')\n        existing_cols = [t.tag for t in value if t and remove is False]\n        d = tag_helper(tag, existing_cols + items, locked, remove)\n        self.edit(**d)\n        self.refresh()", "response": "Helper to edit and refresh a tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrefreshes the metadata for the item even if it already has metadata.", "response": "def refresh(self):\n        \"\"\" Refreshing a Library or individual item causes the metadata for the item to be\n            refreshed, even if it already has metadata. You can think of refreshing as\n            \"update metadata for the requested item even if it already has some\". You should\n            refresh a Library or individual item if:\n\n            * You've changed the Library Metadata Agent.\n            * You've added \"Local Media Assets\" (such as artwork, theme music, external\n                subtitle files, etc.)\n            * You want to freshen the item posters, summary, etc.\n            * There's a problem with the poster image that's been downloaded.\n            * Items are missing posters or other downloaded information. This is possible if\n                the refresh process is interrupted (the Server is turned off, internet\n                connection dies, etc).\n        \"\"\"\n        key = '%s/refresh' % self.key\n        self._server.query(key, method=self._server._session.put)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getStreamURL(self, **params):\n        if self.TYPE not in ('movie', 'episode', 'track'):\n            raise Unsupported('Fetching stream URL for %s is unsupported.' % self.TYPE)\n        mvb = params.get('maxVideoBitrate')\n        vr = params.get('videoResolution', '')\n        params = {\n            'path': self.key,\n            'offset': params.get('offset', 0),\n            'copyts': params.get('copyts', 1),\n            'protocol': params.get('protocol'),\n            'mediaIndex': params.get('mediaIndex', 0),\n            'X-Plex-Platform': params.get('platform', 'Chrome'),\n            'maxVideoBitrate': max(mvb, 64) if mvb else None,\n            'videoResolution': vr if re.match('^\\d+x\\d+$', vr) else None\n        }\n        # remove None values\n        params = {k: v for k, v in params.items() if v is not None}\n        streamtype = 'audio' if self.TYPE in ('track', 'album') else 'video'\n        # sort the keys since the randomness fucks with my tests..\n        sorted_params = sorted(params.items(), key=lambda val: val[0])\n        return self._server.url('/%s/:/transcode/universal/start.m3u8?%s' %\n            (streamtype, urlencode(sorted_params)), includeToken=True)", "response": "Returns the URL for the stream for this item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(self, savepath=None, keep_original_name=False, **kwargs):\n        filepaths = []\n        locations = [i for i in self.iterParts() if i]\n        for location in locations:\n            filename = location.file\n            if keep_original_name is False:\n                filename = '%s.%s' % (self._prettyfilename(), location.container)\n            # So this seems to be a alot slower but allows transcode.\n            if kwargs:\n                download_url = self.getStreamURL(**kwargs)\n            else:\n                download_url = self._server.url('%s?download=1' % location.key)\n            filepath = utils.download(download_url, self._server._token, filename=filename,\n                savepath=savepath, session=self._server._session)\n            if filepath:\n                filepaths.append(filepath)\n        return filepaths", "response": "Downloads this items media to the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self, reason=''):\n        key = '/status/sessions/terminate?sessionId=%s&reason=%s' % (self.session[0].id, quote_plus(reason))\n        return self._server.query(key)", "response": "Stop playback for a media item."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updateProgress(self, time, state='stopped'):\n        key = '/:/progress?key=%s&identifier=com.plexapp.plugins.library&time=%d&state=%s' % (self.ratingKey,\n                                                                                              time, state)\n        self._server.query(key)\n        self.reload()", "response": "Update the watched progress for this video."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef updateTimeline(self, time, state='stopped', duration=None):\n        durationStr = '&duration='\n        if duration is not None:\n            durationStr = durationStr + str(duration)\n        else:\n            durationStr = durationStr + str(self.duration)\n        key = '/:/timeline?ratingKey=%s&key=%s&identifier=com.plexapp.plugins.library&time=%d&state=%s%s'\n        key %= (self.ratingKey, self.key, time, state, durationStr)\n        self._server.query(key)\n        self.reload()", "response": "Update the timeline for this item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all media sections in this library.", "response": "def sections(self):\n        \"\"\" Returns a list of all media sections in this library. Library sections may be any of\n            :class:`~plexapi.library.MovieSection`, :class:`~plexapi.library.ShowSection`,\n            :class:`~plexapi.library.MusicSection`, :class:`~plexapi.library.PhotoSection`.\n        \"\"\"\n        key = '/library/sections'\n        sections = []\n        for elem in self._server.query(key):\n            for cls in (MovieSection, ShowSection, MusicSection, PhotoSection):\n                if elem.attrib.get('type') == cls.TYPE:\n                    section = cls(self._server, elem, key)\n                    self._sectionsByID[section.key] = section\n                    sections.append(section)\n        return sections"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the section that matches the specified title.", "response": "def section(self, title=None):\n        \"\"\" Returns the :class:`~plexapi.library.LibrarySection` that matches the specified title.\n\n            Parameters:\n                title (str): Title of the section to return.\n        \"\"\"\n        for section in self.sections():\n            if section.title.lower() == title.lower():\n                return section\n        raise NotFound('Invalid library section: %s' % title)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the Section object with the specified ID.", "response": "def sectionByID(self, sectionID):\n        \"\"\" Returns the :class:`~plexapi.library.LibrarySection` that matches the specified sectionID.\n\n            Parameters:\n                sectionID (str): ID of the section to return.\n        \"\"\"\n        if not self._sectionsByID or sectionID not in self._sectionsByID:\n            self.sections()\n        return self._sectionsByID[sectionID]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all(self, **kwargs):\n        items = []\n        for section in self.sections():\n            for item in section.all(**kwargs):\n                items.append(item)\n        return items", "response": "Returns a list of all media from all library sections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for items in a library section.", "response": "def search(self, title=None, libtype=None, **kwargs):\n        \"\"\" Searching within a library section is much more powerful. It seems certain\n            attributes on the media objects can be targeted to filter this search down\n            a bit, but I havent found the documentation for it.\n\n            Example: \"studio=Comedy%20Central\" or \"year=1999\" \"title=Kung Fu\" all work. Other items\n            such as actor=<id> seem to work, but require you already know the id of the actor.\n            TLDR: This is untested but seems to work. Use library section search when you can.\n        \"\"\"\n        args = {}\n        if title:\n            args['title'] = title\n        if libtype:\n            args['type'] = utils.searchType(libtype)\n        for attr, value in kwargs.items():\n            args[attr] = value\n        key = '/library/all%s' % utils.joinArgs(args)\n        return self.fetchItems(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new entry to the library.", "response": "def add(self, name='', type='', agent='', scanner='', location='', language='en', *args, **kwargs):\n        \"\"\" Simplified add for the most common options.\n\n            Parameters:\n                name (str): Name of the library\n                agent (str): Example com.plexapp.agents.imdb\n                type (str): movie, show, # check me\n                location (str): /path/to/files\n                language (str): Two letter language fx en\n                kwargs (dict): Advanced options should be passed as a dict. where the id is the key.\n\n            **Photo Preferences**\n\n                * **agent** (str): com.plexapp.agents.none\n                * **enableAutoPhotoTags** (bool): Tag photos. Default value false.\n                * **enableBIFGeneration** (bool): Enable video preview thumbnails. Default value true.\n                * **includeInGlobal** (bool): Include in dashboard. Default value true.\n                * **scanner** (str): Plex Photo Scanner\n\n            **Movie Preferences**\n\n                * **agent** (str): com.plexapp.agents.none, com.plexapp.agents.imdb, com.plexapp.agents.themoviedb\n                * **enableBIFGeneration** (bool): Enable video preview thumbnails. Default value true.\n                * **enableCinemaTrailers** (bool): Enable Cinema Trailers. Default value true.\n                * **includeInGlobal** (bool): Include in dashboard. Default value true.\n                * **scanner** (str): Plex Movie Scanner, Plex Video Files Scanner\n\n            **IMDB Movie Options** (com.plexapp.agents.imdb)\n\n                * **title** (bool): Localized titles. Default value false.\n                * **extras** (bool): Find trailers and extras automatically (Plex Pass required). Default value true.\n                * **only_trailers** (bool): Skip extras which aren't trailers. Default value false.\n                * **redband** (bool): Use red band (restricted audiences) trailers when available. Default value false.\n                * **native_subs** (bool): Include extras with subtitles in Library language. Default value false.\n                * **cast_list** (int): Cast List Source: Default value 1 Possible options: 0:IMDb,1:The Movie Database.\n                * **ratings** (int): Ratings Source, Default value 0 Possible options:\n                  0:Rotten Tomatoes, 1:IMDb, 2:The Movie Database.\n                * **summary** (int): Plot Summary Source: Default value 1 Possible options: 0:IMDb,1:The Movie Database.\n                * **country** (int): Default value 46 Possible options 0:Argentina, 1:Australia, 2:Austria,\n                  3:Belgium, 4:Belize, 5:Bolivia, 6:Brazil, 7:Canada, 8:Chile, 9:Colombia, 10:Costa Rica,\n                  11:Czech Republic, 12:Denmark, 13:Dominican Republic, 14:Ecuador, 15:El Salvador,\n                  16:France, 17:Germany, 18:Guatemala, 19:Honduras, 20:Hong Kong SAR, 21:Ireland,\n                  22:Italy, 23:Jamaica, 24:Korea, 25:Liechtenstein, 26:Luxembourg, 27:Mexico, 28:Netherlands,\n                  29:New Zealand, 30:Nicaragua, 31:Panama, 32:Paraguay, 33:Peru, 34:Portugal,\n                  35:Peoples Republic of China, 36:Puerto Rico, 37:Russia, 38:Singapore, 39:South Africa,\n                  40:Spain, 41:Sweden, 42:Switzerland, 43:Taiwan, 44:Trinidad, 45:United Kingdom,\n                  46:United States, 47:Uruguay, 48:Venezuela.\n                * **collections** (bool): Use collection info from The Movie Database. Default value false.\n                * **localart** (bool): Prefer artwork based on library language. Default value true.\n                * **adult** (bool): Include adult content. Default value false.\n                * **usage** (bool): Send anonymous usage data to Plex. Default value true.\n\n            **TheMovieDB Movie Options** (com.plexapp.agents.themoviedb)\n\n                * **collections** (bool): Use collection info from The Movie Database. Default value false.\n                * **localart** (bool): Prefer artwork based on library language. Default value true.\n                * **adult** (bool): Include adult content. Default value false.\n                * **country** (int): Country (used for release date and content rating). Default value 47 Possible\n                  options 0:, 1:Argentina, 2:Australia, 3:Austria, 4:Belgium, 5:Belize, 6:Bolivia, 7:Brazil, 8:Canada,\n                  9:Chile, 10:Colombia, 11:Costa Rica, 12:Czech Republic, 13:Denmark, 14:Dominican Republic, 15:Ecuador,\n                  16:El Salvador, 17:France, 18:Germany, 19:Guatemala, 20:Honduras, 21:Hong Kong SAR, 22:Ireland,\n                  23:Italy, 24:Jamaica, 25:Korea, 26:Liechtenstein, 27:Luxembourg, 28:Mexico, 29:Netherlands,\n                  30:New Zealand, 31:Nicaragua, 32:Panama, 33:Paraguay, 34:Peru, 35:Portugal,\n                  36:Peoples Republic of China, 37:Puerto Rico, 38:Russia, 39:Singapore, 40:South Africa, 41:Spain,\n                  42:Sweden, 43:Switzerland, 44:Taiwan, 45:Trinidad, 46:United Kingdom, 47:United States, 48:Uruguay,\n                  49:Venezuela.\n\n            **Show Preferences**\n\n                * **agent** (str): com.plexapp.agents.none, com.plexapp.agents.thetvdb, com.plexapp.agents.themoviedb\n                * **enableBIFGeneration** (bool): Enable video preview thumbnails. Default value true.\n                * **episodeSort** (int): Episode order. Default -1 Possible options: 0:Oldest first, 1:Newest first.\n                * **flattenSeasons** (int): Seasons. Default value 0 Possible options: 0:Show,1:Hide.\n                * **includeInGlobal** (bool): Include in dashboard. Default value true.\n                * **scanner** (str): Plex Series Scanner\n\n            **TheTVDB Show Options** (com.plexapp.agents.thetvdb)\n\n                * **extras** (bool): Find trailers and extras automatically (Plex Pass required). Default value true.\n                * **native_subs** (bool): Include extras with subtitles in Library language. Default value false.\n\n            **TheMovieDB Show Options** (com.plexapp.agents.themoviedb)\n\n                * **collections** (bool): Use collection info from The Movie Database. Default value false.\n                * **localart** (bool): Prefer artwork based on library language. Default value true.\n                * **adult** (bool): Include adult content. Default value false.\n                * **country** (int): Country (used for release date and content rating). Default value 47 options\n                  0:, 1:Argentina, 2:Australia, 3:Austria, 4:Belgium, 5:Belize, 6:Bolivia, 7:Brazil, 8:Canada, 9:Chile,\n                  10:Colombia, 11:Costa Rica, 12:Czech Republic, 13:Denmark, 14:Dominican Republic, 15:Ecuador,\n                  16:El Salvador, 17:France, 18:Germany, 19:Guatemala, 20:Honduras, 21:Hong Kong SAR, 22:Ireland,\n                  23:Italy, 24:Jamaica, 25:Korea, 26:Liechtenstein, 27:Luxembourg, 28:Mexico, 29:Netherlands,\n                  30:New Zealand, 31:Nicaragua, 32:Panama, 33:Paraguay, 34:Peru, 35:Portugal,\n                  36:Peoples Republic of China, 37:Puerto Rico, 38:Russia, 39:Singapore, 40:South Africa,\n                  41:Spain, 42:Sweden, 43:Switzerland, 44:Taiwan, 45:Trinidad, 46:United Kingdom, 47:United States,\n                  48:Uruguay, 49:Venezuela.\n\n            **Other Video Preferences**\n\n                * **agent** (str): com.plexapp.agents.none, com.plexapp.agents.imdb, com.plexapp.agents.themoviedb\n                * **enableBIFGeneration** (bool): Enable video preview thumbnails. Default value true.\n                * **enableCinemaTrailers** (bool): Enable Cinema Trailers. Default value true.\n                * **includeInGlobal** (bool): Include in dashboard. Default value true.\n                * **scanner** (str): Plex Movie Scanner, Plex Video Files Scanner\n\n            **IMDB Other Video Options** (com.plexapp.agents.imdb)\n\n                * **title** (bool): Localized titles. Default value false.\n                * **extras** (bool): Find trailers and extras automatically (Plex Pass required). Default value true.\n                * **only_trailers** (bool): Skip extras which aren't trailers. Default value false.\n                * **redband** (bool): Use red band (restricted audiences) trailers when available. Default value false.\n                * **native_subs** (bool): Include extras with subtitles in Library language. Default value false.\n                * **cast_list** (int): Cast List Source: Default value 1 Possible options: 0:IMDb,1:The Movie Database.\n                * **ratings** (int): Ratings Source Default value 0 Possible options:\n                  0:Rotten Tomatoes,1:IMDb,2:The Movie Database.\n                * **summary** (int): Plot Summary Source: Default value 1 Possible options: 0:IMDb,1:The Movie Database.\n                * **country** (int): Country: Default value 46 Possible options: 0:Argentina, 1:Australia, 2:Austria,\n                  3:Belgium, 4:Belize, 5:Bolivia, 6:Brazil, 7:Canada, 8:Chile, 9:Colombia, 10:Costa Rica,\n                  11:Czech Republic, 12:Denmark, 13:Dominican Republic, 14:Ecuador, 15:El Salvador, 16:France,\n                  17:Germany, 18:Guatemala, 19:Honduras, 20:Hong Kong SAR, 21:Ireland, 22:Italy, 23:Jamaica,\n                  24:Korea, 25:Liechtenstein, 26:Luxembourg, 27:Mexico, 28:Netherlands, 29:New Zealand, 30:Nicaragua,\n                  31:Panama, 32:Paraguay, 33:Peru, 34:Portugal, 35:Peoples Republic of China, 36:Puerto Rico,\n                  37:Russia, 38:Singapore, 39:South Africa, 40:Spain, 41:Sweden, 42:Switzerland, 43:Taiwan, 44:Trinidad,\n                  45:United Kingdom, 46:United States, 47:Uruguay, 48:Venezuela.\n                * **collections** (bool): Use collection info from The Movie Database. Default value false.\n                * **localart** (bool): Prefer artwork based on library language. Default value true.\n                * **adult** (bool): Include adult content. Default value false.\n                * **usage** (bool): Send anonymous usage data to Plex. Default value true.\n\n            **TheMovieDB Other Video Options** (com.plexapp.agents.themoviedb)\n\n                * **collections** (bool): Use collection info from The Movie Database. Default value false.\n                * **localart** (bool): Prefer artwork based on library language. Default value true.\n                * **adult** (bool): Include adult content. Default value false.\n                * **country** (int): Country (used for release date and content rating). Default\n                  value 47 Possible options 0:, 1:Argentina, 2:Australia, 3:Austria, 4:Belgium, 5:Belize,\n                  6:Bolivia, 7:Brazil, 8:Canada, 9:Chile, 10:Colombia, 11:Costa Rica, 12:Czech Republic,\n                  13:Denmark, 14:Dominican Republic, 15:Ecuador, 16:El Salvador, 17:France, 18:Germany,\n                  19:Guatemala, 20:Honduras, 21:Hong Kong SAR, 22:Ireland, 23:Italy, 24:Jamaica,\n                  25:Korea, 26:Liechtenstein, 27:Luxembourg, 28:Mexico, 29:Netherlands, 30:New Zealand,\n                  31:Nicaragua, 32:Panama, 33:Paraguay, 34:Peru, 35:Portugal,\n                  36:Peoples Republic of China, 37:Puerto Rico, 38:Russia, 39:Singapore,\n                  40:South Africa, 41:Spain, 42:Sweden, 43:Switzerland, 44:Taiwan, 45:Trinidad,\n                  46:United Kingdom, 47:United States, 48:Uruguay, 49:Venezuela.\n        \"\"\"\n        part = '/library/sections?name=%s&type=%s&agent=%s&scanner=%s&language=%s&location=%s' % (\n            quote_plus(name), type, agent, quote_plus(scanner), language, quote_plus(location))  # noqa E126\n        if kwargs:\n            part += urlencode(kwargs)\n        return self._server.query(part, method=self._server._session.post)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        try:\n            return self._server.query('/library/sections/%s' % self.key, method=self._server._session.delete)\n        except BadRequest:  # pragma: no cover\n            msg = 'Failed to delete library %s' % self.key\n            msg += 'You may need to allow this permission in your Plex settings.'\n            log.error(msg)\n            raise", "response": "Delete a library section."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits a library (Note: agent is required). See :class:`~plexapi.library.Library` for example usage. Parameters: kwargs (dict): Dict of settings to edit.", "response": "def edit(self, **kwargs):\n        \"\"\" Edit a library (Note: agent is required). See :class:`~plexapi.library.Library` for example usage.\n\n            Parameters:\n                kwargs (dict): Dict of settings to edit.\n        \"\"\"\n        part = '/library/sections/%s?%s' % (self.key, urlencode(kwargs))\n        self._server.query(part, method=self._server._session.put)\n\n        # Reload this way since the self.key dont have a full path, but is simply a id.\n        for s in self._server.library.sections():\n            if s.key == self.key:\n                return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, title):\n        key = '/library/sections/%s/all' % self.key\n        return self.fetchItem(key, title__iexact=title)", "response": "Returns the media item with the specified title."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all(self, sort=None, **kwargs):\n        sortStr = ''\n        if sort is not None:\n            sortStr = '?sort=' + sort\n        \n        key = '/library/sections/%s/all%s' % (self.key, sortStr)\n        return self.fetchItems(key, **kwargs)", "response": "Returns a list of all media in this library section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef analyze(self):\n        key = '/library/sections/%s/analyze' % self.key\n        self._server.query(key, method=self._server._session.put)", "response": "Run an analysis on all of the items in this library section. See\n            for more details."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef emptyTrash(self):\n        key = '/library/sections/%s/emptyTrash' % self.key\n        self._server.query(key, method=self._server._session.put)", "response": "If a section has items in the Trash, use this option to empty the Trash."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cancelUpdate(self):\n        key = '/library/sections/%s/refresh' % self.key\n        self._server.query(key, method=self._server._session.delete)", "response": "Cancels the update of this Library Section."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the preview thumbnails for items in this library.", "response": "def deleteMediaPreviews(self):\n        \"\"\" Delete the preview thumbnails for items in this library. This cannot\n            be undone. Recreating media preview files can take hours or even days.\n        \"\"\"\n        key = '/library/sections/%s/indexes' % self.key\n        self._server.query(key, method=self._server._session.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all choices for the specified category and libtype.", "response": "def listChoices(self, category, libtype=None, **kwargs):\n        \"\"\" Returns a list of :class:`~plexapi.library.FilterChoice` objects for the\n            specified category and libtype. kwargs can be any of the same kwargs in\n            :func:`plexapi.library.LibraySection.search()` to help narrow down the choices\n            to only those that matter in your current context.\n\n            Parameters:\n                category (str): Category to list choices for (genre, contentRating, etc).\n                libtype (int): Library type of item filter.\n                **kwargs (dict): Additional kwargs to narrow down the choices.\n\n            Raises:\n                :class:`plexapi.exceptions.BadRequest`: Cannot include kwarg equal to specified category.\n        \"\"\"\n        # TODO: Should this be moved to base?\n        if category in kwargs:\n            raise BadRequest('Cannot include kwarg equal to specified category: %s' % category)\n        args = {}\n        for subcategory, value in kwargs.items():\n            args[category] = self._cleanSearchFilter(subcategory, value)\n        if libtype is not None:\n            args['type'] = utils.searchType(libtype)\n        key = '/library/sections/%s/%s%s' % (self.key, category, utils.joinArgs(args))\n        return self.fetchItems(key, cls=FilterChoice)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch the library for the current library.", "response": "def search(self, title=None, sort=None, maxresults=999999, libtype=None, **kwargs):\n        \"\"\" Search the library. If there are many results, they will be fetched from the server\n            in batches of X_PLEX_CONTAINER_SIZE amounts. If you're only looking for the first <num>\n            results, it would be wise to set the maxresults option to that amount so this functions\n            doesn't iterate over all results on the server.\n\n            Parameters:\n                title (str): General string query to search for (optional).\n                sort (str): column:dir; column can be any of {addedAt, originallyAvailableAt, lastViewedAt,\n                      titleSort, rating, mediaHeight, duration}. dir can be asc or desc (optional).\n                maxresults (int): Only return the specified number of results (optional).\n                libtype (str): Filter results to a spcifiec libtype (movie, show, episode, artist,\n                    album, track; optional).\n                **kwargs (dict): Any of the available filters for the current library section. Partial string\n                        matches allowed. Multiple matches OR together. Negative filtering also possible, just add an\n                        exclamation mark to the end of filter name, e.g. `resolution!=1x1`.\n\n                        * unwatched: Display or hide unwatched content (True, False). [all]\n                        * duplicate: Display or hide duplicate items (True, False). [movie]\n                        * actor: List of actors to search ([actor_or_id, ...]). [movie]\n                        * collection: List of collections to search within ([collection_or_id, ...]). [all]\n                        * contentRating: List of content ratings to search within ([rating_or_key, ...]). [movie,tv]\n                        * country: List of countries to search within ([country_or_key, ...]). [movie,music]\n                        * decade: List of decades to search within ([yyy0, ...]). [movie]\n                        * director: List of directors to search ([director_or_id, ...]). [movie]\n                        * genre: List Genres to search within ([genere_or_id, ...]). [all]\n                        * network: List of TV networks to search within ([resolution_or_key, ...]). [tv]\n                        * resolution: List of video resolutions to search within ([resolution_or_key, ...]). [movie]\n                        * studio: List of studios to search within ([studio_or_key, ...]). [music]\n                        * year: List of years to search within ([yyyy, ...]). [all]\n\n            Raises:\n                :class:`plexapi.exceptions.BadRequest`: when applying unknown filter\n        \"\"\"\n        # cleanup the core arguments\n        args = {}\n        for category, value in kwargs.items():\n            args[category] = self._cleanSearchFilter(category, value, libtype)\n        if title is not None:\n            args['title'] = title\n        if sort is not None:\n            args['sort'] = self._cleanSearchSort(sort)\n        if libtype is not None:\n            args['type'] = utils.searchType(libtype)\n        # iterate over the results\n        results, subresults = [], '_init'\n        args['X-Plex-Container-Start'] = 0\n        args['X-Plex-Container-Size'] = min(X_PLEX_CONTAINER_SIZE, maxresults)\n        while subresults and maxresults > len(results):\n            key = '/library/sections/%s/all%s' % (self.key, utils.joinArgs(args))\n            subresults = self.fetchItems(key)\n            results += subresults[:maxresults - len(results)]\n            args['X-Plex-Container-Start'] += args['X-Plex-Container-Size']\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds new item to the current library section.", "response": "def sync(self, policy, mediaSettings, client=None, clientId=None, title=None, sort=None, libtype=None,\n             **kwargs):\n        \"\"\" Add current library section as sync item for specified device.\n            See description of :func:`~plexapi.library.LibrarySection.search()` for details about filtering / sorting\n            and :func:`plexapi.myplex.MyPlexAccount.sync()` for possible exceptions.\n\n            Parameters:\n                policy (:class:`plexapi.sync.Policy`): policy of syncing the media (how many items to sync and process\n                                                       watched media or not), generated automatically when method\n                                                       called on specific LibrarySection object.\n                mediaSettings (:class:`plexapi.sync.MediaSettings`): Transcoding settings used for the media, generated\n                                                                     automatically when method called on specific\n                                                                     LibrarySection object.\n                client (:class:`plexapi.myplex.MyPlexDevice`): sync destination, see\n                                                               :func:`plexapi.myplex.MyPlexAccount.sync`.\n                clientId (str): sync destination, see :func:`plexapi.myplex.MyPlexAccount.sync`.\n                title (str): descriptive title for the new :class:`plexapi.sync.SyncItem`, if empty the value would be\n                             generated from metadata of current media.\n                sort (str): formatted as `column:dir`; column can be any of {`addedAt`, `originallyAvailableAt`,\n                            `lastViewedAt`, `titleSort`, `rating`, `mediaHeight`, `duration`}. dir can be `asc` or\n                            `desc`.\n                libtype (str): Filter results to a specific libtype (`movie`, `show`, `episode`, `artist`, `album`,\n                               `track`).\n\n            Returns:\n                :class:`plexapi.sync.SyncItem`: an instance of created syncItem.\n\n            Raises:\n                :class:`plexapi.exceptions.BadRequest`: when the library is not allowed to sync\n\n            Example:\n\n                .. code-block:: python\n\n                    from plexapi import myplex\n                    from plexapi.sync import Policy, MediaSettings, VIDEO_QUALITY_3_MBPS_720p\n\n                    c = myplex.MyPlexAccount()\n                    target = c.device('Plex Client')\n                    sync_items_wd = c.syncItems(target.clientIdentifier)\n                    srv = c.resource('Server Name').connect()\n                    section = srv.library.section('Movies')\n                    policy = Policy('count', unwatched=True, value=1)\n                    media_settings = MediaSettings.create(VIDEO_QUALITY_3_MBPS_720p)\n                    section.sync(target, policy, media_settings, title='Next best movie', sort='rating:desc')\n\n        \"\"\"\n        from plexapi.sync import SyncItem\n\n        if not self.allowSync:\n            raise BadRequest('The requested library is not allowed to sync')\n\n        args = {}\n        for category, value in kwargs.items():\n            args[category] = self._cleanSearchFilter(category, value, libtype)\n        if sort is not None:\n            args['sort'] = self._cleanSearchSort(sort)\n        if libtype is not None:\n            args['type'] = utils.searchType(libtype)\n\n        myplex = self._server.myPlexAccount()\n        sync_item = SyncItem(self._server, None)\n        sync_item.title = title if title else self.title\n        sync_item.rootTitle = self.title\n        sync_item.contentType = self.CONTENT_TYPE\n        sync_item.metadataType = self.METADATA_TYPE\n        sync_item.machineIdentifier = self._server.machineIdentifier\n\n        key = '/library/sections/%s/all' % self.key\n\n        sync_item.location = 'library://%s/directory/%s' % (self.uuid, quote_plus(key + utils.joinArgs(args)))\n        sync_item.policy = policy\n        sync_item.mediaSettings = mediaSettings\n\n        return myplex.sync(client=client, clientId=clientId, sync_item=sync_item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync(self, videoQuality, limit=None, unwatched=False, **kwargs):\n        from plexapi.sync import Policy, MediaSettings\n        kwargs['mediaSettings'] = MediaSettings.createVideo(videoQuality)\n        kwargs['policy'] = Policy.create(limit, unwatched)\n        return super(MovieSection, self).sync(**kwargs)", "response": "Add current movie to sync item for specified device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recentlyAdded(self, libtype='episode', maxresults=50):\n        return self.search(sort='addedAt:desc', libtype=libtype, maxresults=maxresults)", "response": "Returns a list of recently added episodes from this library section."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding new music to the current Music library section.", "response": "def sync(self, bitrate, limit=None, **kwargs):\n        \"\"\" Add current Music library section as sync item for specified device.\n            See description of :func:`plexapi.library.LibrarySection.search()` for details about filtering / sorting and\n            :func:`plexapi.library.LibrarySection.sync()` for details on syncing libraries and possible exceptions.\n\n            Parameters:\n                bitrate (int): maximum bitrate for synchronized music, better use one of MUSIC_BITRATE_* values from the\n                               module :mod:`plexapi.sync`.\n                limit (int): maximum count of tracks to sync, unlimited if `None`.\n\n            Returns:\n                :class:`plexapi.sync.SyncItem`: an instance of created syncItem.\n\n            Example:\n\n                .. code-block:: python\n\n                    from plexapi import myplex\n                    from plexapi.sync import AUDIO_BITRATE_320_KBPS\n\n                    c = myplex.MyPlexAccount()\n                    target = c.device('Plex Client')\n                    sync_items_wd = c.syncItems(target.clientIdentifier)\n                    srv = c.resource('Server Name').connect()\n                    section = srv.library.section('Music')\n                    section.sync(AUDIO_BITRATE_320_KBPS, client=target, limit=100, sort='addedAt:desc',\n                                 title='New music')\n\n        \"\"\"\n        from plexapi.sync import Policy, MediaSettings\n        kwargs['mediaSettings'] = MediaSettings.createMusic(bitrate)\n        kwargs['policy'] = Policy.create(limit)\n        return super(MusicSection, self).sync(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef searchAlbums(self, title, **kwargs):\n        return self.search(libtype='photoalbum', title=title, **kwargs)", "response": "Search for an album."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef searchPhotos(self, title, **kwargs):\n        return self.search(libtype='photo', title=title, **kwargs)", "response": "Search for a photo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd current Music library section as sync item for specified device.", "response": "def sync(self, resolution, limit=None, **kwargs):\n        \"\"\" Add current Music library section as sync item for specified device.\n            See description of :func:`plexapi.library.LibrarySection.search()` for details about filtering / sorting and\n            :func:`plexapi.library.LibrarySection.sync()` for details on syncing libraries and possible exceptions.\n\n            Parameters:\n                resolution (str): maximum allowed resolution for synchronized photos, see PHOTO_QUALITY_* values in the\n                                  module :mod:`plexapi.sync`.\n                limit (int): maximum count of tracks to sync, unlimited if `None`.\n\n            Returns:\n                :class:`plexapi.sync.SyncItem`: an instance of created syncItem.\n\n            Example:\n\n                .. code-block:: python\n\n                    from plexapi import myplex\n                    from plexapi.sync import PHOTO_QUALITY_HIGH\n\n                    c = myplex.MyPlexAccount()\n                    target = c.device('Plex Client')\n                    sync_items_wd = c.syncItems(target.clientIdentifier)\n                    srv = c.resource('Server Name').connect()\n                    section = srv.library.section('Photos')\n                    section.sync(PHOTO_QUALITY_HIGH, client=target, limit=100, sort='addedAt:desc',\n                                 title='Fresh photos')\n\n        \"\"\"\n        from plexapi.sync import Policy, MediaSettings\n        kwargs['mediaSettings'] = MediaSettings.createPhoto(resolution)\n        kwargs['policy'] = Policy.create(limit)\n        return super(PhotoSection, self).sync(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loadData(self, data):\n        self._data = data\n        self.fastKey = data.attrib.get('fastKey')\n        self.key = data.attrib.get('key')\n        self.thumb = data.attrib.get('thumb')\n        self.title = data.attrib.get('title')\n        self.type = data.attrib.get('type')", "response": "Load the attribute values from Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to the specified cls with url and token.", "response": "def _connect(cls, url, token, timeout, results, i, job_is_done_event=None):\n    \"\"\" Connects to the specified cls with url and token. Stores the connection\n        information to results[i] in a threadsafe way.\n\n        Arguments:\n            cls: the class which is responsible for establishing connection, basically it's\n                 :class:`~plexapi.client.PlexClient` or :class:`~plexapi.server.PlexServer`\n            url (str): url which should be passed as `baseurl` argument to cls.__init__()\n            token (str): authentication token which should be passed as `baseurl` argument to cls.__init__()\n            timeout (int): timeout which should be passed as `baseurl` argument to cls.__init__()\n            results (list): pre-filled list for results\n            i (int): index of current job, should be less than len(results)\n            job_is_done_event (:class:`~threading.Event`): is X_PLEX_ENABLE_FAST_CONNECT is True then the\n                  event would be set as soon the connection is established\n    \"\"\"\n    starttime = time.time()\n    try:\n        device = cls(baseurl=url, token=token, timeout=timeout)\n        runtime = int(time.time() - starttime)\n        results[i] = (url, token, device, runtime)\n        if X_PLEX_ENABLE_FAST_CONNECT and job_is_done_event:\n            job_is_done_event.set()\n    except Exception as err:\n        runtime = int(time.time() - starttime)\n        log.error('%s: %s', url, err)\n        results[i] = (url, token, None, runtime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _chooseConnection(ctype, name, results):\n    # At this point we have a list of result tuples containing (url, token, PlexServer, runtime)\n    # or (url, token, None, runtime) in the case a connection could not be established.\n    for url, token, result, runtime in results:\n        okerr = 'OK' if result else 'ERR'\n        log.info('%s connection %s (%ss): %s?X-Plex-Token=%s', ctype, okerr, runtime, url, token)\n    results = [r[2] for r in results if r and r[2] is not None]\n    if results:\n        log.info('Connecting to %s: %s?X-Plex-Token=%s', ctype, results[0]._baseurl, results[0]._token)\n        return results[0]\n    raise NotFound('Unable to connect to %s: %s' % (ctype.lower(), name))", "response": "Returns the first connection from the given _connect results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _loadData(self, data):\n        self._data = data\n        self._token = logfilter.add_secret(data.attrib.get('authenticationToken'))\n        self._webhooks = []\n        self.authenticationToken = self._token\n        self.certificateVersion = data.attrib.get('certificateVersion')\n        self.cloudSyncDevice = data.attrib.get('cloudSyncDevice')\n        self.email = data.attrib.get('email')\n        self.guest = utils.cast(bool, data.attrib.get('guest'))\n        self.home = utils.cast(bool, data.attrib.get('home'))\n        self.homeSize = utils.cast(int, data.attrib.get('homeSize'))\n        self.id = data.attrib.get('id')\n        self.locale = data.attrib.get('locale')\n        self.mailing_list_status = data.attrib.get('mailing_list_status')\n        self.maxHomeSize = utils.cast(int, data.attrib.get('maxHomeSize'))\n        self.queueEmail = data.attrib.get('queueEmail')\n        self.queueUid = data.attrib.get('queueUid')\n        self.restricted = utils.cast(bool, data.attrib.get('restricted'))\n        self.scrobbleTypes = data.attrib.get('scrobbleTypes')\n        self.secure = utils.cast(bool, data.attrib.get('secure'))\n        self.thumb = data.attrib.get('thumb')\n        self.title = data.attrib.get('title')\n        self.username = data.attrib.get('username')\n        self.uuid = data.attrib.get('uuid')\n        subscription = data.find('subscription')\n\n        self.subscriptionActive = utils.cast(bool, subscription.attrib.get('active'))\n        self.subscriptionStatus = subscription.attrib.get('status')\n        self.subscriptionPlan = subscription.attrib.get('plan')\n\n        self.subscriptionFeatures = []\n        for feature in subscription.iter('feature'):\n            self.subscriptionFeatures.append(feature.attrib.get('id'))\n\n        roles = data.find('roles')\n        self.roles = []\n        if roles:\n            for role in roles.iter('role'):\n                self.roles.append(role.attrib.get('id'))\n\n        entitlements = data.find('entitlements')\n        self.entitlements = []\n        for entitlement in entitlements.iter('entitlement'):\n            self.entitlements.append(entitlement.attrib.get('id'))\n\n        # TODO: Fetch missing MyPlexAccount attributes\n        self.profile_settings = None\n        self.services = None\n        self.joined_at = None", "response": "Load attributes from Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef device(self, name):\n        for device in self.devices():\n            if device.name.lower() == name.lower():\n                return device\n        raise NotFound('Unable to find device %s' % name)", "response": "Returns the MyPlexDevice object that matches the name specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all MyPlexDevice objects connected to the server.", "response": "def devices(self):\n        \"\"\" Returns a list of all :class:`~plexapi.myplex.MyPlexDevice` objects connected to the server. \"\"\"\n        data = self.query(MyPlexDevice.key)\n        return [MyPlexDevice(self, elem) for elem in data]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the resource with the specified name.", "response": "def resource(self, name):\n        \"\"\" Returns the :class:`~plexapi.myplex.MyPlexResource` that matches the name specified.\n\n            Parameters:\n                name (str): Name to match against.\n        \"\"\"\n        for resource in self.resources():\n            if resource.name.lower() == name.lower():\n                return resource\n        raise NotFound('Unable to find resource %s' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all MyPlexResource objects connected to the server.", "response": "def resources(self):\n        \"\"\" Returns a list of all :class:`~plexapi.myplex.MyPlexResource` objects connected to the server. \"\"\"\n        data = self.query(MyPlexResource.key)\n        return [MyPlexResource(self, elem) for elem in data]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninviting a user to the specified server with the specified user.", "response": "def inviteFriend(self, user, server, sections=None, allowSync=False, allowCameraUpload=False,\n          allowChannels=False, filterMovies=None, filterTelevision=None, filterMusic=None):\n        \"\"\" Share library content with the specified user.\n\n            Parameters:\n                user (str): MyPlexUser, username, email of the user to be added.\n                server (PlexServer): PlexServer object or machineIdentifier containing the library sections to share.\n                sections ([Section]): Library sections, names or ids to be shared (default None shares all sections).\n                allowSync (Bool): Set True to allow user to sync content.\n                allowCameraUpload (Bool): Set True to allow user to upload photos.\n                allowChannels (Bool): Set True to allow user to utilize installed channels.\n                filterMovies (Dict): Dict containing key 'contentRating' and/or 'label' each set to a list of\n                    values to be filtered. ex: {'contentRating':['G'], 'label':['foo']}\n                filterTelevision (Dict): Dict containing key 'contentRating' and/or 'label' each set to a list of\n                    values to be filtered. ex: {'contentRating':['G'], 'label':['foo']}\n                filterMusic (Dict): Dict containing key 'label' set to a list of values to be filtered.\n                    ex: {'label':['foo']}\n        \"\"\"\n        username = user.username if isinstance(user, MyPlexUser) else user\n        machineId = server.machineIdentifier if isinstance(server, PlexServer) else server\n        sectionIds = self._getSectionIds(machineId, sections)\n        params = {\n            'server_id': machineId,\n            'shared_server': {'library_section_ids': sectionIds, 'invited_email': username},\n            'sharing_settings': {\n                'allowSync': ('1' if allowSync else '0'),\n                'allowCameraUpload': ('1' if allowCameraUpload else '0'),\n                'allowChannels': ('1' if allowChannels else '0'),\n                'filterMovies': self._filterDictToStr(filterMovies or {}),\n                'filterTelevision': self._filterDictToStr(filterTelevision or {}),\n                'filterMusic': self._filterDictToStr(filterMusic or {}),\n            },\n        }\n        headers = {'Content-Type': 'application/json'}\n        url = self.FRIENDINVITE.format(machineId=machineId)\n        return self.query(url, self._session.post, json=params, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the specified user from all sharing.", "response": "def removeFriend(self, user):\n        \"\"\" Remove the specified user from all sharing.\n\n            Parameters:\n                user (str): MyPlexUser, username, email of the user to be added.\n        \"\"\"\n        user = self.user(user)\n        url = self.FRIENDUPDATE if user.friend else self.REMOVEINVITE\n        url = url.format(userId=user.id)\n        return self.query(url, self._session.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateFriend(self, user, server, sections=None, removeSections=False, allowSync=None, allowCameraUpload=None,\n                     allowChannels=None, filterMovies=None, filterTelevision=None, filterMusic=None):\n        \"\"\" Update the specified user's share settings.\n\n            Parameters:\n                user (str): MyPlexUser, username, email of the user to be added.\n                server (PlexServer): PlexServer object or machineIdentifier containing the library sections to share.\n                sections: ([Section]): Library sections, names or ids to be shared (default None shares all sections).\n                removeSections (Bool): Set True to remove all shares. Supersedes sections.\n                allowSync (Bool): Set True to allow user to sync content.\n                allowCameraUpload (Bool): Set True to allow user to upload photos.\n                allowChannels (Bool): Set True to allow user to utilize installed channels.\n                filterMovies (Dict): Dict containing key 'contentRating' and/or 'label' each set to a list of\n                    values to be filtered. ex: {'contentRating':['G'], 'label':['foo']}\n                filterTelevision (Dict): Dict containing key 'contentRating' and/or 'label' each set to a list of\n                    values to be filtered. ex: {'contentRating':['G'], 'label':['foo']}\n                filterMusic (Dict): Dict containing key 'label' set to a list of values to be filtered.\n                    ex: {'label':['foo']}\n        \"\"\"\n        # Update friend servers\n        response_filters = ''\n        response_servers = ''\n        user = user if isinstance(user, MyPlexUser) else self.user(user)\n        machineId = server.machineIdentifier if isinstance(server, PlexServer) else server\n        sectionIds = self._getSectionIds(machineId, sections)\n        headers = {'Content-Type': 'application/json'}\n        # Determine whether user has access to the shared server.\n        user_servers = [s for s in user.servers if s.machineIdentifier == machineId]\n        if user_servers and sectionIds:\n            serverId = user_servers[0].id\n            params = {'server_id': machineId, 'shared_server': {'library_section_ids': sectionIds}}\n            url = self.FRIENDSERVERS.format(machineId=machineId, serverId=serverId)\n        else:\n            params = {'server_id': machineId, 'shared_server': {'library_section_ids': sectionIds,\n                \"invited_id\": user.id}}\n            url = self.FRIENDINVITE.format(machineId=machineId)\n        # Remove share sections, add shares to user without shares, or update shares\n        if not user_servers or sectionIds:\n            if removeSections is True:\n                response_servers = self.query(url, self._session.delete, json=params, headers=headers)\n            elif 'invited_id' in params.get('shared_server', ''):\n                response_servers = self.query(url, self._session.post, json=params, headers=headers)\n            else:\n                response_servers = self.query(url, self._session.put, json=params, headers=headers)\n        else:\n            log.warning('Section name, number of section object is required changing library sections')\n        # Update friend filters\n        url = self.FRIENDUPDATE.format(userId=user.id)\n        params = {}\n        if isinstance(allowSync, bool):\n            params['allowSync'] = '1' if allowSync else '0'\n        if isinstance(allowCameraUpload, bool):\n            params['allowCameraUpload'] = '1' if allowCameraUpload else '0'\n        if isinstance(allowChannels, bool):\n            params['allowChannels'] = '1' if allowChannels else '0'\n        if isinstance(filterMovies, dict):\n            params['filterMovies'] = self._filterDictToStr(filterMovies or {})  # '1' if allowChannels else '0'\n        if isinstance(filterTelevision, dict):\n            params['filterTelevision'] = self._filterDictToStr(filterTelevision or {})\n        if isinstance(allowChannels, dict):\n            params['filterMusic'] = self._filterDictToStr(filterMusic or {})\n        if params:\n            url += joinArgs(params)\n            response_filters = self.query(url, self._session.put)\n        return response_servers, response_filters", "response": "Update the user s shared settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user(self, username):\n        for user in self.users():\n            # Home users don't have email, username etc.\n            if username.lower() == user.title.lower():\n                return user\n\n            elif (user.username and user.email and user.id and username.lower() in\n                 (user.username.lower(), user.email.lower(), str(user.id))):\n                return user\n\n        raise NotFound('Unable to find user %s' % username)", "response": "Returns the user object that matches the email or username."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef users(self):\n        friends = [MyPlexUser(self, elem) for elem in self.query(MyPlexUser.key)]\n        requested = [MyPlexUser(self, elem, self.REQUESTED) for elem in self.query(self.REQUESTED)]\n        return friends + requested", "response": "Returns a list of all users connected to your account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a list of section objects or names to sectionIds needed for library sharing.", "response": "def _getSectionIds(self, server, sections):\n        \"\"\" Converts a list of section objects or names to sectionIds needed for library sharing. \"\"\"\n        if not sections: return []\n        # Get a list of all section ids for looking up each section.\n        allSectionIds = {}\n        machineIdentifier = server.machineIdentifier if isinstance(server, PlexServer) else server\n        url = self.PLEXSERVERS.replace('{machineId}', machineIdentifier)\n        data = self.query(url, self._session.get)\n        for elem in data[0]:\n            allSectionIds[elem.attrib.get('id', '').lower()] = elem.attrib.get('id')\n            allSectionIds[elem.attrib.get('title', '').lower()] = elem.attrib.get('id')\n            allSectionIds[elem.attrib.get('key', '').lower()] = elem.attrib.get('id')\n        log.debug(allSectionIds)\n        # Convert passed in section items to section ids from above lookup\n        sectionIds = []\n        for section in sections:\n            sectionKey = section.key if isinstance(section, LibrarySection) else section\n            sectionIds.append(allSectionIds[sectionKey.lower()])\n        return sectionIds"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a dictionary of filter keys to a string representation for transport.", "response": "def _filterDictToStr(self, filterDict):\n        \"\"\" Converts friend filters to a string representation for transport. \"\"\"\n        values = []\n        for key, vals in filterDict.items():\n            if key not in ('contentRating', 'label'):\n                raise BadRequest('Unknown filter key: %s', key)\n            values.append('%s=%s' % (key, '%2C'.join(vals)))\n        return '|'.join(values)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopt - in or out of sharing stuff with plex.", "response": "def optOut(self, playback=None, library=None):\n        \"\"\" Opt in or out of sharing stuff with plex.\n            See: https://www.plex.tv/about/privacy-legal/\n        \"\"\"\n        params = {}\n        if playback is not None:\n            params['optOutPlayback'] = int(playback)\n        if library is not None:\n            params['optOutLibraryStats'] = int(library)\n        url = 'https://plex.tv/api/v2/user/privacy'\n        return self.query(url, method=self._session.put, data=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef syncItems(self, client=None, clientId=None):\n        if client:\n            clientId = client.clientIdentifier\n        elif clientId is None:\n            clientId = X_PLEX_IDENTIFIER\n\n        data = self.query(SyncList.key.format(clientId=clientId))\n\n        return SyncList(self, data)", "response": "Returns an instance of : class : ~plexapi. sync. SyncList for specified client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync(self, sync_item, client=None, clientId=None):\n        if not client and not clientId:\n            clientId = X_PLEX_IDENTIFIER\n\n        if not client:\n            for device in self.devices():\n                if device.clientIdentifier == clientId:\n                    client = device\n                    break\n\n            if not client:\n                raise BadRequest('Unable to find client by clientId=%s', clientId)\n\n        if 'sync-target' not in client.provides:\n            raise BadRequest('Received client doesn`t provides sync-target')\n\n        params = {\n            'SyncItem[title]': sync_item.title,\n            'SyncItem[rootTitle]': sync_item.rootTitle,\n            'SyncItem[metadataType]': sync_item.metadataType,\n            'SyncItem[machineIdentifier]': sync_item.machineIdentifier,\n            'SyncItem[contentType]': sync_item.contentType,\n            'SyncItem[Policy][scope]': sync_item.policy.scope,\n            'SyncItem[Policy][unwatched]': str(int(sync_item.policy.unwatched)),\n            'SyncItem[Policy][value]': str(sync_item.policy.value if hasattr(sync_item.policy, 'value') else 0),\n            'SyncItem[Location][uri]': sync_item.location,\n            'SyncItem[MediaSettings][audioBoost]': str(sync_item.mediaSettings.audioBoost),\n            'SyncItem[MediaSettings][maxVideoBitrate]': str(sync_item.mediaSettings.maxVideoBitrate),\n            'SyncItem[MediaSettings][musicBitrate]': str(sync_item.mediaSettings.musicBitrate),\n            'SyncItem[MediaSettings][photoQuality]': str(sync_item.mediaSettings.photoQuality),\n            'SyncItem[MediaSettings][photoResolution]': sync_item.mediaSettings.photoResolution,\n            'SyncItem[MediaSettings][subtitleSize]': str(sync_item.mediaSettings.subtitleSize),\n            'SyncItem[MediaSettings][videoQuality]': str(sync_item.mediaSettings.videoQuality),\n            'SyncItem[MediaSettings][videoResolution]': sync_item.mediaSettings.videoResolution,\n        }\n\n        url = SyncList.key.format(clientId=client.clientIdentifier)\n        data = self.query(url, method=self._session.post, headers={\n            'Content-type': 'x-www-form-urlencoded',\n        }, params=params)\n\n        return SyncItem(self, data, None, clientIdentifier=client.clientIdentifier)", "response": "Adds specified sync item for the specified client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a str a new claim - token which you can use to register your new Plex Server instance to your account.", "response": "def claimToken(self):\n        \"\"\" Returns a str, a new \"claim-token\", which you can use to register your new Plex Server instance to your\n            account.\n            See: https://hub.docker.com/r/plexinc/pms-docker/, https://www.plex.tv/claim/\n        \"\"\"\n        response = self._session.get('https://plex.tv/api/claim/token.json', headers=self._headers(), timeout=TIMEOUT)\n        if response.status_code not in (200, 201, 204):  # pragma: no cover\n            codename = codes.get(response.status_code)[0]\n            errtext = response.text.replace('\\n', ' ')\n            log.warning('BadRequest (%s) %s %s; %s' % (response.status_code, codename, response.url, errtext))\n            raise BadRequest('(%s) %s %s; %s' % (response.status_code, codename, response.url, errtext))\n        return response.json()['token']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the attributes from the Plex XML response.", "response": "def _loadData(self, data):\n        \"\"\" Load attribute values from Plex XML response. \"\"\"\n        self._data = data\n        self.friend = self._initpath == self.key\n        self.allowCameraUpload = utils.cast(bool, data.attrib.get('allowCameraUpload'))\n        self.allowChannels = utils.cast(bool, data.attrib.get('allowChannels'))\n        self.allowSync = utils.cast(bool, data.attrib.get('allowSync'))\n        self.email = data.attrib.get('email')\n        self.filterAll = data.attrib.get('filterAll')\n        self.filterMovies = data.attrib.get('filterMovies')\n        self.filterMusic = data.attrib.get('filterMusic')\n        self.filterPhotos = data.attrib.get('filterPhotos')\n        self.filterTelevision = data.attrib.get('filterTelevision')\n        self.home = utils.cast(bool, data.attrib.get('home'))\n        self.id = utils.cast(int, data.attrib.get('id'))\n        self.protected = utils.cast(bool, data.attrib.get('protected'))\n        self.recommendationsPlaylistId = data.attrib.get('recommendationsPlaylistId')\n        self.restricted = data.attrib.get('restricted')\n        self.thumb = data.attrib.get('thumb')\n        self.title = data.attrib.get('title', '')\n        self.username = data.attrib.get('username', '')\n        self.servers = self.findItems(data, MyPlexServerShare)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _loadData(self, data):\n        self._data = data\n        self.id = utils.cast(int, data.attrib.get('id'))\n        self.serverId = utils.cast(int, data.attrib.get('serverId'))\n        self.machineIdentifier = data.attrib.get('machineIdentifier')\n        self.name = data.attrib.get('name')\n        self.lastSeenAt = utils.toDatetime(data.attrib.get('lastSeenAt'))\n        self.numLibraries = utils.cast(int, data.attrib.get('numLibraries'))\n        self.allLibraries = utils.cast(bool, data.attrib.get('allLibraries'))\n        self.owned = utils.cast(bool, data.attrib.get('owned'))\n        self.pending = utils.cast(bool, data.attrib.get('pending'))", "response": "Load the attributes from the Plex XML response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect to all known resource.", "response": "def connect(self, ssl=None, timeout=None):\n        \"\"\" Returns a new :class:`~server.PlexServer` or :class:`~client.PlexClient` object.\n            Often times there is more than one address specified for a server or client.\n            This function will prioritize local connections before remote and HTTPS before HTTP.\n            After trying to connect to all available addresses for this resource and\n            assuming at least one connection was successful, the PlexServer object is built and returned.\n\n            Parameters:\n                ssl (optional): Set True to only connect to HTTPS connections. Set False to\n                    only connect to HTTP connections. Set None (default) to connect to any\n                    HTTP or HTTPS connection.\n\n            Raises:\n                :class:`plexapi.exceptions.NotFound`: When unable to connect to any addresses for this resource.\n        \"\"\"\n        # Sort connections from (https, local) to (http, remote)\n        # Only check non-local connections unless we own the resource\n        connections = sorted(self.connections, key=lambda c: c.local, reverse=True)\n        owned_or_unowned_non_local = lambda x: self.owned or (not self.owned and not x.local)\n        https = [c.uri for c in connections if owned_or_unowned_non_local(c)]\n        http = [c.httpuri for c in connections if owned_or_unowned_non_local(c)]\n        cls = PlexServer if 'server' in self.provides else PlexClient\n        # Force ssl, no ssl, or any (default)\n        if ssl is True: connections = https\n        elif ssl is False: connections = http\n        else: connections = https + http\n        # Try connecting to all known resource connections in parellel, but\n        # only return the first server (in order) that provides a response.\n        listargs = [[cls, url, self.accessToken, timeout] for url in connections]\n        log.info('Testing %s resource connections..', len(listargs))\n        results = utils.threaded(_connect, listargs)\n        return _chooseConnection('Resource', self.name, results)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to all available addresses for this client.", "response": "def connect(self, timeout=None):\n        \"\"\" Returns a new :class:`~plexapi.client.PlexClient` or :class:`~plexapi.server.PlexServer`\n            Sometimes there is more than one address specified for a server or client.\n            After trying to connect to all available addresses for this client and assuming\n            at least one connection was successful, the PlexClient object is built and returned.\n\n            Raises:\n                :class:`plexapi.exceptions.NotFound`: When unable to connect to any addresses for this device.\n        \"\"\"\n        cls = PlexServer if 'server' in self.provides else PlexClient\n        listargs = [[cls, url, self.token, timeout] for url in self.connections]\n        log.info('Testing %s device connections..', len(listargs))\n        results = utils.threaded(_connect, listargs)\n        return _chooseConnection('Device', self.name, results)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving this device from your account.", "response": "def delete(self):\n        \"\"\" Remove this device from your account. \"\"\"\n        key = 'https://plex.tv/devices/%s.xml' % self.id\n        self._server.query(key, self._server._session.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef syncItems(self):\n        if 'sync-target' not in self.provides:\n            raise BadRequest('Requested syncList for device which do not provides sync-target')\n\n        return self._server.syncItems(client=self)", "response": "Returns an instance of plexapi. sync. SyncList for current device."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn url to the thumbnail image.", "response": "def thumbUrl(self):\n        \"\"\" Return url to for the thumbnail image. \"\"\"\n        key = self.firstAttr('thumb', 'parentThumb', 'granparentThumb')\n        return self._server.url(key, includeToken=True) if key else None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, server, item, shuffle=0, repeat=0, includeChapters=1, includeRelated=1):\n        args = {}\n        args['includeChapters'] = includeChapters\n        args['includeRelated'] = includeRelated\n        args['repeat'] = repeat\n        args['shuffle'] = shuffle\n        if item.type == 'playlist':\n            args['playlistID'] = item.ratingKey\n            args['type'] = item.playlistType\n        else:\n            uuid = item.section().uuid\n            args['key'] = item.key\n            args['type'] = item.listType\n            args['uri'] = 'library://%s/item/%s' % (uuid, item.key)\n        path = '/playQueues%s' % utils.joinArgs(args)\n        data = server.query(path, method=server._session.post)\n        c = cls(server, data, initpath=path)\n        # we manually add a key so we can pass this to playMedia\n        # since the data, does not contain a key.\n        c.key = item.key\n        return c", "response": "Create and return a new object of type ~plexapi. playqueue. PlayQueue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete all but last count episodes in show.", "response": "def keep_episodes(show, keep):\n    \"\"\" Delete all but last count episodes in show. \"\"\"\n    deleted = 0\n    print('%s Cleaning %s to %s episodes.' % (datestr(), show.title, keep))\n    sort = lambda x:x.originallyAvailableAt or x.addedAt\n    items = sorted(show.episodes(), key=sort, reverse=True)\n    for episode in items[keep:]:\n        delete_episode(episode)\n        deleted += 1\n    return deleted"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nkeep only the latest season.", "response": "def keep_season(show, keep):\n    \"\"\" Keep only the latest season. \"\"\"\n    deleted = 0\n    print('%s Cleaning %s to latest season.' % (datestr(), show.title))\n    for season in show.seasons()[:-1]:\n        for episode in season.episodes():\n            delete_episode(episode)\n            deleted += 1\n    return deleted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmimicking os. makedirs from Python 2.", "response": "def makedirs(name, mode=0o777, exist_ok=False):\n    \"\"\" Mimicks os.makedirs() from Python 3. \"\"\"\n    try:\n        os.makedirs(name, mode)\n    except OSError:\n        if not os.path.isdir(name) or not exist_ok:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef echo_to_output_stream(self, email_messages):\n        if not email_messages:\n            return\n        with self._lock:\n            try:\n                stream_created = self.open()\n                for message in email_messages:\n                    self.write_to_stream(message)\n                    self.stream.flush()  # flush after each message\n                if stream_created:\n                    self.close()\n            except Exception:\n                if not self.fail_silently:\n                    raise", "response": "Write all the messages to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a sendgrid attachment object from a django attachment object.", "response": "def _create_sg_attachment(self, django_attch):\n        \"\"\"\n        Handles the conversion between a django attachment object and a sendgrid attachment object.\n        Due to differences between sendgrid's API versions, use this method when constructing attachments to ensure\n        that attachments get properly instantiated.\n        \"\"\"\n\n        def set_prop(attachment, prop_name, value):\n            if SENDGRID_VERSION < '6':\n                setattr(attachment, prop_name, value)\n            else:\n                if prop_name == \"filename\":\n                    prop_name = \"name\"\n                setattr(attachment, 'file_{}'.format(prop_name), value)\n\n        sg_attch = Attachment()\n\n        if isinstance(django_attch, MIMEBase):\n            filename = django_attch.get_filename()\n            if not filename:\n                ext = mimetypes.guess_extension(django_attch.get_content_type())\n                filename = \"part-{0}{1}\".format(uuid.uuid4().hex, ext)\n            set_prop(sg_attch, \"filename\", filename)\n            # todo: Read content if stream?\n            set_prop(sg_attch, \"content\", django_attch.get_payload().replace(\"\\n\", \"\"))\n            set_prop(sg_attch, \"type\", django_attch.get_content_type())\n            content_id = django_attch.get(\"Content-ID\")\n            if content_id:\n                # Strip brackets since sendgrid's api adds them\n                if content_id.startswith(\"<\") and content_id.endswith(\">\"):\n                    content_id = content_id[1:-1]\n                # These 2 properties did not change in v6, so we set them the usual way\n                sg_attch.content_id = content_id\n                sg_attch.disposition = \"inline\"\n\n        else:\n            filename, content, mimetype = django_attch\n\n            set_prop(sg_attch, \"filename\", filename)\n            # Convert content from chars to bytes, in both Python 2 and 3.\n            # todo: Read content if stream?\n            if isinstance(content, str):\n                content = content.encode('utf-8')\n            set_prop(sg_attch, \"content\", base64.b64encode(content).decode())\n            set_prop(sg_attch, \"type\", mimetype)\n\n        return sg_attch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a list of path name elements return anew list of [ name type ] path components given the reference object.", "response": "def path_types(obj, path):\n    \"\"\"\n    Given a list of path name elements, return anew list of [name, type] path components, given the reference object.\n    \"\"\"\n    result = []\n    #for elem in path[:-1]:\n    cur = obj\n    for elem in path[:-1]:\n        if ((issubclass(cur.__class__, MutableMapping) and elem in cur)):\n            result.append([elem, cur[elem].__class__])\n            cur = cur[elem]\n        elif (issubclass(cur.__class__, MutableSequence) and int(elem) < len(cur)):\n            elem = int(elem)\n            result.append([elem, cur[elem].__class__])\n            cur = cur[elem]\n        else:\n            result.append([elem, dict])\n    try:\n        try:\n            result.append([path[-1], cur[path[-1]].__class__])\n        except TypeError:\n            result.append([path[-1], cur[int(path[-1])].__class__])\n    except (KeyError, IndexError):\n        result.append([path[-1], path[-1].__class__])\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(path, regex=None):\n    validated = []\n    for elem in path:\n        key = elem[0]\n        strkey = str(key)\n        if (regex and (not regex.findall(strkey))):\n            raise dpath.exceptions.InvalidKeyName(\"{} at {} does not match the expression {}\"\n                                                  \"\".format(strkey,\n                                                            validated,\n                                                            regex.pattern))\n        validated.append(strkey)", "response": "Validate that all the keys in the given list of path components are valid given that they do not contain the separator and match any optional regex given."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paths(obj, dirs=True, leaves=True, path=[], skip=False):\n    if isinstance(obj, MutableMapping):\n        # Python 3 support\n        if PY3:\n            iteritems = obj.items()\n            string_class = str\n        else: # Default to PY2\n            iteritems = obj.iteritems()\n            string_class = basestring\n\n        for (k, v) in iteritems:\n            if issubclass(k.__class__, (string_class)):\n                if (not k) and (not dpath.options.ALLOW_EMPTY_STRING_KEYS):\n                    raise dpath.exceptions.InvalidKeyName(\"Empty string keys not allowed without \"\n                                                          \"dpath.options.ALLOW_EMPTY_STRING_KEYS=True\")\n                elif (skip and k[0] == '+'):\n                    continue\n            newpath = path + [[k, v.__class__]]\n            validate(newpath)\n            if dirs:\n                yield newpath\n            for child in paths(v, dirs, leaves, newpath, skip):\n                yield child\n    elif isinstance(obj, MutableSequence):\n        for (i, v) in enumerate(obj):\n            newpath = path + [[i, v.__class__]]\n            if dirs:\n                yield newpath\n            for child in paths(obj[i], dirs, leaves, newpath, skip):\n                yield child\n    elif leaves:\n        yield path + [[obj, obj.__class__]]\n    elif not dirs:\n        yield path", "response": "Yields all paths of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmatching the path with the glob.", "response": "def match(path, glob):\n    \"\"\"Match the path with the glob.\n\n    Arguments:\n\n    path -- A list of keys representing the path.\n    glob -- A list of globs to match against the path.\n\n    \"\"\"\n    path_len = len(path)\n    glob_len = len(glob)\n\n    ss = -1\n    ss_glob = glob\n    if '**' in glob:\n        ss = glob.index('**')\n        if '**' in glob[ss + 1:]:\n            raise dpath.exceptions.InvalidGlob(\"Invalid glob. Only one '**' is permitted per glob.\")\n\n        if path_len >= glob_len:\n            # Just right or more stars.\n            more_stars = ['*'] * (path_len - glob_len + 1)\n            ss_glob = glob[:ss] + more_stars + glob[ss + 1:]\n        elif path_len == glob_len - 1:\n            # Need one less star.\n            ss_glob = glob[:ss] + glob[ss + 1:]\n\n    if path_len == len(ss_glob):\n        # Python 3 support\n        if PY3:\n            return all(map(fnmatch.fnmatch, list(map(str, paths_only(path))), list(map(str, ss_glob))))\n        else: # Default to Python 2\n            return all(map(fnmatch.fnmatch, map(str, paths_only(path)), map(str, ss_glob)))\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(obj, path, value, create_missing=True, afilter=None):\n    cur = obj\n    traversed = []\n\n    def _presence_test_dict(obj, elem):\n        return (elem[0] in obj)\n\n    def _create_missing_dict(obj, elem):\n        obj[elem[0]] = elem[1]()\n\n    def _presence_test_list(obj, elem):\n        return (int(str(elem[0])) < len(obj))\n\n    def _create_missing_list(obj, elem):\n        idx = int(str(elem[0]))\n        while (len(obj)-1) < idx:\n            obj.append(None)\n\n    def _accessor_dict(obj, elem):\n        return obj[elem[0]]\n\n    def _accessor_list(obj, elem):\n        return obj[int(str(elem[0]))]\n\n    def _assigner_dict(obj, elem, value):\n        obj[elem[0]] = value\n\n    def _assigner_list(obj, elem, value):\n        obj[int(str(elem[0]))] = value\n\n    elem = None\n    for elem in path:\n        elem_value = elem[0]\n        elem_type = elem[1]\n\n        tester = None\n        creator = None\n        accessor = None\n        assigner = None\n        if issubclass(obj.__class__, (MutableMapping)):\n            tester = _presence_test_dict\n            creator = _create_missing_dict\n            accessor = _accessor_dict\n            assigner = _assigner_dict\n        elif issubclass(obj.__class__, MutableSequence):\n            if not str(elem_value).isdigit():\n                raise TypeError(\"Can only create integer indexes in lists, \"\n                                \"not {}, in {}\".format(type(obj),\n                                                       traversed\n                                                       )\n                                )\n            tester = _presence_test_list\n            creator = _create_missing_list\n            accessor = _accessor_list\n            assigner = _assigner_list\n        else:\n            raise TypeError(\"Unable to path into elements of type {} \"\n                            \"at {}\".format(obj, traversed))\n\n        if (not tester(obj, elem)) and (create_missing):\n            creator(obj, elem)\n        elif (not tester(obj, elem)):\n            raise dpath.exceptions.PathNotFound(\n                \"{} does not exist in {}\".format(\n                    elem,\n                    traversed\n                    )\n                )\n        traversed.append(elem_value)\n        if len(traversed) < len(path):\n            obj = accessor(obj, elem)\n\n    if elem is None:\n        return\n    if (afilter and afilter(accessor(obj, elem))) or (not afilter):\n        assigner(obj, elem, value)", "response": "Set the value of the given path in the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(obj, path, view=False, afilter=None):\n    index = 0\n    path_count = len(path) - 1\n    target = obj\n    head = type(target)()\n    tail = head\n    up = None\n    for pair in path:\n        key = pair[0]\n        target = target[key]\n\n        if view:\n            if isinstance(tail, MutableMapping):\n                if issubclass(pair[1], (MutableSequence, MutableMapping)) and index != path_count:\n                    tail[key] = pair[1]()\n                else:\n                    tail[key] = target\n                up = tail\n                tail = tail[key]\n            elif issubclass(tail.__class__, MutableSequence):\n                if issubclass(pair[1], (MutableSequence, MutableMapping)) and index != path_count:\n                    tail.append(pair[1]())\n                else:\n                    tail.append(target)\n                up = tail\n                tail = tail[-1]\n\n        if not issubclass(target.__class__, (MutableSequence, MutableMapping)):\n            if (afilter and (not afilter(target))):\n                raise dpath.exceptions.FilteredValue\n\n        index += 1\n\n    if view:\n        return head\n    else:\n        return target", "response": "Get the value of the given path in the object obj."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new(obj, path, value, separator=\"/\"):\n    pathlist = __safe_path__(path, separator)\n    pathobj = dpath.path.path_types(obj, pathlist)\n    return dpath.path.set(obj, pathobj, value, create_missing=True)", "response": "Create a new node in the path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(obj, glob, separator=\"/\", afilter=None):\n    deleted = 0\n    paths = []\n    globlist = __safe_path__(glob, separator)\n    for path in _inner_search(obj, globlist, separator):\n        # These are yielded back, don't mess up the dict.\n        paths.append(path)\n\n    for path in paths:\n        cur = obj\n        prev = None\n        for item in path:\n            prev = cur\n            try:\n                cur = cur[item[0]]\n            except AttributeError as e:\n                # This only happens when we delete X/Y and the next\n                # item in the paths is X/Y/Z\n                pass\n        if (not afilter) or (afilter and afilter(prev[item[0]])):\n            prev.pop(item[0])\n        deleted += 1\n    if not deleted:\n        raise dpath.exceptions.PathNotFound(\"Could not find {0} to delete it\".format(glob))\n    return deleted", "response": "Given a path glob delete all elements that match the glob. Returns the number of objects deleted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(obj, glob, value, separator=\"/\", afilter=None):\n    changed = 0\n    globlist = __safe_path__(glob, separator)\n    for path in _inner_search(obj, globlist, separator):\n        changed += 1\n        dpath.path.set(obj, path, value, create_missing=False, afilter=afilter)\n    return changed", "response": "Sets the value of all existing elements in the document with the given glob. Returns the number of elements changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(obj, glob, separator=\"/\"):\n    ret = None\n    found = False\n    for item in search(obj, glob, yielded=True, separator=separator):\n        if ret is not None:\n            raise ValueError(\"dpath.util.get() globs must match only one leaf : %s\" % glob)\n        ret = item[1]\n        found = True\n    if found is False:\n        raise KeyError(glob)\n    return ret", "response": "Given an object which contains only one possible match for the given glob return the value for the leaf matching the given glob."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an array of all values which match the glob.", "response": "def values(obj, glob, separator=\"/\", afilter=None, dirs=True):\n    \"\"\"\n    Given an object and a path glob, return an array of all values which match\n    the glob. The arguments to this function are identical to those of search(),\n    and it is primarily a shorthand for a list comprehension over a yielded\n    search call.\n    \"\"\"\n    return [x[1] for x in dpath.util.search(obj, glob, yielded=True, separator=separator, afilter=afilter, dirs=dirs)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(obj, glob, yielded=False, separator=\"/\", afilter=None, dirs = True):\n\n    def _search_view(obj, glob, separator, afilter, dirs):\n        view = {}\n        globlist = __safe_path__(glob, separator)\n        for path in _inner_search(obj, globlist, separator, dirs=dirs):\n            try:\n                val = dpath.path.get(obj, path, afilter=afilter, view=True)\n                merge(view, val)\n            except dpath.exceptions.FilteredValue:\n                pass\n        return view\n\n    def _search_yielded(obj, glob, separator, afilter, dirs):\n        globlist = __safe_path__(glob, separator)\n        for path in _inner_search(obj, globlist, separator, dirs=dirs):\n            try:\n                val = dpath.path.get(obj, path, view=False, afilter=afilter)\n                yield (separator.join(map(str, dpath.path.paths_only(path))), val)\n            except dpath.exceptions.FilteredValue:\n                pass\n\n    if afilter is not None:\n        dirs = False\n    if yielded:\n        return _search_yielded(obj, glob, separator, afilter, dirs)\n    return _search_view(obj, glob, separator, afilter, dirs)", "response": "Given a path glob return a dictionary containing all keys\n    that matched the given glob."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch the object paths that match the glob.", "response": "def _inner_search(obj, glob, separator, dirs=True, leaves=False):\n    \"\"\"Search the object paths that match the glob.\"\"\"\n    for path in dpath.path.paths(obj, dirs, leaves, skip=True):\n        if dpath.path.match(path, glob):\n            yield path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges source into destination.", "response": "def merge(dst, src, separator=\"/\", afilter=None, flags=MERGE_ADDITIVE, _path=\"\"):\n    \"\"\"Merge source into destination. Like dict.update() but performs\n    deep merging.\n\n    flags is an OR'ed combination of MERGE_ADDITIVE, MERGE_REPLACE, or\n    MERGE_TYPESAFE.\n        * MERGE_ADDITIVE : List objects are combined onto one long\n          list (NOT a set). This is the default flag.\n        * MERGE_REPLACE : Instead of combining list objects, when\n          2 list objects are at an equal depth of merge, replace\n          the destination with the source.\n        * MERGE_TYPESAFE : When 2 keys at equal levels are of different\n          types, raise a TypeError exception. By default, the source\n          replaces the destination in this situation.\n    \"\"\"\n\n    if afilter:\n        # Having merge do its own afiltering is dumb, let search do the\n        # heavy lifting for us.\n        src = search(src, '**', afilter=afilter)\n        return merge(dst, src)\n\n    def _check_typesafe(obj1, obj2, key, path):\n        if not key in obj1:\n            return\n        elif ( (flags & MERGE_TYPESAFE == MERGE_TYPESAFE) and (type(obj1[key]) != type(obj2[key]))):\n            raise TypeError(\"Cannot merge objects of type {0} and {1} at {2}\"\n                            \"\".format(type(obj1[key]), type(obj2[key]), path))\n        elif ( (flags & MERGE_TYPESAFE != MERGE_TYPESAFE) and (type(obj1[key]) != type(obj2[key]))):\n            obj1.pop(key)\n\n    if isinstance(src, MutableMapping):\n        for (i, v) in enumerate(src):\n            _check_typesafe(dst, src, v, separator.join([_path, str(v)]))\n\n            if not v in dst:\n                dst[v] = src[v]\n            else:\n                if not isinstance(src[v], (MutableMapping, MutableSequence)):\n                    dst[v] = src[v]\n                else:\n                    merge(dst[v], src[v], afilter=afilter, flags=flags,\n                          _path=separator.join([_path, str(v)]), separator=separator)\n    elif isinstance(src, MutableSequence):\n        for (i, v) in enumerate(src):\n            _check_typesafe(dst, src, i, separator.join([_path, str(i)]))\n            dsti = i\n            if ( flags & MERGE_ADDITIVE):\n                dsti = len(dst)\n            if dsti >= len(dst):\n                dst += [None] * (dsti - (len(dst) - 1))\n            if dst[dsti] == None:\n                dst[dsti] = src[i]\n            else:\n                if not isinstance(src[i], (MutableMapping, MutableSequence)):\n                    dst[dsti] = src[i]\n                else:\n                    merge(dst[i], src[i], afilter=afilter, flags=flags,\n                          _path=separator.join([_path, str(i)]), separator=separator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(code, encoding_type='default'):\n    reversed_morsetab = {symbol: character for character,\n                         symbol in list(getattr(encoding, 'morsetab').items())}\n\n    encoding_type = encoding_type.lower()\n    allowed_encoding_type = ['default', 'binary']\n\n    if encoding_type == 'default':\n\n        # For spacing the words\n        letters = 0\n        words = 0\n        index = {}\n\n        for i in range(len(code)):\n            if code[i:i + 3] == ' ' * 3:\n                if code[i:i + 7] == ' ' * 7:\n                    words += 1\n                    letters += 1\n                    index[words] = letters\n                elif code[i + 4] and code[i - 1] != ' ':  # Check for '   '\n                    letters += 1\n\n        message = [reversed_morsetab[i] for i in code.split()]\n        for i, (word, letter) in enumerate(list(index.items())):\n            message.insert(letter + i, ' ')\n        return ''.join(message)\n\n    elif encoding_type == 'binary':\n        lst = list(map(lambda word: word.split('0' * 3), code.split('0' * 7)))\n        # list of list of character (each sub list being a word)\n        for i, word in enumerate(lst):\n            for j, bin_letter in enumerate(word):\n                lst[i][j] = binary_lookup[bin_letter]\n            lst[i] = \"\".join(lst[i])\n        s = \" \".join(lst)\n        return s\n\n    else:\n        raise NotImplementedError(\"encoding_type must be in %s\" % allowed_encoding_type)", "response": "Converts a string of morse code into English message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_samples(channels, nsamples=None):\n    '''\n    create a generator which computes the samples.\n    essentially it creates a sequence of the sum of each function in the channel\n    at each sample in the file for each channel.\n    '''\n    return islice(izip(*(imap(sum, izip(*channel)) for channel in channels)), nsamples)", "response": "create a generator which computes the samples for each channel"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites samples to a wavefile.", "response": "def write_wavefile(f, samples, nframes=None, nchannels=2, sampwidth=2, framerate=44100, bufsize=2048):\n    \"Write samples to a wavefile.\"\n    if nframes is None:\n        nframes = 0\n\n    w = wave.open(f, 'wb')\n    w.setparams((nchannels, sampwidth, framerate, nframes, 'NONE', 'not compressed'))\n\n    max_amplitude = float(int((2 ** (sampwidth * 8)) / 2) - 1)\n\n    # split the samples into chunks (to reduce memory consumption and improve performance)\n    for chunk in grouper(bufsize, samples):\n        frames = b''.join(b''.join(struct.pack('h', int(max_amplitude * sample)) for sample in channels) for channels in chunk if channels is not None)\n        w.writeframesraw(frames)\n\n    w.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sine wave value at a given sample frequency framerate and amplitude", "response": "def sine_wave(i, frequency=FREQUENCY, framerate=FRAMERATE, amplitude=AMPLITUDE):\n    \"\"\"\n    Returns value of a sine wave at a given frequency and framerate\n    for a given sample i\n    \"\"\"\n    omega = 2.0 * pi * float(frequency)\n    sine = sin(omega * (float(i) / float(framerate)))\n    return float(amplitude) * sine"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_wave(message, wpm=WPM, framerate=FRAMERATE, skip_frame=0, amplitude=AMPLITUDE, frequency=FREQUENCY, word_ref=WORD):\n    lst_bin = _encode_binary(message)\n    if amplitude > 1.0:\n        amplitude = 1.0\n    if amplitude < 0.0:\n        amplitude = 0.0\n    seconds_per_dot = _seconds_per_dot(word_ref)  # =1.2\n    for i in count(skip_frame):\n        bit = morse_bin(i=i, lst_bin=lst_bin, wpm=wpm, framerate=framerate, default_value=0.0, seconds_per_dot=seconds_per_dot)\n        sine = sine_wave(i=i, frequency=frequency, framerate=framerate, amplitude=amplitude)\n        yield sine * bit", "response": "Generate a Morse code of a given message at a given code speed wpm and framerate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value of a morse bin list at a given framerate and code speed", "response": "def morse_bin(i, lst_bin, wpm=WPM, framerate=FRAMERATE, default_value=0.0, seconds_per_dot=1.2):\n    \"\"\"\n    Returns value of a morse bin list at a given framerate  and code speed (wpm)\n    for a given sample i\n    \"\"\"\n    try:\n        return lst_bin[int(float(wpm) * float(i) / (seconds_per_dot * float(framerate)))]\n    except IndexError:\n        return default_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates a sin wave and morse code for a single node.", "response": "def calculate_wave(i, lst_bin, wpm=WPM, frequency=FREQUENCY, framerate=FRAMERATE, amplitude=AMPLITUDE, seconds_per_dot=SECONDS_PER_DOT):\n    \"\"\"\n    Returns product of a sin wave and morse code (dit, dah, silent)\n    \"\"\"\n    bit = morse_bin(i=i, lst_bin=lst_bin, wpm=wpm, framerate=framerate,\n                    default_value=0.0, seconds_per_dot=seconds_per_dot)\n    sine = sine_wave(i=i, frequency=frequency, framerate=framerate, amplitude=amplitude)\n    return bit * sine"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preview_wave(message, wpm=WPM, frequency=FREQUENCY, framerate=FRAMERATE, amplitude=AMPLITUDE, word_ref=WORD):\n    samp_nb = samples_nb(message=message, wpm=wpm, framerate=framerate, word_spaced=False)\n    import sounddevice as sd\n    lst_bin = _encode_binary(message)\n    amplitude = _limit_value(amplitude)\n    seconds_per_dot = _seconds_per_dot(word_ref)  # 1.2\n    a = [calculate_wave(i, lst_bin, wpm, frequency, framerate, amplitude, seconds_per_dot)\n         for i in range(samp_nb)]\n    sd.play(a, framerate, blocking=True)", "response": "preview wave of a message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _encode_to_morse_string(message, letter_sep):\n    def to_string(i, s):\n        if i == 0 and s == ' ':\n            return '  '\n        return s\n    return letter_sep.join([to_string(i, s) for i, s in enumerate(_encode_morse(message))])", "response": "Encode a message to Morse string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _encode_binary(message, on=1, off=0):\n    l = _encode_morse(message)\n    s = ' '.join(l)\n    l = list(s)\n    bin_conv = {'.': [on], '-': [on] * 3, ' ': [off]}\n    l = map(lambda symb: [off] + bin_conv[symb], l)\n    lst = [item for sublist in l for item in sublist]  # flatten list\n    return lst[1:]", "response": "Encode a message in binary form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes a message to binary string.", "response": "def _encode_to_binary_string(message, on, off):\n    \"\"\"\n    >>> message = \"SOS\"\n    >>> _encode_to_binary_string(message, on='1', off='0')\n    '101010001110111011100010101'\n\n    >>> message = \" SOS\"\n    >>> _encode_to_binary_string(message, on='1', off='0')\n    '0000000101010001110111011100010101'\n    \"\"\"\n    def to_string(i, s):\n        if i == 0 and s == off:\n            return off * 4\n        return s\n    return ''.join(to_string(i, s) for i, s in enumerate(_encode_binary(message, on=on, off=off)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_x_y(l, duration=1):\n    l = [0] + l + [0]\n    y = []\n    x = []\n    for i, bit in enumerate(l):\n        y.append(bit)\n        y.append(bit)\n        x.append((i - 1) * duration)\n        x.append(i * duration)\n    return x, y", "response": "Create 2 lists\n        x y = time as unit of dot ( dit )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a message in a Matplotlib Axe", "response": "def plot(message, duration=1, ax=None):\n    \"\"\"\n    Plot a message\n\n    Returns: ax a Matplotlib Axe\n    \"\"\"\n    lst_bin = _encode_binary(message)\n    x, y = _create_x_y(lst_bin, duration)\n    ax = _create_ax(ax)\n    ax.plot(x, y, linewidth=2.0)\n    delta_y = 0.1\n    ax.set_ylim(-delta_y, 1 + delta_y)\n    ax.set_yticks([0, 1])\n    delta_x = 0.5 * duration\n    ax.set_xlim(-delta_x, len(lst_bin) * duration + delta_x)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _repeat_word(word, N, word_space=\" \"):\n    message = (word_space + word) * N\n    message = message[len(word_space):]\n    return message", "response": "Return a repeated string of length N."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns Morse length of a message.", "response": "def mlength(message, N=1, word_spaced=True):\n    \"\"\"\n    Returns Morse length\n\n    >>> message = \"PARIS\"\n    >>> mlength(message)\n    50\n    >>> mlength(message, 5)\n    250\n    \"\"\"\n    message = _repeat_word(message, N)\n    if word_spaced:\n        message = message + \" E\"\n    lst_bin = _encode_binary(message)\n    N = len(lst_bin)\n    if word_spaced:\n        N -= 1  # E is one \"dit\" so we remove it\n    return N"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting from WPM word per minute to a duration of an element.", "response": "def wpm_to_duration(wpm, output='timedelta', word_ref=WORD):\n    \"\"\"\n    Convert from WPM (word per minutes) to\n    element duration\n\n    Parameters\n    ----------\n    wpm : int or float - word per minute\n    output : String - type of output\n        'timedelta'\n        'float'\n        'decimal'\n    word_ref : string - reference word (PARIS by default)\n\n    Returns\n    -------\n    duration : timedelta or float or decimal.Decimal - duration of an element\n\n    >>> wpm_to_duration(5, output='decimal')\n    Decimal('240')\n\n    >>> wpm_to_duration(5, output='float')\n    240.0\n\n    >>> wpm_to_duration(5, output='timedelta')\n    datetime.timedelta(0, 0, 240000)\n\n    >>> wpm_to_duration(15, output='decimal')\n    Decimal('80')\n\n    >>> wpm_to_duration(13, output='decimal')\n    Decimal('92.30769230769230769230769231')\n\n    >>> wpm_to_duration(5.01, output='timedelta')\n    datetime.timedelta(0, 0, 239521)\n    \"\"\"\n    N = mlength(word_ref) * wpm\n    output = output.lower()\n    allowed_output = ['decimal', 'float', 'timedelta']\n    if output == 'decimal':\n        import decimal\n        duration = 60 * 1000 / decimal.Decimal(N)\n    elif output == 'float':\n        duration = 60 * 1000 / float(N)\n    elif output == 'timedelta':\n        import datetime\n        duration = datetime.timedelta(seconds=(60 / float(N)))\n    else:\n        raise NotImplementedError(\"output must be in %s\" % allowed_output)\n    return duration"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef duration(message, wpm, output='timedelta', word_ref=WORD, word_spaced=False):\n    elt_duration = wpm_to_duration(wpm, output=output, word_ref=word_ref)\n    word_length = mlength(message, word_spaced=word_spaced)\n    return word_length * elt_duration", "response": "Calculate the duration of a message at a given code speed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the number of samples for a given word at a given framerate", "response": "def samples_nb(message, wpm, framerate=FRAMERATE, word_spaced=False):\n    \"\"\"\n    Calculate the number of samples for a given word at a given framerate (samples / seconds)\n\n    >>> samples_nb('SOS', 15)\n    23814\n    \"\"\"\n    return int(duration(message, wpm, output='float', word_spaced=word_spaced) / 1000.0 * framerate)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _numbers_units(N):\n    lst = range(1, N + 1)\n    return \"\".join(list(map(lambda i: str(i % 10), lst)))", "response": "Returns a string of numbers units."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string of N decades.", "response": "def _numbers_decades(N):\n    \"\"\"\n    >>> _numbers_decades(45)\n    '         1         2         3         4'\n    \"\"\"\n    N = N // 10\n    lst = range(1, N + 1)\n    return \"\".join(map(lambda i: \"%10s\" % i, lst))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a single character to a string in binary format.", "response": "def _char_to_string_binary(c, align=ALIGN.LEFT, padding='-'):\n    \"\"\"\n    >>> _char_to_string_binary('O', align=ALIGN.LEFT)\n    'O----------'\n\n    >>> _char_to_string_binary('O', align=ALIGN.RIGHT)\n    '----------O'\n\n    >>> _char_to_string_binary('O', align=ALIGN.CENTER)\n    '-----O-----'\n    \"\"\"\n    s_bin = mtalk.encode(c, encoding_type='binary', letter_sep=' ')\n    N = len(s_bin)\n    if align == ALIGN.LEFT:\n        s_align = \"<\"\n    elif align == ALIGN.RIGHT:\n        s_align = \">\"\n    elif align == ALIGN.CENTER:\n        s_align = \"^\"\n    else:\n        raise NotImplementedError(\"align '%s' not allowed\" % align)\n    s = \"{0:\" + padding + s_align + str(N) + \"}\"\n    return s.format(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a timing representation of a message.", "response": "def _timing_representation(message):\n    \"\"\"\n    Returns timing representation of a message like\n\n             1         2         3         4         5         6         7         8\n    12345678901234567890123456789012345678901234567890123456789012345678901234567890123456789\n\n    M------   O----------   R------   S----   E       C----------   O----------   D------   E\n    ===.===...===.===.===...=.===.=...=.=.=...=.......===.=.===.=...===.===.===...===.=.=...=\n\n    spoken reprentation:\n    M   O   R   S  E          C    O   D  E\n    -- --- .-. ... . (space) -.-. --- -.. .\n    \"\"\"\n    s = _encode_to_binary_string(message, on=\"=\", off=\".\")\n    N = len(s)\n    s += '\\n' + _numbers_decades(N)\n    s += '\\n' + _numbers_units(N)\n    s += '\\n'\n    s += '\\n' + _timing_char(message)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a string of the MORSE CODE and MORSE CODE.", "response": "def _timing_char(message):\n    \"\"\"\n    >>> message = 'MORSE CODE'\n    >>> _timing_char(message)\n    'M------   O----------   R------   S----   E       C----------   O----------   D------   E'\n    \"\"\"\n    s = ''\n    inter_symb = ' '\n    inter_char = ' ' * 3\n    inter_word = inter_symb * 7\n    for i, word in enumerate(_split_message(message)):\n        if i >= 1:\n            s += inter_word\n        for j, c in enumerate(word):\n            if j != 0:\n                s += inter_char\n            s += _char_to_string_binary(c, align=ALIGN.LEFT)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the spoken representation of the list of words in the L1 language.", "response": "def _spoken_representation_L1(lst_lst_char):\n    \"\"\"\n    >>> lst = [['M', 'O', 'R', 'S', 'E'], ['C', 'O', 'D', 'E']]\n    >>> _spoken_representation_L1(lst)\n    'M   O   R   S  E          C    O   D  E'\n\n    >>> lst = [[], ['M', 'O', 'R', 'S', 'E'], ['C', 'O', 'D', 'E']]\n    >>> _spoken_representation_L1(lst)\n    '         M   O   R   S  E          C    O   D  E'\n    \"\"\"\n    s = ''\n    inter_char = ' '\n    inter_word = inter_char * 9\n    for i, word in enumerate(lst_lst_char):\n        if i >= 1:\n            s += inter_word\n        for j, c in enumerate(word):\n            if j != 0:\n                s += inter_char\n            s += _char_to_string_morse(c)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the spoken representation of a list of words.", "response": "def _spoken_representation_L2(lst_lst_char):\n    \"\"\"\n    >>> lst = [['M', 'O', 'R', 'S', 'E'], ['C', 'O', 'D', 'E']]\n    >>> _spoken_representation_L2(lst)\n    '-- --- .-. ... . (space) -.-. --- -.. .'\n    \"\"\"\n    s = ''\n    inter_char = ' '\n    inter_word = ' (space) '\n    for i, word in enumerate(lst_lst_char):\n        if i >= 1:\n            s += inter_word\n        for j, c in enumerate(word):\n            if j != 0:\n                s += inter_char\n            s += mtalk.encoding.morsetab[c]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _spoken_representation(message):\n    lst_lst_char = _split_message(message)\n    s = _spoken_representation_L1(lst_lst_char)\n    s += '\\n' + _spoken_representation_L2(lst_lst_char)\n    return s", "response": "Returns a spoken representation of a message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display(message, wpm, element_duration, word_ref, strip=False):\n    fmt = \"{0:>8s}: '{1}'\"\n    key = \"text\"\n    if strip:\n        print(fmt.format(key, message.strip()))\n    else:\n        print(fmt.format(key, message.strip()))\n    print(fmt.format(\"morse\", mtalk.encode(message, strip=strip)))\n    print(fmt.format(\"bin\", mtalk.encode(message, encoding_type='binary', strip=strip)))\n    print(\"\")\n    print(\"{0:>8s}:\".format(\"timing\"))\n    print(_timing_representation(message))\n    print(\"\")\n    print(\"{0:>8s}:\".format(\"spoken reprentation\"))\n    print(_spoken_representation(message))\n    print(\"\")\n    print(\"code speed : %s wpm\" % wpm)\n    print(\"element_duration : %s s\" % element_duration)\n    print(\"reference word : %r\" % word_ref)\n    print(\"\")", "response": "Display a message in a morse code and a spoken code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _limit_value(value, upper=1.0, lower=0.0):\n    if value > upper:\n        return(upper)\n    if value < lower:\n        return(lower)\n    return value", "response": "Limit the value to upper and lower values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lookup(self, label):\n        ''' take a field_name_label and return the id'''\n        if self.is_child:\n            try:\n                return self._children[label]\n            except KeyError:\n                self._children[label] = ChildFieldPicklist(self.parent, \n                                                           label, \n                                                           self.field_name) \n                return self._children[label]\n        else:\n            return get_label_value(label, self._picklist)", "response": "take a field_name_label and return the id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a field_name_id and return the label", "response": "def reverse_lookup(self, value, condition=is_active):\n        ''' take a field_name_id and return the label '''\n        label = get_value_label(value, self._picklist, condition=condition)\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntyping : atws. Wrapper entity_type", "response": "def get_field_info(wrapper,entity_type):\n    'type: wrapper :atws.Wrapper'\n    fields = wrapper.new('GetFieldInfo')\n    fields.psObjectType = entity_type\n    return wrapper.GetFieldInfo(fields)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds an item that may be added to the list or Carousel", "response": "def build_item(\n    title, key=None, synonyms=None, description=None, img_url=None, alt_text=None\n):\n    \"\"\"Builds an item that may be added to List or Carousel\"\"\"\n    item = {\n        \"info\": {\"key\": key or title, \"synonyms\": synonyms or []},\n        \"title\": title,\n        \"description\": description,\n        \"image\": {\n            \"imageUri\": img_url or \"\",\n            \"accessibilityText\": alt_text or \"{} img\".format(title),\n        },\n    }\n    return item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef suggest(self, *replies):\n        chips = []\n        for r in replies:\n            chips.append({\"title\": r})\n\n        # NOTE: both of these formats work in the dialogflow console,\n        # but only the first (suggestions) appears in actual Google Assistant\n\n        # native chips for GA\n        self._messages.append(\n            {\"platform\": \"ACTIONS_ON_GOOGLE\", \"suggestions\": {\"suggestions\": chips}}\n        )\n\n        # # quick replies for other platforms\n        # self._messages.append(\n        #     {\n        #         \"platform\": \"ACTIONS_ON_GOOGLE\",\n        #         \"quickReplies\": {\"title\": None, \"quickReplies\": replies},\n        #     }\n        # )\n\n        return self", "response": "Use suggestion chips to hint at responses to continue or pivot the conversation"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npresents a chip similar to suggestion but links to a url", "response": "def link_out(self, name, url):\n        \"\"\"Presents a chip similar to suggestion, but instead links to a url\"\"\"\n        self._messages.append(\n            {\n                \"platform\": \"ACTIONS_ON_GOOGLE\",\n                \"linkOutSuggestion\": {\"destinationName\": name, \"uri\": url},\n            }\n        )\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a list of items for the user with a vertical list of multiple items.", "response": "def build_list(self, title=None, items=None):\n        \"\"\"Presents the user with a vertical list of multiple items.\n\n        Allows the user to select a single item.\n        Selection generates a user query containing the title of the list item\n\n        *Note* Returns a completely new object,\n        and does not modify the existing response object\n        Therefore, to add items, must be assigned to new variable\n        or call the method directly after initializing list\n\n        example usage:\n\n            simple = ask('I speak this text')\n            mylist = simple.build_list('List Title')\n            mylist.add_item('Item1', 'key1')\n            mylist.add_item('Item2', 'key2')\n\n            return mylist\n\n        Arguments:\n            title {str} -- Title displayed at top of list card\n\n        Returns:\n            _ListSelector -- [_Response object exposing the add_item method]\n\n        \"\"\"\n\n        list_card = _ListSelector(\n            self._speech, display_text=self._display_text, title=title, items=items\n        )\n        return list_card"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_item(self, title, key, synonyms=None, description=None, img_url=None):\n        item = build_item(title, key, synonyms, description, img_url)\n        self._items.append(item)\n        return self", "response": "Adds an item to a list or carousel card."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of intent json objects", "response": "def agent_intents(self):\n        \"\"\"Returns a list of intent json objects\"\"\"\n        endpoint = self._intent_uri()\n        intents = self._get(endpoint)  # should be list of dicts\n        if isinstance(intents, dict):  # if error: intents = {status: {error}}\n            raise Exception(intents[\"status\"])\n\n        return [Intent(intent_json=i) for i in intents]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the intent object with the given intent_id", "response": "def get_intent(self, intent_id):\n        \"\"\"Returns the intent object with the given intent_id\"\"\"\n        endpoint = self._intent_uri(intent_id=intent_id)\n        return self._get(endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_intent(self, intent_json):\n        endpoint = self._intent_uri()\n        return self._post(endpoint, data=intent_json)", "response": "Sends post request to create a new intent"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a put request to update the intent with intent_id", "response": "def put_intent(self, intent_id, intent_json):\n        \"\"\"Send a put request to update the intent with intent_id\"\"\"\n        endpoint = self._intent_uri(intent_id)\n        return self._put(endpoint, intent_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of intent json objects", "response": "def agent_entities(self):\n        \"\"\"Returns a list of intent json objects\"\"\"\n        endpoint = self._entity_uri()\n        entities = self._get(endpoint)  # should be list of dicts\n        if isinstance(entities, dict):  # error: entities = {status: {error}}\n            raise Exception(entities[\"status\"])\n\n        return [Entity(entity_json=i) for i in entities if isinstance(i, dict)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind our instance of Assistant and navigating Local s and possible blueprints.", "response": "def find_assistant():  # Taken from Flask-ask courtesy of @voutilad\n    \"\"\"\n    Find our instance of Assistant, navigating Local's and possible blueprints.\n\n    Note: This only supports returning a reference to the first instance\n    of Assistant found.\n    \"\"\"\n    if hasattr(current_app, \"assist\"):\n        return getattr(current_app, \"assist\")\n    else:\n        if hasattr(current_app, \"blueprints\"):\n            blueprints = getattr(current_app, \"blueprints\")\n            for blueprint_name in blueprints:\n                if hasattr(blueprints[blueprint_name], \"assist\"):\n                    return getattr(blueprints[blueprint_name], \"assist\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes a Flask Blueprint instance with the given path.", "response": "def init_blueprint(self, blueprint, path=\"templates.yaml\"):\n        \"\"\"Initialize a Flask Blueprint, similar to init_app, but without the access\n        to the application config.\n\n        Keyword Arguments:\n            blueprint {Flask Blueprint} -- Flask Blueprint instance to initialize\n                                        (Default: {None})\n            path {str} -- path to templates yaml file, relative to Blueprint\n                      (Default: {'templates.yaml'})\n        \"\"\"\n        if self._route is not None:\n            raise TypeError(\"route cannot be set when using blueprints!\")\n\n        # we need to tuck our reference to this Assistant instance\n        # into the blueprint object and find it later!\n        blueprint.assist = self\n\n        # BlueprintSetupState.add_url_rule gets called underneath the covers and\n        # concats the rule string, so we should set to an empty string to allow\n        # Blueprint('blueprint_api', __name__, url_prefix=\"/assist\") to result in\n        # exposing the rule at \"/assist\" and not \"/assist/\".\n        blueprint.add_url_rule(\n            \"\", view_func=self._flask_assitant_view_func, methods=[\"POST\"]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef action(\n        self,\n        intent_name,\n        is_fallback=False,\n        mapping={},\n        convert={},\n        default={},\n        with_context=[],\n        events=[],\n        *args,\n        **kw\n    ):\n        \"\"\"Decorates an intent_name's Action view function.\n\n            The wrapped function is called when a request with the\n            given intent_name is recieved along with all required parameters.\n        \"\"\"\n\n        def decorator(f):\n            action_funcs = self._intent_action_funcs.get(intent_name, [])\n            action_funcs.append(f)\n            self._intent_action_funcs[intent_name] = action_funcs\n\n            self._intent_mappings[intent_name] = mapping\n            self._intent_converts[intent_name] = convert\n            self._intent_defaults[intent_name] = default\n            self._intent_fallbacks[intent_name] = is_fallback\n            self._intent_events[intent_name] = events\n            self._register_context_to_func(intent_name, with_context)\n\n            @wraps(f)\n            def wrapper(*args, **kw):\n                self._flask_assitant_view_func(*args, **kw)\n\n            return f\n\n        return decorator", "response": "Decorates an intent_name s Action view function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecorate a function to prompt for an action s required parameter.", "response": "def prompt_for(self, next_param, intent_name):\n        \"\"\"Decorates a function to prompt for an action's required parameter.\n\n        The wrapped function is called if next_param was not recieved with the given intent's\n        request and is required for the fulfillment of the intent's action.\n\n        Arguments:\n            next_param {str} -- name of the parameter required for action function\n            intent_name {str} -- name of the intent the dependent action belongs to\n        \"\"\"\n\n        def decorator(f):\n            prompts = self._intent_prompts.get(intent_name)\n            if prompts:\n                prompts[next_param] = f\n            else:\n                self._intent_prompts[intent_name] = {}\n                self._intent_prompts[intent_name][next_param] = f\n\n            @wraps(f)\n            def wrapper(*args, **kw):\n                self._flask_assitant_view_func(*args, **kw)\n\n            return f\n\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _context_views(self):\n        possible_views = []\n\n        for func in self._func_contexts:\n            if self._context_satified(func):\n                logger.debug(\"{} context conditions satisified\".format(func.__name__))\n                possible_views.append(func)\n        return possible_views", "response": "Returns a list of view functions that are available for the context requirements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_assistant(filename):\n\n    agent_name = os.path.splitext(filename)[0]\n\n    try:\n        agent_module = import_with_3(\n            agent_name, os.path.join(os.getcwd(), filename))\n\n    except ImportError:\n        agent_module = import_with_2(\n            agent_name, os.path.join(os.getcwd(), filename))\n\n    for name, obj in agent_module.__dict__.items():\n        if isinstance(obj, Assistant):\n            return obj", "response": "Imports a module from filename as a string returns the contained Assistant object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nannotating a given word for the UserSays data field of an Intent object.", "response": "def _annotate_params(self, word):\n        \"\"\"Annotates a given word for the UserSays data field of an Intent object.\n\n        Annotations are created using the entity map within the user_says.yaml template.\n        \"\"\"\n        annotation = {}\n        annotation['text'] = word\n        annotation['meta'] = '@' + self.entity_map[word]\n        annotation['alias'] = self.entity_map[word].replace('sys.', '')\n        annotation['userDefined'] = True\n        self.data.append(annotation)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of Intent objects created from the assistant s acion functions", "response": "def app_intents(self):\n        \"\"\"Returns a list of Intent objects created from the assistant's acion functions\"\"\"\n        from_app = []\n        for intent_name in self.assist._intent_action_funcs:\n            intent = self.build_intent(intent_name)\n            from_app.append(intent)\n        return from_app"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild an Intent object of the given name", "response": "def build_intent(self, intent_name):\n        \"\"\"Builds an Intent object of the given name\"\"\"\n        # TODO: contexts\n        is_fallback = self.assist._intent_fallbacks[intent_name]\n        contexts = self.assist._required_contexts[intent_name]\n        events = self.assist._intent_events[intent_name]\n        new_intent = Intent(intent_name, fallback_intent=is_fallback, contexts=contexts, events=events)\n        self.build_action(new_intent)\n        self.build_user_says(new_intent)  # TODO\n        return new_intent"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_params(self, intent_name):\n\n        params = []\n        action_func = self.assist._intent_action_funcs[intent_name][0]\n        argspec = inspect.getargspec(action_func)\n        param_entity_map = self.assist._intent_mappings.get(intent_name)\n\n        args, defaults = argspec.args, argspec.defaults\n        default_map = {}\n        if defaults:\n            default_map = dict(zip(args[-len(defaults):], defaults))\n\n        # import ipdb; ipdb.set_trace()\n        for arg in args:\n            param_info = {}\n\n            param_entity = param_entity_map.get(arg, arg)\n            param_name = param_entity.replace('sys.', '')\n            # param_name = arg\n\n            param_info['name'] = param_name\n            param_info['value'] = '$' + param_name\n            param_info['dataType'] = '@' + param_entity\n            param_info['prompts'] = []  # TODO: fill in provided prompts\n            param_info['required'] = arg not in default_map\n            param_info['isList'] = isinstance(default_map.get(arg), list)\n            if param_info['isList']:\n                param_info['defaultValue'] = ''\n            else:\n                param_info['defaultValue'] = default_map.get(arg, '')\n\n            params.append(param_info)\n        return params", "response": "Parses the params from an intent s action decorator and view function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push_intent(self, intent):\n        if intent.id:\n            print('Updating {} intent'.format(intent.name))\n            self.update(intent)\n        else:\n            print('Registering {} intent'.format(intent.name))\n            intent = self.register(intent)\n        return intent", "response": "Registers or updates an intent and returns the intent_json with an ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new intent and returns the Intent object with an ID", "response": "def register(self, intent):\n        \"\"\"Registers a new intent and returns the Intent object with an ID\"\"\"\n        response = self.api.post_intent(intent.serialize)\n        print(response)\n        print()\n        if response['status']['code'] == 200:\n            intent.id = response['id']\n        elif response['status']['code'] == 409: # intent already exists\n            intent.id = next(i.id for i in self.api.agent_intents if i.name == intent.name)\n            self.update(intent)\n        return intent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self, entity):\n        response = self.api.post_entity(entity.serialize)\n        print(response)\n        print()\n        if response['status']['code'] == 200:\n            entity.id = response['id']\n        if response['status']['code'] == 409: # entity already exists\n            entity.id = next(i.id for i in self.api.agent_entities if i.name == entity.name)\n            self.update(entity)\n        return entity", "response": "Registers a new entity and returns the entity object with an ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister or updates an entity and returns the entity_json with an ID", "response": "def push_entity(self, entity):\n        \"\"\"Registers or updates an entity and returns the entity_json with an ID\"\"\"\n        if entity.id:\n            print('Updating {} entity'.format(entity.name))\n            self.update(entity)\n        else:\n            print('Registering {} entity'.format(entity.name))\n            entity = self.register(entity)\n        return entity"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_state(self, entity_id, new_state, **kwargs):\n        \"Updates or creates the current state of an entity.\"\n        return remote.set_state(self.api, new_state, **kwargs)", "response": "Updates or creates the current state of an entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given entity has the given state", "response": "def is_state(self, entity_id, state):\n        \"\"\"Checks if the entity has the given state\"\"\"\n        return remote.is_state(self.api, entity_id, state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the ETag of the resource.", "response": "def etag(self, etag):\n        \"\"\"\n        Set the ETag of the resource.\n\n        :param etag: the ETag\n        \"\"\"\n        if not isinstance(etag, bytes):\n            etag = bytes(etag, \"utf-8\")\n        self._etag.append(etag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the payload of the resource according to the content type specified by required_content_type or text / plain by default.", "response": "def payload(self):\n        \"\"\"\n        Get the payload of the resource according to the content type specified by required_content_type or\n        \"text/plain\" by default.\n\n        :return: the payload.\n        \"\"\"\n        if self._content_type is not None:\n            try:\n                return self._payload[self._content_type]\n            except KeyError:\n                raise KeyError(\"Content-Type not available\")\n        else:\n\n            if defines.Content_types[\"text/plain\"] in self._payload:\n                return self._payload[defines.Content_types[\"text/plain\"]]\n            else:\n                val = list(self._payload.keys())\n                return val[0], self._payload[val[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the payload of the resource.", "response": "def payload(self, p):\n        \"\"\"\n        Set the payload of the resource.\n\n        :param p: the new payload\n        \"\"\"\n        if isinstance(p, tuple):\n            k = p[0]\n            v = p[1]\n            self.actual_content_type = k\n            self._payload[k] = v\n        else:\n            self._payload = {defines.Content_types[\"text/plain\"]: p}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the CoRE Link Format ct attribute of the resource.", "response": "def content_type(self):\n        \"\"\"\n        Get the CoRE Link Format ct attribute of the resource.\n\n        :return: the CoRE Link Format ct attribute\n        \"\"\"\n        value = \"\"\n        lst = self._attributes.get(\"ct\")\n        if lst is not None and len(lst) > 0:\n            value = \"ct=\"\n            for v in lst:\n                value += str(v) + \" \"\n        if len(value) > 0:\n            value = value[:-1]\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef content_type(self, lst):\n        value = []\n        if isinstance(lst, str):\n            ct = defines.Content_types[lst]\n            self.add_content_type(ct)\n        elif isinstance(lst, list):\n            for ct in lst:\n                self.add_content_type(ct)", "response": "Set the content type attribute of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a CoRE Link Format ct attribute to the resource.", "response": "def add_content_type(self, ct):\n        \"\"\"\n        Add a CoRE Link Format ct attribute to the resource.\n\n        :param ct: the CoRE Link Format ct attribute\n        \"\"\"\n        lst = self._attributes.get(\"ct\")\n        if lst is None:\n            lst = []\n        if isinstance(ct, str):\n            ct = defines.Content_types[ct]\n        lst.append(ct)\n        self._attributes[\"ct\"] = lst"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_type(self):\n        value = \"rt=\"\n        lst = self._attributes.get(\"rt\")\n        if lst is None:\n            value = \"\"\n        else:\n            value += \"\\\"\" + str(lst) + \"\\\"\"\n        return value", "response": "Get the CoRE Link Format rt attribute of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the CoRE Link Format rt attribute of the resource.", "response": "def resource_type(self, rt):\n        \"\"\"\n        Set the CoRE Link Format rt attribute of the resource.\n\n        :param rt: the CoRE Link Format rt attribute\n        \"\"\"\n        if not isinstance(rt, str):\n            rt = str(rt)\n        self._attributes[\"rt\"] = rt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the CoRE Link Format if attribute of the resource.", "response": "def interface_type(self):\n        \"\"\"\n        Get the CoRE Link Format if attribute of the resource.\n\n        :return: the CoRE Link Format if attribute\n        \"\"\"\n        value = \"if=\"\n        lst = self._attributes.get(\"if\")\n        if lst is None:\n            value = \"\"\n        else:\n            value += \"\\\"\" + str(lst) + \"\\\"\"\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the CoRE Link Format if attribute of the resource.", "response": "def interface_type(self, ift):\n        \"\"\"\n        Set the CoRE Link Format if attribute of the resource.\n\n        :param ift: the CoRE Link Format if attribute\n        \"\"\"\n        if not isinstance(ift, str):\n            ift = str(ift)\n        self._attributes[\"if\"] = ift"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the maximum size estimated attribute of the resource.", "response": "def maximum_size_estimated(self):\n        \"\"\"\n        Get the CoRE Link Format sz attribute of the resource.\n\n        :return: the CoRE Link Format sz attribute\n        \"\"\"\n        value = \"sz=\"\n        lst = self._attributes.get(\"sz\")\n        if lst is None:\n            value = \"\"\n        else:\n            value += \"\\\"\" + str(lst) + \"\\\"\"\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef maximum_size_estimated(self, sz):\n        if not isinstance(sz, str):\n            sz = str(sz)\n        self._attributes[\"sz\"] = sz", "response": "Set the CoRE Link Format sz attribute of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_resource(self, request, res):\n        res.location_query = request.uri_query\n        res.payload = (request.content_type, request.payload)\n        return res", "response": "Helper function to initialize a new resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edit_resource(self, request):\n        self.location_query = request.uri_query\n        self.payload = (request.content_type, request.payload)", "response": "This function is used to edit the content type and payload of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the cache is full.", "response": "def is_full(self):\n        \"\"\"\n        :return:\n        \"\"\"\n        if self.cache.currsize == self.cache.maxsize:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receive_request(self, transaction):\n        if transaction.request.block2 is not None:\n            host, port = transaction.request.source\n            key_token = hash(str(host) + str(port) + str(transaction.request.token))\n            num, m, size = transaction.request.block2\n            if key_token in self._block2_receive:\n                self._block2_receive[key_token].num = num\n                self._block2_receive[key_token].size = size\n                self._block2_receive[key_token].m = m\n                del transaction.request.block2\n            else:\n                # early negotiation\n                byte = 0\n                self._block2_receive[key_token] = BlockItem(byte, num, m, size)\n                del transaction.request.block2\n\n        elif transaction.request.block1 is not None:\n            # POST or PUT\n            host, port = transaction.request.source\n            key_token = hash(str(host) + str(port) + str(transaction.request.token))\n            num, m, size = transaction.request.block1\n            if key_token in self._block1_receive:\n                content_type = transaction.request.content_type\n                if num != self._block1_receive[key_token].num \\\n                        or content_type != self._block1_receive[key_token].content_type:\n                    # Error Incomplete\n                    return self.incomplete(transaction)\n                self._block1_receive[key_token].payload += transaction.request.payload\n            else:\n                # first block\n                if num != 0:\n                    # Error Incomplete\n                    return self.incomplete(transaction)\n                content_type = transaction.request.content_type\n                self._block1_receive[key_token] = BlockItem(size, num, m, size, transaction.request.payload,\n                                                            content_type)\n\n            if m == 0:\n                transaction.request.payload = self._block1_receive[key_token].payload\n                # end of blockwise\n                del transaction.request.block1\n                transaction.block_transfer = False\n                del self._block1_receive[key_token]\n                return transaction\n            else:\n                # Continue\n                transaction.block_transfer = True\n                transaction.response = Response()\n                transaction.response.destination = transaction.request.source\n                transaction.response.token = transaction.request.token\n                transaction.response.code = defines.Codes.CONTINUE.number\n                transaction.response.block1 = (num, m, size)\n\n            num += 1\n            byte = size\n            self._block1_receive[key_token].byte = byte\n            self._block1_receive[key_token].num = num\n            self._block1_receive[key_token].size = size\n            self._block1_receive[key_token].m = m\n\n        return transaction", "response": "Handles the Blocks option in a incoming request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling the Blocks option in a incoming response.", "response": "def receive_response(self, transaction):\n        \"\"\"\n        Handles the Blocks option in a incoming response.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the response\n        :rtype : Transaction\n        :return: the edited transaction\n        \"\"\"\n        host, port = transaction.response.source\n        key_token = hash(str(host) + str(port) + str(transaction.response.token))\n        if key_token in self._block1_sent and transaction.response.block1 is not None:\n            item = self._block1_sent[key_token]\n            transaction.block_transfer = True\n            if item.m == 0:\n                transaction.block_transfer = False\n                del transaction.request.block1\n                return transaction\n            n_num, n_m, n_size = transaction.response.block1\n            if n_num != item.num:  # pragma: no cover\n                logger.warning(\"Blockwise num acknowledged error, expected \" + str(item.num) + \" received \" +\n                               str(n_num))\n                return None\n            if n_size < item.size:\n                logger.debug(\"Scale down size, was \" + str(item.size) + \" become \" + str(n_size))\n                item.size = n_size\n            request = transaction.request\n            del request.mid\n            del request.block1\n            request.payload = item.payload[item.byte: item.byte+item.size]\n            item.num += 1\n            item.byte += item.size\n            if len(item.payload) <= item.byte:\n                item.m = 0\n            else:\n                item.m = 1\n            request.block1 = (item.num, item.m, item.size)\n        elif transaction.response.block2 is not None:\n\n            num, m, size = transaction.response.block2\n            if m == 1:\n                transaction.block_transfer = True\n                if key_token in self._block2_sent:\n                    item = self._block2_sent[key_token]\n                    if num != item.num:  # pragma: no cover\n                        logger.error(\"Receive unwanted block\")\n                        return self.error(transaction, defines.Codes.REQUEST_ENTITY_INCOMPLETE.number)\n                    if item.content_type is None:\n                        item.content_type = transaction.response.content_type\n                    if item.content_type != transaction.response.content_type:  # pragma: no cover\n                        logger.error(\"Content-type Error\")\n                        return self.error(transaction, defines.Codes.UNSUPPORTED_CONTENT_FORMAT.number)\n                    item.byte += size\n                    item.num = num + 1\n                    item.size = size\n                    item.m = m\n                    item.payload += transaction.response.payload\n                else:\n                    item = BlockItem(size, num + 1, m, size, transaction.response.payload,\n                                     transaction.response.content_type)\n                    self._block2_sent[key_token] = item\n                request = transaction.request\n                del request.mid\n                del request.block2\n                request.block2 = (item.num, 0, item.size)\n            else:\n                transaction.block_transfer = False\n                if key_token in self._block2_sent:\n                    if self._block2_sent[key_token].content_type != transaction.response.content_type:  # pragma: no cover\n                        logger.error(\"Content-type Error\")\n                        return self.error(transaction, defines.Codes.UNSUPPORTED_CONTENT_FORMAT.number)\n                    transaction.response.payload = self._block2_sent[key_token].payload + transaction.response.payload\n                    del self._block2_sent[key_token]\n        else:\n            transaction.block_transfer = False\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the Blocks option in a outgoing response.", "response": "def send_response(self, transaction):\n        \"\"\"\n        Handles the Blocks option in a outgoing response.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the response\n        :rtype : Transaction\n        :return: the edited transaction\n        \"\"\"\n        host, port = transaction.request.source\n        key_token = hash(str(host) + str(port) + str(transaction.request.token))\n        if (key_token in self._block2_receive and transaction.response.payload is not None) or \\\n                (transaction.response.payload is not None and len(transaction.response.payload) > defines.MAX_PAYLOAD):\n            if key_token in self._block2_receive:\n\n                byte = self._block2_receive[key_token].byte\n                size = self._block2_receive[key_token].size\n                num = self._block2_receive[key_token].num\n\n            else:\n                byte = 0\n                num = 0\n                size = defines.MAX_PAYLOAD\n                m = 1\n\n                self._block2_receive[key_token] = BlockItem(byte, num, m, size)\n\n            if len(transaction.response.payload) > (byte + size):\n                m = 1\n            else:\n                m = 0\n            transaction.response.payload = transaction.response.payload[byte:byte + size]\n            del transaction.response.block2\n            transaction.response.block2 = (num, m, size)\n\n            self._block2_receive[key_token].byte += size\n            self._block2_receive[key_token].num += 1\n            if m == 0:\n                del self._block2_receive[key_token]\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_request(self, request):\n        assert isinstance(request, Request)\n        if request.block1 or (request.payload is not None and len(request.payload) > defines.MAX_PAYLOAD):\n            host, port = request.destination\n            key_token = hash(str(host) + str(port) + str(request.token))\n            if request.block1:\n                num, m, size = request.block1\n            else:\n                num = 0\n                m = 1\n                size = defines.MAX_PAYLOAD\n\n            self._block1_sent[key_token] = BlockItem(size, num, m, size, request.payload, request.content_type)\n            request.payload = request.payload[0:size]\n            del request.block1\n            request.block1 = (num, m, size)\n        elif request.block2:\n            host, port = request.destination\n            key_token = hash(str(host) + str(port) + str(request.token))\n            num, m, size = request.block2\n            item = BlockItem(size, num, m, size, \"\", None)\n            self._block2_sent[key_token] = item\n            return request\n        return request", "response": "Handles the Blocks option in a outgoing request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnotifying the blockwise exchange that the response contains an incomplete response", "response": "def incomplete(transaction):\n        \"\"\"\n        Notifies incomplete blockwise exchange.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the response\n        :rtype : Transaction\n        :return: the edited transaction\n        \"\"\"\n        transaction.block_transfer = True\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n        transaction.response.code = defines.Codes.REQUEST_ENTITY_INCOMPLETE.number\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef error(transaction, code):  # pragma: no cover\n        transaction.block_transfer = True\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.type = defines.Types[\"RST\"]\n        transaction.response.token = transaction.request.token\n        transaction.response.code = code\n        return transaction", "response": "Notifies generic error on blockwise exchange."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd itself to the observing list", "response": "def send_request(self, request):\n        \"\"\"\n        Add itself to the observing list\n\n        :param request: the request\n        :return: the request unmodified\n        \"\"\"\n        if request.observe == 0:\n            # Observe request\n            host, port = request.destination\n            key_token = hash(str(host) + str(port) + str(request.token))\n\n            self._relations[key_token] = ObserveItem(time.time(), None, True, None)\n\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_response(self, transaction):\n        host, port = transaction.response.source\n        key_token = hash(str(host) + str(port) + str(transaction.response.token))\n        if key_token in self._relations and transaction.response.type == defines.Types[\"CON\"]:\n            transaction.notification = True\n        return transaction", "response": "Sets the notification s parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmanages the observe option in the request end eventually initialize the client for adding to the list of observers or remove from the list of observers.", "response": "def receive_request(self, transaction):\n        \"\"\"\n        Manage the observe option in the request end eventually initialize the client for adding to\n        the list of observers or remove from the list.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :rtype : Transaction\n        :return: the modified transaction\n        \"\"\"\n        if transaction.request.observe == 0:\n            # Observe request\n            host, port = transaction.request.source\n            key_token = hash(str(host) + str(port) + str(transaction.request.token))\n            non_counter = 0\n            if key_token in self._relations:\n                # Renew registration\n                allowed = True\n            else:\n                allowed = False\n            self._relations[key_token] = ObserveItem(time.time(), non_counter, allowed, transaction)\n        elif transaction.request.observe == 1:\n            host, port = transaction.request.source\n            key_token = hash(str(host) + str(port) + str(transaction.request.token))\n            logger.info(\"Remove Subscriber\")\n            try:\n                del self._relations[key_token]\n            except KeyError:\n                pass\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receive_empty(self, empty, transaction):\n        if empty.type == defines.Types[\"RST\"]:\n            host, port = transaction.request.source\n            key_token = hash(str(host) + str(port) + str(transaction.request.token))\n            logger.info(\"Remove Subscriber\")\n            try:\n                del self._relations[key_token]\n            except KeyError:\n                pass\n            transaction.completed = True\n        return transaction", "response": "Manage the observe feature to remove a client in case of a RST message receveide in reply to a notification."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends the response to the observer.", "response": "def send_response(self, transaction):\n        \"\"\"\n        Finalize to add the client to the list of observer.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the response\n        :return: the transaction unmodified\n        \"\"\"\n        host, port = transaction.request.source\n        key_token = hash(str(host) + str(port) + str(transaction.request.token))\n        if key_token in self._relations:\n            if transaction.response.code == defines.Codes.CONTENT.number:\n                if transaction.resource is not None and transaction.resource.observable:\n\n                    transaction.response.observe = transaction.resource.observe_count\n                    self._relations[key_token].allowed = True\n                    self._relations[key_token].transaction = transaction\n                    self._relations[key_token].timestamp = time.time()\n                else:\n                    del self._relations[key_token]\n            elif transaction.response.code >= defines.Codes.ERROR_LOWER_BOUND:\n                del self._relations[key_token]\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare notification for the resource to all interested observers.", "response": "def notify(self, resource, root=None):\n        \"\"\"\n        Prepare notification for the resource to all interested observers.\n\n        :rtype: list\n        :param resource: the resource for which send a new notification\n        :param root: deprecated\n        :return: the list of transactions to be notified\n        \"\"\"\n        ret = []\n        if root is not None:\n            resource_list = root.with_prefix_resource(resource.path)\n        else:\n            resource_list = [resource]\n        for key in list(self._relations.keys()):\n            if self._relations[key].transaction.resource in resource_list:\n                if self._relations[key].non_counter > defines.MAX_NON_NOTIFICATIONS \\\n                        or self._relations[key].transaction.request.type == defines.Types[\"CON\"]:\n                    self._relations[key].transaction.response.type = defines.Types[\"CON\"]\n                    self._relations[key].non_counter = 0\n                elif self._relations[key].transaction.request.type == defines.Types[\"NON\"]:\n                    self._relations[key].non_counter += 1\n                    self._relations[key].transaction.response.type = defines.Types[\"NON\"]\n                self._relations[key].transaction.resource = resource\n                del self._relations[key].transaction.response.mid\n                del self._relations[key].transaction.response.token\n                ret.append(self._relations[key].transaction)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_subscriber(self, message):\n        logger.debug(\"Remove Subcriber\")\n        host, port = message.destination\n        key_token = hash(str(host) + str(port) + str(message.token))\n        try:\n            self._relations[key_token].transaction.completed = True\n            del self._relations[key_token]\n        except KeyError:\n            logger.warning(\"No Subscriber\")", "response": "Remove a subscriber based on token."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npurges all messages from the message layer.", "response": "def purge(self):\n        \"\"\"\n        Clean old transactions\n        \"\"\"\n        while not self.stopped.isSet():\n            self.stopped.wait(timeout=defines.EXCHANGE_LIFETIME)\n            self._messageLayer.purge()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listen(self, timeout=10):\n        self._socket.settimeout(float(timeout))\n        while not self.stopped.isSet():\n            try:\n                data, client_address = self._socket.recvfrom(4096)\n            except socket.timeout:\n                continue\n            try:\n                #Start a new thread not to block other requests\n                args = ((data, client_address), )\n                t = threading.Thread(target=self.receive_datagram, args=args)\n                t.daemon = True\n                t.start()\n            except RuntimeError:\n                logging.exception(\"Exception with Executor\")\n        logging.debug(\"closing socket\")\n        self._socket.close()", "response": "Listen for incoming messages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop the server and close the socket.", "response": "def close(self):\n        \"\"\"\n        Stop the server.\n\n        \"\"\"\n        logger.info(\"Stop server\")\n        self.stopped.set()\n        for event in self.to_be_stopped:\n            event.set()\n        self._socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_datagram(self, message):\n        if not self.stopped.isSet():\n            host, port = message.destination\n            logger.debug(\"send_datagram - \" + str(message))\n            serializer = Serializer()\n\n            message = serializer.serialize(message)\n\n            self._socket.sendto(message, (host, port))", "response": "Send a message through the udp socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nthreads function to retransmit the message in the future :param transaction: the transaction that owns the message that needs retransmission :param message: the message that needs the retransmission task :param future_time: the amount of time to wait before a new attempt :param retransmit_count: the number of retransmissions", "response": "def _retransmit(self, transaction, message, future_time, retransmit_count):\n        \"\"\"\n        Thread function to retransmit the message in the future\n\n        :param transaction: the transaction that owns the message that needs retransmission\n        :param message: the message that needs the retransmission task\n        :param future_time: the amount of time to wait before a new attempt\n        :param retransmit_count: the number of retransmissions\n        \"\"\"\n        with transaction:\n            while retransmit_count < defines.MAX_RETRANSMIT and (not message.acknowledged and not message.rejected) \\\n                    and not self.stopped.isSet():\n                transaction.retransmit_stop.wait(timeout=future_time)\n                if not message.acknowledged and not message.rejected and not self.stopped.isSet():\n                    retransmit_count += 1\n                    future_time *= 2\n                    self.send_datagram(message)\n\n            if message.acknowledged or message.rejected:\n                message.timeouted = False\n            else:\n                logger.warning(\"Give up on message {message}\".format(message=message.line_print))\n                message.timeouted = True\n                if message.observe is not None:\n                    self._observeLayer.remove_subscriber(message)\n\n            try:\n                self.to_be_stopped.remove(transaction.retransmit_stop)\n            except ValueError:\n                pass\n            transaction.retransmit_stop = None\n            transaction.retransmit_thread = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a separate timer that handles the ACK and ACK messages.", "response": "def _start_separate_timer(self, transaction):\n        \"\"\"\n        Start a thread to handle separate mode.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that is in processing\n        :rtype : the Timer object\n        \"\"\"\n        t = threading.Timer(defines.ACK_TIMEOUT, self._send_ack, (transaction,))\n        t.start()\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_config(self):\n        tree = ElementTree.parse(self.file_xml)\n        root = tree.getroot()\n        for server in root.findall('server'):\n            destination = server.text\n            name = server.get(\"name\")\n            self.discover_remote(destination, name)", "response": "Parse the xml file with remote servers and discover resources on each found server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndiscover resources on remote servers.", "response": "def discover_remote(self, destination, name):\n        \"\"\"\n        Discover resources on remote servers.\n\n        :param destination: the remote server (ip, port)\n        :type destination: tuple\n        :param name: the name of the remote server\n        :type name: String\n        \"\"\"\n        assert (isinstance(destination, str))\n        if destination.startswith(\"[\"):\n            split = destination.split(\"]\", 1)\n            host = split[0][1:]\n            port = int(split[1][1:])\n        else:\n            split = destination.split(\":\", 1)\n            host = split[0]\n            port = int(split[1])\n        server = (host, port)\n        client = HelperClient(server)\n        response = client.discover()\n        client.stop()\n        self.discover_remote_results(response, name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discover_remote_results(self, response, name):\n        host, port = response.source\n\n        if response.code == defines.Codes.CONTENT.number:\n            resource = Resource('server', self, visible=True, observable=False, allow_children=True)\n            self.add_resource(name, resource)\n            self._mapping[name] = (host, port)\n            self.parse_core_link_format(response.payload, name, (host, port))\n        else:\n            logger.error(\"Server: \" + response.source + \" isn't valid.\")", "response": "Create a new remote server resource for each valid discover response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the response from the core link format request and add the child resources to the server.", "response": "def parse_core_link_format(self, link_format, base_path, remote_server):\n        \"\"\"\n        Parse discovery results.\n\n        :param link_format: the payload of the response to the discovery request\n        :param base_path: the base path used to create child resources discovered on the remote server\n        :param remote_server: the (ip, port) of the remote server\n        \"\"\"\n        while len(link_format) > 0:\n            pattern = \"<([^>]*)>;\"\n            result = re.match(pattern, link_format)\n            path = result.group(1)\n            path = path.split(\"/\")\n            path = path[1:][0]\n            link_format = link_format[result.end(1) + 2:]\n            pattern = \"([^<,])*\"\n            result = re.match(pattern, link_format)\n            attributes = result.group(0)\n            dict_att = {}\n            if len(attributes) > 0:\n                attributes = attributes.split(\";\")\n                for att in attributes:\n                    a = att.split(\"=\")\n                    if len(a) > 1:\n                        dict_att[a[0]] = a[1]\n                    else:\n                        dict_att[a[0]] = a[0]\n                link_format = link_format[result.end(0) + 1:]\n            # TODO handle observing\n            resource = RemoteResource('server', remote_server, path, coap_server=self, visible=True, observable=False,\n                                      allow_children=True)\n            resource.attributes = dict_att\n            self.add_resource(base_path + \"/\" + path, resource)\n\n        logger.info(self.root.dump())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listen(self, timeout=10):\n        self._socket.settimeout(float(timeout))\n        while not self.stopped.isSet():\n            try:\n                data, client_address = self._socket.recvfrom(4096)\n            except socket.timeout:\n                continue\n            try:\n\n                self.receive_datagram((data, client_address))\n            except RuntimeError:\n                logger.exception(\"Exception with Executor\")\n        self._socket.close()", "response": "Listen for incoming messages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling incoming datagrams from the UDP socket.", "response": "def receive_datagram(self, args):\n        \"\"\"\n        Handle messages coming from the udp socket.\n\n        :param args: (data, client_address)\n        \"\"\"\n        data, client_address = args\n\n        serializer = Serializer()\n        message = serializer.deserialize(data, client_address)\n        if isinstance(message, int):\n            logger.error(\"receive_datagram - BAD REQUEST\")\n\n            rst = Message()\n            rst.destination = client_address\n            rst.type = defines.Types[\"RST\"]\n            rst.code = message\n            self.send_datagram(rst)\n            return\n        logger.debug(\"receive_datagram - \" + str(message))\n        if isinstance(message, Request):\n\n            transaction = self._messageLayer.receive_request(message)\n\n            if transaction.request.duplicated and transaction.completed:\n                logger.debug(\"message duplicated,transaction completed\")\n                transaction = self._observeLayer.send_response(transaction)\n                transaction = self._blockLayer.send_response(transaction)\n                transaction = self._messageLayer.send_response(transaction)\n                self.send_datagram(transaction.response)\n                return\n            elif transaction.request.duplicated and not transaction.completed:\n                logger.debug(\"message duplicated,transaction NOT completed\")\n                self._send_ack(transaction)\n                return\n\n            transaction.separate_timer = self._start_separate_timer(transaction)\n\n            transaction = self._blockLayer.receive_request(transaction)\n\n            if transaction.block_transfer:\n                self._stop_separate_timer(transaction.separate_timer)\n                transaction = self._messageLayer.send_response(transaction)\n                self.send_datagram(transaction.response)\n                return\n\n            transaction = self._observeLayer.receive_request(transaction)\n\n            \"\"\"\n            call to the cache layer to check if there's a cached response for the request\n            if not, call the forward layer\n            \"\"\"\n            if self._cacheLayer is not None:\n                transaction = self._cacheLayer.receive_request(transaction)\n\n                if transaction.cacheHit is False:\n                    logger.debug(transaction.request)\n                    transaction = self._forwardLayer.receive_request_reverse(transaction)\n                    logger.debug(transaction.response)\n\n                transaction = self._observeLayer.send_response(transaction)\n\n                transaction = self._blockLayer.send_response(transaction)\n\n                transaction = self._cacheLayer.send_response(transaction)\n            else:\n                transaction = self._forwardLayer.receive_request_reverse(transaction)\n\n                transaction = self._observeLayer.send_response(transaction)\n\n                transaction = self._blockLayer.send_response(transaction)\n\n            self._stop_separate_timer(transaction.separate_timer)\n\n            transaction = self._messageLayer.send_response(transaction)\n\n            if transaction.response is not None:\n                if transaction.response.type == defines.Types[\"CON\"]:\n                    self._start_retrasmission(transaction, transaction.response)\n                self.send_datagram(transaction.response)\n\n        elif isinstance(message, Message):\n            transaction = self._messageLayer.receive_empty(message)\n            if transaction is not None:\n                transaction = self._blockLayer.receive_empty(message, transaction)\n                self._observeLayer.receive_empty(message, transaction)\n\n        else:  # pragma: no cover\n            logger.error(\"Received response from %s\", message.source)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _thread_body(self, request, callback):\n        self.protocol.send_message(request)\n        while not self.protocol.stopped.isSet():\n            response = self.queue.get(block=True)\n            callback(response)", "response": "Private function that sends a request wait for response and call the callback function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncancels the observing on the remote server.", "response": "def cancel_observing(self, response, send_rst):  # pragma: no cover\n        \"\"\"\n        Delete observing on the remote server.\n\n        :param response: the last received response\n        :param send_rst: if explicitly send RST message\n        :type send_rst: bool\n        \"\"\"\n        if send_rst:\n            message = Message()\n            message.destination = self.server\n            message.code = defines.Codes.EMPTY.number\n            message.type = defines.Types[\"RST\"]\n            message.token = response.token\n            message.mid = response.mid\n            self.protocol.send_message(message)\n        self.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming a GET with observe on a certain path.", "response": "def observe(self, path, callback, timeout=None, **kwargs):  # pragma: no cover\n        \"\"\"\n        Perform a GET with observe on a certain path.\n\n        :param path: the path\n        :param callback: the callback function to invoke upon notifications\n        :param timeout: the timeout of the request\n        :return: the response to the observe request\n        \"\"\"\n        request = self.mk_request(defines.Codes.GET, path)\n        request.observe = 0\n\n        for k, v in kwargs.items():\n            if hasattr(request, k):\n                setattr(request, k, v)\n\n        return self.send_request(request, callback, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, path, callback=None, timeout=None, **kwargs):  # pragma: no cover\n        request = self.mk_request(defines.Codes.DELETE, path)\n\n        for k, v in kwargs.items():\n            if hasattr(request, k):\n                setattr(request, k, v)\n\n        return self.send_request(request, callback, timeout)", "response": "Perform a DELETE on a certain path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a POST request on a certain path.", "response": "def post(self, path, payload, callback=None, timeout=None, no_response=False, **kwargs):  # pragma: no cover\n        \"\"\"\n        Perform a POST on a certain path.\n\n        :param path: the path\n        :param payload: the request payload\n        :param callback: the callback function to invoke upon response\n        :param timeout: the timeout of the request\n        :return: the response\n        \"\"\"\n        request = self.mk_request(defines.Codes.POST, path)\n        request.token = generate_random_token(2)\n        request.payload = payload\n\n        if no_response:\n            request.add_no_response()\n            request.type = defines.Types[\"NON\"]\n\n        for k, v in kwargs.items():\n            if hasattr(request, k):\n                setattr(request, k, v)\n\n        return self.send_request(request, callback, timeout, no_response=no_response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a Discover request on the server.", "response": "def discover(self, callback=None, timeout=None, **kwargs):  # pragma: no cover\n        \"\"\"\n        Perform a Discover request on the server.\n\n        :param callback: the callback function to invoke upon response\n        :param timeout: the timeout of the request\n        :return: the response\n        \"\"\"\n        request = self.mk_request(defines.Codes.GET, defines.DISCOVERY_URL)\n\n        for k, v in kwargs.items():\n            if hasattr(request, k):\n                setattr(request, k, v)\n\n        return self.send_request(request, callback, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a request to the remote server.", "response": "def send_request(self, request, callback=None, timeout=None, no_response=False):  # pragma: no cover\n        \"\"\"\n        Send a request to the remote server.\n\n        :param request: the request to send\n        :param callback: the callback function to invoke upon response\n        :param timeout: the timeout of the request\n        :return: the response\n        \"\"\"\n        if callback is not None:\n            thread = threading.Thread(target=self._thread_body, args=(request, callback))\n            thread.start()\n        else:\n            self.protocol.send_message(request)\n            if no_response:\n                return\n            try:\n                response = self.queue.get(block=True, timeout=timeout)\n            except Empty:\n                #if timeout is set\n                response = None\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a request. :param method: the CoAP method :param path: the path of the request :return: the request", "response": "def mk_request(self, method, path):\n        \"\"\"\n        Create a request.\n\n        :param method: the CoAP method\n        :param path: the path of the request\n        :return:  the request\n        \"\"\"\n        request = Request()\n        request.destination = self.server\n        request.code = method.number\n        request.uri_path = path\n        return request"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mk_request_non(self, method, path):\n        request = Request()\n        request.destination = self.server\n        request.code = method.number\n        request.uri_path = path\n        request.type = defines.Types[\"NON\"]\n        return request", "response": "Create a request.\n\n        :param method: the CoAP method\n        :param path: the path of the request\n        :return:  the request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        server_address = (self.ip, self.hc_port)\n        hc_proxy = HTTPServer(server_address, HCProxyHandler)\n        logger.info('Starting HTTP-CoAP Proxy...')\n        hc_proxy.serve_forever()", "response": "Start the HTTP - CoAP Proxy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_formatted_path(path):\n        if path[0] != '/':\n            path = '/' + path\n        if path[-1] != '/':\n            path = '{0}/'.format(path)\n        return path", "response": "Returns the path string that is a uniform path string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_payload(self):\n        temp = self.get_uri_as_list()\n        query_string = temp[4]\n        if query_string == \"\":\n            return None  # Bad request error code\n        query_string_as_list = str.split(query_string, \"=\")\n        return query_string_as_list[1]", "response": "Return the query string of the uri."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_GET(self):\n        self.do_initial_operations()\n        coap_response = self.client.get(self.coap_uri.path)\n        self.client.stop()\n        logger.info(\"Server response: %s\", coap_response.pretty_print())\n        self.set_http_response(coap_response)", "response": "Perform a GET request"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_HEAD(self):\n        self.do_initial_operations()\n        # the HEAD method is not present in CoAP, so we treat it\n        # like if it was a GET and then we exclude the body from the response\n        # with send_body=False we say that we do not need the body, because it is a HEAD request\n        coap_response = self.client.get(self.coap_uri.path)\n        self.client.stop()\n        logger.info(\"Server response: %s\", coap_response.pretty_print())\n        self.set_http_header(coap_response)", "response": "Perform a HEAD request on the current resource set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a POST request to the COAP server.", "response": "def do_POST(self):\n        \"\"\"\n        Perform a POST request\n        \"\"\"\n        # Doesn't do anything with posted data\n        # print \"uri: \", self.client_address, self.path\n        self.do_initial_operations()\n        payload = self.coap_uri.get_payload()\n        if payload is None:\n            logger.error(\"BAD POST REQUEST\")\n            self.send_error(BAD_REQUEST)\n            return\n        coap_response = self.client.post(self.coap_uri.path, payload)\n        self.client.stop()\n        logger.info(\"Server response: %s\", coap_response.pretty_print())\n        self.set_http_response(coap_response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_PUT(self):\n        self.do_initial_operations()\n        payload = self.coap_uri.get_payload()\n        if payload is None:\n            logger.error(\"BAD PUT REQUEST\")\n            self.send_error(BAD_REQUEST)\n            return\n        logger.debug(payload)\n        coap_response = self.client.put(self.coap_uri.path, payload)\n        self.client.stop()\n        logger.debug(\"Server response: %s\", coap_response.pretty_print())\n        self.set_http_response(coap_response)", "response": "Perform a PUT request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_DELETE(self):\n        self.do_initial_operations()\n        coap_response = self.client.delete(self.coap_uri.path)\n        self.client.stop()\n        logger.debug(\"Server response: %s\", coap_response.pretty_print())\n        self.set_http_response(coap_response)", "response": "Perform a DELETE request"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntelling if the hc path of the request corresponds to that specified by the adminHCPath .", "response": "def request_hc_path_corresponds(self):\n        \"\"\"\n        Tells if the hc path of the request corresponds to that specified by the admin\n\n        :return: a boolean that says if it corresponds or not\n        \"\"\"\n        uri_path = self.path.split(COAP_PREFACE)\n        request_hc_path = uri_path[0]\n        logger.debug(\"HCPATH: %s\", hc_path)\n        # print HC_PATH\n        logger.debug(\"URI: %s\", request_hc_path)\n        if hc_path != request_hc_path:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_http_header(self, coap_response):\n        logger.debug(\n                (\"Server: %s\\n\"\\\n                        \"codice risposta: %s\\n\"\\\n                        \"PROXED: %s\\n\"\\\n                        \"payload risposta: %s\"),\n                coap_response.source,\n                coap_response.code,\n                CoAP_HTTP[Codes.LIST[coap_response.code].name],\n                coap_response.payload)\n        self.send_response(int(CoAP_HTTP[Codes.LIST[coap_response.code].name]))\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()", "response": "Sets the HTTP headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_http_body(self, coap_response):\n        if coap_response.payload is not None:\n            body = \"<html><body><h1>\", coap_response.payload, \"</h1></body></html>\"\n            self.wfile.write(\"\".join(body))\n        else:\n            self.wfile.write(\"<html><body><h1>None</h1></body></html>\")", "response": "Set the HTTP body."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_blockwise(value):\n\n    length = byte_len(value)\n    if length == 1:\n        num = value & 0xF0\n        num >>= 4\n        m = value & 0x08\n        m >>= 3\n        size = value & 0x07\n    elif length == 2:\n        num = value & 0xFFF0\n        num >>= 4\n        m = value & 0x0008\n        m >>= 3\n        size = value & 0x0007\n    else:\n        num = value & 0xFFFFF0\n        num >>= 4\n        m = value & 0x000008\n        m >>= 3\n        size = value & 0x000007\n    return num, int(m), pow(2, (size + 4))", "response": "Parse the blockwise option."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef byte_len(int_type):\n    length = 0\n    while int_type:\n        int_type >>= 1\n        length += 1\n    if length > 0:\n        if length % 8 != 0:\n            length = int(length / 8) + 1\n        else:\n            length = int(length / 8)\n    return length", "response": "Get the number of bytes needed to encode the int passed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the option value depending on the option number.", "response": "def value(self):\n        \"\"\"\n        Return the option value.\n\n        :return: the option value in the correct format depending on the option\n        \"\"\"\n        if type(self._value) is None:\n            self._value = bytearray()\n        opt_type = defines.OptionRegistry.LIST[self._number].value_type\n        if opt_type == defines.INTEGER:\n            if byte_len(self._value) > 0:\n                return int(self._value)\n            else:\n                return defines.OptionRegistry.LIST[self._number].default\n        return self._value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of the option.", "response": "def value(self, value):\n        \"\"\"\n        Set the value of the option.\n\n        :param value: the option value\n        \"\"\"\n        opt_type = defines.OptionRegistry.LIST[self._number].value_type\n        if opt_type == defines.INTEGER:\n            if type(value) is not int:\n                value = int(value)\n            if byte_len(value) == 0:\n                value = 0\n        elif opt_type == defines.STRING:\n            if type(value) is not str:\n                value = str(value)\n        elif opt_type == defines.OPAQUE:\n            if type(value) is bytes:\n                pass\n            else:\n                if value is not None:\n                    value = bytes(value, \"utf-8\")\n\n        self._value = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the length of the value.", "response": "def length(self):\n        \"\"\"\n        Return the value length\n\n        :rtype : int\n        \"\"\"\n        if isinstance(self._value, int):\n            return byte_len(self._value)\n        if self._value is None:\n            return 0\n        return len(self._value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the option is safe.", "response": "def is_safe(self):\n        \"\"\"\n        Check if the option is safe.\n\n        :rtype : bool\n        :return: True, if option is safe\n        \"\"\"\n        if self._number == defines.OptionRegistry.URI_HOST.number \\\n                or self._number == defines.OptionRegistry.URI_PORT.number \\\n                or self._number == defines.OptionRegistry.URI_PATH.number \\\n                or self._number == defines.OptionRegistry.MAX_AGE.number \\\n                or self._number == defines.OptionRegistry.URI_QUERY.number \\\n                or self._number == defines.OptionRegistry.PROXY_URI.number \\\n                or self._number == defines.OptionRegistry.PROXY_SCHEME.number:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the flags from the option number .", "response": "def get_option_flags(option_num):\n        \"\"\"\n        Get Critical, UnSafe, NoCacheKey flags from the option number\n        as per RFC 7252, section 5.4.6\n\n        :param option_num: option number\n        :return: option flags\n        :rtype: 3-tuple (critical, unsafe, no-cache)\n        \"\"\"\n        opt_bytes = array.array('B', '\\0\\0')\n        if option_num < 256:\n            s = struct.Struct(\"!B\")\n            s.pack_into(opt_bytes, 0, option_num)\n        else:\n            s = struct.Struct(\"H\")\n            s.pack_into(opt_bytes, 0, option_num)\n        critical = (opt_bytes[0] & 0x01) > 0\n        unsafe = (opt_bytes[0] & 0x02) > 0\n        nocache = ((opt_bytes[0] & 0x1e) == 0x1c)\n        return (critical, unsafe, nocache)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes a message to a udp packet containing a set of related information.", "response": "def serialize(message):\n        \"\"\"\n        Serialize a message to a udp packet\n\n        :type message: Message\n        :param message: the message to be serialized\n        :rtype: stream of byte\n        :return: the message serialized\n        \"\"\"\n        fmt = \"!BBH\"\n\n        if message.token is None or message.token == \"\":\n            tkl = 0\n        else:\n            tkl = len(message.token)\n        tmp = (defines.VERSION << 2)\n        tmp |= message.type\n        tmp <<= 4\n        tmp |= tkl\n\n        values = [tmp, message.code, message.mid]\n\n        if message.token is not None and tkl > 0:\n\n            for b in str(message.token):\n                fmt += \"c\"\n                values.append(bytes(b, \"utf-8\"))\n\n        options = Serializer.as_sorted_list(message.options)  # already sorted\n        lastoptionnumber = 0\n        for option in options:\n\n            # write 4-bit option delta\n            optiondelta = option.number - lastoptionnumber\n            optiondeltanibble = Serializer.get_option_nibble(optiondelta)\n            tmp = (optiondeltanibble << defines.OPTION_DELTA_BITS)\n\n            # write 4-bit option length\n            optionlength = option.length\n            optionlengthnibble = Serializer.get_option_nibble(optionlength)\n            tmp |= optionlengthnibble\n            fmt += \"B\"\n            values.append(tmp)\n\n            # write extended option delta field (0 - 2 bytes)\n            if optiondeltanibble == 13:\n                fmt += \"B\"\n                values.append(optiondelta - 13)\n            elif optiondeltanibble == 14:\n                fmt += \"H\"\n                values.append(optiondelta - 269)\n\n            # write extended option length field (0 - 2 bytes)\n            if optionlengthnibble == 13:\n                fmt += \"B\"\n                values.append(optionlength - 13)\n            elif optionlengthnibble == 14:\n                fmt += \"H\"\n                values.append(optionlength - 269)\n\n            # write option value\n            if optionlength > 0:\n                opt_type = defines.OptionRegistry.LIST[option.number].value_type\n                if opt_type == defines.INTEGER:\n                    words = Serializer.int_to_words(option.value, optionlength, 8)\n                    for num in range(0, optionlength):\n                        fmt += \"B\"\n                        values.append(words[num])\n                elif opt_type == defines.STRING:\n                    fmt += str(len(bytes(option.value, \"utf-8\"))) + \"s\"\n                    values.append(bytes(option.value, \"utf-8\"))\n\n                else:  # OPAQUE\n                    for b in option.value:\n                        fmt += \"B\"\n                        values.append(b)\n\n            # update last option number\n            lastoptionnumber = option.number\n\n        payload = message.payload\n\n        if payload is not None and len(payload) > 0:\n            # if payload is present and of non-zero length, it is prefixed by\n            # an one-byte Payload Marker (0xFF) which indicates the end of\n            # options and the start of the payload\n\n            fmt += \"B\"\n            values.append(defines.PAYLOAD_MARKER)\n\n            if isinstance(payload, bytes):\n                fmt += str(len(payload)) + \"s\"\n                values.append(payload)\n            else:\n                fmt += str(len(bytes(payload, \"utf-8\"))) + \"s\"\n                values.append(bytes(payload, \"utf-8\"))\n            # for b in str(payload):\n            #     fmt += \"c\"\n            #     values.append(bytes(b, \"utf-8\"))\n\n        datagram = None\n        if values[1] is None:\n            values[1] = 0\n        if values[2] is None:\n            values[2] = 0\n        try:\n            s = struct.Struct(fmt)\n            datagram = ctypes.create_string_buffer(s.size)\n            s.pack_into(datagram, 0, *values)\n        except struct.error:\n            # The .exception method will report on the exception encountered\n            # and provide a traceback.\n            logger.debug(fmt)\n            logger.debug(values)\n            logging.exception('Failed to pack structure')\n\n        return datagram"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the option value from the nibble at the given position.", "response": "def read_option_value_from_nibble(nibble, pos, values):\n        \"\"\"\n        Calculates the value used in the extended option fields.\n\n        :param nibble: the 4-bit option header value.\n        :return: the value calculated from the nibble and the extended option value.\n        \"\"\"\n        if nibble <= 12:\n            return nibble, pos\n        elif nibble == 13:\n            tmp = struct.unpack(\"!B\", values[pos].to_bytes(1, \"big\"))[0] + 13\n            pos += 1\n            return tmp, pos\n        elif nibble == 14:\n            s = struct.Struct(\"!H\")\n            tmp = s.unpack_from(values[pos:].to_bytes(2, \"big\"))[0] + 269\n            pos += 2\n            return tmp, pos\n        else:\n            raise AttributeError(\"Unsupported option nibble \" + str(nibble))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_option_value_len_from_byte(byte, pos, values):\n        h_nibble = (byte & 0xF0) >> 4\n        l_nibble = byte & 0x0F\n        value = 0\n        length = 0\n        if h_nibble <= 12:\n            value = h_nibble\n        elif h_nibble == 13:\n            value = struct.unpack(\"!B\", values[pos].to_bytes(1, \"big\"))[0] + 13\n            pos += 1\n        elif h_nibble == 14:\n            s = struct.Struct(\"!H\")\n            value = s.unpack_from(values[pos:].to_bytes(2, \"big\"))[0] + 269\n            pos += 2\n        else:\n            raise AttributeError(\"Unsupported option number nibble \" + str(h_nibble))\n\n        if l_nibble <= 12:\n            length = l_nibble\n        elif l_nibble == 13:\n            length = struct.unpack(\"!B\", values[pos].to_bytes(1, \"big\"))[0] + 13\n            pos += 1\n        elif l_nibble == 14:\n            length = s.unpack_from(values[pos:].to_bytes(2, \"big\"))[0] + 269\n            pos += 2\n        else:\n            raise AttributeError(\"Unsupported option length nibble \" + str(l_nibble))\n        return value, length, pos", "response": "Reads the value and length from the next option in the array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_to_raw(number, value, length):\n\n        opt_type = defines.OptionRegistry.LIST[number].value_type\n\n        if length == 0 and opt_type != defines.INTEGER:\n            return bytes()\n        elif length == 0 and opt_type == defines.INTEGER:\n            return 0\n        elif opt_type == defines.STRING:\n            if isinstance(value, bytes):\n                return value.decode(\"utf-8\")\n        elif opt_type == defines.OPAQUE:\n            if isinstance(value, bytes):\n                return value\n            else:\n                return bytes(value, \"utf-8\")\n        if isinstance(value, tuple):\n            value = value[0]\n        if isinstance(value, str):\n            value = str(value)\n        if isinstance(value, str):\n            return bytearray(value, \"utf-8\")\n        elif isinstance(value, int):\n            return value\n        else:\n            return bytearray(value)", "response": "Converts the value of an option to a raw byte array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all options in a list sorted according to their option numbers.", "response": "def as_sorted_list(options):\n        \"\"\"\n        Returns all options in a list sorted according to their option numbers.\n\n        :return: the sorted list\n        \"\"\"\n        if len(options) > 0:\n            options = sorted(options, key=lambda o: o.number)\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef int_to_words(int_val, num_words=4, word_size=32):\n        max_int = 2 ** (word_size*num_words) - 1\n        max_word_size = 2 ** word_size - 1\n\n        if not 0 <= int_val <= max_int:\n            raise AttributeError('integer %r is out of bounds!' % hex(int_val))\n\n        words = []\n        for _ in range(num_words):\n            word = int_val & max_word_size\n            words.append(int(word))\n            int_val >>= word_size\n        words.reverse()\n\n        return words", "response": "Convert a Python integer to a list of words."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts each argument to a lower case string appended then hash", "response": "def str_append_hash(*args):\n    \"\"\" Convert each argument to a lower case string, appended, then hash \"\"\"\n    ret_hash = \"\"\n    for i in args:\n        ret_hash += str(i).lower()\n\n    return hash(ret_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the next valid MID.", "response": "def fetch_mid(self):\n        \"\"\"\n        Gets the next valid MID.\n\n        :return: the mid to use\n        \"\"\"\n        current_mid = self._current_mid\n        self._current_mid += 1\n        self._current_mid %= 65535\n        return current_mid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_request(self, request):\n        logger.debug(\"receive_request - \" + str(request))\n        try:\n            host, port = request.source\n        except AttributeError:\n            return\n        key_mid = str_append_hash(host, port, request.mid)\n        key_token = str_append_hash(host, port, request.token)\n\n        if key_mid in list(self._transactions.keys()):\n            # Duplicated\n            self._transactions[key_mid].request.duplicated = True\n            transaction = self._transactions[key_mid]\n        else:\n            request.timestamp = time.time()\n            transaction = Transaction(request=request, timestamp=request.timestamp)\n            with transaction:\n                self._transactions[key_mid] = transaction\n                self._transactions_token[key_token] = transaction\n        return transaction", "response": "Handle duplicates and store received messages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npair responses with requests. :type response: Response :param response: the received response :rtype : Transaction :return: the transaction to which the response belongs to", "response": "def receive_response(self, response):\n        \"\"\"\n        Pair responses with requests.\n\n        :type response: Response\n        :param response: the received response\n        :rtype : Transaction\n        :return: the transaction to which the response belongs to\n        \"\"\"\n        logger.debug(\"receive_response - \" + str(response))\n        try:\n            host, port = response.source\n        except AttributeError:\n            return\n        key_mid = str_append_hash(host, port, response.mid)\n        key_mid_multicast = str_append_hash(defines.ALL_COAP_NODES, port, response.mid)\n        key_token = str_append_hash(host, port, response.token)\n        key_token_multicast = str_append_hash(defines.ALL_COAP_NODES, port, response.token)\n        if key_mid in list(self._transactions.keys()):\n            transaction = self._transactions[key_mid]\n            if response.token != transaction.request.token:\n                logger.warning(\"Tokens does not match -  response message \" + str(host) + \":\" + str(port))\n                return None, False\n        elif key_token in self._transactions_token:\n            transaction = self._transactions_token[key_token]\n        elif key_mid_multicast in list(self._transactions.keys()):\n            transaction = self._transactions[key_mid_multicast]\n        elif key_token_multicast in self._transactions_token:\n            transaction = self._transactions_token[key_token_multicast]\n            if response.token != transaction.request.token:\n                logger.warning(\"Tokens does not match -  response message \" + str(host) + \":\" + str(port))\n                return None, False\n        else:\n            logger.warning(\"Un-Matched incoming response message \" + str(host) + \":\" + str(port))\n            return None, False\n        send_ack = False\n        if response.type == defines.Types[\"CON\"]:\n            send_ack = True\n\n        transaction.request.acknowledged = True\n        transaction.completed = True\n        transaction.response = response\n        if transaction.retransmit_stop is not None:\n            transaction.retransmit_stop.set()\n        return transaction, send_ack"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npairing ACKs with requests. :type message: Message :param message: the received message :rtype : Transaction :return: the transaction to which the message belongs to", "response": "def receive_empty(self, message):\n        \"\"\"\n        Pair ACKs with requests.\n\n        :type message: Message\n        :param message: the received message\n        :rtype : Transaction\n        :return: the transaction to which the message belongs to\n        \"\"\"\n        logger.debug(\"receive_empty - \" + str(message))\n        try:\n            host, port = message.source\n        except AttributeError:\n            return\n        key_mid = str_append_hash(host, port, message.mid)\n        key_mid_multicast = str_append_hash(defines.ALL_COAP_NODES, port, message.mid)\n        key_token = str_append_hash(host, port, message.token)\n        key_token_multicast = str_append_hash(defines.ALL_COAP_NODES, port, message.token)\n        if key_mid in list(self._transactions.keys()):\n            transaction = self._transactions[key_mid]\n        elif key_token in self._transactions_token:\n            transaction = self._transactions_token[key_token]\n        elif key_mid_multicast in list(self._transactions.keys()):\n            transaction = self._transactions[key_mid_multicast]\n        elif key_token_multicast in self._transactions_token:\n            transaction = self._transactions_token[key_token_multicast]\n        else:\n            logger.warning(\"Un-Matched incoming empty message \" + str(host) + \":\" + str(port))\n            return None\n\n        if message.type == defines.Types[\"ACK\"]:\n            if not transaction.request.acknowledged:\n                transaction.request.acknowledged = True\n            elif (transaction.response is not None) and (not transaction.response.acknowledged):\n                transaction.response.acknowledged = True\n        elif message.type == defines.Types[\"RST\"]:\n            if not transaction.request.acknowledged:\n                transaction.request.rejected = True\n            elif not transaction.response.acknowledged:\n                transaction.response.rejected = True\n        elif message.type == defines.Types[\"CON\"]:\n            #implicit ACK (might have been lost)\n            logger.debug(\"Implicit ACK on received CON for waiting transaction\")\n            transaction.request.acknowledged = True\n        else:\n            logger.warning(\"Unhandled message type...\")\n\n        if transaction.retransmit_stop is not None:\n            transaction.retransmit_stop.set()\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_request(self, request):\n        logger.debug(\"send_request - \" + str(request))\n        assert isinstance(request, Request)\n        try:\n            host, port = request.destination\n        except AttributeError:\n            return\n\n        request.timestamp = time.time()\n        transaction = Transaction(request=request, timestamp=request.timestamp)\n        if transaction.request.type is None:\n            transaction.request.type = defines.Types[\"CON\"]\n\n        if transaction.request.mid is None:\n            transaction.request.mid = self.fetch_mid()\n\n        key_mid = str_append_hash(host, port, request.mid)\n        self._transactions[key_mid] = transaction\n\n        key_token = str_append_hash(host, port, request.token)\n        self._transactions_token[key_token] = transaction\n\n        return self._transactions[key_mid]", "response": "Create a transaction and fill it with the outgoing request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_response(self, transaction):\n        logger.debug(\"send_response - \" + str(transaction.response))\n        if transaction.response.type is None:\n            if transaction.request.type == defines.Types[\"CON\"] and not transaction.request.acknowledged:\n                transaction.response.type = defines.Types[\"ACK\"]\n                transaction.response.mid = transaction.request.mid\n                transaction.response.acknowledged = True\n                transaction.completed = True\n            elif transaction.request.type == defines.Types[\"NON\"]:\n                transaction.response.type = defines.Types[\"NON\"]\n            else:\n                transaction.response.type = defines.Types[\"CON\"]\n                transaction.response.token = transaction.request.token\n\n        if transaction.response.mid is None:\n            transaction.response.mid = self.fetch_mid()\n            try:\n                host, port = transaction.response.destination\n            except AttributeError:\n                return\n            key_mid = str_append_hash(host, port, transaction.response.mid)\n            self._transactions[key_mid] = transaction\n\n        transaction.request.acknowledged = True\n        return transaction", "response": "Set the type the token and eventually the MID for the outgoing response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_empty(self, transaction, related, message):\n        logger.debug(\"send_empty - \" + str(message))\n        if transaction is None:\n            try:\n                host, port = message.destination\n            except AttributeError:\n                return\n            key_mid = str_append_hash(host, port, message.mid)\n            key_token = str_append_hash(host, port, message.token)\n            if key_mid in self._transactions:\n                transaction = self._transactions[key_mid]\n                related = transaction.response\n            elif key_token in self._transactions_token:\n                transaction = self._transactions_token[key_token]\n                related = transaction.response\n            else:\n                return message\n\n        if message.type == defines.Types[\"ACK\"]:\n            if transaction.request == related:\n                transaction.request.acknowledged = True\n                transaction.completed = True\n                message.mid = transaction.request.mid\n                message.code = 0\n                message.destination = transaction.request.source\n            elif transaction.response == related:\n                transaction.response.acknowledged = True\n                transaction.completed = True\n                message.mid = transaction.response.mid\n                message.code = 0\n                message.token = transaction.response.token\n                message.destination = transaction.response.source\n\n        elif message.type == defines.Types[\"RST\"]:\n            if transaction.request == related:\n                transaction.request.rejected = True\n                message._mid = transaction.request.mid\n                if message.mid is None:\n                    message.mid = self.fetch_mid()\n                message.code = 0\n                message.token = transaction.request.token\n                message.destination = transaction.request.source\n            elif transaction.response == related:\n                transaction.response.rejected = True\n                transaction.completed = True\n                message._mid = transaction.response.mid\n                if message.mid is None:\n                    message.mid = self.fetch_mid()\n                message.code = 0\n                message.token = transaction.response.token\n                message.destination = transaction.response.source\n        return message", "response": "Sends an empty message to the specified transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef location_path(self):\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.LOCATION_PATH.number:\n                value.append(str(option.value))\n        return \"/\".join(value)", "response": "Returns the Location - Path of the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef location_path(self, path):\n        path = path.strip(\"/\")\n        tmp = path.split(\"?\")\n        path = tmp[0]\n        paths = path.split(\"/\")\n        for p in paths:\n            option = Option()\n            option.number = defines.OptionRegistry.LOCATION_PATH.number\n            option.value = p\n            self.add_option(option)", "response": "Set the Location - Path of the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef location_query(self):\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.LOCATION_QUERY.number:\n                value.append(option.value)\n        return value", "response": "Returns the Location - Query of the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the Location - Query of the response.", "response": "def location_query(self, value):\n        \"\"\"\n        Set the Location-Query of the response.\n\n        :type path: String\n        :param path: the Location-Query as a string\n        \"\"\"\n        del self.location_query\n        queries = value.split(\"&\")\n        for q in queries:\n            option = Option()\n            option.number = defines.OptionRegistry.LOCATION_QUERY.number\n            option.value = str(q)\n            self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the MaxAge of the response.", "response": "def max_age(self):\n        \"\"\"\n        Return the MaxAge of the response.\n\n        :rtype : int\n        :return: the MaxAge option\n        \"\"\"\n        value = defines.OptionRegistry.MAX_AGE.default\n        for option in self.options:\n            if option.number == defines.OptionRegistry.MAX_AGE.number:\n                value = int(option.value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the MaxAge of the response.", "response": "def max_age(self, value):\n        \"\"\"\n        Set the MaxAge of the response.\n\n        :type value: int\n        :param value: the MaxAge option\n        \"\"\"\n        option = Option()\n        option.number = defines.OptionRegistry.MAX_AGE.number\n        option.value = int(value)\n        self.del_option_by_number(defines.OptionRegistry.MAX_AGE.number)\n        self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlisten for incoming messages.", "response": "def listen(self, timeout=10):\n        \"\"\"\n        Listen for incoming messages. Timeout is used to check if the server must be switched off.\n\n        :param timeout: Socket Timeout in seconds\n        \"\"\"\n        self._socket.settimeout(float(timeout))\n        while not self.stopped.isSet():\n            try:\n                data, client_address = self._socket.recvfrom(4096)\n                if len(client_address) > 2:\n                    client_address = (client_address[0], client_address[1])\n            except socket.timeout:\n                continue\n            except Exception as e:\n                if self._cb_ignore_listen_exception is not None and isinstance(self._cb_ignore_listen_exception, collections.Callable):\n                    if self._cb_ignore_listen_exception(e, self):\n                        continue\n                raise\n            try:\n                serializer = Serializer()\n                message = serializer.deserialize(data, client_address)\n                if isinstance(message, int):\n                    logger.error(\"receive_datagram - BAD REQUEST\")\n\n                    rst = Message()\n                    rst.destination = client_address\n                    rst.type = defines.Types[\"RST\"]\n                    rst.code = message\n                    rst.mid = self._messageLayer.fetch_mid()\n                    self.send_datagram(rst)\n                    continue\n\n                logger.debug(\"receive_datagram - \" + str(message))\n                if isinstance(message, Request):\n                    transaction = self._messageLayer.receive_request(message)\n                    if transaction.request.duplicated and transaction.completed:\n                        logger.debug(\"message duplicated, transaction completed\")\n                        if transaction.response is not None:\n                            self.send_datagram(transaction.response)\n                        continue\n                    elif transaction.request.duplicated and not transaction.completed:\n                        logger.debug(\"message duplicated, transaction NOT completed\")\n                        self._send_ack(transaction)\n                        continue\n                    args = (transaction, )\n                    t = threading.Thread(target=self.receive_request, args=args)\n                    t.start()\n                # self.receive_datagram(data, client_address)\n                elif isinstance(message, Response):\n                    logger.error(\"Received response from %s\", message.source)\n\n                else:  # is Message\n                    transaction = self._messageLayer.receive_empty(message)\n                    if transaction is not None:\n                        with transaction:\n                            self._blockLayer.receive_empty(message, transaction)\n                            self._observeLayer.receive_empty(message, transaction)\n\n            except RuntimeError:\n                logger.exception(\"Exception with Executor\")\n        self._socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling requests coming from the udp socket.", "response": "def receive_request(self, transaction):\n        \"\"\"\n        Handle requests coming from the udp socket.\n\n        :param transaction: the transaction created to manage the request\n        \"\"\"\n\n        with transaction:\n\n            transaction.separate_timer = self._start_separate_timer(transaction)\n\n            self._blockLayer.receive_request(transaction)\n\n            if transaction.block_transfer:\n                self._stop_separate_timer(transaction.separate_timer)\n                self._messageLayer.send_response(transaction)\n                self.send_datagram(transaction.response)\n                return\n\n            self._observeLayer.receive_request(transaction)\n\n            self._requestLayer.receive_request(transaction)\n\n            if transaction.resource is not None and transaction.resource.changed:\n                self.notify(transaction.resource)\n                transaction.resource.changed = False\n            elif transaction.resource is not None and transaction.resource.deleted:\n                self.notify(transaction.resource)\n                transaction.resource.deleted = False\n\n            self._observeLayer.send_response(transaction)\n\n            self._blockLayer.send_response(transaction)\n\n            self._stop_separate_timer(transaction.separate_timer)\n\n            self._messageLayer.send_response(transaction)\n\n            if transaction.response is not None:\n                if transaction.response.type == defines.Types[\"CON\"]:\n                    self._start_retransmission(transaction, transaction.response)\n                self.send_datagram(transaction.response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_resource(self, path):\n\n        path = path.strip(\"/\")\n        paths = path.split(\"/\")\n        actual_path = \"\"\n        i = 0\n        for p in paths:\n            i += 1\n            actual_path += \"/\" + p\n        try:\n            res = self.root[actual_path]\n        except KeyError:\n            res = None\n        if res is not None:\n            del(self.root[actual_path])\n        return res", "response": "Helper function to remove a resource from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an ACK message for the request.", "response": "def _send_ack(self, transaction):\n        \"\"\"\n        Sends an ACK message for the request.\n\n        :param transaction: the transaction that owns the request\n        \"\"\"\n\n        ack = Message()\n        ack.type = defines.Types['ACK']\n        # TODO handle mutex on transaction\n        if not transaction.request.acknowledged and transaction.request.type == defines.Types[\"CON\"]:\n            ack = self._messageLayer.send_empty(transaction, transaction.request, ack)\n            self.send_datagram(ack)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notify(self, resource):\n        observers = self._observeLayer.notify(resource)\n        logger.debug(\"Notify\")\n        for transaction in observers:\n            with transaction:\n                transaction.response = None\n                transaction = self._requestLayer.receive_request(transaction)\n                transaction = self._observeLayer.send_response(transaction)\n                transaction = self._blockLayer.send_response(transaction)\n                transaction = self._messageLayer.send_response(transaction)\n                if transaction.response is not None:\n                    if transaction.response.type == defines.Types[\"CON\"]:\n                        self._start_retransmission(transaction, transaction.response)\n\n                    self.send_datagram(transaction.response)", "response": "Notify the observers of a certain resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef edit_resource(self, transaction, path):\n        resource_node = self._parent.root[path]\n        transaction.resource = resource_node\n        # If-Match\n        if transaction.request.if_match:\n            if None not in transaction.request.if_match and str(transaction.resource.etag) \\\n                    not in transaction.request.if_match:\n                transaction.response.code = defines.Codes.PRECONDITION_FAILED.number\n                return transaction\n\n        method = getattr(resource_node, \"render_POST\", None)\n        try:\n            resource = method(request=transaction.request)\n        except NotImplementedError:\n            try:\n                method = getattr(resource_node, \"render_POST_advanced\", None)\n                ret = method(request=transaction.request, response=transaction.response)\n                if isinstance(ret, tuple) and len(ret) == 2 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler\n                    resource, response = ret\n                    resource.changed = True\n                    resource.observe_count += 1\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CREATED.number\n                    return transaction\n                elif isinstance(ret, tuple) and len(ret) == 3 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler separate\n                    resource, response, callback = ret\n                    ret = self._handle_separate_advanced(transaction, callback)\n                    if not isinstance(ret, tuple) or \\\n                            not (isinstance(ret[0], Resource) and isinstance(ret[1], Response)):  # pragma: no cover\n                        transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                        return transaction\n                    resource, response = ret\n                    resource.changed = True\n                    resource.observe_count += 1\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CREATED.number\n                    return transaction\n                else:\n                    raise NotImplementedError\n            except NotImplementedError:\n                transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n                return transaction\n\n        if isinstance(resource, Resource):\n            pass\n        elif isinstance(resource, tuple) and len(resource) == 2:\n            resource, callback = resource\n            resource = self._handle_separate(transaction, callback)\n            if not isinstance(resource, Resource):  # pragma: no cover\n                transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                return transaction\n        else:  # pragma: no cover\n            # Handle error\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n            return transaction\n\n        if resource.path is None:\n            resource.path = path\n        resource.observe_count = resource_node.observe_count\n\n        if resource is resource_node:\n            transaction.response.code = defines.Codes.CHANGED.number\n        else:\n            transaction.response.code = defines.Codes.CREATED.number\n        resource.changed = True\n        resource.observe_count += 1\n        transaction.resource = resource\n\n        assert(isinstance(resource, Resource))\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n\n        transaction.response.location_path = resource.path\n\n        if resource.location_query is not None and len(resource.location_query) > 0:\n            transaction.response.location_query = resource.location_query\n\n        transaction.response.payload = None\n\n        self._parent.root[resource.path] = resource\n\n        return transaction", "response": "Render a POST on an already created resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a POST on a new resource.", "response": "def add_resource(self, transaction, parent_resource, lp):\n        \"\"\"\n        Render a POST on a new resource.\n\n        :param transaction: the transaction\n        :param parent_resource: the parent of the resource\n        :param lp: the location_path attribute of the resource\n        :return: the response\n        \"\"\"\n        method = getattr(parent_resource, \"render_POST\", None)\n        try:\n            resource = method(request=transaction.request)\n        except NotImplementedError:\n            try:\n                method = getattr(parent_resource, \"render_POST_advanced\", None)\n                ret = method(request=transaction.request, response=transaction.response)\n                if isinstance(ret, tuple) and len(ret) == 2 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler\n                    resource, response = ret\n                    resource.path = lp\n                    resource.changed = True\n                    self._parent.root[resource.path] = resource\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CREATED.number\n                    return transaction\n                elif isinstance(ret, tuple) and len(ret) == 3 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler separate\n                    resource, response, callback = ret\n                    ret = self._handle_separate_advanced(transaction, callback)\n                    if not isinstance(ret, tuple) or \\\n                            not (isinstance(ret[0], Resource) and isinstance(ret[1], Response)):  # pragma: no cover\n                        transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                        return transaction\n                    resource, response = ret\n                    resource.path = lp\n                    resource.changed = True\n                    self._parent.root[resource.path] = resource\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CREATED.number\n                    return transaction\n                else:\n                    raise NotImplementedError\n            except NotImplementedError:\n                transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n                return transaction\n        if isinstance(resource, Resource):\n            pass\n        elif isinstance(resource, tuple) and len(resource) == 2:\n            resource, callback = resource\n            resource = self._handle_separate(transaction, callback)\n            if not isinstance(resource, Resource):  # pragma: no cover\n                transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                return transaction\n        else:  # pragma: no cover\n            # Handle error\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n            return transaction\n\n        resource.path = lp\n\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n\n        transaction.response.location_path = resource.path\n\n        if resource.location_query is not None and len(resource.location_query) > 0:\n            transaction.response.location_query = resource.location_query\n\n        transaction.response.code = defines.Codes.CREATED.number\n        transaction.response.payload = None\n\n        assert (isinstance(resource, Resource))\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n        if resource.max_age is not None:\n            transaction.response.max_age = resource.max_age\n\n        resource.changed = True\n\n        transaction.resource = resource\n\n        self._parent.root[resource.path] = resource\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_resource(self, path, transaction):\n        t = self._parent.root.with_prefix(path)\n        max_len = 0\n        imax = None\n        for i in t:\n            if i == path:\n                # Resource already present\n                return self.edit_resource(transaction, path)\n            elif len(i) > max_len:\n                imax = i\n                max_len = len(i)\n\n        lp = path\n        parent_resource = self._parent.root[imax]\n        if parent_resource.allow_children:\n                return self.add_resource(transaction, parent_resource, lp)\n        else:\n            transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n            return transaction", "response": "Render a POST request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender a PUT request.", "response": "def update_resource(self, transaction):\n        \"\"\"\n        Render a PUT request.\n\n        :param transaction: the transaction\n        :return: the response\n        \"\"\"\n        # If-Match\n        if transaction.request.if_match:\n            if None not in transaction.request.if_match and str(transaction.resource.etag) \\\n                    not in transaction.request.if_match:\n                transaction.response.code = defines.Codes.PRECONDITION_FAILED.number\n                return transaction\n        # If-None-Match\n        if transaction.request.if_none_match:\n            transaction.response.code = defines.Codes.PRECONDITION_FAILED.number\n            return transaction\n\n        method = getattr(transaction.resource, \"render_PUT\", None)\n\n        try:\n            resource = method(request=transaction.request)\n        except NotImplementedError:\n            try:\n                method = getattr(transaction.resource, \"render_PUT_advanced\", None)\n                ret = method(request=transaction.request, response=transaction.response)\n                if isinstance(ret, tuple) and len(ret) == 2 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler\n                    resource, response = ret\n                    resource.changed = True\n                    resource.observe_count += 1\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CHANGED.number\n                    return transaction\n                elif isinstance(ret, tuple) and len(ret) == 3 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler separate\n                    resource, response, callback = ret\n                    ret = self._handle_separate_advanced(transaction, callback)\n                    if not isinstance(ret, tuple) or \\\n                            not (isinstance(ret[0], Resource) and isinstance(ret[1], Response)):  # pragma: no cover\n                        transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                        return transaction\n                    resource, response = ret\n                    resource.changed = True\n                    resource.observe_count += 1\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CHANGED.number\n                    return transaction\n                else:\n                    raise NotImplementedError\n            except NotImplementedError:\n                transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n                return transaction\n\n        if isinstance(resource, Resource):\n            pass\n        elif isinstance(resource, tuple) and len(resource) == 2:\n            resource, callback = resource\n            resource = self._handle_separate(transaction, callback)\n            if not isinstance(resource, Resource):  # pragma: no cover\n                transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                return transaction\n        else:  # pragma: no cover\n            # Handle error\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n            return transaction\n\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n\n        transaction.response.code = defines.Codes.CHANGED.number\n\n        transaction.response.payload = None\n\n        assert (isinstance(resource, Resource))\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n        if resource.max_age is not None:\n            transaction.response.max_age = resource.max_age\n\n        resource.changed = True\n        resource.observe_count += 1\n        transaction.resource = resource\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_resource(self, transaction, path):\n\n        resource = transaction.resource\n        method = getattr(resource, 'render_DELETE', None)\n\n        try:\n            ret = method(request=transaction.request)\n        except NotImplementedError:\n            try:\n                method = getattr(transaction.resource, \"render_DELETE_advanced\", None)\n                ret = method(request=transaction.request, response=transaction.response)\n                if isinstance(ret, tuple) and len(ret) == 2 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], bool):\n                    # Advanced handler\n                    delete, response = ret\n                    if delete:\n                        del self._parent.root[path]\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.DELETED.number\n                    return transaction\n                elif isinstance(ret, tuple) and len(ret) == 3 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler separate\n                    resource, response, callback = ret\n                    ret = self._handle_separate_advanced(transaction, callback)\n                    if not isinstance(ret, tuple) or \\\n                            not (isinstance(ret[0], bool) and isinstance(ret[1], Response)):  # pragma: no cover\n                        transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                        return transaction\n                    delete, response = ret\n                    if delete:\n                        del self._parent.root[path]\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.DELETED.number\n                    return transaction\n                else:\n                    raise NotImplementedError\n            except NotImplementedError:\n                transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n                return transaction\n\n        if isinstance(ret, bool):\n            pass\n        elif isinstance(ret, tuple) and len(ret) == 2:\n            resource, callback = ret\n            ret = self._handle_separate(transaction, callback)\n            if not isinstance(ret, bool):  # pragma: no cover\n                transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                return transaction\n        else:  # pragma: no cover\n            # Handle error\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n            return transaction\n        if ret:\n            del self._parent.root[path]\n            transaction.response.code = defines.Codes.DELETED.number\n            transaction.response.payload = None\n            transaction.resource.deleted = True\n        else:  # pragma: no cover\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n\n        return transaction", "response": "Render a DELETE request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a GET request.", "response": "def get_resource(self, transaction):\n        \"\"\"\n        Render a GET request.\n\n        :param transaction: the transaction\n        :return: the transaction\n        \"\"\"\n        method = getattr(transaction.resource, 'render_GET', None)\n\n        transaction.resource.actual_content_type = None\n        # Accept\n        if transaction.request.accept is not None:\n            transaction.resource.actual_content_type = transaction.request.accept\n\n        # Render_GET\n        try:\n            resource = method(request=transaction.request)\n        except NotImplementedError:\n            try:\n                method = getattr(transaction.resource, \"render_GET_advanced\", None)\n                ret = method(request=transaction.request, response=transaction.response)\n                if isinstance(ret, tuple) and len(ret) == 2 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler\n                    resource, response = ret\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CONTENT.number\n                    return transaction\n                elif isinstance(ret, tuple) and len(ret) == 3 and isinstance(ret[1], Response) \\\n                        and isinstance(ret[0], Resource):\n                    # Advanced handler separate\n                    resource, response, callback = ret\n                    ret = self._handle_separate_advanced(transaction, callback)\n                    if not isinstance(ret, tuple) or \\\n                            not (isinstance(ret[0], Resource) and isinstance(ret[1], Response)):  # pragma: no cover\n                        transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                        return transaction\n                    resource, response = ret\n                    transaction.resource = resource\n                    transaction.response = response\n                    if transaction.response.code is None:\n                        transaction.response.code = defines.Codes.CONTENT.number\n                    return transaction\n                else:\n                    raise NotImplementedError\n            except NotImplementedError:\n                transaction.response.code = defines.Codes.METHOD_NOT_ALLOWED.number\n                return transaction\n\n        if isinstance(resource, Resource):\n            pass\n        elif isinstance(resource, tuple) and len(resource) == 2:\n            resource, callback = resource\n            resource = self._handle_separate(transaction, callback)\n            if not isinstance(resource, Resource):  # pragma: no cover\n                transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n                return transaction\n        else:  # pragma: no cover\n            # Handle error\n            transaction.response.code = defines.Codes.INTERNAL_SERVER_ERROR.number\n            return transaction.response\n\n        if resource.etag in transaction.request.etag:\n            transaction.response.code = defines.Codes.VALID.number\n        else:\n            transaction.response.code = defines.Codes.CONTENT.number\n\n        try:\n            transaction.response.payload = resource.payload\n            if resource.actual_content_type is not None \\\n                    and resource.actual_content_type != defines.Content_types[\"text/plain\"]:\n                transaction.response.content_type = resource.actual_content_type\n        except KeyError:\n            transaction.response.code = defines.Codes.NOT_ACCEPTABLE.number\n            return transaction.response\n\n        assert(isinstance(resource, Resource))\n        if resource.etag is not None:\n            transaction.response.etag = resource.etag\n        if resource.max_age is not None:\n            transaction.response.max_age = resource.max_age\n\n        transaction.resource = resource\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a GET request to the. well - know / core link.", "response": "def discover(self, transaction):\n        \"\"\"\n        Render a GET request to the .well-know/core link.\n\n        :param transaction: the transaction\n        :return: the transaction\n        \"\"\"\n        transaction.response.code = defines.Codes.CONTENT.number\n        payload = \"\"\n        for i in self._parent.root.dump():\n            if i == \"/\":\n                continue\n            resource = self._parent.root[i]\n            if resource.visible:\n                ret = self.valid(transaction.request.uri_query, resource.attributes)\n                if ret:\n                    payload += self.corelinkformat(resource)\n\n        transaction.response.payload = payload\n        transaction.response.content_type = defines.Content_types[\"application/link-format\"]\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a formatted string representation of the corelinkformat in the tree.", "response": "def corelinkformat(resource):\n        \"\"\"\n        Return a formatted string representation of the corelinkformat in the tree.\n\n        :return: the string\n        \"\"\"\n        msg = \"<\" + resource.path + \">;\"\n        assert(isinstance(resource, Resource))\n        keys = sorted(list(resource.attributes.keys()))\n        for k in keys:\n            method = getattr(resource, defines.corelinkformat[k], None)\n            if method is not None and method != \"\":\n                v = method\n                msg = msg[:-1] + \";\" + str(v) + \",\"\n            else:\n                v = resource.attributes[k]\n                if v is not None:\n                    msg = msg[:-1] + \";\" + k + \"=\" + v + \",\"\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive_request(self, transaction):\n        method = transaction.request.code\n        if method == defines.Codes.GET.number:\n            transaction = self._handle_get(transaction)\n        elif method == defines.Codes.POST.number:\n            transaction = self._handle_post(transaction)\n        elif method == defines.Codes.PUT.number:\n            transaction = self._handle_put(transaction)\n        elif method == defines.Codes.DELETE.number:\n            transaction = self._handle_delete(transaction)\n        else:\n            transaction.response = None\n        return transaction", "response": "Handle the request and execute the requested method\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle GET requests :type transaction: Transaction :param transaction: the transaction that owns the request :rtype : Transaction :return: the edited transaction with the response to the request", "response": "def _handle_get(self, transaction):\n        \"\"\"\n        Handle GET requests\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :rtype : Transaction\n        :return: the edited transaction with the response to the request\n        \"\"\"\n        path = str(\"/\" + transaction.request.uri_path)\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n        if path == defines.DISCOVERY_URL:\n            transaction = self._server.resourceLayer.discover(transaction)\n        else:\n            try:\n                resource = self._server.root[path]\n            except KeyError:\n                resource = None\n            if resource is None or path == '/':\n                # Not Found\n                transaction.response.code = defines.Codes.NOT_FOUND.number\n            else:\n                transaction.resource = resource\n                transaction = self._server.resourceLayer.get_resource(transaction)\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle POST requests :type transaction: Transaction :param transaction: the transaction that owns the request :rtype : Transaction :return: the edited transaction with the response to the request", "response": "def _handle_post(self, transaction):\n        \"\"\"\n        Handle POST requests\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :rtype : Transaction\n        :return: the edited transaction with the response to the request\n        \"\"\"\n        path = str(\"/\" + transaction.request.uri_path)\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n\n        # Create request\n        transaction = self._server.resourceLayer.create_resource(path, transaction)\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling DELETE requests :type transaction: Transaction :param transaction: the transaction that owns the request :rtype : Transaction :return: the edited transaction with the response to the request", "response": "def _handle_delete(self, transaction):\n        \"\"\"\n        Handle DELETE requests\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :rtype : Transaction\n        :return: the edited transaction with the response to the request\n        \"\"\"\n        path = str(\"/\" + transaction.request.uri_path)\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n        try:\n            resource = self._server.root[path]\n        except KeyError:\n            resource = None\n\n        if resource is None:\n            transaction.response.code = defines.Codes.NOT_FOUND.number\n        else:\n            # Delete\n            transaction.resource = resource\n            transaction = self._server.resourceLayer.delete_resource(transaction, path)\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uri_path(self):\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.URI_PATH.number:\n                value.append(str(option.value) + '/')\n        value = \"\".join(value)\n        value = value[:-1]\n        return value", "response": "Returns the Uri - Path of a request containing the set of all the resource types that are part of the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the Uri - Path of a request.", "response": "def uri_path(self, path):\n        \"\"\"\n        Set the Uri-Path of a request.\n\n        :param path: the Uri-Path\n        \"\"\"\n        path = path.strip(\"/\")\n        tmp = path.split(\"?\")\n        path = tmp[0]\n        paths = path.split(\"/\")\n        for p in paths:\n            option = Option()\n            option.number = defines.OptionRegistry.URI_PATH.number\n            option.value = p\n            self.add_option(option)\n        if len(tmp) > 1:\n            query = tmp[1]\n            self.uri_query = query"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Uri - Query of a request.", "response": "def uri_query(self):\n        \"\"\"\n        Get the Uri-Query of a request.\n\n        :return: the Uri-Query\n        :rtype : String\n        :return: the Uri-Query string\n        \"\"\"\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.URI_QUERY.number:\n                value.append(str(option.value))\n        return \"&\".join(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a query. option to the message.", "response": "def uri_query(self, value):\n        \"\"\"\n        Adds a query.\n\n        :param value: the query\n        \"\"\"\n        del self.uri_query\n        queries = value.split(\"&\")\n        for q in queries:\n            option = Option()\n            option.number = defines.OptionRegistry.URI_QUERY.number\n            option.value = str(q)\n            self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the Accept option of a request. If the Accept option is not specified by the request None is returned.", "response": "def accept(self):\n        \"\"\"\n        Get the Accept option of a request.\n\n        :return: the Accept value or None if not specified by the request\n        :rtype : String\n        \"\"\"\n        for option in self.options:\n            if option.number == defines.OptionRegistry.ACCEPT.number:\n                return option.value\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accept(self, value):\n        if value in list(defines.Content_types.values()):\n            option = Option()\n            option.number = defines.OptionRegistry.ACCEPT.number\n            option.value = value\n            self.add_option(option)", "response": "Add an Accept option to a request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the If - Match option of a request.", "response": "def if_match(self):\n        \"\"\"\n        Get the If-Match option of a request.\n\n        :return: the If-Match values or [] if not specified by the request\n        :rtype : list\n        \"\"\"\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.IF_MATCH.number:\n                value.append(option.value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the If - Match option of a request.", "response": "def if_match(self, values):\n        \"\"\"\n        Set the If-Match option of a request.\n\n        :param values: the If-Match values\n        :type values : list\n        \"\"\"\n        assert isinstance(values, list)\n        for v in values:\n            option = Option()\n            option.number = defines.OptionRegistry.IF_MATCH.number\n            option.value = v\n            self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the if - none - match option is present otherwise False.", "response": "def if_none_match(self):\n        \"\"\"\n        Get the if-none-match option of a request.\n\n        :return: True, if if-none-match is present\n        :rtype : bool\n        \"\"\"\n        for option in self.options:\n            if option.number == defines.OptionRegistry.IF_NONE_MATCH.number:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the if - none - match option to the request.", "response": "def add_if_none_match(self):\n        \"\"\"\n        Add the if-none-match option to the request.\n        \"\"\"\n        option = Option()\n        option.number = defines.OptionRegistry.IF_NONE_MATCH.number\n        option.value = None\n        self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_no_response(self):\n        option = Option()\n        option.number = defines.OptionRegistry.NO_RESPONSE.number\n        option.value = 26\n        self.add_option(option)", "response": "Add the no - response option to the request\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef proxy_uri(self):\n        for option in self.options:\n            if option.number == defines.OptionRegistry.PROXY_URI.number:\n                return option.value\n        return None", "response": "Returns the Proxy - Uri option of a request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef proxy_uri(self, value):\n        option = Option()\n        option.number = defines.OptionRegistry.PROXY_URI.number\n        option.value = str(value)\n        self.add_option(option)", "response": "Set the Proxy - Uri option of a request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the Proxy - Schema option of a request.", "response": "def proxy_schema(self):\n        \"\"\"\n        Get the Proxy-Schema option of a request.\n\n        :return: the Proxy-Schema values or None if not specified by the request\n        :rtype : String\n        \"\"\"\n        for option in self.options:\n            if option.number == defines.OptionRegistry.PROXY_SCHEME.number:\n                return option.value\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proxy_schema(self, value):\n        option = Option()\n        option.number = defines.OptionRegistry.PROXY_SCHEME.number\n        option.value = str(value)\n        self.add_option(option)", "response": "Set the Proxy - Schema option of a request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cache_add(self, request, response):\n        logger.debug(\"adding response to the cache\")\n\n        \"\"\"\n        checking for valid code\n-       \"\"\"\n        code = response.code\n        try:\n            utils.check_code(code)\n        except utils.InvalidResponseCode:  # pragma no cover\n            logger.error(\"Invalid response code\")\n            return\n\n        \"\"\"\n        return if max_age is 0\n        \"\"\"\n        if response.max_age == 0:\n            return\n\n        \"\"\"\n        Initialising new cache element based on the mode and updating the cache\n        \"\"\"\n\n        if self.mode == defines.FORWARD_PROXY:\n            new_key = CacheKey(request)\n        else:\n            new_key = ReverseCacheKey(request)\n\n        logger.debug(\"MaxAge = {maxage}\".format(maxage=response.max_age))\n        new_element = CacheElement(new_key, response, request, response.max_age)\n\n        self.cache.update(new_key, new_element)\n        logger.debug(\"Cache Size = {size}\".format(size=self.cache.debug_print()))", "response": "Add a response to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_related(self, request):\n        logger.debug(\"Cache Search Request\")\n        if self.cache.is_empty() is True:\n            logger.debug(\"Empty Cache\")\n            return None\n\n        \"\"\"\n        extracting everything from the cache\n        \"\"\"\n        result = []\n        items = list(self.cache.cache.items())\n\n        for key, item in items:\n            element = self.cache.get(item.key)\n            logger.debug(\"Element : {elm}\".format(elm=str(element)))\n\n            if request.proxy_uri == element.uri:\n                result.append(item)\n\n        return result", "response": "Search related cache items."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches the cache for a new key and returns the response", "response": "def search_response(self, request):\n        \"\"\"\n        creates a key from the request and searches the cache with it\n\n        :param request:\n        :return CacheElement: returns None if there's a cache miss\n        \"\"\"\n        logger.debug(\"Cache Search Response\")\n\n        if self.cache.is_empty() is True:\n            logger.debug(\"Empty Cache\")\n            return None\n\n        \"\"\"\n        create a new cache key from the request\n        \"\"\"\n\n        if self.mode == defines.FORWARD_PROXY:\n            search_key = CacheKey(request)\n        else:\n            search_key = ReverseCacheKey(request)\n\n        response = self.cache.get(search_key)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh a resource when a validation response is received", "response": "def validate(self, request, response):\n        \"\"\"\n        refreshes a resource when a validation response is received\n\n        :param request:\n        :param response:\n        :return:\n        \"\"\"\n        element = self.search_response(request)\n        if element is not None:\n            element.cached_response.options = response.options\n            element.freshness = True\n            element.max_age = response.max_age\n            element.creation_time = time.time()\n            element.uri = request.proxy_uri"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark the requested resource in the cache as not fresh.", "response": "def mark(self, element):\n        \"\"\"\n        marks the requested resource in the cache as not fresh\n        :param element:\n        :return:\n        \"\"\"\n        logger.debug(\"Element : {elm}\".format(elm=str(element)))\n        if element is not None:\n            logger.debug(\"Mark as not fresh\")\n            element.freshness = False\n        logger.debug(str(self.cache))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receive_request(self, transaction):\n        uri = transaction.request.proxy_uri\n        if uri is None:\n            transaction.response = Response()\n            transaction.response.destination = transaction.request.source\n            transaction.response.token = transaction.request.token\n            transaction.response.type = defines.Types[\"RST\"]\n            transaction.response.code = defines.Codes.BAD_REQUEST.number\n            return transaction\n\n        host, port, path = parse_uri(uri)\n        path = str(\"/\" + path)\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n        return self._forward_request(transaction, (host, port), path)", "response": "Setup the transaction for forwarding purposes on Forward Proxies on Forward Proxies on Forward Proxies on HTTP."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef receive_request_reverse(self, transaction):\n        path = str(\"/\" + transaction.request.uri_path)\n        transaction.response = Response()\n        transaction.response.destination = transaction.request.source\n        transaction.response.token = transaction.request.token\n        if path == defines.DISCOVERY_URL:\n            transaction = self._server.resourceLayer.discover(transaction)\n        else:\n            new = False\n            if transaction.request.code == defines.Codes.POST.number:\n                new_paths = self._server.root.with_prefix(path)\n                new_path = \"/\"\n                for tmp in new_paths:\n                    if len(tmp) > len(new_path):\n                        new_path = tmp\n                if path != new_path:\n                    new = True\n                path = new_path\n            try:\n                resource = self._server.root[path]\n            except KeyError:\n                resource = None\n            if resource is None or path == '/':\n                # Not Found\n                transaction.response.code = defines.Codes.NOT_FOUND.number\n            else:\n                transaction.resource = resource\n                transaction = self._handle_request(transaction, new)\n        return transaction", "response": "Handles the request for the current resource and returns the edited transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nforward the request to the destination.", "response": "def _forward_request(transaction, destination, path):\n        \"\"\"\n        Forward requests.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :param destination: the destination of the request (IP, port)\n        :param path: the path of the request.\n        :rtype : Transaction\n        :return: the edited transaction\n        \"\"\"\n        client = HelperClient(destination)\n        request = Request()\n        request.options = copy.deepcopy(transaction.request.options)\n        del request.block2\n        del request.block1\n        del request.uri_path\n        del request.proxy_uri\n        del request.proxy_schema\n        # TODO handle observing\n        del request.observe\n        # request.observe = transaction.request.observe\n\n        request.uri_path = path\n        request.destination = destination\n        request.payload = transaction.request.payload\n        request.code = transaction.request.code\n        response = client.send_request(request)\n        client.stop()\n        if response is not None:\n            transaction.response.payload = response.payload\n            transaction.response.code = response.code\n            transaction.response.options = response.options\n        else:\n            transaction.response.code = defines.Codes.SERVICE_UNAVAILABLE.number\n\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the request for the current set of virtual resources.", "response": "def _handle_request(self, transaction, new_resource):\n        \"\"\"\n        Forward requests. Used by reverse proxies to also create new virtual resources on the proxy \n        in case of created resources\n        \n        :type new_resource: bool\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the request\n        :rtype : Transaction\n        :param new_resource: if the request will generate a new resource \n        :return: the edited transaction\n        \"\"\"\n        client = HelperClient(transaction.resource.remote_server)\n        request = Request()\n        request.options = copy.deepcopy(transaction.request.options)\n        del request.block2\n        del request.block1\n        del request.uri_path\n        del request.proxy_uri\n        del request.proxy_schema\n        # TODO handle observing\n        del request.observe\n        # request.observe = transaction.request.observe\n\n        request.uri_path = \"/\".join(transaction.request.uri_path.split(\"/\")[1:])\n        request.destination = transaction.resource.remote_server\n        request.payload = transaction.request.payload\n        request.code = transaction.request.code\n        response = client.send_request(request)\n        client.stop()\n        transaction.response.payload = response.payload\n        transaction.response.code = response.code\n        transaction.response.options = response.options\n        if response.code == defines.Codes.CREATED.number:\n            lp = transaction.response.location_path\n            del transaction.response.location_path\n            transaction.response.location_path = transaction.request.uri_path.split(\"/\")[0] + \"/\" + lp\n            # TODO handle observing\n            if new_resource:\n                resource = RemoteResource('server', transaction.resource.remote_server, lp, coap_server=self,\n                                          visible=True,\n                                          observable=False,\n                                          allow_children=True)\n                self._server.add_resource(transaction.response.location_path, resource)\n        if response.code == defines.Codes.DELETED.number:\n            del self._server.root[\"/\" + transaction.request.uri_path]\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_message(self, message):\n        if isinstance(message, Request):\n            request = self._requestLayer.send_request(message)\n            request = self._observeLayer.send_request(request)\n            request = self._blockLayer.send_request(request)\n            transaction = self._messageLayer.send_request(request)\n            self.send_datagram(transaction.request)\n            if transaction.request.type == defines.Types[\"CON\"]:\n                self._start_retransmission(transaction, transaction.request)\n        elif isinstance(message, Message):\n            message = self._observeLayer.send_empty(message)\n            message = self._messageLayer.send_empty(None, None, message)\n            self.send_datagram(message)", "response": "Send a message to the UDP socket. Eventually set retransmissions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for the retransmit thread to finish", "response": "def _wait_for_retransmit_thread(transaction):\n        \"\"\"\n        Only one retransmit thread at a time, wait for other to finish\n        \n        \"\"\"\n        if hasattr(transaction, 'retransmit_thread'):\n            while transaction.retransmit_thread is not None:\n                logger.debug(\"Waiting for retransmit thread to finish ...\")\n                time.sleep(0.01)\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _send_block_request(self, transaction):\n        transaction = self._messageLayer.send_request(transaction.request)\n        # ... but don't forget to reset the acknowledge flag\n        transaction.request.acknowledged = False\n        self.send_datagram(transaction.request)\n        if transaction.request.type == defines.Types[\"CON\"]:\n            self._start_retransmission(transaction, transaction.request)", "response": "Send a block wise request to the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message over the UDP socket.", "response": "def send_datagram(self, message):\n        \"\"\"\n        Send a message over the UDP socket.\n\n        :param message: the message to send\n        \"\"\"\n        host, port = message.destination\n        logger.debug(\"send_datagram - \" + str(message))\n        serializer = Serializer()\n        raw_message = serializer.serialize(message)\n\n        try:\n            self._socket.sendto(raw_message, (host, port))\n        except Exception as e:\n            if self._cb_ignore_write_exception is not None and isinstance(self._cb_ignore_write_exception, collections.Callable):\n                if not self._cb_ignore_write_exception(e, self):\n                    raise\n\n        # if you're explicitly setting that you don't want a response, don't wait for it\n        # https://tools.ietf.org/html/rfc7967#section-2.1\n        for opt in message.options:\n            if opt.number == defines.OptionRegistry.NO_RESPONSE.number:\n                if opt.value == 26:\n                    return\n\n        if self._receiver_thread is None or not self._receiver_thread.isAlive():\n            self._receiver_thread = threading.Thread(target=self.receive_datagram)\n            self._receiver_thread.daemon = True\n            self._receiver_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the retransmission task.", "response": "def _start_retransmission(self, transaction, message):\n        \"\"\"\n        Start the retransmission task.\n\n        :type transaction: Transaction\n        :param transaction: the transaction that owns the message that needs retransmission\n        :type message: Message\n        :param message: the message that needs the retransmission task\n        \"\"\"\n        with transaction:\n            if message.type == defines.Types['CON']:\n                future_time = random.uniform(defines.ACK_TIMEOUT, (defines.ACK_TIMEOUT * defines.ACK_RANDOM_FACTOR))\n                transaction.retransmit_stop = threading.Event()\n                self.to_be_stopped.append(transaction.retransmit_stop)\n                transaction.retransmit_thread = threading.Thread(target=self._retransmit,\n                                                                 name=str('%s-Retry-%d' % (threading.current_thread().name, message.mid)),\n                                                                 args=(transaction, message, future_time, 0))\n                transaction.retransmit_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreceiving datagram from the UDP socket and invoke the callback function.", "response": "def receive_datagram(self):\n        \"\"\"\n        Receive datagram from the UDP socket and invoke the callback function.\n        \"\"\"\n        logger.debug(\"Start receiver Thread\")\n        while not self.stopped.isSet():\n            self._socket.settimeout(0.1)\n            try:\n                datagram, addr = self._socket.recvfrom(1152)\n            except socket.timeout:  # pragma: no cover\n                continue\n            except Exception as e:  # pragma: no cover\n                if self._cb_ignore_read_exception is not None and isinstance(self._cb_ignore_read_exception, collections.Callable):\n                    if self._cb_ignore_read_exception(e, self):\n                        continue\n                return\n            else:  # pragma: no cover\n                if len(datagram) == 0:\n                    logger.debug(\"Exiting receiver Thread due to orderly shutdown on server end\")\n                    return\n\n            serializer = Serializer()\n\n            try:\n                host, port = addr\n            except ValueError:\n                host, port, tmp1, tmp2 = addr\n\n            source = (host, port)\n\n            message = serializer.deserialize(datagram, source)\n\n            if isinstance(message, Response):\n                logger.debug(\"receive_datagram - \" + str(message))\n                transaction, send_ack = self._messageLayer.receive_response(message)\n                if transaction is None:  # pragma: no cover\n                    continue\n                self._wait_for_retransmit_thread(transaction)\n                if send_ack:\n                    self._send_ack(transaction)\n                self._blockLayer.receive_response(transaction)\n                if transaction.block_transfer:\n                    self._send_block_request(transaction)\n                    continue\n                elif transaction is None:  # pragma: no cover\n                    self._send_rst(transaction)\n                    return\n                self._observeLayer.receive_response(transaction)\n                if transaction.notification:  # pragma: no cover\n                    ack = Message()\n                    ack.type = defines.Types['ACK']\n                    ack = self._messageLayer.send_empty(transaction, transaction.response, ack)\n                    self.send_datagram(ack)\n                    self._callback(transaction.response)\n                else:\n                    self._callback(transaction.response)\n            elif isinstance(message, Message):\n                self._messageLayer.receive_empty(message)\n\n        logger.debug(\"Exiting receiver Thread due to request\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an RST message for the response.", "response": "def _send_rst(self, transaction):  # pragma: no cover\n        \"\"\"\n        Sends an RST message for the response.\n\n        :param transaction: transaction that holds the response\n        \"\"\"\n\n        rst = Message()\n        rst.type = defines.Types['RST']\n\n        if not transaction.response.acknowledged:\n            rst = self._messageLayer.send_empty(transaction, transaction.response, rst)\n            self.send_datagram(rst)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_request(self, transaction):\n\n        transaction.cached_element = self.cache.search_response(transaction.request)\n        if transaction.cached_element is None:\n            transaction.cacheHit = False\n        else:\n            transaction.response = transaction.cached_element.cached_response\n            transaction.response.mid = transaction.request.mid\n            transaction.cacheHit = True\n\n            age = transaction.cached_element.creation_time + transaction.cached_element.max_age - time.time()\n            if transaction.cached_element.freshness is True:\n                if age <= 0:\n                    logger.debug(\"resource not fresh\")\n                    \"\"\"\n                    if the resource is not fresh, its Etag must be added to the request so that the server might validate it instead of sending a new one\n                    \"\"\"\n                    transaction.cached_element.freshness = False\n                    \"\"\"\n                    ensuring that the request goes to the server\n                    \"\"\"\n                    transaction.cacheHit = False\n                    logger.debug(\"requesting etag %s\", transaction.response.etag)\n                    transaction.request.etag = transaction.response.etag\n                else:\n                    transaction.response.max_age = age\n            else:\n                transaction.cacheHit = False\n        return transaction", "response": "checks the cache for a response to the request and adds it to the response object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a response based on the code", "response": "def send_response(self, transaction):\n        \"\"\"\n        updates the cache with the response if there was a cache miss\n\n        :param transaction:\n        :return:\n        \"\"\"\n        if transaction.cacheHit is False:\n            \"\"\"\n            handling response based on the code\n            \"\"\"\n            logger.debug(\"handling response\")\n            self._handle_response(transaction)\n        return transaction"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_response(self, transaction):\n        code = transaction.response.code\n        utils.check_code(code)\n        \"\"\"\n        VALID response:\n        change the current cache value by switching the option set with the one provided\n        also resets the timestamp\n        if the request etag is different from the response, send the cached response\n        \"\"\"\n        if code == Codes.VALID.number:\n            logger.debug(\"received VALID\")\n            self.cache.validate(transaction.request, transaction.response)\n            if transaction.request.etag != transaction.response.etag:\n                element = self.cache.search_response(transaction.request)\n                transaction.response = element.cached_response\n            return transaction\n\n        \"\"\"\n        CHANGED, CREATED or DELETED response:\n        mark the requested resource as not fresh\n        \"\"\"\n        if code == Codes.CHANGED.number or code == Codes.CREATED.number or code == Codes.DELETED.number:\n            target = self.cache.search_related(transaction.request)\n            if target is not None:\n                for element in target:\n                    self.cache.mark(element)\n            return transaction\n\n        \"\"\"\n        any other response code can be cached normally\n        \"\"\"\n        self.cache.cache_add(transaction.request, transaction.response)\n        return transaction", "response": "handles responses based on their type and returns the related cache entry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the CoAP version of the object.", "response": "def version(self, v):\n        \"\"\"\n        Sets the CoAP version\n\n        :param v: the version\n        :raise AttributeError: if value is not 1\n        \"\"\"\n        if not isinstance(v, int) or v != 1:\n            raise AttributeError\n        self._version = v"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the type of the message.", "response": "def type(self, value):\n        \"\"\"\n        Sets the type of the message.\n\n        :type value: Types\n        :param value: the type\n        :raise AttributeError: if value is not a valid type\n        \"\"\"\n        if value not in list(defines.Types.values()):\n            raise AttributeError\n        self._type = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the MID of the message.", "response": "def mid(self, value):\n        \"\"\"\n        Sets the MID of the message.\n\n        :type value: Integer\n        :param value: the MID\n        :raise AttributeError: if value is not int or cannot be represented on 16 bits.\n        \"\"\"\n        if not isinstance(value, int) or value > 65536:\n            raise AttributeError\n        self._mid = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef token(self, value):\n        if value is None:\n            self._token = value\n            return\n        if not isinstance(value, str):\n            value = str(value)\n        if len(value) > 256:\n            raise AttributeError\n        self._token = value", "response": "Sets the Token of the message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the options of the CoAP message.", "response": "def options(self, value):\n        \"\"\"\n        Set the options of the CoAP message.\n\n        :type value: list\n        :param value: list of options\n        \"\"\"\n        if value is None:\n            value = []\n        assert isinstance(value, list)\n        self._options = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef payload(self, value):\n        if isinstance(value, tuple):\n            content_type, payload = value\n            self.content_type = content_type\n            self._payload = payload\n        else:\n            self._payload = value", "response": "Sets the payload of the message and eventually the Content - Type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the destination of the message.", "response": "def destination(self, value):\n        \"\"\"\n        Set the destination of the message.\n\n        :type value: tuple\n        :param value: (ip, port)\n        :raise AttributeError: if value is not a ip and a port.\n        \"\"\"\n        if value is not None and (not isinstance(value, tuple) or len(value)) != 2:\n            raise AttributeError\n        self._destination = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef source(self, value):\n        if not isinstance(value, tuple) or len(value) != 2:\n            raise AttributeError\n        self._source = value", "response": "Set the source of the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the code of the message.", "response": "def code(self, value):\n        \"\"\"\n        Set the code of the message.\n\n        :type value: Codes\n        :param value: the code\n        :raise AttributeError: if value is not a valid code\n        \"\"\"\n        if value not in list(defines.Codes.LIST.keys()) and value is not None:\n            raise AttributeError\n        self._code = value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the acknowledged flag.", "response": "def acknowledged(self, value):\n        \"\"\"\n        Marks this message as acknowledged.\n\n        :type value: Boolean\n        :param value: if acknowledged\n        \"\"\"\n        assert (isinstance(value, bool))\n        self._acknowledged = value\n        if value:\n            self._timeouted = False\n            self._rejected = False\n            self._cancelled = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the flag indicating that this message was rejected.", "response": "def rejected(self, value):\n        \"\"\"\n        Marks this message as rejected.\n\n        :type value: Boolean\n        :param value: if rejected\n        \"\"\"\n        assert (isinstance(value, bool))\n        self._rejected = value\n        if value:\n            self._timeouted = False\n            self._acknowledged = False\n            self._cancelled = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if an option is already in the message.", "response": "def _already_in(self, option):\n        \"\"\"\n        Check if an option is already in the message.\n\n        :type option: Option\n        :param option: the option to be checked\n        :return: True if already present, False otherwise\n        \"\"\"\n        for opt in self._options:\n            if option.number == opt.number:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_option(self, option):\n        assert isinstance(option, Option)\n        repeatable = defines.OptionRegistry.LIST[option.number].repeatable\n        if not repeatable:\n            ret = self._already_in(option)\n            if ret:\n                raise TypeError(\"Option : %s is not repeatable\", option.name)\n            else:\n                self._options.append(option)\n        else:\n            self._options.append(option)", "response": "Add an option to the message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting an option from the message", "response": "def del_option(self, option):\n        \"\"\"\n        Delete an option from the message\n\n        :type option: Option\n        :param option: the option\n        \"\"\"\n        assert isinstance(option, Option)\n        while option in list(self._options):\n            self._options.remove(option)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an option from the message by name.", "response": "def del_option_by_name(self, name):\n        \"\"\"\n        Delete an option from the message by name\n\n        :type name: String\n        :param name: option name\n        \"\"\"\n        for o in list(self._options):\n            assert isinstance(o, Option)\n            if o.name == name:\n                self._options.remove(o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes an option from the message by number.", "response": "def del_option_by_number(self, number):\n        \"\"\"\n        Delete an option from the message by number\n\n        :type number: Integer\n        :param number: option naumber\n        \"\"\"\n        for o in list(self._options):\n            assert isinstance(o, Option)\n            if o.number == number:\n                self._options.remove(o)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef etag(self):\n        value = []\n        for option in self.options:\n            if option.number == defines.OptionRegistry.ETAG.number:\n                value.append(option.value)\n        return value", "response": "Returns the ETag option of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an ETag option to the message.", "response": "def etag(self, etag):\n        \"\"\"\n        Add an ETag option to the message.\n\n        :param etag: the etag\n        \"\"\"\n        if not isinstance(etag, list):\n            etag = [etag]\n        for e in etag:\n            option = Option()\n            option.number = defines.OptionRegistry.ETAG.number\n            if not  isinstance(e, bytes):\n                e = bytes(e, \"utf-8\")\n            option.value = e\n            self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the Content - Type option of a response.", "response": "def content_type(self):\n        \"\"\"\n        Get the Content-Type option of a response.\n\n        :return: the Content-Type value or 0 if not specified by the response\n        \"\"\"\n        value = 0\n        for option in self.options:\n            if option.number == defines.OptionRegistry.CONTENT_TYPE.number:\n                value = int(option.value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef content_type(self, content_type):\n        option = Option()\n        option.number = defines.OptionRegistry.CONTENT_TYPE.number\n        option.value = int(content_type)\n        self.add_option(option)", "response": "Set the Content - Type option of a response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef observe(self):\n        for option in self.options:\n            if option.number == defines.OptionRegistry.OBSERVE.number:\n                # if option.value is None:\n                #    return 0\n                if option.value is None:\n                    return 0\n                return option.value\n        return None", "response": "Check if the request is an observing request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the Observe option. Observe is a convenience method that adds the Observe option.", "response": "def observe(self, ob):\n        \"\"\"\n        Add the Observe option.\n\n        :param ob: observe count\n        \"\"\"\n        option = Option()\n        option.number = defines.OptionRegistry.OBSERVE.number\n        option.value = ob\n        self.del_option_by_number(defines.OptionRegistry.OBSERVE.number)\n        self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the Block1 option.", "response": "def block1(self):\n        \"\"\"\n        Get the Block1 option.\n\n        :return: the Block1 value\n        \"\"\"\n        value = None\n        for option in self.options:\n            if option.number == defines.OptionRegistry.BLOCK1.number:\n                value = parse_blockwise(option.value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the Block1 option.", "response": "def block1(self, value):\n        \"\"\"\n        Set the Block1 option.\n\n        :param value: the Block1 value\n        \"\"\"\n        option = Option()\n        option.number = defines.OptionRegistry.BLOCK1.number\n        num, m, size = value\n        if size > 512:\n            szx = 6\n        elif 256 < size <= 512:\n            szx = 5\n        elif 128 < size <= 256:\n            szx = 4\n        elif 64 < size <= 128:\n            szx = 3\n        elif 32 < size <= 64:\n            szx = 2\n        elif 16 < size <= 32:\n            szx = 1\n        else:\n            szx = 0\n\n        value = (num << 4)\n        value |= (m << 3)\n        value |= szx\n\n        option.value = value\n        self.add_option(option)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the Block2 option.", "response": "def block2(self):\n        \"\"\"\n        Get the Block2 option.\n\n        :return: the Block2 value\n        \"\"\"\n        value = None\n        for option in self.options:\n            if option.number == defines.OptionRegistry.BLOCK2.number:\n                value = parse_blockwise(option.value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef block2(self, value):\n        option = Option()\n        option.number = defines.OptionRegistry.BLOCK2.number\n        num, m, size = value\n        if size > 512:\n            szx = 6\n        elif 256 < size <= 512:\n            szx = 5\n        elif 128 < size <= 256:\n            szx = 4\n        elif 64 < size <= 128:\n            szx = 3\n        elif 32 < size <= 64:\n            szx = 2\n        elif 16 < size <= 32:\n            szx = 1\n        else:\n            szx = 0\n\n        value = (num << 4)\n        value |= (m << 3)\n        value |= szx\n\n        option.value = value\n        self.add_option(option)", "response": "Set the Block2 option."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the message as a one - line string.", "response": "def line_print(self):\n        \"\"\"\n        Return the message as a one-line string.\n\n        :return: the string representing the message\n        \"\"\"\n        inv_types = {v: k for k, v in defines.Types.items()}\n\n        if self._code is None:\n            self._code = defines.Codes.EMPTY.number\n\n        msg = \"From {source}, To {destination}, {type}-{mid}, {code}-{token}, [\"\\\n            .format(source=self._source, destination=self._destination, type=inv_types[self._type], mid=self._mid,\n                    code=defines.Codes.LIST[self._code].name, token=self._token)\n        for opt in self._options:\n            msg += \"{name}: {value}, \".format(name=opt.name, value=opt.value)\n        msg += \"]\"\n        if self.payload is not None:\n            if isinstance(self.payload, dict):\n                tmp = list(self.payload.values())[0][0:20]\n            else:\n                tmp = self.payload[0:20]\n            msg += \" {payload}...{length} bytes\".format(payload=tmp, length=len(self.payload))\n        else:\n            msg += \" No payload\"\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_print(self):\n        msg = \"Source: \" + str(self._source) + \"\\n\"\n        msg += \"Destination: \" + str(self._destination) + \"\\n\"\n        inv_types = {v: k for k, v in defines.Types.items()}\n        msg += \"Type: \" + str(inv_types[self._type]) + \"\\n\"\n        msg += \"MID: \" + str(self._mid) + \"\\n\"\n        if self._code is None:\n            self._code = 0\n\n        msg += \"Code: \" + str(defines.Codes.LIST[self._code].name) + \"\\n\"\n        msg += \"Token: \" + str(self._token) + \"\\n\"\n        for opt in self._options:\n            msg += str(opt)\n        msg += \"Payload: \" + \"\\n\"\n        msg += str(self._payload) + \"\\n\"\n        return msg", "response": "Return the message as a formatted string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interp_box(x, y, z, box, values):\n\n    # Calculate the distance to each vertex\n\n    val = 0\n    norm = 0\n    for i in range(8):\n        # Inv distance, or Inv-dsq weighting\n        distance = sqrt((x-box[i,0])**2 + (y-box[i,1])**2 + (z-box[i, 2])**2)\n\n        # If you happen to land on exactly a corner, you're done.\n        if distance == 0:\n            val = values[i]\n            norm = 1.\n            break\n\n        w = 1./distance\n        # w = 1./((x-box[i,0])*(x-box[i,0]) +\n        #         (y-box[i,1])*(y-box[i,1]) +\n        #         (z-box[i, 2])*(z-box[i, 2]))\n        val += w * values[i]\n        norm += w\n\n    return val/norm", "response": "Calculate the value of a single entry in a box."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninterpolate the values of the given array of values at the specified column index.", "response": "def interp_values(mass_arr, age_arr, feh_arr, icol,\n                 grid, mass_col, ages, fehs, grid_Ns):\n    \"\"\"mass_arr, age_arr, feh_arr are all arrays at which values are desired\n\n    icol is the column index of desired value\n    grid is nfeh x nage x max(nmass) x ncols array\n    mass_col is the column index of mass\n    ages is grid of ages\n    fehs is grid of fehs\n    grid_Ns keeps track of nmass in each slice (beyond this are nans)\n\n    \"\"\"\n\n    N = len(mass_arr)\n    results = np.zeros(N)\n\n    Nage = len(ages)\n    Nfeh = len(fehs)\n\n    for i in range(N):\n        results[i] = interp_value(mass_arr[i], age_arr[i], feh_arr[i], icol,\n                                 grid, mass_col, ages, fehs, grid_Ns, False)\n\n        ## Things are slightly faster if the below is used, but for consistency,\n        ## using above.\n        # mass = mass_arr[i]\n        # age = age_arr[i]\n        # feh = feh_arr[i]\n\n        # ifeh = searchsorted(fehs, Nfeh, feh)\n        # iage = searchsorted(ages, Nage, age)\n        # if ifeh==0 or iage==0 or ifeh==Nfeh or iage==Nage:\n        #     results[i] = np.nan\n        #     continue\n\n        # pts = np.zeros((8,3))\n        # vals = np.zeros(8)\n\n        # i_f = ifeh - 1\n        # i_a = iage - 1\n        # Nmass = grid_Ns[i_f, i_a]\n        # imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        # pts[0, 0] = grid[i_f, i_a, imass, mass_col]\n        # pts[0, 1] = ages[i_a]\n        # pts[0, 2] = fehs[i_f]\n        # vals[0] = grid[i_f, i_a, imass, icol]\n        # pts[1, 0] = grid[i_f, i_a, imass-1, mass_col]\n        # pts[1, 1] = ages[i_a]\n        # pts[1, 2] = fehs[i_f]\n        # vals[1] = grid[i_f, i_a, imass-1, icol]\n\n        # i_f = ifeh - 1\n        # i_a = iage\n        # Nmass = grid_Ns[i_f, i_a]\n        # imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        # pts[2, 0] = grid[i_f, i_a, imass, mass_col]\n        # pts[2, 1] = ages[i_a]\n        # pts[2, 2] = fehs[i_f]\n        # vals[2] = grid[i_f, i_a, imass, icol]\n        # pts[3, 0] = grid[i_f, i_a, imass-1, mass_col]\n        # pts[3, 1] = ages[i_a]\n        # pts[3, 2] = fehs[i_f]\n        # vals[3] = grid[i_f, i_a, imass-1, icol]\n\n        # i_f = ifeh\n        # i_a = iage - 1\n        # Nmass = grid_Ns[i_f, i_a]\n        # imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        # pts[4, 0] = grid[i_f, i_a, imass, mass_col]\n        # pts[4, 1] = ages[i_a]\n        # pts[4, 2] = fehs[i_f]\n        # vals[4] = grid[i_f, i_a, imass, icol]\n        # pts[5, 0] = grid[i_f, i_a, imass-1, mass_col]\n        # pts[5, 1] = ages[i_a]\n        # pts[5, 2] = fehs[i_f]\n        # vals[5] = grid[i_f, i_a, imass-1, icol]\n\n        # i_f = ifeh\n        # i_a = iage\n        # Nmass = grid_Ns[i_f, i_a]\n        # imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        # pts[6, 0] = grid[i_f, i_a, imass, mass_col]\n        # pts[6, 1] = ages[i_a]\n        # pts[6, 2] = fehs[i_f]\n        # vals[6] = grid[i_f, i_a, imass, icol]\n        # pts[7, 0] = grid[i_f, i_a, imass-1, mass_col]\n        # pts[7, 1] = ages[i_a]\n        # pts[7, 2] = fehs[i_f]\n        # vals[7] = grid[i_f, i_a, imass-1, icol]\n\n        # results[i] = interp_box(mass, age, feh, pts, vals)\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the feh of a file", "response": "def get_feh(cls, filename):\n        \"\"\"\n        example filename: yapsi_w_X0p602357_Z0p027643.dat\n        \"\"\"\n        X,Y,Z = cls._get_XYZ(filename)\n\n        Xsun = 0.703812\n        Zsun = 0.016188\n\n        return np.log10((Z/X) / (Zsun/Xsun))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of photometry of closest match COOKIE.", "response": "def get_photometry(self, brightest=False,\n                    min_unc=0.02, convert=True):\n        \"\"\"Returns dictionary of photometry of closest match\n\n        unless brightest is True, in which case the brightest match.\n        \"\"\"\n        if brightest:\n            row = self.brightest\n        else:\n            row = self.closest\n\n        if not hasattr(self, 'conversions'):\n            convert = False\n\n        if convert:\n            bands = self.conversions\n        else:\n            bands = self.bands.keys()\n\n        d = {}\n        for b in bands:\n            if convert:\n                key = b\n                mag, dmag = getattr(self, b)(brightest=brightest)\n            else:\n                key = self.bands[b]\n                mag, dmag = row[b], row['e_{}'.format(b)]\n\n            d[key] = mag, max(dmag, min_unc)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ichrone(models, bands=None, default=False, **kwargs):\n    if isinstance(models, Isochrone):\n        return models\n\n    def actual(bands, ictype):\n        if bands is None:\n            return list(ictype.default_bands)\n        elif default:\n            return list(set(bands).union(set(ictype.default_bands)))\n        else:\n            return bands\n\n    if type(models) is type(type):\n        ichrone = models(actual(bands, models))\n    elif models=='dartmouth':\n        from isochrones.dartmouth import Dartmouth_Isochrone\n        ichrone = Dartmouth_Isochrone(bands=actual(bands, Dartmouth_Isochrone), **kwargs)\n    elif models=='dartmouthfast':\n        from isochrones.dartmouth import Dartmouth_FastIsochrone\n        ichrone = Dartmouth_FastIsochrone(bands=actual(bands, Dartmouth_FastIsochrone), **kwargs)\n    elif models=='mist':\n        from isochrones.mist import MIST_Isochrone\n        ichrone = MIST_Isochrone(bands=actual(bands, MIST_Isochrone), **kwargs)\n    elif models=='padova':\n        from isochrones.padova import Padova_Isochrone\n        ichrone = Padova_Isochrone(bands=actual(bands, Padova_Isochrone), **kwargs)\n    elif models=='basti':\n        from isochrones.basti import Basti_Isochrone\n        ichrone = Basti_Isochrone(bands=actual(bands, Basti_Isochrone), **kwargs)\n    else:\n        raise ValueError('Unknown stellar models: {}'.format(models))\n    return ichrone", "response": "Gets Isochrone Object by name or type with the right bands"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef density(self, *args):\n        M = self.mass(*args) * MSUN\n        V = 4./3 * np.pi * (self.radius(*args) * RSUN)**3\n        return  M/V", "response": "Mean density in g / cc\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns asteroseismic delta_nu in uHz", "response": "def delta_nu(self, *args):\n        \"\"\"Returns asteroseismic delta_nu in uHz\n\n        reference: https://arxiv.org/pdf/1312.3853v1.pdf, Eq (2)\n        \"\"\"\n        return 134.88 * np.sqrt(self.mass(*args) / self.radius(*args)**3)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning asteroseismic nu_max in uHz", "response": "def nu_max(self, *args):\n        \"\"\"Returns asteroseismic nu_max in uHz\n\n        reference: https://arxiv.org/pdf/1312.3853v1.pdf, Eq (3)\n        \"\"\"\n        return 3120.* (self.mass(*args) /\n                        (self.radius(*args)**2 * np.sqrt(self.Teff(*args)/5777.)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the min and max allowed ages for a given mass and feh.", "response": "def agerange(self, m, feh=0.0):\n        \"\"\"\n        For a given mass and feh, returns the min and max allowed ages.\n        \"\"\"\n        ages = np.arange(self.minage, self.maxage, 0.01)\n        rs = self.radius(m, ages, feh)\n        w = np.where(np.isfinite(rs))[0]\n        return ages[w[0]],ages[w[-1]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evtrack(self,m,feh=0.0,minage=None,maxage=None,dage=0.02,\n                return_df=True):\n        \"\"\"\n        Returns evolution track for a single initial mass and feh.\n\n        :param m:\n            Initial mass of desired evolution track.\n\n        :param feh: (optional)\n            Metallicity of desired track.  Default = 0.0 (solar)\n\n        :param minage, maxage: (optional)\n            Minimum and maximum log(age) of desired track. Will default\n            to min and max age of model isochrones.\n\n        :param dage: (optional)\n            Spacing in log(age) at which to evaluate models.  Default = 0.02\n\n        :param return_df: (optional)\n            Whether to return a ``DataFrame`` or dicionary.  Default is ``True``.\n\n\n        :return:\n            Either a :class:`pandas.DataFrame` or dictionary\n            representing the evolution\n            track---fixed mass, sampled at chosen range of ages.\n\n        \"\"\"\n        if minage is None:\n            minage = self.minage\n        if maxage is None:\n            maxage = self.maxage\n        ages = np.arange(minage,maxage,dage)\n        Ms = self.mass(m,ages,feh)\n        Rs = self.radius(m,ages,feh)\n        logLs = self.logL(m,ages,feh)\n        loggs = self.logg(m,ages,feh)\n        Teffs = self.Teff(m,ages,feh)\n        mags = {band:self.mag[band](m,ages,feh) for band in self.bands}\n\n        props = {'age':ages,'mass':Ms,'radius':Rs,'logL':logLs,\n                'logg':loggs, 'Teff':Teffs, 'mag':mags}\n\n        if not return_df:\n            return props\n        else:\n            d = {}\n            for key in props.keys():\n                if key=='mag':\n                    for m in props['mag'].keys():\n                        d['{}_mag'.format(m)] = props['mag'][m]\n                else:\n                    d[key] = props[key]\n            try:\n                df = pd.DataFrame(d)\n            except ValueError:\n                df = pd.DataFrame(d, index=[0])\n            return df", "response": "Returns evolution track for a single initial mass and feh."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isochrone(self,age,feh=0.0,minm=None,maxm=None,dm=0.02,\n                  return_df=True,distance=None,AV=0.0):\n        \"\"\"\n        Returns stellar models at constant age and feh, for a range of masses\n\n        :param age:\n            log10(age) of desired isochrone.\n\n        :param feh: (optional)\n            Metallicity of desired isochrone (default = 0.0)\n\n        :param minm, maxm: (optional)\n            Mass range of desired isochrone (will default to max and min available)\n\n        :param dm: (optional)\n            Spacing in mass of desired isochrone.  Default = 0.02 Msun.\n\n        :param return_df: (optional)\n            Whether to return a :class:``pandas.DataFrame`` or dictionary.  Default is ``True``.\n\n        :param distance:\n            Distance in pc.  If passed, then mags will be converted to\n            apparent mags based on distance (and ``AV``).\n\n        :param AV:\n            V-band extinction (magnitudes).\n\n        :return:\n            :class:`pandas.DataFrame` or dictionary containing results.\n\n        \"\"\"\n        if minm is None:\n            minm = self.minmass\n        if maxm is None:\n            maxm = self.maxmass\n        ms = np.arange(minm,maxm,dm)\n        ages = np.ones(ms.shape)*age\n\n        Ms = self.mass(ms,ages,feh)\n        Rs = self.radius(ms,ages,feh)\n        logLs = self.logL(ms,ages,feh)\n        loggs = self.logg(ms,ages,feh)\n        Teffs = self.Teff(ms,ages,feh)\n        mags = {band:self.mag[band](ms,ages,feh) for band in self.bands}\n        #for band in self.bands:\n        #    mags[band] = self.mag[band](ms,ages)\n        if distance is not None:\n            dm = 5*np.log10(distance) - 5\n            for band in mags:\n                A = AV*EXTINCTION[band]\n                mags[band] = mags[band] + dm + A\n\n        props = {'M':Ms,'R':Rs,'logL':logLs,'logg':loggs,\n                'Teff':Teffs,'mag':mags}\n\n        if not return_df:\n            return props\n        else:\n            d = {}\n            for key in props.keys():\n                if key=='mag':\n                    for m in props['mag'].keys():\n                        d['{}_mag'.format(m)] = props['mag'][m]\n                else:\n                    d[key] = props[key]\n            try:\n                df = pd.DataFrame(d)\n            except ValueError:\n                df = pd.DataFrame(d, index=[0])\n            return df", "response": "Returns stellar models at constant age and feh for a range of masses."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns n random mass age feh points.", "response": "def random_points(self,n,minmass=None,maxmass=None,\n                      minage=None,maxage=None,\n                      minfeh=None,maxfeh=None):\n        \"\"\"\n        Returns n random mass, age, feh points, none of which are out of range.\n\n        :param n:\n            Number of desired points.\n\n        :param minmass, maxmass: (optional)\n            Desired allowed range.  Default is mass range of ``self``.\n\n        :param minage, maxage: (optional)\n            Desired allowed range.  Default is log10(age) range of\n            ``self``.\n\n        :param minfehs, maxfeh: (optional)\n            Desired allowed range.  Default is feh range of ``self``.\n\n        :return:\n            :class:`np.ndarray` arrays of randomly selected mass, log10(age),\n            and feh values\n            within allowed ranges.  Used, e.g., to initialize random walkers for\n            :class:`StarModel` fits.\n\n        .. todo::\n\n            Should change this to drawing from priors!  Current implementation\n            is a bit outdated.\n        \"\"\"\n        if minmass is None:\n            minmass = self.minmass\n        if maxmass is None:\n            maxmass = self.maxmass\n        if minage is None:\n            minage = self.minage\n        if maxage is None:\n            maxage = self.maxage\n        if minfeh is None:\n            minfeh = self.minfeh\n        if maxfeh is None:\n            maxfeh = self.maxfeh\n\n        ms = rand.uniform(minmass,maxmass,size=n)\n        ages = rand.uniform(minage,maxage,size=n)\n        fehs = rand.uniform(minage,maxage,size=n)\n\n        Rs = self.radius(ms,ages,fehs)\n        bad = np.isnan(Rs)\n        nbad = bad.sum()\n        while nbad > 0:\n            ms[bad] = rand.uniform(minmass,maxmass,size=nbad)\n            ages[bad] = rand.uniform(minage,maxage,size=nbad)\n            fehs[bad] = rand.uniform(minfeh,maxfeh,size=nbad)\n            Rs = self.radius(ms,ages,fehs)\n            bad = np.isnan(Rs)\n            nbad = bad.sum()\n        return ms,ages,fehs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn photometric band from inifile keyword", "response": "def _parse_band(cls, kw):\n        \"\"\"Returns photometric band from inifile keyword\n        \"\"\"\n        m = re.search('([a-zA-Z0-9]+)(_\\d+)?', kw)\n        if m:\n            if m.group(1) in cls._not_a_band:\n                return None\n            else:\n                return m.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize a StarModel from an ini file.", "response": "def from_ini(cls, ic, folder='.', ini_file='star.ini', **kwargs):\n        \"\"\"\n        Initialize a StarModel from a .ini file\n\n        The \"classic\" format (version <= 0.9) should still work for a single star,\n        where all properties are just listed in the file; e.g.,\n\n            J = 10, 0.05\n            H = 9.5, 0.05\n            K = 9.0, 0.05\n            Teff = 5000, 150\n\n        If there are multiple stars observed, you can either define them in\n        the ini file, or use the `obsfile` keyword, pointing to a file with\n        the summarized photometric observations.  In this case, spectroscopic/parallax\n        info should still be included in the .ini file; e.g.,\n\n            obsfile = obs.csv\n            Teff = 5000, 150\n\n        The obsfile should be a comma-separated table with the following columns:\n        `[name, band, resolution, mag, e_mag, separation, pa, relative]`.\n\n          * `name` is the name of instrument\n          * `band` is the photometric bandpass\n          * `resolution` is the approximate spatial resolution of instrument\n          * `mag`, `e_mag` describe magnitude of source (absolute or relative)\n          * `separation`, `pa` describe position of source\n          * `relative`: single-bit flag; if 1 then magnitudes taken with this\n            instrument are assumed to be relative rather than absolute.\n\n        If an obsfile is not provided, you can also define all the same information\n        in the ini file, following these rules:\n\n          * Every instrument/survey gets its own [section].  Sections are only\n        created for different photometric observations.\n\n          * if photometry relates to *all* stars in aperture,\n            there is no extra info in the section, just the photometry.  In this case, it is\n            also assumed that the photometry is absolute. (`relative=False`)\n\n          * If 'resolution' is an attribute under a particular survey section (and\n        'relative' is not explicitly stated), then the survey is assumed to have relative\n        photometry, and to be listing\n        information about companion stars.  In this case, there must be \"separation\"\n        and \"PA\" included for each companion.  If there is more than one companion star,\n        they must be identifed by tag, e.g., separation_1, PA_1, Ks_1, J_1, etc.  The\n        tag can be anything alphanumeric, but it must be consistent within a particular\n        section (instrument).  If there\n        is no tag, there is assumed to be only one companion detected.\n\n          * If there are no sections, then bands will be interpreted at face value\n        and will all be assumed to apply to all stars modeled.\n\n          * Default is to model each star in the highest-resolution observation as a\n        single star, at the same distance/age/feh/AV.\n\n\n        The `N` and `index`\n        parameters may also be provided, to specify the relations between the\n        model stars.  If these are not provided, then `N` will default to `1`\n        (one model star per star observed in highest-resolution observation)\n        and `index` will default to all `0` (all stars physically associated).\n\n        \"\"\"\n\n        if not os.path.isabs(ini_file):\n            ini_file = os.path.join(folder,ini_file)\n\n        bands = cls.get_bands(ini_file)\n\n        if not isinstance(ic, Isochrone):\n            ic = get_ichrone(ic, bands)\n\n        logging.debug('Initializing StarModel from {}'.format(ini_file))\n\n        c = configobj.ConfigObj(ini_file)\n\n        RA = c.get('RA')\n        dec = c.get('dec')\n        maxAV = c.get('maxAV')\n\n        if len(c.sections) == 0:\n            for k in c:\n                kwargs[k] = _parse_config_value(c[k])\n            obs = None\n        else:\n\n            columns = ['name', 'band', 'resolution', 'relative', 'separation', 'pa', 'mag', 'e_mag']\n            df = pd.DataFrame(columns=columns)\n            i = 0\n            for k in c:\n                if type(c[k]) != configobj.Section:\n                    kwargs[k] = _parse_config_value(c[k])\n                else:\n                    instrument = k\n\n                    # Set values of 'resolution' and 'relative'\n                    if 'resolution' in c[k]:\n                        resolution = float(c[k]['resolution'])\n                        relative = True\n                    else:\n                        resolution = 4.0 #default\n                        relative = False\n\n                    # Overwrite value of 'relative' if it is explicitly set\n                    if 'relative' in c[k]:\n                        relative = c[k]['relative']=='True'\n\n\n                    # Check if there are multiple stars (defined by whether\n                    # any separations are listed).\n                    # While we're at it, keep track of tags if they exist,\n                    #  and pull out the names of the bands.\n                    multiple = False\n                    tags = []\n                    bands = []\n                    for label in c[k]:\n                        m = re.search('separation(_\\w+)?', label)\n                        if m:\n                            multiple = True\n                            if m.group(1) is not None:\n                                if m.group(1) not in tags:\n                                    tags.append(m.group(1))\n                        elif re.search('PA', label) or re.search('id', label) or \\\n                                label in ['resolution', 'relative']:\n                            continue\n                        else:\n                            # At this point, this should be a photometric band\n                            m = re.search('([a-zA-Z0-9]+)(_\\w+)?', label)\n                            b = m.group(1)\n                            if b not in bands:\n                                bands.append(b)\n\n                    # If a blank tags needs to be created, do so\n                    if len(bands) > 0 and (len(tags)==0 or bands[0] in c[k]):\n                        tags.append('')\n\n                    # For each band and each star, create a row\n                    for b in bands:\n                        for tag in tags:\n                            if '{}{}'.format(b, tag) not in c[k]:\n                                continue\n                            row = {}\n                            row['name'] = instrument\n                            row['band'] = b\n                            row['resolution'] = resolution\n                            row['relative'] = relative\n                            if 'separation{}'.format(tag) in c[k]:\n                                row['separation'] = c[k]['separation{}'.format(tag)]\n                                row['pa'] = c[k]['PA{}'.format(tag)]\n                            else:\n                                row['separation'] = 0.\n                                row['pa'] = 0.\n                            mag, e_mag = c[k]['{}{}'.format(b,tag)]\n                            row['mag'] = float(mag)\n                            row['e_mag'] = float(e_mag)\n                            if not np.isnan(row['mag']) and not np.isnan(row['e_mag']):\n                                df = df.append(pd.DataFrame(row, index=[i]))\n                                i += 1\n\n                        # put the reference star in w/ mag=0\n                        if relative:\n                            row = {}\n                            row['name'] = instrument\n                            row['band'] = b\n                            row['resolution'] = resolution\n                            row['relative'] = relative\n                            row['separation'] = 0.\n                            row['pa'] = 0.\n                            row['mag'] = 0.\n                            row['e_mag'] = 0.01\n                            df = df.append(pd.DataFrame(row, index=[i]))\n                            i += 1\n\n            obs = ObservationTree.from_df(df)\n\n        if 'obsfile' in c:\n            obs = c['obsfile']\n\n        logging.debug('Obs is {}'.format(obs))\n\n        if 'name' not in kwargs:\n            kwargs['name'] = os.path.basename(folder)\n        new = StarModel(ic, obs=obs, **kwargs)\n        new._directory = os.path.abspath(folder)\n\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_obs(self, **kwargs):\n        logging.debug('Building ObservationTree...')\n        tree = ObservationTree()\n        for k,v in kwargs.items():\n            if k in self.ic.bands:\n                if np.size(v) != 2:\n                    logging.warning('{}={} ignored.'.format(k,v))\n                    # continue\n                    v = [v, np.nan]\n                o = Observation('', k, 99) #bogus resolution=99\n                s = Source(v[0], v[1])\n                o.add_source(s)\n                logging.debug('Adding {} ({})'.format(s,o))\n                tree.add_observation(o)\n\n        self.obs = tree", "response": "Builds an ObservationTree out of the keyword arguments that are not a photometric bandpass."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_properties(self, **kwargs):\n        for k,v in kwargs.items():\n            if k=='parallax':\n                self.obs.add_parallax(v)\n            elif k in ['Teff', 'logg', 'feh', 'density']:\n                par = {k:v}\n                self.obs.add_spectroscopy(**par)\n            elif re.search('_', k):\n                m = re.search('^(\\w+)_(\\w+)$', k)\n                prop = m.group(1)\n                tag = m.group(2)\n                self.obs.add_spectroscopy(**{prop:v, 'label':'0_{}'.format(tag)})", "response": "Adds non - photometry properties to ObservationTree"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfulling path to basename", "response": "def mnest_basename(self):\n        \"\"\"Full path to basename\n        \"\"\"\n        if not hasattr(self, '_mnest_basename'):\n            s = self.labelstring\n            if s=='0_0':\n                s = 'single'\n            elif s=='0_0-0_1':\n                s = 'binary'\n            elif s=='0_0-0_1-0_2':\n                s = 'triple'\n\n            s = '{}-{}'.format(self.ic.name, s)\n            self._mnest_basename = os.path.join('chains', s+'-')\n\n        if os.path.isabs(self._mnest_basename):\n            return self._mnest_basename\n        else:\n            return os.path.join(self.directory, self._mnest_basename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting the multinest model using MultiNest.", "response": "def fit_multinest(self, n_live_points=1000, basename=None,\n                      verbose=True, refit=False, overwrite=False,\n                      test=False,\n                      **kwargs):\n        \"\"\"\n        Fits model using MultiNest, via pymultinest.\n\n        :param n_live_points:\n            Number of live points to use for MultiNest fit.\n\n        :param basename:\n            Where the MulitNest-generated files will live.\n            By default this will be in a folder named `chains`\n            in the current working directory.  Calling this\n            will define a `_mnest_basename` attribute for\n            this object.\n\n        :param verbose:\n            Whether you want MultiNest to talk to you.\n\n        :param refit, overwrite:\n            Set either of these to true if you want to\n            delete the MultiNest files associated with the\n            given basename and start over.\n\n        :param **kwargs:\n            Additional keyword arguments will be passed to\n            :func:`pymultinest.run`.\n\n        \"\"\"\n\n        if basename is not None: #Should this even be allowed?\n            self.mnest_basename = basename\n\n        basename = self.mnest_basename\n        if verbose:\n            logging.info('MultiNest basename: {}'.format(basename))\n\n        folder = os.path.abspath(os.path.dirname(basename))\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n\n\n        #If previous fit exists, see if it's using the same\n        # observed properties\n        prop_nomatch = False\n        propfile = '{}properties.json'.format(basename)\n\n        \"\"\"\n        if os.path.exists(propfile):\n            with open(propfile) as f:\n                props = json.load(f)\n            if set(props.keys()) != set(self.properties.keys()):\n                prop_nomatch = True\n            else:\n                for k,v in props.items():\n                    if np.size(v)==2:\n                        if not self.properties[k][0] == v[0] and \\\n                                self.properties[k][1] == v[1]:\n                            props_nomatch = True\n                    else:\n                        if not self.properties[k] == v:\n                            props_nomatch = True\n\n        if prop_nomatch and not overwrite:\n            raise ValueError('Properties not same as saved chains ' +\n                            '(basename {}*). '.format(basename) +\n                            'Use overwrite=True to fit.')\n        \"\"\"\n\n        if refit or overwrite:\n            files = glob.glob('{}*'.format(basename))\n            [os.remove(f) for f in files]\n\n        short_basename = self._mnest_basename\n\n        mnest_kwargs = dict(n_live_points=n_live_points, outputfiles_basename=short_basename,\n                        verbose=verbose)\n\n        for k,v in kwargs.items():\n            mnest_kwargs[k] = v\n\n        if test:\n            print('pymultinest.run() with the following kwargs: {}'.format(mnest_kwargs))\n        else:\n            wd = os.getcwd()\n            os.chdir(os.path.join(folder, '..'))\n            pymultinest.run(self.mnest_loglike, self.mnest_prior, self.n_params,\n                            **mnest_kwargs)\n            os.chdir(wd)\n            #with open(propfile, 'w') as f:\n            #    json.dump(self.properties, f, indent=2)\n\n            self._make_samples()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef maxlike(self, p0, **kwargs):\n        def fn(p):\n            return -self.lnpost(p)\n\n        if 'method' not in kwargs:\n            kwargs['method'] = 'Nelder-Mead'\n\n        p0 = [0.8, 9.5, 0.0, 200, 0.2]\n        fit = scipy.optimize.minimize(fn, p0, **kwargs)\n        return fit", "response": "Finds the max likelihood of a local in parameter space."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits stellar model using MCMC.", "response": "def fit_mcmc(self,nwalkers=300,nburn=200,niter=100,\n                 p0=None,initial_burn=None,\n                 ninitial=50, loglike_kwargs=None,\n                 **kwargs):\n        \"\"\"Fits stellar model using MCMC.\n\n        :param nwalkers: (optional)\n            Number of walkers to pass to :class:`emcee.EnsembleSampler`.\n            Default is 200.\n\n        :param nburn: (optional)\n            Number of iterations for \"burn-in.\"  Default is 100.\n\n        :param niter: (optional)\n            Number of for-keeps iterations for MCMC chain.\n            Default is 200.\n\n        :param p0: (optional)\n            Initial parameters for emcee.  If not provided, then chains\n            will behave according to whether inital_burn is set.\n\n        :param initial_burn: (optional)\n            If `True`, then initialize walkers first with a random initialization,\n            then cull the walkers, keeping only those with > 15% acceptance\n            rate, then reinitialize sampling.  If `False`, then just do\n            normal burn-in.  Default is `None`, which will be set to `True` if\n            fitting for distance (i.e., if there are apparent magnitudes as\n            properties of the model), and `False` if not.\n\n        :param ninitial: (optional)\n            Number of iterations to test walkers for acceptance rate before\n            re-initializing.\n\n        :param loglike_args:\n            Any arguments to pass to :func:`StarModel.loglike`, such\n            as what priors to use.\n\n        :param **kwargs:\n            Additional keyword arguments passed to :class:`emcee.EnsembleSampler`\n            constructor.\n\n        :return:\n            :class:`emcee.EnsembleSampler` object.\n\n        \"\"\"\n\n        #clear any saved _samples\n        if self._samples is not None:\n            self._samples = None\n\n        npars = self.n_params\n\n        if p0 is None:\n            p0 = self.emcee_p0(nwalkers)\n            if initial_burn:\n                sampler = emcee.EnsembleSampler(nwalkers,npars,self.lnpost,\n                                                **kwargs)\n                #ninitial = 300 #should this be parameter?\n                pos, prob, state = sampler.run_mcmc(p0, ninitial)\n\n                # Choose walker with highest final lnprob to seed new one\n                i,j = np.unravel_index(sampler.lnprobability.argmax(),\n                                        sampler.shape)\n                p0_best = sampler.chain[i,j,:]\n                print(\"After initial burn, p0={}\".format(p0_best))\n                p0 = p0_best * (1 + rand.normal(size=p0.shape)*0.001)\n                print(p0)\n        else:\n            p0 = np.array(p0)\n            p0 = rand.normal(size=(nwalkers,npars))*0.01 + p0.T[None,:]\n\n        sampler = emcee.EnsembleSampler(nwalkers,npars,self.lnpost)\n        pos, prob, state = sampler.run_mcmc(p0, nburn)\n        sampler.reset()\n        sampler.run_mcmc(pos, niter, rstate0=state)\n\n        self._sampler = sampler\n        return sampler"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random sampling of given size from the existing samples.", "response": "def random_samples(self, n):\n        \"\"\"\n        Returns a random sampling of given size from the existing samples.\n\n        :param n:\n            Number of samples\n\n        :return:\n            :class:`pandas.DataFrame` of length ``n`` with random samples.\n        \"\"\"\n        samples = self.samples\n        inds = rand.randint(len(samples),size=int(n))\n\n        newsamples = samples.iloc[inds]\n        newsamples.reset_index(inplace=True)\n        return newsamples"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a corner plot for each observed node magnitude", "response": "def corner_observed(self, **kwargs):\n        \"\"\"Makes corner plot for each observed node magnitude\n        \"\"\"\n        tot_mags = []\n        names = []\n        truths = []\n        rng = []\n        for n in self.obs.get_obs_nodes():\n            labels = [l.label for l in n.get_model_nodes()]\n            band = n.band\n            mags = [self.samples['{}_mag_{}'.format(band, l)] for l in labels]\n            tot_mag = addmags(*mags)\n\n            if n.relative:\n                name = '{} $\\Delta${}'.format(n.instrument, n.band)\n                ref = n.reference\n                if ref is None:\n                    continue\n                ref_labels = [l.label for l in ref.get_model_nodes()]\n                ref_mags = [self.samples['{}_mag_{}'.format(band, l)] for l in ref_labels]\n                tot_ref_mag = addmags(*ref_mags)\n                tot_mags.append(tot_mag - tot_ref_mag)\n                truths.append(n.value[0] - ref.value[0])\n            else:\n                name = '{} {}'.format(n.instrument, n.band)\n                tot_mags.append(tot_mag)\n                truths.append(n.value[0])\n\n            names.append(name)\n            rng.append((min(truths[-1], np.percentile(tot_mags[-1],0.5)),\n                        max(truths[-1], np.percentile(tot_mags[-1],99.5))))\n        tot_mags = np.array(tot_mags).T\n\n\n        return corner.corner(tot_mags, labels=names, truths=truths, range=rng, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_hdf(self, filename, path='', overwrite=False, append=False):\n        if os.path.exists(filename):\n            with pd.HDFStore(filename) as store:\n                if path in store:\n                    if overwrite:\n                        os.remove(filename)\n                    elif not append:\n                        raise IOError('{} in {} exists.  Set either overwrite or append option.'.format(path,filename))\n\n        if self.samples is not None:\n            self.samples.to_hdf(filename, path+'/samples')\n        else:\n            pd.DataFrame().to_hdf(filename, path+'/samples')\n\n        self.obs.save_hdf(filename, path+'/obs', append=True)\n\n        with pd.HDFStore(filename) as store:\n            # store = pd.HDFStore(filename)\n            attrs = store.get_storer('{}/samples'.format(path)).attrs\n\n            attrs.ic_type = type(self.ic)\n            attrs.ic_bands = list(self.ic.bands)\n            attrs.use_emcee = self.use_emcee\n            if hasattr(self, '_mnest_basename'):\n                attrs._mnest_basename = self._mnest_basename\n\n            attrs._bounds = self._bounds\n            attrs._priors = self._priors\n\n            attrs.name = self.name\n            store.close()", "response": "Saves object data to HDF file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_hdf(cls, filename, path='', name=None):\n        if not os.path.exists(filename):\n            raise IOError('{} does not exist.'.format(filename))\n        store = pd.HDFStore(filename)\n        try:\n            samples = store[path+'/samples']\n            attrs = store.get_storer(path+'/samples').attrs\n        except:\n            store.close()\n            raise\n\n        try:\n            ic = attrs.ic_type(attrs.ic_bands)\n        except AttributeError:\n            ic = attrs.ic_type\n\n        use_emcee = attrs.use_emcee\n        mnest = True\n        try:\n            basename = attrs._mnest_basename\n        except AttributeError:\n            mnest = False\n        bounds = attrs._bounds\n        priors = attrs._priors\n\n        if name is None:\n            try:\n                name = attrs.name\n            except:\n                name = ''\n\n        store.close()\n\n        obs = ObservationTree.load_hdf(filename, path+'/obs', ic=ic)\n\n        mod = cls(ic, obs=obs,\n                  use_emcee=use_emcee, name=name)\n        mod._samples = samples\n        if mnest:\n            mod._mnest_basename = basename\n        mod._directory = os.path.dirname(filename)\n        return mod", "response": "A method to load a saved StarModel from an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_df(self):\n        grids = {}\n        df = pd.DataFrame()\n        for bnd in self.bands:\n            s,b = self.get_band(bnd, **self.kwargs)\n            logging.debug('loading {} band from {}'.format(b,s))\n            if s not in grids:\n                grids[s] = self.get_hdf(s)\n            if self.common_columns[0] not in df:\n                df[list(self.common_columns)] = grids[s][list(self.common_columns)]\n            col = grids[s][b]\n            n_nan = np.isnan(col).sum()\n            if n_nan > 0:\n                logging.debug('{} NANs in {} column'.format(n_nan, b))\n            df.loc[:, bnd] = col.values #dunno why it has to be this way; something\n                                        # funny with indexing.\n\n        return df", "response": "Returns a Pandas DataFrame with the stellar model grid with desired bandpasses and with standard column names"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_master_tarball(cls):\n        if not os.path.exists(cls.master_tarball_file):\n            cls.download_grids()\n\n        with tarfile.open(os.path.join(ISOCHRONES, cls.master_tarball_file)) as tar:\n            logging.info('Extracting {}...'.format(cls.master_tarball_file))\n            tar.extractall(ISOCHRONES)", "response": "Unpack tarball of tarballs of tarballs containing the master image"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Pandas DataFrame of all files in the photometry.", "response": "def df_all(self, phot):\n        \"\"\"Subclasses may want to sort this\n        \"\"\"\n        df = pd.concat([self.to_df(f) for f in self.get_filenames(phot)])\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a file from the URL to the local path.", "response": "def download_file(url, path=None, clobber=False):\n    \"\"\"\n    thanks to: https://stackoverflow.com/questions/16694907/how-to-download-large-file-in-python-with-requests-py\n\n    path : str\n        local path to download to.\n    \"\"\"\n    if path is None:\n        local_filename = os.path.join(directory, url.split('/')[-1])\n    else:\n        local_filename = path\n\n    if os.path.exists(local_filename) and not clobber:\n        logging.info('{} exists; not downloading.'.format(local_filename))\n        return local_filename\n        \n    # NOTE the stream=True parameter\n    r = requests.get(url, stream=True)\n    with open(local_filename, 'wb') as f:\n        for chunk in r.iter_content(chunk_size=1024):\n            if chunk: # filter out keep-alive new chunks\n                f.write(chunk)\n                #f.flush() commented by recommendation from J.F.Sebastian\n    return local_filename"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addmags(*mags):\n    tot = 0\n    uncs = []\n    for mag in mags:\n        try:\n            tot += 10**(-0.4*mag)\n        except:\n            m, dm = mag\n            f = 10**(-0.4*m)\n            tot += f\n            unc = f * (1 - 10**(-0.4*dm))\n            uncs.append(unc)\n\n    totmag = -2.5*np.log10(tot)\n    if len(uncs) > 0:\n        f_unc = np.sqrt(np.array([u**2 for u in uncs]).sum())\n        return totmag, -2.5*np.log10(1 - f_unc/tot)\n    else:\n        return totmag", "response": "addmags - add mags to the national tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef distance(pos0, pos1):\n    r0, pa0 = pos0\n    #logging.debug('r0={}, pa0={} (from {})'.format(r0, pa0, self))\n    ra0 = r0*np.sin(pa0*np.pi/180)\n    dec0 = r0*np.cos(pa0*np.pi/180)\n\n    r1, pa1 = pos1\n    #logging.debug('r1={}, pa1={} (from {})'.format(r0, pa0, other))\n    ra1 = r1*np.sin(pa1*np.pi/180)\n    dec1 = r1*np.cos(pa1*np.pi/180)\n\n    dra = (ra1 - ra0)\n    ddec = (dec1 - dec0)\n    return np.sqrt(dra**2 + ddec**2)", "response": "distance between two positions defined by ( separation PA )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef V(self, brightest=False):\n        mags = self.get_photometry(brightest=brightest, convert=False)\n        VT, dVT = mags['VT']\n        BT, dBT = mags['BT']\n        if (-0.25 < BT - VT < 2.0):\n            (a, b, c, d) = (0.00097, 0.1334, 0.05486, 0.01998)\n            V = (VT + a - b * (BT - VT) + c * (BT - VT)**2 -\n                d * (BT - VT)**3)\n\n            dVdVT = 1 + b - 2*c*(BT-VT) + 3*d*(BT-VT)**2\n            dVdBT = -b + 2*c*(BT-VT) - 3*d*(BT-VT)**2\n            dV = np.sqrt((dVdVT**2 * dVT**2) + (dVdBT**2*dBT**2))\n\n        else:\n            raise ValueError('BT-VT outside of range to convert')\n\n        return V, dV", "response": "A function to get the V and dV from the species."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_band(cls, b, **kwargs):\n        phot = None\n\n        # Default to SDSS for these\n        if b in ['u','g','r','i','z']:\n            phot = 'SDSS'\n            band = 'SDSS_{}'.format(b)\n        elif b in ['U','B','V','R','I']:\n            phot = 'UBVRIplus'\n            band = 'Bessell_{}'.format(b)\n        elif b in  ['J','H','Ks']:\n            phot = 'UBVRIplus'\n            band = '2MASS_{}'.format(b)\n        elif b=='K':\n            phot = 'UBVRIplus'\n            band = '2MASS_Ks'\n        elif b in ['kep','Kepler','Kp']:\n            phot = 'UBVRIplus'\n            band = 'Kepler_Kp'\n        elif b=='TESS':\n            phot = 'UBVRIplus'\n            band = 'TESS'\n        elif b in ['W1','W2','W3','W4']:\n            phot = 'WISE'\n            band = 'WISE_{}'.format(b)\n        elif b in ('G', 'BP', 'RP'):\n            phot = 'UBVRIplus'\n            band = 'Gaia_{}'.format(b)\n            if 'version' in kwargs:\n                if kwargs['version']=='1.1':\n                    band += '_DR2Rev'\n        else:\n            m = re.match('([a-zA-Z]+)_([a-zA-Z_]+)',b)\n            if m:\n                if m.group(1) in cls.phot_systems:\n                    phot = m.group(1)\n                    if phot=='PanSTARRS':\n                        band = 'PS_{}'.format(m.group(2))\n                    else:\n                        band = m.group(0)\n                elif m.group(1) in ['UK','UKIRT']:\n                    phot = 'UKIDSS'\n                    band = 'UKIDSS_{}'.format(m.group(2))\n\n        if phot is None:\n            for system, bands in cls.phot_bands.items():\n                if b in bands:\n                    phot = system\n                    band = b\n                    break\n            if phot is None:\n                raise ValueError('MIST grids cannot resolve band {}!'.format(b))\n        return phot, band", "response": "Defines what a shortcut band name refers to. Returns phot_system band"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_child(self, label):\n        ind = None\n        for i,c in enumerate(self.children):\n            if c.label==label:\n                ind = i\n\n        if ind is None:\n            logging.warning('No child labeled {}.'.format(label))\n            return\n        self.children.pop(ind)\n        self._clear_all_leaves()", "response": "Removes a child from the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all leaves under all nodes matching name", "response": "def select_leaves(self, name):\n        \"\"\"Returns all leaves under all nodes matching name\n\n        \"\"\"\n\n        if self.is_leaf:\n            return [self] if re.search(name, self.label) else []\n        else:\n            leaves = []\n            if re.search(name, self.label):\n                for c in self.children:\n                    leaves += c._get_leaves() #all leaves\n            else:\n                for c in self.children:\n                    leaves += c.select_leaves(name) #only matching ones\n            return leaves"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_obs_leaves(self):\n        obs_leaves = []\n        for n in self:\n            if n.is_leaf:\n                if isinstance(n, ModelNode):\n                    l = n.parent\n                else:\n                    l = n\n            if l not in obs_leaves:\n                obs_leaves.append(l)\n        return obs_leaves", "response": "Returns the last obs nodes that are leaves\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncoordinates distance from another ObsNode", "response": "def distance(self, other):\n        \"\"\"Coordinate distance from another ObsNode\n        \"\"\"\n        return distance((self.separation, self.pa), (other.separation, other.pa))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Nstars(self):\n        if self._Nstars is None:\n            N = {}\n            for n in self.get_model_nodes():\n                if n.index not in N:\n                    N[n.index] = 1\n                else:\n                    N[n.index] += 1\n            self._Nstars = N\n        return self._Nstars", "response": "Returns a dictionary of number of stars per system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_model(self, ic, N=1, index=0):\n        if type(index) in [list,tuple]:\n            if len(index) != N:\n                raise ValueError('If a list, index must be of length N.')\n        else:\n            index = [index]*N\n\n        for idx in index:\n            existing = self.get_system(idx)\n            tag = len(existing)\n            self.add_child(ModelNode(ic, index=idx, tag=tag))", "response": "Add a model to the tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef model_mag(self, pardict, use_cache=True):\n        if pardict == self._cache_key and use_cache:\n            #print('{}: using cached'.format(self))\n            return self._cache_val\n\n        #print('{}: calculating'.format(self))\n        self._cache_key = pardict\n\n\n        # Generate appropriate parameter vector from dictionary\n        p = []\n        for l in self.leaf_labels:\n            p.extend(pardict[l])\n\n        assert len(p) == self.n_params\n\n        tot = np.inf\n        #print('Building {} mag for {}:'.format(self.band, self))\n        for i,m in enumerate(self.leaves):\n            mag = m.evaluate(p[i*5:(i+1)*5], self.band)\n            # logging.debug('{}: mag={}'.format(self,mag))\n            #print('{}: {}({}) = {}'.format(m,self.band,p[i*5:(i+1)*5],mag))\n            tot = addmags(tot, mag)\n\n        self._cache_val = tot\n        return tot", "response": "Compute the model magnitude for all leaves."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the log - likelihood of this observation", "response": "def lnlike(self, pardict, use_cache=True):\n        \"\"\"\n        returns log-likelihood of this observation\n\n        pardict is a dictionary of parameters for all leaves\n        gets converted back to traditional parameter vector\n        \"\"\"\n\n        mag, dmag = self.value\n        if np.isnan(dmag):\n            return 0\n        if self.relative:\n            # If this *is* the reference, just return\n            if self.reference is None:\n                return 0\n            mod = (self.model_mag(pardict, use_cache=use_cache) -\n                   self.reference.model_mag(pardict, use_cache=use_cache))\n            mag -= self.reference.value[0]\n        else:\n            mod = self.model_mag(pardict, use_cache=use_cache)\n\n        lnl = -0.5*(mag - mod)**2 / dmag**2\n\n        # logging.debug('{} {}: mag={}, mod={}, lnlike={}'.format(self.instrument,\n        #                                                         self.band,\n        #                                                         mag,mod,lnl))\n        return lnl"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and adds appropriate synthetic Source objects for list of stars", "response": "def observe(self, stars, unc, ic=None):\n        \"\"\"Creates and adds appropriate synthetic Source objects for list of stars (max 2 for now)\n        \"\"\"\n        if ic is None:\n            ic = get_ichrone('mist')\n\n        if len(stars) > 2:\n            raise NotImplementedError('No support yet for > 2 synthetic stars')\n\n        mags = [ic(*s.pars)['{}_mag'.format(self.band)].values[0] for s in stars]\n\n        d = stars[0].distance(stars[1])\n\n        if d < self.resolution:\n            mag = addmags(*mags) + unc*np.random.randn()\n            sources = [Source(mag, unc, stars[0].separation, stars[0].pa,\n                           relative=self.relative)]\n        else:\n            mags = np.array([m + unc*np.random.randn() for m in mags])\n            if self.relative:\n                mags -= mags.min()\n            sources = [Source(m, unc, s.separation, s.pa, relative=self.relative)\n                        for m,s in zip(mags, stars)]\n\n        for s in sources:\n            self.add_source(s)\n\n        self._set_reference()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd source to observation keeping sorted order of separation.", "response": "def add_source(self, source):\n        \"\"\"\n        Adds source to observation, keeping sorted order (in separation)\n        \"\"\"\n        if not type(source)==Source:\n            raise TypeError('Can only add Source object.')\n\n        if len(self.sources)==0:\n            self.sources.append(source)\n        else:\n            ind = 0\n            for s in self.sources:\n                # Keep sorted order of separation\n                if source.separation < s.separation:\n                    break\n                ind += 1\n\n            self.sources.insert(ind, source)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new tree from a DataFrame.", "response": "def from_df(cls, df, **kwargs):\n        \"\"\"\n        DataFrame must have the right columns.\n\n        these are: name, band, resolution, mag, e_mag, separation, pa\n        \"\"\"\n        tree = cls(**kwargs)\n\n        for (n,b), g in df.groupby(['name','band']):\n            #g.sort('separation', inplace=True) #ensures that the first is reference\n            sources = [Source(**s[['mag','e_mag','separation','pa','relative']])\n                        for _,s in g.iterrows()]\n            obs = Observation(n, b, g.resolution.mean(),\n                              sources=sources, relative=g.relative.any())\n            tree.add_observation(obs)\n\n        # For all relative mags, set reference to be brightest\n\n\n\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Pandas DataFrame with photometry from observations organized.", "response": "def to_df(self):\n        \"\"\"\n        Returns DataFrame with photometry from observations organized.\n\n        This DataFrame should be able to be read back in to\n        reconstruct the observation.\n        \"\"\"\n        df = pd.DataFrame()\n        name = []\n        band = []\n        resolution = []\n        mag = []\n        e_mag = []\n        separation = []\n        pa = []\n        relative = []\n        for o in self._observations:\n            for s in o.sources:\n                name.append(o.name)\n                band.append(o.band)\n                resolution.append(o.resolution)\n                mag.append(s.mag)\n                e_mag.append(s.e_mag)\n                separation.append(s.separation)\n                pa.append(s.pa)\n                relative.append(s.relative)\n\n        return pd.DataFrame({'name':name,'band':band,'resolution':resolution,\n                             'mag':mag,'e_mag':e_mag,'separation':separation,\n                             'pa':pa,'relative':relative})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current object to HDF file.", "response": "def save_hdf(self, filename, path='', overwrite=False, append=False):\n        \"\"\"\n        Writes all info necessary to recreate object to HDF file\n\n        Saves table of photometry in DataFrame\n\n        Saves model specification, spectroscopy, parallax to attrs\n        \"\"\"\n\n        if os.path.exists(filename):\n            store = pd.HDFStore(filename)\n            if path in store:\n                store.close()\n                if overwrite:\n                    os.remove(filename)\n                elif not append:\n                    raise IOError('{} in {} exists.  Set either overwrite or append option.'.format(path,filename))\n            else:\n                store.close()\n\n        df = self.to_df()\n        df.to_hdf(filename, path+'/df')\n        with pd.HDFStore(filename) as store:\n            # store = pd.HDFStore(filename)\n            attrs = store.get_storer(path+'/df').attrs\n            attrs.spectroscopy = self.spectroscopy\n            attrs.parallax = self.parallax\n            attrs.N = self._N\n            attrs.index = self._index\n            store.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads ObservationTree from a hdf file.", "response": "def load_hdf(cls, filename, path='', ic=None):\n        \"\"\"\n        Loads stored ObservationTree from file.\n\n        You can provide the isochrone to use; or it will default to MIST\n\n        TODO: saving and loading must be fixed!  save ic type, bands, etc.\n        \"\"\"\n        store = pd.HDFStore(filename)\n        try:\n            samples = store[path+'/df']\n            attrs = store.get_storer(path+'/df').attrs\n        except:\n            store.close()\n            raise\n        df = store[path+'/df']\n        new = cls.from_df(df)\n\n        if ic is None:\n            ic = get_ichrone('mist')\n\n        new.define_models(ic, N=attrs.N, index=attrs.index)\n        new.spectroscopy = attrs.spectroscopy\n        new.parallax = attrs.parallax\n        store.close()\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an observation to the list keeping proper order AttributeNames", "response": "def add_observation(self, obs):\n        \"\"\"Adds an observation to observation list, keeping proper order\n        \"\"\"\n        if len(self._observations)==0:\n            self._observations.append(obs)\n        else:\n            res = obs.resolution\n            ind = 0\n            for o in self._observations:\n                if res > o.resolution:\n                    break\n                ind += 1\n            self._observations.insert(ind, obs)\n\n        self._build_tree()\n        self._clear_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd spectroscopic measurement to particular star ( s ) corresponding to individual model node.", "response": "def add_spectroscopy(self, label='0_0', **props):\n        \"\"\"\n        Adds spectroscopic measurement to particular star(s) (corresponding to individual model node)\n\n        Default 0_0 should be primary star\n\n        legal inputs are 'Teff', 'logg', 'feh', and in form (val, err)\n        \"\"\"\n        if label not in self.leaf_labels:\n            raise ValueError('No model node named {} (must be in {}). Maybe define models first?'.format(label, self.leaf_labels))\n        for k,v in props.items():\n            if k not in self.spec_props:\n                raise ValueError('Illegal property {} (only {} allowed).'.format(k, self.spec_props))\n            if len(v) != 2:\n                raise ValueError('Must provide (value, uncertainty) for {}.'.format(k))\n\n        if label not in self.spectroscopy:\n            self.spectroscopy[label] = {}\n\n        for k,v in props.items():\n            self.spectroscopy[label][k] = v\n\n        self._clear_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine limits to spectroscopic property of particular stars.", "response": "def add_limit(self, label='0_0', **props):\n        \"\"\"Define limits to spectroscopic property of particular stars.\n\n        Usually will be used for 'logg', but 'Teff' and 'feh' will also work.\n\n        In form (min, max): e.g., t.add_limit(logg=(3.0,None))\n\n        None will be converted to (-)np.inf\n        \"\"\"\n\n        if label not in self.leaf_labels:\n            raise ValueError('No model node named {} (must be in {}). Maybe define models first?'.format(label, self.leaf_labels))\n        for k,v in props.items():\n            if k not in self.spec_props:\n                raise ValueError('Illegal property {} (only {} allowed).'.format(k, self.spec_props))\n            if len(v) != 2:\n                raise ValueError('Must provide (min, max) for {}. (`None` is allowed value)'.format(k))\n\n        if label not in self.limits:\n            self.limits[label] = {}\n\n        for k,v in props.items():\n            vmin, vmax = v\n            if vmin is None:\n                vmin = -np.inf\n            if vmax is None:\n                vmax = np.inf\n            self.limits[label][k] = (vmin, vmax)\n\n        self._clear_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefining the models for the given image and leaves.", "response": "def define_models(self, ic, leaves=None, N=1, index=0):\n        \"\"\"\n        N, index are either integers or lists of integers.\n\n        N : number of model stars per observed star\n        index : index of physical association\n\n        leaves: either a list of leaves, or a pattern by which\n        the leaves are selected (via `select_leaves`)\n\n        If these are lists, then they are defined individually for\n        each leaf.\n\n        If `index` is a list, then each entry must be either\n        an integer or a list of length `N` (where `N` is the corresponding\n            entry in the `N` list.)\n\n        This bugs up if you call it multiple times.  If you want\n        to re-do a call to this function, please re-define the tree.\n        \"\"\"\n\n        self.clear_models()\n\n        if leaves is None:\n            leaves = self._get_leaves()\n        elif type(leaves)==type(''):\n            leaves = self.select_leaves(leaves)\n\n        # Sort leaves by distance, to ensure system 0 will be assigned\n        # to the main reference star.\n\n\n        if np.isscalar(N):\n            N = (np.ones(len(leaves))*N)\n            #if np.size(index) > 1:\n            #    index = [index]\n        N = np.array(N).astype(int)\n\n        if np.isscalar(index):\n            index = (np.ones_like(N)*index)\n        index = np.array(index).astype(int)\n\n        # Add the appropriate number of model nodes to each\n        #  star in the highest-resoluion image\n        for s,n,i in zip(leaves, N, index):\n            # Remove any previous model nodes (should do some checks here?)\n            s.remove_children()\n            s.add_model(ic, n, i)\n\n        # For each system, make sure tag _0 is the brightest.\n        self._fix_labels()\n\n        self._N = N\n        self._index = index\n\n        self._clear_all_leaves()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fix_labels(self):\n        for s in self.systems:\n            mag0 = np.inf\n            n0 = None\n            for n in self.get_system(s):\n                if isinstance(n.parent, DummyObsNode):\n                    continue\n                mag, _ = n.parent.value\n                if mag < mag0:\n                     mag0 = mag\n                     n0 = n\n\n            # If brightest is not tag _0, then switch them.\n            if n0 is not None and n0.tag != 0:\n                n_other = self.get_leaf('{}_{}'.format(s,0))\n                n_other.tag = n0.tag\n                n0.tag = 0", "response": "Make sure that brightest star is the brightest star in the highest - resolution image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of nodes whose instrument - band matches name", "response": "def select_observations(self, name):\n        \"\"\"Returns nodes whose instrument-band matches 'name'\n        \"\"\"\n        return [n for n in self.get_obs_nodes() if n.obsname==name]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lnlike(self, p, use_cache=True):\n        if use_cache and self._cache_key is not None and np.all(p==self._cache_key):\n            return self._cache_val\n        self._cache_key = p\n\n        pardict = self.p2pardict(p)\n\n        # lnlike from photometry\n        lnl = 0\n        for n in self:\n            if n is not self:\n                lnl += n.lnlike(pardict, use_cache=use_cache)\n            if not np.isfinite(lnl):\n                self._cache_val = -np.inf\n                return -np.inf\n\n        # lnlike from spectroscopy\n        for l in self.spectroscopy:\n            for prop,(val,err) in self.spectroscopy[l].items():\n                mod = self.get_leaf(l).evaluate(pardict[l], prop)\n                lnl += -0.5*(val - mod)**2/err**2\n            if not np.isfinite(lnl):\n                self._cache_val = -np.inf\n                return -np.inf\n\n        # enforce limits\n        for l in self.limits:\n            for prop,(vmin,vmax) in self.limits[l].items():\n                mod = self.get_leaf(l).evaluate(pardict[l], prop)\n                if mod < vmin or mod > vmax or not np.isfinite(mod):\n                    self._cache_val = -np.inf\n                    return -np.inf\n\n        # lnlike from parallax\n        for s,(val,err) in self.parallax.items():\n            dist = pardict['{}_0'.format(s)][3]\n            mod = 1./dist * 1000.\n            lnl += -0.5*(val-mod)**2/err**2\n\n        if not np.isfinite(lnl):\n            self._cache_val = -np.inf\n            return -np.inf\n\n        self._cache_val = lnl\n        return lnl", "response": "returns the ln - likelihood of a parameter vector"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_closest(self, n0):\n        dmin = np.inf\n        nclose = None\n\n        ds = []\n        nodes = []\n\n        ds.append(np.inf)\n        nodes.append(self)\n\n        for n in self:\n            if n is n0:\n                continue\n            try:\n                if n._in_same_observation(n0):\n                    continue\n                ds.append(n.distance(n0))\n                nodes.append(n)\n            except AttributeError:\n                pass\n\n        inds = np.argsort(ds)\n        ds = [ds[i] for i in inds]\n        nodes = [nodes[i] for i in inds]\n\n        for d,n in zip(ds, nodes):\n            try:\n                if d < n.resolution or n.resolution==-1:\n                    return n\n            except AttributeError:\n                pass\n\n        # If nothing else works\n        return self", "response": "returns the node in the tree that is closest to n0 but not\n          in the same observation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefaulting prior on mass ratio q ~ q^gamma", "response": "def q_prior(q, m=1, gamma=0.3, qmin=0.1):\n    \"\"\"Default prior on mass ratio q ~ q^gamma\n    \"\"\"\n    if q < qmin or q > 1:\n        return 0\n    C = 1/(1/(gamma+1)*(1 - qmin**(gamma+1)))\n    return C*q**gamma"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the feh PDF based on local SDSS distribution", "response": "def local_fehdist(feh):\n    \"\"\"feh PDF based on local SDSS distribution\n    \n    From Jo Bovy:\n    https://github.com/jobovy/apogee/blob/master/apogee/util/__init__.py#L3\n    2D gaussian fit based on Casagrande (2011)\n    \"\"\"\n    fehdist= 0.8/0.15*np.exp(-0.5*(feh-0.016)**2./0.15**2.)\\\n        +0.2/0.22*np.exp(-0.5*(feh+0.15)**2./0.22**2.)\n\n    return fehdist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_ini(cls, ic, folder='.', ini_file='star.ini'):\n        if not os.path.isabs(ini_file):\n            ini_file = os.path.join(folder,ini_file)\n\n        config = ConfigObj(ini_file)\n        kwargs = {}\n        for kw in config.keys():\n            try:\n                kwargs[kw] = float(config[kw])\n            except:\n                kwargs[kw] = (float(config[kw][0]), float(config[kw][1]))\n\n        return cls(ic, **kwargs)", "response": "Initialize a StarModel from a. ini file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _clean_props(self):\n        remove = []\n        for p in self.properties.keys():\n            if not hasattr(self.ic, p) and \\\n              p not in self.ic.bands and p not in ['parallax','feh','age','mass_B','mass_C'] and \\\n              not re.search('delta_',p):\n                remove.append(p)\n\n        for p in remove:\n            del self.properties[p]\n\n        if len(remove) > 0:\n            logging.warning('Properties removed from Model because ' +\n                            'not present in {}: {}'.format(type(self.ic),remove))\n\n        remove = []\n        for p in self.properties.keys():\n            try:\n                val = self.properties[p][0]\n                if not np.isfinite(val):\n                    remove.append(p)\n            except:\n                pass\n\n        for p in remove:\n            del self.properties[p]\n\n        if len(remove) > 0:\n            logging.warning('Properties removed from Model because ' +\n                            'value is nan or inf: {}'.format(remove))\n        \n\n\n        self._props_cleaned = True", "response": "Removes all properties that are not legit for an ISOchrone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_props(self,**kwargs):\n        for kw,val in kwargs.iteritems():\n            self.properties[kw] = val", "response": "Adds observable properties to self. properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves properties from the object.", "response": "def remove_props(self,*args):\n        \"\"\"\n        Removes desired properties from ``self.properties``.\n        \n        \"\"\"\n        for arg in args:\n            if arg in self.properties:\n                del self.properties[arg]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the class is fit for a distance.", "response": "def fit_for_distance(self):\n        \"\"\"\n        ``True`` if any of the properties are apparent magnitudes.\n        \n        \"\"\"\n        for prop in self.properties.keys():\n            if prop in self.ic.bands:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lnlike(self, p):\n\n        if not self._props_cleaned:\n            self._clean_props()\n            \n        if not self.use_emcee:\n            fit_for_distance = True\n            mass, age, feh, dist, AV = (p[0], p[1], p[2], p[3], p[4])\n        else:\n            if len(p)==5:\n                fit_for_distance = True\n                mass,age,feh,dist,AV = p\n            elif len(p)==3:\n                fit_for_distance = False\n                mass,age,feh = p\n\n        if mass < self.ic.minmass or mass > self.ic.maxmass \\\n           or age < self.ic.minage or age > self.ic.maxage \\\n           or feh < self.ic.minfeh or feh > self.ic.maxfeh:\n            return -np.inf\n        if fit_for_distance:\n            if dist < 0 or AV < 0 or dist > self.max_distance:\n                return -np.inf\n            if AV > self.maxAV:\n                return -np.inf\n\n        if self.min_logg is not None:\n            logg = self.ic.logg(mass,age,feh)\n            if logg < self.min_logg:\n                return -np.inf\n\n        logl = 0\n        for prop in self.properties.keys():\n            try:\n                val,err = self.properties[prop]\n            except TypeError:\n                #property not appropriate for fitting (e.g. no error provided)\n                continue\n\n            if prop in self.ic.bands:\n                if not fit_for_distance:\n                    raise ValueError('must fit for mass, age, feh, dist, A_V if apparent magnitudes provided.')\n                mod = self.ic.mag[prop](mass,age,feh) + 5*np.log10(dist) - 5\n                A = AV*EXTINCTION[prop]\n                mod += A\n            elif re.search('delta_',prop):\n                continue\n            elif prop=='feh':\n                mod = feh\n            elif prop=='parallax':\n                mod = 1./dist * 1000\n            else:\n                mod = getattr(self.ic,prop)(mass,age,feh)\n\n            logl += -(val-mod)**2/(2*err**2) + np.log(1/(err*np.sqrt(2*np.pi)))\n\n        if np.isnan(logl):\n            logl = -np.inf\n\n        return logl", "response": "Returns the log - likelihood of the given parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates log - prior for model parameters", "response": "def lnprior(self, mass, age, feh,\n                distance=None, AV=None, \n                use_local_fehprior=True):\n        \"\"\"\n        log-prior for model parameters\n        \n        \"\"\"\n        mass_prior = salpeter_prior(mass)\n        if mass_prior==0:\n            mass_lnprior = -np.inf\n        else:\n            mass_lnprior = np.log(mass_prior)\n\n        if np.isnan(mass_lnprior):\n            logging.warning('mass prior is nan at {}'.format(mass))\n\n        age_lnprior = np.log(age * (2/(self.ic.maxage**2-self.ic.minage**2)))\n        if np.isnan(age_lnprior):\n            logging.warning('age prior is nan at {}'.format(age))\n\n\n        if use_local_fehprior:\n            fehdist = local_fehdist(feh)\n        else:\n            fehdist = 1/(self.ic.maxfeh - self.ic.minfeh)\n        feh_lnprior = np.log(fehdist)\n        if np.isnan(feh_lnprior):\n            logging.warning('feh prior is nan at {}'.format(feh))\n\n\n        if distance is not None:\n            if distance <= 0:\n                distance_lnprior = -np.inf\n            else:\n                distance_lnprior = np.log(3/self.max_distance**3 * distance**2)\n        else:\n            distance_lnprior = 0\n        if np.isnan(distance_lnprior):\n            logging.warning('distance prior is nan at {}'.format(distance))\n\n\n        if AV is not None:\n            AV_lnprior = np.log(1/self.maxAV)\n        else:\n            AV_lnprior = 0\n        if np.isnan(AV_lnprior):\n            logging.warning('AV prior is nan at {}'.format(AV))\n            \n\n        lnprior = (mass_lnprior + age_lnprior + feh_lnprior + \n                distance_lnprior + AV_lnprior)\n\n        return lnprior"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef maxlike(self,nseeds=50):\n        m0,age0,feh0 = self.ic.random_points(nseeds)\n        d0 = 10**(rand.uniform(0,np.log10(self.max_distance),size=nseeds))\n        AV0 = rand.uniform(0,self.maxAV,size=nseeds)\n\n        \n\n        costs = np.zeros(nseeds)\n\n        if self.fit_for_distance:\n            pfits = np.zeros((nseeds,5))\n        else:\n            pfits = np.zeros((nseeds,3))\n            \n        def fn(p): #fmin is a function *minimizer*\n            return -1*self.lnpost(p)\n        \n        for i,m,age,feh,d,AV in zip(range(nseeds),\n                                    m0,age0,feh0,d0,AV0):\n                if self.fit_for_distance:\n                    pfit = scipy.optimize.fmin(fn,[m,age,feh,d,AV],disp=False)\n                else:\n                    pfit = scipy.optimize.fmin(fn,[m,age,feh],disp=False)\n                pfits[i,:] = pfit\n                costs[i] = self.lnpost(pfit)\n\n        return pfits[np.argmax(costs),:]", "response": "Returns the best - fit parameters choosing the best of multiple starting guesses."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap for either fit_multinest or fit_mcmc.", "response": "def fit(self, **kwargs):\n        \"\"\"\n        Wrapper for either :func:`fit_multinest` or :func:`fit_mcmc`.\n\n        Default will be to use MultiNest; set `use_emcee` keyword to `True` \n        if you want to use MCMC, or just call :func:`fit_mcmc` directly.\n        \"\"\"\n        if self.use_emcee:\n            if 'basename' in kwargs:\n                del kwargs['basename']\n            if 'verbose' in kwargs:\n                del kwargs['verbose']\n            if 'overwrite' in kwargs:\n                del kwargs['overwrite']\n            self.fit_mcmc(**kwargs)\n        else:\n            self.fit_multinest(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_multinest(self, n_live_points=1000, basename='chains/single-',\n                      verbose=True, refit=False, overwrite=False,\n                      **kwargs):\n        \"\"\"\n        Fits model using MultiNest, via pymultinest.  \n\n        :param n_live_points:\n            Number of live points to use for MultiNest fit.\n\n        :param basename:\n            Where the MulitNest-generated files will live.  \n            By default this will be in a folder named `chains`\n            in the current working directory.  Calling this \n            will define a `_mnest_basename` attribute for \n            this object.\n\n        :param verbose:\n            Whether you want MultiNest to talk to you.\n\n        :param refit, overwrite:\n            Set either of these to true if you want to \n            delete the MultiNest files associated with the\n            given basename and start over.\n\n        :param **kwargs:\n            Additional keyword arguments will be passed to \n            :func:`pymultinest.run`.\n\n        \"\"\"\n        folder = os.path.abspath(os.path.dirname(basename))\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n\n        #If previous fit exists, see if it's using the same\n        # observed properties\n        prop_nomatch = False\n        propfile = '{}properties.json'.format(basename)\n        if os.path.exists(propfile):\n            with open(propfile) as f:\n                props = json.load(f)\n            if set(props.keys()) != set(self.properties.keys()):\n                prop_nomatch = True\n            else:\n                for k,v in props.items():\n                    if np.size(v)==2:\n                        if not self.properties[k][0] == v[0] and \\\n                                self.properties[k][1] == v[1]:\n                            props_nomatch = True\n                    else:\n                        if not self.properties[k] == v:\n                            props_nomatch = True\n\n        if prop_nomatch and not overwrite:\n            raise ValueError('Properties not same as saved chains ' +\n                            '(basename {}*). '.format(basename) +\n                            'Use overwrite=True to fit.')\n\n\n        if refit or overwrite:\n            files = glob.glob('{}*'.format(basename))\n            [os.remove(f) for f in files]\n\n        self._mnest_basename = basename\n\n        pymultinest.run(self.mnest_loglike, self.mnest_prior, self.n_params,\n                        n_live_points=n_live_points, outputfiles_basename=basename,\n                        verbose=verbose,\n                        **kwargs)\n\n        with open(propfile, 'w') as f:\n            json.dump(self.properties, f, indent=2)\n\n        self._make_samples()", "response": "Fits the multinest model using MultiNest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_mcmc(self,nwalkers=300,nburn=200,niter=100,\n                 p0=None,initial_burn=None,\n                 ninitial=100, loglike_kwargs=None,\n                 **kwargs):\n        \"\"\"Fits stellar model using MCMC.\n\n        :param nwalkers: (optional)\n            Number of walkers to pass to :class:`emcee.EnsembleSampler`.\n            Default is 200.\n\n        :param nburn: (optional)\n            Number of iterations for \"burn-in.\"  Default is 100.\n\n        :param niter: (optional)\n            Number of for-keeps iterations for MCMC chain.\n            Default is 200.\n\n        :param p0: (optional)\n            Initial parameters for emcee.  If not provided, then chains\n            will behave according to whether inital_burn is set.\n\n        :param initial_burn: (optional)\n            If `True`, then initialize walkers first with a random initialization,\n            then cull the walkers, keeping only those with > 15% acceptance\n            rate, then reinitialize sampling.  If `False`, then just do\n            normal burn-in.  Default is `None`, which will be set to `True` if\n            fitting for distance (i.e., if there are apparent magnitudes as\n            properties of the model), and `False` if not.\n            \n        :param ninitial: (optional)\n            Number of iterations to test walkers for acceptance rate before\n            re-initializing.\n\n        :param loglike_args:\n            Any arguments to pass to :func:`StarModel.loglike`, such \n            as what priors to use.\n\n        :param **kwargs:\n            Additional keyword arguments passed to :class:`emcee.EnsembleSampler`\n            constructor.\n            \n        :return:\n            :class:`emcee.EnsembleSampler` object.\n            \n        \"\"\"\n\n        #clear any saved _samples\n        if self._samples is not None:\n            self._samples = None\n            \n\n        if self.fit_for_distance:\n            npars = 5\n            if initial_burn is None:\n                initial_burn = True\n        else:\n            if initial_burn is None:\n                initial_burn = False\n            npars = 3\n\n        if p0 is None:\n            m0,age0,feh0 = self.ic.random_points(nwalkers)\n            d0 = 10**(rand.uniform(0,np.log10(self.max_distance),size=nwalkers))\n            AV0 = rand.uniform(0,self.maxAV,size=nwalkers)\n            if self.fit_for_distance:\n                p0 = np.array([m0,age0,feh0,d0,AV0]).T\n            else:\n                p0 = np.array([m0,age0,feh0]).T\n            if initial_burn:\n                sampler = emcee.EnsembleSampler(nwalkers,npars,self.lnpost,\n                                                **kwargs)\n                #ninitial = 300 #should this be parameter?\n                pos, prob, state = sampler.run_mcmc(p0, ninitial) \n                wokinds = np.where((sampler.naccepted/ninitial > 0.15) &\n                                   (sampler.naccepted/ninitial < 0.4))[0]\n                i=1\n                while len(wokinds)==0:\n                    thresh = 0.15 - i*0.02\n                    if thresh < 0:\n                        raise RuntimeError('Initial burn has no acceptance?')\n                    wokinds = np.where((sampler.naccepted/ninitial > thresh) &\n                                       (sampler.naccepted/ninitial < 0.4))[0]\n                    i += 1\n                inds = rand.randint(len(wokinds),size=nwalkers)\n                p0 = sampler.chain[wokinds[inds],:,:].mean(axis=1) #reset p0\n                p0 *= (1 + rand.normal(size=p0.shape)*0.01)\n        else:\n            p0 = np.array(p0)\n            p0 = rand.normal(size=(nwalkers,npars))*0.01 + p0.T[None,:]\n            if self.fit_for_distance:\n                p0[:,3] *= (1 + rand.normal(size=nwalkers)*0.5)\n        \n        sampler = emcee.EnsembleSampler(nwalkers,npars,self.lnpost)\n        pos, prob, state = sampler.run_mcmc(p0, nburn)\n        sampler.reset()\n        sampler.run_mcmc(pos, niter, rstate0=state)\n        \n        self._sampler = sampler\n        return sampler", "response": "Fits stellar model using MCMC."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef triangle_plots(self, basename=None, format='png',\n                       **kwargs):\n        \"\"\"Returns two triangle plots, one with physical params, one observational\n\n        :param basename:\n            If basename is provided, then plots will be saved as\n            \"[basename]_physical.[format]\" and \"[basename]_observed.[format]\"\n\n        :param format:\n            Format in which to save figures (e.g., 'png' or 'pdf')\n\n        :param **kwargs:\n            Additional keyword arguments passed to :func:`StarModel.triangle`\n            and :func:`StarModel.prop_triangle`\n\n        :return:\n             * Physical parameters triangle plot (mass, radius, Teff, feh, age, distance)\n             * Observed properties triangle plot.\n             \n        \"\"\"\n        if self.fit_for_distance:\n            fig1 = self.triangle(plot_datapoints=False,\n                                 params=['mass','radius','Teff','logg','feh','age',\n                                         'distance','AV'],\n                                 **kwargs)\n        else:\n            fig1 = self.triangle(plot_datapoints=False,\n                                 params=['mass','radius','Teff','feh','age'],\n                                 **kwargs)\n            \n\n        if basename is not None:\n            plt.savefig('{}_physical.{}'.format(basename,format))\n            plt.close()\n        fig2 = self.prop_triangle(**kwargs)\n        if basename is not None:\n            plt.savefig('{}_observed.{}'.format(basename,format))\n            plt.close()\n        return fig1, fig2", "response": "Returns two triangle plots one with physical params one observational parameter and one with observed properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef triangle(self, params=None, query=None, extent=0.999,\n                 **kwargs):\n        \"\"\"\n        Makes a nifty corner plot.\n\n        Uses :func:`triangle.corner`.\n\n        :param params: (optional)\n            Names of columns (from :attr:`StarModel.samples`)\n            to plot.  If ``None``, then it will plot samples\n            of the parameters used in the MCMC fit-- that is,\n            mass, age, [Fe/H], and optionally distance and A_V.\n\n        :param query: (optional)\n            Optional query on samples.\n\n        :param extent: (optional)\n            Will be appropriately passed to :func:`triangle.corner`.\n\n        :param **kwargs:\n            Additional keyword arguments passed to :func:`triangle.corner`.\n\n        :return:\n            Figure oject containing corner plot.\n            \n        \"\"\"\n        if triangle is None:\n            raise ImportError('please run \"pip install triangle_plot\".')\n        \n        if params is None:\n            if self.fit_for_distance:\n                params = ['mass', 'age', 'feh', 'distance', 'AV']\n            else:\n                params = ['mass', 'age', 'feh']\n\n        df = self.samples\n\n        if query is not None:\n            df = df.query(query)\n\n        #convert extent to ranges, but making sure\n        # that truths are in range.\n        extents = []\n        remove = []\n        for i,par in enumerate(params):\n            m = re.search('delta_(\\w+)$',par)\n            if m:\n                if type(self) == BinaryStarModel:\n                    b = m.group(1)\n                    values = (df['{}_mag_B'.format(b)] - \n                              df['{}_mag_A'.format(b)])\n                    df[par] = values\n                else:\n                    remove.append(i)\n                    continue\n                    \n            else:\n                values = df[par]\n            qs = np.array([0.5 - 0.5*extent, 0.5 + 0.5*extent])\n            minval, maxval = values.quantile(qs)\n            if 'truths' in kwargs:\n                datarange = maxval - minval\n                if kwargs['truths'][i] < minval:\n                    minval = kwargs['truths'][i] - 0.05*datarange\n                if kwargs['truths'][i] > maxval:\n                    maxval = kwargs['truths'][i] + 0.05*datarange\n            extents.append((minval,maxval))\n            \n        [params.pop(i) for i in remove]\n\n        fig = triangle.corner(df[params], labels=params, \n                               extents=extents, **kwargs)\n\n        fig.suptitle(self.name, fontsize=22)\n        return fig", "response": "Plots a nifty corner plot of the MCMC."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prop_triangle(self, **kwargs):\n        truths = []\n        params = []\n        for p in self.properties:\n            try:\n                val, err = self.properties[p]\n            except:\n                continue\n\n            if p in self.ic.bands:\n                params.append('{}_mag'.format(p))\n                truths.append(val)\n            elif p=='parallax':\n                params.append('distance')\n                truths.append(1/(val/1000.))\n            else:\n                params.append(p)\n                truths.append(val)\n        return self.triangle(params, truths=truths, **kwargs)", "response": "Make corner plot of only observable properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prop_samples(self,prop,return_values=True,conf=0.683):\n        samples = self.samples[prop].values\n        \n        if return_values:\n            sorted = np.sort(samples)\n            med = np.median(samples)\n            n = len(samples)\n            lo_ind = int(n*(0.5 - conf/2))\n            hi_ind = int(n*(0.5 + conf/2))\n            lo = med - sorted[lo_ind]\n            hi = sorted[hi_ind] - med\n            return samples, (med,lo,hi)\n        else:\n            return samples", "response": "Returns the samples of the given property based on MCMC"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_samples(self,prop,fig=None,label=True,\n                     histtype='step',bins=50,lw=3,\n                     **kwargs):\n        \"\"\"Plots histogram of samples of desired property.\n\n        :param prop:\n            Desired property (must be legit column of samples)\n            \n        :param fig:\n              Argument for :func:`plotutils.setfig` (``None`` or int).\n\n        :param histtype, bins, lw:\n             Passed to :func:`plt.hist`.\n\n        :param **kwargs:\n            Additional keyword arguments passed to `plt.hist`\n\n        :return:\n            Figure object.\n        \"\"\"\n        setfig(fig)\n        samples,stats = self.prop_samples(prop)\n        fig = plt.hist(samples,bins=bins,normed=True,\n                 histtype=histtype,lw=lw,**kwargs)\n        plt.xlabel(prop)\n        plt.ylabel('Normalized count')\n        \n        if label:\n            med,lo,hi = stats\n            plt.annotate('$%.2f^{+%.2f}_{-%.2f}$' % (med,hi,lo),\n                         xy=(0.7,0.8),xycoords='axes fraction',fontsize=20)\n\n        return fig", "response": "Plots histogram of samples of desired property."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_hdf(self, filename, path='', overwrite=False, append=False):\n        \n        if os.path.exists(filename):\n            store = pd.HDFStore(filename)\n            if path in store:\n                store.close()\n                if overwrite:\n                    os.remove(filename)\n                elif not append:\n                    raise IOError('{} in {} exists.  Set either overwrite or append option.'.format(path,filename))\n            else:\n                store.close()\n\n        self.samples.to_hdf(filename, '{}/samples'.format(path))\n\n        store = pd.HDFStore(filename)\n        attrs = store.get_storer('{}/samples'.format(path)).attrs\n        attrs.properties = self.properties\n        attrs.ic_type = type(self.ic)\n        attrs.maxAV = self.maxAV\n        attrs.max_distance = self.max_distance\n        attrs.min_logg = self.min_logg\n\n        attrs.use_emcee = self.use_emcee\n        attrs._mnest_basename = self._mnest_basename\n\n        attrs.name = self.name\n\n        store.close()", "response": "Saves the object to HDF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the best - fit parameters choosing the best of multiple starting guesses.", "response": "def maxlike(self,nseeds=50):\n        \"\"\"Returns the best-fit parameters, choosing the best of multiple starting guesses\n\n        :param nseeds: (optional)\n            Number of starting guesses, uniformly distributed throughout\n            allowed ranges.  Default=50.\n\n        :return:\n            list of best-fit parameters: ``[mA,mB,age,feh,[distance,A_V]]``.\n            Note that distance and A_V values will be meaningless unless\n            magnitudes are present in ``self.properties``.\n        \n        \"\"\"\n        mA_0,age0,feh0 = self.ic.random_points(nseeds)\n        mB_0,foo1,foo2 = self.ic.random_points(nseeds)\n        mA_fixed = np.maximum(mA_0,mB_0)\n        mB_fixed = np.minimum(mA_0,mB_0)\n        mA_0, mB_0 = (mA_fixed, mB_fixed)\n\n        d0 = 10**(rand.uniform(0,np.log10(self.max_distance),size=nseeds))\n        AV0 = rand.uniform(0,self.maxAV,size=nseeds)\n\n        \n\n        costs = np.zeros(nseeds)\n\n        if self.fit_for_distance:\n            pfits = np.zeros((nseeds,6))\n        else:\n            pfits = np.zeros((nseeds,4))\n            \n        def fn(p): #fmin is a function *minimizer*\n            return -1*self.lnpost(p)\n        \n        for i,mA,mB,age,feh,d,AV in zip(range(nseeds),\n                                    mA_0,mB_0,age0,feh0,d0,AV0):\n                if self.fit_for_distance:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,age,feh,d,AV],disp=False)\n                else:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,age,feh],disp=False)\n                pfits[i,:] = pfit\n                costs[i] = self.lnpost(pfit)\n\n        return pfits[np.argmax(costs),:]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef triangle(self, params=None, **kwargs):\n        if params is None:\n            params = ['mass_A', 'mass_B', 'age', 'feh', 'distance', 'AV']\n\n        super(BinaryStarModel, self).triangle(params=params, **kwargs)", "response": "Makes a nifty corner plot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the best - fit parameters choosing the best of multiple starting guesses.", "response": "def maxlike(self,nseeds=50):\n        \"\"\"Returns the best-fit parameters, choosing the best of multiple starting guesses\n\n        :param nseeds: (optional)\n            Number of starting guesses, uniformly distributed throughout\n            allowed ranges.  Default=50.\n\n        :return:\n            list of best-fit parameters: ``[mA,mB,age,feh,[distance,A_V]]``.\n            Note that distance and A_V values will be meaningless unless\n            magnitudes are present in ``self.properties``.\n        \n        \"\"\"\n        mA_0,age0,feh0 = self.ic.random_points(nseeds)\n        mB_0,foo1,foo2 = self.ic.random_points(nseeds)\n        mC_0,foo3,foo4 = self.ic.random_points(nseeds)\n        m_all = np.sort(np.array([mA_0, mB_0, mC_0]), axis=0)\n        mA_0, mB_0, mC_0 = (m_all[0,:], m_all[1,:], m_all[2,:])\n\n        d0 = 10**(rand.uniform(0,np.log10(self.max_distance),size=nseeds))\n        AV0 = rand.uniform(0,self.maxAV,size=nseeds)\n\n        \n\n        costs = np.zeros(nseeds)\n\n        if self.fit_for_distance:\n            pfits = np.zeros((nseeds,7))\n        else:\n            pfits = np.zeros((nseeds,5))\n            \n        def fn(p): #fmin is a function *minimizer*\n            return -1*self.lnpost(p)\n        \n        for i,mA,mB,mC,age,feh,d,AV in zip(range(nseeds),\n                                    mA_0,mB_0,mC_0,age0,feh0,d0,AV0):\n                if self.fit_for_distance:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,mC,age,feh,d,AV],disp=False)\n                else:\n                    pfit = scipy.optimize.fmin(fn,[mA,mB,mC,age,feh],disp=False)\n                pfits[i,:] = pfit\n                costs[i] = self.lnpost(pfit)\n\n        return pfits[np.argmax(costs),:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a nifty corner plot.", "response": "def triangle(self, params=None, **kwargs):\n        \"\"\"\n        Makes a nifty corner plot.\n\n        \"\"\"\n        if params is None:\n            params = ['mass_A', 'mass_B', 'mass_C', \n                      'age', 'feh', 'distance', 'AV']\n\n        super(TripleStarModel, self).triangle(params=params, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef starfit(folder, multiplicities=['single'], models='mist',\n            use_emcee=False, plot_only=False, overwrite=False, verbose=False,\n            logger=None, starmodel_type=None, ini_file='star.ini',\n            no_plots=False, bands=None, **kwargs):\n    \"\"\" Runs starfit routine for a given folder.\n    \"\"\"\n    nstars = {'single':1,\n              'binary':2,\n              'triple':3}\n\n    if starmodel_type is None:\n        Mod = StarModel\n    else:\n        Mod = starmodel_type\n\n    ichrone = None\n\n    print('Fitting {}'.format(folder))\n    for mult in multiplicities:\n        print('{} starfit...'.format(mult))\n        model_filename = '{}_starmodel_{}.h5'.format(models, mult)\n\n        #initialize logger for folder\n        logfile = os.path.join(folder, 'starfit.log')\n        logger = initLogging(logfile, logger)\n\n        name = os.path.basename(os.path.abspath(folder))\n        mod = None\n        try:\n            start = time.time()\n            if plot_only:\n                try:\n                    mod = Mod.load_hdf('{}/{}'.format(folder,model_filename),\n                                           name=name)\n                except:\n                    pass\n            else:\n                # Only try to fit model if it doesn't exist, unless overwrite is set\n                fit_model = True\n\n                try:\n                    mod = Mod.load_hdf('{}/{}'.format(folder,model_filename),\n                                         name=name)\n                    fit_model = False\n                except:\n                    filename = '{}/{}'.format(folder,model_filename)\n                    if os.path.exists(filename):\n                        os.remove(filename)\n\n                if fit_model or overwrite:\n                    ini_file_path = os.path.join(folder, ini_file)\n                    c = ConfigObj(ini_file_path)\n\n                    if ichrone is None:\n                        if bands is None:\n                            bands = StarModel.get_bands(ini_file_path)\n                        else:\n                            bands += StarModel.get_bands(ini_file_path)\n                        ichrone = get_ichrone(models, bands)\n\n                    N = nstars[mult] if 'N' not in c else None\n                    mod = Mod.from_ini(ichrone, folder, use_emcee=use_emcee, N=N,\n                                        ini_file=ini_file, name=name)\n                    try:\n                        mod.obs.print_ascii()\n                    except:\n                        pass\n\n                    # # Prime the jit call signature?\n                    # ichrone.mag['J'](1.0, 9.7, 0.1, 1000, 0.4)\n\n                    mod.fit(verbose=verbose, overwrite=overwrite, **kwargs)\n                    mod.save_hdf(os.path.join(folder, model_filename), overwrite=overwrite)\n                else:\n                    logger.info('{} exists.  Use -o to overwrite.'.format(model_filename))\n\n            # Only make corner plots if they are older\n            #  than the starmodel hdf file\n            make_corners = False\n            for x in ['physical', 'observed']:\n                f = os.path.join(folder,\n                                 '{}_corner_{}_{}.png'.format(models, mult, x))\n                if not os.path.exists(f):\n                    make_corners = True\n                    break\n                else:\n                    t_mod = os.path.getmtime(os.path.join(folder,model_filename))\n                    t_plot = os.path.getmtime(f)\n                    if t_mod > t_plot:\n                        make_corners=True\n\n            if (make_corners or plot_only) and not no_plots:\n                corner_base = os.path.join(folder, '{}_corner_{}'.format(models, mult))\n                fig1,fig2 = mod.corner_plots(corner_base)\n\n\n            # Make mag plot if necessary.\n            magplot_file = os.path.join(folder, '{}_mags_{}.png'.format(models, mult))\n            make_magplot = False #True\n            if os.path.exists(magplot_file):\n                if os.path.getmtime(os.path.join(folder, model_filename)) > \\\n                        os.path.getmtime(magplot_file) or \\\n                        plot_only:\n                    pass\n                else:\n                    make_magplot = False\n\n            if make_magplot:\n                fig = mod.mag_plot()\n                plt.savefig(os.path.join(folder,'{}_mags_{}.png'.format(models, mult)))\n\n            end = time.time()\n            if plot_only:\n                logger.info('{} starfit successful (plots only) for '.format(mult) +\n                            '{} in {:.1f} minutes.'.format(folder, (end-start)/60))\n            else:\n                logger.info('{} starfit successful for '.format(mult) +\n                            '{} in {:.1f} minutes.'.format(folder, (end-start)/60))\n        except KeyboardInterrupt:\n            logger.error('{} starfit calculation interrupted for {}.'.format(mult,folder))\n            raise\n        except:\n            logger.error('{} starfit calculation failed for {}.'.format(mult,folder),\n                         exc_info=True)\n\n    return mod, logger", "response": "Fit a single or binary star model for a given folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine what a shortcut band name refers to.", "response": "def get_band(cls, b, **kwargs):\n        \"\"\"Defines what a \"shortcut\" band name refers to.\n\n        \"\"\"\n        phot = None\n\n        # Default to SDSS for these\n        if b in ['u','g','r','i','z']:\n            phot = 'SDSSugriz'\n            band = 'sdss_{}'.format(b)\n        elif b in ['U','B','V','R','I','J','H','Ks']:\n            phot = 'UBVRIJHKsKp'\n            band = b\n        elif b=='K':\n            phot = 'UBVRIJHKsKp'\n            band = 'Ks'\n        elif b in ['kep','Kepler','Kp']:\n            phot = 'UBVRIJHKsKp'\n            band = 'Kp'\n        elif b in ['W1','W2','W3','W4']:\n            phot = 'WISE'\n            band = b\n        elif re.match('uvf', b) or re.match('irf', b):\n            phot = 'HST_WFC3'\n            band = b\n        else:\n            m = re.match('([a-zA-Z]+)_([a-zA-Z_]+)',b)\n            if m:\n                if m.group(1) in cls.phot_systems:\n                    phot = m.group(1)\n                    if phot=='LSST':\n                        band = b\n                    else:\n                        band = m.group(2)\n                elif m.group(1) in ['UK','UKIRT']:\n                    phot = 'UKIDSS'\n                    band = m.group(2)\n        if phot is None:\n            raise ValueError('Dartmouth Models cannot resolve band {}!'.format(b))\n        return phot, band"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninterpolate the values of a single object into a single object.", "response": "def interp_values(mass_arr, age_arr, feh_arr, icol, \n                 grid, mass_col, ages, fehs, grid_Ns):\n    \"\"\"mass_arr, age_arr, feh_arr are all arrays at which values are desired\n\n    icol is the column index of desired value\n    grid is nfeh x nage x max(nmass) x ncols array\n    mass_col is the column index of mass\n    ages is grid of ages\n    fehs is grid of fehs\n    grid_Ns keeps track of nmass in each slice (beyond this are nans)\n    \n    \"\"\"\n    \n    N = len(mass_arr)\n    results = np.zeros(N)\n\n    Nage = len(ages)\n    Nfeh = len(fehs)\n\n    for i in range(N):\n        mass = mass_arr[i]\n        age = age_arr[i]\n        feh = feh_arr[i]\n\n        ifeh = searchsorted(fehs, Nfeh, feh)\n        iage = searchsorted(ages, Nage, age)\n\n        pts = np.zeros((8,3))\n        vals = np.zeros(8)\n\n        i_f = ifeh - 1\n        i_a = iage - 1\n        Nmass = grid_Ns[i_f, i_a]\n        imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        pts[0, 0] = grid[i_f, i_a, imass, mass_col]\n        pts[0, 1] = ages[i_a]\n        pts[0, 2] = fehs[i_f]\n        vals[0] = grid[i_f, i_a, imass, icol]\n        pts[1, 0] = grid[i_f, i_a, imass-1, mass_col]\n        pts[1, 1] = ages[i_a]\n        pts[1, 2] = fehs[i_f]\n        vals[1] = grid[i_f, i_a, imass-1, icol]\n\n        i_f = ifeh - 1\n        i_a = iage \n        Nmass = grid_Ns[i_f, i_a]\n        imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        pts[2, 0] = grid[i_f, i_a, imass, mass_col]\n        pts[2, 1] = ages[i_a]\n        pts[2, 2] = fehs[i_f]\n        vals[2] = grid[i_f, i_a, imass, icol]\n        pts[3, 0] = grid[i_f, i_a, imass-1, mass_col]\n        pts[3, 1] = ages[i_a]\n        pts[3, 2] = fehs[i_f]\n        vals[3] = grid[i_f, i_a, imass-1, icol]\n\n        i_f = ifeh\n        i_a = iage - 1\n        Nmass = grid_Ns[i_f, i_a]\n        imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        pts[4, 0] = grid[i_f, i_a, imass, mass_col]\n        pts[4, 1] = ages[i_a]\n        pts[4, 2] = fehs[i_f]\n        vals[4] = grid[i_f, i_a, imass, icol]\n        pts[5, 0] = grid[i_f, i_a, imass-1, mass_col]\n        pts[5, 1] = ages[i_a]\n        pts[5, 2] = fehs[i_f]\n        vals[5] = grid[i_f, i_a, imass-1, icol]\n\n        i_f = ifeh \n        i_a = iage\n        Nmass = grid_Ns[i_f, i_a]\n        imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n        pts[6, 0] = grid[i_f, i_a, imass, mass_col]\n        pts[6, 1] = ages[i_a]\n        pts[6, 2] = fehs[i_f]\n        vals[6] = grid[i_f, i_a, imass, icol]\n        pts[7, 0] = grid[i_f, i_a, imass-1, mass_col]\n        pts[7, 1] = ages[i_a]\n        pts[7, 2] = fehs[i_f]\n        vals[7] = grid[i_f, i_a, imass-1, icol]\n        \n        results[i] = interp_box(mass, age, feh, pts, vals)\n        \n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interp_value(mass, age, feh, icol, \n                 grid, mass_col, ages, fehs, grid_Ns):\n                 # return_box):\n    \"\"\"mass, age, feh are *single values* at which values are desired\n\n    icol is the column index of desired value\n    grid is nfeh x nage x max(nmass) x ncols array\n    mass_col is the column index of mass\n    ages is grid of ages\n    fehs is grid of fehs\n    grid_Ns keeps track of nmass in each slice (beyond this are nans)\n    \n    \"\"\"\n    \n\n    Nage = len(ages)\n    Nfeh = len(fehs)\n\n    ifeh = searchsorted(fehs, Nfeh, feh)\n    iage = searchsorted(ages, Nage, age)\n\n    pts = np.zeros((8,3))\n    vals = np.zeros(8)\n\n    i_f = ifeh - 1\n    i_a = iage - 1\n    Nmass = grid_Ns[i_f, i_a]\n    imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n    pts[0, 0] = grid[i_f, i_a, imass, mass_col]\n    pts[0, 1] = ages[i_a]\n    pts[0, 2] = fehs[i_f]\n    vals[0] = grid[i_f, i_a, imass, icol]\n    pts[1, 0] = grid[i_f, i_a, imass-1, mass_col]\n    pts[1, 1] = ages[i_a]\n    pts[1, 2] = fehs[i_f]\n    vals[1] = grid[i_f, i_a, imass-1, icol]\n\n    i_f = ifeh - 1\n    i_a = iage \n    Nmass = grid_Ns[i_f, i_a]\n    imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n    pts[2, 0] = grid[i_f, i_a, imass, mass_col]\n    pts[2, 1] = ages[i_a]\n    pts[2, 2] = fehs[i_f]\n    vals[2] = grid[i_f, i_a, imass, icol]\n    pts[3, 0] = grid[i_f, i_a, imass-1, mass_col]\n    pts[3, 1] = ages[i_a]\n    pts[3, 2] = fehs[i_f]\n    vals[3] = grid[i_f, i_a, imass-1, icol]\n\n    i_f = ifeh\n    i_a = iage - 1\n    Nmass = grid_Ns[i_f, i_a]\n    imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n    pts[4, 0] = grid[i_f, i_a, imass, mass_col]\n    pts[4, 1] = ages[i_a]\n    pts[4, 2] = fehs[i_f]\n    vals[4] = grid[i_f, i_a, imass, icol]\n    pts[5, 0] = grid[i_f, i_a, imass-1, mass_col]\n    pts[5, 1] = ages[i_a]\n    pts[5, 2] = fehs[i_f]\n    vals[5] = grid[i_f, i_a, imass-1, icol]\n\n    i_f = ifeh \n    i_a = iage\n    Nmass = grid_Ns[i_f, i_a]\n    imass = searchsorted(grid[i_f, i_a, :, mass_col], Nmass, mass)\n    pts[6, 0] = grid[i_f, i_a, imass, mass_col]\n    pts[6, 1] = ages[i_a]\n    pts[6, 2] = fehs[i_f]\n    vals[6] = grid[i_f, i_a, imass, icol]\n    pts[7, 0] = grid[i_f, i_a, imass-1, mass_col]\n    pts[7, 1] = ages[i_a]\n    pts[7, 2] = fehs[i_f]\n    vals[7] = grid[i_f, i_a, imass-1, icol]\n    \n    # if return_box:\n    #     return pts, vals\n    # else:\n    return interp_box(mass, age, feh, pts, vals)", "response": "interp_value is a wrapper around the interp function that takes a single value at a given column index and returns a list of values that are found in the array"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_AV_infinity(ra,dec,frame='icrs'):\n    coords = SkyCoord(ra,dec,unit='deg',frame=frame).transform_to('icrs')\n\n    rah,ram,ras = coords.ra.hms\n    decd,decm,decs = coords.dec.dms\n    if decd > 0:\n        decsign = '%2B'\n    else:\n        decsign = '%2D'\n    url = 'http://ned.ipac.caltech.edu/cgi-bin/nph-calc?in_csys=Equatorial&in_equinox=J2000.0&obs_epoch=2010&lon='+'%i' % rah + \\\n        '%3A'+'%i' % ram + '%3A' + '%05.2f' % ras + '&lat=%s' % decsign + '%i' % abs(decd) + '%3A' + '%i' % abs(decm) + '%3A' + '%05.2f' % abs(decs) + \\\n        '&pa=0.0&out_csys=Equatorial&out_equinox=J2000.0'\n\n    AV = None\n    for line in urllib.request.urlopen(url).readlines():\n        m = re.search(b'^Landolt V \\(0.54\\)\\s+(\\d+\\.\\d+)', line)\n        if m:\n            AV = (float(m.group(1)))\n            break\n\n    if AV is None:\n        raise RuntimeError('AV query fails!  URL is {}'.format(url))\n\n    return AV", "response": "Gets the A_V exctinction at infinity for a given line of sight."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_flask_restful_resource(\n    fun: Callable, flask_restful_api: FlaskRestfulApi, injector: Injector\n) -> Callable:\n    \"\"\"\n    This is needed because of how flask_restful views are registered originally.\n\n    :type flask_restful_api: :class:`flask_restful.Api`\n    \"\"\"\n    # The following fragment of code is copied from flask_restful project\n\n    \"\"\"\n    Copyright (c) 2013, Twilio, Inc.\n    All rights reserved.\n\n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions are met:\n\n    - Redistributions of source code must retain the above copyright notice, this\n      list of conditions and the following disclaimer.\n    - Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n    - Neither the name of the Twilio, Inc. nor the names of its contributors may be\n      used to endorse or promote products derived from this software without\n      specific prior written permission.\n\n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n    ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n    DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n    FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n    DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n    CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n    OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n    OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n    \"\"\"\n\n    @functools.wraps(fun)\n    def wrapper(*args: Any, **kwargs: Any) -> Any:\n        resp = fun(*args, **kwargs)\n        if isinstance(resp, Response):  # There may be a better way to test\n            return resp\n        data, code, headers = flask_response_unpack(resp)\n        return flask_restful_api.make_response(data, code, headers=headers)\n\n    # end of flask_restful code\n\n    return wrapper", "response": "Wraps a function in a Flask Restful API to create a new base base"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompleting a given URL with this instance s URL base.", "response": "def complete_url(self, url):\n    \"\"\" Completes a given URL with this instance's URL base. \"\"\"\n    if self.base_url:\n      return urlparse.urljoin(self.base_url, url)\n    else:\n      return url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndrop the user into an interactive Python session with the sess variable set to the current session instance.", "response": "def interact(self, **local):\n    \"\"\" Drops the user into an interactive Python session with the ``sess`` variable\n    set to the current session instance. If keyword arguments are supplied, these\n    names will also be available within the session. \"\"\"\n    import code\n    code.interact(local=dict(sess=self, **local))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting until a condition holds.", "response": "def wait_for(self,\n               condition,\n               interval = DEFAULT_WAIT_INTERVAL,\n               timeout  = DEFAULT_WAIT_TIMEOUT):\n    \"\"\" Wait until a condition holds by checking it in regular intervals.\n    Raises ``WaitTimeoutError`` on timeout. \"\"\"\n\n    start = time.time()\n\n    # at least execute the check once!\n    while True:\n      res = condition()\n      if res:\n        return res\n\n      # timeout?\n      if time.time() - start > timeout:\n        break\n\n      # wait a bit\n      time.sleep(interval)\n\n    # timeout occured!\n    raise WaitTimeoutError(\"wait_for timed out\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_while(self, condition, *args, **kw):\n    return self.wait_for(lambda: not condition(), *args, **kw)", "response": "Wait while a condition holds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first node matching the given CSSv3 expression or None if no node is found.", "response": "def at_css(self, css, timeout = DEFAULT_AT_TIMEOUT, **kw):\n    \"\"\" Returns the first node matching the given CSSv3 expression or ``None``\n    if a timeout occurs. \"\"\"\n    return self.wait_for_safe(lambda: super(WaitMixin, self).at_css(css),\n                              timeout = timeout,\n                              **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef at_xpath(self, xpath, timeout = DEFAULT_AT_TIMEOUT, **kw):\n    return self.wait_for_safe(lambda: super(WaitMixin, self).at_xpath(xpath),\n                              timeout = timeout,\n                              **kw)", "response": "Returns the first node matching the given XPath expression or None if no node is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef switch_axis_limits(ax, which_axis):\n    '''\n    Switch the axis limits of either x or y. Or both!\n    '''\n    for a in which_axis:\n        assert a in ('x', 'y')\n        ax_limits = ax.axis()\n        if a == 'x':\n            ax.set_xlim(ax_limits[1], ax_limits[0])\n        else:\n            ax.set_ylim(ax_limits[3], ax_limits[2])", "response": "Switch the axis limits of either x or y. Or both!"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_chartjunk(ax, spines, grid=None, ticklabels=None, show_ticks=False,\n                     xkcd=False):\n    '''\n    Removes \"chartjunk\", such as extra lines of axes and tick marks.\n\n    If grid=\"y\" or \"x\", will add a white grid at the \"y\" or \"x\" axes,\n    respectively\n\n    If ticklabels=\"y\" or \"x\", or ['x', 'y'] will remove ticklabels from that\n    axis\n    '''\n    all_spines = ['top', 'bottom', 'right', 'left', 'polar']\n    for spine in spines:\n        # The try/except is for polar coordinates, which only have a 'polar'\n        # spine and none of the others\n        try:\n            ax.spines[spine].set_visible(False)\n        except KeyError:\n            pass\n\n    # For the remaining spines, make their line thinner and a slightly\n    # off-black dark grey\n    if not xkcd:\n        for spine in set(all_spines).difference(set(spines)):\n            # The try/except is for polar coordinates, which only have a\n            # 'polar' spine and none of the others\n            try:\n                ax.spines[spine].set_linewidth(0.5)\n            except KeyError:\n                pass\n                # ax.spines[spine].set_color(almost_black)\n                # ax.spines[spine].set_tick_params(color=almost_black)\n                # Check that the axes are not log-scale. If they are, leave\n                # the ticks because otherwise people assume a linear scale.\n    x_pos = set(['top', 'bottom'])\n    y_pos = set(['left', 'right'])\n    xy_pos = [x_pos, y_pos]\n    xy_ax_names = ['xaxis', 'yaxis']\n\n    for ax_name, pos in zip(xy_ax_names, xy_pos):\n        axis = ax.__dict__[ax_name]\n        # axis.set_tick_params(color=almost_black)\n        #print 'axis.get_scale()', axis.get_scale()\n        if show_ticks or axis.get_scale() == 'log':\n            # if this spine is not in the list of spines to remove\n            for p in pos.difference(spines):\n                #print 'p', p\n                axis.set_tick_params(direction='out')\n                axis.set_ticks_position(p)\n                #                axis.set_tick_params(which='both', p)\n        else:\n            axis.set_ticks_position('none')\n\n    if grid is not None:\n        for g in grid:\n            assert g in ('x', 'y')\n            ax.grid(axis=grid, color='white', linestyle='-', linewidth=0.5)\n\n    if ticklabels is not None:\n        if type(ticklabels) is str:\n            assert ticklabels in set(('x', 'y'))\n            if ticklabels == 'x':\n                ax.set_xticklabels([])\n            if ticklabels == 'y':\n                ax.set_yticklabels([])\n        else:\n            assert set(ticklabels) | set(('x', 'y')) > 0\n            if 'x' in ticklabels:\n                ax.set_xticklabels([])\n            elif 'y' in ticklabels:\n                ax.set_yticklabels([])", "response": "Removes chartjunk from the specified axes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a matplotlib Axes object for the .", "response": "def maybe_get_ax(*args, **kwargs):\n    \"\"\"\n    It used to be that the first argument of prettyplotlib had to be the 'ax'\n    object, but that's not the case anymore.\n\n    @param args:\n    @type args:\n    @param kwargs:\n    @type kwargs:\n    @return:\n    @rtype:\n    \"\"\"\n\n    if 'ax' in kwargs:\n        ax = kwargs.pop('ax')\n    elif len(args) == 0:\n        fig = plt.gcf()\n        ax = plt.gca()\n    elif isinstance(args[0], mpl.axes.Axes):\n        ax = args[0]\n        args = args[1:]\n    else:\n        ax = plt.gca()\n    return ax, args, dict(kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a figure and axes object for the Taxonomy object.", "response": "def maybe_get_fig_ax(*args, **kwargs):\n    \"\"\"\n    It used to be that the first argument of prettyplotlib had to be the 'ax'\n    object, but that's not the case anymore. This is specially made for\n    pcolormesh.\n\n    @param args:\n    @type args:\n    @param kwargs:\n    @type kwargs:\n    @return:\n    @rtype:\n    \"\"\"\n    if 'ax' in kwargs:\n        ax = kwargs.pop('ax')\n        if 'fig' in kwargs:\n            fig = kwargs.pop('fig')\n        else:\n            fig = plt.gcf()\n    elif len(args) == 0:\n        fig = plt.gcf()\n        ax = plt.gca()\n    elif isinstance(args[0], mpl.figure.Figure) and \\\n            isinstance(args[1], mpl.axes.Axes):\n        fig = args[0]\n        ax = args[1]\n        args = args[2:]\n    else:\n        fig, ax = plt.subplots(1)\n    return fig, ax, args, dict(kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bar(*args, **kwargs):\n    ax, args, kwargs = maybe_get_ax(*args, **kwargs)\n    kwargs.setdefault('color', set2[0])\n    kwargs.setdefault('edgecolor', 'white')\n    middle = 0.4 if 'width' not in kwargs else kwargs['width']/2.0\n\n    # Check if data contains stacks\n    stacked = kwargs.pop('stacked',False)\n    # Check if stack text should be included\n    stack_text = kwargs.pop('stack_text',False)\n    # Get legend if available\n    legend = kwargs.pop('legend',False)\n\n    left = args[0]\n    height = np.array(args[1])\n\n    # Label each individual bar, if xticklabels is provided\n    xtickabels = kwargs.pop('xticklabels', None)\n    # left+0.4 is the center of the bar\n    xticks = np.array(left) + middle\n\n    # Whether or not to annotate each bar with the height value\n    annotate = kwargs.pop('annotate', False)\n\n    show_ticks = kwargs.pop('show_ticks', False)\n\n    # If no grid specified, don't draw one.\n    grid = kwargs.pop('grid', None)\n\n    cmap = kwargs.pop('cmap', False)\n    if cmap:\n        kwargs['edgecolor'] = almost_black\n        if not stacked:\n            kwargs['color'] = getcolors(cmap, height, 0)\n\n    # Check if stacked and plot data accordingly\n    color = kwargs.get('color', None)\n    if stacked:\n        num_stacks, num_data = height.shape\n        bottom = np.zeros(num_data)\n        for i in np.arange(num_stacks):\n            lst = list(args)\n            lst[1] = height[i]\n            args = tuple(lst)\n            # make sure number of user specified colors equals to the stacks \n            if not color or len(color) != num_stacks:\n                if cmap:\n                    kwargs['color'] = getcolors(cmap, height[i], i)\n                else:\n                    kwargs['color'] = set2[i]\n            else:\n                kwargs['color'] = color[i]\n            kwargs['bottom'] = bottom\n            rectangles = ax.bar(*args, **kwargs)\n            bottom += height[i]\n    else:\n        rectangles = ax.bar(*args, **kwargs)\n   \n    # add legend\n    if isinstance(legend, collections.Iterable):\n        ax.legend(legend,loc='upper center',bbox_to_anchor=(0.5,1.11), ncol=5)\n\n    # add whitespace padding on left\n    xmin, xmax = ax.get_xlim()\n    xmin -= 0.2\n    if stacked:\n        xmax = num_data\n    ax.set_xlim(xmin, xmax)\n\n    # If the user is only plotting one bar, make it an iterable\n    if not isinstance(height, collections.Iterable):\n        height = [height]\n\n\n    # If there are negative counts, remove the bottom axes\n    # and add a line at y=0\n    if any(h < 0 for h in height.tolist()):\n        axes_to_remove = ['top', 'right', 'bottom']\n        ax.hlines(y=0, xmin=xmin, xmax=xmax,\n                      linewidths=0.75)\n    else:\n        axes_to_remove = ['top', 'right']\n\n    # Remove excess axes\n    remove_chartjunk(ax, axes_to_remove, grid=grid, show_ticks=show_ticks)\n\n    if stacked:\n        data = height\n        height = height.sum(axis=0)\n\n    # Add the xticklabels if they are there\n    if xtickabels is not None:\n        ax.set_xticks(xticks)\n        ax.set_xticklabels(xtickabels)\n\n    if annotate or isinstance(annotate, collections.Iterable):\n        annotate_yrange_factor = 0.025\n        ymin, ymax = ax.get_ylim()\n        yrange = ymax - ymin\n\n        # Reset ymax and ymin so there's enough room to see the annotation of\n        # the top-most\n        if ymax > 0:\n            ymax += yrange * 0.1\n        if ymin < 0:\n            ymin -= yrange * 0.1\n        ax.set_ylim(ymin, ymax)\n        yrange = ymax - ymin\n\n        if kwargs.get('log') == True:\n            offset_ = np.log(yrange) * annotate_yrange_factor\n        else:\n            offset_ = yrange * annotate_yrange_factor\n\n        if isinstance(annotate, collections.Iterable):\n            annotations = map(str, annotate)\n        else:\n            annotations = ['%.3f' % h if type(h) is np.float_ else str(h)\n                               for h in height]\n\n        for x, h, annotation in zip(xticks, height, annotations):\n            # Adjust the offset to account for negative bars\n            offset = offset_ if h >= 0 else -1 * offset_\n            verticalalignment = 'bottom' if h >= 0 else 'top'\n\n            # Finally, add the text to the axes\n            ax.annotate(annotation, (x, h + offset),\n                        verticalalignment=verticalalignment,\n                        horizontalalignment='center',\n                        color=almost_black)\n\n    # Text for each block of stack\n    # This was partially inspired by the following article by Tableau software\n    # http://www.tableausoftware.com/about/blog/2014/1/new-whitepaper-survey-data-less-ugly-more-understandable-27812\n    if stack_text:\n        bottom = np.zeros(num_data)\n        max_h = max(height)\n        for i in np.arange(num_stacks):\n            for x, d, b in zip(xticks, data[i], bottom):\n                if (d*100.0/max_h) > 4.0:\n                    ax.text(x,b+d/2.0,d, ha='center', va='center', color=almost_black)\n            bottom += data[i]\n    return rectangles", "response": "Plots a bar plot on a colorbar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scatter(*args, **kwargs):\n    # Force 'color' to indicate the edge color, so the middle of the\n    # scatter patches are empty. Can specify\n    ax, args, kwargs = utils.maybe_get_ax(*args, **kwargs)\n\n    if 'color' not in kwargs:\n        # Assume that color means the edge color. You can assign the\n        color_cycle = ax._get_lines.color_cycle\n        kwargs['color'] = next(color_cycle)\n    kwargs.setdefault('edgecolor', almost_black)\n    kwargs.setdefault('alpha', 0.5)\n\n    lw = utils.maybe_get_linewidth(**kwargs)\n    kwargs['lw'] = lw\n\n    show_ticks = kwargs.pop('show_ticks', False)\n\n    scatterpoints = ax.scatter(*args, **kwargs)\n    utils.remove_chartjunk(ax, ['top', 'right'], show_ticks=show_ticks)\n    return scatterpoints", "response": "This function will plot a scatterplot of x and y."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a box - and - whisker plot showing the mean 25th percentile and 75th percentile and 75th percentile.", "response": "def boxplot(*args, **kwargs):\n    \"\"\"\n    Create a box-and-whisker plot showing the mean, 25th percentile, and 75th\n    percentile. The difference from matplotlib is only the left axis line is\n    shown, and ticklabels labeling each category of data can be added.\n\n    @param ax:\n    @param x:\n    @param kwargs: Besides xticklabels, which is a prettyplotlib-specific\n    argument which will label each individual boxplot, any argument for\n    matplotlib.pyplot.boxplot will be accepted:\n    http://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes.boxplot\n    @return:\n    \"\"\"\n    ax, args, kwargs = maybe_get_ax(*args, **kwargs)\n    # If no ticklabels are specified, don't draw any\n    xticklabels = kwargs.pop('xticklabels', None)\n    fontsize = kwargs.pop('fontsize', 10)\n\n    kwargs.setdefault('widths', 0.15)\n\n    bp = ax.boxplot(*args, **kwargs)\n\n    if xticklabels:\n        ax.xaxis.set_ticklabels(xticklabels, fontsize=fontsize)\n\n    show_caps = kwargs.pop('show_caps', True)\n    show_ticks = kwargs.pop('show_ticks', False)\n\n    remove_chartjunk(ax, ['top', 'right', 'bottom'], show_ticks=show_ticks)\n    linewidth = 0.75\n\n    blue = colors.set1[1]\n    red = colors.set1[0]\n    plt.setp(bp['boxes'], color=blue, linewidth=linewidth)\n    plt.setp(bp['medians'], color=red)\n    plt.setp(bp['whiskers'], color=blue, linestyle='solid',\n             linewidth=linewidth)\n    plt.setp(bp['fliers'], color=blue)\n    if show_caps:\n        plt.setp(bp['caps'], color=blue, linewidth=linewidth)\n    else:\n        plt.setp(bp['caps'], color='none')\n    ax.spines['left']._linewidth = 0.5\n    return bp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hist(*args, **kwargs):\n    ax, args, kwargs = maybe_get_ax(*args, **kwargs)\n\n    color_cycle = ax._get_lines.color_cycle\n    # Reassign the default colors to Set2 by Colorbrewer\n    if iterable(args[0]):\n        if isinstance(args[0], list):\n            ncolors = len(args[0])\n        else:\n            if len(args[0].shape) == 2:\n                ncolors = args[0].shape[1]\n            else:\n                ncolors = 1\n        kwargs.setdefault('color', [next(color_cycle) for _ in range(ncolors)])\n    else:\n        kwargs.setdefault('color', next(color_cycle))\n    kwargs.setdefault('edgecolor', 'white')\n    show_ticks = kwargs.pop('show_ticks', False)\n\n    # If no grid specified, don't draw one.\n    grid = kwargs.pop('grid', None)\n\n    # print 'hist kwargs', kwargs\n    patches = ax.hist(*args, **kwargs)\n    remove_chartjunk(ax, ['top', 'right'], grid=grid, show_ticks=show_ticks)\n    return patches", "response": "Plots a histogram of the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _beeswarm(ax, x, notch=0, sym='b+', vert=1, whis=1.5,\n            positions=None, widths=None, patch_artist=False,\n            bootstrap=None):\n    \"\"\"\n    Call signature::\n\n      beeswarm(x, notch=0, sym='+', vert=1, whis=1.5,\n              positions=None, widths=None, patch_artist=False)\n\n    Make a box and whisker plot for each column of *x* or each\n    vector in sequence *x*.  The box extends from the lower to\n    upper quartile values of the data, with a line at the median.\n    The whiskers extend from the box to show the range of the\n    data.  Flier points are those past the end of the whiskers.\n\n    Function Arguments:\n\n      *x* :\n        Array or a sequence of vectors.\n\n      *notch* : [ 0 (default) | 1]\n        If 0, produce a rectangular box plot.\n        If 1, produce a notched box plot\n\n      *sym* :\n        (default 'b+') is the default symbol for flier points.\n        Enter an empty string ('') if you don't want to show fliers.\n\n      *vert* : [1 (default) | 0]\n        If 1, make the boxes vertical.\n        If 0, make horizontal boxes. (Odd, but kept for compatibility\n        with MATLAB boxplots)\n\n      *whis* : (default 1.5)\n        Defines the length of the whiskers as\n        a function of the inner quartile range.  They extend to the\n        most extreme data point within ( ``whis*(75%-25%)`` ) data range.\n\n      *bootstrap* : [ *None* (default) | integer ]\n        Specifies whether to bootstrap the confidence intervals\n        around the median for notched boxplots. If *None*, no\n        bootstrapping is performed, and notches are calculated\n        using a Gaussian-based asymptotic approximation\n        (see McGill, R., Tukey, J.W., and Larsen, W.A.,\n        1978, and Kendall and Stuart, 1967). Otherwise, bootstrap\n        specifies the number of times to bootstrap the median to\n        determine its 95% confidence intervals. Values between 1000\n        and 10000 are recommended.\n\n      *positions* : (default 1,2,...,n)\n        Sets the horizontal positions of\n        the boxes. The ticks and limits are automatically set to match\n        the positions.\n\n      *widths* : [ scalar | array ]\n        Either a scalar or a vector to set the width of each box.\n        The default is 0.5, or ``0.15*(distance between extreme\n        positions)`` if that is smaller.\n\n      *patch_artist* : boolean\n        If *False* (default), produce boxes with the\n        :class:`~matplotlib.lines.Line2D` artist.\n        If *True*, produce boxes with the\n        :class:`~matplotlib.patches.Patch` artist.\n\n    Returns a dictionary mapping each component of the boxplot\n    to a list of the :class:`~matplotlib.lines.Line2D`\n    instances created (unless *patch_artist* was *True*. See above.).\n\n    **Example:**\n\n    .. plot:: pyplots/boxplot_demo.py\n    \"\"\"\n    if not ax._hold: ax.cla()\n    holdStatus = ax._hold\n    whiskers, caps, boxes, medians, fliers = [], [], [], [], []\n\n    # convert x to a list of vectors\n    if hasattr(x, 'shape'):\n        if len(x.shape) == 1:\n            if hasattr(x[0], 'shape'):\n                x = list(x)\n            else:\n                x = [x,]\n        elif len(x.shape) == 2:\n            nr, nc = x.shape\n            if nr == 1:\n                x = [x]\n            elif nc == 1:\n                x = [x.ravel()]\n            else:\n                x = [x[:,i] for i in xrange(nc)]\n        else:\n            raise ValueError(\"input x can have no more than 2 dimensions\")\n    if not hasattr(x[0], '__len__'):\n        x = [x]\n    col = len(x)\n\n    # get some plot info\n    if positions is None:\n        positions = range(1, col + 1)\n    if widths is None:\n        distance = max(positions) - min(positions)\n        widths = min(0.15*max(distance,1.0), 0.5)\n    if isinstance(widths, float) or isinstance(widths, int):\n        widths = np.ones((col,), float) * widths\n\n    # loop through columns, adding each to plot\n    ax.hold(True)\n    for i,pos in enumerate(positions):\n        d = np.ravel(x[i])\n        row = len(d)\n        if row==0:\n            # no data, skip this position\n            continue\n        # get median and quartiles\n        q1, med, q3 = mlab.prctile(d,[25,50,75])\n        # get high extreme\n        iq = q3 - q1\n        hi_val = q3 + whis*iq\n        wisk_hi = np.compress( d <= hi_val , d )\n        if len(wisk_hi) == 0:\n            wisk_hi = q3\n        else:\n            wisk_hi = max(wisk_hi)\n        # get low extreme\n        lo_val = q1 - whis*iq\n        wisk_lo = np.compress( d >= lo_val, d )\n        if len(wisk_lo) == 0:\n            wisk_lo = q1\n        else:\n            wisk_lo = min(wisk_lo)\n        \n        # get x locations for fliers, whisker, whisker cap and box sides\n        box_x_min = pos - widths[i] * 0.5\n        box_x_max = pos + widths[i] * 0.5\n        \n        # get fliers - if we are showing them\n        flier = []\n        flier_x = []\n        if len(sym) != 0:\n            flier = d\n            flier_x = np.ones(flier.shape[0]) * pos              \n            flier_x = np.linspace(box_x_min , box_x_max, flier.shape[0])\n        \n        wisk_x = np.ones(2) * pos\n\n        cap_x_min = pos - widths[i] * 0.25\n        cap_x_max = pos + widths[i] * 0.25\n        cap_x = [cap_x_min, cap_x_max]\n\n        # get y location for median\n        med_y = [med, med]\n\n        # calculate 'regular' plot\n        if notch == 0:\n            # make our box vectors\n            box_x = [box_x_min, box_x_max, box_x_max, box_x_min, box_x_min ]\n            box_y = [q1, q1, q3, q3, q1 ]\n            # make our median line vectors\n            med_x = [box_x_min, box_x_max]\n        # calculate 'notch' plot\n        else:\n            if bootstrap is not None:\n                # Do a bootstrap estimate of notch locations.\n                def bootstrapMedian(data, N=5000):\n                    # determine 95% confidence intervals of the median\n                    M = len(data)\n                    percentile = [2.5,97.5]\n                    estimate = np.zeros(N)\n                    for n in range(N):\n                        bsIndex = np.random.random_integers(0,M-1,M)\n                        bsData = data[bsIndex]\n                        estimate[n] = mlab.prctile(bsData, 50)\n                    CI = mlab.prctile(estimate, percentile)\n                    return CI\n\n                # get conf. intervals around median\n                CI = bootstrapMedian(d, N=bootstrap)\n                notch_max = CI[1]\n                notch_min = CI[0]\n            else:\n                # Estimate notch locations using Gaussian-based\n                # asymptotic approximation.\n                #\n                # For discussion: McGill, R., Tukey, J.W.,\n                # and Larsen, W.A. (1978) \"Variations of\n                # Boxplots\", The American Statistician, 32:12-16.\n                notch_max = med + 1.57*iq/np.sqrt(row)\n                notch_min = med - 1.57*iq/np.sqrt(row)\n            # make our notched box vectors\n            box_x = [box_x_min, box_x_max, box_x_max, cap_x_max, box_x_max,\n                     box_x_max, box_x_min, box_x_min, cap_x_min, box_x_min,\n                     box_x_min ]\n            box_y = [q1, q1, notch_min, med, notch_max, q3, q3, notch_max,\n                     med, notch_min, q1]\n            # make our median line vectors\n            med_x = [cap_x_min, cap_x_max]\n            med_y = [med, med]\n\n        def to_vc(xs,ys):\n            # convert arguments to verts and codes\n            verts = []\n            #codes = []\n            for xi,yi in zip(xs,ys):\n                verts.append( (xi,yi) )\n            verts.append( (0,0) ) # ignored\n            codes = [mpath.Path.MOVETO] + \\\n                    [mpath.Path.LINETO]*(len(verts)-2) + \\\n                    [mpath.Path.CLOSEPOLY]\n            return verts,codes\n\n        def patch_list(xs,ys):\n            verts,codes = to_vc(xs,ys)\n            path = mpath.Path( verts, codes )\n            patch = mpatches.PathPatch(path)\n            ax.add_artist(patch)\n            return [patch]\n\n        # vertical or horizontal plot?\n        if vert:\n            def doplot(*args):\n                return ax.plot(*args)\n            def dopatch(xs,ys):\n                return patch_list(xs,ys)\n        else:\n            def doplot(*args):\n                shuffled = []\n                for i in xrange(0, len(args), 3):\n                    shuffled.extend([args[i+1], args[i], args[i+2]])\n                return ax.plot(*shuffled)\n            def dopatch(xs,ys):\n                xs,ys = ys,xs # flip X, Y\n                return patch_list(xs,ys)\n\n        if patch_artist:\n            median_color = 'k'\n        else:\n            median_color = 'r'\n\n        #whiskers.extend(doplot(wisk_x, [q1, wisk_lo], 'b--',\n        #                       wisk_x, [q3, wisk_hi], 'b--'))\n        #caps.extend(doplot(cap_x, [wisk_hi, wisk_hi], 'k-',\n        #                   cap_x, [wisk_lo, wisk_lo], 'k-'))\n        #if patch_artist:\n        #    boxes.extend(dopatch(box_x, box_y))\n        #else:\n        #    boxes.extend(doplot(box_x, box_y, 'b-'))\n        medians.extend(doplot(med_x, med_y, median_color+'-'))\n        fliers.extend(doplot(flier_x, flier, sym))\n\n    # fix our axes/ticks up a little\n    if 1 == vert:\n        setticks, setlim = ax.set_xticks, ax.set_xlim\n    else:\n        setticks, setlim = ax.set_yticks, ax.set_ylim\n\n    newlimits = min(positions)-0.5, max(positions)+0.5\n    setlim(newlimits)\n    setticks(positions)\n\n    # reset hold status\n    ax.hold(holdStatus)\n\n    return dict(whiskers=whiskers, caps=caps, boxes=boxes,\n                medians=medians, fliers=fliers)", "response": "A function to create a non - empty box and whisker plot for each column of x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef beeswarm(*args, **kwargs):\n    ax, args, kwargs = maybe_get_ax(*args, **kwargs)\n    # If no ticklabels are specified, don't draw any\n    xticklabels = kwargs.pop('xticklabels', None)\n    colors = kwargs.pop('colors', None)\n    fontsize = kwargs.pop('fontsize', 10)\n    \n    gray = _colors.set1[8]\n    red = _colors.set1[0]\n    blue = kwargs.pop('color', _colors.set1[1])\n\n    kwargs.setdefault('widths', 0.25)\n    kwargs.setdefault('sym', \"o\")\n    \n    bp = _beeswarm(ax, *args, **kwargs)\n    \n    kwargs.setdefault(\"median_color\", gray)\n    kwargs.setdefault(\"median_linewidth\", 2)\n    \n    \n    if xticklabels:\n        ax.xaxis.set_ticklabels(xticklabels, fontsize=fontsize)\n\n    show_caps = kwargs.pop('show_caps', True)\n    show_ticks = kwargs.pop('show_ticks', False)\n\n    remove_chartjunk(ax, ['top', 'right', 'bottom'], show_ticks=show_ticks)\n    linewidth = 0.75\n\n    plt.setp(bp['boxes'], color=blue, linewidth=linewidth)\n    plt.setp(bp['medians'], color=kwargs.pop(\"median_color\"), linewidth=kwargs.pop(\"median_linewidth\"))\n    #plt.setp(bp['whiskers'], color=blue, linestyle='solid',\n    #         linewidth=linewidth)\n    for color, flier in zip(colors, bp['fliers']):\n        plt.setp(flier, color=color)\n    #if show_caps:\n    #    plt.setp(bp['caps'], color=blue, linewidth=linewidth)\n    #else:\n    #    plt.setp(bp['caps'], color='none')\n    ax.spines['left']._linewidth = 0.5\n    return bp", "response": "Create a R - like beeswarm plot showing the mean and datapoints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting a bar plot on a matplotlib. Axes instance containing the matplotlib. bar plot.", "response": "def barh(*args, **kwargs):\n    \"\"\"\n    Creates a bar plot, with white outlines and a fill color that defaults to\n     the first teal-ish green in ColorBrewer's Set2. Optionally accepts\n     grid='y' or grid='x' to draw a white grid over the bars,\n     to show the scale. Almost like \"erasing\" some of the plot,\n     but it adds more information!\n\n    Can also add an annotation of the width of the barplots directly onto\n    the bars with the `annotate` parameter, which can either be True,\n    which will annotate the values, or a list of strings, which will annotate\n    with the supplied strings.\n\n    Can support stacked bars with the value of each stack shown on the stack\n    (Added by Salil Banerjee)\n\n    @param ax: matplotlib.axes instance\n    @param top: Vector of values of where to put the top side of the bar\n    @param width: Vector of values of the bar widths\n    @param ytickabels: Vector of labels of the bar widths\n    @param kwargs: Any additional arguments to matplotlib.bar()\n    \"\"\"\n    ax, args, kwargs = maybe_get_ax(*args, **kwargs)\n    kwargs.setdefault('color', set2[0])\n    kwargs.setdefault('edgecolor', 'white')\n    middle = 0.4 if 'width' not in kwargs else kwargs['width']/2.0\n\n    # Check if data contains stacks\n    stacked = kwargs.pop('stacked',False)\n    # Check if stack text should be included\n    stack_text = kwargs.pop('stack_text',False)\n    # Get legend if available\n    legend = kwargs.pop('legend',False)\n\n    top = args[0]\n    width = np.array(args[1])\n\n    # Label each individual bar, if xticklabels is provided\n    ytickabels = kwargs.pop('yticklabels', None)\n    # left+0.4 is the center of the bar\n    yticks = np.array(top) + middle\n\n    # Whether or not to annotate each bar with the width value\n    annotate = kwargs.pop('annotate', False)\n\n    # If no grid specified, don't draw one.\n    grid = kwargs.pop('grid', None)\n\n    cmap = kwargs.pop('cmap', False)\n    if cmap:\n        kwargs['edgecolor'] = almost_black\n        if not stacked:\n            kwargs['color'] = getcolors(cmap, width, 0)\n\n    # Check if stacked and plot data accordingly\n    if stacked:\n        num_stacks, num_data = width.shape\n        left = np.zeros(num_data)\n        for i in np.arange(num_stacks):\n            lst = list(args)\n            lst[1] = width[i]\n            args = tuple(lst)\n            if cmap:\n                kwargs['color'] = getcolors(cmap, width[i], i)\n            else:\n                kwargs['color'] = set2[i]\n            kwargs['left'] = left\n            rectangles = ax.barh(*args, **kwargs)\n            left += width[i]\n    else:\n        rectangles = ax.barh(*args, **kwargs)\n\n    # add legend\n    if isinstance(legend, collections.Iterable):\n        ax.legend(legend,loc='upper center',bbox_to_anchor=(0.5,1.11), ncol=5)\n\n    # add whitespace padding on left\n    ymin, ymax = ax.get_ylim()\n    ymin -= 0.2\n    if stacked:\n        ymax = num_data\n    ax.set_ylim(ymin, ymax)\n\n    # If there are negative counts, remove the bottom axes\n    # and add a line at y=0\n    if any(w < 0 for w in width.tolist()):\n        axes_to_remove = ['top', 'right', 'bottom']\n        ax.vlines(x=0, ymin=ymin, ymax=ymax,\n                  linewidths=0.75)\n       #ax.hlines(y=0, xmin=xmin, xmax=xmax,\n       #       linewidths=0.75)\n    else:\n        axes_to_remove = ['top', 'right']\n\n    #Remove excess axes\n    remove_chartjunk(ax, axes_to_remove, grid=grid)\n\n    if stacked:\n        data = width\n        width = width.sum(axis=0)\n\n    # Add the yticklabels if they are there\n    if ytickabels is not None:\n        ax.set_yticks(yticks)\n        ax.set_yticklabels(ytickabels)\n\n    if annotate or isinstance(annotate, collections.Iterable):\n        annotate_xrange_factor = 0.050\n        xmin, xmax = ax.get_xlim()\n        xrange = xmax - xmin\n\n        # Reset ymax and ymin so there's enough room to see the annotation of\n        # the top-most\n        if xmax > 0:\n            xmax += xrange * 0.1\n        if xmin < 0:\n            xmin -= xrange * 0.1\n        ax.set_xlim(xmin, xmax)\n        xrange = xmax - xmin\n\n        offset_ = xrange * annotate_xrange_factor\n        if isinstance(annotate, collections.Iterable):\n            annotations = map(str, annotate)\n        else:\n            annotations = ['%.3f' % w if type(w) is np.float_ else str(w)\n                           for w in width]\n        for y, w, annotation in zip(yticks, width, annotations):\n            # Adjust the offset to account for negative bars\n            offset = offset_ if w >= 0 else -1 * offset_\n            # Finally, add the text to the axes\n            ax.annotate(annotation, (w + offset, y),\n                        verticalalignment='center',\n                        horizontalalignment='center',\n                        color=almost_black)\n\n    # Text for each block of stack\n    # This was partially inspired by the following article by Tableau software\n    # http://www.tableausoftware.com/about/blog/2014/1/new-whitepaper-survey-data-less-ugly-more-understandable-27812\n    if stack_text:\n        left = np.zeros(num_data)\n        max_w = max(width)\n        for i in np.arange(num_stacks):\n            for y, d, l in zip(yticks, data[i], left):\n                if (d*100.0/max_w) > 2.0:\n                    ax.text(l+d/2.0,y,d, ha='center', va='center', color=almost_black)\n            left += data[i]\n\n    return rectangles"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse for large datasets Non-traditional `pcolormesh` kwargs are: - xticklabels, which will put x tick labels exactly in the center of the heatmap block - yticklables, which will put y tick labels exactly aligned in the center of the heatmap block - xticklabels_rotation, which can be either 'horizontal' or 'vertical' depending on how you want the xticklabels rotated. The default is 'horizontal', but if you have xticklabels that are longer, you may want to do 'vertical' so they don't overlap. - yticklabels_rotation, which can also be either 'horizontal' or 'vertical'. The default is 'horizontal' and in most cases, that's what you'll want to stick with. But the option is there if you want. - center_value, which will be the centered value for a divergent colormap, for example if you have data above and below zero, but you want the white part of the colormap to be equal to 10 rather than 0, then specify 'center_value=10'.", "response": "def pcolormesh(*args, **kwargs):\n    \"\"\"\n    Use for large datasets\n\n    Non-traditional `pcolormesh` kwargs are:\n    - xticklabels, which will put x tick labels exactly in the center of the\n    heatmap block\n    - yticklables, which will put y tick labels exactly aligned in the center\n     of the heatmap block\n     - xticklabels_rotation, which can be either 'horizontal' or 'vertical'\n     depending on how you want the xticklabels rotated. The default is\n     'horizontal', but if you have xticklabels that are longer, you may want\n     to do 'vertical' so they don't overlap.\n     - yticklabels_rotation, which can also be either 'horizontal' or\n     'vertical'. The default is 'horizontal' and in most cases,\n     that's what you'll want to stick with. But the option is there if you\n     want.\n    - center_value, which will be the centered value for a divergent\n    colormap, for example if you have data above and below zero, but you want\n    the white part of the colormap to be equal to 10 rather than 0,\n    then specify 'center_value=10'.\n    \"\"\"\n    # Deal with arguments in kwargs that should be there, or need to be taken\n    #  out\n    fig, ax, args, kwargs = maybe_get_fig_ax(*args, **kwargs)\n\n    # If x and y axis are passed in arguments, gets correct data\n    # Ticks will work with x and y data, although it would be pointless to use\n    # both x/y and custom ticks\n    if len(args) == 3:\n        x = args[0]\n        y = args[1]\n        data = args[2]\n    elif len(args) == 1:\n        data = args[0]\n\n    kwargs.setdefault('vmax', data.max())\n    kwargs.setdefault('vmin', data.min())\n\n    center_value = kwargs.pop('center_value', 0)\n\n    # If\n    divergent_data = False\n    if kwargs['vmax'] > 0 and kwargs['vmin'] < 0:\n        divergent_data = True\n        kwargs['vmax'] += center_value\n        kwargs['vmin'] += center_value\n\n    # If we have both negative and positive values, use a divergent colormap\n    if 'cmap' not in kwargs:\n        # Check if this is divergent\n        if divergent_data:\n            kwargs['cmap'] = blue_red\n        elif kwargs['vmax'] <= 0:\n            kwargs['cmap'] = blues_r\n        elif kwargs['vmax'] > 0:\n            kwargs['cmap'] = reds\n\n    if 'xticklabels' in kwargs:\n        xticklabels = kwargs['xticklabels']\n        kwargs.pop('xticklabels')\n    else:\n        xticklabels = None\n    if 'yticklabels' in kwargs:\n        yticklabels = kwargs['yticklabels']\n        kwargs.pop('yticklabels')\n    else:\n        yticklabels = None\n\n    if 'xticklabels_rotation' in kwargs:\n        xticklabels_rotation = kwargs['xticklabels_rotation']\n        kwargs.pop('xticklabels_rotation')\n    else:\n        xticklabels_rotation = 'horizontal'\n    if 'yticklabels_rotation' in kwargs:\n        yticklabels_rotation = kwargs['yticklabels_rotation']\n        kwargs.pop('yticklabels_rotation')\n    else:\n        yticklabels_rotation = 'horizontal'\n\n    ax_colorbar = kwargs.pop('ax_colorbar', None)\n    orientation_colorbar = kwargs.pop('orientation_colorbar', 'vertical')\n\n    p = ax.pcolormesh(*args, **kwargs)\n    # ax.set_ylim(0, x.shape[0])\n    # ax.set_xlim(0, x.shape[1])\n\n    # Get rid of ALL axes\n    remove_chartjunk(ax, ['top', 'right', 'left', 'bottom'])\n\n    if xticklabels is not None and any(xticklabels):\n        if len(args) == 1:\n            xticks = np.arange(0.5, data.shape[1] + 0.5)\n        else:\n            xticks = []\n            for i in np.arange(len(x) - 1):\n                half = float(x[i + 1] - x[i]) / 2. + x[i]\n                xticks.append(half)\n        xticks = np.array(xticks)\n        ax.set_xticks(xticks)\n        ax.set_xticklabels(xticklabels, rotation=xticklabels_rotation)\n\n    if yticklabels is not None and any(yticklabels):\n        if len(args) == 1:\n            yticks = np.arange(0.5, data.shape[1] + 0.5)\n        else:\n            yticks = []\n            for i in np.arange(len(y) - 1):\n                half = float(y[i + 1] - y[i]) / 2. + y[i]\n                yticks.append(half)\n        yticks = np.array(yticks)\n        ax.set_yticks(yticks)\n        ax.set_yticklabels(yticklabels, rotation=yticklabels_rotation)\n\n    # Show the scale of the colorbar\n    cbar = fig.colorbar(p, cax=ax_colorbar, use_gridspec=True,\n                 orientation=orientation_colorbar)\n    return p, cbar"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a request to a specific method in this client.", "response": "def call(self, op_name, query=None, **kwargs):\n        \"\"\"\n        Make a request to a method in this client.  The response data is\n        returned from this call as native Python data structures.\n\n        This method differs from just calling the client method directly\n        in the following ways:\n\n          * It automatically handles the pagination rather than\n            relying on a separate pagination method call.\n          * You can pass an optional jmespath query and this query\n            will be applied to the data returned from the low-level\n            call.  This allows you to tailor the returned data to be\n            exactly what you want.\n\n        :type op_name: str\n        :param op_name: The name of the request you wish to make.\n\n        :type query: str\n        :param query: A jmespath query that will be applied to the\n            data returned by the operation prior to returning\n            it to the user.\n\n        :type kwargs: keyword arguments\n        :param kwargs: Additional keyword arguments you want to pass\n            to the method when making the request.\n        \"\"\"\n        LOG.debug(kwargs)\n        if query:\n            query = jmespath.compile(query)\n        if self._client.can_paginate(op_name):\n            paginator = self._client.get_paginator(op_name)\n            results = paginator.paginate(**kwargs)\n            data = results.build_full_result()\n        else:\n            op = getattr(self._client, op_name)\n            done = False\n            data = {}\n            while not done:\n                try:\n                    data = op(**kwargs)\n                    done = True\n                except ClientError as e:\n                    LOG.debug(e, kwargs)\n                    if 'Throttling' in str(e):\n                        time.sleep(1)\n                    elif 'AccessDenied' in str(e):\n                        done = True\n                    elif 'NoSuchTagSet' in str(e):\n                        done = True\n                except Exception:\n                    done = True\n        if query:\n            data = query.search(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match(self, pattern, context=None):\n        matches = []\n        regex = pattern\n        if regex == '*':\n            regex = '.*'\n        regex = re.compile(regex)\n        for choice in self.choices(context):\n            if regex.search(choice):\n                matches.append(choice)\n        return matches", "response": "This method returns a list of strings that match the regular expression pattern provided."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the ugly Tags JSON into a real dictionary and memorize the result.", "response": "def tags(self):\n        \"\"\"\n        Convert the ugly Tags JSON into a real dictionary and\n        memorize the result.\n        \"\"\"\n        if self._tags is None:\n            LOG.debug('need to build tags')\n            self._tags = {}\n\n            if hasattr(self.Meta, 'tags_spec') and (self.Meta.tags_spec is not None):\n                LOG.debug('have a tags_spec')\n                method, path, param_name, param_value = self.Meta.tags_spec[:4]\n                kwargs = {}\n                filter_type = getattr(self.Meta, 'filter_type', None)\n                if filter_type == 'arn':\n                    kwargs = {param_name: [getattr(self, param_value)]}\n                elif filter_type == 'list':\n                    kwargs = {param_name: [getattr(self, param_value)]}\n                else:\n                    kwargs = {param_name: getattr(self, param_value)}\n                if len(self.Meta.tags_spec) > 4:\n                    kwargs.update(self.Meta.tags_spec[4])\n                LOG.debug('fetching tags')\n                self.data['Tags'] = self._client.call(\n                    method, query=path, **kwargs)\n                LOG.debug(self.data['Tags'])\n\n            if 'Tags' in self.data:\n                _tags = self.data['Tags']\n                if isinstance(_tags, list):\n                    for kvpair in _tags:\n                        if kvpair['Key'] in self._tags:\n                            if not isinstance(self._tags[kvpair['Key']], list):\n                                self._tags[kvpair['Key']] = [self._tags[kvpair['Key']]]\n                            self._tags[kvpair['Key']].append(kvpair['Value'])\n                        else:\n                            self._tags[kvpair['Key']] = kvpair['Value']\n                elif isinstance(_tags, dict):\n                    self._tags = _tags\n        return self._tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the CloudWatch metric data for this resource.", "response": "def get_metric_data(self, metric_name=None, metric=None,\n                        days=None, hours=1, minutes=None,\n                        statistics=None, period=None):\n        \"\"\"\n        Get metric data for this resource.  You can specify the time\n        frame for the data as either the number of days or number of\n        hours.  The maximum window is 14 days.  Based on the time frame\n        this method will calculate the correct ``period`` to return\n        the maximum number of data points up to the CloudWatch max\n        of 1440.\n\n        :type metric_name: str\n        :param metric_name: The name of the metric this data will\n            pertain to.\n\n        :type days: int\n        :param days: The number of days worth of data to return.\n            You can specify either ``days`` or ``hours``.  The default\n            is one hour.  The maximum value is 14 days.\n\n        :type hours: int\n        :param hours: The number of hours worth of data to return.\n            You can specify either ``days`` or ``hours``.  The default\n            is one hour.  The maximum value is 14 days.\n\n        :type statistics: list of str\n        :param statistics: The metric statistics to return.  The default\n            value is **Average**.  Possible values are:\n\n            * Average\n            * Sum\n            * SampleCount\n            * Maximum\n            * Minimum\n\n        :returns: A ``MetricData`` object that contains both the CloudWatch\n            data as well as the ``period`` used since this value may have\n            been calculated by skew.\n        \"\"\"\n        if not statistics:\n            statistics = ['Average']\n        if days:\n            delta = datetime.timedelta(days=days)\n        elif hours:\n            delta = datetime.timedelta(hours=hours)\n        else:\n            delta = datetime.timedelta(minutes=minutes)\n        if not period:\n            period = max(60, self._total_seconds(delta) // 1440)\n        if not metric:\n            metric = self.find_metric(metric_name)\n        if metric and self._cloudwatch:\n            end = datetime.datetime.utcnow()\n            start = end - delta\n            data = self._cloudwatch.call(\n                'get_metric_statistics',\n                Dimensions=metric['Dimensions'],\n                Namespace=metric['Namespace'],\n                MetricName=metric['MetricName'],\n                StartTime=start.isoformat(), EndTime=end.isoformat(),\n                Statistics=statistics, Period=period)\n            return MetricData(jmespath.search('Datapoints', data),\n                              period)\n        else:\n            raise ValueError('Metric (%s) not available' % metric_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_all_distributions(self):\n        distributions = []\n        for this in dir(scipy.stats):\n            if \"fit\" in eval(\"dir(scipy.stats.\" + this +\")\"):\n                distributions.append(this)\n        self.distributions = distributions[:]", "response": "Replace the. distributions attribute with all scipy distributions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hist(self):\n        _ = pylab.hist(self._data, bins=self.bins, density=True)\n        pylab.grid(True)", "response": "Draw a normed histogram of the data using the binning of the objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self):\n        for distribution in self.distributions:\n            try:\n                # need a subprocess to check time it takes. If too long, skip it\n                dist = eval(\"scipy.stats.\" + distribution)\n\n                # TODO here, dist.fit may take a while or just hang forever\n                # with some distributions. So, I thought to use signal module\n                # to catch the error when signal takes too long. It did not work\n                # presumably because another try/exception is inside the\n                # fit function, so I used threading with arecipe from stackoverflow\n                # See timed_run function above\n                param = self._timed_run(dist.fit, distribution, args=self._data)\n\n                # with signal, does not work. maybe because another expection is caught\n                pdf_fitted = dist.pdf(self.x, *param) # hoping the order returned by fit is the same as in pdf\n\n                self.fitted_param[distribution] = param[:]\n                self.fitted_pdf[distribution] = pdf_fitted\n\n                sq_error = pylab.sum((self.fitted_pdf[distribution] - self.y)**2)\n                if self.verbose:\n                    print(\"Fitted {} distribution with error={})\".format(distribution, sq_error))\n\n                # compute some errors now\n                self._fitted_errors[distribution] = sq_error\n            except Exception as err:\n                if self.verbose:\n                    print(\"SKIPPED {} distribution (taking more than {} seconds)\".format(distribution, \n                        self.timeout))\n                # if we cannot compute the error, set it to large values\n                # FIXME use inf\n                self._fitted_errors[distribution] = 1e6\n\n        self.df_errors = pd.DataFrame({'sumsquare_error':self._fitted_errors})", "response": "r This function is called by the fit method of the base class. It will loop over distributions and find the best parameter to fit the data for each of the dataframes and populate the set of dataframes that are currently fitted onto the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting the pdf of the distributions with the highest likelihood.", "response": "def plot_pdf(self, names=None, Nbest=5, lw=2):\n        \"\"\"Plots Probability density functions of the distributions\n\n        :param str,list names: names can be a single distribution name, or a list\n            of distribution names, or kept as None, in which case, the first Nbest\n            distribution will be taken (default to best 5)\n\n\n        \"\"\"\n        assert Nbest > 0\n        if Nbest > len(self.distributions):\n            Nbest = len(self.distributions)\n\n        if isinstance(names, list):\n            for name in names:\n                pylab.plot(self.x, self.fitted_pdf[name], lw=lw, label=name)\n        elif names:\n            pylab.plot(self.x, self.fitted_pdf[names], lw=lw, label=names)\n        else:\n            try:\n                names = self.df_errors.sort_values(\n                        by=\"sumsquare_error\").index[0:Nbest]\n            except:\n                names = self.df_errors.sort(\"sumsquare_error\").index[0:Nbest]\n\n            for name in names:\n                if name in self.fitted_pdf.keys():\n                    pylab.plot(self.x, self.fitted_pdf[name], lw=lw, label=name)\n                else:\n                    print(\"%s was not fitted. no parameters available\" % name)\n        pylab.grid(True)\n        pylab.legend()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the distribution of the data and Nbest distribution", "response": "def summary(self, Nbest=5, lw=2, plot=True):\n        \"\"\"Plots the distribution of the data and Nbest distribution\n\n        \"\"\"\n        if plot:\n            pylab.clf()\n            self.hist()\n            self.plot_pdf(Nbest=Nbest, lw=lw)\n            pylab.grid(True)\n\n        Nbest = min(Nbest, len(self.distributions))\n        try:\n            names = self.df_errors.sort_values(\n                    by=\"sumsquare_error\").index[0:Nbest]\n        except:\n            names = self.df_errors.sort(\"sumsquare_error\").index[0:Nbest]\n        return self.df_errors.loc[names]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _timed_run(self, func, distribution, args=(), kwargs={},  default=None):\n        class InterruptableThread(threading.Thread):\n            def __init__(self):\n                threading.Thread.__init__(self)\n                self.result = default\n                self.exc_info = (None, None, None)\n\n            def run(self):\n                try:\n                    self.result = func(args, **kwargs)\n                except Exception as err:\n                    self.exc_info = sys.exc_info()\n\n            def suicide(self):\n                raise RuntimeError('Stop has been called')\n\n        it = InterruptableThread()\n        it.start()\n        started_at = datetime.now()\n        it.join(self.timeout)\n        ended_at = datetime.now()\n        diff = ended_at - started_at\n\n        if it.exc_info[0] is not None:  # if there were any exceptions\n            a,b,c = it.exc_info\n            raise Exception(a,b,c)  # communicate that to caller\n\n        if it.isAlive():\n            it.suicide()\n            raise RuntimeError\n        else:\n            return it.result", "response": "This function will spawn a thread and run the given function using the args kwargs and return the default value if the timeout is exceeded."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_norm_tig(g, **kwargs):\n    tig = compute_tig(g, **kwargs)\n    return np.linalg.norm(tig, axis=1, ord=2)", "response": "r Compute the norm of the Tig."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(self, s, method='chebyshev', order=30):\n        s = self.G._check_signal(s)\n\n        # TODO: not in self.Nin (Nf = Nin x Nout).\n        if s.ndim == 1 or s.shape[-1] not in [1, self.Nf]:\n            if s.ndim == 3:\n                raise ValueError('Third dimension (#features) should be '\n                                 'either 1 or the number of filters Nf = {}, '\n                                 'got {}.'.format(self.Nf, s.shape))\n            s = np.expand_dims(s, -1)\n        n_features_in = s.shape[-1]\n\n        if s.ndim < 3:\n            s = np.expand_dims(s, 1)\n        n_signals = s.shape[1]\n\n        if s.ndim > 3:\n            raise ValueError('At most 3 dimensions: '\n                             '#nodes x #signals x #features.')\n        assert s.ndim == 3\n\n        # TODO: generalize to 2D (m --> n) filter banks.\n        # Only 1 --> Nf (analysis) and Nf --> 1 (synthesis) for now.\n        n_features_out = self.Nf if n_features_in == 1 else 1\n\n        if method == 'exact':\n\n            # TODO: will be handled by g.adjoint().\n            axis = 1 if n_features_in == 1 else 2\n            f = self.evaluate(self.G.e)\n            f = np.expand_dims(f.T, axis)\n            assert f.shape == (self.G.N, n_features_in, n_features_out)\n\n            s = self.G.gft(s)\n            s = np.matmul(s, f)\n            s = self.G.igft(s)\n\n        elif method == 'chebyshev':\n\n            # TODO: update Chebyshev implementation (after 2D filter banks).\n            c = approximations.compute_cheby_coeff(self, m=order)\n\n            if n_features_in == 1:  # Analysis.\n                s = s.squeeze(axis=2)\n                s = approximations.cheby_op(self.G, c, s)\n                s = s.reshape((self.G.N, n_features_out, n_signals), order='F')\n                s = s.swapaxes(1, 2)\n\n            elif n_features_in == self.Nf:  # Synthesis.\n                s = s.swapaxes(1, 2)\n                s_in = s.reshape(\n                    (self.G.N * n_features_in, n_signals), order='F')\n                s = np.zeros((self.G.N, n_signals))\n                tmpN = np.arange(self.G.N, dtype=int)\n                for i in range(n_features_in):\n                    s += approximations.cheby_op(self.G,\n                                                 c[i],\n                                                 s_in[i * self.G.N + tmpN])\n                s = np.expand_dims(s, 2)\n\n        else:\n            raise ValueError('Unknown method {}.'.format(method))\n\n        # Return a 1D signal if e.g. a 1D signal was filtered by one filter.\n        return s.squeeze()", "response": "r Filter a signal by a given method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef synthesize(self, s, method='chebyshev', order=30):\n        if s.shape[-1] != self.Nf:\n            raise ValueError('Last dimension (#features) should be the number '\n                             'of filters Nf = {}, got {}.'.format(self.Nf,\n                                                                  s.shape))\n        return self.filter(s, method, order)", "response": "Synthesize a set of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter(self, s, method='exact', order=None):\n        return super(Gabor, self).filter(s, method='exact')", "response": "Filter the Gabor object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef D(self):\n        if self._D is None:\n            self.logger.warning('The differential operator G.D is not '\n                                'available, we need to compute it. Explicitly '\n                                'call G.compute_differential_operator() '\n                                'once beforehand to suppress the warning.')\n            self.compute_differential_operator()\n        return self._D", "response": "Returns the differential operator for gradient and divergence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_differential_operator(self):\n\n        sources, targets, weights = self.get_edge_list()\n\n        n = self.n_edges\n        rows = np.concatenate([sources, targets])\n        columns = np.concatenate([np.arange(n), np.arange(n)])\n        values = np.empty(2*n)\n\n        if self.lap_type == 'combinatorial':\n            values[:n] = -np.sqrt(weights)\n            values[n:] = -values[:n]\n        elif self.lap_type == 'normalized':\n            values[:n] = -np.sqrt(weights / self.dw[sources])\n            values[n:] = +np.sqrt(weights / self.dw[targets])\n        else:\n            raise ValueError('Unknown lap_type {}'.format(self.lap_type))\n\n        if self.is_directed():\n            values /= np.sqrt(2)\n\n        self._D = sparse.csc_matrix((values, (rows, columns)),\n                                    shape=(self.n_vertices, self.n_edges))\n        self._D.eliminate_zeros()", "response": "r Compute the graph differential operator for a given set of modules."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grad(self, x):\n        x = self._check_signal(x)\n        return self.D.T.dot(x)", "response": "r Compute the gradient of a signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gft(self, s):\n        s = self._check_signal(s)\n        U = np.conjugate(self.U)  # True Hermitian. (Although U is often real.)\n        return np.tensordot(U, s, ([0], [0]))", "response": "r Compute the graph Fourier transform of a signal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef igft(self, s_hat):\n        s_hat = self._check_signal(s_hat)\n        return np.tensordot(self.U, s_hat, ([1], [0]))", "response": "r Compute the inverse graph Fourier transform of a Fourier domain signal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_cheby_coeff(f, m=30, N=None, *args, **kwargs):\n    G = f.G\n    i = kwargs.pop('i', 0)\n\n    if not N:\n        N = m + 1\n\n    a_arange = [0, G.lmax]\n\n    a1 = (a_arange[1] - a_arange[0]) / 2\n    a2 = (a_arange[1] + a_arange[0]) / 2\n    c = np.zeros(m + 1)\n\n    tmpN = np.arange(N)\n    num = np.cos(np.pi * (tmpN + 0.5) / N)\n    for o in range(m + 1):\n        c[o] = 2. / N * np.dot(f._kernels[i](a1 * num + a2),\n                               np.cos(np.pi * o * (tmpN + 0.5) / N))\n\n    return c", "response": "r Compute Chebyshev coefficients for a Filterbank."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cheby_op(G, c, signal, **kwargs):\n    # Handle if we do not have a list of filters but only a simple filter in cheby_coeff.\n    if not isinstance(c, np.ndarray):\n        c = np.array(c)\n\n    c = np.atleast_2d(c)\n    Nscales, M = c.shape\n\n    if M < 2:\n        raise TypeError(\"The coefficients have an invalid shape\")\n\n    # thanks to that, we can also have 1d signal.\n    try:\n        Nv = np.shape(signal)[1]\n        r = np.zeros((G.N * Nscales, Nv))\n    except IndexError:\n        r = np.zeros((G.N * Nscales))\n\n    a_arange = [0, G.lmax]\n\n    a1 = float(a_arange[1] - a_arange[0]) / 2.\n    a2 = float(a_arange[1] + a_arange[0]) / 2.\n\n    twf_old = signal\n    twf_cur = (G.L.dot(signal) - a2 * signal) / a1\n\n    tmpN = np.arange(G.N, dtype=int)\n    for i in range(Nscales):\n        r[tmpN + G.N*i] = 0.5 * c[i, 0] * twf_old + c[i, 1] * twf_cur\n\n    factor = 2/a1 * (G.L - a2 * sparse.eye(G.N))\n    for k in range(2, M):\n        twf_new = factor.dot(twf_cur) - twf_old\n        for i in range(Nscales):\n            r[tmpN + G.N*i] += c[i, k] * twf_new\n\n        twf_old = twf_cur\n        twf_cur = twf_new\n\n    return r", "response": "r Chebyshev polynomial of graph Laplacian applied to vector."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cheby_rect(G, bounds, signal, **kwargs):\n    if not (isinstance(bounds, (list, np.ndarray)) and len(bounds) == 2):\n        raise ValueError('Bounds of wrong shape.')\n\n    bounds = np.array(bounds)\n\n    m = int(kwargs.pop('order', 30) + 1)\n\n    try:\n        Nv = np.shape(signal)[1]\n        r = np.zeros((G.N, Nv))\n    except IndexError:\n        r = np.zeros((G.N))\n\n    b1, b2 = np.arccos(2. * bounds / G.lmax - 1.)\n    factor = 4./G.lmax * G.L - 2.*sparse.eye(G.N)\n\n    T_old = signal\n    T_cur = factor.dot(signal) / 2.\n    r = (b1 - b2)/np.pi * signal + 2./np.pi * (np.sin(b1) - np.sin(b2)) * T_cur\n\n    for k in range(2, m):\n        T_new = factor.dot(T_cur) - T_old\n        r += 2./(k*np.pi) * (np.sin(k*b1) - np.sin(k*b2)) * T_new\n        T_old = T_cur\n        T_cur = T_new\n\n    return r", "response": "r Fast filtering using Chebyshev polynomial for a perfect rectangle filter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lanczos_op(f, s, order=30):\n    G = f.G\n    Nf = len(f.g)\n\n    # To have the right shape for the output array depending on the signal dim\n    try:\n        Nv = np.shape(s)[1]\n        is2d = True\n        c = np.zeros((G.N*Nf, Nv))\n    except IndexError:\n        Nv = 1\n        is2d = False\n        c = np.zeros((G.N*Nf))\n\n    tmpN = np.arange(G.N, dtype=int)\n    for j in range(Nv):\n        if is2d:\n            V, H, _ = lanczos(G.L.toarray(), order, s[:, j])\n        else:\n            V, H, _ = lanczos(G.L.toarray(), order, s)\n\n        Eh, Uh = np.linalg.eig(H)\n\n        Eh[Eh < 0] = 0\n        fe = f.evaluate(Eh)\n        V = np.dot(V, Uh)\n\n        for i in range(Nf):\n            if is2d:\n                c[tmpN + i*G.N, j] = np.dot(V, fe[:][i] * np.dot(V.T, s[:, j]))\n            else:\n                c[tmpN + i*G.N] = np.dot(V, fe[:][i] * np.dot(V.T, s))\n\n    return c", "response": "r Perform the lanczos approximation of the signal s."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpolate(G, f_subsampled, keep_inds, order=100, reg_eps=0.005, **kwargs):\n    L_reg = G.L + reg_eps * sparse.eye(G.N)\n    K_reg = getattr(G.mr, 'K_reg', kron_reduction(L_reg, keep_inds))\n    green_kernel = getattr(G.mr, 'green_kernel',\n                           filters.Filter(G, lambda x: 1. / (reg_eps + x)))\n\n    alpha = K_reg.dot(f_subsampled)\n\n    try:\n        Nv = np.shape(f_subsampled)[1]\n        f_interpolated = np.zeros((G.N, Nv))\n    except IndexError:\n        f_interpolated = np.zeros((G.N))\n\n    f_interpolated[keep_inds] = alpha\n\n    return _analysis(green_kernel, f_interpolated, order=order, **kwargs)", "response": "r Interpolate a graph signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pyramid_synthesis(Gs, cap, pe, order=30, **kwargs):\n    least_squares = bool(kwargs.pop('least_squares', False))\n    def_ul = Gs[0].N > 3000 or Gs[0]._e is None or Gs[0]._U is None\n    use_landweber = bool(kwargs.pop('use_landweber', def_ul))\n    reg_eps = float(kwargs.get('reg_eps', 0.005))\n\n    if least_squares and 'h_filters' not in kwargs:\n        ValueError('h-filters not provided.')\n\n    levels = len(Gs) - 1\n    if len(pe) != levels:\n        ValueError('Gs and pe have different shapes.')\n\n    ca = [cap]\n\n    # Reconstruct each level\n    for i in range(levels):\n\n        if not least_squares:\n            s_pred = interpolate(Gs[levels - i - 1], ca[i], Gs[levels - i].mr['idx'],\n                                 order=order, reg_eps=reg_eps, **kwargs)\n            ca.append(s_pred + pe[levels - i - 1])\n\n        else:\n            ca.append(_pyramid_single_interpolation(Gs[levels - i - 1], ca[i],\n                      pe[levels - i - 1], h_filters[levels - i - 1],\n                      use_landweber=use_landweber, **kwargs))\n\n    ca.reverse()\n    reconstruction = ca[0]\n\n    return reconstruction, ca", "response": "r Synthesize a signal from its pyramid coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pyramid_single_interpolation(G, ca, pe, keep_inds, h_filter, **kwargs):\n    nb_ind = keep_inds.shape\n    N = G.N\n    reg_eps = float(kwargs.pop('reg_eps', 0.005))\n    use_landweber = bool(kwargs.pop('use_landweber', False))\n    landweber_its = int(kwargs.pop('landweber_its', 50))\n    landweber_tau = float(kwargs.pop('landweber_tau', 1.))\n\n    # index matrix (nb_ind x N) of keep_inds, S_i,j = 1 iff keep_inds[i] = j\n    S = sparse.csr_matrix(([1] * nb_ind, (range(nb_ind), keep_inds)), shape=(nb_ind, N))\n\n    if use_landweber:\n        x = np.zeros(N)\n        z = np.concatenate((ca, pe), axis=0)\n        green_kernel = filters.Filter(G, lambda x: 1./(x+reg_eps))\n        PhiVlt = _analysis(green_kernel, S.T, **kwargs).T\n        filt = filters.Filter(G, h_filter, **kwargs)\n\n        for iteration in range(landweber_its):\n            h_filtered_sig = _analysis(filt, x, **kwargs)\n            x_bar = h_filtered_sig[keep_inds]\n            y_bar = x - interpolate(G, x_bar, keep_inds, **kwargs)\n            z_delt = np.concatenate((x_bar, y_bar), axis=0)\n            z_delt = z - z_delt\n            alpha_new = PhiVlt * z_delt[nb_ind:]\n            x_up = sparse.csr_matrix((z_delt, (range(nb_ind), [1] * nb_ind)), shape=(N, 1))\n            reg_L = G.L + reg_esp * sparse.eye(N)\n\n            elim_inds = np.setdiff1d(np.arange(N, dtype=int), keep_inds)\n            L_red = reg_L[np.ix_(keep_inds, keep_inds)]\n            L_in_out = reg_L[np.ix_(keep_inds, elim_inds)]\n            L_out_in = reg_L[np.ix_(elim_inds, keep_inds)]\n            L_comp = reg_L[np.ix_(elim_inds, elim_inds)]\n\n            next_term = L_red * alpha_new - L_in_out * linalg.spsolve(L_comp, L_out_in * alpha_new)\n            next_up = sparse.csr_matrix((next_term, (keep_inds, [1] * nb_ind)), shape=(N, 1))\n            x += landweber_tau * _analysis(filt, x_up - next_up, **kwargs) + z_delt[nb_ind:]\n\n        finer_approx = x\n\n    else:\n        # When the graph is small enough, we can do a full eigendecomposition\n        # and compute the full analysis operator T_a\n        H = G.U * sparse.diags(h_filter(G.e), 0) * G.U.T\n        Phi = G.U * sparse.diags(1./(reg_eps + G.e), 0) * G.U.T\n        Ta = np.concatenate((S * H, sparse.eye(G.N) - Phi[:, keep_inds] * linalg.spsolve(Phi[np.ix_(keep_inds, keep_inds)], S*H)), axis=0)\n        finer_approx = linalg.spsolve(Ta.T * Ta, Ta.T * np.concatenate((ca, pe), axis=0))", "response": "r Synthesize a single level of the graph pyramid transform."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the modulation of the class.", "response": "def evaluate(self, x):\n        \"\"\"TODO: will become _evaluate once polynomial filtering is merged.\"\"\"\n\n        if not hasattr(self, '_coefficients'):\n            # Graph Fourier transform -> modulation -> inverse GFT.\n            c = self.G.igft(self._kernels.evaluate(self.G.e).squeeze())\n            c = np.sqrt(self.G.n_vertices) * self.G.U * c[:, np.newaxis]\n            self._coefficients = self.G.gft(c)\n\n        shape = x.shape\n        x = x.flatten()\n        y = np.full((self.n_features_out, x.size), np.nan)\n        for i in range(len(x)):\n            query = self._coefficients[x[i] == self.G.e]\n            if len(query) != 0:\n                y[:, i] = query[0]\n        return y.reshape((self.n_features_out,) + shape)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, s, method='exact', order=None):\n        if self._modulation_first:\n            return super(Modulation, self).filter(s, method='exact')\n        else:\n            # The dot product with each modulated kernel is equivalent to the\n            # GFT, as for the localization and the IGFT.\n            y = np.empty((self.G.n_vertices, self.G.n_vertices))\n            for i in range(self.G.n_vertices):\n                x = s * self._kernels.localize(i)\n                y[i] = np.sqrt(self.G.n_vertices) * self.G.gft(x)\n            return y", "response": "Filter the modulated kernels and return a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close_all():\n\n    # Windows can be closed by releasing all references to them so they can be\n    # garbage collected. May not be necessary to call close().\n    global _qtg_windows\n    for window in _qtg_windows:\n        window.close()\n    _qtg_windows = []\n\n    global _qtg_widgets\n    for widget in _qtg_widgets:\n        widget.close()\n    _qtg_widgets = []\n\n    global _plt_figures\n    for fig in _plt_figures:\n        _, plt, _ = _import_plt()\n        plt.close(fig)\n    _plt_figures = []", "response": "r Close all opened windows."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show(*args, **kwargs):\n    _, plt, _ = _import_plt()\n    plt.show(*args, **kwargs)", "response": "r Show created figures alias to plt. show."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(*args, **kwargs):\n    _, plt, _ = _import_plt()\n    plt.close(*args, **kwargs)", "response": "r Close last created figure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _plot_filter(filters, n, eigenvalues, sum, title, ax, **kwargs):\n\n    if eigenvalues is None:\n        eigenvalues = (filters.G._e is not None)\n\n    if sum is None:\n        sum = filters.n_filters > 1\n\n    if title is None:\n        title = repr(filters)\n\n    return _plt_plot_filter(filters, n=n, eigenvalues=eigenvalues, sum=sum,\n                            title=title, ax=ax, **kwargs)", "response": "r Plot the spectral response of a filter bank."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _plot_spectrogram(G, node_idx):\n    from pygsp import features\n\n    qtg, _, _ = _import_qtg()\n\n    if not hasattr(G, 'spectr'):\n        features.compute_spectrogram(G)\n\n    M = G.spectr.shape[1]\n    spectr = G.spectr[node_idx, :] if node_idx is not None else G.spectr\n    spectr = np.ravel(spectr)\n    min_spec, max_spec = spectr.min(), spectr.max()\n\n    pos = np.array([0., 0.25, 0.5, 0.75, 1.])\n    color = [[20, 133, 212, 255], [53, 42, 135, 255], [48, 174, 170, 255],\n             [210, 184, 87, 255], [249, 251, 14, 255]]\n    color = np.array(color, dtype=np.ubyte)\n    cmap = qtg.ColorMap(pos, color)\n\n    spectr = (spectr.astype(float) - min_spec) / (max_spec - min_spec)\n\n    w = qtg.GraphicsWindow()\n    w.setWindowTitle(\"Spectrogram of {}\".format(G.__repr__(limit=4)))\n    label = 'frequencies {}:{:.2f}:{:.2f}'.format(0, G.lmax/M, G.lmax)\n    v = w.addPlot(labels={'bottom': 'nodes',\n                          'left': label})\n    v.setAspectLocked()\n\n    spi = qtg.ScatterPlotItem(np.repeat(np.arange(G.N), M),\n                              np.ravel(np.tile(np.arange(M), (1, G.N))),\n                              pxMode=False,\n                              symbol='s',\n                              size=1,\n                              brush=cmap.map(spectr, 'qcolor'))\n    v.addItem(spi)\n\n    global _qtg_windows\n    _qtg_windows.append(w)", "response": "r Plot the graph s spectrogram."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef classification_tikhonov_simplex(G, y, M, tau=0.1, **kwargs):\n\n    functions, solvers = _import_pyunlocbox()\n\n    if tau <= 0:\n        raise ValueError('Tau should be greater than 0.')\n\n    y[M == False] = 0\n    Y = _to_logits(y.astype(np.int))\n    Y[M == False, :] = 0\n\n    def proj_simplex(y):\n        d = y.shape[1]\n        a = np.ones(d)\n        idx = np.argsort(y)\n\n        def evalpL(y, k, idx):\n            return np.sum(y[idx[k:]] - y[idx[k]]) - 1\n\n        def bisectsearch(idx, y):\n            idxL, idxH = 0, d-1\n            L = evalpL(y, idxL, idx)\n            H = evalpL(y, idxH, idx)\n\n            if L < 0:\n                return idxL\n\n            while (idxH-idxL) > 1:\n                iMid = int((idxL + idxH) / 2)\n                M = evalpL(y, iMid, idx)\n\n                if M > 0:\n                    idxL, L = iMid, M\n                else:\n                    idxH, H = iMid, M\n\n            return idxH\n\n        def proj(idx, y):\n            k = bisectsearch(idx, y)\n            lam = (np.sum(y[idx[k:]]) - 1) / (d - k)\n            return np.maximum(0, y - lam)\n\n        x = np.empty_like(y)\n        for i in range(len(y)):\n            x[i] = proj(idx[i], y[i])\n        # x = np.stack(map(proj, idx, y))\n\n        return x\n\n    def smooth_eval(x):\n        xTLx = np.sum(x * (G.L.dot(x)))\n        e = M * ((M * x.T) - Y.T)\n        l2 = np.sum(e * e)\n        return tau * xTLx + l2\n\n    def smooth_grad(x):\n        return 2 * ((M * (M * x.T - Y.T)).T + tau * G.L * x)\n\n    f1 = functions.func()\n    f1._eval = smooth_eval\n    f1._grad = smooth_grad\n\n    f2 = functions.func()\n    f2._eval = lambda x: 0  # Indicator functions evaluate to zero.\n    f2._prox = lambda x, step: proj_simplex(x)\n\n    step = 0.5 / (1 + tau * G.lmax)\n    solver = solvers.forward_backward(step=step)\n    ret = solvers.solve([f1, f2], Y.copy(), solver, **kwargs)\n    return ret['sol']", "response": "r Solve a classification problem on graph via Tikhonov minimization with simple constraints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classification_tikhonov(G, y, M, tau=0):\n    y[M == False] = 0\n    Y = _to_logits(y.astype(np.int))\n    return regression_tikhonov(G, Y, M, tau)", "response": "r Solve a classification problem on graph via Tikhonov minimization."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef regression_tikhonov(G, y, M, tau=0):\n\n    if tau > 0:\n\n        y[M == False] = 0\n\n        if sparse.issparse(G.L):\n\n            def Op(x):\n                return (M * x.T).T + tau * (G.L.dot(x))\n\n            LinearOp = sparse.linalg.LinearOperator([G.N, G.N], Op)\n\n            if y.ndim > 1:\n                sol = np.empty(shape=y.shape)\n                res = np.empty(shape=y.shape[1])\n                for i in range(y.shape[1]):\n                    sol[:, i], res[i] = sparse.linalg.cg(\n                        LinearOp, y[:, i])\n            else:\n                sol, res = sparse.linalg.cg(LinearOp, y)\n\n            # TODO: do something with the residual...\n            return sol\n\n        else:\n\n            # Creating this matrix may be problematic in term of memory.\n            # Consider using an operator instead...\n            if type(G.L).__module__ == np.__name__:\n                LinearOp = np.diag(M*1) + tau * G.L\n            return np.linalg.solve(LinearOp, M * y)\n\n    else:\n\n        if np.prod(M.shape) != G.n_vertices:\n            raise ValueError(\"M should be of size [G.n_vertices,]\")\n\n        indl = M\n        indu = (M == False)\n\n        Luu = G.L[indu, :][:, indu]\n        Wul = - G.L[indu, :][:, indl]\n\n        if sparse.issparse(G.L):\n            sol_part = sparse.linalg.spsolve(Luu, Wul.dot(y[indl]))\n        else:\n            sol_part = np.linalg.solve(Luu, np.matmul(Wul, y[indl]))\n\n        sol = y.copy()\n        sol[indu] = sol_part\n\n        return sol", "response": "r Solve a regression problem on graph via Tikhonov minimization."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_signal(self, signal, name):\n        signal = self._check_signal(signal)\n        self.signals[name] = signal", "response": "r Attach a signal to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the graph is directed.", "response": "def is_directed(self):\n        r\"\"\"Check if the graph has directed edges (cached).\n\n        In this framework, we consider that a graph is directed if and\n        only if its weight matrix is not symmetric.\n\n        Returns\n        -------\n        directed : bool\n            True if the graph is directed, False otherwise.\n\n        Examples\n        --------\n\n        Directed graph:\n\n        >>> graph = graphs.Graph([\n        ...     [0, 3, 0],\n        ...     [3, 0, 4],\n        ...     [0, 0, 0],\n        ... ])\n        >>> graph.is_directed()\n        True\n\n        Undirected graph:\n\n        >>> graph = graphs.Graph([\n        ...     [0, 3, 0],\n        ...     [3, 0, 4],\n        ...     [0, 4, 0],\n        ... ])\n        >>> graph.is_directed()\n        False\n\n        \"\"\"\n        if self._directed is None:\n            self._directed = (self.W != self.W.T).nnz != 0\n        return self._directed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_laplacian(self, lap_type='combinatorial'):\n\n        if lap_type != self.lap_type:\n            # Those attributes are invalidated when the Laplacian is changed.\n            # Alternative: don't allow the user to change the Laplacian.\n            self._lmax = None\n            self._U = None\n            self._e = None\n            self._coherence = None\n            self._D = None\n\n        self.lap_type = lap_type\n\n        if not self.is_directed():\n            W = self.W\n        else:\n            W = utils.symmetrize(self.W, method='average')\n\n        if lap_type == 'combinatorial':\n            D = sparse.diags(self.dw)\n            self.L = D - W\n        elif lap_type == 'normalized':\n            d = np.zeros(self.n_vertices)\n            disconnected = (self.dw == 0)\n            np.power(self.dw, -0.5, where=~disconnected, out=d)\n            D = sparse.diags(d)\n            self.L = sparse.identity(self.n_vertices) - D * W * D\n            self.L[disconnected, disconnected] = 0\n            self.L.eliminate_zeros()\n        else:\n            raise ValueError('Unknown Laplacian type {}'.format(lap_type))", "response": "r Compute a Laplacian of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dirichlet_energy(self, x):\n        x = self._check_signal(x)\n        return x.T.dot(self.L.dot(x))", "response": "r Compute the Dirichlet energy of a signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef d(self):\n        if self._d is None:\n            if not self.is_directed():\n                # Shortcut for undirected graphs.\n                self._d = self.W.getnnz(axis=1)\n                # axis=1 faster for CSR (https://stackoverflow.com/a/16391764)\n            else:\n                degree_in = self.W.getnnz(axis=0)\n                degree_out = self.W.getnnz(axis=1)\n                self._d = (degree_in + degree_out) / 2\n        return self._d", "response": "r Returns the degree of the current entry in the undirected graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lmax(self):\n        if self._lmax is None:\n            self.logger.warning('The largest eigenvalue G.lmax is not '\n                                'available, we need to estimate it. '\n                                'Explicitly call G.estimate_lmax() or '\n                                'G.compute_fourier_basis() '\n                                'once beforehand to suppress the warning.')\n            self.estimate_lmax()\n        return self._lmax", "response": "r Returns the maximum eigenvalue of the graph Laplacian."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef estimate_lmax(self, method='lanczos'):\n        if method == self._lmax_method:\n            return\n        self._lmax_method = method\n\n        if method == 'lanczos':\n            try:\n                # We need to cast the matrix L to a supported type.\n                # TODO: not good for memory. Cast earlier?\n                lmax = sparse.linalg.eigsh(self.L.asfptype(), k=1, tol=5e-3,\n                                           ncv=min(self.N, 10),\n                                           return_eigenvectors=False)\n                lmax = lmax[0]\n                assert lmax <= self._get_upper_bound() + 1e-12\n                lmax *= 1.01  # Increase by 1% to be robust to errors.\n                self._lmax = lmax\n            except sparse.linalg.ArpackNoConvergence:\n                raise ValueError('The Lanczos method did not converge. '\n                                 'Try to use bounds.')\n\n        elif method == 'bounds':\n            self._lmax = self._get_upper_bound()\n\n        else:\n            raise ValueError('Unknown method {}'.format(method))", "response": "r Estimates the Laplacian s largest eigenvalue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_edge_list(self):\n\n        if self.is_directed():\n            W = self.W.tocoo()\n        else:\n            W = sparse.triu(self.W, format='coo')\n\n        sources = W.row\n        targets = W.col\n        weights = W.data\n\n        assert self.n_edges == sources.size == targets.size == weights.size\n        return sources, targets, weights", "response": "Return an edge list for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_spectrogram(self, node_idx=None):\n        from pygsp.plotting import _plot_spectrogram\n        _plot_spectrogram(self, node_idx=node_idx)", "response": "Plot the current spectrogram for this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_regular(self):\n        warn = False\n        msg = 'The given matrix'\n\n        # check symmetry\n        if np.abs(self.A - self.A.T).sum() > 0:\n            warn = True\n            msg = '{} is not symmetric,'.format(msg)\n\n        # check parallel edged\n        if self.A.max(axis=None) > 1:\n            warn = True\n            msg = '{} has parallel edges,'.format(msg)\n\n        # check that d is d-regular\n        if np.min(self.d) != np.max(self.d):\n            warn = True\n            msg = '{} is not d-regular,'.format(msg)\n\n        # check that g doesn't contain any self-loop\n        if self.A.diagonal().any():\n            warn = True\n            msg = '{} has self loop.'.format(msg)\n\n        if warn:\n            self.logger.warning('{}.'.format(msg[:-1]))", "response": "r Check that the given matrix is a regular one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _break_signals(self):\n        for name in list(self.signals.keys()):\n            if self.signals[name].ndim == 2:\n                for i, signal_1d in enumerate(self.signals[name].T):\n                    self.signals[name + '_' + str(i)] = signal_1d\n                del self.signals[name]", "response": "Break N - dimensional signals into N 1D signals."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _join_signals(self):\n        joined = dict()\n        for name in self.signals:\n            name_base = name.rsplit('_', 1)[0]\n            names = joined.get(name_base, list())\n            names.append(name)\n            joined[name_base] = names\n        for name_base, names in joined.items():\n            if len(names) > 1:\n                names = sorted(names)  # ensure dim ordering (_0, _1, etc.)\n                signal_nd = np.stack([self.signals[n] for n in names], axis=1)\n                self.signals[name_base] = signal_nd\n                for name in names:\n                    del self.signals[name]", "response": "r Join N 1D signals into one N - dimensional signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports the graph to NetworkX.", "response": "def to_networkx(self):\n        r\"\"\"Export the graph to NetworkX.\n\n        Edge weights are stored as an edge attribute,\n        under the name \"weight\".\n\n        Signals are stored as node attributes,\n        under their name in the :attr:`signals` dictionary.\n        `N`-dimensional signals are broken into `N` 1-dimensional signals.\n        They will eventually be joined back together on import.\n\n        Returns\n        -------\n        graph : :class:`networkx.Graph`\n            A NetworkX graph object.\n\n        See Also\n        --------\n        to_graphtool : export to graph-tool\n        save : save to a file\n\n        Examples\n        --------\n        >>> import networkx as nx\n        >>> from matplotlib import pyplot as plt\n        >>> graph = graphs.Path(4, directed=True)\n        >>> graph.set_signal(np.full(4, 2.3), 'signal')\n        >>> graph = graph.to_networkx()\n        >>> print(nx.info(graph))\n        Name: Path\n        Type: DiGraph\n        Number of nodes: 4\n        Number of edges: 3\n        Average in degree:   0.7500\n        Average out degree:   0.7500\n        >>> nx.is_directed(graph)\n        True\n        >>> graph.nodes()\n        NodeView((0, 1, 2, 3))\n        >>> graph.edges()\n        OutEdgeView([(0, 1), (1, 2), (2, 3)])\n        >>> graph.nodes()[2]\n        {'signal': 2.3}\n        >>> graph.edges()[(0, 1)]\n        {'weight': 1.0}\n        >>> # nx.draw(graph, with_labels=True)\n\n        Another common goal is to use NetworkX to compute some properties to be\n        be imported back in the PyGSP as signals.\n\n        >>> import networkx as nx\n        >>> from matplotlib import pyplot as plt\n        >>> graph = graphs.Sensor(100, seed=42)\n        >>> graph.set_signal(graph.coords, 'coords')\n        >>> graph = graph.to_networkx()\n        >>> betweenness = nx.betweenness_centrality(graph, weight='weight')\n        >>> nx.set_node_attributes(graph, betweenness, 'betweenness')\n        >>> graph = graphs.Graph.from_networkx(graph)\n        >>> graph.compute_fourier_basis()\n        >>> graph.set_coordinates(graph.signals['coords'])\n        >>> fig, axes = plt.subplots(1, 2)\n        >>> _ = graph.plot(graph.signals['betweenness'], ax=axes[0])\n        >>> _ = axes[1].plot(graph.e, graph.gft(graph.signals['betweenness']))\n\n        \"\"\"\n        nx = _import_networkx()\n\n        def convert(number):\n            # NetworkX accepts arbitrary python objects as attributes, but:\n            # * the GEXF writer does not accept any NumPy types (on signals),\n            # * the GraphML writer does not accept NumPy ints.\n            if issubclass(number.dtype.type, (np.integer, np.bool_)):\n                return int(number)\n            else:\n                return float(number)\n\n        def edges():\n            for source, target, weight in zip(*self.get_edge_list()):\n                yield int(source), int(target), {'weight': convert(weight)}\n\n        def nodes():\n            for vertex in range(self.n_vertices):\n                signals = {name: convert(signal[vertex])\n                           for name, signal in self.signals.items()}\n                yield vertex, signals\n\n        self._break_signals()\n        graph = nx.DiGraph() if self.is_directed() else nx.Graph()\n        graph.add_nodes_from(nodes())\n        graph.add_edges_from(edges())\n        graph.name = self.__class__.__name__\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports the graph to graph - tool.", "response": "def to_graphtool(self):\n        r\"\"\"Export the graph to graph-tool.\n\n        Edge weights are stored as an edge property map,\n        under the name \"weight\".\n\n        Signals are stored as vertex property maps,\n        under their name in the :attr:`signals` dictionary.\n        `N`-dimensional signals are broken into `N` 1-dimensional signals.\n        They will eventually be joined back together on import.\n\n        Returns\n        -------\n        graph : :class:`graph_tool.Graph`\n            A graph-tool graph object.\n\n        See Also\n        --------\n        to_networkx : export to NetworkX\n        save : save to a file\n\n        Examples\n        --------\n        >>> import graph_tool as gt\n        >>> import graph_tool.draw\n        >>> from matplotlib import pyplot as plt\n        >>> graph = graphs.Path(4, directed=True)\n        >>> graph.set_signal(np.full(4, 2.3), 'signal')\n        >>> graph = graph.to_graphtool()\n        >>> graph.is_directed()\n        True\n        >>> graph.vertex_properties['signal'][2]\n        2.3\n        >>> graph.edge_properties['weight'][(0, 1)]\n        1.0\n        >>> # gt.draw.graph_draw(graph, vertex_text=graph.vertex_index)\n\n        Another common goal is to use graph-tool to compute some properties to\n        be imported back in the PyGSP as signals.\n\n        >>> import graph_tool as gt\n        >>> import graph_tool.centrality\n        >>> from matplotlib import pyplot as plt\n        >>> graph = graphs.Sensor(100, seed=42)\n        >>> graph.set_signal(graph.coords, 'coords')\n        >>> graph = graph.to_graphtool()\n        >>> vprop, eprop = gt.centrality.betweenness(\n        ...     graph, weight=graph.edge_properties['weight'])\n        >>> graph.vertex_properties['betweenness'] = vprop\n        >>> graph = graphs.Graph.from_graphtool(graph)\n        >>> graph.compute_fourier_basis()\n        >>> graph.set_coordinates(graph.signals['coords'])\n        >>> fig, axes = plt.subplots(1, 2)\n        >>> _ = graph.plot(graph.signals['betweenness'], ax=axes[0])\n        >>> _ = axes[1].plot(graph.e, graph.gft(graph.signals['betweenness']))\n\n        \"\"\"\n\n        # See gt.value_types() for the list of accepted types.\n        # See the definition of _type_alias() for a list of aliases.\n        # Mapping from https://docs.scipy.org/doc/numpy/user/basics.types.html.\n        convert = {\n            np.bool_: 'bool',\n            np.int8: 'int8_t',\n            np.int16: 'int16_t',\n            np.int32: 'int32_t',\n            np.int64: 'int64_t',\n            np.short: 'short',\n            np.intc: 'int',\n            np.uintc: 'unsigned int',\n            np.long: 'long',\n            np.longlong: 'long long',\n            np.uint: 'unsigned long',\n            np.single: 'float',\n            np.double: 'double',\n            np.longdouble: 'long double',\n        }\n\n        gt = _import_graphtool()\n        graph = gt.Graph(directed=self.is_directed())\n\n        sources, targets, weights = self.get_edge_list()\n        graph.add_edge_list(np.asarray((sources, targets)).T)\n        try:\n            dtype = convert[weights.dtype.type]\n        except KeyError:\n            raise TypeError(\"Type {} of the edge weights is not supported.\"\n                            .format(weights.dtype))\n        prop = graph.new_edge_property(dtype)\n        prop.get_array()[:] = weights\n        graph.edge_properties['weight'] = prop\n\n        self._break_signals()\n        for name, signal in self.signals.items():\n            try:\n                dtype = convert[signal.dtype.type]\n            except KeyError:\n                raise TypeError(\"Type {} of signal {} is not supported.\"\n                                .format(signal.dtype, name))\n            prop = graph.new_vertex_property(dtype)\n            prop.get_array()[:] = signal\n            graph.vertex_properties[name] = prop\n\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_networkx(cls, graph, weight='weight'):\n        nx = _import_networkx()\n        from .graph import Graph\n\n        adjacency = nx.to_scipy_sparse_matrix(graph, weight=weight)\n        graph_pg = Graph(adjacency)\n\n        for i, node in enumerate(graph.nodes()):\n            for name in graph.nodes[node].keys():\n                try:\n                    signal = graph_pg.signals[name]\n                except KeyError:\n                    signal = np.full(graph_pg.n_vertices, np.nan)\n                    graph_pg.set_signal(signal, name)\n                try:\n                    signal[i] = graph.nodes[node][name]\n                except KeyError:\n                    pass  # attribute not set for node\n\n        graph_pg._join_signals()\n        return graph_pg", "response": "r Import a networkx graph into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(cls, path, fmt=None, backend=None):\n\n        if fmt is None:\n            fmt = os.path.splitext(path)[1][1:]\n        if fmt not in ['graphml', 'gml', 'gexf']:\n            raise ValueError('Unsupported format {}.'.format(fmt))\n\n        def load_networkx(path, fmt):\n            nx = _import_networkx()\n            load = getattr(nx, 'read_' + fmt)\n            graph = load(path)\n            return cls.from_networkx(graph)\n\n        def load_graphtool(path, fmt):\n            gt = _import_graphtool()\n            graph = gt.load_graph(path, fmt=fmt)\n            return cls.from_graphtool(graph)\n\n        if backend == 'networkx':\n            return load_networkx(path, fmt)\n        elif backend == 'graph-tool':\n            return load_graphtool(path, fmt)\n        elif backend is None:\n            try:\n                return load_networkx(path, fmt)\n            except ImportError:\n                try:\n                    return load_graphtool(path, fmt)\n                except ImportError:\n                    raise ImportError('Cannot import networkx nor graph-tool.')\n        else:\n            raise ValueError('Unknown backend {}.'.format(backend))", "response": "r Load a graph from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, path, fmt=None, backend=None):\n\n        if fmt is None:\n            fmt = os.path.splitext(path)[1][1:]\n        if fmt not in ['graphml', 'gml', 'gexf']:\n            raise ValueError('Unsupported format {}.'.format(fmt))\n\n        def save_networkx(graph, path, fmt):\n            nx = _import_networkx()\n            graph = graph.to_networkx()\n            save = getattr(nx, 'write_' + fmt)\n            save(graph, path)\n\n        def save_graphtool(graph, path, fmt):\n            graph = graph.to_graphtool()\n            graph.save(path, fmt=fmt)\n\n        if backend == 'networkx':\n            save_networkx(self, path, fmt)\n        elif backend == 'graph-tool':\n            save_graphtool(self, path, fmt)\n        elif backend is None:\n            try:\n                save_networkx(self, path, fmt)\n            except ImportError:\n                try:\n                    save_graphtool(self, path, fmt)\n                except ImportError:\n                    raise ImportError('Cannot import networkx nor graph-tool.')\n        else:\n            raise ValueError('Unknown backend {}.'.format(backend))", "response": "Save the graph to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadmat(path):\n    data = pkgutil.get_data('pygsp', 'data/' + path + '.mat')\n    data = io.BytesIO(data)\n    return scipy.io.loadmat(data)", "response": "r Load a matlab data file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef distanz(x, y=None):\n    try:\n        x.shape[1]\n    except IndexError:\n        x = x.reshape(1, x.shape[0])\n\n    if y is None:\n        y = x\n\n    else:\n        try:\n            y.shape[1]\n        except IndexError:\n            y = y.reshape(1, y.shape[0])\n\n    rx, cx = x.shape\n    ry, cy = y.shape\n\n    # Size verification\n    if rx != ry:\n        raise ValueError(\"The sizes of x and y do not fit\")\n\n    xx = (x * x).sum(axis=0)\n    yy = (y * y).sum(axis=0)\n    xy = np.dot(x.T, y)\n\n    d = abs(np.kron(np.ones((cy, 1)), xx).T +\n            np.kron(np.ones((cx, 1)), yy) - 2 * xy)\n\n    return np.sqrt(d)", "response": "r Returns the distance between two colon vectors."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resistance_distance(G):\n\n    if sparse.issparse(G):\n        L = G.tocsc()\n\n    else:\n        if G.lap_type != 'combinatorial':\n            raise ValueError('Need a combinatorial Laplacian.')\n        L = G.L.tocsc()\n\n    try:\n        pseudo = sparse.linalg.inv(L)\n    except RuntimeError:\n        pseudo = sparse.lil_matrix(np.linalg.pinv(L.toarray()))\n\n    N = np.shape(L)[0]\n    d = sparse.csc_matrix(pseudo.diagonal())\n    rd = sparse.kron(d, sparse.csc_matrix(np.ones((N, 1)))).T \\\n        + sparse.kron(d, sparse.csc_matrix(np.ones((N, 1)))) \\\n        - pseudo - pseudo.T\n\n    return rd", "response": "r Compute the resistance distance of a cite graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rescale_center(x):\n    N = x.shape[1]\n    y = x - np.kron(np.ones((1, N)), np.mean(x, axis=1)[:, np.newaxis])\n    c = np.amax(y)\n    r = y / c\n\n    return r", "response": "r Rescales and center data e. g. embedding coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_log_scales(lmin, lmax, Nscales, t1=1, t2=2):\n    scale_min = t1 / lmax\n    scale_max = t2 / lmin\n    return np.exp(np.linspace(np.log(scale_max), np.log(scale_min), Nscales))", "response": "r Compute logarithm scales for wavelets."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport modules in package.", "response": "def import_modules(names, src, dst):\n    \"\"\"Import modules in package.\"\"\"\n    for name in names:\n        module = importlib.import_module(src + '.' + name)\n        setattr(sys.modules[dst], name, module)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_classes(names, src, dst):\n    for name in names:\n        module = importlib.import_module('pygsp.' + src + '.' + name.lower())\n        setattr(sys.modules['pygsp.' + dst], name, getattr(module, name))", "response": "Import classes in package from their implementation modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting functions in package from their implementation modules.", "response": "def import_functions(names, src, dst):\n    \"\"\"Import functions in package from their implementation modules.\"\"\"\n    for name in names:\n        module = importlib.import_module('pygsp.' + src)\n        setattr(sys.modules['pygsp.' + dst], name, getattr(module, name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the API result from the API.", "response": "def _handle_api_result(result: Optional[Dict[str, Any]]) -> Any:\n    \"\"\"\n    Retrieve 'data' field from the API result object.\n\n    :param result: API result that received from HTTP API\n    :return: the 'data' field in result object\n    :raise ActionFailed: the 'status' field is 'failed'\n    \"\"\"\n    if isinstance(result, dict):\n        if result.get('status') == 'failed':\n            raise ActionFailed(retcode=result.get('retcode'))\n        return result.get('data')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reduce(self) -> None:\n        idx = 0\n        while idx < len(self):\n            if idx > 0 and \\\n                    self[idx - 1].type == 'text' and self[idx].type == 'text':\n                self[idx - 1].data['text'] += self[idx].data['text']\n                del self[idx]\n            else:\n                idx += 1", "response": "Remove redundant segments.\n\n        Since this class is implemented based on list,\n        this method may require O(n) time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract text segments from the message joined by single space.", "response": "def extract_plain_text(self, reduce: bool = False) -> str:\n        \"\"\"\n        Extract text segments from the message, joined by single space.\n\n        :param reduce: reduce the message before extracting\n        :return: the joined string\n        \"\"\"\n        if reduce:\n            self.reduce()\n\n        result = ''\n        for seg in self:\n            if seg.type == 'text':\n                result += ' ' + seg.data['text']\n        if result:\n            result = result[1:]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to queue HTML e - mails", "response": "def send_html_mail(subject, message, message_html, from_email, recipient_list,\n                   priority=None, fail_silently=False, auth_user=None,\n                   auth_password=None, headers={}):\n    \"\"\"\n    Function to queue HTML e-mails\n    \"\"\"\n    from django.utils.encoding import force_text\n    from django.core.mail import EmailMultiAlternatives\n    from mailer.models import make_message\n\n    priority = get_priority(priority)\n\n    # need to do this in case subject used lazy version of ugettext\n    subject = force_text(subject)\n    message = force_text(message)\n\n    msg = make_message(subject=subject,\n                       body=message,\n                       from_email=from_email,\n                       to=recipient_list,\n                       priority=priority)\n    email = msg.email\n    email = EmailMultiAlternatives(\n        email.subject,\n        email.body,\n        email.from_email,\n        email.to,\n        headers=headers\n    )\n    email.attach_alternative(message_html, \"text/html\")\n    msg.email = email\n    msg.save()\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_message(subject=\"\", body=\"\", from_email=None, to=None, bcc=None,\n                 attachments=None, headers=None, priority=None):\n    \"\"\"\n    Creates a simple message for the email parameters supplied.\n    The 'to' and 'bcc' lists are filtered using DontSendEntry.\n\n    If needed, the 'email' attribute can be set to any instance of EmailMessage\n    if e-mails with attachments etc. need to be supported.\n\n    Call 'save()' on the result when it is ready to be sent, and not before.\n    \"\"\"\n    to = filter_recipient_list(to)\n    bcc = filter_recipient_list(bcc)\n    core_msg = EmailMessage(\n        subject=subject,\n        body=body,\n        from_email=from_email,\n        to=to,\n        bcc=bcc,\n        attachments=attachments,\n        headers=headers\n    )\n    db_msg = Message(priority=priority)\n    db_msg.email = core_msg\n    return db_msg", "response": "Creates a new email message for the email parameters supplied."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_address(self, address):\n        queryset = self.filter(to_address__iexact=address)\n        return queryset.exists()", "response": "Returns True if the given address is on the don t send list False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log(self, message, result_code, log_message=\"\"):\n        return self.create(\n            message_data=message.message_data,\n            message_id=get_message_id(message.email),\n            when_added=message.when_added,\n            priority=message.priority,\n            # @@@ other fields from Message\n            result=result_code,\n            log_message=log_message,\n        )", "response": "create a log entry for an attempt to send the given message and record the given result and a log message"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield the messages in the queue in the order they should be sent.", "response": "def prioritize():\n    \"\"\"\n    Yield the messages in the queue in the order they should be sent.\n    \"\"\"\n\n    while True:\n        hp_qs = Message.objects.high_priority().using('default')\n        mp_qs = Message.objects.medium_priority().using('default')\n        lp_qs = Message.objects.low_priority().using('default')\n        while hp_qs.count() or mp_qs.count():\n            while hp_qs.count():\n                for message in hp_qs.order_by(\"when_added\"):\n                    yield message\n            while hp_qs.count() == 0 and mp_qs.count():\n                yield mp_qs.order_by(\"when_added\")[0]\n        while hp_qs.count() == 0 and mp_qs.count() == 0 and lp_qs.count():\n            yield lp_qs.order_by(\"when_added\")[0]\n        if Message.objects.non_deferred().using('default').count() == 0:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_all():\n    # The actual backend to use for sending, defaulting to the Django default.\n    # To make testing easier this is not stored at module level.\n    EMAIL_BACKEND = getattr(\n        settings,\n        \"MAILER_EMAIL_BACKEND\",\n        \"django.core.mail.backends.smtp.EmailBackend\"\n    )\n\n    acquired, lock = acquire_lock()\n    if not acquired:\n        return\n\n    start_time = time.time()\n\n    deferred = 0\n    sent = 0\n\n    try:\n        connection = None\n        for message in prioritize():\n            try:\n                if connection is None:\n                    connection = get_connection(backend=EMAIL_BACKEND)\n                logging.info(\"sending message '{0}' to {1}\".format(\n                    message.subject,\n                    \", \".join(message.to_addresses))\n                )\n                email = message.email\n                if email is not None:\n                    email.connection = connection\n                    if not hasattr(email, 'reply_to'):\n                        # Compatability fix for EmailMessage objects\n                        # pickled when running < Django 1.8 and then\n                        # unpickled under Django 1.8\n                        email.reply_to = []\n                    ensure_message_id(email)\n                    email.send()\n\n                    # connection can't be stored in the MessageLog\n                    email.connection = None\n                    message.email = email  # For the sake of MessageLog\n                    MessageLog.objects.log(message, RESULT_SUCCESS)\n                    sent += 1\n                else:\n                    logging.warning(\"message discarded due to failure in converting from DB. Added on '%s' with priority '%s'\" % (message.when_added, message.priority))  # noqa\n                message.delete()\n\n            except (socket_error, smtplib.SMTPSenderRefused,\n                    smtplib.SMTPRecipientsRefused,\n                    smtplib.SMTPDataError,\n                    smtplib.SMTPAuthenticationError) as err:\n                message.defer()\n                logging.info(\"message deferred due to failure: %s\" % err)\n                MessageLog.objects.log(message, RESULT_FAILURE, log_message=str(err))\n                deferred += 1\n                # Get new connection, it case the connection itself has an error.\n                connection = None\n\n            # Check if we reached the limits for the current run\n            if _limits_reached(sent, deferred):\n                break\n\n            _throttle_emails()\n\n    finally:\n        release_lock(lock)\n\n    logging.info(\"\")\n    logging.info(\"%s sent; %s deferred;\" % (sent, deferred))\n    logging.info(\"done in %.2f seconds\" % (time.time() - start_time))", "response": "Sends all eligible messages in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nloop indefinitely checking the queue for messages and sending them.", "response": "def send_loop():\n    \"\"\"\n    Loop indefinitely, checking queue at intervals of EMPTY_QUEUE_SLEEP and\n    sending messages if any are on queue.\n    \"\"\"\n\n    while True:\n        while not Message.objects.all():\n            logging.debug(\"sleeping for %s seconds before checking queue again\" % EMPTY_QUEUE_SLEEP)\n            time.sleep(EMPTY_QUEUE_SLEEP)\n        send_all()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_name(name):\n    if isinstance(name, str):\n        components = name.split('.')\n        mod = __import__('.'.join(components[0:-1]), globals(), locals(), [components[-1]] )\n        return getattr(mod, components[-1])\n    else:\n        return name", "response": "import module given by str or pass the module if it is not str"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of the status of the current user s account.", "response": "def account_status(request):\n    \"\"\"\n    Set following ``RequestContext`` variables:\n\n     * ``ACCOUNT_EXPIRED = boolean``, account was expired state,\n     * ``ACCOUNT_NOT_ACTIVE = boolean``, set when account is not expired, but it is over quotas so it is\n                                        not active\n     * ``EXPIRE_IN_DAYS = integer``, number of days to account expiration,\n     * ``EXTEND_URL = string``, URL to account extend page.\n     * ``ACTIVATE_URL = string``, URL to account activation needed if  account is not active\n\n    \"\"\"\n\n    if request.user.is_authenticated:\n        try:\n            return {\n                'ACCOUNT_EXPIRED': request.user.userplan.is_expired(),\n                'ACCOUNT_NOT_ACTIVE': (\n                not request.user.userplan.is_active() and not request.user.userplan.is_expired()),\n                'EXPIRE_IN_DAYS': request.user.userplan.days_left(),\n                'EXTEND_URL': reverse('current_plan'),\n                'ACTIVATE_URL': reverse('account_activation'),\n            }\n        except UserPlan.DoesNotExist:\n            pass\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_plan(modeladmin, request, queryset):\n    for plan in queryset:\n        plan_copy = deepcopy(plan)\n        plan_copy.id = None\n        plan_copy.available = False\n        plan_copy.default = False\n        plan_copy.created = None\n        plan_copy.save(force_insert=True)\n\n        for pricing in plan.planpricing_set.all():\n            pricing.id = None\n            pricing.plan = plan_copy\n            pricing.save(force_insert=True)\n\n        for quota in plan.planquota_set.all():\n            quota.id = None\n            quota.plan = plan_copy\n            quota.save(force_insert=True)", "response": "Copy plans preserving quotas and pricings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plan_table(self, plan_list):\n\n        # Retrieve all quotas that are used by any ``Plan`` in ``plan_list``\n        quota_list = Quota.objects.all().filter(planquota__plan__in=plan_list).distinct()\n\n        # Create random access dict that for every ``Plan`` map ``Quota`` -> ``PlanQuota``\n        plan_quotas_dic = {}\n        for plan in plan_list:\n            plan_quotas_dic[plan] = {}\n            for plan_quota in plan.planquota_set.all():\n                plan_quotas_dic[plan][plan_quota.quota] = plan_quota\n\n        # Generate data structure described in method docstring, propagate ``None`` whenever\n        # ``PlanQuota`` is not available for given ``Plan`` and ``Quota``\n        return map(lambda quota: (quota,\n                                  map(lambda plan: plan_quotas_dic[plan].get(quota, None), plan_list)\n\n        ), quota_list)", "response": "This method returns a list of all quotas that are used by given plans and returns a dictionary that maps each plan quota to the corresponding resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recalculate(self, amount, billing_info):\n        order = Order(pk=-1)\n        order.amount = amount\n        order.currency = self.get_currency()\n        country = getattr(billing_info, 'country', None)\n        if not country is None:\n            country = country.code\n        tax_number = getattr(billing_info, 'tax_number', None)\n\n        # Calculating tax can be complex task (e.g. VIES webservice call)\n        # To ensure that tax calculated on order preview will be the same on final order\n        # tax rate is cached for a given billing data (as this value only depends on it)\n        tax_session_key = \"tax_%s_%s\" % (tax_number, country)\n\n        tax = self.request.session.get(tax_session_key)\n        if tax is None:\n            taxation_policy = getattr(settings, 'PLANS_TAXATION_POLICY', None)\n            if not taxation_policy:\n                raise ImproperlyConfigured('PLANS_TAXATION_POLICY is not set')\n            taxation_policy = import_name(taxation_policy)\n            tax = str(taxation_policy.get_tax_rate(tax_number, country))\n            # Because taxation policy could return None which clutters with saving this value\n            # into cache, we use str() representation of this value\n            self.request.session[tax_session_key] = tax\n\n        order.tax = Decimal(tax) if tax != 'None' else None\n\n        return order", "response": "Calculates and returns a pre - filled Order object with the given amount and billing info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_context(self):\n        self.plan_pricing = get_object_or_404(PlanPricing.objects.all().select_related('plan', 'pricing'),\n                                              Q(pk=self.kwargs['pk']) & Q(plan__available=True) & (\n                                                  Q(plan__customized=self.request.user) | Q(\n                                                      plan__customized__isnull=True)))\n\n\n        # User is not allowed to create new order for Plan when he has different Plan\n        # He should use Plan Change View for this kind of action\n        if not self.request.user.userplan.is_expired() and self.request.user.userplan.plan != self.plan_pricing.plan:\n            raise Http404\n\n        self.plan = self.plan_pricing.plan\n        self.pricing = self.plan_pricing.pricing", "response": "Retrieves Plan and Pricing for current order creation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_proforma_invoice(sender, instance, created, **kwargs):\n    if created:\n        Invoice.create(instance, Invoice.INVOICE_TYPES['PROFORMA'])", "response": "Create proforma invoice for every Order if there are defined billing_data creates invoice proforma"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plan_validation(user, plan=None, on_activation=False):\n    if plan is None:\n        # if plan is not given, the default is to use current plan of the user\n        plan = user.userplan.plan\n    quota_dict = plan.get_quota_dict()\n    validators = getattr(settings, 'PLANS_VALIDATORS', {})\n    validators = import_name(validators)\n    errors = {\n        'required_to_activate': [],\n        'other': [],\n    }\n\n    for quota in validators:\n        validator = import_name(validators[quota])\n\n        if on_activation:\n            validator.on_activation(user, quota_dict)\n        else:\n            try:\n                validator(user, quota_dict)\n            except ValidationError as e:\n                if validator.required_to_activate:\n                    errors['required_to_activate'].extend(e.messages)\n                else:\n                    errors['other'].extend(e.messages)\n    return errors", "response": "Validates that the user has permission to perform quotas in a given system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_quota_value(self, user, quota_dict=None):\n        if quota_dict is None:\n            quota_dict = get_user_quota(user)\n\n        return quota_dict.get(self.code, self.default_quota_value)", "response": "Returns the quota value for a given user"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends e - mail using templating system", "response": "def send_template_email(recipients, title_template, body_template, context, language):\n    \"\"\"Sends e-mail using templating system\"\"\"\n\n    send_emails = getattr(settings, 'SEND_PLANS_EMAILS', True)\n    if not send_emails:\n        return\n\n    site_name = getattr(settings, 'SITE_NAME', 'Please define settings.SITE_NAME')\n    domain = getattr(settings, 'SITE_URL', None)\n\n    if domain is None:\n        try:\n            Site = apps.get_model('sites', 'Site')\n            current_site = Site.objects.get_current()\n            site_name = current_site.name\n            domain = current_site.domain\n        except LookupError:\n            pass\n\n    context.update({'site_name': site_name, 'site_domain': domain})\n\n    if language is not None:\n        translation.activate(language)\n\n    mail_title_template = loader.get_template(title_template)\n    mail_body_template = loader.get_template(body_template)\n    title = mail_title_template.render(context)\n    body = mail_body_template.render(context)\n\n    try:\n        email_from = getattr(settings, 'DEFAULT_FROM_EMAIL')\n    except AttributeError:\n        raise ImproperlyConfigured('DEFAULT_FROM_EMAIL setting needed for sending e-mails')\n\n    mail.send_mail(title, body, email_from, recipients)\n\n    if language is not None:\n        translation.deactivate()\n\n    email_logger.info(u\"Email (%s) sent to %s\\nTitle: %s\\n%s\\n\\n\" % (language, recipients, title, body))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user_language(user):\n    return_value = {}\n    user_language.send(sender=user, user=user, return_value=return_value)\n    return return_value.get('language')", "response": "This helper will fire django signal to get User language"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _calculate_day_cost(self, plan, period):\n\n        plan_pricings = plan.planpricing_set.order_by('-pricing__period').select_related('pricing')\n        selected_pricing = None\n        for plan_pricing in plan_pricings:\n            selected_pricing = plan_pricing\n            if plan_pricing.pricing.period <= period:\n                break\n\n        if selected_pricing:\n            return (selected_pricing.price / selected_pricing.pricing.period).quantize(Decimal('1.00'))\n\n        raise ValueError('Plan %s has no pricings.' % plan)", "response": "Calculates the day cost for a given plan and period."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the price of a change in a given period. Returns None if no payment is required.", "response": "def get_change_price(self, plan_old, plan_new, period):\n        \"\"\"\n        Calculates total price of plan change. Returns None if no payment is required.\n        \"\"\"\n        if period is None or period < 1:\n            return None\n\n        plan_old_day_cost = self._calculate_day_cost(plan_old, period)\n        plan_new_day_cost = self._calculate_day_cost(plan_new, period)\n\n        if plan_new_day_cost <= plan_old_day_cost:\n            return self._calculate_final_price(period, None)\n        else:\n            return self._calculate_final_price(period, plan_new_day_cost - plan_old_day_cost)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef comparator(operator):\n    @wraps(operator)\n    def wrapper(self, other):\n        if not isinstance(other, (VersionInfo, dict)):\n            return NotImplemented\n        return operator(self, other)\n    return wrapper", "response": "Wrap a VersionInfo binary op method in a type - check"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride default values for Dirichlet hyperparameters.", "response": "def set_priors(self, alpha, beta):\n\n        \"\"\"\n        Override default values for Dirichlet hyperparameters.\n        alpha: hyperparameter for distribution of topics within documents.\n        beta: hyperparameter for distribution of tokens within topics.\n        \"\"\"\n\n        assert type(alpha) == float and type(beta) == float\n\n        self.alpha = alpha\n        self.beta = beta"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_sampled_topics(self, sampled_topics):\n\n        \"\"\"\n        Allocate sampled topics to the documents rather than estimate them.\n        Automatically generate term-topic and document-topic matrices.\n        \"\"\"\n\n        assert sampled_topics.dtype == np.int and \\\n            len(sampled_topics.shape) <= 2\n\n        if len(sampled_topics.shape) == 1:\n            self.sampled_topics = \\\n                sampled_topics.reshape(1, sampled_topics.shape[0])\n        else:\n            self.sampled_topics = sampled_topics\n\n        self.samples = self.sampled_topics.shape[0]\n\n        self.tt = self.tt_comp(self.sampled_topics)\n        self.dt = self.dt_comp(self.sampled_topics)", "response": "Set the self. sampled_topics attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample(self, burnin, thinning, samples, append=True):\n\n        \"\"\"\n        Estimate topics via Gibbs sampling.\n        burnin: number of iterations to allow chain to burn in before sampling.\n        thinning: thinning interval between samples.\n        samples: number of samples to take.\n        Total number of samples = burnin + thinning * samples\n        If sampled topics already exist and append = True, extend chain from\n        last sample.\n        If append = False, start new chain from the seed.\n        \"\"\"\n\n        if hasattr(self, 'sampled_topics') and append:\n\n            sampled_topics = \\\n                samplers_lda.sampler(self.docid, self.tokens,\n                                     self.sampled_topics[self.samples-1, :],\n                                     self.N, self.V, self.K, self.D,\n                                     self.alpha, self.beta,\n                                     burnin, thinning, samples)\n\n            tt_temp = self.tt_comp(sampled_topics)\n            dt_temp = self.dt_comp(sampled_topics)\n\n            self.sampled_topics = \\\n                np.concatenate((self.sampled_topics, sampled_topics))\n            self.tt = np.concatenate((self.tt, tt_temp), axis=2)\n            self.dt = np.concatenate((self.dt, dt_temp), axis=2)\n\n            self.samples = self.samples + samples\n\n        else:\n\n                self.samples = samples\n\n                seed = np.copy(self.topic_seed)\n\n                self.sampled_topics = \\\n                    samplers_lda.sampler(self.docid, self.tokens, seed,\n                                         self.N, self.V, self.K, self.D,\n                                         self.alpha, self.beta,\n                                         burnin, thinning, self.samples)\n\n                self.tt = self.tt_comp(self.sampled_topics)\n                self.dt = self.dt_comp(self.sampled_topics)", "response": "Samples the topics from the topic seed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes document - topic matrix from sampled_topics.", "response": "def dt_comp(self, sampled_topics):\n\n        \"\"\"\n        Compute document-topic matrix from sampled_topics.\n        \"\"\"\n\n        samples = sampled_topics.shape[0]\n        dt = np.zeros((self.D, self.K, samples))\n\n        for s in range(samples):            \n                dt[:, :, s] = \\\n                    samplers_lda.dt_comp(self.docid, sampled_topics[s, :],\n                                         self.N, self.K, self.D, self.alpha)\n\n        return dt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tt_comp(self, sampled_topics):\n\n        \"\"\"\n        Compute term-topic matrix from sampled_topics.\n        \"\"\"\n\n        samples = sampled_topics.shape[0]\n        tt = np.zeros((self.V, self.K, samples))\n\n        for s in range(samples):            \n            tt[:, :, s] = \\\n                samplers_lda.tt_comp(self.tokens, sampled_topics[s, :],\n                                     self.N, self.V, self.K, self.beta)\n\n        return tt", "response": "Compute term - topic matrix from sampled_topics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef topic_content(self, W, output_file=\"topic_description.csv\"):\n\n        \"\"\"\n        Print top W words in each topic to file.\n        \"\"\"\n\n        topic_top_probs = []\n        topic_top_words = []\n\n        tt = self.tt_avg(False)\n\n        for t in range(self.K):            \n            top_word_indices = list(tt[:, t].argsort()[-W:][::-1])\n            topic_top_probs.append(np.round(np.sort(tt[:, t])[-W:][::-1], 3))\n            topic_top_words.append([list(self.token_key.keys())\n                                   [list(self.token_key.values()).index(i)]\n                                   for i in top_word_indices])            \n\n        with codecs.open(output_file, \"w\", \"utf-8\") as f:\n            for t in range(self.K):                \n                words = ','.join(topic_top_words[t])\n                probs = ','.join([str(i) for i in topic_top_probs[t]])\n                f.write(\"topic\" + str(t) + ',')\n                f.write(\"%s\\n\" % words)\n                f.write(\" \" + ',')\n                f.write(\"%s\\n\" % probs)", "response": "Print top W words in each topic to file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef perplexity(self):\n\n        \"\"\"\n        Compute perplexity for each sample.\n        \"\"\"\n\n        return samplers_lda.perplexity_comp(self.docid, self.tokens,\n                                            self.tt, self.dt, self.N,\n                                            self.K, self.samples)", "response": "Compute the perplexity of each sample."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkeeps subset of samples.", "response": "def samples_keep(self, index):\n\n        \"\"\"\n        Keep subset of samples.  If index is an integer, keep last N=index\n        samples.  If index is a list, keep the samples\n        corresponding to the index values in the list.\n        \"\"\"\n\n        try:\n            if isinstance(index, (int, long)):\n                index = range(self.samples)[-index:]\n        except(NameError):\n            if isinstance(index,int):\n                index = range(self.samples)[-index:]            \n        self.sampled_topics = np.take(self.sampled_topics, index, axis=0)\n        self.tt = np.take(self.tt, index, axis=2)\n        self.dt = np.take(self.dt, index, axis=2)\n\n        self.samples = len(index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tt_avg(self, print_output=True, output_file=\"tt.csv\"):\n\n        \"\"\"\n        Compute average term-topic matrix, and print to file if\n        print_output=True.\n        \"\"\"\n\n        avg = self.tt.mean(axis=2)\n        if print_output:\n            np.savetxt(output_file, avg, delimiter=\",\")\n        return avg", "response": "Compute average term - topic matrix and print to file if print_output is True."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint mapping from tokens to numeric indices.", "response": "def dict_print(self, output_file=\"dict.csv\"):\n\n        \"\"\"\n        Print mapping from tokens to numeric indices.\n        \"\"\"\n\n        with codecs.open(output_file, \"w\", encoding='utf-8') as f:\n                for (v, k) in self.token_key.items():\n                    f.write(\"%s,%d\\n\" % (v, k))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverriding default values for random initial topic assignment to seed instead.", "response": "def set_seed(self, seed):\n\n        \"\"\"\n        Override default values for random initial topic assignment,\n        set to \"seed\" instead.\n        seed is 2-d array (number of samples in LDA model x number\n        of tokens in LDA model)\n        \"\"\"\n\n        assert seed.dtype == np.int and seed.shape == (self.samples, self.N)\n        self.topic_seed = seed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query(self, query_samples):\n\n        \"\"\"\n        Query docs with query_samples number of Gibbs\n        sampling iterations.\n        \"\"\"\n\n        self.sampled_topics = np.zeros((self.samples, self.N),\n                                       dtype=np.int)\n\n        for s in range(self.samples):            \n\n            self.sampled_topics[s, :] = \\\n                samplers_lda.sampler_query(self.docid, self.tokens,\n                                           self.topic_seed,\n                                           np.ascontiguousarray(\n                                               self.tt[:, :, s],\n                                               dtype=np.float),\n                                           self.N, self.K, self.D,\n                                           self.alpha, query_samples)\n\n            print(\"Sample %d queried\" % s)\n\n        self.dt = np.zeros((self.D, self.K, self.samples))\n\n        for s in range(self.samples):            \n            self.dt[:, :, s] = \\\n               samplers_lda.dt_comp(self.docid, self.sampled_topics[s, :],\n                                    self.N, self.K, self.D, self.alpha)", "response": "Query the docs with query_samples number of GibbsResources objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dt_avg(self, print_output=True, output_file=\"dt_query.csv\"):\n\n        \"\"\"\n        Compute average document-topic matrix,\n        and print to file if print_output=True.\n        \"\"\"\n\n        avg = self.dt.mean(axis=2)\n        if print_output:\n            np.savetxt(output_file, avg, delimiter=\",\")\n        return avg", "response": "Compute average document - topic matrix and print to file if print_output = True."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef phrase_replace(self, replace_dict):\n\n        \"\"\"\n        Replace phrases with single token, mapping defined in replace_dict\n        \"\"\"\n\n        def r(tokens):\n                text = ' ' + ' '.join(tokens)\n                for k, v in replace_dict.items():                    \n                    text = text.replace(\" \" + k + \" \", \" \" + v + \" \")\n                return text.split()\n        self.stems = list(map(r, self.stems))", "response": "Replace phrases with single token mapping defined in replace_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef token_clean(self, length, numbers=True):\n\n        \"\"\"\n        Strip out non-alphanumeric tokens.\n        length: remove tokens of length \"length\" or less.\n        numbers: strip out non-alpha tokens.\n        \"\"\"\n\n        def clean1(tokens):\n            return [t for t in tokens if t.isalpha() == 1 and len(t) > length]\n\n        def clean2(tokens):\n            return [t for t in tokens if t.isalnum() == 1 and len(t) > length]\n\n        if numbers:\n            self.tokens = list(map(clean1, self.tokens))\n        else:\n            self.tokens = list(map(clean2, self.tokens))", "response": "Remove non - alphanumeric and non - alphanumeric tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstemming the tokens with Porter Stemmer.", "response": "def stem(self):\n\n        \"\"\"\n        Stem tokens with Porter Stemmer.\n        \"\"\"\n\n        def s(tokens):\n            return [PorterStemmer().stem(t) for t in tokens]\n        self.stems = list(map(s, self.tokens))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bigram(self, items):\n\n        \"\"\"\n        generate bigrams of either items = \"tokens\" or \"stems\"\n        \"\"\"\n\n        def bigram_join(tok_list):\n            text = nltk.bigrams(tok_list)\n            return list(map(lambda x: x[0] + '.' + x[1], text))\n\n        if items == \"tokens\":\n            self.bigrams = list(map(bigram_join, self.tokens))\n        elif items == \"stems\":\n            self.bigrams = list(map(bigram_join, self.stems))\n        else:\n            raise ValueError(\"Items must be either \\'tokens\\' or \\'stems\\'.\")", "response": "Generate bigrams of either items = tokens or stems."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving stopwords from either tokens or stems.", "response": "def stopword_remove(self, items, threshold=False):\n\n        \"\"\"\n        Remove stopwords from either tokens (items = \"tokens\")\n        or stems (items = \"stems\")\n        \"\"\"\n\n        def remove(tokens):\n            return [t for t in tokens if t not in self.stopwords]\n\n        if items == 'tokens':\n            self.tokens = list(map(remove, self.tokens))\n        elif items == 'stems':\n            self.stems = list(map(remove, self.stems))\n        else:\n            raise ValueError(\"Items must be either \\'tokens\\' or \\'stems\\'.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef term_rank(self, items, print_output=True):\n\n        \"\"\"\n        Calculate corpus-level df and tf-idf scores on either tokens (items =\n        \"tokens\") bigrams (items = 'bigrams') or stems (items = \"stems\"). Print to file if\n        print_output = True.\n        \"\"\"\n\n        if items == 'stems':\n            v = self.stems\n        elif items == 'tokens':\n            v = self.tokens\n        elif items == 'bigrams':\n            v = self.bigrams\n        else:\n            raise ValueError(\"Items must be either \\'tokens\\' , \\'bigrams\\' or \\'stems\\'.\")\n\n        agg = itertools.chain(*v)\n        counts = collections.Counter(agg)\n\n        v_unique = list(map(lambda x: set(x), v))\n        agg_d = itertools.chain(*v_unique)\n        counts_d = collections.Counter(agg_d)\n\n        unique_tokens = set(itertools.chain(*v))\n\n        def tf_idf_compute(t):\n            return (1 + np.log(counts[t]))*np.log(self.N/counts_d[t])\n\n        unsorted_df = [counts[t] for t in unique_tokens]\n        unsorted_tf_idf = [tf_idf_compute(t) for t in unique_tokens]\n\n        self.df_ranking = sorted(zip(unique_tokens, unsorted_df),\n                                 key=lambda x: x[1], reverse=True)\n        self.tfidf_ranking = sorted(zip(unique_tokens, unsorted_tf_idf),\n                                    key=lambda x: x[1], reverse=True)\n\n        if print_output:\n            with codecs.open('df_ranking.csv', 'w', 'utf-8') as f:\n                    for p in self.df_ranking:\n                        f.write(\"%s,%d\\n\" % (p[0], p[1]))\n            with codecs.open('tfidf_ranking.csv', 'w', 'utf-8') as f:\n                    for p in self.tfidf_ranking:\n                        f.write(\"%s,%f\\n\" % (p[0], p[1]))", "response": "Calculate corpus - level df and tf - idf scores on either tokens bigrams or stems. Print to file if print_output = False."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rank_remove(self, rank, items, cutoff):\n\n        \"\"\"\n        remove tokens or stems (specified in items) based on rank's (df or\n        tfidf) value being less than cutoff to remove all words with rank R or\n        less, specify cutoff = self.xxx_ranking[R][1]\n        \"\"\"\n\n        def remove(tokens):\n            return [t for t in tokens if t not in to_remove]\n\n        if rank == \"df\":\n            to_remove = set([t[0] for t in self.df_ranking if t[1] <= cutoff])\n        elif rank == \"tfidf\":\n            to_remove = set([t[0] for t in self.tfidf_ranking\n                             if t[1] <= cutoff])\n        else:\n            raise ValueError(\"Rank must be either \\'df\\' or \\'tfidf\\'.\")\n\n        if items == 'tokens':\n            self.tokens = list(map(remove, self.tokens))\n        elif items == 'bigrams':\n            self.bigrams = list(map(remove, self.bigrams))\n        elif items == 'stems':\n            self.stems = list(map(remove, self.stems))\n        else:\n            raise ValueError(\"Items must be either \\'tokens\\', \\'bigrams\\' or \\'stems\\'.\")", "response": "remove all words with rank R less than cutoff from self. xxx_ranking"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_seed(self, rho_seed, mu_seed):\n\n        \"\"\"\n        set seeds manually (should add dimensionality check)\n        \"\"\"\n\n        self.rho = rho_seed\n        self.mu = mu_seed", "response": "set seed for the n - tuple"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef E_step(self):\n\n        \"\"\"\n        compute type probabilities given current parameter estimates.\n        \"\"\"\n\n        # on the first iteration of estimation, this will be called\n        if not hasattr(self, 'type_prob'):\n                self.type_prob = np.empty((self.N, self.K))\n\n        temp_probs = np.zeros((self.N, self.K))\n\n        for i in range(self.N):\n            for k in range(self.K):\n                temp_probs[i, k] = \\\n                    np.log(self.rho[k]) + np.dot(self.feature_counts[i, :],\n                                                 np.log(self.mu[k, :]))\n\n        temp_probsZ = temp_probs - np.max(temp_probs, axis=1)[:, np.newaxis]\n        self.type_prob = np.exp(temp_probsZ) / \\\n            np.exp(temp_probsZ).sum(axis=1)[:, np.newaxis]\n\n        return np.log(np.exp(temp_probsZ).sum(axis=1)).sum() + \\\n            np.max(temp_probs, axis=1).sum()", "response": "Compute type probabilities given current parameter estimates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef M_step(self):\n\n        \"\"\"\n        generate new parameter estimates given updated type distribution\n        \"\"\"\n\n        for k in range(self.K):\n            self.rho[k] = self.type_prob[:, k].sum() / self.N\n\n        for k in range(self.K):\n            for m in range(self.M):\n                temp_prob = np.dot(self.type_prob[:, k],\n                                   self.feature_counts[:, m])\n                if temp_prob < 1e-99:\n                    temp_prob = 1e-99\n                self.mu[k, m] = temp_prob / np.dot(self.type_prob[:, k],\n                                                   self.observations)", "response": "M step for the type distribution"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef estimate(self, maxiter=250, convergence=1e-7):\n\n        \"\"\"\n        run EM algorithm until convergence, or until maxiter reached\n        \"\"\"\n\n        self.loglik = np.zeros(maxiter)\n\n        iter = 0\n\n        while iter < maxiter:\n\n            self.loglik[iter] = self.E_step()\n            if np.isnan(self.loglik[iter]):\n                    print(\"undefined log-likelihood\")\n                    break\n            self.M_step()\n\n            if self.loglik[iter] - self.loglik[iter - 1] < 0 and iter > 0:\n                    print(\"log-likelihood decreased by %f at iteration %d\"\n                          % (self.loglik[iter] - self.loglik[iter - 1],\n                             iter))\n            elif self.loglik[iter] - self.loglik[iter - 1] < convergence \\\n                    and iter > 0:\n                    print(\"convergence at iteration %d, loglik = %f\" %\n                           (iter, self.loglik[iter]))\n                    self.loglik = self.loglik[self.loglik < 0]\n                    break\n\n            iter += 1", "response": "estimate log - likelihood at each iteration"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting content of file.", "response": "def get_content(path):\n    \"\"\"Get content of file.\"\"\"\n    with codecs.open(abs_path(path), encoding='utf-8') as f:\n        return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sanitize_dataframe(df):\n    import pandas as pd\n    import numpy as np\n\n    df = df.copy()\n\n    if isinstance(df.index, pd.core.index.MultiIndex):\n        raise ValueError('Hierarchical indices not supported')\n    if isinstance(df.columns, pd.core.index.MultiIndex):\n        raise ValueError('Hierarchical indices not supported')\n\n    def to_list_if_array(val):\n        if isinstance(val, np.ndarray):\n            return val.tolist()\n        else:\n            return val\n\n    for col_name, dtype in df.dtypes.iteritems():\n        if str(dtype) == 'category':\n            # XXXX: work around bug in to_json for categorical types\n            # https://github.com/pydata/pandas/issues/10778\n            df[col_name] = df[col_name].astype(str)\n        elif str(dtype) == 'bool':\n            # convert numpy bools to objects; np.bool is not JSON serializable\n            df[col_name] = df[col_name].astype(object)\n        elif np.issubdtype(dtype, np.integer):\n            # convert integers to objects; np.int is not JSON serializable\n            df[col_name] = df[col_name].astype(object)\n        elif np.issubdtype(dtype, np.floating):\n            # For floats, convert to Python float: np.float is not JSON serializable\n            # Also convert NaN/inf values to null, as they are not JSON serializable\n            col = df[col_name]\n            bad_values = col.isnull() | np.isinf(col)\n            df[col_name] = col.astype(object).where(~bad_values, None)\n        elif str(dtype).startswith('datetime'):\n            # Convert datetimes to strings\n            # astype(str) will choose the appropriate resolution\n            df[col_name] = df[col_name].astype(str).replace('NaT', '')\n        elif dtype == object:\n            # Convert numpy arrays saved as objects to lists\n            # Arrays are not JSON serializable\n            col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n            df[col_name] = col.where(col.notnull(), None)\n    return df", "response": "Sanitize a DataFrame to be JSON serializable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_spec(spec, data=None):\n    import pandas as pd\n\n    if isinstance(data, pd.DataFrame):\n        # We have to do the isinstance test first because we can't\n        # compare a DataFrame to None.\n        data = sanitize_dataframe(data)\n        spec['data'] = {'values': data.to_dict(orient='records')}\n    elif data is None:\n        # Assume data is within spec & do nothing\n        # It may be deep in the spec rather than at the top level\n        pass\n    else:\n        # As a last resort try to pass the data to a DataFrame and use it\n        data = pd.DataFrame(data)\n        data = sanitize_dataframe(data)\n        spec['data'] = {'values': data.to_dict(orient='records')}\n    return spec", "response": "Prepare a Vega - Lite spec for sending to the frontend."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _repr_mimebundle_(self, include=None, exclude=None):\n        id = uuid.uuid4()\n        return (\n            {'application/javascript': self._generate_js(id)},\n            {'jupyter-vega': '#{0}'.format(id)},\n        )", "response": "Display the visualization in the Jupyter notebook."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the URL of the Ngrok server.", "response": "def ngrok_url():\n    \"\"\"\n    If ngrok is running, it exposes an API on port 4040. We can use that\n    to figure out what URL it has assigned, and suggest that to the user.\n    https://ngrok.com/docs#list-tunnels\n    \"\"\"\n    try:\n        ngrok_resp = requests.get(\"http://localhost:4040/api/tunnels\")\n    except requests.ConnectionError:\n        # I guess ngrok isn't running.\n        return None\n    ngrok_data = ngrok_resp.json()\n    secure_urls = [\n        tunnel[\"public_url\"]\n        for tunnel in ngrok_data[\"tunnels\"]\n        if tunnel[\"proto\"] == \"https\"\n    ]\n    return secure_urls[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pass_creds_to_nylas(name, email, password, server_host=None):\n    # Start the connection process by looking up all the information that\n    # Nylas needs in order to connect, and sending it to the authorize API.\n    nylas_authorize_data = {\n        \"client_id\": app.config[\"NYLAS_OAUTH_CLIENT_ID\"],\n        \"name\": name,\n        \"email_address\": email,\n        \"provider\": \"exchange\",\n        \"settings\": {\"username\": email, \"password\": password},\n    }\n    if server_host:\n        nylas_authorize_data[\"settings\"][\"eas_server_host\"] = server_host\n\n    nylas_authorize_resp = requests.post(\n        \"https://api.nylas.com/connect/authorize\", json=nylas_authorize_data\n    )\n    if not nylas_authorize_resp.ok:\n        message = nylas_authorize_resp.json()[\"message\"]\n        raise APIError(message)\n\n    nylas_code = nylas_authorize_resp.json()[\"code\"]\n\n    # Now that we've got the `code` from the authorize response,\n    # pass it to the token response to complete the connection.\n    nylas_token_data = {\n        \"client_id\": app.config[\"NYLAS_OAUTH_CLIENT_ID\"],\n        \"client_secret\": app.config[\"NYLAS_OAUTH_CLIENT_SECRET\"],\n        \"code\": nylas_code,\n    }\n    nylas_token_resp = requests.post(\n        \"https://api.nylas.com/connect/token\", json=nylas_token_data\n    )\n    if not nylas_token_resp.ok:\n        message = nylas_token_resp.json()[\"message\"]\n        raise APIError(message)\n\n    nylas_access_token = nylas_token_resp.json()[\"access_token\"]\n\n    # Great, we've connected the Exchange account to Nylas!\n    # In the process, Nylas gave us an OAuth access token, which we'll need\n    # in order to make API requests to Nylas in the future.\n    # We'll save that access token in the Flask session, so we can pick it up\n    # later and use it when we need it.\n    session[\"nylas_access_token\"] = nylas_access_token\n\n    # We're all done here. Redirect the user back to the success page,\n    # which will pick up the access token we just saved.\n    return redirect(url_for(\"success\"))", "response": "Passes Exchange credentials to Nylas and sets up native authentication."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_resource_raw(\n        self, cls, id, extra=None, headers=None, stream=False, **filters\n    ):\n        \"\"\"Get an individual REST resource\"\"\"\n        headers = headers or {}\n        headers.update(self.session.headers)\n\n        postfix = \"/{}\".format(extra) if extra else \"\"\n        if cls.api_root != \"a\":\n            url = \"{}/{}/{}{}\".format(self.api_server, cls.collection_name, id, postfix)\n        else:\n            url = \"{}/a/{}/{}/{}{}\".format(\n                self.api_server, self.app_id, cls.collection_name, id, postfix\n            )\n\n        converted_filters = convert_datetimes_to_timestamps(\n            filters, cls.datetime_filter_attrs\n        )\n        url = str(URLObject(url).add_query_params(converted_filters.items()))\n        response = self._get_http_session(cls.api_root).get(\n            url, headers=headers, stream=stream\n        )\n        return _validate(response)", "response": "Get an individual REST resource"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _call_resource_method(self, cls, id, method_name, data):\n\n        if cls.api_root != \"a\":\n            url_path = \"/{name}/{id}/{method}\".format(\n                name=cls.collection_name, id=id, method=method_name\n            )\n        else:\n            # Management method.\n            url_path = \"/a/{app_id}/{name}/{id}/{method}\".format(\n                app_id=self.app_id, name=cls.collection_name, id=id, method=method_name\n            )\n\n        url = URLObject(self.api_server).with_path(url_path)\n        converted_data = convert_datetimes_to_timestamps(data, cls.datetime_attrs)\n\n        session = self._get_http_session(cls.api_root)\n        response = session.post(url, json=converted_data)\n\n        result = _validate(response).json()\n        return cls.create(self, **result)", "response": "POST a dictionary to an API method for example / a... / accounts / id / upgrade"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a datetime to a timestamp.", "response": "def timestamp_from_dt(dt, epoch=datetime(1970, 1, 1)):\n    \"\"\"\n    Convert a datetime to a timestamp.\n    https://stackoverflow.com/a/8778548/141395\n    \"\"\"\n    delta = dt - epoch\n    # return delta.total_seconds()\n    return delta.seconds + delta.days * 86400"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a dictionary of data and a dictionary of datetime attributes return a new dictionary that converts any datetime attributes that may be present to their timestamped equivalent.", "response": "def convert_datetimes_to_timestamps(data, datetime_attrs):\n    \"\"\"\n    Given a dictionary of data, and a dictionary of datetime attributes,\n    return a new dictionary that converts any datetime attributes that may\n    be present to their timestamped equivalent.\n    \"\"\"\n    if not data:\n        return data\n\n    new_data = {}\n    for key, value in data.items():\n        if key in datetime_attrs and isinstance(value, datetime):\n            new_key = datetime_attrs[key]\n            new_data[new_key] = timestamp_from_dt(value)\n        else:\n            new_data[key] = value\n\n    return new_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying the authenticity of a message and a signature.", "response": "def verify_signature(message, key, signature):\n    \"\"\"\n    This function will verify the authenticity of a digital signature.\n    For security purposes, Nylas includes a digital signature in the headers\n    of every webhook notification, so that clients can verify that the\n    webhook request came from Nylas and no one else. The signing key\n    is your OAuth client secret, which only you and Nylas know.\n    \"\"\"\n    digest = hmac.new(key, msg=message, digestmod=hashlib.sha256).hexdigest()\n    return digest == signature"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef error_respond(self):\n        response = JSONRPCErrorResponse()\n\n        response.error = self.message\n        response.unique_id = None\n        response._jsonrpc_error_code = self.jsonrpc_error_code\n        if hasattr(self, 'data'):\n            response.data = self.data\n        return response", "response": "Converts the error to an error response object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef error_respond(self, error):\n        if self.unique_id is None:\n            return None\n\n        response = JSONRPCErrorResponse()\n        response.unique_id = None if self.one_way else self.unique_id\n\n        code, msg, data = _get_code_message_and_data(error)\n\n        response.error = msg\n        response._jsonrpc_error_code = code\n        if data:\n            response.data = data\n        return response", "response": "Create an error response to this request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a response to this request.", "response": "def respond(self, result):\n        \"\"\"Create a response to this request.\n\n        When processing the request completed successfully this method can be used to\n        create a response object.\n\n        :param result: The result of the invoked method.\n        :type result: Anything that can be encoded by JSON.\n        :returns: A response object that can be serialized and sent to the client.\n        :rtype: :py:class:`JSONRPCSuccessResponse`\n        \"\"\"\n        if self.one_way or self.unique_id is None:\n            return None\n\n        response = JSONRPCSuccessResponse()\n\n        response.result = result\n        response.unique_id = self.unique_id\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_request(self, method, args=None, kwargs=None, one_way=False):\n        if args and kwargs:\n            raise InvalidRequestError(\n                'Does not support args and kwargs at '\n                'the same time'\n            )\n\n        request = self.request_factory()\n        request.one_way = one_way\n\n        if not one_way:\n            request.unique_id = self._get_unique_id()\n\n        request.method = method\n        request.args = args\n        request.kwargs = kwargs\n\n        return request", "response": "Creates a new JSON - RPC request object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_reply(self, data):\n        if isinstance(data, bytes):\n            data = data.decode()\n\n        try:\n            rep = json.loads(data)\n        except Exception as e:\n            raise InvalidReplyError(e)\n\n        for k in rep.keys():\n            if not k in self._ALLOWED_REPLY_KEYS:\n                raise InvalidReplyError('Key not allowed: %s' % k)\n\n        if 'jsonrpc' not in rep:\n            raise InvalidReplyError('Missing jsonrpc (version) in response.')\n\n        if rep['jsonrpc'] != self.JSON_RPC_VERSION:\n            raise InvalidReplyError('Wrong JSONRPC version')\n\n        if 'id' not in rep:\n            raise InvalidReplyError('Missing id in response')\n\n        if ('error' in rep) and ('result' in rep):\n            raise InvalidReplyError(\n                'Reply must contain exactly one of result and error.'\n            )\n\n        if 'error' in rep:\n            response = JSONRPCErrorResponse()\n            error = rep['error']\n            response.error = error[\"message\"]\n            response._jsonrpc_error_code = error[\"code\"]\n            if \"data\" in error:\n                response.data = error[\"data\"]\n        else:\n            response = JSONRPCSuccessResponse()\n            response.result = rep.get('result', None)\n\n        response.unique_id = rep['id']\n\n        return response", "response": "Deserializes and validates a reply."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_request(self, data):\n        if isinstance(data, bytes):\n            data = data.decode()\n\n        try:\n            req = json.loads(data)\n        except Exception as e:\n            raise JSONRPCParseError()\n\n        if isinstance(req, list):\n            # batch request\n            requests = JSONRPCBatchRequest()\n            for subreq in req:\n                try:\n                    requests.append(self._parse_subrequest(subreq))\n                except RPCError as e:\n                    requests.append(e)\n                except Exception as e:\n                    requests.append(JSONRPCInvalidRequestError())\n\n            if not requests:\n                raise JSONRPCInvalidRequestError()\n            return requests\n        else:\n            return self._parse_subrequest(req)", "response": "Deserializes and validates a request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrecreate the exception. Creates a :py:class:`~tinyrpc.protocols.jsonrpc.JSONRPCError` instance and raises it. This allows the error, message and data attributes of the original exception to propagate into the client code. The :py:attr:`~tinyrpc.protocols.RPCProtocol.raises_error` flag controls if the exception obejct is raised or returned. :returns: the exception object if it is not allowed to raise it. :raises JSONRPCError: when the exception can be raised. The exception object will contain ``message``, ``code`` and optionally a ``data`` property.", "response": "def raise_error(self, error):\n        \"\"\"Recreates the exception.\n\n        Creates a :py:class:`~tinyrpc.protocols.jsonrpc.JSONRPCError` instance\n        and raises it.\n        This allows the error, message and data attributes of the original\n        exception to propagate into the client code.\n\n        The :py:attr:`~tinyrpc.protocols.RPCProtocol.raises_error` flag controls if the exception obejct is\n        raised or returned.\n\n        :returns: the exception object if it is not allowed to raise it.\n        :raises JSONRPCError: when the exception can be raised.\n            The exception object will contain ``message``, ``code`` and optionally a\n            ``data`` property.\n        \"\"\"\n        exc = JSONRPCError(error)\n        if self.raises_errors:\n            raise exc\n        return exc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(self, environ, start_response):\n        request = Request(environ)\n        request.max_content_length = self.max_content_length\n\n        access_control_headers = {\n            'Access-Control-Allow-Methods': 'POST',\n            'Access-Control-Allow-Origin': self.allow_origin,\n            'Access-Control-Allow-Headers': \\\n                'Content-Type, X-Requested-With, Accept, Origin'\n        }\n\n        if request.method == 'OPTIONS':\n            response = Response(headers=access_control_headers)\n\n        elif request.method == 'POST':\n            # message is encoded in POST, read it...\n            msg = request.stream.read()\n\n            # create new context\n            context = self._queue_class()\n\n            self.messages.put((context, msg))\n\n            # ...and send the reply\n            response = Response(context.get(), headers=access_control_headers)\n        else:\n            # nothing else supported at the moment\n            response = Response('Only POST supported', 405)\n\n        return response(environ, start_response)", "response": "This function handles the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a single message.", "response": "def receive_one_message(self):\n        \"\"\"Handle a single request.\n\n        Polls the transport for a new message.\n\n        After a new message has arrived :py:meth:`_spawn` is called with a handler\n        function and arguments to handle the request.\n\n        The handler function will try to decode the message using the supplied\n        protocol, if that fails, an error response will be sent. After decoding\n        the message, the dispatcher will be asked to handle the resulting\n        request and the return value (either an error or a result) will be sent\n        back to the client using the transport.\n        \"\"\"\n        context, message = self.transport.receive_message()\n        if callable(self.trace):\n            self.trace('-->', context, message)\n\n        # assuming protocol is threadsafe and dispatcher is theadsafe, as\n        # long as its immutable\n\n        def handle_message(context, message):\n            try:\n                request = self.protocol.parse_request(message)\n            except tinyrpc.exc.RPCError as e:\n                response = e.error_respond()\n            else:\n                response = self.dispatcher.dispatch(request)\n\n            # send reply\n            if response is not None:\n                result = response.serialize()\n                if callable(self.trace):\n                    self.trace('<--', context, result)\n                self.transport.send_reply(context, result)\n\n        self._spawn(handle_message, context, message)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef raise_error(self, error):\n        ex = exc.RPCError('Error calling remote procedure: %s' % error.error['message'])\n        if self.raises_errors:\n            raise ex\n        return ex", "response": "Raises the exception in the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, zmq_context, endpoint):\n        socket = zmq_context.socket(zmq.ROUTER)\n        socket.bind(endpoint)\n        return cls(socket)", "response": "Create a new server transport."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, zmq_context, endpoint):\n        socket = zmq_context.socket(zmq.REQ)\n        socket.connect(endpoint)\n        return cls(socket)", "response": "Create a new client transport."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_message(self):\n\n        if not ('REQUEST_METHOD' in os.environ\n                and os.environ['REQUEST_METHOD'] == 'POST'):\n            print(\"Status: 405 Method not Allowed; only POST is accepted\")\n            exit(0)\n\n        # POST\n        content_length = int(os.environ['CONTENT_LENGTH'])\n        request_json = sys.stdin.read(content_length)\n        request_json = urlparse.unquote(request_json)\n        # context isn't used with cgi\n        return None, request_json", "response": "Receive a message from the transport."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_reply(self, context, reply):\n\n        # context isn't used with cgi\n        # Using sys.stdout.buffer.write() fails as stdout is on occasion monkey patched\n        # to AsyncFile which doesn't support the buffer attribute.\n        print(\"Status: 200 OK\")\n        print(\"Content-Type: application/json\")\n        print(\"Cache-Control: no-cache\")\n        print(\"Pragma: no-cache\")\n        print(\"Content-Length: %d\" % len(reply))\n        print()\n        print(reply.decode())", "response": "Sends a reply to a client."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns a function with args and kwargs as a greenlet.", "response": "def _spawn(self, func, *args, **kwargs):\n        \"\"\"Spawn a handler function.\n\n        Spawns the supplied ``func`` with ``*args`` and ``**kwargs``\n        as a gevent greenlet.\n\n        :param func: A callable to call.\n        :param args: Arguments to ``func``.\n        :param kwargs: Keyword arguments to ``func``.\n        \"\"\"\n        gevent.spawn(func, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling the requested method and returns the result.", "response": "def call(self, method, args, kwargs, one_way=False):\n        \"\"\"Calls the requested method and returns the result.\n\n        If an error occured, an :py:class:`~tinyrpc.exc.RPCError` instance\n        is raised.\n\n        :param method: Name of the method to call.\n        :param args: Arguments to pass to the method.\n        :param kwargs: Keyword arguments to pass to the method.\n        :param one_way: Whether or not a reply is desired.\n        \"\"\"\n        req = self.protocol.create_request(method, args, kwargs, one_way)\n\n        rep = self._send_and_handle_reply(req, one_way)\n\n        if one_way:\n            return\n\n        return rep.result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling the methods in the request in parallel.", "response": "def call_all(self, requests):\n        \"\"\"Calls the methods in the request in parallel.\n\n        When the :py:mod:`gevent` module is already loaded it is assumed to be\n        correctly initialized, including monkey patching if necessary.\n        In that case the RPC calls defined by ``requests`` is performed in\n        parallel otherwise the methods are called sequentially.\n\n        :param requests: A listof either :py:class:`~tinyrpc.client.RPCCall` or :py:class:`~tinyrpc.client.RPCCallTo` elements.\n                         When RPCCallTo is used each element defines a transport.\n                         Otherwise the default transport set when RPCClient is\n                         created is used.\n        :return: A list with replies matching the order of the requests.\n        \"\"\"\n        threads = []\n\n        if 'gevent' in sys.modules:\n            # assume that gevent is available and functional, make calls in parallel\n            import gevent\n            for r in requests:\n                req = self.protocol.create_request(r.method, r.args, r.kwargs)\n                tr = r.transport.transport if len(r) == 4 else None\n                threads.append(\n                    gevent.spawn(\n                        self._send_and_handle_reply, req, False, tr, True\n                    )\n                )\n            gevent.joinall(threads)\n            return [t.value for t in threads]\n        else:\n            # call serially\n            for r in requests:\n                req = self.protocol.create_request(r.method, r.args, r.kwargs)\n                tr = r.transport.transport if len(r) == 4 else None\n                threads.append(\n                    self._send_and_handle_reply(req, False, tr, True)\n                )\n            return threads"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_call(self, calls):\n        req = self.protocol.create_batch_request()\n\n        for call_args in calls:\n            req.append(self.protocol.create_request(*call_args))\n\n        return self._send_and_handle_reply(req)", "response": "Sends a batch call to the server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a subdispatcher to the internal list of subdispatchers.", "response": "def add_subdispatch(self, dispatcher, prefix=''):\n        \"\"\"Adds a subdispatcher, possibly in its own namespace.\n\n        :param dispatcher: The dispatcher to add as a subdispatcher.\n        :type dispatcher: RPCDispatcher\n        :param str prefix: A prefix. All of the new subdispatchers methods will be\n                       available as prefix + their original name.\n        \"\"\"\n        self.subdispatchers.setdefault(prefix, []).append(dispatcher)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a method to the dispatcher.", "response": "def add_method(self, f, name=None):\n        \"\"\"Add a method to the dispatcher.\n\n        :param f: Callable to be added.\n        :type f: callable\n        :param str name: Name to register it with. If ``None``, ``f.__name__`` will\n                     be used.\n        :raises ~tinyrpc.exc.RPCError: When the `name` is already registered.\n        \"\"\"\n        assert callable(f), \"method argument must be callable\"\n        # catches a few programming errors that are\n        # commonly silently swallowed otherwise\n        if not name:\n            name = f.__name__\n\n        if name in self.method_map:\n            raise exc.RPCError('Name %s already registered')\n\n        self.method_map[name] = f"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a previously registered method.", "response": "def get_method(self, name):\n        \"\"\"Retrieve a previously registered method.\n\n        Checks if a method matching ``name`` has been registered.\n\n        If :py:func:`get_method` cannot find a method, every subdispatcher\n        with a prefix matching the method name is checked as well.\n\n        :param str name: Function to find.\n        :returns: The callable implementing the function.\n        :rtype: callable\n        :raises: :py:exc:`~tinyrpc.exc.MethodNotFoundError`\n        \"\"\"\n        if name in self.method_map:\n            return self.method_map[name]\n\n        for prefix, subdispatchers in self.subdispatchers.items():\n            if name.startswith(prefix):\n                for sd in subdispatchers:\n                    try:\n                        return sd.get_method(name[len(prefix):])\n                    except exc.MethodNotFoundError:\n                        pass\n\n        raise exc.MethodNotFoundError(name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_instance(self, obj, prefix=''):\n        dispatch = self.__class__()\n        for name, f in inspect.getmembers(\n                obj, lambda f: callable(f) and hasattr(f, '_rpc_public_name')):\n            dispatch.add_method(f, f._rpc_public_name)\n\n        # add to dispatchers\n        self.add_subdispatch(dispatch, prefix)", "response": "Create a new subdispatcher and register all public object methods on\n        it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatch(self, request):\n        if hasattr(request, 'create_batch_response'):\n            results = [self._dispatch(req) for req in request]\n\n            response = request.create_batch_response()\n            if response is not None:\n                response.extend(results)\n\n            return response\n        else:\n            return self._dispatch(request)", "response": "Fully handle the request and return a response containing a list of results."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_parameters(self, method, args, kwargs):\n        if hasattr(method, '__code__'):\n            try:\n                inspect.getcallargs(method, *args, **kwargs)\n            except TypeError:\n                raise exc.InvalidParamsError()", "response": "Verify that the provided arguments are acceptable for the method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an item from the dict and return it.", "response": "def pop(self, key, default=None):\n        \"\"\" Get item from the dict and remove it.\n\n        Return default if expired or does not exist. Never raise KeyError.\n        \"\"\"\n        with self.lock:\n            try:\n                item = OrderedDict.__getitem__(self, key)\n                del self[key]\n                return item[0]\n            except KeyError:\n                return default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ttl(self, key):\n        key_value, key_age = self.get(key, with_age=True)\n        if key_age:\n            key_ttl = self.max_age - key_age\n            if key_ttl > 0:\n                return key_ttl\n        return None", "response": "Return the TTL of the key in seconds. Returns None if the key is not found or expired."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, key, default=None, with_age=False):\n        \" Return the value for key if key is in the dictionary, else default. \"\n        try:\n            return self.__getitem__(key, with_age)\n        except KeyError:\n            if with_age:\n                return default, None\n            else:\n                return default", "response": "Return the value for key if key is in the dictionary else default."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef items(self):\n        r = []\n        for key in self._safe_keys():\n            try:\n                r.append((key, self[key]))\n            except KeyError:\n                pass\n        return r", "response": "Return a list of ( key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef values(self):\n        r = []\n        for key in self._safe_keys():\n            try:\n                r.append(self[key])\n            except KeyError:\n                pass\n        return r", "response": "Return a list of all the values in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reload(self, callback=None, errback=None):\n        return self.load(reload=True, callback=callback, errback=errback)", "response": "Reload the record data from the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, callback=None, errback=None, reload=False):\n        if not reload and self.data:\n            raise RecordException('record already loaded')\n\n        def success(result, *args):\n            self._parseModel(result)\n            if callback:\n                return callback(self)\n            else:\n                return self\n        return self._rest.retrieve(self.parentZone.zone,\n                                   self.domain, self.type,\n                                   callback=success, errback=errback)", "response": "Load the record from the API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the record from the zone.", "response": "def delete(self, callback=None, errback=None):\n        \"\"\"\n        Delete the record from the zone, including all advanced configuration,\n        meta data, etc.\n        \"\"\"\n        if not self.data:\n            raise RecordException('record not loaded')\n\n        def success(result, *args):\n            if callback:\n                return callback(result)\n            else:\n                return result\n\n        return self._rest.delete(self.parentZone.zone,\n                                 self.domain, self.type,\n                                 callback=success, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the record configuration.", "response": "def update(self, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Update record configuration. Pass list of keywords and their values to\n        update. For the list of keywords available for zone configuration, see\n        :attr:`ns1.rest.records.Records.INT_FIELDS`,\n        :attr:`ns1.rest.records.Records.PASSTHRU_FIELDS`,\n        :attr:`ns1.rest.records.Records.BOOL_FIELDS`\n        \"\"\"\n        if not self.data:\n            raise RecordException('record not loaded')\n\n        def success(result, *args):\n            self._parseModel(result)\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.parentZone.zone, self.domain, self.type,\n                                 callback=success, errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the current QPS for this record.", "response": "def qps(self, callback=None, errback=None):\n        \"\"\"\n        Return the current QPS for this record\n\n        :rtype: dict\n        :return: QPS information\n        \"\"\"\n        if not self.data:\n            raise RecordException('record not loaded')\n        stats = Stats(self.parentZone.config)\n        return stats.qps(zone=self.parentZone.zone,\n                         domain=self.domain,\n                         type=self.type,\n                         callback=callback,\n                         errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding answers to the record.", "response": "def addAnswers(self, answers, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Add answers to the record.\n\n        :param answers: answers structure. See the class note on answer format.\n        \"\"\"\n        if not self.data:\n            raise RecordException('record not loaded')\n        orig_answers = self.data['answers']\n        new_answers = self._rest._getAnswersForBody(answers)\n        orig_answers.extend(new_answers)\n        return self.update(answers=orig_answers, callback=callback,\n                           errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a basic config from an API key.", "response": "def createFromAPIKey(self, apikey, maybeWriteDefault=False):\n        \"\"\"\n        Create a basic config from a single API key\n\n        :param str apikey: NS1 API Key, as created in the NS1 portal\n        :param bool maybeWriteDefault: If True and DEFAULT_CONFIG_FILE doesn't\\\n            exist write out the resulting config there.\n        \"\"\"\n        self._data = {\n            'default_key': 'default',\n            'keys': {\n                'default': {\n                    'key': apikey,\n                    'desc': 'imported API key'\n                }\n            }\n        }\n        self._keyID = 'default'\n        self._doDefaults()\n        if maybeWriteDefault:\n            path = os.path.expanduser(self.DEFAULT_CONFIG_FILE)\n            self.write(path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload config data from a string", "response": "def loadFromString(self, body):\n        \"\"\"\n        Load config data (i.e. JSON text) from the given string\n\n        :param str body: config data in JSON format\n        \"\"\"\n        try:\n            self._data = json.loads(body)\n        except Exception as e:\n            raise ConfigException('%s: invalid config body: %s' %\n                                  (self._path, e.message))\n        self._doDefaults()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadFromFile(self, path):\n        if '~' in path:\n            path = os.path.expanduser(path)\n        f = open(path)\n        body = f.read()\n        f.close()\n        self._path = path\n        self.loadFromString(body)", "response": "Load the JSON config file at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the config data to disk.", "response": "def write(self, path=None):\n        \"\"\"\n         Write config data to disk. If this config object already has a path,\n         it will write to it. If it doesn't, one must be passed during this\n         call.\n\n        :param str path: path to config file\n        \"\"\"\n        if not self._path and not path:\n            raise ConfigException('no config path given')\n        if path:\n            self._path = path\n        if '~' in self._path:\n            self._path = os.path.expanduser(self._path)\n        f = open(self._path, 'w')\n        f.write(json.dumps(self._data))\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef useKeyID(self, keyID):\n        if keyID not in self._data['keys']:\n            raise ConfigException('keyID does not exist: %s' % keyID)\n        self._keyID = keyID", "response": "Use the given API key config specified by keyID during subsequent\n        API calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getKeyConfig(self, keyID=None):\n        k = keyID if keyID is not None else self._keyID\n        if not k or k not in self._data['keys']:\n            raise ConfigException('request key does not exist: %s' % k)\n        return self._data['keys'][k]", "response": "Get key configuration specified by keyID or current keyID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isKeyWriteLocked(self, keyID=None):\n        kcfg = self.getKeyConfig(keyID)\n        return 'writeLock' in kcfg and kcfg['writeLock'] is True", "response": "Determines if a given keyID is write locked."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAPIKey(self, keyID=None):\n        kcfg = self.getKeyConfig(keyID)\n        if 'key' not in kcfg:\n            raise ConfigException('invalid config: missing api key')\n        return kcfg['key']", "response": "Retrieve the NS1 API Key for the given keyID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getEndpoint(self):\n        port = ''\n        endpoint = ''\n        keyConfig = self.getKeyConfig()\n        if 'port' in keyConfig:\n            port = ':' + keyConfig['port']\n        elif self._data['port'] != self.PORT:\n            port = ':' + self._data['port']\n        if 'endpoint' in keyConfig:\n            endpoint = keyConfig['endpoint']\n        else:\n            endpoint = self._data['endpoint']\n        return 'https://%s%s/%s/' % (endpoint,\n                                     port,\n                                     self._data['api_version'])", "response": "Retrieve the NS1 API Endpoint URL that will be used for requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, callback=None, errback=None, reload=False):\n        if not reload and self.data:\n            raise NetworkException('Network already loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.name = result['name']\n            self.report = self._rest.report(self.id)\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        if self.id is None:\n            if self.name is None:\n                raise NetworkException('Must at least specify an id or name')\n            else:\n                self.id = [network for network in self._rest.list()\n                           if network['name'] == self.name][0]['id']\n\n        return self._rest.retrieve(self.id, callback=success,\n                                   errback=errback)", "response": "Load the network data from the API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the Network and all associated addresses", "response": "def delete(self, callback=None, errback=None):\n        \"\"\"\n        Delete the Network and all associated addresses\n        \"\"\"\n        return self._rest.delete(self.id, callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the properties of a specific resource in the Network.", "response": "def update(self, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Update Network configuration. Pass a list of keywords and their values to update.\n        For the list of keywords available for zone configuration, see :attr:`ns1.rest.ipam.Networks.INT_FIELDS` and :attr:`ns1.rest.ipam.Networks.PASSTHRU_FIELDS`\n        \"\"\"\n        if not self.data:\n            raise NetworkException('Network not loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.name = result['name']\n            self.report = self._rest.report(self.id)\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.id, callback=success, errback=errback,\n                                 **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new address space in this Network.", "response": "def new_address(self, prefix, type, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Create a new address space in this Network\n\n        :param str prefix: The CIDR prefix of the address to add\n        :param str type: planned, assignment, host\n        :return: The newly created Address object\n        \"\"\"\n        if not self.data:\n            raise NetworkException('Network not loaded')\n\n        return Address(self.config, prefix, type, self).create(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads address data from the API.", "response": "def load(self, callback=None, errback=None, reload=False):\n        \"\"\"\n        Load address data from the API.\n        \"\"\"\n        if not reload and self.data:\n            raise AddressException('Address already loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.prefix = result['prefix']\n            self.type = result['type']\n            self.network = Network(self.config, id=result['network_id'])\n            # self.scope_group = Scopegroup(config=self.config, id=result['scope_group_id']) NYI\n            if self.type != 'host':\n                self.report = self._rest.report(self.id)\n                children = self._rest.retrieve_children(self.id)\n                self.children = [Address(self.config, id=child['id']) for child in\n                                 children if len(children) > 0]\n            try:\n                parent = self._rest.retrieve_parent(self.id)\n                self.parent = Address(self.config, id=parent['id'])\n            except ResourceException:\n                pass\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        if self.id is None:\n            if self.prefix is None or self.type is None or self.network is None:\n                raise AddressException('Must at least specify an id or prefix, type and network')\n            else:\n                network_id = self.network.id\n                try:\n                    self.id = [address for address in self._rest.list() if address['prefix'] == self.prefix and address[\n                        'type'] == self.type and address['network_id'] == network_id][0]['id']\n                except IndexError:\n                    raise AddressException(\"Could not find address by prefix. It may not exist, or is a child address. \"\n                                           \"Use the topmost parent prefix or specify ID\")\n\n        return self._rest.retrieve(self.id, callback=success,\n                                   errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the address configuration.", "response": "def update(self, callback=None, errback=None, parent=True, **kwargs):\n        \"\"\"\n        Update address configuration. Pass a list of keywords and their values to\n        update. For the list of keywords available for address configuration, see :attr:`ns1.rest.ipam.Addresses.INT_FIELDS` and :attr:`ns1.rest.ipam.Addresses.PASSTHRU_FIELDS`\n        \"\"\"\n        if not self.data:\n            raise AddressException('Address not loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.prefix = result['prefix']\n            self.type = result['type']\n            self.network = Network(self.config, id=result['network_id'])\n            # self.scope_group = Scopegroup(config=self.config, id=result['scope_group_id'])\n            if self.type != 'host':\n                self.report = self._rest.report(self.id)\n                children = self._rest.retrieve_children(self.id)\n                self.children = [Address(self.config, id=child['id']) for child in\n                                 children if len(children) > 0]\n            try:\n                parent = self._rest.retrieve_parent(self.id)\n                self.parent = Address(self.config, id=parent['id'])\n            except ResourceException:\n                pass\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.id, callback=success, errback=errback, parent=parent,\n                                 **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the scope group from the API.", "response": "def load(self, callback=None, errback=None, reload=False):\n        \"\"\"\n        Load Scopegroup data from the API.\n        \"\"\"\n        if not reload and self.data:\n            raise ScopegroupException('Scope Group already loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.dhcp4 = result['dhcp4']\n            self.dhcp6 = result['dhcp6']\n            self.name = result['name']\n            self.service_group_id = result['service_group_id']\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        if self.id is None:\n            if self.dhcp4 is None or self.dhcp6 is None or self.name is None or self.service_group_id is None:\n                raise AddressException('Must at least specify an id or name and service_group_id')\n            else:\n                try:\n                    self.id = [scope_group for scope_group in self._rest.list() if scope_group['name'] == self.name and\n                               scope_group['service_group_id'] == self.service_group_id][0]['id']\n                except IndexError:\n                    raise AddressException(\"Could not find Scope Group by name and service_group_id. It may not exist\")\n\n        return self._rest.retrieve(self.id, callback=success,\n                                   errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the scope group configuration.", "response": "def update(self, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Update scope group configuration. Pass a list of keywords and their values to\n        update. For the list of keywords available for address configuration, see :attr:`ns1.rest.ipam.Scopegroups.INT_FIELDS` and :attr:`ns1.rest.ipam.Scopegroups.PASSTHRU_FIELDS`\n        \"\"\"\n        if not self.data:\n            raise ScopegroupException('Scope Group not loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.dhcp4 = result['dhcp4']\n            self.dhcp6 = result['dhcp6']\n            self.name = result['name']\n            self.service_group_id = result['service_group_id']\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.id, callback=success, errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, dhcp4, dhcp6, callback=None, errback=None):\n        if self.data:\n            raise ScopegroupException('Scope Group already loaded')\n\n        def success(result, *args):\n            self.data = result\n            self.id = result['id']\n            self.dhcp4 = result['dhcp4']\n            self.dhcp6 = result['dhcp6']\n            self.name = result['name']\n            self.service_group_id = result['service_group_id']\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.create(dhcp4=dhcp4.option_list, dhcp6=dhcp6.option_list, name=self.name, service_group_id=self.service_group_id,\n                                 callback=success, errback=errback)", "response": "Create a new Scope Group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch within a zone for specific metadata.", "response": "def search(self, q=None, has_geo=False, callback=None, errback=None):\n        \"\"\"\n        Search within a zone for specific metadata. Zone must already be loaded.\n        \"\"\"\n        if not self.data:\n            raise ZoneException('zone not loaded')\n\n        return self._rest.search(self.zone, q, has_geo, callback, errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, callback=None, errback=None):\n        return self._rest.delete(self.zone, callback=callback, errback=errback)", "response": "Delete the records in this zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, callback=None, errback=None, **kwargs):\n        if not self.data:\n            raise ZoneException('zone not loaded')\n\n        def success(result, *args):\n            self.data = result\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.zone, callback=success, errback=errback,\n                                 **kwargs)", "response": "Update the local cache of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, zoneFile=None, callback=None, errback=None, **kwargs):\n        if self.data:\n            raise ZoneException('zone already loaded')\n\n        def success(result, *args):\n            self.data = result\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        if zoneFile:\n            return self._rest.import_file(self.zone, zoneFile,\n                                          callback=success, errback=errback,\n                                          **kwargs)\n        else:\n            return self._rest.create(self.zone, callback=success,\n                                     errback=errback, **kwargs)", "response": "Create a new zone."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new linked zone linking to ourselves.", "response": "def createLinkToSelf(self, new_zone, callback=None, errback=None,\n                         **kwargs):\n        \"\"\"\n        Create a new linked zone, linking to ourselves. All records in this\n        zone will then be available as \"linked records\" in the new zone.\n\n        :param str new_zone: the new zone name to link to this one\n        :return: new Zone\n        \"\"\"\n        zone = Zone(self.config, new_zone)\n        kwargs['link'] = self.data['zone']\n        return zone.create(callback=callback, errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef linkRecord(self, existing_domain, new_domain, rtype,\n                   callback=None, errback=None, **kwargs):\n\n        \"\"\"\n        Create a new linked record in this zone. These records use the\n        configuration (answers, ttl, filters, etc) from an existing record\n        in the NS1 platform.\n\n        :param str existing_domain: FQDN of the target record whose config \\\n            should be used. Does not have to be in the same zone.\n        :param str new_domain: Name of the new (linked) record. Zone name is\\\n            appended automatically.\n        :param str rtype: DNS record type, which must match the target record.\n        :rtype: ns1.records.Record\n        :return: new Record\n        \"\"\"\n\n        if '.' not in existing_domain:\n            existing_domain = existing_domain + '.' + self.zone\n\n        record = Record(self, new_domain, rtype)\n        return record.create(answers=[],\n                             link=existing_domain,\n                             callback=callback,\n                             errback=errback,\n                             **kwargs)", "response": "Create a new linked record in this zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cloneRecord(self, existing_domain, new_domain, rtype,\n                    zone=None, callback=None, errback=None):\n        \"\"\"\n        Clone the given record to a new record such that their configs are\n        identical.\n\n        :param str existing_domain: The existing record to clone\n        :param str new_domain: The name of the new cloned record\n        :param str rtype: DNS record type\n        :param str zone: Optional zone name, if the new record should exist in\\\n            a different zone than the original record.\n        :rtype: ns1.records.Record\n        :return: new Record\n        \"\"\"\n        if zone is None:\n            zone = self.zone\n\n        if not new_domain.endswith(zone):\n            new_domain = new_domain + '.' + zone\n\n        def onSaveNewRecord(new_data):\n            if zone != self.zone:\n                pZone = Zone(self.config, zone)\n            else:\n                pZone = self\n            new_rec = Record(pZone, new_domain, rtype)\n            new_rec._parseModel(new_data)\n            if callback:\n                return callback(new_rec)\n            else:\n                return new_rec\n\n        def onLoadRecord(old_rec):\n            data = old_rec.data\n            data['zone'] = zone\n            data['domain'] = new_domain\n            restapi = Records(self.config)\n            return restapi.create_raw(zone, new_domain, rtype, data,\n                                      callback=onSaveNewRecord,\n                                      errback=errback)\n\n        return self.loadRecord(existing_domain, rtype,\n                               callback=onLoadRecord,\n                               errback=errback)", "response": "Clones the given record to a new record such that their configs are identical."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a high level record from a domain within this Zone.", "response": "def loadRecord(self, domain, rtype, callback=None, errback=None):\n        \"\"\"\n        Load a high level Record object from a domain within this Zone.\n\n        :param str domain: The name of the record to load\n        :param str rtype: The DNS record type\n        :rtype: ns1.records.Record\n        :return: new Record\n        \"\"\"\n        rec = Record(self, domain, rtype)\n        return rec.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the current QPS for this zone", "response": "def qps(self, callback=None, errback=None):\n        \"\"\"\n        Return the current QPS for this zone\n\n        :rtype: dict\n        :return: QPS information\n        \"\"\"\n        stats = Stats(self.config)\n        return stats.qps(zone=self.zone, callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current usage information for this zone", "response": "def usage(self, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Return the current usage information for this zone\n\n        :rtype: dict\n        :return: usage information\n        \"\"\"\n        stats = Stats(self.config)\n        return stats.usage(zone=self.zone, callback=callback, errback=errback,\n                           **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads monitor data from the API.", "response": "def load(self, callback=None, errback=None, reload=False):\n        \"\"\"\n        Load monitor data from the API.\n        \"\"\"\n        if not reload and self.data:\n            raise MonitorException('monitor already loaded')\n\n        def success(result, *args):\n            self.data = result\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.retrieve(self.data['id'], callback=success,\n                                   errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the monitor configuration.", "response": "def update(self, callback=None, errback=None, **kwargs):\n        \"\"\"\n        Update monitor configuration. Pass a list of keywords and their values to\n        update.\n        \"\"\"\n        if not self.data:\n            raise MonitorException('monitor not loaded')\n\n        def success(result, *args):\n            self.data = result\n            if callback:\n                return callback(self)\n            else:\n                return self\n\n        return self._rest.update(self.data['id'], {}, callback=success, errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new raw REST interface to zone resources", "response": "def zones(self):\n        \"\"\"\n        Return a new raw REST interface to zone resources\n\n        :rtype: :py:class:`ns1.rest.zones.Zones`\n        \"\"\"\n        import ns1.rest.zones\n        return ns1.rest.zones.Zones(self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new raw REST interface to record resources", "response": "def records(self):\n        \"\"\"\n        Return a new raw REST interface to record resources\n\n        :rtype: :py:class:`ns1.rest.records.Records`\n        \"\"\"\n        import ns1.rest.records\n        return ns1.rest.records.Records(self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addresses(self):\n        import ns1.rest.ipam\n        return ns1.rest.ipam.Addresses(self.config)", "response": "Return a new raw REST interface to address resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef networks(self):\n        import ns1.rest.ipam\n        return ns1.rest.ipam.Networks(self.config)", "response": "Return a new raw REST interface to network resources\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new raw REST interface to scope_group resources", "response": "def scope_groups(self):\n        \"\"\"\n        Return a new raw REST interface to scope_group resources\n\n        :rtype: :py:class:`ns1.rest.ipam.Scopegroups`\n        \"\"\"\n        import ns1.rest.ipam\n        return ns1.rest.ipam.Scopegroups(self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stats(self):\n        import ns1.rest.stats\n        return ns1.rest.stats.Stats(self.config)", "response": "Return a new raw REST interface to stats resources\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef datasource(self):\n        import ns1.rest.data\n        return ns1.rest.data.Source(self.config)", "response": "Returns a new raw REST interface to datasource resources\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new raw REST interface to feed resources", "response": "def datafeed(self):\n        \"\"\"\n        Return a new raw REST interface to feed resources\n\n        :rtype: :py:class:`ns1.rest.data.Feed`\n        \"\"\"\n        import ns1.rest.data\n        return ns1.rest.data.Feed(self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef monitors(self):\n        import ns1.rest.monitoring\n        return ns1.rest.monitoring.Monitors(self.config)", "response": "Return a new raw REST interface to monitors resources\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef notifylists(self):\n        import ns1.rest.monitoring\n        return ns1.rest.monitoring.NotifyLists(self.config)", "response": "Return a new raw REST interface to notify list resources"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new raw REST interface to account", "response": "def plan(self):\n        \"\"\"\n        Return a new raw REST interface to account plan\n\n        :rtype: :py:class:`ns1.rest.account.Plan`\n        \"\"\"\n        import ns1.rest.account\n        return ns1.rest.account.Plan(self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading an existing zone into a high level Zone object.", "response": "def loadZone(self, zone, callback=None, errback=None):\n        \"\"\"\n        Load an existing zone into a high level Zone object.\n\n        :param str zone: zone name, like 'example.com'\n        :rtype: :py:class:`ns1.zones.Zone`\n        \"\"\"\n        import ns1.zones\n        zone = ns1.zones.Zone(self.config, zone)\n        return zone.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef searchZone(self, zone, q=None, has_geo=False, callback=None, errback=None):\n        import ns1.zones\n        return zone.search(q, has_geo, callback=callback, errback=errback)", "response": "Search a zone for a given search query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new zone and return an associated high level Zone object.", "response": "def createZone(self, zone, zoneFile=None, callback=None, errback=None,\n                   **kwargs):\n        \"\"\"\n        Create a new zone, and return an associated high level Zone object.\n        Several optional keyword arguments are available to configure the SOA\n        record.\n\n        If zoneFile is specified, upload the specific zone definition file\n        to populate the zone with.\n\n        :param str zone: zone name, like 'example.com'\n        :param str zoneFile: absolute path of a zone file\n        :keyword int retry: retry time\n        :keyword int refresh: refresh ttl\n        :keyword int expiry: expiry ttl\n        :keyword int nx_ttl: nxdomain TTL\n\n        :rtype: :py:class:`ns1.zones.Zone`\n        \"\"\"\n        import ns1.zones\n        zone = ns1.zones.Zone(self.config, zone)\n        return zone.create(zoneFile=zoneFile, callback=callback,\n                           errback=errback, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadRecord(self, domain, type, zone=None, callback=None,\n                   errback=None, **kwargs):\n        \"\"\"\n        Load an existing record into a high level Record object.\n\n        :param str domain: domain name of the record in the zone, for example \\\n            'myrecord'. You may leave off the zone, since it must be \\\n            specified in the zone parameter\n        :param str type: record type, such as 'A', 'MX', 'AAAA', etc.\n        :param str zone: zone name, like 'example.com'\n        :rtype: :py:class:`ns1.records`\n        \"\"\"\n        import ns1.zones\n        if zone is None:\n            # extract from record string\n            parts = domain.split('.')\n            if len(parts) <= 2:\n                zone = '.'.join(parts)\n            else:\n                zone = '.'.join(parts[1:])\n        z = ns1.zones.Zone(self.config, zone)\n        return z.loadRecord(domain, type, callback=callback, errback=errback,\n                            **kwargs)", "response": "Load an existing record into a high level Record object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadMonitors(self, callback=None, errback=None, **kwargs):\n        import ns1.monitoring\n        monitors_list = self.monitors().list(callback, errback)\n\n        return [ns1.monitoring.Monitor(self.config, m) for m in monitors_list]", "response": "Load all monitors from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createMonitor(self, callback=None, errback=None, **kwargs):\n        import ns1.monitoring\n        monitor = ns1.monitoring.Monitor(self.config)\n        return monitor.create(callback=callback, errback=errback, **kwargs)", "response": "Create a monitor for this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload an existing Network into a high level Network object", "response": "def loadNetworkbyID(self, id, callback=None, errback=None):\n        \"\"\"\n        Load an existing Network by ID into a high level Network object\n\n        :param int id: id of an existing Network\n        \"\"\"\n        import ns1.ipam\n        network = ns1.ipam.Network(self.config, id=id)\n        return network.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads an existing Network into a high level Network object", "response": "def loadNetworkbyName(self, name, callback=None, errback=None):\n        \"\"\"\n        Load an existing Network by name into a high level Network object\n\n        :param str name: Name of an existing Network\n        \"\"\"\n        import ns1.ipam\n        network = ns1.ipam.Network(self.config, name=name)\n        return network.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createNetwork(self, name, scope_group_id=None, callback=None, errback=None, **kwargs):\n        import ns1.ipam\n        if scope_group_id is not None:\n            scope_group = ns1.ipam.Scopegroup(self.config, id=scope_group_id).update()\n            kwargs['scope_group'] = scope_group\n        network = ns1.ipam.Network(self.config, name=name)\n        return network.create(callback=callback, errback=errback, **kwargs)", "response": "Create a new Network object with optional scope group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads an existing address into a high level Address object", "response": "def loadAddressbyID(self, id, callback=None, errback=None):\n        \"\"\"\n        Load an existing address by ID into a high level Address object\n\n        :param int id: id of an existing Address\n        \"\"\"\n        import ns1.ipam\n        address = ns1.ipam.Address(self.config, id=id)\n        return address.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload an existing address by prefix type and network into a high level Address object", "response": "def loadAddressbyPrefix(self, prefix, type, network_id, callback=None, errback=None):\n        \"\"\"\n        Load an existing address by prefix, type and network into a high level Address object\n\n        :param str prefix: CIDR prefix of an existing Address\n        :param str type: Type of address assignement (planned, assignment or host)\n        :param int network_id: network_id associated with the address\n        \"\"\"\n        import ns1.ipam\n        network = ns1.ipam.Network(self.config, id=network_id).load()\n        address = ns1.ipam.Address(self.config, prefix=prefix, type=type, network=network)\n        return address.load(callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createAddress(self, prefix, type, network_id, callback=None, errback=None, **kwargs):\n        import ns1.ipam\n        network = ns1.ipam.Network(self.config, id=network_id).load()\n        address = ns1.ipam.Address(self.config, prefix=prefix, type=type, network=network)\n        return address.create(callback=callback, errback=errback, **kwargs)", "response": "Create a new Address object in the given network"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef loadScopeGroupbyID(self, id, callback=None, errback=None):\n        import ns1.ipam\n        scope_group = ns1.ipam.Scopegroup(self.config, id=id)\n        return scope_group.load(callback=callback, errback=errback)", "response": "Load an existing Scope Group into a high level Scope Group object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadScopeGroupbyName(self, name, service_group_id, callback=None, errback=None):\n        import ns1.ipam\n        scope_group = ns1.ipam.Scopegroup(self.config, name=name, service_group_id=service_group_id)\n        return scope_group.load(callback=callback, errback=errback)", "response": "Load an existing Scope Group by name and service group id into a high level Scope Group object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new Scope Group", "response": "def createScopeGroup(self, name, service_group_id, dhcp4, dhcp6, callback=None, errback=None):\n        \"\"\"\n        Create a new Scope Group\n        For the list of keywords available, see :attr:`ns1.rest.ipam.ScopeGroups.INT_FIELDS` and :attr:`ns1.rest.ipam.ScopeGroups.PASSTHRU_FIELDS`\n\n        :param str name: Name of the Scope Group to be created\n        :param int service_group_id: id of the service group the Scope group is associated with\n        :param ns1.ipam.DHCPIOptions dhcp4: DHCPOptions object that contains the options for dhcpv4\n        :param ns1.ipam.DHCPIOptions dhcp6: DHCPOptions object that contains the options for dhcpv6\n        \"\"\"\n        import ns1.ipam\n        scope_group = ns1.ipam.Scopegroup(self.config, name=name, service_group_id=service_group_id)\n        return scope_group.create(dhcp4=dhcp4, dhcp6=dhcp6, callback=callback, errback=errback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating boilerplate dictionary to hold dhcp options for given address family", "response": "def generateDHCPOptionsTemplate(self, address_family):\n        \"\"\"\n        Generate boilerplate dictionary to hold dhcp options\n\n        :param str address_family: dhcpv4 or dhcpv6\n        :return: dict containing valid option set for address family\n        \"\"\"\n        from ns1.ipam import DHCPOptions\n        options = {}\n        for option in DHCPOptions.OPTIONS[address_family]:\n            options[option] = \"\"\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a high level DHCPOptions object for the given address family and options.", "response": "def loadDHCPOptions(self, address_family, options):\n        \"\"\"\n        Create a high level DHCPOptions object\n\n        :param str address_family: Address family of the options. Can be either dhcpv4 or dhcpv6\n        :param dict options: Dictionary containing the option set to apply for this address family. Note: only those specified will be applied. Allowed options can be found in :attr:`ns1.ipam.DHCPOptions.OPTIONS`\n        \"\"\"\n        import ns1.ipam\n        return ns1.ipam.DHCPOptions(address_family, options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fill_tree(comments):\n    if not comments:\n        return\n\n    it = iter(comments)\n    first = next(it)\n    extra_path_items = imap(_mark_as_root_path, first.root_path)\n    return chain(extra_path_items, [first], it)", "response": "Fill in the tree with the comments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef annotate_tree_properties(comments):\n    if not comments:\n        return\n\n    it = iter(comments)\n\n    # get the first item, this will fail if no items !\n    old = next(it)\n\n    # first item starts a new thread\n    old.open = True\n    last = set()\n    for c in it:\n        # if this comment has a parent, store its last child for future reference\n        if old.last_child_id:\n            last.add(old.last_child_id)\n\n        # this is the last child, mark it\n        if c.pk in last:\n            c.last = True\n\n        # increase the depth\n        if c.depth > old.depth:\n            c.open = True\n\n        else:  # c.depth <= old.depth\n            # close some depths\n            old.close = list(range(old.depth - c.depth))\n\n            # new thread\n            if old.root_id != c.root_id:\n                # close even the top depth\n                old.close.append(len(old.close))\n                # and start a new thread\n                c.open = True\n                # empty the last set\n                last = set()\n        # iterate\n        yield old\n        old = c\n\n    old.close = range(old.depth)\n    yield old", "response": "iterate through nodes and adds some magic properties to each of them\n    representing opening list of children and closing list of children and closing it\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun SPAdes on all kmers. Each a separate run because SPAdes dies if any kmer does not work.", "response": "def run_spades(self, stop_at_first_success=False):\n        '''Runs spades on all kmers. Each a separate run because SPAdes dies if any kmer does\n           not work. Chooses the 'best' assembly to be the one with the biggest N50'''\n        n50 = {}\n        kmer_to_dir = {}\n\n        for k in self.spades_kmers:\n            tmpdir = tempfile.mkdtemp(prefix=self.outdir + '.tmp.spades.' + str(k) + '.', dir=os.getcwd())\n            kmer_to_dir[k] = tmpdir\n            ok, errs = self.run_spades_once(k, tmpdir)\n            if ok:\n                contigs_fasta = os.path.join(tmpdir, 'contigs.fasta')\n                contigs_fai = contigs_fasta + '.fai'\n                common.syscall(self.samtools.exe() + ' faidx ' + contigs_fasta, verbose=self.verbose)\n                stats = pyfastaq.tasks.stats_from_fai(contigs_fai)\n                if stats['N50'] != 0:\n                    n50[k] = stats['N50']\n\n                    if stop_at_first_success:\n                        break\n\n        if len(n50) > 0:\n            if self.verbose:\n                print('[assemble]\\tkmer\\tN50')\n                for k in sorted(n50):\n                    print('[assemble]', k, n50[k], sep='\\t')\n\n            best_k = None\n\n            for k in sorted(n50):\n                if best_k is None or n50[k] >= n50[best_k]:\n                    best_k = k\n\n            assert best_k is not None\n\n            for k, directory in kmer_to_dir.items():\n                if k == best_k:\n                    if self.verbose:\n                        print('[assemble] using assembly with kmer', k)\n                    os.rename(directory, self.outdir)\n                else:\n                    shutil.rmtree(directory)\n        else:\n            raise Error('Error running SPAdes. Output directories are:\\n  ' + '\\n  '.join(kmer_to_dir.values()) + '\\nThe reason why should be in the spades.log file in each directory.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_canu(self):\n        '''Runs canu instead of spades'''\n        cmd = self._make_canu_command(self.outdir,'canu')\n        ok, errs = common.syscall(cmd, verbose=self.verbose, allow_fail=False)\n        if not ok:\n            raise Error('Error running Canu.')\n\n        original_contigs = os.path.join(self.outdir, 'canu.contigs.fasta')\n        renamed_contigs = os.path.join(self.outdir, 'contigs.fasta')\n        Assembler._rename_canu_contigs(original_contigs, renamed_contigs)\n        original_gfa = os.path.join(self.outdir, 'canu.contigs.gfa')\n        renamed_gfa = os.path.join(self.outdir, 'contigs.gfa')\n        os.rename(original_gfa, renamed_gfa)", "response": "Runs canu instead of spades"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef aligned_read_to_read(read, revcomp=True, qual=None, ignore_quality=False):\n    '''Returns Fasta or Fastq sequence from pysam aligned read'''\n    if read.qual is None or ignore_quality:\n        if qual is None or ignore_quality:\n            seq = pyfastaq.sequences.Fasta(read.qname, common.decode(read.seq))\n        else:\n            seq = pyfastaq.sequences.Fastq(read.qname, common.decode(read.seq), qual * read.query_length)\n    else:\n        if qual is None:\n            seq = pyfastaq.sequences.Fastq(read.qname, common.decode(read.seq), common.decode(read.qual))\n        else:\n            seq = pyfastaq.sequences.Fastq(read.qname, common.decode(read.seq), qual * read.query_length)\n\n    if read.is_reverse and revcomp:\n        seq.revcomp()\n\n    return seq", "response": "Returns Fasta or Fastq sequence from pysam aligned read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_ref_lengths(self):\n        '''Gets the length of each reference sequence from the header of the bam. Returns dict name => length'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        return dict(zip(sam_reader.references, sam_reader.lengths))", "response": "Gets the length of each reference sequence from the header of the bam. Returns dict name => length"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a set of contigs that are to be used by the database.", "response": "def _get_contigs_to_use(self, contigs_to_use):\n        '''If contigs_to_use is a set, returns that set. If it's None, returns an empty set.\n        Otherwise, assumes it's a file name, and gets names from the file'''\n        if type(contigs_to_use) == set:\n            return contigs_to_use\n        elif contigs_to_use is None:\n            return set()\n        else:\n            f = pyfastaq.utils.open_file_read(contigs_to_use)\n            contigs_to_use = set([line.rstrip() for line in f])\n            pyfastaq.utils.close(f)\n            return contigs_to_use"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_contigs_to_use(self, ref_dict):\n        '''Checks that the set of contigs to use are all in the reference\n        fasta lengths dict made by self._get_ref_lengths()'''\n        if self.contigs_to_use is None:\n            return True\n\n        for contig in self.contigs_to_use:\n            if contig not in ref_dict:\n                raise Error('Requested to use contig \"' + contig + '\", but not found in input BAM file \"' + self.bam + '\"')\n\n        return True", "response": "Checks that the set of contigs to use are all in the reference\n        fasta lengths dict made by self. _get_ref_lengths"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _all_reads_from_contig(self, contig, fout):\n        '''Gets all reads from contig called \"contig\" and writes to fout'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        for read in sam_reader.fetch(contig):\n            print(mapping.aligned_read_to_read(read, ignore_quality=not self.fastq_out), file=fout)", "response": "Gets all reads from contig and writes to fout"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading all unmapped reads from the bam and writes them to fout", "response": "def _get_all_unmapped_reads(self, fout):\n        '''Writes all unmapped reads to fout'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        for read in sam_reader.fetch(until_eof=True):\n            if read.is_unmapped:\n                print(mapping.aligned_read_to_read(read, ignore_quality=not self.fastq_out), file=fout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _break_reads(self, contig, position, fout, min_read_length=250):\n        '''Get all reads from contig, but breaks them all at given position (0-based) in the reference. Writes to fout. Currently pproximate where it breaks (ignores indels in the alignment)'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        for read in sam_reader.fetch(contig):\n            seqs = []\n            if read.pos < position < read.reference_end - 1:\n                split_point = position - read.pos\n                if split_point - 1 >= min_read_length:\n                    sequence = mapping.aligned_read_to_read(read, revcomp=False, ignore_quality=not self.fastq_out).subseq(0, split_point)\n                    sequence.id += '.left'\n                    seqs.append(sequence)\n                if read.query_length - split_point >= min_read_length:\n                    sequence = mapping.aligned_read_to_read(read, revcomp=False, ignore_quality=not self.fastq_out).subseq(split_point, read.query_length)\n                    sequence.id += '.right'\n                    seqs.append(sequence)\n            else:\n                seqs.append(mapping.aligned_read_to_read(read, revcomp=False, ignore_quality=not self.fastq_out))\n\n            for seq in seqs:\n                if read.is_reverse:\n                    seq.revcomp()\n                print(seq, file=fout)", "response": "Get all reads from contig but breaks them all at given position. Writes to fout. Currently pproximate where it breaks ( ignores indels in the alignment )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _exclude_region(self, contig, start, end, fout):\n        '''Writes reads not mapping to the given region of contig, start and end as per python convention'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        exclude_interval = pyfastaq.intervals.Interval(start, end - 1)\n        for read in sam_reader.fetch(contig):\n            read_interval = pyfastaq.intervals.Interval(read.pos, read.reference_end - 1)\n            if not read_interval.intersects(exclude_interval):\n                print(mapping.aligned_read_to_read(read, ignore_quality=not self.fastq_out), file=fout)", "response": "Writes reads not mapping to the given region of contig start and end as per python convention"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_region(self, contig, start, end, fout, min_length=250):\n        '''Writes reads mapping to given region of contig, trimming part of read not in the region'''\n        sam_reader = pysam.Samfile(self.bam, \"rb\")\n        trimming_end = (start == 0)\n        for read in sam_reader.fetch(contig, start, end):\n            read_interval = pyfastaq.intervals.Interval(read.pos, read.reference_end - 1)\n            seq = mapping.aligned_read_to_read(read, ignore_quality=not self.fastq_out, revcomp=False)\n\n            if trimming_end:\n                bases_off_start = 0\n                bases_off_end = max(0, read.reference_end - 1 - end)\n                #seq.seq = seq.seq[:read.query_alignment_end - bases_off_end]\n                seq = seq.subseq(0, read.query_alignment_end - bases_off_end)\n            else:\n                bases_off_start = max(0, start - read.pos + 1)\n                #seq.seq = seq.seq[bases_off_start  + read.query_alignment_start:]\n                seq = seq.subseq(bases_off_start  + read.query_alignment_start, len(seq))\n\n            if read.is_reverse:\n                seq.revcomp()\n\n            if len(seq) >= min_length:\n                print(seq, file=fout)", "response": "Writes reads mapping to given region of contig"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of names from file called filename.", "response": "def _get_contigs_to_keep(self, filename):\n        '''Returns a set of names from file called filename. If filename is None, returns an empty set'''\n        if filename is None:\n            return set()\n\n        with open(filename) as f:\n            return {line.rstrip() for line in f}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading nucmer hits from a file.", "response": "def _load_nucmer_hits(self, infile):\n        '''Returns two dictionaries:\n           1) name=>contig length.\n           2) Second is dictionary of nucmer hits (ignoring self matches).\n              contig name => list of hits'''\n        hits = {}\n        lengths = {}\n        file_reader = pymummer.coords_file.reader(infile)\n        for al in file_reader:\n            if al.qry_name == al.ref_name:\n                continue\n            elif al.qry_name not in hits:\n                hits[al.qry_name] = []\n            hits[al.qry_name].append(al)\n            lengths[al.qry_name] = al.qry_length\n            lengths[al.ref_name] = al.ref_length\n        return lengths, hits"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _contains(self, hit):\n        '''Returns True iff (the query contig is contained in the reference contig and\n           the query contig is not flagged to be kept)'''\n        return (\n            hit.qry_name not in self.contigs_to_keep\n            and hit.qry_name != hit.ref_name\n            and (100 * hit.hit_length_qry / hit.qry_length >= self.min_contig_percent_match)\n            and hit.percent_identity >= self.nucmer_min_id\n        )", "response": "Returns True iff the query contig is contained in the reference contig and\n           the query contig is not flagged to be kept"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _containing_contigs(self, hits):\n        '''Given a list of hits, all with same query,\n           returns a set of the contigs containing that query'''\n        return {hit.ref_name for hit in hits if self._contains(hit)}", "response": "Given a list of hits all with same query returns a set of the contigs containing that query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a dictionary of nucmer hits returns a dictionary. key = contig name. Value = set of contigs that contain the key.", "response": "def _get_containing_contigs(self, hits_dict):\n        '''Given dictionary of nucmer hits (made by self._load_nucmer_hits()), returns a dictionary.\n           key=contig name. Value = set of contigs that contain the key.'''\n        containing = {}\n\n        for qry_name in hits_dict:\n            d = self._containing_contigs(hits_dict[qry_name])\n            if len(d):\n                containing[qry_name] = d\n\n        return containing"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_all_containing(self, containing_contigs, name, exclude=None, max_depth=10):\n        '''containing_contigs is a dict:\n             key=contig name. Value = set of contigs that contain the key.\n           Returns alls contigs called \"name\" that contain that contig'''\n        contains_name = set()\n\t\t\n        # failsafe to prevent infinite recursion\n        if max_depth < 0:\n            return contains_name\n\t\t\n        if name in containing_contigs:\n            for containing_contig in containing_contigs[name]:\n                # if we have a contains b and b contains a, then this stops infinite recursion\n                if containing_contig==exclude:\n                    continue\n                contains_name.add(containing_contig)\n                new_names = self._get_all_containing(containing_contigs, containing_contig, exclude=name,max_depth=max_depth-1)\n                new_names.discard(name)\n                contains_name.update(new_names)\n        return contains_name", "response": "Returns alls contigs called name that contain that contig"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _expand_containing_using_transitivity(self, containing_contigs):\n        '''This uses a contined in b, and b contained in c to force a contained in c.\n           Just in case a contained in c wasn't already found by nucmer'''\n        for name in containing_contigs:\n            containing_contigs[name] = self._get_all_containing(containing_contigs, name)\n        return containing_contigs", "response": "Expand all continues of a set of contigs using transititivity."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninputs is a list of sets. Merges any intersecting sets in the list.", "response": "def _collapse_list_of_sets(self, sets):\n        '''Input is a list of sets. Merges any intersecting sets in the list'''\n        found = True\n        while found:\n            found = False\n            to_intersect = None\n            for i in range(len(sets)):\n                for j in range(len(sets)):\n                    if i == j:\n                        continue\n                    elif sets[i].intersection(sets[j]):\n                        to_intersect = i, j\n                        break\n\n                if to_intersect is not None:\n                    break\n\n            if to_intersect is not None:\n                found = True\n                sets[i].update(sets[j])\n                sets.pop(j)\n\n        return sets"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of sets of contigs that are equivalent to the given key.", "response": "def _get_identical_contigs(self, hits_dict):\n        '''Input is a dict:\n             key=contig name. Value = set of contigs that contain the key.\n           Returns a list of sets of contigs that are equivalent'''\n        equivalent_contigs = []\n\n        for qry_name, containing in hits_dict.items():\n            equivalent = set()\n            for containing_name in containing:\n                if containing_name in hits_dict and qry_name in hits_dict[containing_name]:\n                    equivalent.add(containing_name)\n                    equivalent.add(qry_name)\n\n            if len(equivalent):\n                equivalent_contigs.append(equivalent)\n                equivalent_contigs = self._collapse_list_of_sets(equivalent_contigs)\n\n        return equivalent_contigs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _longest_contig(self, contig_set, contig_lengths):\n        '''Returns the name of the longest contig, from the set of names contig_set. contig_lengths\n           is expected to be a dictionary of contig name => length.'''\n        longest_name = None\n        max_length = -1\n        for name in contig_set:\n            if contig_lengths[name] > max_length:\n                longest_name = name\n                max_length = contig_lengths[name]\n        assert max_length != -1\n        assert longest_name is not None\n        return longest_name", "response": "Returns the name of the longest contig from the set of names contig_set. contig_lengths\n           is expected to be a dictionary of contig name => length."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_identical_contigs(self, containing_contigs, contig_lengths):\n        '''Input is dictionary of containing contigs made by self._expand_containing_using_transitivity().\n           Removes redundant identical contigs, leaving one representative (the longest) of\n           each set of identical contigs.\n           Returns new version of dictionary, and a dictionary of contig name => contig it was replaced with'''\n        identical_contigs = self._get_identical_contigs(containing_contigs)\n        to_replace = {}  # contig name => name to replace it with\n        for contig_set in identical_contigs:\n            longest_contig = self._longest_contig(contig_set, contig_lengths)\n            for name in contig_set - {longest_contig}:\n                assert name not in to_replace\n                to_replace[name] = longest_contig\n\n        for name, replace_with in to_replace.items():\n            if replace_with not in containing_contigs:\n                containing_contigs[replace_with] = set()\n\n            if name in containing_contigs:\n                containing_contigs[replace_with].update(containing_contigs[name])\n                del containing_contigs[name]\n\n        to_delete = set()\n\n        for name, names_set in containing_contigs.items():\n            assert name not in to_replace\n            new_set = {to_replace.get(x, x) for x in names_set}\n            new_set.discard(name)\n            if len(new_set) > 0:\n                containing_contigs[name] = new_set\n            else:\n                to_delete.add(name)\n\n        for name in to_delete:\n            del containing_contigs[name]\n\n        return containing_contigs, to_replace", "response": "Remove redundant identical contigs from the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_files_exist(filenames):\n    '''Dies if any files in the list of filenames does not exist'''\n    files_not_found = [x for x in filenames if not os.path.exists(x)]\n    if len(files_not_found):\n        for filename in files_not_found:\n            print('File not found: \"', filename, '\"', sep='', file=sys.stderr)\n        raise Error('File(s) not found. Cannot continue')", "response": "Dies if any files in the list of filenames does not exist'''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_contigs(self):\n        '''Returns a dictionary of contig_name -> pyfastaq.Sequences.Fasta object'''\n        contigs = {}\n        pyfastaq.tasks.file_to_dict(self.contigs_fasta, contigs)\n        return contigs", "response": "Returns a dictionary of contig_name -> pyfastaq. Fasta object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a set of the contig names that are circular", "response": "def circular_contigs(self):\n        '''Returns a set of the contig names that are circular'''\n        if self.assembler == 'spades':\n            if self.contigs_fastg is not None:\n                return self._circular_contigs_from_spades_before_3_6_1(self.contigs_fastg)\n            elif None not in [self.contigs_paths, self.assembly_graph_fastg]:\n                return self._circular_contigs_from_spades_after_3_6_1(self.assembly_graph_fastg, self.contigs_paths)\n            else:\n                return set()\n        elif self.assembler == 'canu':\n            return self._circular_contigs_from_canu_gfa(self.contigs_gfa)\n        else:\n            return set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_nucmer(self, ref, qry, outfile):\n        '''Run nucmer of new assembly vs original assembly'''\n        n = pymummer.nucmer.Runner(\n            ref,\n            qry,\n            outfile,\n            min_id=self.nucmer_min_id,\n            min_length=self.nucmer_min_length,\n            diagdiff=self.nucmer_diagdiff,\n            maxmatch=True,\n            breaklen=self.nucmer_breaklen,\n            simplify=True,\n            verbose=self.verbose\n        )\n        n.run()", "response": "Run nucmer of new assembly vs original assembly"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_nucmer_hits(self, infile):\n        '''Returns dict ref name => list of nucmer hits from infile'''\n        hits = {}\n        file_reader = pymummer.coords_file.reader(infile)\n        for al in file_reader:\n            if al.ref_name not in hits:\n                hits[al.ref_name] = []\n            hits[al.ref_name].append(al)\n        return hits", "response": "Returns dict ref name => list of nucmer hits from infile"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninputs list of nucmer hits. Output: dictionary keys are query names values are lists of hits", "response": "def _hits_hashed_by_query(self, hits):\n        '''Input: list of nucmer hits. Output: dictionary, keys are query names, values are lists of hits'''\n        d = {}\n        for hit in hits:\n            if hit.qry_name not in d:\n                d[hit.qry_name] = []\n            d[hit.qry_name].append(hit)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_longest_hit_by_ref_length(self, nucmer_hits):\n        '''Input: list of nucmer hits. Returns the longest hit, taking hit length on the reference'''\n        if len(nucmer_hits) == 0:\n            return None\n\n        max_length = None\n        longest_hit = None\n        for hit in nucmer_hits:\n            if max_length is None or hit.hit_length_ref > max_length:\n                max_length = hit.hit_length_ref\n                longest_hit = copy.copy(hit)\n\n        assert longest_hit is not None\n        return longest_hit", "response": "Returns the longest hit that is taking hit length on the reference"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True iff the hit is close enough to the start of the reference sequence", "response": "def _is_at_ref_start(self, nucmer_hit):\n        '''Returns True iff the hit is \"close enough\" to the start of the reference sequence'''\n        hit_coords = nucmer_hit.ref_coords()\n        return hit_coords.start < self.ref_end_tolerance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_at_ref_end(self, nucmer_hit):\n        '''Returns True iff the hit is \"close enough\" to the end of the reference sequence'''\n        hit_coords = nucmer_hit.ref_coords()\n        return hit_coords.end >= nucmer_hit.ref_length - self.ref_end_tolerance", "response": "Returns True iff the hit is close enough to the end of the reference sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True iff the hit is close enough to the start of the query sequence", "response": "def _is_at_qry_start(self, nucmer_hit):\n        '''Returns True iff the hit is \"close enough\" to the start of the query sequence'''\n        hit_coords = nucmer_hit.qry_coords()\n        return hit_coords.start < self.qry_end_tolerance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True iff the hit is close enough to the end of the query sequence", "response": "def _is_at_qry_end(self, nucmer_hit):\n        '''Returns True iff the hit is \"close enough\" to the end of the query sequence'''\n        hit_coords = nucmer_hit.qry_coords()\n        return hit_coords.end >= nucmer_hit.qry_length - self.qry_end_tolerance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_hit_nearest_ref_start(self, hits):\n        '''Returns the hit nearest to the start of the ref sequence from the input list of hits'''\n        nearest_to_start = hits[0]\n        for hit in hits[1:]:\n            if hit.ref_coords().start < nearest_to_start.ref_coords().start:\n                nearest_to_start = hit\n        return nearest_to_start", "response": "Returns the hit nearest to the start of the ref sequence from the input list of hits"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the hit nearest to the end of the ref sequence from the input list of hits", "response": "def _get_hit_nearest_ref_end(self, hits):\n        '''Returns the hit nearest to the end of the ref sequence from the input list of hits'''\n        nearest_to_end = hits[0]\n        for hit in hits[1:]:\n            if hit.ref_coords().end > nearest_to_end.ref_coords().end:\n                nearest_to_end = hit\n        return nearest_to_end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the longest hit to the start of the reference.", "response": "def _get_longest_hit_at_ref_start(self, nucmer_hits, hits_to_exclude=None):\n        '''Input: list of nucmer hits to the same reference. Returns the longest hit to the start of the reference, or None if there is no such hit'''\n        if hits_to_exclude is None:\n            hits_to_exclude = set()\n        hits_at_start = [hit for hit in nucmer_hits if self._is_at_ref_start(hit) and hit not in hits_to_exclude]\n        return self._get_longest_hit_by_ref_length(hits_at_start)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the longest hit to the end of the reference.", "response": "def _get_longest_hit_at_ref_end(self, nucmer_hits, hits_to_exclude=None):\n        '''Input: list of nucmer hits to the same reference. Returns the longest hit to the end of the reference, or None if there is no such hit'''\n        if hits_to_exclude is None:\n            hits_to_exclude = set()\n        hits_at_end = [hit for hit in nucmer_hits if self._is_at_ref_end(hit) and hit not in hits_to_exclude]\n        return self._get_longest_hit_by_ref_length(hits_at_end)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_longest_hit_at_qry_start(self, nucmer_hits):\n        '''Input: list of nucmer hits to the same query. Returns the longest hit to the start of the query, or None if there is no such hit'''\n        hits_at_start = [hit for hit in nucmer_hits if self._is_at_qry_start(hit)]\n        return self._get_longest_hit_by_ref_length(hits_at_start)", "response": "Returns the longest hit to the start of the query"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninput : list of nucmer hits to the same query. Returns the longest hit to the end of the query or None if there is no such hit", "response": "def _get_longest_hit_at_qry_end(self, nucmer_hits):\n        '''Input: list of nucmer hits to the same query. Returns the longest hit to the end of the query, or None if there is no such hit'''\n        hits_at_end = [hit for hit in nucmer_hits if self._is_at_qry_end(hit)]\n        return self._get_longest_hit_by_ref_length(hits_at_end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _has_qry_hit_longer_than(self, nucmer_hits, min_length, hits_to_exclude=None):\n        '''Returns True iff list of nucmer_hits has a hit longer than min_length, not counting the hits in hits_to_exclude'''\n        if hits_to_exclude is None:\n            to_exclude = set()\n        else:\n            to_exclude = hits_to_exclude\n        long_hits = [hit.hit_length_qry for hit in nucmer_hits if hit not in to_exclude and hit.hit_length_qry > min_length]\n        return len(long_hits) > 0", "response": "Returns True iff list of nucmer_hits has a hit longer than min_length not counting the hits in hits_to_exclude"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _can_circularise(self, start_hit, end_hit):\n        '''Returns true iff the two hits can be used to circularise the reference sequence of the hits'''\n        if not(self._is_at_ref_start(start_hit) or self._is_at_ref_end(end_hit)):\n            return False\n\n        if self._is_at_qry_end(start_hit) \\\n          and self._is_at_qry_start(end_hit) \\\n          and start_hit.on_same_strand() \\\n          and end_hit.on_same_strand():\n            return True\n\n        if self._is_at_qry_start(start_hit) \\\n          and self._is_at_qry_end(end_hit) \\\n          and (not start_hit.on_same_strand()) \\\n          and (not end_hit.on_same_strand()):\n            return True\n\n        return False", "response": "Returns true iff the two hits can be circularised the reference sequence of the hits"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict ref name = > tuple", "response": "def _get_possible_circular_ref_contigs(self, nucmer_hits, log_fh=None, log_outprefix=None):\n        '''Returns a dict ref name => tuple(hit at start, hit at end) for each ref sequence in the hash nucmer_hits (each value is a list of nucmer hits)'''\n        writing_log_file = None not in [log_fh, log_outprefix]\n        maybe_circular = {}\n        all_nucmer_hits = []\n        for l in nucmer_hits.values():\n            all_nucmer_hits.extend(l)\n        nucmer_hits_by_qry = self._hits_hashed_by_query(all_nucmer_hits)\n\n        for ref_name, list_of_hits in nucmer_hits.items():\n            if writing_log_file:\n                print(log_outprefix, ref_name, 'Checking ' + str(len(list_of_hits)) + ' nucmer hits', sep='\\t', file=log_fh)\n\n            longest_start_hit = self._get_longest_hit_at_ref_start(list_of_hits)\n            longest_end_hit = self._get_longest_hit_at_ref_end(list_of_hits)\n            if longest_start_hit == longest_end_hit:\n                second_longest_start_hit = self._get_longest_hit_at_ref_start(list_of_hits, hits_to_exclude={longest_start_hit})\n                second_longest_end_hit = self._get_longest_hit_at_ref_end(list_of_hits, hits_to_exclude={longest_end_hit})\n                if second_longest_start_hit is not None:\n                    longest_start_hit = self._get_hit_nearest_ref_start([longest_start_hit, second_longest_start_hit])\n                if second_longest_end_hit is not None:\n                    longest_end_hit = self._get_hit_nearest_ref_end([longest_end_hit, second_longest_end_hit])\n\n            if (\n              longest_start_hit is not None\n              and longest_end_hit is not None\n              and longest_start_hit != longest_end_hit\n              and self._hits_have_same_query(longest_start_hit, longest_end_hit)\n            ):\n                if writing_log_file:\n                    print(log_outprefix, ref_name, 'potential pair of nucmer hits for circularization:', sep='\\t', file=log_fh)\n                    print(log_outprefix, ref_name, '', longest_start_hit, sep='\\t', file=log_fh)\n                    print(log_outprefix, ref_name, '', longest_end_hit, sep='\\t', file=log_fh)\n\n                shortest_hit_length = self._min_qry_hit_length([longest_start_hit, longest_end_hit])\n                has_longer_hit = self._has_qry_hit_longer_than(\n                    nucmer_hits_by_qry[longest_start_hit.qry_name],\n                    shortest_hit_length,\n                    hits_to_exclude={longest_start_hit, longest_end_hit}\n                )\n\n                if writing_log_file and has_longer_hit:\n                    print(log_outprefix, ref_name, 'cannot use this pair because longer match was found', sep='\\t', file=log_fh)\n\n                can_circularise = self._can_circularise(longest_start_hit, longest_end_hit)\n\n                if writing_log_file and not can_circularise:\n                    print(log_outprefix, ref_name, 'cannot use this pair because positions/orientations of matches no good', sep='\\t', file=log_fh)\n\n                if (not has_longer_hit) and can_circularise:\n                    print(log_outprefix, ref_name, 'can use this pair of hits', sep='\\t', file=log_fh)\n                    maybe_circular[ref_name] = (longest_start_hit, longest_end_hit)\n\n        return maybe_circular"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _remove_keys_from_dict_with_nonunique_values(self, d, log_fh=None, log_outprefix=None):\n        '''Returns a new dictionary, with keys from input dict removed if their value was not unique'''\n        value_counts = collections.Counter(d.values())\n        new_d = {}\n        writing_log_file = None not in [log_fh, log_outprefix]\n\n        for key in d:\n            if value_counts[d[key]] == 1:\n                new_d[key] = d[key]\n            elif writing_log_file:\n                print(log_outprefix, 'Reject because non-unique:', d[key], sep='\\t', file=log_fh)\n\n        return new_d", "response": "Returns a new dictionary with keys from input dict removed if their value was not unique"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_circularised_contig(self, ref_start_hit, ref_end_hit):\n        '''Given a nucmer ref_start_hit and ref_end_hit, returns a new contig. Assumes that these hits can be used to circularise the reference contig of the hits using the query contig'''\n        assert ref_start_hit.ref_name == ref_end_hit.ref_name\n        assert ref_start_hit.qry_name == ref_end_hit.qry_name\n\n\n        qry_name = ref_start_hit.qry_name\n        ref_name = ref_start_hit.ref_name\n        ref_start_coords = ref_start_hit.ref_coords()\n        ref_end_coords = ref_end_hit.ref_coords()\n\n        if ref_start_coords.intersects(ref_end_coords):\n            new_ctg = copy.copy(self.reassembly_contigs[qry_name])\n            new_ctg.id = ref_name\n            return new_ctg\n\n        if ref_start_hit.on_same_strand():\n            qry_start_coords = ref_end_hit.qry_coords()\n            qry_end_coords = ref_start_hit.qry_coords()\n            bases = self.original_contigs[ref_name][ref_start_coords.end+1:ref_end_coords.start] + \\\n                    self.reassembly_contigs[qry_name][qry_start_coords.start:qry_end_coords.end+1]\n            return pyfastaq.sequences.Fasta(ref_name, bases)\n        else:\n            qry_start_coords = ref_start_hit.qry_coords()\n            qry_end_coords = ref_end_hit.qry_coords()\n            tmp_seq = pyfastaq.sequences.Fasta('x', self.reassembly_contigs[qry_name][qry_start_coords.start:qry_end_coords.end+1])\n            tmp_seq.revcomp()\n            return pyfastaq.sequences.Fasta(ref_name, self.original_contigs[ref_name][ref_start_coords.end+1:ref_end_coords.start] + tmp_seq.seq)", "response": "Given a nucmer ref_start_hit and ref_end_hit returns a new contig. Assumes that these hits can be used to circularise the reference contig of the hits using the query contig."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True iff the orientation of the hits means that the query contig of both hits can bridge the reference contigs of the hits", "response": "def _orientation_ok_to_bridge_contigs(self, start_hit, end_hit):\n        '''Returns True iff the orientation of the hits means that the query contig of both hits can bridge the reference contigs of the hits'''\n        assert start_hit.qry_name == end_hit.qry_name\n        if start_hit.ref_name == end_hit.ref_name:\n            return False\n\n        if (\n            (self._is_at_ref_end(start_hit) and start_hit.on_same_strand())\n            or (self._is_at_ref_start(start_hit) and not start_hit.on_same_strand())\n        ):\n            start_hit_ok = True\n        else:\n            start_hit_ok = False\n\n        if (\n            (self._is_at_ref_start(end_hit) and end_hit.on_same_strand())\n            or (self._is_at_ref_end(end_hit) and not end_hit.on_same_strand())\n        ):\n            end_hit_ok = True\n        else:\n            end_hit_ok = False\n\n        return start_hit_ok and end_hit_ok"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting possible query bridging contigs.", "response": "def _get_possible_query_bridging_contigs(self, nucmer_hits, log_fh=None, log_outprefix=None):\n        '''Input is dict qry_name -> list of nucmer hits to that qry. Returns dict qry_name -> tuple(start hit, end hit)'''\n        bridges = {}\n        writing_log_file = None not in [log_fh, log_outprefix]\n\n        for qry_name, hits_to_qry in nucmer_hits.items():\n            if len(hits_to_qry) < 2:\n                continue\n\n            if writing_log_file:\n                print(log_outprefix, '\\t', qry_name, ': checking nucmer matches', sep='', file=log_fh)\n\n            longest_start_hit = self._get_longest_hit_at_qry_start(hits_to_qry)\n            longest_end_hit = self._get_longest_hit_at_qry_end(hits_to_qry)\n\n            if (\n                None in (longest_start_hit, longest_end_hit)\n              or longest_start_hit.ref_name == longest_end_hit.ref_name\n              or self._hits_have_same_reference(longest_start_hit, longest_end_hit)\n            ):\n                if writing_log_file:\n                    print(log_outprefix, '\\t', qry_name, ': no potential pairs of hits to merge contigs', sep='', file=log_fh)\n                continue\n\n            if writing_log_file:\n                print(log_outprefix, '\\t', qry_name, ': potential pair of hits to merge contigs...', sep='', file=log_fh)\n                print(log_outprefix, '\\t', qry_name, ':    ', longest_start_hit, sep='', file=log_fh)\n                print(log_outprefix, '\\t', qry_name, ':    ', longest_end_hit, sep='', file=log_fh)\n\n            shortest_hit_length = self._min_qry_hit_length([longest_start_hit, longest_end_hit])\n            has_longer_hit = self._has_qry_hit_longer_than(\n                hits_to_qry,\n                shortest_hit_length,\n                hits_to_exclude={longest_start_hit, longest_end_hit}\n            )\n\n            if has_longer_hit and writing_log_file:\n                print(log_outprefix, '\\t', qry_name, ':    rejected - there is a longer hit to elsewhere', sep='', file=log_fh)\n\n            orientation_ok = self._orientation_ok_to_bridge_contigs(longest_start_hit, longest_end_hit)\n\n            if writing_log_file and not orientation_ok:\n                print(log_outprefix, '\\t', qry_name, ':    rejected - orientation/distance from ends not correct to make a merge', sep='', file=log_fh)\n\n            if orientation_ok and not has_longer_hit:\n                if writing_log_file:\n                    print(log_outprefix, '\\t', qry_name, ':    might be used - no longer hits elsewhere and orientation/distance to ends OK', sep='', file=log_fh)\n                bridges[qry_name] = (longest_start_hit, longest_end_hit)\n\n        return bridges"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter out the bridges that are not in the ref contigs.", "response": "def _filter_bridging_contigs(self, bridges):\n        '''Input is dict qry_name -> tuple(start hit, end hit) made by _get_possible_query_bridging_contigs. Removes key/values where the value(==ref contig) has a hit at the start, or at the end, to more than one key(==qry contig)'''\n        ref_hits_start = {}\n        ref_hits_end = {}\n        for qry_name, (start_hit, end_hit) in bridges.items():\n            for hit in start_hit, end_hit:\n                assert self._is_at_ref_start(hit) or self._is_at_ref_end(hit)\n                if self._is_at_ref_start(hit):\n                    ref_hits_start[hit.ref_name] = ref_hits_start.get(hit.ref_name, 0) + 1\n                elif self._is_at_ref_end(hit):\n                    ref_hits_end[hit.ref_name] = ref_hits_end.get(hit.ref_name, 0) + 1\n\n        qry_names_to_remove = set()\n\n        for qry_name, (start_hit, end_hit) in bridges.items():\n            for hit in start_hit, end_hit:\n                remove = False\n                if (\n                  (self._is_at_ref_start(hit) and ref_hits_start.get(hit.ref_name, 0) > 1)\n                  or (self._is_at_ref_end(hit) and ref_hits_end.get(hit.ref_name, 0) > 1)\n                ):\n                    qry_names_to_remove.add(qry_name)\n\n        for name in qry_names_to_remove:\n            del bridges[name]\n\n        return bridges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _merge_all_bridged_contigs(self, nucmer_hits, ref_contigs, qry_contigs, log_fh=None, log_outprefix=None):\n        '''Input is dict of nucmer_hits. Makes any possible contig merges.\n           Returns True iff any merges were made'''\n        writing_log_file = None not in [log_fh, log_outprefix]\n\n        if len(nucmer_hits) == 0:\n            if writing_log_file:\n                print(log_outprefix, 'No nucmer hits, so will not make any merges', sep='\\t', file=log_fh)\n            return\n\n        all_nucmer_hits = []\n        for l in nucmer_hits.values():\n            all_nucmer_hits.extend(l)\n        nucmer_hits_by_qry = self._hits_hashed_by_query(all_nucmer_hits)\n        bridges = self._get_possible_query_bridging_contigs(nucmer_hits_by_qry, log_fh=log_fh, log_outprefix=log_outprefix)\n        if writing_log_file:\n            print(log_outprefix, '\\tPotential contigs to use for merging: ', ' '.join(sorted(bridges.keys())), sep='', file=log_fh)\n        bridges = self._filter_bridging_contigs(bridges)\n        if writing_log_file:\n            print(log_outprefix, '\\tContigs to use for merging after uniqueness filtering: ', ' '.join(sorted(bridges.keys())), sep='', file=log_fh)\n\n        merged = set()\n        made_a_join = False\n\n        for qry_name, (start_hit, end_hit) in bridges.items():\n            if start_hit.ref_name in merged or end_hit.ref_name in merged:\n                continue\n            self._merge_bridged_contig_pair(start_hit, end_hit, ref_contigs, qry_contigs, log_fh=log_fh, log_outprefix=log_outprefix)\n            merged.add(start_hit.ref_name)\n            merged.add(end_hit.ref_name)\n            made_a_join = True\n\n        if writing_log_file:\n            print(log_outprefix, '\\tMade at least one contig join: ', made_a_join, sep='', file=log_fh)\n\n        return made_a_join", "response": "Takes a dict of nucmer_hits. Makes any possible contig merges. Returns True iff any merges were made"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite crunch file and shell script to start up ACT showing comparison of ref and qry", "response": "def _write_act_files(self, ref_fasta, qry_fasta, coords_file, outprefix):\n        '''Writes crunch file and shell script to start up ACT, showing comparison of ref and qry'''\n        if self.verbose:\n            print('Making ACT files from', ref_fasta, qry_fasta, coords_file)\n        ref_fasta = os.path.relpath(ref_fasta)\n        qry_fasta = os.path.relpath(qry_fasta)\n        coords_file = os.path.relpath(coords_file)\n        outprefix = os.path.relpath(outprefix)\n        self._index_fasta(ref_fasta)\n        self._index_fasta(qry_fasta)\n        crunch_file = outprefix + '.crunch'\n        pymummer.coords_file.convert_to_msp_crunch(\n            coords_file,\n            crunch_file,\n            ref_fai=ref_fasta + '.fai',\n            qry_fai=qry_fasta + '.fai'\n        )\n\n        bash_script = outprefix + '.start_act.sh'\n        with open(bash_script, 'w') as f:\n            print('#!/usr/bin/env bash', file=f)\n            print('act', ref_fasta, crunch_file, qry_fasta, file=f)\n\n        pyfastaq.utils.syscall('chmod +x ' + bash_script)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _iterative_bridged_contig_pair_merge(self, outprefix):\n        '''Iteratively merges contig pairs using bridging contigs from reassembly, until no more can be merged'''\n        if self.reads is None:\n            if self.verbose:\n                print('Skipping iterative contig merging because no reads given (see --reads option)')\n            return self.original_fasta, None, None\n\n        log_file = outprefix + '.iterations.log'\n        log_fh = pyfastaq.utils.open_file_write(log_file)\n        genome_fasta = self.original_fasta\n        nucmer_coords = outprefix + '.iter.1.coords'\n        reads_to_map = self.reads\n        act_prefix = None\n        made_a_join = True\n        iteration = 1\n\n        while made_a_join:\n            this_log_prefix = '[' + self.log_prefix + ' iterative_merge ' + str(iteration) + ']'\n            print(this_log_prefix, '\\tUsing nucmer matches from ', nucmer_coords, sep='', file=log_fh)\n            self._run_nucmer(genome_fasta, self.reassembly.contigs_fasta, nucmer_coords)\n            act_prefix = outprefix + '.iter.' + str(iteration)\n            print(this_log_prefix, '\\tYou can view the nucmer matches with ACT using: ./', act_prefix, '.start_act.sh', sep='', file=log_fh)\n            self._write_act_files(genome_fasta, self.reassembly.contigs_fasta, nucmer_coords, act_prefix)\n            nucmer_hits_by_ref = self._load_nucmer_hits(nucmer_coords)\n            made_a_join = self._merge_all_bridged_contigs(nucmer_hits_by_ref, self.original_contigs, self.reassembly_contigs, log_fh, this_log_prefix)\n            iteration += 1\n\n            if made_a_join:\n                print(this_log_prefix, '\\tMade at least one merge. Remapping reads and reassembling',sep='', file=log_fh)\n                nucmer_coords = outprefix + '.iter.' + str(iteration) + '.coords'\n                genome_fasta = outprefix + '.iter.' + str(iteration) + '.merged.fasta'\n                self._contigs_dict_to_file(self.original_contigs, genome_fasta)\n                bam = outprefix + '.iter.' + str(iteration) + '.bam'\n\n                circlator.mapping.bwa_mem(\n                  genome_fasta,\n                  reads_to_map,\n                  bam,\n                  threads=self.threads,\n                  verbose=self.verbose,\n                )\n\n                reads_prefix = outprefix + '.iter.' + str(iteration) + '.reads'\n                reads_to_map =  reads_prefix + ('.fasta' if self.spades_only_assembler else '.fastq')\n                bam_filter = circlator.bamfilter.BamFilter(bam, reads_prefix, fastq_out=not self.spades_only_assembler, split_all_reads=self.split_all_reads)\n                bam_filter.run()\n                assembler_dir = outprefix + '.iter.' + str(iteration) + '.assembly'\n                a = circlator.assemble.Assembler(\n                    reads_prefix + ('.fasta' if self.spades_only_assembler else '.fastq'),\n                    assembler_dir,\n                    threads=self.threads,\n                    careful=self.spades_careful,\n                    only_assembler=self.spades_only_assembler,\n                    verbose=self.verbose,\n                    spades_kmers=self.spades_kmers,\n                    spades_use_first_success=self.spades_use_first_success,\n                    assembler=self.assembler,\n                    genomeSize=self.length_cutoff,\n                    data_type=self.data_type\n                )\n                a.run()\n                self.reassembly = circlator.assembly.Assembly(assembler_dir, assembler=self.assembler)\n                self.reassembly_contigs = self.reassembly.get_contigs()\n            elif iteration <= 2:\n                print(this_log_prefix, '\\tNo contig merges were made',sep='', file=log_fh)\n\n        pyfastaq.utils.close(log_fh)\n        return genome_fasta, nucmer_coords, act_prefix + '.start_act.sh'", "response": "Iteratively merges contig pairs using bridging contigs from reassembly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite dictionary of contigs to file", "response": "def _contigs_dict_to_file(self, contigs, fname):\n        '''Writes dictionary of contigs to file'''\n        f = pyfastaq.utils.open_file_write(fname)\n        for contig in sorted(contigs, key=lambda x:len(contigs[x]), reverse=True):\n            print(contigs[contig], file=f)\n        pyfastaq.utils.close(f)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_spades_circular_nodes(self, fastg):\n        '''Returns set of names of nodes in SPAdes fastg file that are circular. Names will match those in spades fasta file'''\n        seq_reader = pyfastaq.sequences.file_reader(fastg)\n        names = set([x.id.rstrip(';') for x in seq_reader if ':' in x.id])\n        found_fwd = set()\n        found_rev = set()\n        for name in names:\n            l = name.split(':')\n            if len(l) != 2:\n                continue\n            if l[0] == l[1]:\n                if l[0][-1] == \"'\":\n                    found_rev.add(l[0][:-1])\n                else:\n                    found_fwd.add(l[0])\n\n        return found_fwd.intersection(found_rev)", "response": "Returns set of names of nodes in SPAdes fastg that are circular. Names will match those in SPAdes fastg file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_new_contig_from_nucmer_and_spades(self, original_contig, hits, circular_spades, log_fh=None, log_outprefix=None):\n        '''Tries to make new circularised contig from contig called original_contig. hits = list of nucmer hits, all with ref=original contg. circular_spades=set of query contig names that spades says are circular'''\n        writing_log_file = None not in [log_fh, log_outprefix]\n        hits_to_circular_contigs = [x for x in hits if x.qry_name in circular_spades]\n        if len(hits_to_circular_contigs) == 0:\n            if writing_log_file:\n                print(log_outprefix, original_contig, 'No matches to SPAdes circular contigs', sep='\\t', file=log_fh)\n            return None, None\n\n        for hit in hits_to_circular_contigs:\n            print(log_outprefix, original_contig, 'Checking hit:', hit, sep='\\t', file=log_fh)\n            percent_query_covered = 100 * (hit.hit_length_qry / hit.qry_length)\n\n            if self.min_spades_circular_percent <= percent_query_covered:\n                print(log_outprefix, '\\t', original_contig, '\\t\\tHit is long enough. Percent of contig covered by hit is ', percent_query_covered, sep='', file=log_fh)\n                # the spades contig hit is long enough, but now check that\n                #\u00a0the input contig is covered by hits from this spades contig\n                hit_intervals = [x.ref_coords() for x in hits_to_circular_contigs if x.qry_name == hit.qry_name]\n\n                if len(hit_intervals) > 0:\n                    pyfastaq.intervals.merge_overlapping_in_list(hit_intervals)\n                    percent_covered = 100 * pyfastaq.intervals.length_sum_from_list(hit_intervals) / hit.ref_length\n\n                    if writing_log_file:\n                        print(log_outprefix, '\\t', original_contig, '\\t\\treference bases covered by spades contig:', ', '.join([str(x) for x in hit_intervals]), sep='', file=log_fh)\n                        print(log_outprefix, '\\t', original_contig, '\\t\\t   ... which is ', percent_covered, ' percent of ', hit.ref_length, ' bases', sep='', file=log_fh)\n\n                    if self.min_spades_circular_percent <= percent_covered:\n                        if writing_log_file:\n                            print(log_outprefix, original_contig, '\\tUsing hit to call as circular (enough bases covered)', sep='\\t', file=log_fh)\n\n                        return pyfastaq.sequences.Fasta(original_contig, self.reassembly_contigs[hit.qry_name].seq), hit.qry_name\n                    elif writing_log_file:\n                        print(log_outprefix, original_contig, '\\tNot using hit to call as circular (not enough bases covered)', sep='\\t', file=log_fh)\n            else:\n                print(log_outprefix, original_contig, '\\tNot using hit to call as circular (hit too short)', sep='\\t', file=log_fh)\n\n        if writing_log_file:\n            print(log_outprefix, original_contig, 'No suitable matches to SPAdes circular contigs', sep='\\t', file=log_fh)\n\n        return None, None", "response": "Tries to make new circularised contig from original_contig and the set of spades that are circular."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the hunk details.", "response": "def _parse_hunk(self, header, diff, encoding):\n        \"\"\"Parse hunk details.\"\"\"\n        header_info = RE_HUNK_HEADER.match(header)\n        hunk_info = header_info.groups()\n        hunk = Hunk(*hunk_info)\n\n        source_line_no = hunk.source_start\n        target_line_no = hunk.target_start\n        expected_source_end = source_line_no + hunk.source_length\n        expected_target_end = target_line_no + hunk.target_length\n\n        for diff_line_no, line in diff:\n            if encoding is not None:\n                line = line.decode(encoding)\n\n            valid_line = RE_HUNK_EMPTY_BODY_LINE.match(line)\n            if not valid_line:\n                valid_line = RE_HUNK_BODY_LINE.match(line)\n\n            if not valid_line:\n                raise UnidiffParseError('Hunk diff line expected: %s' % line)\n\n            line_type = valid_line.group('line_type')\n            if line_type == LINE_TYPE_EMPTY:\n                line_type = LINE_TYPE_CONTEXT\n            value = valid_line.group('value')\n            original_line = Line(value, line_type=line_type)\n            if line_type == LINE_TYPE_ADDED:\n                original_line.target_line_no = target_line_no\n                target_line_no += 1\n            elif line_type == LINE_TYPE_REMOVED:\n                original_line.source_line_no = source_line_no\n                source_line_no += 1\n            elif line_type == LINE_TYPE_CONTEXT:\n                original_line.target_line_no = target_line_no\n                target_line_no += 1\n                original_line.source_line_no = source_line_no\n                source_line_no += 1\n            elif line_type == LINE_TYPE_NO_NEWLINE:\n                pass\n            else:\n                original_line = None\n\n            # stop parsing if we got past expected number of lines\n            if (source_line_no > expected_source_end or\n                    target_line_no > expected_target_end):\n                raise UnidiffParseError('Hunk is longer than expected')\n\n            if original_line:\n                original_line.diff_line_no = diff_line_no\n                hunk.append(original_line)\n\n            # if hunk source/target lengths are ok, hunk is complete\n            if (source_line_no == expected_source_end and\n                    target_line_no == expected_target_end):\n                break\n\n        # report an error if we haven't got expected number of lines\n        if (source_line_no < expected_source_end or\n                target_line_no < expected_target_end):\n            raise UnidiffParseError('Hunk is shorter than expected')\n\n        self.append(hunk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path(self):\n        if (self.source_file.startswith('a/') and\n                self.target_file.startswith('b/')):\n            filepath = self.source_file[2:]\n        elif (self.source_file.startswith('a/') and\n              self.target_file == '/dev/null'):\n            filepath = self.source_file[2:]\n        elif (self.target_file.startswith('b/') and\n              self.source_file == '/dev/null'):\n            filepath = self.target_file[2:]\n        else:\n            filepath = self.source_file\n        return filepath", "response": "Return the file path abstracted from VCS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tag_value(string, pre, post, tagtype=float, greedy=True):\n    greedy = '?' if greedy else ''  # For greedy search\n\n    if isinstance(post, (list, tuple)):\n        post = '(?=' + '|'.join(post) + ')'\n\n    tag_list = re.findall(r'{pre}(.+{greedy}){post}'.format(pre=pre, post=post, greedy=greedy),\n                          string)\n\n    if len(tag_list) > 1:\n        raise ValueError('More than one matching pattern found... check filename')\n    elif len(tag_list) == 0:\n        return None\n    else:\n        return tagtype(tag_list[0])", "response": "Returns the value of a tag from a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_files(dirname=None, pattern='*.*', recursive=True):\n    # get dirname from user if not given\n    if dirname is None:\n        from FlowCytometryTools.gui import dialogs\n        dirname = dialogs.select_directory_dialog('Select a directory')\n\n    # find all files in dirname that match pattern\n    if recursive:  # search subdirs\n        matches = []\n        for root, dirnames, filenames in os.walk(dirname):\n            for filename in fnmatch.filter(filenames, pattern):\n                matches.append(os.path.join(root, filename))\n    else:\n        matches = glob.glob(os.path.join(dirname, pattern))\n    return matches", "response": "Get all files within a given directory that match a given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving object to file path", "response": "def save(obj, path):\n    \"\"\"\n    Pickle (serialize) object to input file path\n\n    Parameters\n    ----------\n    obj : any object\n    path : string\n        File path\n    \"\"\"\n    with open(path, 'wb') as f:\n        try:\n            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n        except Exception as e:\n            print('Pickling failed for object {0}, path {1}'.format(obj, path))\n            print('Error message: {0}'.format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(path):\n    f = open(path, 'rb')\n    try:\n        return pickle.load(f)\n    finally:\n        f.close()", "response": "Load pickled object from the specified file path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_iter(obj):\n    if isinstance(obj, type(None)):\n        return None\n    elif isinstance(obj, six.string_types):\n        return [obj]\n    else:\n        # Nesting here since symmetry is broken in isinstance checks.\n        # Strings are iterables in python 3, so the relative order of if statements is important.\n        if isinstance(obj, collections.Iterable):\n            return obj\n        else:\n            return [obj]", "response": "Convert an object to a list if it is not already an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_list(obj):\n    obj = to_iter(obj)\n\n    if isinstance(obj, type(None)):\n        return None\n    else:\n        return list(obj)", "response": "Converts an object into a list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a deep copy of this object", "response": "def copy(self, deep=True):\n        \"\"\"\n        Make a copy of this object\n\n        Parameters\n        ----------\n        deep : boolean, default True\n            Make a deep copy, i.e. also copy data\n\n        Returns\n        -------\n        copy : type of caller\n        \"\"\"\n        from copy import copy, deepcopy\n        if deep:\n            return deepcopy(self)\n        else:\n            return copy(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntruncates log10 transform. Parameters ---------- x : num | num iterable values to be transformed. th : num values below th are transormed to 0. Must be positive. r : num (default = 10**4) maximal transformed value. d : num (default = log10(2**18)) log10 of maximal possible measured value. tlog(10**d) = r Returns ------- Array of transformed values.", "response": "def tlog(x, th=1, r=_display_max, d=_l_mmax):\n    \"\"\"\n    Truncated log10 transform.\n\n    Parameters\n    ----------\n    x : num | num iterable\n        values to be transformed.\n    th : num\n        values below th are transormed to 0.\n        Must be positive.\n    r : num (default = 10**4)\n        maximal transformed value.\n    d : num (default = log10(2**18))\n        log10 of maximal possible measured value.\n        tlog(10**d) = r\n\n    Returns\n    -------\n    Array of transformed values.\n    \"\"\"\n    if th <= 0:\n        raise ValueError('Threshold value must be positive. %s given.' % th)\n    return where(x <= th, log10(th) * 1. * r / d, log10(x) * 1. * r / d)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tlog_inv(y, th=1, r=_display_max, d=_l_mmax):\n    if th <= 0:\n        raise ValueError('Threshold value must be positive. %s given.' % th)\n    x = 10 ** (y * 1. * d / r)\n    try:\n        x[x < th] = th\n    except TypeError:\n        if x < th: x = th\n    return x", "response": "Inverse truncated log10 transform."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hlog_inv(y, b=500, r=_display_max, d=_l_mmax):\n    aux = 1. * d / r * y\n    s = sign(y)\n    if s.shape:  # to catch case where input is a single number\n        s[s == 0] = 1\n    elif s == 0:\n        s = 1\n    return s * 10 ** (s * aux) + b * aux - s", "response": "Inverse of base 10 hyperlog transform."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns vector of values for a spline.", "response": "def _x_for_spln(x, nx, log_spacing):\n    \"\"\"\n    Create vector of values to be used in constructing a spline.\n\n    Parameters\n    ----------\n    x : num | num iterable\n        Resulted values will span the range [min(x), max(x)]\n    nx : int\n        Length of returned vector.\n    log_spacing: bool\n        False - Create linearly spaced values.\n        True - Create logarithmically spaced values.\n            To extend to negative values, the spacing is done separately on the\n            negative and positive range, and these are later combined.\n            The number of points in the negative/positive range is proportional\n            to their relative range in log space. i.e., for data in the range\n            [-100, 1000] 2/5 of the resulting points will be in the negative range.\n\n    Returns\n    -------\n    x_spln : array\n    \"\"\"\n    x = asarray(x)\n    xmin = min(x)\n    xmax = max(x)\n    if xmin == xmax:\n        return asarray([xmin] * nx)\n    if xmax <= 0:  # all values<=0\n        return -_x_for_spln(-x, nx, log_spacing)[::-1]\n\n    if not log_spacing:\n        return linspace(xmin, xmax, nx)\n\n    # All code below is to handle-log-spacing when x has potentially both negative\n    # and positive values.\n    if xmin > 0:\n        return logspace(log10(xmin), log10(xmax), nx)\n    else:\n        lxmax = max([log10(xmax), 0])\n        lxmin = max([log10(abs(xmin)), 0])\n\n        # All the code below is for log-spacing, when xmin < 0 and xmax > 0\n        if lxmax == 0 and lxmin == 0:\n            return linspace(xmin, xmax, nx)  # Use linear spacing as fallback\n\n        if xmin > 0:\n            x_spln = logspace(lxmin, lxmax, nx)\n        elif xmin == 0:\n            x_spln = r_[0, logspace(-1, lxmax, nx - 1)]\n        else:  # (xmin < 0)\n            f = lxmin / (lxmin + lxmax)\n            nx_neg = int(f * nx)\n            nx_pos = nx - nx_neg\n\n            if nx <= 1:\n                # If triggered fix edge case behavior\n                raise AssertionError(u'nx should never bebe 0 or 1')\n\n            # Work-around various edge cases\n            if nx_neg == 0:\n                nx_neg = 1\n                nx_pos = nx_pos - 1\n\n            if nx_pos == 0:\n                nx_pos = 1\n                nx_neg = nx_neg - 1\n\n            x_spln_pos = logspace(-1, lxmax, nx_pos)\n            x_spln_neg = -logspace(lxmin, -1, nx_neg)\n\n            x_spln = r_[x_spln_neg, x_spln_pos]\n    return x_spln"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_hlog_numeric(b, r, d):\n    hlog_obj = lambda y, x, b, r, d: hlog_inv(y, b, r, d) - x\n    find_inv = vectorize(lambda x: brentq(hlog_obj, -2 * r, 2 * r,\n                                          args=(x, b, r, d)))\n    return find_inv", "response": "Return a function that numerically computes the hlog transformation for given parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hlog(x, b=500, r=_display_max, d=_l_mmax):\n    hlog_fun = _make_hlog_numeric(b, r, d)\n    if not hasattr(x, '__len__'):  # if transforming a single number\n        y = hlog_fun(x)\n    else:\n        n = len(x)\n        if not n:  # if transforming empty container\n            return x\n        else:\n            y = hlog_fun(x)\n    return y", "response": "Base 10 hyperlog transform."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a transform into a tuple of the name and the name of the element.", "response": "def parse_transform(transform, direction='forward'):\n    \"\"\"\n    direction : 'forward' | 'inverse'\n    \"\"\"\n    if hasattr(transform, '__call__'):\n        tfun = transform\n        tname = None\n    elif hasattr(transform, 'lower'):\n        tname = _get_canonical_name(transform)\n        if tname is None:\n            raise ValueError('Unknown transform: %s' % transform)\n        else:\n            tfun = name_transforms[tname][direction]\n    else:\n        raise TypeError('Unsupported transform type: %s' % type(transform))\n    return tfun, tname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a transform to a DataFrame.", "response": "def transform_frame(frame, transform, columns=None, direction='forward',\n                    return_all=True, args=(), **kwargs):\n    \"\"\"\n    Apply transform to specified columns.\n\n    direction: 'forward' | 'inverse'\n    return_all: bool\n        True -  return all columns, with specified ones transformed.\n        False - return only specified columns.\n\n    .. warning:: deprecated\n    \"\"\"\n    tfun, tname = parse_transform(transform, direction)\n    columns = to_list(columns)\n    if columns is None:\n        columns = frame.columns\n    if return_all:\n        transformed = frame.copy()\n        for c in columns:\n            transformed[c] = tfun(frame[c], *args, **kwargs)\n    else:\n        transformed = frame.filter(columns).apply(tfun, *args, **kwargs)\n    return transformed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying transform to x", "response": "def transform(self, x, use_spln=False, **kwargs):\n        \"\"\"\n        Apply transform to x\n\n        Parameters\n        ----------\n        x : float-array-convertible\n            Data to be transformed.\n            Should support conversion to an array of floats.\n        use_spln: bool\n            True - transform using the spline specified in self.slpn.\n                    If self.spln is None, set the spline.\n            False - transform using self.tfun\n        kwargs:\n            Keyword arguments to be passed to self.set_spline.\n            Only used if use_spln=True & self.spln=None.\n\n        Returns\n        -------\n        Array of transformed values.\n        \"\"\"\n        x = asarray(x, dtype=float)\n\n        if use_spln:\n            if self.spln is None:\n                self.set_spline(x.min(), x.max(), **kwargs)\n            return apply_along_axis(self.spln, 0, x)\n        else:\n            return self.tfun(x, *self.args, **self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering and prep user for PyPi upload.", "response": "def pypi_register(server='pypitest'):\n    \"\"\"Register and prep user for PyPi upload.\n\n    .. note:: May need to weak ~/.pypirc file per issue:\n        http://stackoverflow.com/questions/1569315\n    \"\"\"\n    base_command = 'python setup.py register'\n\n    if server == 'pypitest':\n        command = base_command + ' -r https://testpypi.python.org/pypi'\n    else:\n        command = base_command\n\n    _execute_setup_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats all non - iterables inside of the iterable var using the format_str", "response": "def apply_format(var, format_str):\n    \"\"\"Format all non-iterables inside of the iterable var using the format_str\n\n    Example:\n    >>> print apply_format([2, [1, 4], 4, 1], '{:.1f}')\n\n    will return ['2.0', ['1.0', '4.0'], '4.0', '1.0']\n    \"\"\"\n    if isinstance(var, (list, tuple)):\n        new_var = map(lambda x: apply_format(x, format_str), var)\n        if isinstance(var, tuple):\n            new_var = '(' + ', '.join(new_var) + ')'\n        elif isinstance(var, list):\n            new_var = '[' + ', '.join(new_var) + ']'\n        return '{}'.format(new_var)\n    else:\n        return format_str.format(var)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_spawnable(source_channels, target_channels):\n    if len(target_channels) != len(set(target_channels)):\n        raise Exception('Spawn channels must be unique')\n    return source_channels.issubset(\n        set(target_channels))", "response": "Check whether gate is spawnable on the source channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles keyboard shortcuts for the FCToolbar.", "response": "def key_press_handler(event, canvas, toolbar=None):\n    \"\"\"\n    Handles keyboard shortcuts for the FCToolbar.\n    \"\"\"\n    if event.key is None: return\n\n    key = event.key.encode('ascii', 'ignore')\n\n    if key in ['1']:\n        toolbar.create_gate_widget(kind='poly')\n    elif key in ['2', '3', '4']:\n        kind = {'2': 'quad', '3': 'horizontal threshold', '4': 'vertical threshold'}[key]\n        toolbar.create_gate_widget(kind=kind)\n    elif key in ['9']:\n        toolbar.remove_active_gate()\n    elif key in ['0']:\n        toolbar.load_fcs()\n    elif key in ['a']:\n        toolbar.set_axes(('d1', 'd2'), pl.gca())\n    elif key in ['b']:\n        toolbar.set_axes(('d2', 'd1'), pl.gca())\n    elif key in ['c']:\n        toolbar.set_axes(('d1', 'd3'), pl.gca())\n    elif key in ['8']:\n        print(toolbar.get_generation_code())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a callback function to the callback list", "response": "def add_callback(self, func):\n        \"\"\" Registers a call back function \"\"\"\n        if func is None: return\n        func_list = to_list(func)\n\n        if not hasattr(self, 'callback_list'):\n            self.callback_list = func_list\n        else:\n            self.callback_list.extend(func_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spawn(self, ax, target_channels):\n        source_channels = set(self.coordinates.keys())\n        is_spawnable = _check_spawnable(source_channels, target_channels)\n\n        if not is_spawnable:\n            return None\n\n        if len(target_channels) == 1:\n            verts = self.coordinates.get(target_channels[0], None), None\n        else:\n            verts = tuple([self.coordinates.get(ch, None) for ch in target_channels])\n\n        def _callback(event):\n            if event.type == Event.CHANGE:\n                svertex = event.info['caller']\n                ch = svertex.channels\n                coordinates = svertex.coordinates\n                new_coordinates = {k: v for k, v in zip(ch, coordinates)}\n                self.update_coordinates(new_coordinates)\n            elif event.type == Event.VERTEX_REMOVED:\n                svertex = event.info['caller']\n                self.spawn_list.remove(svertex)\n            else:\n                raise ValueError('Unrecognized event {}'.format(event))\n\n        spawned_vertex = SpawnableVertex(verts, ax, _callback)\n        spawned_vertex.channels = target_channels\n\n        if self.spawn_list is None:\n            self.spawn_list = []\n        self.spawn_list.append(spawned_vertex)\n        return spawned_vertex", "response": "Spawns a new vertex from the target_channels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_coordinates(self, new_coordinates):\n        for k, v in new_coordinates.items():\n            if k in self.coordinates:\n                self.coordinates[k] = v\n\n        for svertex in self.spawn_list:\n            verts = tuple([self.coordinates.get(ch, None) for ch in svertex.channels])\n\n            if len(svertex.channels) == 1:  # This means a histogram\n                svertex.update_position(verts[0], None)\n            else:\n                svertex.update_position(verts[0], verts[1])\n        self.callback(Event(Event.BASE_GATE_CHANGED))", "response": "Update the coordinates of the base gate."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_artist(self):\n        verts = self.coordinates\n\n        if not self.tracky:\n            trans = self.ax.get_xaxis_transform(which='grid')\n        elif not self.trackx:\n            trans = self.ax.get_yaxis_transform(which='grid')\n        else:\n            trans = self.ax.transData\n\n        self.artist = pl.Line2D([verts[0]], [verts[1]], transform=trans, picker=15)\n        self.update_looks('inactive')\n        self.ax.add_artist(self.artist)", "response": "Creates the artist for the current artist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nspawning a graphical gate that can be used to update the coordinates of the current gate.", "response": "def spawn(self, channels, ax):\n        \"\"\" Spawns a graphical gate that can be used to update the coordinates of the current gate. \"\"\"\n        if _check_spawnable(self.source_channels, channels):\n            sgate = self.gate_type(self.verts, ax, channels)\n            self.spawn_list.append(sgate)\n            return sgate\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all spawned gates.", "response": "def remove_spawned_gates(self, spawn_gate=None):\n        \"\"\" Removes all spawned gates. \"\"\"\n        if spawn_gate is None:\n            for sg in list(self.spawn_list):\n                self.spawn_list.remove(sg)\n                sg.remove()\n        else:\n            spawn_gate.remove()\n            self.spawn_list.remove(spawn_gate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate python code that can create the gate.", "response": "def get_generation_code(self, **gencode):\n        \"\"\"\n        Generates python code that can create the gate.\n        \"\"\"\n        channels, verts = self.coordinates\n        channels = ', '.join([\"'{}'\".format(ch) for ch in channels])\n\n        verts = list(verts)\n\n        ## Formatting the vertexes\n        # List level (must be first), used for gates that may have multiple vertexes like a polygon\n        if len(verts) == 1:\n            verts = verts[0]\n\n            # Tuple level (must be second), used for catching the number of dimensions\n            # on which a vertex is defined\n            if len(verts) == 1:\n                verts = verts[0]\n\n        # Format vertices to include less sigfigs\n        verts = apply_format(verts, '{:.3e}')\n\n        gencode.setdefault('name', self.name)\n        gencode.setdefault('region', self.region)\n        gencode.setdefault('gate_type', self._gencode_gate_class)\n        gencode.setdefault('verts', verts)\n        gencode.setdefault('channels', channels)\n        format_string = \"{name} = {gate_type}({verts}, ({channels}), region='{region}', name='{name}')\"\n        return format_string.format(**gencode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the class name that generates this gate.", "response": "def _gencode_gate_class(self):\n        \"\"\" Returns the class name that generates this gate. \"\"\"\n        channels, verts = self.coordinates\n        num_channels = len(channels)\n        gate_type_name = self.gate_type.__name__\n        if gate_type_name == 'ThresholdGate' and num_channels == 2:\n            gate_type_name = 'QuadGate'\n        return gate_type_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set describing the source channels on which the gate is defined.", "response": "def source_channels(self):\n        \"\"\" Returns a set describing the source channels on which the gate is defined. \"\"\"\n        source_channels = [v.coordinates.keys() for v in self.verts]\n        return set(itertools.chain(*source_channels))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the looks of the active gate depending on state.", "response": "def update_looks(self):\n        \"\"\" Updates the looks of the gate depending on state. \"\"\"\n        if self.state == 'active':\n            style = {'color': 'red', 'linestyle': 'solid', 'fill': False}\n        else:\n            style = {'color': 'black', 'fill': False}\n        self.poly.update(style)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_looks(self):\n        if self.state == 'active':\n            style = {'color': 'red', 'linestyle': 'solid'}\n        else:\n            style = {'color': 'black'}\n        for artist in self.artist_list:\n            artist.update(style)", "response": "Updates the looks of the active or inactive gates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging the axis of the current log entry.", "response": "def change_axis(self, axis_num, channel_name):\n        \"\"\"\n        TODO: refactor that and set_axes\n        what to do with ax?\n\n        axis_num: int\n           axis number\n        channel_name: str\n           new channel to plot on that axis\n        \"\"\"\n        current_channels = list(self.current_channels)\n        if len(current_channels) == 1:\n            if axis_num == 0:\n                new_channels = channel_name,\n            else:\n                new_channels = current_channels[0], channel_name\n        else:\n            new_channels = list(current_channels)\n            new_channels[axis_num] = channel_name\n\n        self.set_axes(new_channels, self.ax)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the axes of the current state of the gates.", "response": "def set_axes(self, channels, ax):\n        \"\"\"\n        channels : iterable of string\n            each value corresponds to a channel names\n            names must be unique\n        \"\"\"\n        # To make sure displayed as hist\n        if len(set(channels)) == 1:\n            channels = channels[0],\n\n        self.current_channels = channels\n        # Remove existing gates\n        for gate in self.gates:\n            gate.remove_spawned_gates()\n        ## \n        # Has a clear axis command inside!!\n        # which will \"force kill\" spawned gates\n        self.plot_data()\n\n        for gate in self.gates:\n            sgate = gate.spawn(channels, ax)\n            gate._refresh_activation()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_data(self):\n        # Clear the plot before plotting onto it\n        self.ax.cla()\n\n        if self.sample is None:\n            return\n\n        if self.current_channels is None:\n            self.current_channels = self.sample.channel_names[:2]\n\n        channels = self.current_channels\n        channels_to_plot = channels[0] if len(channels) == 1 else channels\n        self.sample.plot(channels_to_plot, ax=self.ax)\n\n        xaxis = self.ax.get_xaxis()\n        yaxis = self.ax.get_yaxis()\n        self.xlabel_artist = xaxis.get_label()\n        self.ylabel_artist = yaxis.get_label()\n        self.xlabel_artist.set_picker(5)\n        self.ylabel_artist.set_picker(5)\n\n        self.fig.canvas.draw()", "response": "Plots the loaded data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_generation_code(self):\n        if len(self.gates) < 1:\n            code = ''\n        else:\n            import_list = set([gate._gencode_gate_class for gate in self.gates])\n            import_list = 'from FlowCytometryTools import ' + ', '.join(import_list)\n            code_list = [gate.get_generation_code() for gate in self.gates]\n            code_list.sort()\n            code_list = '\\n'.join(code_list)\n            code = import_list + 2 * '\\n' + code_list\n\n        self.callback(Event('generated_code',\n                            {'code': code}))\n        return code", "response": "Return python code that generates all drawn gates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace(self):\n        doc_dict = self.doc_dict.copy()\n        for k, v in doc_dict.items():\n            if '{' and '}' in v:\n                self.doc_dict[k] = v.format(**doc_dict)", "response": "Reformat values inside the self. doc_dict using self. doc_dict\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _format(self, doc):\n        if self.allow_partial_formatting:\n            mapping = FormatDict(self.doc_dict)\n        else:\n            mapping = self.doc_dict\n        formatter = string.Formatter()\n        return formatter.vformat(doc, (), mapping)", "response": "Formats the docstring using self. doc_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a directory selection dialog", "response": "def select_multi_directory_dialog():\n    \"\"\" Opens a directory selection dialog\n        Style - specifies style of dialog (read wx documentation for information)\n    \"\"\"\n    import wx.lib.agw.multidirdialog as MDD\n\n    app = wx.App(0)\n    dlg = MDD.MultiDirDialog(None, title=\"Select directories\", defaultPath=os.getcwd(),\n                             agwStyle=MDD.DD_MULTIPLE | MDD.DD_DIR_MUST_EXIST)\n\n    if dlg.ShowModal() != wx.ID_OK:\n        dlg.Destroy()\n        return\n\n    paths = dlg.GetPaths()\n\n    dlg.Destroy()\n    app.MainLoop()\n\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a directory selection dialog", "response": "def select_directory_dialog(windowTitle, defaultPath=os.getcwd(), style=None):\n    \"\"\" Opens a directory selection dialog\n        Style - specifies style of dialog (read wx documentation for information)\n    \"\"\"\n    app = wx.App(None)\n\n    if style == None:\n        style = wx.DD_DIR_MUST_EXIST\n\n    dialog = wx.DirDialog(None, windowTitle, defaultPath=defaultPath, style=style)\n\n    if dialog.ShowModal() == wx.ID_OK:\n        path = dialog.GetPath()\n    else:\n        path = None\n    dialog.Destroy()\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a wx. FileDialog and returns the path of the file selected.", "response": "def open_file_dialog(windowTitle, wildcard, defaultDir=os.getcwd(), style=None, parent=None):\n    \"\"\" Opens a wx widget file select dialog.\n        Wild card specifies which kinds of files are allowed.\n        Style - specifies style of dialog (read wx documentation for information)\n    \"\"\"\n\n    if parent == None:\n        app = wx.App(None)\n\n    if style == None:\n        style = wx.OPEN | wx.CHANGE_DIR\n\n    dialog = wx.FileDialog(parent, windowTitle, defaultDir=defaultDir, wildcard=wildcard,\n                           style=style)\n\n    if dialog.ShowModal() == wx.ID_OK:\n        path = dialog.GetPath()\n    else:\n        path = None\n    dialog.Destroy()\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_file_dialog(wildcard):\n    app = wx.App(None)\n    # style = wx.FD_OPEN | wx.FD_FILE_MUST_EXIST\n    dialog = wx.FileDialog(None, 'Save file as ...', defaultDir=os.getcwd(), defaultFile=\"\",\n                           wildcard=wildcard, style=wx.SAVE)\n    if dialog.ShowModal() == wx.ID_OK:\n        path = dialog.GetPath()\n        print(\"You chose the following filename: %s\" % path)\n    else:\n        path = None\n    dialog.Destroy()\n    return path", "response": "Show a save file dialog."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a select option dialog.", "response": "def select_option_dialog(windowTitle, optionList):\n    \"\"\" Opens a select option dialog.\n    Select the option by double clicking.\n    TODO: Clean up this function\n    TODO: Improve interface (i.e., add cancel, OK)\n    \"\"\"\n\n    class OptionFrame(wx.Frame):\n        selectedOption = None\n\n        def __init__(self, windowTitle, optionList):\n            wx.Frame.__init__(self, None, -1, windowTitle, size=(250, 200))\n            panel = wx.Panel(self, -1)\n            listBox = wx.ListBox(panel, -1, (20, 20), (80, 120), optionList, wx.LB_SINGLE)\n            listBox.SetSelection(0)\n            self.Bind(wx.EVT_LISTBOX_DCLICK, self.doubleclick)\n            self.optionList = optionList\n\n        def doubleclick(self, event):\n            index = event.GetSelection()\n            value = self.optionList[index]\n            OptionFrame.selectedOption = (index, value)\n            self.Close()\n\n    app = wx.PySimpleApp()\n    OptionFrame(windowTitle, optionList).Show()\n    app.MainLoop()\n\n    return OptionFrame.selectedOption"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the version from the version file", "response": "def get_package_version(path):\n    '''Extracts the version'''\n    with open(VERSION_FILE, \"rt\") as f:\n        verstrline = f.read()\n\n    VERSION = r\"^version = ['\\\"]([^'\\\"]*)['\\\"]\"\n    results = re.search(VERSION, verstrline, re.M)\n\n    if results:\n        version = results.group(1)\n    else:\n        raise RuntimeError(\"Unable to find version string in {}.\".format(path))\n\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_widget_channels(self):\n        sel1 = self.x_axis_list.GetSelection()\n        sel2 = self.y_axis_list.GetSelection()\n\n        if sel1 >= 0 and sel2 >= 0:\n            channel_1 = self.x_axis_list.GetString(sel1)\n            channel_2 = self.y_axis_list.GetString(sel2)\n            self.fcgatemanager.set_axes((channel_1, channel_2), self.ax)", "response": "Updates the axes of the current channel list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _assign_IDS_to_datafiles(datafiles, parser, measurement_class=None, **kwargs):\n    if isinstance(parser, collections.Mapping):\n        fparse = lambda x: parser[x]\n    elif hasattr(parser, '__call__'):\n        fparse = lambda x: parser(x, **kwargs)\n    elif parser == 'name':\n        kwargs.setdefault('pre', 'Well_')\n        kwargs.setdefault('post', ['_', '\\.', '$'])\n        kwargs.setdefault('tagtype', str)\n        fparse = lambda x: get_tag_value(os.path.basename(x), **kwargs)\n    elif parser == 'number':\n        fparse = lambda x: int(x.split('.')[-2])\n    elif parser == 'read':\n        fparse = lambda x: measurement_class(ID='temporary', datafile=x).ID_from_data(**kwargs)\n    else:\n        raise ValueError('Encountered unsupported value \"%s\" for parser parameter.' % parser)\n    d = dict((fparse(dfile), dfile) for dfile in datafiles)\n    return d", "response": "Assign measurement IDS to datafiles using specified parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef int2letters(x, alphabet):\n    base = len(alphabet)\n    if x < 0:\n        raise ValueError('Only non-negative numbers are supported. Encounterd %s' % x)\n    letters = []\n    quotient = x\n    while quotient >= 0:\n        quotient, remainder = divmod(quotient, base)\n        quotient -= 1\n        letters.append(alphabet[remainder])\n    letters.reverse()\n    return ''.join(letters)", "response": "Return the alphabet representation of a non - negative integer x."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_data(self, data=None, **kwargs):\n        '''\n        Read data into memory, applying all actions in queue.\n        Additionally, update queue and history.\n        '''\n        if data is None:\n            data = self.get_data(**kwargs)\n        setattr(self, '_data', data)\n        self.history += self.queue\n        self.queue = []", "response": "Set the data of the current object to the given data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_meta(self, meta=None, **kwargs):\n        '''\n        Assign values to self.meta.\n        Meta is not returned\n        '''\n        if meta is None:\n            meta = self.get_meta(**kwargs)\n        setattr(self, '_meta', meta)", "response": "Assign values to self. meta.\n        Meta is not returned\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the value of an attribute from the file.", "response": "def _get_attr_from_file(self, name, **kwargs):\n        '''\n        return values of attribute of self.\n        Attribute values can the ones assigned already, or the read for\n        the corresponding file.\n        If read from file:\n            i) the method used to read the file is 'self.read_[attr name]'\n            (e.g. for an attribute named 'meta' 'self.read_meta'\n            will be used).\n            ii) the file path will be the one specified in an attribute\n            named: '[attr name]file'. (e.g. for an attribute named\n            'meta' a 'metafile' attribute will be created).\n        '''\n        current_value = getattr(self, '_' + name)\n        if current_value is not None:\n            value = current_value\n        else:\n            parser_kwargs = getattr(self, 'read%s_kwargs' % name, {})\n            value = getattr(self, 'read_%s' % name)(**parser_kwargs)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the measurement data.", "response": "def get_data(self, **kwargs):\n        '''\n        Get the measurement data.\n        If data is not set, read from 'self.datafile' using 'self.read_data'.\n        '''\n        if self.queue:\n            new = self.apply_queued()\n            return new.get_data()\n        else:\n            return self._get_attr_from_file('data', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, func, applyto='measurement', noneval=nan, setdata=False):\n        applyto = applyto.lower()\n        if applyto == 'data':\n            if self.data is not None:\n                data = self.data\n            elif self.datafile is None:\n                return noneval\n            else:\n                data = self.read_data()\n                if setdata:\n                    self.data = data\n            return func(data)\n        elif applyto == 'measurement':\n            return func(self)\n        else:\n            raise ValueError('Encountered unsupported value \"%s\" for applyto parameter.' % applyto)", "response": "Applies func to self and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Collection of measurements from a set of data files.", "response": "def from_files(cls, ID, datafiles, parser, readdata_kwargs={}, readmeta_kwargs={}, **ID_kwargs):\n        \"\"\"\n        Create a Collection of measurements from a set of data files.\n\n        Parameters\n        ----------\n        {_bases_ID}\n        {_bases_data_files}\n        {_bases_filename_parser}\n        {_bases_ID_kwargs}\n        \"\"\"\n        d = _assign_IDS_to_datafiles(datafiles, parser, cls._measurement_class, **ID_kwargs)\n        measurements = []\n        for sID, dfile in d.items():\n            try:\n                measurements.append(cls._measurement_class(sID, datafile=dfile,\n                                                           readdata_kwargs=readdata_kwargs,\n                                                           readmeta_kwargs=readmeta_kwargs))\n            except:\n                msg = 'Error occurred while trying to parse file: %s' % dfile\n                raise IOError(msg)\n        return cls(ID, measurements)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_dir(cls, ID, datadir, parser, pattern='*.fcs', recursive=False,\n                 readdata_kwargs={}, readmeta_kwargs={}, **ID_kwargs):\n        \"\"\"\n        Create a Collection of measurements from data files contained in a directory.\n\n        Parameters\n        ----------\n        ID : hashable\n            Collection ID\n        datadir : str\n            Path of directory containing the data files.\n        pattern : str\n            Only files matching the pattern will be used to create measurements.\n        recursive : bool\n            Recursively look for files matching pattern in subdirectories.\n        {_bases_filename_parser}\n        {_bases_ID_kwargs}\n        \"\"\"\n        datafiles = get_files(datadir, pattern, recursive)\n        return cls.from_files(ID, datafiles, parser,\n                              readdata_kwargs=readdata_kwargs, readmeta_kwargs=readmeta_kwargs,\n                              **ID_kwargs)", "response": "Create a Collection of measurements from a directory containing the data files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, func, ids=None, applyto='measurement', noneval=nan,\n              setdata=False, output_format='dict', ID=None,\n              **kwargs):\n        '''\n        Apply func to each of the specified measurements.\n\n        Parameters\n        ----------\n        func : callable\n            Accepts a Measurement object or a DataFrame.\n        ids : hashable| iterable of hashables | None\n            Keys of measurements to which func will be applied.\n            If None is given apply to all measurements.\n        applyto :  'measurement' | 'data'\n            * 'measurement' : apply to measurements objects themselves.\n            * 'data'        : apply to measurement associated data\n        noneval : obj\n            Value returned if applyto is 'data' but no data is available.\n        setdata : bool\n            Whether to set the data in the Measurement object.\n            Used only if data is not already set.\n        output_format : ['dict' | 'collection']\n            * collection : keeps result as collection\n            WARNING: For collection, func should return a copy of the measurement instance rather\n            than the original measurement instance.\n        Returns\n        -------\n        Dictionary keyed by measurement keys containing the corresponding output of func\n        or returns a collection (if output_format='collection').\n        '''\n        if ids is None:\n            ids = self.keys()\n        else:\n            ids = to_list(ids)\n        result = dict((i, self[i].apply(func, applyto, noneval, setdata)) for i in ids)\n\n        if output_format == 'collection':\n            can_keep_as_collection = all(\n                [isinstance(r, self._measurement_class) for r in result.values()])\n            if not can_keep_as_collection:\n                raise TypeError(\n                    'Cannot turn output into a collection. The provided func must return results of type {}'.format(\n                        self._measurement_class))\n\n            new_collection = self.copy()\n            # Locate IDs to remove\n            ids_to_remove = [x for x in self.keys() if x not in ids]\n            # Remove data for these IDs\n            for ids in ids_to_remove:\n                new_collection.pop(ids)\n            # Update keys with new values\n            for k, v in new_collection.items():\n                new_collection[k] = result[k]\n            if ID is not None:\n                new_collection.ID = ID\n            return new_collection\n        else:\n            # Return a dictionary\n            return result", "response": "Applies a function to each of the specified measurements. Returns a dictionary containing the results of the function applied to each of the specified measurements."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the data for all specified measurements.", "response": "def set_data(self, ids=None):\n        \"\"\"\n        Set the data for all specified measurements (all if None given).\n        \"\"\"\n        fun = lambda x: x.set_data()\n        self.apply(fun, ids=ids, applyto='measurement')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the metadata of the specified measurements.", "response": "def get_measurement_metadata(self, fields, ids=None, noneval=nan,\n                                 output_format='DataFrame'):\n        \"\"\"\n        Get the metadata fields of specified measurements (all if None given).\n\n        Parameters\n        ----------\n        fields : str | iterable of str\n            Names of metadata fields to be returned.\n        ids : hashable| iterable of hashables | None\n            Keys of measurements for which metadata will be returned.\n            If None is given return metadata of all measurements.\n        noneval : obj\n            Value returned if applyto is 'data' but no data is available.\n        output_format :  'DataFrame' | 'dict'\n            'DataFrame' : return DataFrame,\n            'dict'      : return dictionary.\n\n        Returns\n        -------\n        Measurement metadata in specified output_format.\n        \"\"\"\n        fields = to_list(fields)\n        func = lambda x: x.get_meta_fields(fields)\n        meta_d = self.apply(func, ids=ids, applyto='measurement',\n                            noneval=noneval, output_format='dict')\n        if output_format is 'dict':\n            return meta_d\n        elif output_format is 'DataFrame':\n            from pandas import DataFrame as DF\n            meta_df = DF(meta_d, index=fields)\n            return meta_df\n        else:\n            msg = (\"The output_format must be either 'dict' or 'DataFrame'. \" +\n                   \"Encountered unsupported value %s.\" % repr(output_format))\n            raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(self, criteria, applyto='measurement', ID=None):\n        fil = criteria\n        new = self.copy()\n        if isinstance(applyto, collections.Mapping):\n            remove = (k for k, v in self.items() if not fil(applyto[k]))\n        elif applyto == 'measurement':\n            remove = (k for k, v in self.items() if not fil(v))\n        elif applyto == 'keys':\n            remove = (k for k, v in self.items() if not fil(k))\n        elif applyto == 'data':\n            remove = (k for k, v in self.items() if not fil(v.get_data()))\n        else:\n            raise ValueError('Unsupported value \"%s\" for applyto parameter.' % applyto)\n        for r in remove:\n            del new[r]\n        if ID is None:\n            ID = self.ID\n        new.ID = ID\n        return new", "response": "Returns a new collection with only measurements matching the given criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new TimeSeries with only Measurements with given keys.", "response": "def filter_by_key(self, keys, ID=None):\n        \"\"\"\n        Keep only Measurements with given keys.\n        \"\"\"\n        keys = to_list(keys)\n        fil = lambda x: x in keys\n        if ID is None:\n            ID = self.ID\n        return self.filter(fil, applyto='keys', ID=ID)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkeeping only Measurements with given IDs.", "response": "def filter_by_IDs(self, ids, ID=None):\n        \"\"\"\n        Keep only Measurements with given IDs.\n        \"\"\"\n        fil = lambda x: x in ids\n        return self.filter_by_attr('ID', fil, ID)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering the list by the given rows.", "response": "def filter_by_rows(self, rows, ID=None):\n        \"\"\"\n        Keep only Measurements in corresponding rows.\n        \"\"\"\n        rows = to_list(rows)\n        fil = lambda x: x in rows\n        applyto = {k: self._positions[k][0] for k in self.keys()}\n        if ID is None:\n            ID = self.ID\n        return self.filter(fil, applyto=applyto, ID=ID)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters the list of Measurements in corresponding columns.", "response": "def filter_by_cols(self, cols, ID=None):\n        \"\"\"\n        Keep only Measurements in corresponding columns.\n        \"\"\"\n        rows = to_list(cols)\n        fil = lambda x: x in rows\n        applyto = {k: self._positions[k][1] for k in self.keys()}\n        if ID is None:\n            ID = self.ID + '.filtered_by_cols'\n        return self.filter(fil, applyto=applyto, ID=ID)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an OrderedCollection of measurements from a set of data files.", "response": "def from_files(cls, ID, datafiles, parser='name',\n                   position_mapper=None,\n                   readdata_kwargs={}, readmeta_kwargs={}, ID_kwargs={}, **kwargs):\n        \"\"\"\n        Create an OrderedCollection of measurements from a set of data files.\n\n        Parameters\n        ----------\n        {_bases_ID}\n        {_bases_data_files}\n        {_bases_filename_parser}\n        {_bases_position_mapper}\n        {_bases_ID_kwargs}\n        kwargs : dict\n            Additional key word arguments to be passed to constructor.\n        \"\"\"\n        if position_mapper is None:\n            if isinstance(parser, six.string_types):\n                position_mapper = parser\n            else:\n                msg = \"When using a custom parser, you must specify the position_mapper keyword.\"\n                raise ValueError(msg)\n        d = _assign_IDS_to_datafiles(datafiles, parser, cls._measurement_class, **ID_kwargs)\n        measurements = []\n        for sID, dfile in d.items():\n            try:\n                measurements.append(cls._measurement_class(sID, datafile=dfile,\n                                                           readdata_kwargs=readdata_kwargs,\n                                                           readmeta_kwargs=readmeta_kwargs))\n            except:\n                msg = 'Error occured while trying to parse file: %s' % dfile\n                raise IOError(msg)\n        return cls(ID, measurements, position_mapper, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Collection of measurements from a directory containing the data files.", "response": "def from_dir(cls, ID, path,\n                 parser='name',\n                 position_mapper=None, pattern='*.fcs', recursive=False,\n                 readdata_kwargs={}, readmeta_kwargs={}, ID_kwargs={}, **kwargs):\n        \"\"\"\n        Create a Collection of measurements from data files contained in a directory.\n\n        Parameters\n        ----------\n        {_bases_ID}\n        datadir : str\n            Path of directory containing the data files.\n        pattern : str\n            Only files matching the pattern will be used to create measurements.\n        recursive : bool\n            Recursively look for files matching pattern in subdirectories.\n        {_bases_filename_parser}\n        {_bases_position_mapper}\n        {_bases_ID_kwargs}\n        kwargs : dict\n            Additional key word arguments to be passed to constructor.\n        \"\"\"\n        datafiles = get_files(path, pattern, recursive)\n        return cls.from_files(ID, datafiles, parser=parser, position_mapper=position_mapper,\n                              readdata_kwargs=readdata_kwargs, readmeta_kwargs=readmeta_kwargs,\n                              ID_kwargs=ID_kwargs, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_labels(self, labels, axis='rows'):\n        '''\n        Set the row/col labels.\n        Note that this method doesn't check that enough labels were set for all the assigned positions.\n        '''\n        if axis.lower() in ('rows', 'row', 'r', 0):\n            assigned_pos = set(v[0] for v in self._positions.itervalues())\n            not_assigned = set(labels) - assigned_pos\n            if len(not_assigned) > 0:\n                msg = 'New labels must contain all assigned positions'\n                raise ValueError(msg)\n            self.row_labels = labels\n        elif axis.lower() in ('cols', 'col', 'c', 1):\n            self.col_labels = labels\n        else:\n            raise TypeError('Unsupported axis value %s' % axis)", "response": "Set the row and col labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_valid_position(self, position):\n        '''\n        check if given position is valid for this collection\n        '''\n        row, col = position\n        valid_r = row in self.row_labels\n        valid_c = col in self.col_labels\n        return valid_r and valid_c", "response": "check if given position is valid for this collection\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that returns a function that takes a string representing the key to position mapping.", "response": "def _get_ID2position_mapper(self, position_mapper):\n        '''\n        Defines a position parser that is used\n        to map between sample IDs and positions.\n\n        Parameters\n        --------------\n        {_bases_position_mapper}\n\n        TODO: Fix the name to work with more than 26 letters\n        of the alphabet.\n        '''\n\n        def num_parser(x, order):\n            i, j = unravel_index(int(x - 1), self.shape, order=order)\n            return (self.row_labels[i], self.col_labels[j])\n\n        if hasattr(position_mapper, '__call__'):\n            mapper = position_mapper\n        elif isinstance(position_mapper, collections.Mapping):\n            mapper = lambda x: position_mapper[x]\n        elif position_mapper == 'name':\n            mapper = lambda x: (x[0], int(x[1:]))\n        elif position_mapper in ('row_first_enumerator', 'number'):\n            mapper = lambda x: num_parser(x, 'F')\n        elif position_mapper == 'col_first_enumerator':\n            mapper = lambda x: num_parser(x, 'C')\n        else:\n            msg = '\"{}\" is not a known key_to_position_parser.'.format(position_mapper)\n            raise ValueError(msg)\n        return mapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the positions of the items in the current object to the given positions.", "response": "def set_positions(self, positions=None, position_mapper='name', ids=None):\n        '''\n        checks for position validity & collisions,\n        but not that all measurements are assigned.\n\n        Parameters\n        -----------\n        positions : is dict-like of measurement_key:(row,col)\n        parser :\n            callable - gets key and returns position\n            mapping  - key:pos\n            'name'   - parses things like 'A1', 'G12'\n            'number' - converts number to positions, going over rows first.\n        ids :\n            parser will be applied to specified ids only.\n            If None is given, parser will be applied to all measurements.\n\n        TODO: output a more informative message for position collisions\n        '''\n        if positions is None:\n            if ids is None:\n                ids = self.keys()\n            else:\n                ids = to_list(ids)\n            mapper = self._get_ID2position_mapper(position_mapper)\n            positions = dict((ID, mapper(ID)) for ID in ids)\n        else:\n            pass\n        # check that resulting assignment is unique (one measurement per position)\n        temp = self._positions.copy()\n        temp.update(positions)\n        if not len(temp.values()) == len(set(temp.values())):\n            msg = 'A position can only be occupied by a single measurement'\n            raise Exception(msg)\n\n        for k, pos in positions.items():\n            if not self._is_valid_position(pos):\n                msg = 'Position {} is not supported for this collection'.format(pos)\n                raise ValueError(msg)\n            self._positions[k] = pos\n            self[k]._set_position(self.ID, pos)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_positions(self, copy=True):\n        '''\n        Get a dictionary of measurement positions.\n        '''\n        if copy:\n            return self._positions.copy()\n        else:\n            return self._positions", "response": "Get a dictionary of measurement positions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new instance with rows and cols that have no assigned measurements.", "response": "def dropna(self):\n        '''\n        Remove rows and cols that have no assigned measurements.\n        Return new instance.\n        '''\n        new = self.copy()\n        tmp = self._dict2DF(self, nan, True)\n        new.row_labels = list(tmp.index)\n        new.col_labels = list(tmp.columns)\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying a function to each of the specified measurements.", "response": "def apply(self, func, ids=None, applyto='measurement',\n              output_format='DataFrame', noneval=nan,\n              setdata=False, dropna=False, ID=None):\n        \"\"\"\n        Apply func to each of the specified measurements.\n\n        Parameters\n        ----------\n        func : callable\n            Accepts a Measurement object or a DataFrame.\n        ids : hashable| iterable of hashables | None\n            Keys of measurements to which func will be applied.\n            If None is given apply to all measurements.\n        applyto :  'measurement' | 'data'\n            'measurement' : apply to measurements objects themselves.\n            'data'        : apply to measurement associated data\n        output_format: ['DataFrame' | 'dict' | 'collection']\n        noneval : obj\n            Value returned if applyto is 'data' but no data is available.\n        setdata : bool\n            Whether to set the data in the Measurement object.\n            Used only if data is not already set.\n        dropna : bool\n            whether to remove rows/cols that contain no measurements.\n        ID : [None | str | numeric]\n            ID is used as the new ID for the collection.\n            If None, then the old ID is retained.\n            Note: Only applicable when output is a collection.\n\n        Returns\n        -------\n        DataFrame/Dictionary/Collection containing the output of func for each Measurement.\n        \"\"\"\n        _output = 'collection' if output_format == 'collection' else 'dict'\n        result = super(OrderedCollection, self).apply(func, ids, applyto,\n                                                      noneval, setdata,\n                                                      output_format=_output)\n\n        # Note: result should be of type dict or collection for the code\n        # below to work\n        if output_format is 'dict':\n            return result\n        elif output_format is 'DataFrame':\n            return self._dict2DF(result, noneval, dropna)\n        elif output_format is 'collection':\n            return result\n        else:\n            msg = (\"output_format must be either 'dict' or 'DataFrame'. \" +\n                   \"Encountered unsupported value %s.\" % repr(output_format))\n            raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a function on each well in the plate.", "response": "def grid_plot(self, func, applyto='measurement', ids=None,\n                  row_labels=None, col_labels=None,\n                  xlim='auto', ylim='auto',\n                  xlabel=None, ylabel=None,\n                  colorbar=True,\n                  row_label_xoffset=None, col_label_yoffset=None,\n                  hide_tick_labels=True, hide_tick_lines=True,\n                  hspace=0, wspace=0,\n                  row_labels_kwargs={}, col_labels_kwargs={}):\n        \"\"\"\n        Creates subplots for each well in the plate. Uses func to plot on each axis.\n        Follow with a call to matplotlibs show() in order to see the plot.\n\n        Parameters\n        ----------\n        func : callable\n            func is a callable that accepts a measurement\n            object (with an optional axis reference) and plots on the current axis.\n            Return values from func are ignored.\n            .. note: if using applyto='measurement', the function\n            when querying for data should make sure that the data\n            actually exists\n        applyto : 'measurement' | 'data'\n        {_graph_grid_layout}\n        {bases_OrderedCollection_grid_plot_pars}\n\n        Returns\n        -------\n        {_graph_grid_layout_returns}\n\n        Examples\n        ---------\n        >>> def y(well, ax):\n        >>>     data = well.get_data()\n        >>>     if data is None:\n        >>>         return None\n        >>>     graph.plotFCM(data, 'Y2-A')\n        >>> def z(data, ax):\n        >>>     plot(data[0:100, 1], data[0:100, 2])\n        >>> plate.plot(y, applyto='measurement');\n        >>> plate.plot(z, applyto='data');\n        \"\"\"\n        # Acquire call arguments to be passed to create plate layout\n        callArgs = locals().copy()  # This statement must remain first. The copy is just defensive.\n        [callArgs.pop(varname) for varname in\n         ['self', 'func', 'applyto', 'ids', 'colorbar', 'xlim', 'ylim']]  # pop args\n\n        callArgs['rowNum'] = self.shape[0]\n        callArgs['colNum'] = self.shape[1]\n\n        subplots_adjust_args = {}\n        subplots_adjust_args.setdefault('right', 0.85)\n        subplots_adjust_args.setdefault('top', 0.85)\n        pl.subplots_adjust(**subplots_adjust_args)\n\n        # Uses plate default row/col labels if user does not override them by specifying row/col\n        # labels\n        if row_labels == None: callArgs['row_labels'] = self.row_labels\n        if col_labels == None: callArgs['col_labels'] = self.col_labels\n\n        ax_main, ax_subplots = graph.create_grid_layout(**callArgs)\n        subplots_ax = DF(ax_subplots, index=self.row_labels, columns=self.col_labels)\n\n        if ids is None:\n            ids = self.keys()\n        ids = to_list(ids)\n\n        for ID in ids:\n            measurement = self[ID]\n            if not hasattr(measurement, 'data'):\n                continue\n\n            row, col = self._positions[ID]\n            ax = subplots_ax[col][row]\n            pl.sca(ax)  # sets the current axis\n\n            if applyto == 'measurement':\n                func(measurement, ax)  # reminder: pandas row/col order is reversed\n            elif applyto == 'data':\n                data = measurement.get_data()\n                if data is not None:\n                    if func.func_code.co_argcount == 1:\n                        func(data)\n                    else:\n                        func(data, ax)\n            else:\n                raise ValueError('Encountered unsupported value {} for applyto parameter.'.format(\n                    applyto))\n\n        # Autoscaling axes\n        graph.scale_subplots(ax_subplots, xlim=xlim, ylim=ylim)\n\n        #####\n        # Placing ticks on the top left subplot\n        ax_label = ax_subplots[0, -1]\n        pl.sca(ax_label)\n\n        if xlabel:\n            xlim = ax_label.get_xlim()\n            pl.xticks([xlim[0], xlim[1]], rotation=90)\n\n        if ylabel:\n            ylim = ax_label.get_ylim()\n            pl.yticks([ylim[0], ylim[1]], rotation=0)\n\n        pl.sca(ax_main)  # sets to the main axis -- more intuitive\n\n        return ax_main, ax_subplots"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises appropriate exception if gate was defined incorrectly.", "response": "def validate_input(self):\n        \"\"\"Raise appropriate exception if gate was defined incorrectly.\"\"\"\n        if self.vert[1] <= self.vert[0]:\n            raise ValueError(u'{} must be larger than {}'.format(self.vert[1], self.vert[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _identify(self, dataframe):\n        idx = ((dataframe[self.channels[0]] <= self.vert[1]) &\n               (dataframe[self.channels[0]] >= self.vert[0]))\n\n        if self.region == 'out':\n            idx = ~idx\n\n        return idx", "response": "Return bool series which is True for indexes that pass the gate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot(self, flip=False, ax_channels=None, ax=None, *args, **kwargs):\n        if ax == None:\n            ax = pl.gca()\n\n        if ax_channels is not None:\n            flip = self._find_orientation(ax_channels)\n\n        plot_func = ax.axes.axhline if flip else ax.axes.axvline\n\n        kwargs.setdefault('color', 'black')\n        a1 = plot_func(self.vert[0], *args, **kwargs)\n        a2 = plot_func(self.vert[1], *args, **kwargs)\n\n        return (a1, a2)", "response": "Plot the entry - time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nidentifying the points that pass the filter.", "response": "def _identify(self, dataframe):\n        \"\"\"\n        Returns a list of indexes containing only the points that pass the filter.\n\n        Parameters\n        ----------\n        dataframe : DataFrame\n        \"\"\"\n        ##\n        # TODO Fix this implementation. (i.e., why not support just 'left')\n        # At the moment this implementation won't work at all.\n        # The logic here can be simplified.\n        id1 = dataframe[self.channels[0]] >= self.vert[0]\n        id2 = dataframe[self.channels[1]] >= self.vert[1]\n\n        if 'left' in self.region: id1 = ~id1\n        if 'bottom' in self.region: id2 = ~id2\n\n        idx = id1 & id2\n\n        if 'out' in self.region:\n            idx = ~idx\n\n        return idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots the entry in the order of the channel.", "response": "def plot(self, flip=False, ax_channels=None, ax=None, *args, **kwargs):\n        \"\"\"\n        {_gate_plot_doc}\n        \"\"\"\n        if ax == None:\n            ax = pl.gca()\n\n        kwargs.setdefault('color', 'black')\n\n        if ax_channels is not None:\n            flip = self._find_orientation(ax_channels)\n\n        if not flip:\n            a1 = ax.axes.axvline(self.vert[0], *args, **kwargs)\n            a2 = ax.axes.axhline(self.vert[1], *args, **kwargs)\n        else:\n            a1 = ax.axes.axvline(self.vert[1], *args, **kwargs)\n            a2 = ax.axes.axhline(self.vert[0], *args, **kwargs)\n\n        return (a1, a2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _identify(self, dataframe):\n        path = Path(self.vert)\n        idx = path.contains_points(dataframe.filter(self.channels))\n\n        if self.region == 'out':\n            idx = ~idx\n\n        return idx", "response": "Identify the set of points that pass the filter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the current state of the object.", "response": "def plot(self, flip=False, ax_channels=None, ax=None, *args, **kwargs):\n        \"\"\"\n        {_gate_plot_doc}\n        \"\"\"\n        if ax == None:\n            ax = pl.gca()\n\n        if ax_channels is not None:\n            flip = self._find_orientation(ax_channels)\n        if flip:\n            vert = [v[::-1] for v in self.vert]\n        else:\n            vert = self.vert\n        kwargs.setdefault('fill', False)\n        kwargs.setdefault('color', 'black')\n        poly = pl.Polygon(vert, *args, **kwargs)\n        return ax.add_artist(poly)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot(self, flip=False, ax_channels=None, ax=None, *args, **kwargs):\n        for gate in self.gates:\n            gate.plot(flip=flip, ax_channels=ax_channels, ax=ax, *args, **kwargs)", "response": "Plot the current state of all the related objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_paths():\n    import os\n    base_path = os.path.dirname(os.path.abspath(__file__))\n    test_data_dir = os.path.join(base_path, 'tests', 'data', 'Plate01')\n    test_data_file = os.path.join(test_data_dir, 'RFP_Well_A3.fcs')\n    return test_data_dir, test_data_file", "response": "Generate paths to test data. Done in a function to protect namespace a bit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush a copy of older release to appropriate version directory", "response": "def upload_prev(ver, doc_root='./'):\n    'push a copy of older release to appropriate version directory'\n    local_dir = doc_root + 'build/html'\n    remote_dir = '/usr/share/nginx/pandas/pandas-docs/version/%s/' % ver\n    cmd = 'cd %s; rsync -avz . pandas@pandas.pydata.org:%s -essh'\n    cmd = cmd % (local_dir, remote_dir)\n    print cmd\n    if os.system(cmd):\n        raise SystemExit(\n            'Upload to %s from %s failed' % (remote_dir, local_dir))\n\n    local_dir = doc_root + 'build/latex'\n    pdf_cmd = 'cd %s; scp pandas.pdf pandas@pandas.pydata.org:%s'\n    pdf_cmd = pdf_cmd % (local_dir, remote_dir)\n    if os.system(pdf_cmd):\n        raise SystemExit('Upload PDF to %s from %s failed' % (ver, doc_root))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plotFCM(data, channel_names, kind='histogram', ax=None,\n            autolabel=True, xlabel_kwargs={}, ylabel_kwargs={},\n            colorbar=False, grid=False,\n            **kwargs):\n    \"\"\"\n    Plots the sample on the current axis.\n\n    Follow with a call to matplotlibs show() in order to see the plot.\n\n    Parameters\n    ----------\n    data : DataFrame\n    {graph_plotFCM_pars}\n    {common_plot_ax}\n\n    Returns\n    -------\n    The output of the plot command used\n    \"\"\"\n\n    if ax == None: ax = pl.gca()\n\n    xlabel_kwargs.setdefault('size', 16)\n    ylabel_kwargs.setdefault('size', 16)\n\n    channel_names = to_list(channel_names)\n\n    if len(channel_names) == 1:\n        # 1D so histogram plot\n        kwargs.setdefault('color', 'gray')\n        kwargs.setdefault('histtype', 'stepfilled')\n        kwargs.setdefault('bins', 200)  # Do not move above\n\n        x = data[channel_names[0]].values\n        if len(x) >= 1:\n            if (len(x) == 1) and isinstance(kwargs['bins'], int):\n                # Only needed for hist (not hist2d) due to hist function doing\n                # excessive input checking\n                warnings.warn(\"One of the data sets only has a single event. \"\n                              \"This event won't be plotted unless the bin locations\"\n                              \" are explicitly provided to the plotting function. \")\n                return None\n            plot_output = ax.hist(x, **kwargs)\n        else:\n            return None\n\n    elif len(channel_names) == 2:\n        x = data[channel_names[0]].values  # value of first channel\n        y = data[channel_names[1]].values  # value of second channel\n\n        if len(x) == 0:\n            # Don't draw a plot if there's no data\n            return None\n        if kind == 'scatter':\n            kwargs.setdefault('edgecolor', 'none')\n            plot_output = ax.scatter(x, y, **kwargs)\n        elif kind == 'histogram':\n            kwargs.setdefault('bins', 200)  # Do not move above\n            kwargs.setdefault('cmin', 1)\n            kwargs.setdefault('cmap', pl.cm.copper)\n            kwargs.setdefault('norm', matplotlib.colors.LogNorm())\n            plot_output = ax.hist2d(x, y, **kwargs)\n            mappable = plot_output[-1]\n\n            if colorbar:\n                pl.colorbar(mappable, ax=ax)\n        else:\n            raise ValueError(\"Not a valid plot type. Must be 'scatter', 'histogram'\")\n    else:\n        raise ValueError('Received an unexpected number of channels: \"{}\"'.format(channel_names))\n\n    pl.grid(grid)\n\n    if autolabel:\n        y_label_text = 'Counts' if len(channel_names) == 1 else channel_names[1]\n        ax.set_xlabel(channel_names[0], **xlabel_kwargs)\n        ax.set_ylabel(y_label_text, **ylabel_kwargs)\n\n    return plot_output", "response": "Plots the FCM of the sample on the current axis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a 2D grid layout of the specified rows and columns.", "response": "def create_grid_layout(rowNum=8, colNum=12, row_labels=None, col_labels=None,\n                       xlim=None, ylim=None,\n                       xlabel=None, ylabel=None,\n                       row_label_xoffset=None, col_label_yoffset=None,\n                       hide_tick_labels=True, hide_tick_lines=False,\n                       hspace=0, wspace=0,\n                       row_labels_kwargs={},\n                       col_labels_kwargs={},\n                       subplot_kw={},\n                       xscale=None, yscale=None,\n                       plotFuncList=None):\n    \"\"\"\n    Creates a figure with a 2d matrix of subplots (rows=rowNum, cols=colNum), automatically annotating\n    and setting default plotting settings for the subplots.\n\n    The function creates a main axes that is invisible but\n    can be used for setting x and y labels.\n    On top of the main axes, it creates the subplots, which are used for plotting.\n\n    Parameters\n    ----------\n    rowNum : int\n        Specifies the number of rows\n    colNum : int\n        Specifies the number of columns\n    row_labels : [list of str, None]\n        Used for labeling each row of subplots\n        If set to None, no labels are written. Default is None.\n    col_labels : [list of str, None]\n        Used for labeling each col of subplots.\n        If set to None, no labels are written. Default is None.\n    {_graph_grid_layout}\n    plotFuncList : list of callable functions\n        Each function must accept row, col arguments\n        Each of these functions must know how to plot using the row, col arguments\n\n    Returns\n    -------\n    {_graph_grid_layout_returns}\n\n    How to use\n    ----------\n    Call this function with the desired parameters.\n    Use the references to the individual subplot axis to plot.\n\n    Call autoscale() command after plotting on the subplots in order to adjust their limits properly.\n    \"\"\"\n\n    fig = plt.gcf()  # get reference to current open figure\n\n    # Configure main axis appearance\n    ax_main = plt.gca()\n\n    # Hides the main axis but retains the ability to use xlabel, ylabel\n    for spine in ax_main.spines.values():\n        spine.set_visible(False)\n    ax_main.patch.set_alpha(0)\n    # ax_main.axison = False # If true, xlabel and ylabel do not work\n\n    _set_tick_lines_visibility(ax_main, False)\n    _set_tick_labels_visibility(ax_main, False)\n\n    # Configure subplot appearance\n    subplot_kw.update(xlim=xlim, ylim=ylim, xscale=xscale,\n                      yscale=yscale)  # This could potentially confuse a user\n\n    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n    _, ax_subplots = plt.subplots(rowNum, colNum, squeeze=False,\n                                  subplot_kw=subplot_kw, num=fig.number)\n\n    # configure defaults for appearance of row and col labels\n    row_labels_kwargs.setdefault('horizontalalignment', 'right')\n    row_labels_kwargs.setdefault('verticalalignment', 'center')\n    row_labels_kwargs.setdefault('size', 'x-large')\n\n    col_labels_kwargs.setdefault('horizontalalignment', 'center')\n    col_labels_kwargs.setdefault('verticalalignment', 'top')\n    col_labels_kwargs.setdefault('size', 'x-large')\n\n    # Translate using figure coordinates\n\n    row_label_translation = -0.10\n\n    if row_label_xoffset:\n        row_label_translation -= row_label_xoffset\n\n    col_label_translation = -0.10\n\n    if col_label_yoffset:\n        col_label_translation -= col_label_yoffset\n\n    offset_row_labels = transforms.ScaledTranslation(row_label_translation, 0, fig.dpi_scale_trans)\n    offset_col_labels = transforms.ScaledTranslation(0, col_label_translation, fig.dpi_scale_trans)\n\n    for (row, col), ax in numpy.ndenumerate(ax_subplots):\n        plt.sca(ax)  # Sets the current axis for all plotting operations\n\n        if row_labels is not None and col == 0:\n            plt.text(0, 0.5, '{0}'.format(row_labels[row]),\n                     transform=(ax.transAxes + offset_row_labels), **row_labels_kwargs)\n            # plt.text(0 + row_label_translation, 0.5, '{0}'.format(row_labels[row]), transform=(ax.transAxes), **row_labels_kwargs)\n\n        if col_labels is not None and row == (rowNum - 1):\n            plt.text(0.5, 0, '{0}'.format(col_labels[col]),\n                     transform=(ax.transAxes + offset_col_labels), **col_labels_kwargs)\n            # plt.text(0.5, 0+ col_label_translation, '{0}'.format(col_labels[col]), transform=(ax.transAxes), **col_labels_kwargs)\n\n        if row == 0 and col == colNum - 1:\n            visible = [False, False]\n\n            if xlabel:\n                ax.xaxis.tick_top()\n                ax.xaxis.set_label_position('top')\n                ax.set_xlabel(xlabel, fontsize='large', labelpad=5)\n                visible[0] = True\n\n            if ylabel:\n                ax.yaxis.tick_right()\n                ax.yaxis.set_label_position('right')\n                ax.set_ylabel(ylabel, fontsize='large', labelpad=5)\n                visible[1] = True\n\n            _set_tick_lines_visibility(ax, visible)\n            _set_tick_labels_visibility(ax, visible)\n        else:\n            if hide_tick_lines:\n                _set_tick_lines_visibility(ax, False)\n            if hide_tick_labels:\n                _set_tick_labels_visibility(ax, False)\n\n        if plotFuncList is not None:\n            for plot_function in plotFuncList:\n                plot_function(row, col)\n\n    # Make sure this is right before the return statement.\n    # It is here to comply with a user's expectation to calls that make reference to gca().\n    plt.sca(ax_main)\n\n    return (ax_main, ax_subplots)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autoscale_subplots(subplots=None, axis='both'):\n    axis_options = ('x', 'y', 'both', 'none', '', 'xy', 'yx')\n    if axis.lower() not in axis_options:\n        raise ValueError('axis must be in {0}'.format(axis_options))\n\n    if subplots is None:\n        subplots = plt.gcf().axes\n\n    data_limits = [(ax.xaxis.get_data_interval(), ax.yaxis.get_data_interval()) for loc, ax in\n                   numpy.ndenumerate(subplots)]  # TODO: Make a proper iterator\n    xlims, ylims = zip(*data_limits)\n\n    xmins_list, xmaxs_list = zip(*xlims)\n    ymins_list, ymaxs_list = zip(*ylims)\n\n    xmin = numpy.min(xmins_list)\n    xmax = numpy.max(xmaxs_list)\n\n    ymin = numpy.min(ymins_list)\n    ymax = numpy.max(ymaxs_list)\n\n    for loc, ax in numpy.ndenumerate(subplots):\n        if axis in ('x', 'both', 'xy', 'yx'):\n            ax.set_xlim((xmin, xmax))\n        if axis in ('y', 'both', 'xy', 'yx'):\n            ax.set_ylim((ymin, ymax))", "response": "Set the x and y limits for each subplot to match the x and y limits of the most extreme data points encountered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the x and y limits for a collection of subplots.", "response": "def scale_subplots(subplots=None, xlim='auto', ylim='auto'):\n    \"\"\"Set the x and y axis limits for a collection of subplots.\n\n    Parameters\n    -----------\n    subplots : ndarray or list of matplotlib.axes.Axes\n\n    xlim : None | 'auto' | (xmin, xmax)\n        'auto' : sets the limits according to the most\n        extreme values of data encountered.\n    ylim : None | 'auto' | (ymin, ymax)\n    \"\"\"\n    auto_axis = ''\n    if xlim == 'auto':\n        auto_axis += 'x'\n    if ylim == 'auto':\n        auto_axis += 'y'\n\n    autoscale_subplots(subplots, auto_axis)\n\n    for loc, ax in numpy.ndenumerate(subplots):\n        if 'x' not in auto_axis:\n            ax.set_xlim(xlim)\n        if 'y' not in auto_axis:\n            ax.set_ylim(ylim)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_ndpanel(panel, func=None,\n                 xlim='auto', ylim='auto',\n                 row_labels='auto', col_labels='auto',\n                 row_name='auto', col_name='auto',\n                 pass_slicing_meta_to_func=False,\n                 subplot_xlabel=None, subplot_ylabel=None,\n                 row_name_pad=40.0, col_name_pad=40.0,\n                 hspace=0, wspace=0,\n                 hide_tick_labels=True, hide_tick_lines=False,\n                 legend=None, legend_title=None,\n                 grid_kwargs={},\n                 **kwargs):\n    \"\"\"Use to visualize mutli-dimensional data stored in N-dimensional pandas panels.\n\n    Given an nd-panel of shape (.., .., .., rows, cols), the function creates a 2d grid of subplot\n    of shape (rows, cols). subplot i, j calls func parameter with an (n-2) nd panel\n    that corresponds to (..., .., .., i, j).\n\n    Parameters\n    ---------------\n    panel : pandas Panel (3d-5d.. indexing is hard coded at the moment)\n        items : time series generated along this axis\n        major : rows\n        minor : cols\n    func : function that accepts a slice of a panel (two dimensions less than input panel)\n    {_graph_grid_layout}\n\n    pass_slicing_meta_to_func : [False | True]\n        Changes the arguments that are passed to the provided function.\n        If False: func(data_slice, **kwargs) (Default)\n        If True: func(data_slice, row=row, col=col, row_value=row_value, col_value=col_value, **kwargs)\n\n    grid_kwargs : dict\n        kwargs to be passed to the create_grid_layout method. See its documentation for further details.\n    legend : None, tuple\n        If provided as tuple, must be a 2-d tuple corresponding to a subplot position.\n        If legend=(2, 4), then the legend will drawn using the labels of the lines provided\n        in subplot in 2nd row and 4th column.\n        A better name could be subplot_source_for_legend?\n    legend_title : str, None\n        If provided, used as title for the legend.\n\n    Returns\n    ---------------\n\n    Reference to main axis and to subplot axes.\n\n    Examples\n    ----------------\n\n    if a is a panel:\n\n    plot_panel(a, func=plot, marker='o');\n\n    Code that could be useful\n    ---------------------------\n\n    # Checks number of arguments function accepts\n    if func.func_code.co_argcount == 1:\n        func(data)\n    else:\n        func(data, ax)\n\n    \"\"\"\n    auto_col_name, auto_col_labels, auto_row_name, auto_row_labels = extract_annotation(panel)\n    shape = panel.values.shape\n    rowNum, colNum = shape[-2], shape[-1]  # Last two are used for setting up the size\n    ndim = len(shape)\n\n    if ndim < 2 or ndim > 5:\n        raise Exception('Only dimensions between 2 and 5 are supported')\n\n    if row_labels == 'auto':\n        row_labels = auto_row_labels\n    if col_labels == 'auto':\n        col_labels = auto_col_labels\n\n    # Figure out xlimits and y limits\n    axis = ''  # used below to autoscale subplots\n\n    if xlim == 'auto':\n        xlim = None\n        axis += 'x'\n    if ylim == 'auto':\n        ylim = None\n        axis += 'y'\n\n    ax_main, ax_subplots = create_grid_layout(rowNum=rowNum, colNum=colNum,\n                                              row_labels=row_labels, col_labels=col_labels,\n                                              xlabel=subplot_xlabel, ylabel=subplot_ylabel,\n                                              hide_tick_labels=hide_tick_labels,\n                                              hide_tick_lines=hide_tick_lines,\n                                              xlim=xlim, ylim=ylim, hspace=hspace, wspace=wspace,\n                                              **grid_kwargs)\n\n    nrange = arange(ndim)\n    nrange = list(nrange[(nrange - 2) % ndim])  # Moves the last two dimensions to the first two\n\n    if not isinstance(panel, pandas.DataFrame):\n        panel = panel.transpose(*nrange)\n\n    for (row, col), ax in numpy.ndenumerate(ax_subplots):\n        plt.sca(ax)\n\n        data_slice = panel.iloc[row].iloc[col]\n        row_value = panel.axes[0][row]\n        col_value = panel.axes[1][col]\n\n        if pass_slicing_meta_to_func:\n            func(data_slice, row=row, col=col, row_value=row_value, col_value=col_value, **kwargs)\n        else:\n            func(data_slice, **kwargs)\n\n    autoscale_subplots(ax_subplots, axis)\n\n    plt.sca(ax_main)\n\n    if legend is not None:\n        items, labels = ax_subplots[legend].get_legend_handles_labels()\n\n        # lines = ax_subplots[legend].lines\n        # l = pl.legend(lines , map(lambda x : x.get_label(), lines),\n        l = pl.legend(items, labels,\n                      bbox_to_anchor=(0.9, 0.5), bbox_transform=pl.gcf().transFigure,\n                      loc='center left',\n                      numpoints=1, frameon=False)\n        if legend_title is not None:\n            l.set_title(legend_title)\n\n    if row_name == 'auto':\n        row_name = auto_row_name\n    if col_name == 'auto':\n        col_name = auto_col_name\n    if row_name is not None:\n        pl.xlabel(col_name, labelpad=col_name_pad)\n    if col_name is not None:\n        pl.ylabel(row_name, labelpad=row_name_pad)\n\n    #####\n    # Placing ticks on the top left subplot\n    ax_label = ax_subplots[0, -1]\n    pl.sca(ax_label)\n\n    if subplot_xlabel:\n        xticks = numpy.array(pl.xticks()[0], dtype=object)\n        xticks[1::2] = ''\n        ax_label.set_xticklabels(xticks, rotation=90, size='small')\n\n    if subplot_ylabel:\n        yticks = numpy.array(pl.yticks()[0], dtype=object)\n        yticks[1::2] = ''\n        ax_label.set_yticklabels(yticks, rotation=0, size='small')\n\n    pl.sca(ax_main)\n\n    return ax_main, ax_subplots", "response": "Plots mutli - dimensional data stored in N - dimensional pandas panels."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a heat map of a single dataset.", "response": "def plot_heat_map(z, include_values=False,\n                  cmap=matplotlib.cm.Reds,\n                  ax=None,\n                  xlabel='auto', ylabel='auto',\n                  xtick_labels='auto', ytick_labels='auto',\n                  xtick_locs=None, ytick_locs=None,\n                  xtick_kwargs={}, ytick_kwargs={},\n                  clabel_pos='top',\n                  transpose_y=False, convert_to_log_scale=False,\n                  show_colorbar=False, colorbar_dict={},\n                  values_format='{:.2}', values_font_size='small',\n                  values_color=None, values_text_kw={},\n                  bad_color=None,\n                  **kwargs):\n    \"\"\"Plot a heat map of z.\n\n    Parameters\n    -------------\n\n    z : ndarray | DataFrame\n    ax : None # NOT IMPLEMENTED YET\n        Axis to be used. If None uses the current axis.\n    xlabel : str | 'auto' | None\n        name for the x-axis\n    ylabel : str | 'auto' | None\n        name for the y-axis\n    xtick_labels : list of str\n        names for the columns\n    ytick_labels : list of str\n        names for the rows\n    transpose_y : bool\n        Flips the data along the y axis if true\n    convert_to_log_scale : bool\n        If true, plots the log of z.\n    clabel_pos : 'top' | 'bottom'\n        Location of the column labels. Default is 'top'.\n    cmap : colormap | str\n        colormap to use for plotting the values; e.g., matplotlib.cmap.Blues,\n        if str then expecting something like 'Blues' to look up using getattr(matplotlib.cm, ...)\n    values_color : None | color\n        if None, coloring will be the inverse of cmap\n        Otherwise the color given would be used for the text color of all the values.\n    bad_color : color\n        This is the color that will be used for nan values\n\n    Returns\n    ---------------\n        Output from matshow command (matplotlib.image.AxesImage)\n    \"\"\"\n    # TODO: Add possibility to change rotation, size, etc. of xtick markers\n    # TODO: Rename in API : xtick_labels and ytick_labels\n    # TODO: Implement ax\n\n    # Setting default font sizes\n    xtick_kwargs.setdefault('fontsize', 'large')\n    ytick_kwargs.setdefault('fontsize', 'large')\n\n    ##\n    # Figure out annotation for axes based on data frame.\n    # DataFrame annotation is used only if 'auto' was given\n    # to the annotation.\n    auto_col_name, auto_col_labels, auto_row_name, auto_row_labels = extract_annotation(z)\n\n    if xtick_labels is 'auto': xtick_labels = auto_col_labels\n    if ytick_labels is 'auto': ytick_labels = auto_row_labels\n    if xlabel is 'auto': xlabel = auto_col_name\n    if ylabel is 'auto': ylabel = auto_row_name\n\n    if isinstance(z, pandas.DataFrame):\n        values = z.values\n    else:\n        values = z\n\n    if convert_to_log_scale:\n        values = numpy.log(values)\n\n    if transpose_y:\n        values = numpy.flipud(values)\n\n    if isinstance(cmap, str):\n        cmap = getattr(cm, cmap)\n\n    old_ax = plt.gca()\n\n    if ax is not None:\n        plt.sca(ax)\n    else:\n        ax = plt.gca()\n\n    output = ax.matshow(values, cmap=cmap, **kwargs)\n\n    #####\n    # Make the colorbar pretty\n    #\n    if show_colorbar:\n        from mpl_toolkits.axes_grid1 import make_axes_locatable\n        divider = make_axes_locatable(ax)\n\n        colorbar_dict.setdefault('size', \"5%\")\n        colorbar_dict.setdefault('pad', 0.05)\n        cax = divider.append_axes(\"right\", **colorbar_dict)\n        cb = plt.colorbar(output, cax=cax)\n        plt.sca(ax)  # Switch back to original axes\n\n    #######\n    # Annotate the heat amp\n    #\n    if xtick_labels is not None and len(xtick_labels) > 0:\n        if xtick_locs:\n            plt.xticks(xtick_locs, xtick_labels, **xtick_kwargs)\n        else:\n            plt.xticks(range(len(xtick_labels)), xtick_labels, **xtick_kwargs)\n\n    if ytick_labels is not None and len(ytick_labels) > 0:\n        if ytick_locs:\n            plt.yticks(ytick_locs, ytick_labels, **ytick_kwargs)\n        else:\n            plt.yticks(range(len(ytick_labels)), ytick_labels, **ytick_kwargs)\n\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n\n    if include_values:\n        def text_cmap(x):\n            if numpy.isnan(x):\n                return cmap(1.0)\n            if x > 0.2 and x < 0.5:\n                x = 0.2\n            if x < 0.8 and x >= 0.5:\n                x = 0.8\n            return cmap(1.0 - x)\n\n        values_text_kw['fontsize'] = values_font_size\n        values_text_kw['color'] = values_color\n        _plot_table(values, text_format=values_format, cmap=text_cmap, **values_text_kw)\n\n    # Changes the default position for the xlabel to the 'top'\n    xaxis = ax.xaxis\n\n    if clabel_pos == 'top':\n        xaxis.set_label_position('top')\n        xaxis.tick_top()\n    else:\n        ax.xaxis.tick_bottom()\n        ax.xaxis.set_label_position('bottom')\n\n    ##\n    # Can get rid of the part below when the part above\n    # is rewritten so that changes are applied specifically to the axes\n    # object rather than using the method interface.\n    plt.sca(old_ax)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot a numpy matrix as a table.", "response": "def _plot_table(matrix, text_format='{:.2f}', cmap=None, **kwargs):\n    \"\"\"\n    Plot a numpy matrix as a table. Uses the current axis bounding box to decide on limits.\n    text_format specifies the formatting to apply to the values.\n\n    Parameters\n    ----------\n\n    matrix : ndarray\n\n    text_format : str\n        Indicates how to format the the values\n        text_format = {:.2} -> keeps all digits until the first 2 significant digits past the decimal\n        text_format = {:.2f} -> keeps only 2 digits past the decimal\n\n    cmap : None | colormap\n        if a colormap is provided, this colormap will be used to choose the color of the text.\n\n    **kwargs : all other arguments passed to plt.text function\n\n    Examples\n    ----------\n\n    plot_table(numpy.random.random((3,3))\n    plt.show()\n    \"\"\"\n    shape = matrix.shape\n\n    xtick_pos = numpy.arange(shape[1])\n    ytick_pos = numpy.arange(shape[0])\n\n    xtick_grid, ytick_grid = numpy.meshgrid(xtick_pos, ytick_pos)\n\n    vmax = numpy.nanmax(matrix)\n    vmin = numpy.nanmin(matrix)\n\n    if not kwargs.get('color', None) and cmap is not None:\n        use_cmap = True\n        norm = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax, clip=False)\n    else:\n        use_cmap = False\n\n    for (row, col), w in numpy.ndenumerate(matrix):\n        x = xtick_grid[row, col]\n        y = ytick_grid[row, col]\n\n        if use_cmap:\n            kwargs['color'] = cmap(norm(w))\n\n        plt.text(x, y, text_format.format(w), horizontalalignment='center',\n                 verticalalignment='center', transform=plt.gca().transData, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the visibility of the tick lines of the requested axis.", "response": "def _set_tick_lines_visibility(ax, visible=True):\n    \"\"\"Set the visibility of the tick lines of the requested axis.\"\"\"\n    for i, thisAxis in enumerate((ax.get_xaxis(), ax.get_yaxis())):\n        for thisItem in thisAxis.get_ticklines():\n            if isinstance(visible, list):\n                thisItem.set_visible(visible[i])\n            else:\n                thisItem.set_visible(visible)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_tick_labels_visibility(ax, visible=True):\n    for i, thisAxis in enumerate((ax.get_xaxis(), ax.get_yaxis())):\n        for thisItem in thisAxis.get_ticklabels():\n            if isinstance(visible, list):\n                thisItem.set_visible(visible[i])\n            else:\n                thisItem.set_visible(visible)", "response": "Set the visibility of the tick labels of the requested axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts names and values of rows and columns.", "response": "def extract_annotation(data):\n    \"\"\"Extract names and values of rows and columns.\n\n    Parameter:\n        data : DataFrame | Panel\n\n    Returns:\n        col_name, col_values, row_name, row_values\n    \"\"\"\n    xlabel = None\n    xvalues = None\n    ylabel = None\n    yvalues = None\n    if hasattr(data, 'minor_axis'):\n        xvalues = data.minor_axis\n        if hasattr(data.minor_axis, 'name'):\n            xlabel = data.minor_axis.name\n    if hasattr(data, 'columns'):\n        xvalues = data.columns\n        if hasattr(data.columns, 'name'):\n            xlabel = data.columns.name\n    if hasattr(data, 'major_axis'):\n        yvalues = data.major_axis\n        if hasattr(data.major_axis, 'name'):\n            ylabel = data.major_axis.name\n    if hasattr(data, 'index'):\n        yvalues = data.index\n        if hasattr(data.index, 'name'):\n            ylabel = data.index.name\n    return xlabel, xvalues, ylabel, yvalues"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform_using_this_method(original_sample):\n    # Copy the original sample\n    new_sample = original_sample.copy()\n    new_data = new_sample.data\n\n    # Our transformation goes here\n    new_data['Y2-A'] = log(new_data['Y2-A'])\n    new_data = new_data.dropna()  # Removes all NaN entries\n    new_sample.data = new_data\n    return new_sample", "response": "This function implements a log transformation on the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the datafile specified in Sample. datafile and return the resulting object.", "response": "def read_data(self, **kwargs):\n        '''\n        Read the datafile specified in Sample.datafile and\n        return the resulting object.\n        Does NOT assign the data to self.data\n\n        It's advised not to use this method, but instead to access\n        the data through the FCMeasurement.data attribute.\n        '''\n        meta, data = parse_fcs(self.datafile, **kwargs)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_meta(self, **kwargs):\n        '''\n        Read only the annotation of the FCS file (without reading DATA segment).\n\n        It's advised not to use this method, but instead to access\n        the meta data through the FCMeasurement.meta attribute.\n        '''\n        # TODO Try to rewrite the code to be more logical\n        # The reason the equivalent statement is not in the read_data method\n        # above is because self.readdata_kwargs are passed\n        # as **kwargs to the read_data function.\n        if 'channel_naming' in self.readdata_kwargs:\n            kwargs['channel_naming'] = self.readdata_kwargs['channel_naming']\n        meta = parse_fcs(self.datafile,\n                         reformat_meta=True,\n                         meta_data_only=True, **kwargs)\n        return meta", "response": "Read the metadata of the FCS file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_meta_fields(self, fields, kwargs={}):\n        '''\n        Return a dictionary of metadata fields\n        '''\n        fields = to_list(fields)\n        meta = self.get_meta()\n        return {field: meta.get(field) for field in fields}", "response": "Return a dictionary of metadata fields"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ID_from_data(self, ID_field='$SRC'):\n        '''\n        Returns the well ID from the src keyword in the FCS file. (e.g., A2)\n        This keyword may not appear in FCS files generated by other machines,\n        in which case this function will raise an exception.\n        '''\n        try:\n            return self.get_meta_fields(ID_field)[ID_field]\n        except KeyError:\n            msg = \"The keyword '{}' does not exist in the following FCS file: {}\"\n            msg = msg.format(ID_field, self.datafile)\n            raise Exception(msg)", "response": "Returns the well ID from the src keyword in the FCS file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(self, channel_names, kind='histogram',\n             gates=None, gate_colors=None, gate_lw=1, **kwargs):\n        \"\"\"Plot the flow cytometry data associated with the sample on the current axis.\n\n        To produce the plot, follow up with a call to matplotlib's show() function.\n\n        Parameters\n        ----------\n        {graph_plotFCM_pars}\n        {FCMeasurement_plot_pars}\n        {common_plot_ax}\n        gates : [None, Gate, list of Gate]\n            Gate must be of type {_gate_available_classes}.\n        gate_lw: float | iterable\n            line width to use when drawing gates\n            if float, uses the same line width for all gates\n            if iterable, then cycles between the values\n        kwargs : dict\n            Additional keyword arguments to be passed to graph.plotFCM\n\n        Returns\n        -------\n        None : if no data is present\n        plot_output : output of plot command used to draw (e.g., output of hist)\n\n        Examples\n        --------\n        >>> sample.plot('Y2-A', bins=100, alpha=0.7, color='green', normed=1) # 1d histogram\n        >>> sample.plot(['B1-A', 'Y2-A'], cmap=cm.Oranges, colorbar=False) # 2d histogram\n        \"\"\"\n        ax = kwargs.get('ax')\n\n        channel_names = to_list(channel_names)\n        gates = to_list(gates)\n\n        plot_output = graph.plotFCM(self.data, channel_names, kind=kind, **kwargs)\n\n        if gates is not None:\n            if gate_colors is None:\n                gate_colors = cycle(('b', 'g', 'r', 'm', 'c', 'y'))\n\n            if not isinstance(gate_lw, collections.Iterable):\n                gate_lw = [gate_lw]\n\n            gate_lw = cycle(gate_lw)\n\n            for (g, c, lw) in zip(gates, gate_colors, gate_lw):\n                g.plot(ax=ax, ax_channels=channel_names, color=c, lw=lw)\n\n        return plot_output", "response": "Plot the flow cytometry data associated with the sample on the current axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef view(self, channel_names='auto',\n             gates=None,\n             diag_kw={}, offdiag_kw={},\n             gate_colors=None, **kwargs):\n        \"\"\"\n        Generates a matrix of subplots allowing for a quick way\n        to examine how the sample looks in different channels.\n\n        Parameters\n        ----------\n        channel_names : [list | 'auto']\n            List of channel names to plot.\n        offdiag_plot : ['histogram' | 'scatter']\n            Specifies the type of plot for the off-diagonal elements.\n        diag_kw : dict\n            Not implemented\n\n        Returns\n        ------------\n\n        axes references\n        \"\"\"\n        if channel_names == 'auto':\n            channel_names = list(self.channel_names)\n\n        def plot_region(channels, **kwargs):\n            if channels[0] == channels[1]:\n                channels = channels[0]\n            kind = 'histogram'\n\n            self.plot(channels, kind=kind, gates=gates,\n                      gate_colors=gate_colors, autolabel=False)\n\n        channel_list = np.array(list(channel_names), dtype=object)\n        channel_mat = [[(x, y) for x in channel_list] for y in channel_list]\n        channel_mat = DataFrame(channel_mat, columns=channel_list, index=channel_list)\n        kwargs.setdefault('wspace', 0.1)\n        kwargs.setdefault('hspace', 0.1)\n        return plot_ndpanel(channel_mat, plot_region, **kwargs)", "response": "Generates a matrix of subplots allowing for quick way to examine how the sample looks in different channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_interactively(self, backend='wx'):\n        '''Loads the current sample in a graphical interface for drawing gates.\n\n        Parameters\n        ----------\n        backend: 'auto' | 'wx' | 'webagg'\n            Specifies which backend should be used to view the sample.\n        '''\n        if backend == 'auto':\n            if matplotlib.__version__ >= '1.4.3':\n                backend = 'WebAgg'\n            else:\n                backend = 'wx'\n\n        if backend == 'wx':\n            from FlowCytometryTools.gui.wx_backend import gui\n        elif backend == 'webagg':\n            from FlowCytometryTools.gui.webagg_backend import gui\n        else:\n            raise ValueError('No support for backend {}'.format(backend))\n\n        gui.GUILauncher(measurement=self)", "response": "Loads the current sample in a graphical interface for drawing gates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new measurement with the transformed data.", "response": "def transform(self, transform, direction='forward',\n                  channels=None, return_all=True, auto_range=True,\n                  use_spln=True, get_transformer=False, ID=None,\n                  apply_now=True,\n                  args=(), **kwargs):\n        \"\"\"\n        Applies a transformation to the specified channels.\n\n        The transformation parameters are shared between all transformed channels.\n        If different parameters need to be applied to different channels,\n        use several calls to `transform`.\n\n        Parameters\n        ----------\n        {FCMeasurement_transform_pars}\n        ID : hashable | None\n            ID for the resulting collection. If None is passed, the original ID is used.\n\n        Returns\n        -------\n        new : FCMeasurement\n            New measurement containing the transformed data.\n        transformer : Transformation\n            The Transformation applied to the input measurement.\n            Only returned if get_transformer=True.\n\n        Examples\n        --------\n        {FCMeasurement_transform_examples}\n        \"\"\"\n        # Create new measurement\n        new = self.copy()\n        data = new.data\n\n        channels = to_list(channels)\n        if channels is None:\n            channels = data.columns\n        ## create transformer\n        if isinstance(transform, Transformation):\n            transformer = transform\n        else:\n            if auto_range:  # determine transformation range\n                if 'd' in kwargs:\n                    warnings.warn(\n                        'Encountered both auto_range=True and user-specified range value in '\n                        'parameter d.\\n Range value specified in parameter d is used.')\n                else:\n                    channel_meta = self.channels\n                    # the -1 below because the channel numbers begin from 1 instead of 0\n                    # (this is fragile code)\n                    ranges = [float(r['$PnR']) for i, r in channel_meta.iterrows() if\n                              self.channel_names[i - 1] in channels]\n                    if not np.allclose(ranges, ranges[0]):\n                        raise Exception(\"\"\"Not all specified channels have the same data range,\n                            therefore they cannot be transformed together.\\n\n                            HINT: Try transforming one channel at a time.\n                            You'll need to provide the name of the channel in the transform.\"\"\")\n\n                    if transform in {'hlog', 'tlog', 'hlog_inv', 'tlog_inv'}:\n                        # Hacky fix to make sure that 'd' is provided only\n                        # for hlog / tlog transformations\n                        kwargs['d'] = np.log10(ranges[0])\n            transformer = Transformation(transform, direction, args, **kwargs)\n        ## create new data\n        transformed = transformer(data[channels], use_spln)\n        if return_all:\n            new_data = data\n        else:\n            new_data = data.filter(channels)\n        new_data[channels] = transformed\n        ## update new Measurement\n        new.data = new_data\n\n        if ID is not None:\n            new.ID = ID\n        if get_transformer:\n            return new, transformer\n        else:\n            return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallows arbitrary slicing (subsampling) of the data. Parameters ---------- {FCMeasurement_subsample_parameters} Returns ------- FCMeasurement Sample with subsampled data.", "response": "def subsample(self, key, order='random', auto_resize=False):\n        \"\"\"\n        Allows arbitrary slicing (subsampling) of the data.\n\n        Parameters\n        ----------\n        {FCMeasurement_subsample_parameters}\n\n        Returns\n        -------\n        FCMeasurement\n            Sample with subsampled data.\n        \"\"\"\n\n        data = self.get_data()\n        num_events = data.shape[0]\n\n        if isinstance(key, float):\n            if (key > 1.0) or (key < 0.0):\n                raise ValueError('If float, key must be between 0.0 and 1.0')\n            key = int(num_events * key)\n        elif isinstance(key, tuple):\n            all_float = all([isinstance(x, float) for x in key])\n            if (len(key) > 2) or (not all_float):\n                raise ValueError('Tuple must consist of two floats, each between 0.0 and 1.0')\n            start = int(num_events * key[0])\n            stop = int(num_events * key[1])\n            key = slice(start, stop)  # Convert to a slice\n\n        try:\n            if isinstance(key, slice):\n                if auto_resize:\n                    stop = key.stop if key.stop < num_events else num_events\n                    start = key.start if key.start < num_events else num_events\n                    key = slice(start, stop, key.step)  # Generate new slice\n                newdata = data.iloc[key]\n            elif isinstance(key, int):\n                if auto_resize:\n                    if key > num_events:\n                        key = num_events\n                if key < 1:\n                    # EDGE CAES: Must return an empty sample\n                    order = 'start'\n                if order == 'random':\n                    newdata = data.loc[sample(list(data.index), key)]  # Use loc not iloc here!!\n                elif order == 'start':\n                    newdata = data.iloc[:key]\n                elif order == 'end':\n                    newdata = data.iloc[-key:]\n                else:\n                    raise ValueError(\"order must be in ('random', 'start', 'end')\")\n            else:\n                raise TypeError(\"'key' must be of type int, float, tuple or slice.\")\n        except IndexError:\n            print(\"If you're encountering an out-of-bounds error, \"\n                  \"try to setting 'auto_resize' to True.\")\n            raise\n        newsample = self.copy()\n        newsample.set_data(data=newdata)\n        return newsample"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gate(self, gate, apply_now=True):\n        '''\n        Apply given gate and return new gated sample (with assigned data).\n\n        Parameters\n        ----------\n        gate : {_gate_available_classes}\n\n        Returns\n        -------\n\n        FCMeasurement\n            Sample with data that passes gates\n        '''\n        data = self.get_data()\n        newdata = gate(data)\n        newsample = self.copy()\n        newsample.data = newdata\n        return newsample", "response": "Returns a new FCMeasurement\n            Sample with assigned data applied to the current sample."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, transform, direction='forward', share_transform=True,\n                  channels=None, return_all=True, auto_range=True,\n                  use_spln=True, get_transformer=False, ID=None,\n                  apply_now=True,\n                  args=(), **kwargs):\n        '''\n        Apply transform to each Measurement in the Collection.\n\n        Return a new Collection with transformed data.\n\n        {_containers_held_in_memory_warning}\n\n        Parameters\n        ----------\n        {FCMeasurement_transform_pars}\n        ID : hashable | None\n            ID for the resulting collection. If None is passed, the original ID is used.\n\n        Returns\n        -------\n        new : FCCollection\n            New collection containing the transformed measurements.\n        transformer : Transformation\n            The Transformation applied to the measurements.\n            Only returned if get_transformer=True & share_transform=True.\n\n        Examples\n        --------\n        {FCMeasurement_transform_examples}\n        '''\n        new = self.copy()\n        if share_transform:\n\n            channel_meta = list(self.values())[0].channels\n            channel_names = list(self.values())[0].channel_names\n            if channels is None:\n                channels = list(channel_names)\n            else:\n                channels = to_list(channels)\n            ## create transformer\n            if isinstance(transform, Transformation):\n                transformer = transform\n            else:\n                if auto_range:  # determine transformation range\n                    if 'd' in kwargs:\n                        warnings.warn('Encountered both auto_range=True and user-specified range '\n                                      'value in parameter d.\\n '\n                                      'Range value specified in parameter d is used.')\n                    else:\n                        # the -1 below because the channel numbers begin from 1 instead of 0 (this is fragile code)\n                        ranges = [float(r['$PnR']) for i, r in channel_meta.iterrows() if\n                                  channel_names[i - 1] in channels]\n\n                        if not np.allclose(ranges, ranges[0]):\n                            raise Exception('Not all specified channels have the same '\n                                            'data range, therefore they cannot be '\n                                            'transformed together.')\n\n                        if transform in {'hlog', 'tlog', 'hlog_inv', 'tlog_inv'}:\n                            # Hacky fix to make sure that 'd' is provided only\n                            # for hlog / tlog transformations\n                            kwargs['d'] = np.log10(ranges[0])\n                transformer = Transformation(transform, direction, args, **kwargs)\n                if use_spln:\n                    xmax = self.apply(lambda x: x[channels].max().max(), applyto='data').max().max()\n                    xmin = self.apply(lambda x: x[channels].min().min(), applyto='data').min().min()\n                    transformer.set_spline(xmin, xmax)\n            ## transform all measurements\n            for k, v in new.items():\n                new[k] = v.transform(transformer, channels=channels, return_all=return_all,\n                                     use_spln=use_spln, apply_now=apply_now)\n        else:\n            for k, v in new.items():\n                new[k] = v.transform(transform, direction=direction, channels=channels,\n                                     return_all=return_all, auto_range=auto_range,\n                                     get_transformer=False,\n                                     use_spln=use_spln, apply_now=apply_now, args=args, **kwargs)\n        if ID is not None:\n            new.ID = ID\n        if share_transform and get_transformer:\n            return new, transformer\n        else:\n            return new", "response": "Returns a new FCCollection containing the transformed measurements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the gate to each Measurement in the Collection returning a new Collection with gated data.", "response": "def gate(self, gate, ID=None, apply_now=True):\n        '''\n        Applies the gate to each Measurement in the Collection, returning a new Collection with gated data.\n\n        {_containers_held_in_memory_warning}\n\n        Parameters\n        ----------\n        gate : {_gate_available_classes}\n\n        ID : [ str, numeric, None]\n            New ID to be given to the output. If None, the ID of the current collection will be used.\n        '''\n\n        def func(well):\n            return well.gate(gate, apply_now=apply_now)\n\n        return self.apply(func, output_format='collection', ID=ID)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nallowing arbitrary slicing (subsampling) of the data. .. note:: When using order='random', the sampling is random for each of the measurements in the collection. Parameters ---------- {FCMeasurement_subsample_parameters} Returns ------- FCCollection or a subclass new collection of subsampled event data.", "response": "def subsample(self, key, order='random', auto_resize=False, ID=None):\n        \"\"\"\n        Allows arbitrary slicing (subsampling) of the data.\n\n        .. note::\n\n            When using order='random', the sampling is random\n            for each of the measurements in the collection.\n\n        Parameters\n        ----------\n        {FCMeasurement_subsample_parameters}\n\n        Returns\n        -------\n        FCCollection or a subclass\n            new collection of subsampled event data.\n        \"\"\"\n\n        def func(well):\n            return well.subsample(key=key, order=order, auto_resize=auto_resize)\n\n        return self.apply(func, output_format='collection', ID=ID)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the counts in each of the specified measurements.", "response": "def counts(self, ids=None, setdata=False, output_format='DataFrame'):\n        \"\"\"\n        Return the counts in each of the specified measurements.\n\n        Parameters\n        ----------\n        ids : [hashable | iterable of hashables | None]\n            Keys of measurements to get counts of.\n            If None is given get counts of all measurements.\n        setdata : bool\n            Whether to set the data in the Measurement object.\n            Used only if data is not already set.\n        output_format : DataFrame | dict\n            Specifies the output format for that data.\n\n        Returns\n        -------\n        [DataFrame | Dictionary]\n            Dictionary keys correspond to measurement keys.\n        \"\"\"\n        return self.apply(lambda x: x.counts, ids=ids, setdata=setdata, output_format=output_format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot(self, channel_names, kind='histogram',\n             gates=None, gate_colors=None,\n             ids=None, row_labels=None, col_labels=None,\n             xlim='auto', ylim='auto',\n             autolabel=True,\n             **kwargs):\n        \"\"\"\n        Produces a grid plot with each subplot corresponding to the data at the given position.\n\n        Parameters\n        ---------------\n        {FCMeasurement_plot_pars}\n        {graph_plotFCM_pars}\n        {_graph_grid_layout}\n\n        Returns\n        -------\n        {_graph_grid_layout_returns}\n\n        Examples\n        --------\n\n        Below, plate is an instance of FCOrderedCollection\n\n        >>> plate.plot(['SSC-A', 'FSC-A'], kind='histogram', autolabel=True)\n        >>> plate.plot(['SSC-A', 'FSC-A'], xlim=(0, 10000))\n        >>> plate.plot(['B1-A', 'Y2-A'], kind='scatter', color='red', s=1, alpha=0.3)\n        >>> plate.plot(['B1-A', 'Y2-A'], bins=100, alpha=0.3)\n        >>> plate.plot(['B1-A', 'Y2-A'], bins=[linspace(-1000, 10000, 100), linspace(-1000, 10000, 100)], alpha=0.3)\n\n        .. note::\n\n            For more details see documentation for FCMeasurement.plot\n            **kwargs passes arguments to both grid_plot and to FCMeasurement.plot.\n        \"\"\"\n        ##\n        # Note\n        # -------\n        # The function assumes that grid_plot and FCMeasurement.plot use unique key words.\n        # Any key word arguments that appear in both functions are passed only to grid_plot in the end.\n\n        ##\n        # Automatically figure out which of the kwargs should\n        # be sent to grid_plot instead of two sample.plot\n        # (May not be a robust solution, we'll see as the code evolves\n\n        grid_arg_list = inspect.getargspec(OrderedCollection.grid_plot).args\n\n        grid_plot_kwargs = {'ids': ids,\n                            'row_labels': row_labels,\n                            'col_labels': col_labels}\n\n        for key, value in list(kwargs.items()):\n            if key in grid_arg_list:\n                kwargs.pop(key)\n                grid_plot_kwargs[key] = value\n\n        ##\n        # Make sure channel names is a list to make the code simpler below\n        channel_names = to_list(channel_names)\n\n        ##\n        # Determine data limits for binning\n        #\n\n        if kind == 'histogram':\n            nbins = kwargs.get('bins', 200)\n\n            if isinstance(nbins, int):\n                min_list = []\n                max_list = []\n                for sample in self:\n                    min_list.append(self[sample].data[channel_names].min().values)\n                    max_list.append(self[sample].data[channel_names].max().values)\n\n                min_list = list(zip(*min_list))\n                max_list = list(zip(*max_list))\n\n                bins = []\n\n                for i, c in enumerate(channel_names):\n                    min_v = min(min_list[i])\n                    max_v = max(max_list[i])\n                    bins.append(np.linspace(min_v, max_v, nbins))\n\n                # Check if 1d\n                if len(channel_names) == 1:\n                    bins = bins[0]  # bins should be an ndarray, not a list of ndarrays\n\n                kwargs['bins'] = bins\n\n        ##########\n        # Defining the plotting function that will be used.\n        # At the moment grid_plot handles the labeling\n        # (rather than sample.plot or the base function\n        # in GoreUtilities.graph\n\n        def plot_sample(sample, ax):\n            return sample.plot(channel_names, ax=ax,\n                               gates=gates, gate_colors=gate_colors,\n                               colorbar=False,\n                               kind=kind, autolabel=False, **kwargs)\n\n        xlabel, ylabel = None, None\n\n        if autolabel:\n            cnames = to_list(channel_names)\n            xlabel = cnames[0]\n            if len(cnames) == 2:\n                ylabel = cnames[1]\n\n        return self.grid_plot(plot_sample, xlim=xlim, ylim=ylim,\n                              xlabel=xlabel, ylabel=ylabel,\n                              **grid_plot_kwargs)", "response": "Plots the data for the given channel names."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obj2unicode(obj):\n    if isinstance(obj, unicode_type):\n        return obj\n    elif isinstance(obj, bytes_type):\n        try:\n            return unicode_type(obj, 'utf-8')\n        except UnicodeDecodeError as strerror:\n            sys.stderr.write(\"UnicodeDecodeError exception for string '%s': %s\\n\" % (obj, strerror))\n            return unicode_type(obj, 'utf-8', 'replace')\n    else:\n        return unicode_type(obj)", "response": "Return a unicode representation of a python object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nredefines len here so it will be able to work with non - ASCII characters", "response": "def len(iterable):\n    \"\"\"Redefining len here so it will be able to work with non-ASCII characters\n    \"\"\"\n    if isinstance(iterable, bytes_type) or isinstance(iterable, unicode_type):\n        return sum([uchar_width(c) for c in obj2unicode(iterable)])\n    else:\n        return iterable.__len__()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the characters used to draw lines between rows and columns.", "response": "def set_chars(self, array):\n        \"\"\"Set the characters used to draw lines between rows and columns\n\n        - the array should contain 4 fields:\n\n            [horizontal, vertical, corner, header]\n\n        - default is set to:\n\n            ['-', '|', '+', '=']\n        \"\"\"\n\n        if len(array) != 4:\n            raise ArraySizeError(\"array should contain 4 characters\")\n        array = [ x[:1] for x in [ str(s) for s in array ] ]\n        (self._char_horiz, self._char_vert,\n            self._char_corner, self._char_header) = array\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the desired header alignment for the log entries", "response": "def set_header_align(self, array):\n        \"\"\"Set the desired header alignment\n\n        - the elements of the array should be either \"l\", \"c\" or \"r\":\n\n            * \"l\": column flushed left\n            * \"c\": column centered\n            * \"r\": column flushed right\n        \"\"\"\n\n        self._check_row_size(array)\n        self._header_align = array\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the desired columns alignment", "response": "def set_cols_align(self, array):\n        \"\"\"Set the desired columns alignment\n\n        - the elements of the array should be either \"l\", \"c\" or \"r\":\n\n            * \"l\": column flushed left\n            * \"c\": column centered\n            * \"r\": column flushed right\n        \"\"\"\n\n        self._check_row_size(array)\n        self._align = array\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the desired columns vertical alignment", "response": "def set_cols_valign(self, array):\n        \"\"\"Set the desired columns vertical alignment\n\n        - the elements of the array should be either \"t\", \"m\" or \"b\":\n\n            * \"t\": column aligned on the top of the cell\n            * \"m\": column aligned on the middle of the cell\n            * \"b\": column aligned on the bottom of the cell\n        \"\"\"\n\n        self._check_row_size(array)\n        self._valign = array\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_cols_dtype(self, array):\n\n        self._check_row_size(array)\n        self._dtype = array\n        return self", "response": "Set the desired columns datatype for the columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_precision(self, width):\n\n        if not type(width) is int or width < 0:\n            raise ValueError('width must be an integer greater then 0')\n        self._precision = width\n        return self", "response": "Set the desired precision for float or exponential formats"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef header(self, array):\n\n        self._check_row_size(array)\n        self._header = list(map(obj2unicode, array))\n        return self", "response": "Specify the header of the table"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds several rows in the rows stack.", "response": "def add_rows(self, rows, header=True):\n        \"\"\"Add several rows in the rows stack\n\n        - The 'rows' argument can be either an iterator returning arrays,\n          or a by-dimensional array\n        - 'header' specifies if the first row should be used as the header\n          of the table\n        \"\"\"\n\n        # nb: don't use 'iter' on by-dimensional arrays, to get a\n        #     usable code for python 2.1\n        if header:\n            if hasattr(rows, '__iter__') and hasattr(rows, 'next'):\n                self.header(rows.next())\n            else:\n                self.header(rows[0])\n                rows = rows[1:]\n        for row in rows:\n            self.add_row(row)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw(self):\n\n        if not self._header and not self._rows:\n            return\n        self._compute_cols_width()\n        self._check_align()\n        out = \"\"\n        if self._has_border():\n            out += self._hline()\n        if self._header:\n            out += self._draw_line(self._header, isheader=True)\n            if self._has_header():\n                out += self._hline_header()\n        length = 0\n        for row in self._rows:\n            length += 1\n            out += self._draw_line(row)\n            if self._has_hlines() and length < len(self._rows):\n                out += self._hline()\n        if self._has_border():\n            out += self._hline()\n        return out[:-1]", "response": "Draw the table\n\n        - the table is returned as a whole string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfloating formatting class - method.", "response": "def _fmt_float(cls, x, **kw):\n        \"\"\"Float formatting class-method.\n\n        - x parameter is ignored. Instead kw-argument f being x float-converted\n          will be used.\n\n        - precision will be taken from `n` kw-argument.\n        \"\"\"\n        n = kw.get('n')\n        return '%.*f' % (n, cls._to_float(x))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fmt_exp(cls, x, **kw):\n        n = kw.get('n')\n        return '%.*e' % (n, cls._to_float(x))", "response": "Exponential formatting class - method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fmt_auto(cls, x, **kw):\n        f = cls._to_float(x)\n        if abs(f) > 1e8:\n            fn = cls._fmt_exp\n        else:\n            if f - round(f) == 0:\n                fn = cls._fmt_int\n            else:\n                fn = cls._fmt_float\n        return fn(x, **kw)", "response": "auto formatting class - method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _str(self, i, x):\n        FMT = {\n            'a':self._fmt_auto,\n            'i':self._fmt_int,\n            'f':self._fmt_float,\n            'e':self._fmt_exp,\n            't':self._fmt_text,\n            }\n\n        n = self._precision\n        dtype = self._dtype[i]\n        try:\n            if callable(dtype):\n                return dtype(x)\n            else:\n                return FMT[dtype](x, n=n)\n        except FallbackToText:\n            return self._fmt_text(x)", "response": "Handles string formatting of the data in the log entry i - index of the cell datatype in self. _dtype\n            x - cell data to format\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _hline(self):\n\n        if not self._hline_string:\n            self._hline_string = self._build_hline()\n        return self._hline_string", "response": "Print an horizontal line of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a string used to separated rows or separate header from rows", "response": "def _build_hline(self, is_header=False):\n        \"\"\"Return a string used to separated rows or separate header from\n        rows\n        \"\"\"\n        horiz = self._char_horiz\n        if (is_header):\n            horiz = self._char_header\n        # compute cell separator\n        s = \"%s%s%s\" % (horiz, [horiz, self._char_corner][self._has_vlines()],\n            horiz)\n        # build the line\n        l = s.join([horiz * n for n in self._width])\n        # add border if needed\n        if self._has_border():\n            l = \"%s%s%s%s%s\\n\" % (self._char_corner, horiz, l, horiz,\n                self._char_corner)\n        else:\n            l += \"\\n\"\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _len_cell(self, cell):\n\n        cell_lines = cell.split('\\n')\n        maxi = 0\n        for line in cell_lines:\n            length = 0\n            parts = line.split('\\t')\n            for part, i in zip(parts, list(range(1, len(parts) + 1))):\n                length = length + len(part)\n                if i < len(parts):\n                    length = (length//8 + 1) * 8\n            maxi = max(maxi, length)\n        return maxi", "response": "Return the width of the cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the width of each column in the table.", "response": "def _compute_cols_width(self):\n        \"\"\"Return an array with the width of each column\n\n        If a specific width has been specified, exit. If the total of the\n        columns width exceed the table desired width, another width will be\n        computed to fit, and cells will be wrapped.\n        \"\"\"\n\n        if hasattr(self, \"_width\"):\n            return\n        maxi = []\n        if self._header:\n            maxi = [ self._len_cell(x) for x in self._header ]\n        for row in self._rows:\n            for cell,i in zip(row, list(range(len(row)))):\n                try:\n                    maxi[i] = max(maxi[i], self._len_cell(cell))\n                except (TypeError, IndexError):\n                    maxi.append(self._len_cell(cell))\n\n        ncols = len(maxi)\n        content_width = sum(maxi)\n        deco_width = 3*(ncols-1) + [0,4][self._has_border()]\n        if self._max_width and (content_width + deco_width) > self._max_width:\n            \"\"\" content too wide to fit the expected max_width\n            let's recompute maximum cell width for each cell\n            \"\"\"\n            if self._max_width < (ncols + deco_width):\n                raise ValueError('max_width too low to render data')\n            available_width = self._max_width - deco_width\n            newmaxi = [0] * ncols\n            i = 0\n            while available_width > 0:\n                if newmaxi[i] < maxi[i]:\n                    newmaxi[i] += 1\n                    available_width -= 1\n                i = (i + 1) % ncols\n            maxi = newmaxi\n        self._width = maxi"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _splitit(self, line, isheader):\n\n        line_wrapped = []\n        for cell, width in zip(line, self._width):\n            array = []\n            for c in cell.split('\\n'):\n                if c.strip() == \"\":\n                    array.append(\"\")\n                else:\n                    array.extend(textwrapper(c, width))\n            line_wrapped.append(array)\n        max_cell_lines = reduce(max, list(map(len, line_wrapped)))\n        for cell, valign in zip(line_wrapped, self._valign):\n            if isheader:\n                valign = \"t\"\n            if valign == \"m\":\n                missing = max_cell_lines - len(cell)\n                cell[:0] = [\"\"] * int(missing / 2)\n                cell.extend([\"\"] * int(missing / 2 + missing % 2))\n            elif valign == \"b\":\n                cell[:0] = [\"\"] * (max_cell_lines - len(cell))\n            else:\n                cell.extend([\"\"] * (max_cell_lines - len(cell)))\n        return line_wrapped", "response": "Split each element of line into a list of lists each element is turned into a list result of the wrapping of the original string to the desired width\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef color_hex_to_dec_tuple(color):\n    assert len(color) in [3, 4, 6, 8]\n    if len(color) in [3, 4]:\n        color = \"\".join([c*2 for c in color])\n    n = int(color, 16)\n    t = ((n >> 16) & 255, (n >> 8) & 255, n & 255)\n    if len(color) == 8:\n        t = t + ((n >> 24) & 255,)\n    return t", "response": "Converts a color from hexadecimal to decimal tuple"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting a sub - region of the image using the supplied rectangle x y width height.", "response": "def region(self, rect):\n        \"\"\" Selects a sub-region of the image using the supplied rectangle,\n            x, y, width, height.\n        \"\"\"\n        box = (int(rect[0]), int(rect[1]), int(rect[0]) + int(rect[2]),\n               int(rect[1]) + int(rect[3]))\n        if box[2] > self.img.size[0] or box[3] > self.img.size[1]:\n            raise errors.RectangleError(\"Region out-of-bounds\")\n        self.img = self.img.crop(box)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resize(self, width, height, **kwargs):\n        opts = Image._normalize_options(kwargs)\n        size = self._get_size(width, height)\n        if opts[\"mode\"] == \"adapt\":\n            self._adapt(size, opts)\n        elif opts[\"mode\"] == \"clip\":\n            self._clip(size, opts)\n        elif opts[\"mode\"] == \"fill\":\n            self._fill(size, opts)\n        elif opts[\"mode\"] == \"scale\":\n            self._scale(size, opts)\n        else:\n            self._crop(size, opts)\n        return self", "response": "Resizes the image to the supplied width and height. Returns the new image instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotate(self, deg, **kwargs):\n        opts = Image._normalize_options(kwargs)\n\n        if deg == \"auto\":\n            if self._orig_format == \"JPEG\":\n                try:\n                    exif = self.img._getexif() or dict()\n                    deg = _orientation_to_rotation.get(exif.get(274, 0), 0)\n                except Exception:\n                    logger.warn('unable to parse exif')\n                    deg = 0\n            else:\n                deg = 0\n\n        deg = 360 - (int(deg) % 360)\n        if deg % 90 == 0:\n            if deg == 90:\n                self.img = self.img.transpose(PIL.Image.ROTATE_90)\n            elif deg == 180:\n                self.img = self.img.transpose(PIL.Image.ROTATE_180)\n            elif deg == 270:\n                self.img = self.img.transpose(PIL.Image.ROTATE_270)\n        else:\n            self.img = self.img.rotate(deg, expand=bool(int(opts[\"expand\"])))\n\n        return self", "response": "Rotates the image clockwise around its center."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, **kwargs):\n        opts = Image._normalize_options(kwargs)\n        outfile = BytesIO()\n        if opts[\"pil\"][\"format\"]:\n            fmt = opts[\"pil\"][\"format\"]\n        else:\n            fmt = self._orig_format\n        save_kwargs = dict()\n\n        if Image._isint(opts[\"quality\"]):\n            save_kwargs[\"quality\"] = int(opts[\"quality\"])\n\n        if int(opts[\"optimize\"]):\n            save_kwargs[\"optimize\"] = True\n\n        if int(opts[\"progressive\"]):\n            save_kwargs[\"progressive\"] = True\n\n        if int(opts[\"preserve_exif\"]):\n            save_kwargs[\"exif\"] = self._exif\n\n        color = color_hex_to_dec_tuple(opts[\"background\"])\n\n        if self.img.mode == \"RGBA\":\n            self._background(fmt, color)\n\n        if fmt == \"JPEG\":\n            if self.img.mode == \"P\":\n                # Converting old GIF and PNG files to JPEG can raise\n                # IOError: cannot write mode P as JPEG\n                # https://mail.python.org/pipermail/python-list/2000-May/036017.html\n                self.img = self.img.convert(\"RGB\")\n            elif self.img.mode == \"RGBA\":\n                # JPEG does not have an alpha channel so cannot be\n                # saved as RGBA. It must be converted to RGB.\n                self.img = self.img.convert(\"RGB\")\n\n        if self._orig_format == \"JPEG\":\n            self.img.format = self._orig_format\n            save_kwargs[\"subsampling\"] = \"keep\"\n            if opts[\"quality\"] == \"keep\":\n                save_kwargs[\"quality\"] = \"keep\"\n\n        try:\n            self.img.save(outfile, fmt, **save_kwargs)\n        except IOError as e:\n            raise errors.ImageSaveError(str(e))\n        self.img.format = fmt\n        outfile.seek(0)\n\n        return outfile", "response": "Returns a BytesIO object that can be used to write the image to the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef derive_signature(key, qs):\n    key, qs = (key or \"\", qs or \"\")\n    return hmac.new(key.encode(), qs.encode(), hashlib.sha1).hexdigest()", "response": "Derives the signature from the supplied query string using the key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign(key, qs):\n    sig = derive_signature(key, qs)\n    return \"%s&%s\" % (qs, urlencode([(\"sig\", sig)]))", "response": "Signs the query string using the key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_signature(key, qs):\n    unsigned_qs = re.sub(r'&?sig=[^&]*', '', qs)\n    sig = derive_signature(key, unsigned_qs)\n    return urlparse.parse_qs(qs).get(\"sig\", [None])[0] == sig", "response": "Verifies that the signature in the query string is correct."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef canonical_name(name):\n    if name.lower() == 'planck':  # make sure to handle the Planck window\n        return 'planck'\n    try:  # use equivalence introduced in scipy 0.16.0\n        # pylint: disable=protected-access\n        return scipy_windows._win_equiv[name.lower()].__name__\n    except AttributeError:  # old scipy\n        try:\n            return getattr(scipy_windows, name.lower()).__name__\n        except AttributeError:  # no match\n            pass  # raise later\n    except KeyError:  # no match\n        pass  # raise later\n\n    raise ValueError('no window function in scipy.signal equivalent to %r'\n                     % name,)", "response": "Find the canonical name for the given window in scipy. signal\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the recommended fractional overlap for the given window.", "response": "def recommended_overlap(name, nfft=None):\n    \"\"\"Returns the recommended fractional overlap for the given window\n\n    If ``nfft`` is given, the return is in samples\n\n    Parameters\n    ----------\n    name : `str`\n        the name of the window you are using\n\n    nfft : `int`, optional\n        the length of the window\n\n    Returns\n    -------\n    rov : `float`, `int`\n        the recommended overlap (ROV) for the given window, in samples if\n        ``nfft` is given (`int`), otherwise fractional (`float`)\n\n    Examples\n    --------\n    >>> from gwpy.signal.window import recommended_overlap\n    >>> recommended_overlap('hann')\n    0.5\n    >>> recommended_overlap('blackmanharris', nfft=128)\n    85\n    \"\"\"\n    try:\n        name = canonical_name(name)\n    except KeyError as exc:\n        raise ValueError(str(exc))\n    try:\n        rov = ROV[name]\n    except KeyError:\n        raise ValueError(\"no recommended overlap for %r window\" % name)\n    if nfft:\n        return int(ceil(nfft * rov))\n    return rov"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef planck(N, nleft=0, nright=0):\n    # construct a Planck taper window\n    w = numpy.ones(N)\n    if nleft:\n        w[0] *= 0\n        zleft = numpy.array([nleft * (1./k + 1./(k-nleft))\n                            for k in range(1, nleft)])\n        w[1:nleft] *= expit(-zleft)\n    if nright:\n        w[N-1] *= 0\n        zright = numpy.array([-nright * (1./(k-nright) + 1./k)\n                             for k in range(1, nright)])\n        w[N-nright:N-1] *= expit(-zright)\n    return w", "response": "Return a Planck taper window."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an environment variable as a boolean switch True is returned if the environment variable value matches one of the following values.", "response": "def bool_env(key, default=False):\n    \"\"\"Parse an environment variable as a boolean switch\n\n    `True` is returned if the variable value matches one of the following:\n\n    - ``'1'``\n    - ``'y'``\n    - ``'yes'``\n    - ``'true'``\n\n    The match is case-insensitive (so ``'Yes'`` will match as `True`)\n\n    Parameters\n    ----------\n    key : `str`\n        the name of the environment variable to find\n\n    default : `bool`\n        the default return value if the key is not found\n\n    Returns\n    -------\n    True\n        if the environment variable matches as 'yes' or similar\n    False\n        otherwise\n\n    Examples\n    --------\n    >>> import os\n    >>> from gwpy.utils.env import bool_env\n    >>> os.environ['GWPY_VALUE'] = 'yes'\n    >>> print(bool_env('GWPY_VALUE'))\n    True\n    >>> os.environ['GWPY_VALUE'] = 'something else'\n    >>> print(bool_env('GWPY_VALUE'))\n    False\n    >>> print(bool_env('GWPY_VALUE2'))\n    False\n    \"\"\"\n    try:\n        return os.environ[key].lower() in TRUE\n    except KeyError:\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall a command and returns the output and error streams of the command.", "response": "def call(cmd, stdout=PIPE, stderr=PIPE, on_error='raise', **kwargs):\n    \"\"\"Call out to the shell using `subprocess.Popen`\n\n    Parameters\n    ----------\n    stdout : `file-like`, optional\n        stream for stdout\n\n    stderr : `file-like`, optional\n        stderr for stderr\n\n    on_error : `str`, optional\n        what to do when the command fails, one of\n\n        - 'ignore' - do nothing\n        - 'warn' - print a warning\n        - 'raise' - raise an exception\n\n    **kwargs\n        other keyword arguments to pass to `subprocess.Popen`\n\n    Returns\n    -------\n    out : `str`\n        the output stream of the command\n    err : `str`\n        the error stream from the command\n\n    Raises\n    ------\n    OSError\n        if `cmd` is a `str` (or `shell=True` is passed) and the executable\n        is not found\n    subprocess.CalledProcessError\n        if the command fails otherwise\n    \"\"\"\n    if isinstance(cmd, (list, tuple)):\n        cmdstr = ' '.join(cmd)\n        kwargs.setdefault('shell', False)\n    else:\n        cmdstr = str(cmd)\n        kwargs.setdefault('shell', True)\n    proc = Popen(cmd, stdout=stdout, stderr=stderr, **kwargs)\n    out, err = proc.communicate()\n    if proc.returncode:\n        if on_error == 'ignore':\n            pass\n        elif on_error == 'warn':\n            e = CalledProcessError(proc.returncode, cmdstr)\n            warnings.warn(str(e))\n        else:\n            raise CalledProcessError(proc.returncode, cmdstr)\n    return out.decode('utf-8'), err.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_with_columns(func):\n    def wrapper(*args, **kwargs):\n        # parse columns argument\n        columns = kwargs.pop(\"columns\", None)\n\n        # read table\n        tab = func(*args, **kwargs)\n\n        # filter on columns\n        if columns is None:\n            return tab\n        return tab[columns]\n\n    return _safe_wraps(wrapper, func)", "response": "Decorate a Table read method to use the columns keyword\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecorates a Table read method to apply a selection keyword", "response": "def read_with_selection(func):\n    \"\"\"Decorate a Table read method to apply ``selection`` keyword\n    \"\"\"\n    def wrapper(*args, **kwargs):\n        \"\"\"Execute a function, then apply a selection filter\n        \"\"\"\n        # parse selection\n        selection = kwargs.pop('selection', None) or []\n\n        # read table\n        tab = func(*args, **kwargs)\n\n        # apply selection\n        if selection:\n            return filter_table(tab, selection)\n\n        return tab\n\n    return _safe_wraps(wrapper, func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap an existing registered reader to use GWpy s input decorators", "response": "def decorate_registered_reader(\n        name,\n        data_class=EventTable,\n        columns=True,\n        selection=True,\n):\n    \"\"\"Wrap an existing registered reader to use GWpy's input decorators\n\n    Parameters\n    ----------\n    name : `str`\n        the name of the registered format\n\n    data_class : `type`, optional\n        the class for whom the format is registered\n\n    columns : `bool`, optional\n        use the `read_with_columns` decorator\n\n    selection : `bool`, optional\n        use the `read_with_selection` decorator\n    \"\"\"\n    reader = registry.get_reader(name, data_class)\n    wrapped = (  # noqa\n        read_with_columns(  # use ``columns``\n        read_with_selection(  # use ``selection``\n            reader\n        ))\n    )\n    return registry.register_reader(name, data_class, wrapped, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table_from_root(source, treename=None, columns=None, **kwargs):\n    import root_numpy\n\n    # parse column filters into tree2array ``selection`` keyword\n    # NOTE: not all filters can be passed directly to root_numpy, so we store\n    #       those separately and apply them after-the-fact before returning\n    try:\n        selection = kwargs.pop('selection')\n    except KeyError:  # no filters\n        filters = None\n    else:\n        rootfilters = []\n        filters = []\n        for col, op_, value in parse_column_filters(selection):\n            try:\n                opstr = [key for key in OPERATORS if OPERATORS[key] is op_][0]\n            except (IndexError, KeyError):  # cannot filter with root_numpy\n                filters.append((col, op_, value))\n            else:  # can filter with root_numpy\n                rootfilters.append('{0} {1} {2!r}'.format(col, opstr, value))\n        kwargs['selection'] = ' && '.join(rootfilters)\n\n    # pass file name (not path)\n    if not isinstance(source, string_types):\n        source = source.name\n\n    # find single tree (if only one tree present)\n    if treename is None:\n        trees = root_numpy.list_trees(source)\n        if len(trees) == 1:\n            treename = trees[0]\n        elif not trees:\n            raise ValueError(\"No trees found in %s\" % source)\n        else:\n            raise ValueError(\"Multiple trees found in %s, please select on \"\n                             \"via the `treename` keyword argument, e.g. \"\n                             \"`treename='events'`. Available trees are: %s.\"\n                             % (source, ', '.join(map(repr, trees))))\n\n    # read, filter, and return\n    t = Table(root_numpy.root2array(\n        source,\n        treename,\n        branches=columns,\n        **kwargs\n    ))\n    if filters:\n        return filter_table(t, *filters)\n    return t", "response": "Read a Table from a ROOT tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef table_to_root(table, filename, **kwargs):\n    import root_numpy\n    root_numpy.array2root(table.as_array(), filename, **kwargs)", "response": "Write a Table to a ROOT file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _truncate(f, n):\n    s = \"{}\".format(f)\n    if \"e\" in s or \"E\" in s:\n        return \"{0:.{1}f}\".format(f, n)\n    i, p, d = s.partition(\".\")\n    return \".\".join([i, (d+\"0\"*n)[:n]])", "response": "Truncates a float f to n decimal places without rounding\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a GPSScale for this GPS time unit", "response": "def _gps_scale_factory(unit):\n    \"\"\"Construct a GPSScale for this unit\n    \"\"\"\n    class FixedGPSScale(GPSScale):\n        \"\"\"`GPSScale` for a specific GPS time unit\n        \"\"\"\n        name = str('{0}s'.format(unit.long_names[0] if unit.long_names else\n                                 unit.names[0]))\n\n        def __init__(self, axis, epoch=None):\n            \"\"\"\n            \"\"\"\n            super(FixedGPSScale, self).__init__(axis, epoch=epoch, unit=unit)\n    return FixedGPSScale"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the GPS epoch", "response": "def set_epoch(self, epoch):\n        \"\"\"Set the GPS epoch\n        \"\"\"\n        if epoch is None:\n            self._epoch = None\n            return\n        if isinstance(epoch, (Number, Decimal)):\n            self._epoch = float(epoch)\n        else:\n            self._epoch = float(to_gps(epoch))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_unit(self, unit):\n        # accept all core time units\n        if unit is None or (isinstance(unit, units.NamedUnit) and\n                            unit.physical_type == 'time'):\n            self._unit = unit\n            return\n        # convert float to custom unit in seconds\n        if isinstance(unit, Number):\n            unit = units.Unit(unit * units.second)\n        # otherwise, should be able to convert to a time unit\n        try:\n            unit = units.Unit(unit)\n        except ValueError as exc:\n            # catch annoying plurals\n            try:\n                unit = units.Unit(str(unit).rstrip('s'))\n            except ValueError:\n                raise exc\n        # decompose and check that it's actually a time unit\n        dec = unit.decompose()\n        if dec.bases != [units.second]:\n            raise ValueError(\"Cannot set GPS unit to %s\" % unit)\n        # check equivalent units\n        for other in TIME_UNITS:\n            if other.decompose().scale == dec.scale:\n                self._unit = other\n                return\n        raise ValueError(\"Unrecognised unit: %s\" % unit)", "response": "Set the GPS step unit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of the unit for this GPS scale", "response": "def get_unit_name(self):\n        \"\"\"Returns the name of the unit for this GPS scale\n\n        Note that this returns a simply-pluralised version of the name.\n        \"\"\"\n        if not self.unit:\n            return None\n        name = sorted(self.unit.names, key=len)[-1]\n        return '%ss' % name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms an array of GPS times and return a numpy array of GPS times.", "response": "def transform_non_affine(self, values):\n        \"\"\"Transform an array of GPS times.\n\n        This method is designed to filter out transformations that will\n        generate text elements that require exact precision, and use\n        `Decimal` objects to do the transformation, and simple `float`\n        otherwise.\n        \"\"\"\n        scale = self.scale or 1\n        epoch = self.epoch or 0\n\n        values = numpy.asarray(values)\n\n        # handle simple or data transformations with floats\n        if self._parents or (  # part of composite transform (from draw())\n                epoch == 0 and  # no large additions\n                scale == 1  # no multiplications\n        ):\n            return self._transform(values, float(epoch), float(scale))\n\n        # otherwise do things carefully (and slowly) with Decimals\n        # -- ideally this only gets called for transforming tick positions\n        flat = values.flatten()\n\n        def _trans(x):\n            return self._transform_decimal(x, epoch, scale)\n\n        return numpy.asarray(list(map(_trans, flat))).reshape(values.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _transform_decimal(cls, value, epoch, scale):\n        vdec = Decimal(_truncate(value, 12))\n        edec = Decimal(_truncate(epoch, 12))\n        sdec = Decimal(_truncate(scale, 12))\n        return type(value)(cls._transform(vdec, edec, sdec))", "response": "Transform to GPS using decimal. Decimal for precision\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a `DeprecationWarning` to a function Parameters ---------- func : `callable` the function to decorate with a `DeprecationWarning` warning : `str`, optional the warning to present Notes ----- The final warning message is formatted as ``warning.format(func)`` so you can use attribute references to the function itself. See the default message as an example.", "response": "def deprecated_function(func, warning=DEPRECATED_FUNCTION_WARNING):\n    \"\"\"Adds a `DeprecationWarning` to a function\n\n    Parameters\n    ----------\n    func : `callable`\n        the function to decorate with a `DeprecationWarning`\n\n    warning : `str`, optional\n        the warning to present\n\n    Notes\n    -----\n    The final warning message is formatted as ``warning.format(func)``\n    so you can use attribute references to the function itself.\n    See the default message as an example.\n    \"\"\"\n    @wraps(func)\n    def wrapped_func(*args, **kwargs):\n        warnings.warn(\n            DEPRECATED_FUNCTION_WARNING.format(func),\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        return func(*args, **kwargs)\n\n    return wrapped_func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_citations(zid, url='https://zenodo.org/', hits=10, tag_prefix='v'):\n    # query for metadata\n    url = ('{url}/api/records/?'\n           'page=1&'\n           'size={hits}&'\n           'q=conceptrecid:\"{id}\"&'\n           'sort=-version&'\n           'all_versions=True'.format(id=zid, url=url, hits=hits))\n    metadata = requests.get(url).json()\n\n    lines = []\n    for i, hit in enumerate(metadata['hits']['hits']):\n        version = hit['metadata']['version'][len(tag_prefix):]\n        lines.append('-' * len(version))\n        lines.append(version)\n        lines.append('-' * len(version))\n        lines.append('')\n        lines.append('.. image:: {badge}\\n'\n                     '   :target: {doi}'.format(**hit['links']))\n        if i < hits - 1:\n            lines.append('')\n\n    return '\\n'.join(lines)", "response": "Query and format a citations page from Zenodo entries and return a RST - formatted string of the citations page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(source, channels, start=None, end=None, scaled=None, type=None,\n         series_class=TimeSeries):\n    # pylint: disable=redefined-builtin\n    \"\"\"Read a dict of series from one or more GWF files\n\n    Parameters\n    ----------\n    source : `str`, `list`\n        Source of data, any of the following:\n\n        - `str` path of single data file,\n        - `str` path of cache file,\n        - `list` of paths.\n\n    channels : `~gwpy.detector.ChannelList`, `list`\n        a list of channels to read from the source.\n\n    start : `~gwpy.time.LIGOTimeGPS`, `float`, `str` optional\n        GPS start time of required data, anything parseable by\n        :func:`~gwpy.time.to_gps` is fine.\n\n    end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n        GPS end time of required data, anything parseable by\n        :func:`~gwpy.time.to_gps` is fine.\n\n    scaled : `bool`, optional\n        apply slope and bias calibration to ADC data.\n\n    type : `dict`, optional\n        a `dict` of ``(name, channel-type)`` pairs, where ``channel-type``\n        can be one of ``'adc'``, ``'proc'``, or ``'sim'``.\n\n    series_class : `type`, optional\n        the `Series` sub-type to return.\n\n    Returns\n    -------\n    data : `~gwpy.timeseries.TimeSeriesDict` or similar\n        a dict of ``(channel, series)`` pairs read from the GWF source(s).\n    \"\"\"\n    # parse input source\n    source = file_list(source)\n\n    # parse type\n    ctype = channel_dict_kwarg(type, channels, (str,))\n\n    # read each individually and append\n    out = series_class.DictClass()\n    for i, file_ in enumerate(source):\n        if i == 1:  # force data into fresh memory so that append works\n            for name in out:\n                out[name] = numpy.require(out[name], requirements=['O'])\n        # read frame\n        out.append(read_gwf(file_, channels, start=start, end=end, ctype=ctype,\n                            scaled=scaled, series_class=series_class),\n                   copy=False)\n    return out", "response": "Read a dict of series from one or more GWF files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_gwf(filename, channels, start=None, end=None, scaled=None,\n             ctype=None, series_class=TimeSeries):\n    \"\"\"Read a dict of series data from a single GWF file\n\n    Parameters\n    ----------\n    filename : `str`\n        the GWF path from which to read\n\n    channels : `~gwpy.detector.ChannelList`, `list`\n        a list of channels to read from the source.\n\n    start : `~gwpy.time.LIGOTimeGPS`, `float`, `str` optional\n        GPS start time of required data, anything parseable by\n        :func:`~gwpy.time.to_gps` is fine.\n\n    end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n        GPS end time of required data, anything parseable by\n        :func:`~gwpy.time.to_gps` is fine.\n\n    scaled : `bool`, optional\n        apply slope and bias calibration to ADC data.\n\n    type : `dict`, optional\n        a `dict` of ``(name, channel-type)`` pairs, where ``channel-type``\n        can be one of ``'adc'``, ``'proc'``, or ``'sim'``.\n\n    series_class : `type`, optional\n        the `Series` sub-type to return.\n\n    Returns\n    -------\n    data : `~gwpy.timeseries.TimeSeriesDict` or similar\n        a dict of ``(channel, series)`` pairs read from the GWF file.\n    \"\"\"\n    # parse kwargs\n    if not start:\n        start = 0\n    if not end:\n        end = 0\n    span = Segment(start, end)\n\n    # open file\n    stream = io_gwf.open_gwf(filename, 'r')\n    nframes = stream.GetNumberOfFrames()\n\n    # find channels\n    out = series_class.DictClass()\n\n    # loop over frames in GWF\n    i = 0\n    while True:\n        this = i\n        i += 1\n\n        # read frame\n        try:\n            frame = stream.ReadFrameNSubset(this, 0)\n        except IndexError:\n            if this >= nframes:\n                break\n            raise\n\n        # check whether we need this frame at all\n        if not _need_frame(frame, start, end):\n            continue\n\n        # get epoch for this frame\n        epoch = LIGOTimeGPS(*frame.GetGTime())\n\n        # and read all the channels\n        for channel in channels:\n            _scaled = _dynamic_scaled(scaled, channel)\n            try:\n                new = _read_channel(stream, this, str(channel),\n                                    ctype.get(channel, None),\n                                    epoch, start, end, scaled=_scaled,\n                                    series_class=series_class)\n            except _Skip:  # don't need this frame for this channel\n                continue\n            try:\n                out[channel].append(new)\n            except KeyError:\n                out[channel] = numpy.require(new, requirements=['O'])\n\n        # if we have all of the data we want, stop now\n        if all(span in out[channel].span for channel in out):\n            break\n\n    # if any channels weren't read, something went wrong\n    for channel in channels:\n        if channel not in out:\n            msg = \"Failed to read {0!r} from {1!r}\".format(\n                str(channel), filename)\n            if start or end:\n                msg += ' for {0}'.format(span)\n            raise ValueError(msg)\n\n    return out", "response": "Read a dict of series data from a single GWF file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a specific channel from a specific frame in a specific stream.", "response": "def _read_channel(stream, num, name, ctype, epoch, start, end,\n                  scaled=True, series_class=TimeSeries):\n    \"\"\"Read a channel from a specific frame in a stream\n    \"\"\"\n    data = _get_frdata(stream, num, name, ctype=ctype)\n    return read_frdata(data, epoch, start, end,\n                       scaled=scaled, series_class=series_class)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_frdata(stream, num, name, ctype=None):\n    ctypes = (ctype,) if ctype else ('adc', 'proc', 'sim')\n    for ctype in ctypes:\n        _reader = getattr(stream, 'ReadFr{0}Data'.format(ctype.title()))\n        try:\n            return _reader(num, name)\n        except IndexError as exc:\n            if FRERR_NO_CHANNEL_OF_TYPE.match(str(exc)):\n                continue\n            raise\n    raise ValueError(\"no Fr{{Adc,Proc,Sim}}Data structures with the \"\n                     \"name {0}\".format(name))", "response": "Brute force -ish method to return the FrData structure for a channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_frdata(frdata, epoch, start, end, scaled=True,\n                series_class=TimeSeries):\n    \"\"\"Read a series from an `FrData` structure\n\n    Parameters\n    ----------\n    frdata : `LDAStools.frameCPP.FrAdcData` or similar\n        the data structure to read\n\n    epoch : `float`\n        the GPS start time of the containing frame\n        (`LDAStools.frameCPP.FrameH.GTime`)\n\n    start : `float`\n        the GPS start time of the user request\n\n    end : `float`\n        the GPS end time of the user request\n\n    scaled : `bool`, optional\n        apply slope and bias calibration to ADC data.\n\n    series_class : `type`, optional\n        the `Series` sub-type to return.\n\n    Returns\n    -------\n    series : `~gwpy.timeseries.TimeSeriesBase`\n        the formatted data series\n\n    Raises\n    ------\n    _Skip\n        if this data structure doesn't overlap with the requested\n        ``[start, end)`` interval.\n    \"\"\"\n    datastart = epoch + frdata.GetTimeOffset()\n    try:\n        trange = frdata.GetTRange()\n    except AttributeError:  # not proc channel\n        trange = 0.\n\n    # check overlap with user-requested span\n    if (end and datastart >= end) or (trange and datastart + trange < start):\n        raise _Skip()\n\n    # get scaling\n    try:\n        slope = frdata.GetSlope()\n        bias = frdata.GetBias()\n    except AttributeError:  # not FrAdcData\n        slope = None\n        bias = None\n        null_scaling = True\n    else:\n        null_scaling = slope == 1. and bias == 0.\n\n    out = None\n    for j in range(frdata.data.size()):\n        # we use range(frdata.data.size()) to avoid segfault\n        # related to iterating directly over frdata.data\n        try:\n            new = read_frvect(frdata.data[j], datastart, start, end,\n                              name=frdata.GetName(),\n                              series_class=series_class)\n        except _Skip:\n            continue\n\n        # apply ADC scaling (only if interesting; this prevents unnecessary\n        #                                         type-casting errors)\n        if scaled and not null_scaling:\n            new *= slope\n            new += bias\n        if slope is not None:\n            # user has deliberately disabled the ADC calibration, so\n            # the stored engineering unit is not valid, revert to 'counts':\n            new.override_unit('count')\n\n        if out is None:\n            out = new\n        else:\n            out.append(new)\n    return out", "response": "Read a series from an FrData object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_frvect(vect, epoch, start, end, name=None, series_class=TimeSeries):\n    # only read FrVect with matching name (or no name set)\n    #    frame spec allows for arbitrary other FrVects\n    #    to hold other information\n    if vect.GetName() and name and vect.GetName() != name:\n        raise _Skip()\n\n    # get array\n    arr = vect.GetDataArray()\n    nsamp = arr.size\n\n    # and dimensions\n    dim = vect.GetDim(0)\n    dx = dim.dx\n    x0 = dim.startX\n\n    # start and end GPS times of this FrVect\n    dimstart = epoch + x0\n    dimend = dimstart + nsamp * dx\n\n    # index of first required sample\n    nxstart = int(max(0., float(start-dimstart)) / dx)\n\n    # requested start time is after this frame, skip\n    if nxstart >= nsamp:\n        raise _Skip()\n\n    # index of end sample\n    if end:\n        nxend = int(nsamp - ceil(max(0., float(dimend-end)) / dx))\n    else:\n        nxend = None\n\n    if nxstart or nxend:\n        arr = arr[nxstart:nxend]\n\n    # -- cast as a series\n\n    # get unit\n    unit = vect.GetUnitY() or None\n\n    # create array\n    series = series_class(arr, t0=dimstart+nxstart*dx, dt=dx, name=name,\n                          channel=name, unit=unit, copy=False)\n\n    # add information to channel\n    series.channel.sample_rate = series.sample_rate.value\n    series.channel.unit = unit\n    series.channel.dtype = series.dtype\n\n    return series", "response": "Read an array from a FrVect structur."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a dictionary of time series to a GWF file.", "response": "def write(tsdict, outfile, start=None, end=None, name='gwpy', run=0,\n          compression=257, compression_level=6):\n    \"\"\"Write data to a GWF file using the frameCPP API\n    \"\"\"\n    # set frame header metadata\n    if not start:\n        starts = {LIGOTimeGPS(tsdict[key].x0.value) for key in tsdict}\n        if len(starts) != 1:\n            raise RuntimeError(\"Cannot write multiple TimeSeries to a single \"\n                               \"frame with different start times, \"\n                               \"please write into different frames\")\n        start = list(starts)[0]\n    if not end:\n        ends = {tsdict[key].span[1] for key in tsdict}\n        if len(ends) != 1:\n            raise RuntimeError(\"Cannot write multiple TimeSeries to a single \"\n                               \"frame with different end times, \"\n                               \"please write into different frames\")\n        end = list(ends)[0]\n    duration = end - start\n    start = LIGOTimeGPS(start)\n    ifos = {ts.channel.ifo for ts in tsdict.values() if\n            ts.channel and ts.channel.ifo and\n            hasattr(frameCPP, 'DETECTOR_LOCATION_{0}'.format(ts.channel.ifo))}\n\n    # create frame\n    frame = io_gwf.create_frame(time=start, duration=duration, name=name,\n                                run=run, ifos=ifos)\n\n    # append channels\n    for i, key in enumerate(tsdict):\n        try:\n            # pylint: disable=protected-access\n            ctype = tsdict[key].channel._ctype or 'proc'\n        except AttributeError:\n            ctype = 'proc'\n        append_to_frame(frame, tsdict[key].crop(start, end),\n                        type=ctype, channelid=i)\n\n    # write frame to file\n    io_gwf.write_frames(outfile, [frame], compression=compression,\n                        compression_level=compression_level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends data from a TimeSeries to a ~frameCPP. FrameH object.", "response": "def append_to_frame(frame, timeseries, type='proc', channelid=0):\n    # pylint: disable=redefined-builtin\n    \"\"\"Append data from a `TimeSeries` to a `~frameCPP.FrameH`\n\n    Parameters\n    ----------\n    frame : `~frameCPP.FrameH`\n        frame object to append to\n\n    timeseries : `TimeSeries`\n        the timeseries to append\n\n    type : `str`\n        the type of the channel, one of 'adc', 'proc', 'sim'\n\n    channelid : `int`, optional\n        the ID of the channel within the group (only used for ADC channels)\n    \"\"\"\n    if timeseries.channel:\n        channel = str(timeseries.channel)\n    else:\n        channel = str(timeseries.name)\n\n    offset = float(LIGOTimeGPS(timeseries.t0.value) -\n                   LIGOTimeGPS(*frame.GetGTime()))\n\n    # create the data container\n    if type.lower() == 'adc':\n        frdata = frameCPP.FrAdcData(\n            channel,\n            0,  # channel group\n            channelid,  # channel number in group\n            16,  # number of bits in ADC\n            timeseries.sample_rate.value,  # sample rate\n        )\n        frdata.SetTimeOffset(offset)\n        append = frame.AppendFrAdcData\n    elif type.lower() == 'proc':\n        frdata = frameCPP.FrProcData(\n            channel,  # channel name\n            str(timeseries.name),  # comment\n            frameCPP.FrProcData.TIME_SERIES,  # ID as time-series\n            frameCPP.FrProcData.UNKNOWN_SUB_TYPE,  # empty sub-type (fseries)\n            offset,  # offset of first sample relative to frame start\n            abs(timeseries.span),  # duration of data\n            0.,  # heterodyne frequency\n            0.,  # phase of heterodyne\n            0.,  # frequency range\n            0.,  # resolution bandwidth\n        )\n        append = frame.AppendFrProcData\n    elif type.lower() == 'sim':\n        frdata = frameCPP.FrSimData(\n            str(timeseries.channel),  # channel name\n            str(timeseries.name),  # comment\n            timeseries.sample_rate.value,  # sample rate\n            offset,  # time offset of first sample\n            0.,  # heterodyne frequency\n            0.,  # phase of heterodyne\n        )\n        append = frame.AppendFrSimData\n    else:\n        raise RuntimeError(\"Invalid channel type {!r}, please select one of \"\n                           \"'adc, 'proc', or 'sim'\".format(type))\n    # append an FrVect\n    frdata.AppendData(create_frvect(timeseries))\n    append(frdata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_frvect(timeseries):\n    # create timing dimension\n    dims = frameCPP.Dimension(\n        timeseries.size, timeseries.dx.value,\n        str(timeseries.dx.unit), 0)\n    # create FrVect\n    vect = frameCPP.FrVect(\n        timeseries.name or '', FRVECT_TYPE_FROM_NUMPY[timeseries.dtype.type],\n        1, dims, str(timeseries.unit))\n    # populate FrVect and return\n    vect.GetDataArray()[:] = numpy.require(timeseries.value,\n                                           requirements=['C'])\n    return vect", "response": "Create a ~frameCPP. FrVect from a TimeSeries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _bool_segments(array, start=0, delta=1, minlen=1):\n    array = iter(array)\n    i = 0\n    while True:\n        try:  # get next value\n            val = next(array)\n        except StopIteration:  # end of array\n            return\n\n        if val:  # start of new segment\n            n = 1  # count consecutive True\n            try:\n                while next(array):  # run until segment will end\n                    n += 1\n            except StopIteration:  # have reached the end\n                return  # stop\n            finally:  # yield segment (including at StopIteration)\n                if n >= minlen:  # ... if long enough\n                    yield (start + i * delta, start + (i + n) * delta)\n            i += n\n        i += 1", "response": "Yields segments of consecutive True values in a boolean array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dqflag(self, name=None, minlen=1, dtype=None, round=False,\n                  label=None, description=None):\n        \"\"\"Convert this series into a `~gwpy.segments.DataQualityFlag`.\n\n        Each contiguous set of `True` values are grouped as a\n        `~gwpy.segments.Segment` running from the GPS time the first\n        found `True`, to the GPS time of the next `False` (or the end\n        of the series)\n\n        Parameters\n        ----------\n        minlen : `int`, optional\n            minimum number of consecutive `True` values to identify as a\n            `~gwpy.segments.Segment`. This is useful to ignore single\n            bit flips, for example.\n\n        dtype : `type`, `callable`\n            output segment entry type, can pass either a type for simple\n            casting, or a callable function that accepts a float and returns\n            another numeric type, defaults to the `dtype` of the time index\n\n        round : `bool`, optional\n            choose to round each `~gwpy.segments.Segment` to its\n            inclusive integer boundaries\n\n        label : `str`, optional\n            the :attr:`~gwpy.segments.DataQualityFlag.label` for the\n            output flag.\n\n        description : `str`, optional\n            the :attr:`~gwpy.segments.DataQualityFlag.description` for the\n            output flag.\n\n        Returns\n        -------\n        dqflag : `~gwpy.segments.DataQualityFlag`\n            a segment representation of this `StateTimeSeries`, the span\n            defines the `known` segments, while the contiguous `True`\n            sets defined each of the `active` segments\n        \"\"\"\n        from ..segments import DataQualityFlag\n\n        # format dtype\n        if dtype is None:\n            dtype = self.t0.dtype\n        if isinstance(dtype, numpy.dtype):  # use callable dtype\n            dtype = dtype.type\n        start = dtype(self.t0.value)\n        dt = dtype(self.dt.value)\n\n        # build segmentlists (can use simple objects since DQFlag converts)\n        active = _bool_segments(self.value, start, dt, minlen=int(minlen))\n        known = [tuple(map(dtype, self.span))]\n\n        # build flag and return\n        out = DataQualityFlag(name=name or self.name, active=active,\n                              known=known, label=label or self.name,\n                              description=description)\n        if round:\n            return out.round()\n        return out", "response": "Convert this stateTimeSeries into a ~gwpy. segments. DataQualityFlag object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist of Bits for this StateVector", "response": "def bits(self):\n        \"\"\"list of `Bits` for this `StateVector`\n\n        :type: `Bits`\n        \"\"\"\n        try:\n            return self._bits\n        except AttributeError:\n            if self.dtype.name.startswith(('uint', 'int')):\n                nbits = self.itemsize * 8\n                self.bits = Bits(['Bit %d' % b for b in range(nbits)],\n                                 channel=self.channel, epoch=self.epoch)\n                return self.bits\n            elif hasattr(self.channel, 'bits'):\n                self.bits = self.channel.bits\n                return self.bits\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef boolean(self):\n        try:\n            return self._boolean\n        except AttributeError:\n            nbits = len(self.bits)\n            boolean = numpy.zeros((self.size, nbits), dtype=bool)\n            for i, sample in enumerate(self.value):\n                boolean[i, :] = [int(sample) >> j & 1 for j in range(nbits)]\n            self._boolean = Array2D(boolean, name=self.name,\n                                    x0=self.x0, dx=self.dx, y0=0, dy=1)\n            return self.boolean", "response": "A mapping of this StateVector to a 2 - D array containing all the binary bits as booleans for each time point."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the StateTimeSeriesDict for each bit of this StateVector.", "response": "def get_bit_series(self, bits=None):\n        \"\"\"Get the `StateTimeSeries` for each bit of this `StateVector`.\n\n        Parameters\n        ----------\n        bits : `list`, optional\n            a list of bit indices or bit names, defaults to all bits\n\n        Returns\n        -------\n        bitseries : `StateTimeSeriesDict`\n            a `dict` of `StateTimeSeries`, one for each given bit\n        \"\"\"\n        if bits is None:\n            bits = [b for b in self.bits if b not in {None, ''}]\n        bindex = []\n        for bit in bits:\n            try:\n                bindex.append((self.bits.index(bit), bit))\n            except (IndexError, ValueError) as exc:\n                exc.args = ('Bit %r not found in StateVector' % bit,)\n                raise\n        self._bitseries = StateTimeSeriesDict()\n        for i, bit in bindex:\n            self._bitseries[bit] = StateTimeSeries(\n                self.value >> i & 1, name=bit, epoch=self.x0.value,\n                channel=self.channel, sample_rate=self.sample_rate)\n        return self._bitseries"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(cls, source, *args, **kwargs):\n        return super(StateVector, cls).read(source, *args, **kwargs)", "response": "Read data into a StateVector object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dqflags(self, bits=None, minlen=1, dtype=float, round=False):\n        from ..segments import DataQualityDict\n        out = DataQualityDict()\n        bitseries = self.get_bit_series(bits=bits)\n        for bit, sts in bitseries.items():\n            out[bit] = sts.to_dqflag(name=bit, minlen=minlen, round=round,\n                                     dtype=dtype,\n                                     description=self.bits.description[bit])\n        return out", "response": "Convert this StateVector into a ~gwpy. segments. DataQualityDict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(cls, channel, start, end, bits=None, host=None, port=None,\n              verbose=False, connection=None, type=Nds2ChannelType.any()):\n        \"\"\"Fetch data from NDS into a `StateVector`.\n\n        Parameters\n        ----------\n        channel : `str`, `~gwpy.detector.Channel`\n            the name of the channel to read, or a `Channel` object.\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS start time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS end time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        bits : `Bits`, `list`, optional\n            definition of bits for this `StateVector`\n\n        host : `str`, optional\n            URL of NDS server to use, defaults to observatory site host\n\n        port : `int`, optional\n            port number for NDS server query, must be given with `host`\n\n        verify : `bool`, optional, default: `True`\n            check channels exist in database before asking for data\n\n        connection : `nds2.connection`\n            open NDS connection to use\n\n        verbose : `bool`, optional\n            print verbose output about NDS progress\n\n        type : `int`, optional\n            NDS2 channel type integer\n\n        dtype : `type`, `numpy.dtype`, `str`, optional\n            identifier for desired output data type\n        \"\"\"\n        new = cls.DictClass.fetch(\n            [channel], start, end, host=host, port=port,\n            verbose=verbose, connection=connection)[channel]\n        if bits:\n            new.bits = bits\n        return new", "response": "Fetch data from NDS into a StateVector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(cls, channel, start, end, bits=None, **kwargs):\n        new = cls.DictClass.get([channel], start, end, **kwargs)[channel]\n        if bits:\n            new.bits = bits\n        return new", "response": "Get data for this channel from frames or NDS2 server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot(self, format='segments', bits=None, **kwargs):\n        if format == 'timeseries':\n            return super(StateVector, self).plot(**kwargs)\n        if format == 'segments':\n            from ..plot import Plot\n            kwargs.setdefault('xscale', 'auto-gps')\n            return Plot(*self.to_dqflags(bits=bits).values(),\n                        projection='segments', **kwargs)\n        raise ValueError(\"'format' argument must be one of: 'timeseries' or \"\n                         \"'segments'\")", "response": "Plot the data for this state vector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resample(self, rate):\n        rate1 = self.sample_rate.value\n        if isinstance(rate, units.Quantity):\n            rate2 = rate.value\n        else:\n            rate2 = float(rate)\n        # upsample\n        if (rate2 / rate1).is_integer():\n            raise NotImplementedError(\"StateVector upsampling has not \"\n                                      \"been implemented yet, sorry.\")\n        # downsample\n        elif (rate1 / rate2).is_integer():\n            factor = int(rate1 / rate2)\n            # reshape incoming data to one column per new sample\n            newsize = int(self.size / factor)\n            old = self.value.reshape((newsize, self.size // newsize))\n            # work out number of bits\n            if self.bits:\n                nbits = len(self.bits)\n            else:\n                max_ = self.value.max()\n                nbits = int(ceil(log(max_, 2))) if max_ else 1\n            bits = range(nbits)\n            # construct an iterator over the columns of the old array\n            itr = numpy.nditer(\n                [old, None],\n                flags=['external_loop', 'reduce_ok'],\n                op_axes=[None, [0, -1]],\n                op_flags=[['readonly'], ['readwrite', 'allocate']])\n            dtype = self.dtype\n            type_ = self.dtype.type\n            # for each new sample, each bit is logical AND of old samples\n            # bit is ON,\n            for x, y in itr:\n                y[...] = numpy.sum([type_((x >> bit & 1).all() * (2 ** bit))\n                                    for bit in bits], dtype=self.dtype)\n            new = StateVector(itr.operands[1], dtype=dtype)\n            new.__metadata_finalize__(self)\n            new._unit = self.unit\n            new.sample_rate = rate2\n            return new\n        # error for non-integer resampling factors\n        elif rate1 < rate2:\n            raise ValueError(\"New sample rate must be multiple of input \"\n                             \"series rate if upsampling a StateVector\")\n        else:\n            raise ValueError(\"New sample rate must be divisor of input \"\n                             \"series rate if downsampling a StateVector\")", "response": "Resample this StateVector to a new rate and return the new version of the state - vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads segments from file into a segment list.", "response": "def read(cls, source, format=None, coalesce=False, **kwargs):\n        # pylint: disable=redefined-builtin\n        \"\"\"Read segments from file into a `SegmentList`\n\n        Parameters\n        ----------\n        filename : `str`\n            path of file to read\n\n        format : `str`, optional\n            source format identifier. If not given, the format will be\n            detected if possible. See below for list of acceptable\n            formats.\n\n        coalesce : `bool`, optional\n            if `True` coalesce the segment list before returning,\n            otherwise return exactly as contained in file(s).\n\n        **kwargs\n            other keyword arguments depend on the format, see the online\n            documentation for details (:ref:`gwpy-segments-io`)\n\n        Returns\n        -------\n        segmentlist : `SegmentList`\n            `SegmentList` active and known segments read from file.\n\n        Notes\n        -----\"\"\"\n        def combiner(listofseglists):\n            \"\"\"Combine `SegmentList` from each file into a single object\n            \"\"\"\n            out = cls(seg for seglist in listofseglists for seg in seglist)\n            if coalesce:\n                return out.coalesce()\n            return out\n\n        return io_read_multi(combiner, cls, source, format=format, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting this SegmentList to a file output.", "response": "def write(self, target, *args, **kwargs):\n        \"\"\"Write this `SegmentList` to a file\n\n        Arguments and keywords depend on the output format, see the\n        online documentation for full details for each format.\n\n        Parameters\n        ----------\n        target : `str`\n            output filename\n\n        Notes\n        -----\"\"\"\n        return io_registry.write(self, target, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading an EventTable from a Coherent WaveBurst ROOT file", "response": "def table_from_cwb(source, *args, **kwargs):\n    \"\"\"Read an `EventTable` from a Coherent WaveBurst ROOT file\n\n    This function just redirects to the format='root' reader with appropriate\n    defaults.\n    \"\"\"\n    return EventTable.read(source, 'waveburst', *args, format='root', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cols(self, lines):\n        re_name_def = re.compile(\n            r'^\\s*#\\s+'  # whitespace and comment marker\n            r'(?P<colnumber>[0-9]+)\\s+-\\s+'  # number of column\n            r'(?P<colname>(.*))'\n        )\n        self.names = []\n        include_cuts = False\n        for line in lines:\n            if not line:  # ignore empty lines in header (windows)\n                continue\n            if not line.startswith('# '):  # end of header lines\n                break\n            if line.startswith('# -/+'):\n                include_cuts = True\n            else:\n                match = re_name_def.search(line)\n                if match:\n                    self.names.append(match.group('colname').rstrip())\n\n        if not self.names:\n            raise core.InconsistentTableError(\n                'No column names found in cWB header')\n\n        if include_cuts:\n            self.cols = [  # pylint: disable=attribute-defined-outside-init\n                core.Column(name='selection cut 1'),\n                core.Column(name='selection cut 2'),\n            ]\n        else:\n            self.cols = []  # pylint: disable=attribute-defined-outside-init\n        for name in self.names:\n            col = core.Column(name=name)\n            self.cols.append(col)", "response": "Initialize Column objects from a multi - line ASCII header."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_backend_mod(name=None):\n    if name is None:\n        name = get_backend()\n    backend_name = (name[9:] if name.startswith(\"module://\") else\n                    \"matplotlib.backends.backend_{}\".format(name.lower()))\n    return importlib.import_module(backend_name)", "response": "Returns the imported module for the given backend name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _group_axes_data(inputs, separate=None, flat=False):\n    # determine auto-separation\n    if separate is None and inputs:\n        # if given a nested list of data, multiple axes are required\n        if any(isinstance(x, iterable_types + (dict,)) for x in inputs):\n            separate = True\n        # if data are of different types, default to separate\n        elif not all(type(x) is type(inputs[0]) for x in inputs):  # noqa: E721\n            separate = True\n\n    # build list of lists\n    out = []\n    for x in inputs:\n        if isinstance(x, dict):  # unwrap dict\n            x = list(x.values())\n\n        # new group from iterable, notes:\n        #     the iterable is presumed to be a list of independent data\n        #     structures, unless its a list of scalars in which case we\n        #     should plot them all as one\n        if (\n                isinstance(x, (KeysView, ValuesView)) or\n                isinstance(x, (list, tuple)) and (\n                    not x or not numpy.isscalar(x[0]))\n        ):\n            out.append(x)\n\n        # dataset starts a new group\n        elif separate or not out:\n            out.append([x])\n\n        # dataset joins current group\n        else:  # append input to most recent group\n            out[-1].append(x)\n\n    if flat:\n        return [s for group in out for s in group]\n\n    return out", "response": "This function will determine the number of axes from the input args to this Plot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating this figure with data creating axes as necessary", "response": "def _init_axes(self, data, method='plot',\n                   xscale=None, sharex=False, sharey=False,\n                   geometry=None, separate=None, **kwargs):\n        \"\"\"Populate this figure with data, creating `Axes` as necessary\n        \"\"\"\n        if isinstance(sharex, bool):\n            sharex = \"all\" if sharex else \"none\"\n        if isinstance(sharey, bool):\n            sharey = \"all\" if sharey else \"none\"\n\n        # parse keywords\n        axes_kw = {key: kwargs.pop(key) for key in utils.AXES_PARAMS if\n                   key in kwargs}\n\n        # handle geometry and group axes\n        if geometry is not None and geometry[0] * geometry[1] == len(data):\n            separate = True\n        axes_groups = _group_axes_data(data, separate=separate)\n        if geometry is None:\n            geometry = (len(axes_groups), 1)\n        nrows, ncols = geometry\n        if axes_groups and nrows * ncols != len(axes_groups):\n            # mismatching data and geometry\n            raise ValueError(\"cannot group data into {0} axes with a \"\n                             \"{1}x{2} grid\".format(len(axes_groups), nrows,\n                                                   ncols))\n\n        # create grid spec\n        gs = GridSpec(nrows, ncols)\n        axarr = numpy.empty((nrows, ncols), dtype=object)\n\n        # set default labels\n        defxlabel = 'xlabel' not in axes_kw\n        defylabel = 'ylabel' not in axes_kw\n        flatdata = [s for group in axes_groups for s in group]\n        for axis in ('x', 'y'):\n            unit = _common_axis_unit(flatdata, axis=axis)\n            if unit:\n                axes_kw.setdefault('{}label'.format(axis),\n                                   unit.to_string('latex_inline_dimensional'))\n\n        # create axes for each group and draw each data object\n        for group, (row, col) in zip_longest(\n                axes_groups, itertools.product(range(nrows), range(ncols)),\n                fillvalue=[]):\n            # create Axes\n            shared_with = {\"none\": None, \"all\": axarr[0, 0],\n                           \"row\": axarr[row, 0], \"col\": axarr[0, col]}\n            axes_kw[\"sharex\"] = shared_with[sharex]\n            axes_kw[\"sharey\"] = shared_with[sharey]\n            axes_kw['xscale'] = xscale if xscale else _parse_xscale(group)\n            ax = axarr[row, col] = self.add_subplot(gs[row, col], **axes_kw)\n\n            # plot data\n            plot_func = getattr(ax, method)\n            if method in ('imshow', 'pcolormesh'):\n                for obj in group:\n                    plot_func(obj, **kwargs)\n            elif group:\n                plot_func(*group, **kwargs)\n\n            # set default axis labels\n            for axis, share, pos, n, def_ in (\n                    (ax.xaxis, sharex, row, nrows, defxlabel),\n                    (ax.yaxis, sharey, col, ncols, defylabel),\n            ):\n                # hide label if shared axis and not bottom left panel\n                if share == 'all' and pos < n - 1:\n                    axis.set_label_text('')\n                # otherwise set default status\n                else:\n                    axis.isDefault_label = def_\n\n        return self.axes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrefreshes the current figure", "response": "def refresh(self):\n        \"\"\"Refresh the current figure\n        \"\"\"\n        for cbar in self.colorbars:\n            cbar.draw_all()\n        self.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying the current figure.", "response": "def show(self, block=None, warn=True):\n        \"\"\"Display the current figure (if possible).\n\n        If blocking, this method replicates the behaviour of\n        :func:`matplotlib.pyplot.show()`, otherwise it just calls up to\n        :meth:`~matplotlib.figure.Figure.show`.\n\n        This method also supports repeatedly showing the same figure, even\n        after closing the display window, which isn't supported by\n        `pyplot.show` (AFAIK).\n\n        Parameters\n        ----------\n        block : `bool`, optional\n            open the figure and block until the figure is closed, otherwise\n            open the figure as a detached window, default: `None`.\n            If `None`, block if using an interactive backend and _not_\n            inside IPython.\n\n        warn : `bool`, optional\n            print a warning if matplotlib is not running in an interactive\n            backend and cannot display the figure, default: `True`.\n        \"\"\"\n        # this method tries to reproduce the functionality of pyplot.show,\n        # mainly for user convenience. However, as of matplotlib-3.0.0,\n        # pyplot.show() ends up calling _back_ to Plot.show(),\n        # so we have to be careful not to end up in a recursive loop\n        #\n        # Developer note: if we ever make it pinning to matplotlib >=3.0.0\n        #                 this method can likely be completely removed\n        #\n        import inspect\n        try:\n            callframe = inspect.currentframe().f_back\n        except AttributeError:\n            pass\n        else:\n            if 'matplotlib' in callframe.f_code.co_filename:\n                block = False\n\n        # render\n        super(Plot, self).show(warn=warn)\n\n        # don't block on ipython with interactive backends\n        if block is None and interactive_backend():\n            block = not IPYTHON\n\n        # block in GUI loop (stolen from mpl.backend_bases._Backend.show)\n        if block:\n            backend_mod = get_backend_mod()\n            try:\n                backend_mod.Show().mainloop()\n            except AttributeError:  # matplotlib < 2.1.0\n                backend_mod.show.mainloop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the plot and release its memory.", "response": "def close(self):\n        \"\"\"Close the plot and release its memory.\n        \"\"\"\n        from matplotlib.pyplot import close\n        for ax in self.axes[::-1]:\n            # avoid matplotlib/matplotlib#9970\n            ax.set_xscale('linear')\n            ax.set_yscale('linear')\n            # clear the axes\n            ax.cla()\n        # close the figure\n        close(self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all axes optionally matching the given projection", "response": "def get_axes(self, projection=None):\n        \"\"\"Find all `Axes`, optionally matching the given projection\n\n        Parameters\n        ----------\n        projection : `str`\n            name of axes types to return\n\n        Returns\n        -------\n        axlist : `list` of `~matplotlib.axes.Axes`\n        \"\"\"\n        if projection is None:\n            return self.axes\n        return [ax for ax in self.axes if ax.name == projection.lower()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef colorbar(self, mappable=None, cax=None, ax=None, fraction=0.,\n                 label=None, emit=True, **kwargs):\n        \"\"\"Add a colorbar to the current `Plot`\n\n        A colorbar must be associated with an `Axes` on this `Plot`,\n        and an existing mappable element (e.g. an image).\n\n        Parameters\n        ----------\n        mappable : matplotlib data collection\n            Collection against which to map the colouring\n\n        cax : `~matplotlib.axes.Axes`\n            Axes on which to draw colorbar\n\n        ax : `~matplotlib.axes.Axes`\n            Axes relative to which to position colorbar\n\n        fraction : `float`, optional\n            Fraction of original axes to use for colorbar, give `fraction=0`\n            to not resize the original axes at all.\n\n        emit : `bool`, optional\n            If `True` update all mappables on `Axes` to match the same\n            colouring as the colorbar.\n\n        **kwargs\n            other keyword arguments to be passed to the\n            :meth:`~matplotlib.figure.Figure.colorbar`\n\n        Returns\n        -------\n        cbar : `~matplotlib.colorbar.Colorbar`\n            the newly added `Colorbar`\n\n        See Also\n        --------\n        matplotlib.figure.Figure.colorbar\n        matplotlib.colorbar.Colorbar\n\n        Examples\n        --------\n        >>> import numpy\n        >>> from gwpy.plot import Plot\n\n        To plot a simple image and add a colorbar:\n\n        >>> plot = Plot()\n        >>> ax = plot.gca()\n        >>> ax.imshow(numpy.random.randn(120).reshape((10, 12)))\n        >>> plot.colorbar(label='Value')\n        >>> plot.show()\n\n        Colorbars can also be generated by directly referencing the parent\n        axes:\n\n        >>> Plot = Plot()\n        >>> ax = plot.gca()\n        >>> ax.imshow(numpy.random.randn(120).reshape((10, 12)))\n        >>> ax.colorbar(label='Value')\n        >>> plot.show()\n        \"\"\"\n        # pre-process kwargs\n        mappable, kwargs = gcbar.process_colorbar_kwargs(\n            self, mappable, ax, cax=cax, fraction=fraction, **kwargs)\n\n        # generate colour bar\n        cbar = super(Plot, self).colorbar(mappable, **kwargs)\n        self.colorbars.append(cbar)\n        if label:  # mpl<1.3 doesn't accept label in Colorbar constructor\n            cbar.set_label(label)\n\n        # update mappables for this axis\n        if emit:\n            ax = kwargs.pop('ax')\n            norm = mappable.norm\n            cmap = mappable.get_cmap()\n            for map_ in ax.collections + ax.images:\n                map_.set_norm(norm)\n                map_.set_cmap(cmap)\n\n        return cbar", "response": "Add a colorbar to the current plot."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_colorbar(self, *args, **kwargs):\n        warnings.warn(\n            \"{0}.add_colorbar was renamed {0}.colorbar, this warnings will \"\n            \"result in an error in the future\".format(type(self).__name__),\n            DeprecationWarning)\n        return self.colorbar(*args, **kwargs)", "response": "DEPRECATED use Plot. colorbar instead."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a segment bar to the current figure.", "response": "def add_segments_bar(self, segments, ax=None, height=0.14, pad=0.1,\n                         sharex=True, location='bottom', **plotargs):\n        \"\"\"Add a segment bar `Plot` indicating state information.\n\n        By default, segments are displayed in a thin horizontal set of Axes\n        sitting immediately below the x-axis of the main,\n        similarly to a colorbar.\n\n        Parameters\n        ----------\n        segments : `~gwpy.segments.DataQualityFlag`\n            A data-quality flag, or `SegmentList` denoting state segments\n            about this Plot\n\n        ax : `Axes`, optional\n            Specific `Axes` relative to which to position new `Axes`,\n            defaults to :func:`~matplotlib.pyplot.gca()`\n\n        height : `float, `optional\n            Height of the new axes, as a fraction of the anchor axes\n\n        pad : `float`, optional\n            Padding between the new axes and the anchor, as a fraction of\n            the anchor axes dimension\n\n        sharex : `True`, `~matplotlib.axes.Axes`, optional\n            Either `True` to set ``sharex=ax`` for the new segment axes,\n            or an `Axes` to use directly\n\n        location : `str`, optional\n            Location for new segment axes, defaults to ``'bottom'``,\n            acceptable values are ``'top'`` or ``'bottom'``.\n\n        **plotargs\n            extra keyword arguments are passed to\n            :meth:`~gwpy.plot.SegmentAxes.plot`\n        \"\"\"\n        # get axes to anchor against\n        if not ax:\n            ax = self.gca()\n\n        # set options for new axes\n        axes_kw = {\n            'pad': pad,\n            'add_to_figure': True,\n            'sharex': ax if sharex is True else sharex or None,\n            'axes_class': get_projection_class('segments'),\n        }\n\n        # map X-axis limit from old axes\n        if axes_kw['sharex'] is ax and not ax.get_autoscalex_on():\n            axes_kw['xlim'] = ax.get_xlim()\n\n        # if axes uses GPS scaling, copy the epoch as well\n        try:\n            axes_kw['epoch'] = ax.get_epoch()\n        except AttributeError:\n            pass\n\n        # add new axes\n        if ax.get_axes_locator():\n            divider = ax.get_axes_locator()._axes_divider\n        else:\n            from mpl_toolkits.axes_grid1 import make_axes_locatable\n            divider = make_axes_locatable(ax)\n        if location not in {'top', 'bottom'}:\n            raise ValueError(\"Segments can only be positoned at 'top' or \"\n                             \"'bottom'.\")\n        segax = divider.append_axes(location, height, **axes_kw)\n\n        # update anchor axes\n        if axes_kw['sharex'] is ax and location == 'bottom':\n            # map label\n            segax.set_xlabel(ax.get_xlabel())\n            segax.xaxis.isDefault_label = ax.xaxis.isDefault_label\n            ax.set_xlabel(\"\")\n            # hide ticks on original axes\n            setp(ax.get_xticklabels(), visible=False)\n\n        # plot segments\n        segax.plot(segments, **plotargs)\n        segax.grid(b=False, which='both', axis='y')\n        segax.autoscale(axis='y', tight=True)\n\n        return segax"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the names of all channels present in the given HACR database", "response": "def get_hacr_channels(db=None, gps=None, connection=None,\n                      **conectkwargs):\n    \"\"\"Return the names of all channels present in the given HACR database\n    \"\"\"\n    # connect if needed\n    if connection is None:\n        if gps is None:\n            gps = from_gps('now')\n        if db is None:\n            db = get_database_names(gps, gps)[0]\n        connection = connect(db=db, **conectkwargs)\n    # query\n    out = query(\"select channel from job where monitorName = 'chacr'\")\n    return [r[0] for r in out]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_hacr_triggers(channel, start, end, columns=HACR_COLUMNS, pid=None,\n                      monitor='chacr', selection=None, **connectkwargs):\n    \"\"\"Fetch a table of HACR triggers in the given interval\n    \"\"\"\n    if columns is None:\n        columns = HACR_COLUMNS\n    columns = list(columns)\n    span = Segment(*map(to_gps, (start, end)))\n\n    # parse selection for SQL query (removing leading 'where ')\n    selectionstr = 'and %s' % format_db_selection(selection, engine=None)[6:]\n\n    # get database names and loop over each on\n    databases = get_database_names(start, end)\n    rows = []\n    for db in databases:\n        conn = connect(db, **connectkwargs)\n        cursor = conn.cursor()\n        # find process ID(s) for this channel\n        pids = query(\"select process_id, gps_start, gps_stop \"\n                     \"from job where monitorName = %r and channel = %r\"\n                     % (monitor, str(channel)), connection=conn)\n        for p, s, e in pids:\n            # validate this process id\n            if pid is not None and int(p) != int(pid):\n                continue\n            tspan = Segment(float(s), float(e))\n            if not tspan.intersects(span):\n                continue\n            # execute trigger query\n            q = ('select %s from mhacr where process_id = %d and '\n                 'gps_start > %s and gps_start < %d %s order by gps_start asc'\n                 % (', '.join(columns), int(p), span[0], span[1],\n                    selectionstr))\n            n = cursor.execute(q)\n            if n == 0:\n                continue\n            # get new events, convert to recarray, and append to table\n            rows.extend(cursor.fetchall())\n    return EventTable(rows=rows, names=columns)", "response": "Fetch a table of HACR triggers in the given interval"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(db, host=HACR_DATABASE_SERVER, user=HACR_DATABASE_USER,\n            passwd=HACR_DATABASE_PASSWD):\n    \"\"\"Connect to the given SQL database\n    \"\"\"\n    try:\n        import pymysql\n    except ImportError as e:\n        e.args = ('pymysql is required to fetch HACR triggers',)\n        raise\n    return pymysql.connect(host=host, user=user, passwd=passwd, db=db)", "response": "Connect to the given SQL database returning a connection object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query(querystr, connection=None, **connectkwargs):\n    if connection is None:\n        connection = connect(**connectkwargs)\n    cursor = connection.cursor()\n    cursor.execute(querystr)\n    return cursor.fetchall()", "response": "Execute a query of the given SQL database returning a list of rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a linear time - invariant filter to this BodePlot.", "response": "def add_filter(self, filter_, frequencies=None, dB=True,\n                   analog=False, sample_rate=None, **kwargs):\n        \"\"\"Add a linear time-invariant filter to this BodePlot\n\n        Parameters\n        ----------\n        filter_ : `~scipy.signal.lti`, `tuple`\n            the filter to plot, either as a `~scipy.signal.lti`, or a\n            `tuple` with the following number and meaning of elements\n\n                 - 2: (numerator, denominator)\n                 - 3: (zeros, poles, gain)\n                 - 4: (A, B, C, D)\n\n        frequencies : `numpy.ndarray`, optional\n            list of frequencies (in Hertz) at which to plot\n\n        dB : `bool`, optional\n            if `True`, display magnitude in decibels, otherwise display\n            amplitude, default: `True`\n\n        **kwargs\n            any other keyword arguments accepted by\n            :meth:`~matplotlib.axes.Axes.plot`\n\n        Returns\n        -------\n        mag, phase : `tuple` of `lines <matplotlib.lines.Line2D>`\n            the lines drawn for the magnitude and phase of the filter.\n        \"\"\"\n        if not analog:\n            if not sample_rate:\n                raise ValueError(\"Must give sample_rate frequency to display \"\n                                 \"digital (analog=False) filter\")\n            sample_rate = Quantity(sample_rate, 'Hz').value\n            dt = 2 * pi / sample_rate\n            if not isinstance(frequencies, (type(None), int)):\n                frequencies = numpy.atleast_1d(frequencies).copy()\n                frequencies *= dt\n\n        # parse filter (without digital conversions)\n        _, fcomp = parse_filter(filter_, analog=False)\n        if analog:\n            lti = signal.lti(*fcomp)\n        else:\n            lti = signal.dlti(*fcomp, dt=dt)\n\n        # calculate frequency response\n        w, mag, phase = lti.bode(w=frequencies)\n\n        # convert from decibels\n        if not dB:\n            mag = 10 ** (mag / 10.)\n\n        # draw\n        mline = self.maxes.plot(w, mag, **kwargs)[0]\n        pline = self.paxes.plot(w, phase, **kwargs)[0]\n        return mline, pline"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a frequency - series to the current object.", "response": "def add_frequencyseries(self, spectrum, dB=True, power=False, **kwargs):\n        \"\"\"Plot the magnitude and phase of a complex-valued `FrequencySeries`\n\n        Parameters\n        ----------\n        spectrum : `~gwpy.frequencyseries.FrequencySeries`\n            the (complex-valued) `FrequencySeries` to display\n\n        db : `bool`, optional, default: `True`\n            if `True`, display magnitude in decibels, otherwise display\n            amplitude.\n\n        power : `bool`, optional, default: `False`\n            give `True` to incidate that ``spectrum`` holds power values,\n            so ``dB = 10 * log(abs(spectrum))``, otherwise\n            ``db = 20 * log(abs(spectrum))``. This argument is ignored if\n            ``db=False``.\n\n        **kwargs\n            any other keyword arguments accepted by\n            :meth:`~matplotlib.axes.Axes.plot`\n\n        Returns\n        -------\n        mag, phase : `tuple` of `lines <matplotlib.lines.Line2D>`\n            the lines drawn for the magnitude and phase of the filter.\n        \"\"\"\n        # parse spectrum arguments\n        kwargs.setdefault('label', spectrum.name)\n        # get magnitude\n        mag = numpy.absolute(spectrum.value)\n        if dB:\n            mag = to_db(mag)\n            if not power:\n                mag *= 2.\n        # get phase\n        phase = numpy.angle(spectrum.value, deg=True)\n        # plot\n        w = spectrum.frequencies.value\n        mline = self.maxes.plot(w, mag, **kwargs)[0]\n        pline = self.paxes.plot(w, phase, **kwargs)[0]\n        return mline, pline"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing an Omega - scan configuration file into a list of ChannelList objects.", "response": "def read_omega_scan_config(source):\n    \"\"\"Parse an Omega-scan configuration file into a `ChannelList`\n\n    Parameters\n    ----------\n    source : `str`\n        path of Omega configuration file to parse\n\n    Returns\n    -------\n    channels : `ChannelList`\n        the list of channels (in order) as parsed\n\n    Raises\n    ------\n    RuntimeError\n        if this method finds a line it cannot parse sensibly\n    \"\"\"\n    out = ChannelList()\n    append = out.append\n    if isinstance(source, FILE_LIKE):\n        close = False\n    else:\n        source = open(source, 'r')\n        close = True\n    try:\n        section = None\n        while True:\n            try:\n                line = next(source)\n            except StopIteration:\n                break\n            if line == '' or line == '\\n' or line.startswith('#'):\n                continue\n            elif line.startswith('['):\n                section = line[1:-2]\n            elif line.startswith('{'):\n                append(parse_omega_channel(source, section))\n            else:\n                raise RuntimeError(\"Failed to parse Omega config line:\\n%s\"\n                                   % line)\n    finally:\n        if close:\n            source.close()\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_omega_channel(fobj, section=None):\n    params = OrderedDict()\n    while True:\n        line = next(fobj)\n        if line == '}\\n':\n            break\n        key, value = line.split(':', 1)\n        params[key.strip().rstrip()] = omega_param(value)\n    out = Channel(params.get('channelName'),\n                  sample_rate=params.get('sampleFrequency'),\n                  frametype=params.get('frameType'),\n                  frequency_range=params.get('searchFrequencyRange'))\n    out.group = section\n    out.params = params\n    return out", "response": "Parse a Channel from an Omega - scan configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a value from an Omega - scan configuration file into a str float or tuple", "response": "def omega_param(val):\n    \"\"\"Parse a value from an Omega-scan configuration file\n\n    This method tries to parse matlab-syntax parameters into a `str`,\n    `float`, or `tuple`\n    \"\"\"\n    val = val.strip().rstrip()\n    if val.startswith(('\"', \"'\")):\n        return str(val[1:-1])\n    if val.startswith('['):\n        return tuple(map(float, val[1:-1].split()))\n    return float(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_omega_scan_config(channellist, fobj, header=True):\n    if isinstance(fobj, FILE_LIKE):\n        close = False\n    else:\n        fobj = open(fobj, 'w')\n        close = True\n    try:\n        # print header\n        if header:\n            print('# Q Scan configuration file', file=fobj)\n            print('# Generated with GWpy from a ChannelList', file=fobj)\n        group = None\n        for channel in channellist:\n            # print header\n            if channel.group != group:\n                group = channel.group\n                print('\\n[%s]' % group, file=fobj)\n            print(\"\", file=fobj)\n            print_omega_channel(channel, file=fobj)\n    finally:\n        if close:\n            fobj.close()", "response": "Write a ChannelList to an Omega - pipeline scan configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a Omega - pipeline channel in Omega - pipeline scan format", "response": "def print_omega_channel(channel, file=sys.stdout):\n    \"\"\"Print a `Channel` in Omega-pipeline scan format\n    \"\"\"\n    print('{', file=file)\n    try:\n        params = channel.params.copy()\n    except AttributeError:\n        params = OrderedDict()\n    params.setdefault('channelName', str(channel))\n    params.setdefault('alwaysPlotFlag', int(params.pop('important', False)))\n    if channel.frametype:\n        params.setdefault('frameType', channel.frametype)\n    if channel.sample_rate is not None:\n        params.setdefault('sampleFrequency',\n                          channel.sample_rate.to('Hz').value)\n    if channel.frequency_range is not None:\n        low, high = channel.frequency_range.to('Hz').value\n        params.setdefault('searchFrequencyRange', (low, high))\n    if 'qlow' in params or 'qhigh' in params:\n        qlow = params.pop('qlow', 'sqrt(11)')\n        qhigh = params.pop('qhigh', 64)\n        params.setdefault('searchQRange', (qlow, qhigh))\n    # write params\n    for key in ['channelName', 'frameType']:\n        if key not in params:\n            raise KeyError(\"No %r defined for %s\" % (key, str(channel)))\n    for key, value in params.items():\n        key = '%s:' % str(key)\n        if isinstance(value, tuple):\n            value = '[%s]' % ' '.join(map(str, value))\n        elif isinstance(value, float) and value.is_integer():\n            value = int(value)\n        elif isinstance(value, str):\n            value = repr(value)\n        print('  {0: <30}  {1}'.format(key, value), file=file)\n    print('}', file=file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the NDS2 - formatted name for a channel object", "response": "def _get_nds2_name(channel):\n    \"\"\"Returns the NDS2-formatted name for a channel\n\n    Understands how to format NDS name strings from\n    `gwpy.detector.Channel` and `nds2.channel` objects\n    \"\"\"\n    if hasattr(channel, 'ndsname'):  # gwpy.detector.Channel\n        return channel.ndsname\n    if hasattr(channel, 'channel_type'):  # nds2.channel\n        return '%s,%s' % (channel.name,\n                          channel.channel_type_to_string(channel.channel_type))\n    return str(channel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_nds_env(env='NDSSERVER'):\n    hosts = []\n    for host in os.getenv(env).split(','):\n        try:\n            host, port = host.rsplit(':', 1)\n        except ValueError:\n            port = None\n        else:\n            port = int(port)\n        if (host, port) not in hosts:\n            hosts.append((host, port))\n    return hosts", "response": "Parse the NDSSERVER environment variable into a list of hosts and ports."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a logical ordering of NDS servers for this IFO and a set of ports for that NDS server.", "response": "def host_resolution_order(ifo, env='NDSSERVER', epoch='now',\n                          lookback=14*86400):\n    \"\"\"Generate a logical ordering of NDS (host, port) tuples for this IFO\n\n    Parameters\n    ----------\n    ifo : `str`\n        prefix for IFO of interest\n    env : `str`, optional\n        environment variable name to use for server order,\n        default ``'NDSSERVER'``. The contents of this variable should\n        be a comma-separated list of `host:port` strings, e.g.\n        ``'nds1.server.com:80,nds2.server.com:80'``\n    epoch : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n        GPS epoch of data requested\n    lookback : `float`\n        duration of spinning-disk cache. This value triggers defaulting to\n        the CIT NDS2 server over those at the LIGO sites\n\n    Returns\n    -------\n    hro : `list` of `2-tuples <tuple>`\n        ordered `list` of ``(host, port)`` tuples\n    \"\"\"\n    hosts = []\n    # if given environment variable exists, it will contain a\n    # comma-separated list of host:port strings giving the logical ordering\n    if env and os.getenv(env):\n        hosts = parse_nds_env(env)\n    # If that host fails, return the server for this IFO and the backup at CIT\n    if to_gps('now') - to_gps(epoch) > lookback:\n        ifolist = [None, ifo]\n    else:\n        ifolist = [ifo, None]\n    for difo in ifolist:\n        try:\n            host, port = DEFAULT_HOSTS[difo]\n        except KeyError:\n            # unknown default NDS2 host for detector, if we don't have\n            # hosts already defined (either by NDSSERVER or similar)\n            # we should warn the user\n            if not hosts:\n                warnings.warn('No default host found for ifo %r' % ifo)\n        else:\n            if (host, port) not in hosts:\n                hosts.append((host, port))\n    return list(hosts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening an nds2. connection to a given host and port.", "response": "def connect(host, port=None):\n    \"\"\"Open an `nds2.connection` to a given host and port\n\n    Parameters\n    ----------\n    host : `str`\n        name of server with which to connect\n\n    port : `int`, optional\n        connection port\n\n    Returns\n    -------\n    connection : `nds2.connection`\n        a new open connection to the given NDS host\n    \"\"\"\n    import nds2\n    # pylint: disable=no-member\n\n    # set default port for NDS1 connections (required, I think)\n    if port is None and NDS1_HOSTNAME.match(host):\n        port = 8088\n\n    if port is None:\n        return nds2.connection(host)\n    return nds2.connection(host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen an nds2. connection handling simple authentication errors and return a new nds2. connection object.", "response": "def auth_connect(host, port=None):\n    \"\"\"Open an `nds2.connection` handling simple authentication errors\n\n    This method will catch exceptions related to kerberos authentication,\n    and execute a kinit() for the user before attempting to connect again.\n\n    Parameters\n    ----------\n    host : `str`\n        name of server with which to connect\n\n    port : `int`, optional\n        connection port\n\n    Returns\n    -------\n    connection : `nds2.connection`\n        a new open connection to the given NDS host\n    \"\"\"\n    try:\n        return connect(host, port)\n    except RuntimeError as exc:\n        if 'Request SASL authentication' not in str(exc):\n            raise\n    warnings.warn('Error authenticating against {0}:{1}'.format(host, port),\n                  NDSWarning)\n    kinit()\n    return connect(host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_connection(func):\n    @wraps(func)\n    def wrapped_func(*args, **kwargs):  # pylint: disable=missing-docstring\n        if kwargs.get('connection', None) is None:\n            try:\n                host = kwargs.pop('host')\n            except KeyError:\n                raise TypeError(\"one of `connection` or `host` is required \"\n                                \"to query NDS2 server\")\n            kwargs['connection'] = auth_connect(host, kwargs.pop('port', None))\n        return func(*args, **kwargs)\n    return wrapped_func", "response": "Decorate a function to create a nds2. connection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecorating a function to translate a type string into an integer", "response": "def parse_nds2_enums(func):\n    \"\"\"Decorate a function to translate a type string into an integer\n    \"\"\"\n    @wraps(func)\n    def wrapped_func(*args, **kwargs):  # pylint: disable=missing-docstring\n        for kwd, enum_ in (('type', Nds2ChannelType),\n                           ('dtype', Nds2DataType)):\n            if kwargs.get(kwd, None) is None:\n                kwargs[kwd] = enum_.any()\n            elif not isinstance(kwargs[kwd], int):\n                kwargs[kwd] = enum_.find(kwargs[kwd]).value\n        return func(*args, **kwargs)\n    return wrapped_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping a function to reset the epoch when finished otope", "response": "def reset_epoch(func):\n    \"\"\"Wrap a function to reset the epoch when finished\n\n    This is useful for functions that wish to use `connection.set_epoch`.\n    \"\"\"\n    @wraps(func)\n    def wrapped_func(*args, **kwargs):  # pylint: disable=missing-docstring\n        connection = kwargs.get('connection', None)\n        epoch = connection.current_epoch() if connection else None\n        try:\n            return func(*args, **kwargs)\n        finally:\n            if epoch is not None:\n                connection.set_epoch(epoch.gps_start, epoch.gps_stop)\n    return wrapped_func"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_channels(channels, connection=None, host=None, port=None,\n                  sample_rate=None, type=Nds2ChannelType.any(),\n                  dtype=Nds2DataType.any(), unique=False, epoch='ALL'):\n    # pylint: disable=unused-argument,redefined-builtin\n    \"\"\"Query an NDS2 server for channel information\n\n    Parameters\n    ----------\n    channels : `list` of `str`\n        list of channel names to query, each can include bash-style globs\n\n    connection : `nds2.connection`, optional\n        open NDS2 connection to use for query\n\n    host : `str`, optional\n        name of NDS2 server to query, required if ``connection`` is not\n        given\n\n    port : `int`, optional\n        port number on host to use for NDS2 connection\n\n    sample_rate : `int`, `float`, `tuple`, optional\n        a single number, representing a specific sample rate to match,\n        or a tuple representing a ``(low, high)` interval to match\n\n    type : `int`, optional\n        the NDS2 channel type to match\n\n    dtype : `int`, optional\n        the NDS2 data type to match\n\n    unique : `bool`, optional, default: `False`\n        require one (and only one) match per channel\n\n    epoch : `str`, `tuple` of `int`, optional\n        the NDS epoch to restrict to, either the name of a known epoch,\n        or a 2-tuple of GPS ``[start, stop)`` times\n\n    Returns\n    -------\n    channels : `list` of `nds2.channel`\n        list of NDS2 channel objects\n\n    See also\n    --------\n    nds2.connection.find_channels\n        for documentation on the underlying query method\n\n    Examples\n    --------\n    >>> from gwpy.io.nds2 import find_channels\n    >>> find_channels(['G1:DER_DATA_H'], host='nds.ligo.caltech.edu')\n    [<G1:DER_DATA_H (16384Hz, RDS, FLOAT64)>]\n    \"\"\"\n    # set epoch\n    if not isinstance(epoch, tuple):\n        epoch = (epoch or 'All',)\n    connection.set_epoch(*epoch)\n\n    # format sample_rate as tuple for find_channels call\n    if isinstance(sample_rate, (int, float)):\n        sample_rate = (sample_rate, sample_rate)\n    elif sample_rate is None:\n        sample_rate = tuple()\n\n    # query for channels\n    out = []\n    for name in _get_nds2_names(channels):\n        out.extend(_find_channel(connection, name, type, dtype, sample_rate,\n                                 unique=unique))\n    return out", "response": "Query an NDS2 server for channel information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _strip_ctype(name, ctype, protocol=2):\n    # parse channel type from name (e.g. 'L1:GDS-CALIB_STRAIN,reduced')\n    try:\n        name, ctypestr = name.rsplit(',', 1)\n    except ValueError:\n        pass\n    else:\n        ctype = Nds2ChannelType.find(ctypestr).value\n        # NDS1 stores channels with trend suffix, so we put it back:\n        if protocol == 1 and ctype in (\n                Nds2ChannelType.STREND.value,\n                Nds2ChannelType.MTREND.value\n        ):\n            name += ',{0}'.format(ctypestr)\n    return name, ctype", "response": "Strip the ctype from a channel name for the given nds server version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_availability(channels, start, end,\n                     connection=None, host=None, port=None):\n    # pylint: disable=unused-argument\n    \"\"\"Query an NDS2 server for data availability\n\n    Parameters\n    ----------\n    channels : `list` of `str`\n        list of channel names to query; this list is mapped to NDS channel\n        names using :func:`find_channels`.\n\n    start : `int`\n        GPS start time of query\n\n    end : `int`\n        GPS end time of query\n\n    connection : `nds2.connection`, optional\n        open NDS2 connection to use for query\n\n    host : `str`, optional\n        name of NDS2 server to query, required if ``connection`` is not\n        given\n\n    port : `int`, optional\n        port number on host to use for NDS2 connection\n\n    Returns\n    -------\n    segdict : `~gwpy.segments.SegmentListDict`\n        dict of ``(name, SegmentList)`` pairs\n\n    Raises\n    ------\n    ValueError\n        if the given channel name cannot be mapped uniquely to a name\n        in the NDS server database.\n\n    See also\n    --------\n    nds2.connection.get_availability\n        for documentation on the underlying query method\n    \"\"\"\n    from ..segments import (Segment, SegmentList, SegmentListDict)\n    connection.set_epoch(start, end)\n    # map user-given real names to NDS names\n    names = list(map(\n        _get_nds2_name, find_channels(channels, epoch=(start, end),\n                                      connection=connection, unique=True),\n    ))\n    # query for availability\n    result = connection.get_availability(names)\n    # map to segment types\n    out = SegmentListDict()\n    for name, result in zip(channels, result):\n        out[name] = SegmentList([Segment(s.gps_start, s.gps_stop) for s in\n                                 result.simple_list()])\n    return out", "response": "Query an NDS2 server for data availability of a given set of channels."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexpand a start and end time for use in querying for minute trends", "response": "def minute_trend_times(start, end):\n    \"\"\"Expand a [start, end) interval for use in querying for minute trends\n\n    NDS2 requires start and end times for minute trends to be a multiple of\n    60 (to exactly match the time of a minute-trend sample), so this function\n    expands the given ``[start, end)`` interval to the nearest multiples.\n\n    Parameters\n    ----------\n    start : `int`\n        GPS start time of query\n\n    end : `int`\n        GPS end time of query\n\n    Returns\n    -------\n    mstart : `int`\n        ``start`` rounded down to nearest multiple of 60\n    mend : `int`\n        ``end`` rounded up to nearest multiple of 60\n    \"\"\"\n    if start % 60:\n        start = int(start) // 60 * 60\n    if end % 60:\n        end = int(end) // 60 * 60 + 60\n    return int(start), int(end)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(cls, name):\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n            for ctype in cls._member_map_.values():\n                if ctype.name == name:\n                    return ctype\n            raise ValueError('%s is not a valid %s' % (name, cls.__name__))", "response": "Returns the NDS2 channel type corresponding to the given name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the NDS2 type corresponding to the given python type", "response": "def find(cls, dtype):\n        \"\"\"Returns the NDS2 type corresponding to the given python type\n        \"\"\"\n        try:\n            return cls._member_map_[dtype]\n        except KeyError:\n            try:\n                dtype = numpy.dtype(dtype).type\n            except TypeError:\n                for ndstype in cls._member_map_.values():\n                    if ndstype.value is dtype:\n                        return ndstype\n            else:\n                for ndstype in cls._member_map_.values():\n                    if ndstype.value and ndstype.numpy_dtype is dtype:\n                        return ndstype\n            raise ValueError('%s is not a valid %s' % (dtype, cls.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a new connection based on an existing connection", "response": "def reconnect(connection):\n    \"\"\"Open a new datafind connection based on an existing connection\n\n    This is required because of https://git.ligo.org/lscsoft/glue/issues/1\n\n    Parameters\n    ----------\n    connection : :class:`~gwdatafind.http.HTTPConnection` or `FflConnection`\n        a connection object (doesn't need to be open)\n\n    Returns\n    -------\n    newconn : :class:`~gwdatafind.http.HTTPConnection` or `FflConnection`\n        the new open connection to the same `host:port` server\n    \"\"\"\n    if isinstance(connection, FflConnection):\n        return type(connection)(connection.ffldir)\n    kw = {'context': connection._context} if connection.port != 80 else {}\n    return connection.__class__(connection.host, port=connection.port, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _type_priority(ifo, ftype, trend=None):\n    # if looking for a trend channel, prioritise the matching type\n    for trendname, trend_regex in [\n            ('m-trend', MINUTE_TREND_TYPE),\n            ('s-trend', SECOND_TREND_TYPE),\n    ]:\n        if trend == trendname and trend_regex.match(ftype):\n            return 0, len(ftype)\n\n    # otherwise rank this type according to priority\n    for reg, prio in {\n            HIGH_PRIORITY_TYPE: 1,\n            re.compile(r'[A-Z]\\d_C'): 6,\n            LOW_PRIORITY_TYPE: 10,\n            MINUTE_TREND_TYPE: 10,\n            SECOND_TREND_TYPE: 10,\n    }.items():\n        if reg.search(ftype):\n            return prio, len(ftype)\n\n    return 5, len(ftype)", "response": "Prioritise the given GWF type based on its name or trend status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if any of the given files are on tape.", "response": "def on_tape(*files):\n    \"\"\"Determine whether any of the given files are on tape\n\n    Parameters\n    ----------\n    *files : `str`\n        one or more paths to GWF files\n\n    Returns\n    -------\n    True/False : `bool`\n        `True` if any of the files are determined to be on tape,\n        otherwise `False`\n    \"\"\"\n    for path in files:\n        try:\n            if os.stat(path).st_blocks == 0:\n                return True\n        except AttributeError:  # windows doesn't have st_blocks\n            return False\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_connection(func):\n    @wraps(func)\n    def wrapped(*args, **kwargs):\n        if kwargs.get('connection') is None:\n            kwargs['connection'] = _choose_connection(host=kwargs.get('host'),\n                                                      port=kwargs.get('port'))\n        try:\n            return func(*args, **kwargs)\n        except HTTPException:\n            kwargs['connection'] = reconnect(kwargs['connection'])\n            return func(*args, **kwargs)\n    return wrapped", "response": "Decorate a function to open a new datafind connection if required\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the frametype that hold data for a given channel", "response": "def find_frametype(channel, gpstime=None, frametype_match=None,\n                   host=None, port=None, return_all=False, allow_tape=False,\n                   connection=None, on_gaps='error'):\n    \"\"\"Find the frametype(s) that hold data for a given channel\n\n    Parameters\n    ----------\n    channel : `str`, `~gwpy.detector.Channel`\n        the channel to be found\n\n    gpstime : `int`, optional\n        target GPS time at which to find correct type\n\n    frametype_match : `str`, optional\n        regular expression to use for frametype `str` matching\n\n    host : `str`, optional\n        name of datafind host to use\n\n    port : `int`, optional\n        port on datafind host to use\n\n    return_all : `bool`, optional, default: `False`\n        return all found types, default is to return to 'best' match\n\n    allow_tape : `bool`, optional, default: `False`\n        do not test types whose frame files are stored on tape (not on\n        spinning disk)\n\n    on_gaps : `str`, optional\n        action to take when gaps are discovered in datafind coverage,\n        default: ``'error'``, i.e. don't match frametypes with gaps.\n        Select ``'ignore'`` to ignore gaps, or ``'warn'`` to display\n        warnings when gaps are found in a datafind `find_urls` query\n\n    Returns\n    -------\n    If a single name is given, and `return_all=False` (default):\n\n    frametype : `str`\n        name of best match frame type\n\n    If a single name is given, and `return_all=True`:\n\n    types : `list` of `str`\n        the list of all matching frame types\n\n    If multiple names are given, the above return types are wrapped into a\n    `dict` of `(channel, type_or_list)` pairs.\n\n    Examples\n    --------\n    >>> from gwpy.io import datafind as io_datafind\n    >>> io_datafind.find_frametype('H1:IMC-PWR_IN_OUTPUT', gpstime=1126259462)\n    'H1_R'\n    >>> io_datafind.find_frametype('H1:IMC-PWR_IN_OUTPUT', gpstime=1126259462,\n    ...                            return_all=True)\n    ['H1_R', 'H1_C']\n    >>> io_datafind.find_frametype(\n    ...     ('H1:IMC-PWR_IN_OUTPUT', 'H1:OMC-DCPD_SUM_OUTPUT',\n    ...      'H1:GDS-CALIB_STRAIN'),\n    ...     gpstime=1126259462, return_all=True))\"\n    {'H1:GDS-CALIB_STRAIN': ['H1_HOFT_C00'],\n     'H1:OMC-DCPD_SUM_OUTPUT': ['H1_R', 'H1_C'],\n     'H1:IMC-PWR_IN_OUTPUT': ['H1_R', 'H1_C']}\n    \"\"\"\n    # this function is now horrendously complicated to support a large\n    # number of different use cases, hopefully the comments are sufficient\n\n    from ..detector import Channel\n\n    # format channel names as list\n    if isinstance(channel, (list, tuple)):\n        channels = channel\n    else:\n        channels = [channel]\n\n    # create set() of GWF channel names, and dict map back to user names\n    #    this allows users to use nds-style names in this query, e.g.\n    #    'X1:TEST.mean,m-trend', and still get results\n    chans = {Channel(c).name: c for c in channels}\n    names = set(chans.keys())\n\n    # format GPS time(s)\n    if isinstance(gpstime, (list, tuple)):\n        from ..segments import Segment\n        gpssegment = Segment(*gpstime)\n        gpstime = gpssegment[0]\n    else:\n        gpssegment = None\n    if gpstime is not None:\n        gpstime = int(to_gps(gpstime))\n\n    # if use gaps post-S5 GPStime, forcibly skip _GRBYYMMDD frametypes at CIT\n    if frametype_match is None and gpstime is not None and gpstime > 875232014:\n        frametype_match = GRB_TYPE\n\n    # -- go\n\n    match = {}\n    ifos = set()  # record IFOs we have queried to prevent duplication\n\n    # loop over set of names, which should get smaller as names are searched\n    while names:\n        # parse first channel name (to get IFO and channel type)\n        try:\n            name = next(iter(names))\n        except KeyError:\n            break\n        else:\n            chan = Channel(chans[name])\n\n        # parse IFO ID\n        try:\n            ifo = chan.ifo[0]\n        except TypeError:  # chan.ifo is None\n            raise ValueError(\"Cannot parse interferometer prefix from channel \"\n                             \"name %r, cannot proceed with find()\" % str(chan))\n\n        # if we've already gone through the types for this IFO, skip\n        if ifo in ifos:\n            names.pop()\n            continue\n        ifos.add(ifo)\n\n        types = find_types(ifo, match=frametype_match, trend=chan.type,\n                           connection=connection)\n\n        # loop over types testing each in turn\n        for ftype in types:\n            # find instance of this frametype\n            try:\n                path = find_latest(ifo, ftype, gpstime=gpstime,\n                                   allow_tape=allow_tape,\n                                   connection=connection, on_missing='ignore')\n            except (RuntimeError, IOError, IndexError):  # something went wrong\n                continue\n\n            # check for gaps in the record for this type\n            if gpssegment is None:\n                gaps = 0\n            else:\n                cache = find_urls(ifo, ftype, *gpssegment, on_gaps=on_gaps,\n                                  connection=connection)\n                csegs = cache_segments(cache)\n                gaps = abs(gpssegment) - abs(csegs)\n\n            # search the TOC for one frame file and match any channels\n            i = 0\n            nchan = len(names)\n            for n in iter_channel_names(path):\n                if n in names:\n                    i += 1\n                    c = chans[n]  # map back to user-given channel name\n                    try:\n                        match[c].append((ftype, path, -gaps))\n                    except KeyError:\n                        match[c] = [(ftype, path, -gaps)]\n                    if not return_all:  # match once only\n                        names.remove(n)\n                    if not names or n == nchan:  # break out of TOC loop\n                        break\n\n            if not names:  # break out of ftype loop if all names matched\n                break\n\n        try:\n            names.pop()\n        except KeyError:  # done\n            break\n\n    # raise exception if nothing found\n    missing = set(channels) - set(match.keys())\n    if missing:\n        msg = \"Cannot locate the following channel(s) in any known frametype\"\n        if gpstime:\n            msg += \" at GPS=%d\" % gpstime\n        msg += \":\\n    {}\".format('\\n    '.join(missing))\n        if not allow_tape:\n            msg += (\"\\n[files on tape have not been checked, use \"\n                    \"allow_tape=True for a complete search]\")\n        raise ValueError(msg)\n\n    # if matching all types, rank based on coverage, tape, and TOC size\n    if return_all:\n        paths = set(p[1] for key in match for p in match[key])\n        rank = {path: (on_tape(path), num_channels(path)) for path in paths}\n        # deprioritise types on tape and those with lots of channels\n        for key in match:\n            match[key].sort(key=lambda x: (x[2],) + rank[x[1]])\n        # remove instance paths (just leave channel and list of frametypes)\n        ftypes = {key: list(list(zip(*match[key]))[0]) for key in match}\n    else:\n        ftypes = {key: match[key][0][0] for key in match}\n\n    # if given a list of channels, return a dict\n    if isinstance(channel, (list, tuple)):\n        return ftypes\n\n    # otherwise just return a list for this type\n    return ftypes[str(channel)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_types(observatory, match=None, trend=None,\n               connection=None, **connection_kw):\n    \"\"\"Find the available data types for a given observatory.\n\n    See also\n    --------\n    gwdatafind.http.HTTPConnection.find_types\n    FflConnection.find_types\n        for details on the underlying method(s)\n    \"\"\"\n    return sorted(connection.find_types(observatory, match=match),\n                  key=lambda x: _type_priority(observatory, x, trend=trend))", "response": "Find the available data types for a given observatory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_urls(observatory, frametype, start, end, on_gaps='error',\n              connection=None, **connection_kw):\n    \"\"\"Find the URLs of files of a given data type in a GPS interval.\n\n    See also\n    --------\n    gwdatafind.http.HTTPConnection.find_urls\n    FflConnection.find_urls\n        for details on the underlying method(s)\n    \"\"\"\n    return connection.find_urls(observatory, frametype, start, end,\n                                on_gaps=on_gaps)", "response": "Find the URLs of files of a given data type in a GPS interval."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ffl_path(self, site, frametype):\n        try:\n            return self.paths[(site, frametype)]\n        except KeyError:\n            self._find_paths()\n            return self.paths[(site, frametype)]", "response": "Returns the path of the FFL file for the given site and frametype"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of known data types.", "response": "def find_types(self, site=None, match=r'^(?!lastfile|spectro|\\.).*'):\n        \"\"\"Return the list of known data types.\n\n        This is just the basename of each FFL file found in the\n        FFL directory (minus the ``.ffl`` extension)\n        \"\"\"\n        self._find_paths()\n        types = [tag for (site_, tag) in self.paths if site in (None, site_)]\n        if match is not None:\n            match = re.compile(match)\n            return list(filter(match.search, types))\n        return types"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_urls(self, site, frametype, gpsstart, gpsend,\n                  match=None, on_gaps='warn'):\n        \"\"\"Find all files of the given type in the [start, end) GPS interval.\n        \"\"\"\n        span = Segment(gpsstart, gpsend)\n        cache = [e for e in self._read_ffl_cache(site, frametype) if\n                 e.observatory == site and e.description == frametype and\n                 e.segment.intersects(span)]\n        urls = [e.path for e in cache]\n        missing = SegmentList([span]) - cache_segments(cache)\n\n        if match:\n            match = re.compile(match)\n            urls = list(filter(match.search, urls))\n\n        # no missing data or don't care, return\n        if on_gaps == 'ignore' or not missing:\n            return urls\n\n        # handle missing data\n        msg = 'Missing segments: \\n{0}'.format('\\n'.join(map(str, missing)))\n        if on_gaps == 'warn':\n            warnings.warn(msg)\n            return urls\n        raise RuntimeError(msg)", "response": "Find all files of the given type in the given start and end GPS interval."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a LIGO_LW ContentHandler class for reading a series of LIGO_LW content.", "response": "def series_contenthandler():\n    \"\"\"Build a `~xml.sax.handlers.ContentHandler` to read a LIGO_LW <Array>\n    \"\"\"\n    from ligo.lw import (\n        ligolw,\n        array as ligolw_array,\n        param as ligolw_param\n    )\n\n    @ligolw_array.use_in\n    @ligolw_param.use_in\n    class ArrayContentHandler(ligolw.LIGOLWContentHandler):\n        \"\"\"`~xml.sax.handlers.ContentHandler` to read a LIGO_LW <Array>\n        \"\"\"\n        pass\n\n    return ArrayContentHandler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_series(source, name, match=None):\n    from ligo.lw.ligolw import (LIGO_LW, Time, Array, Dim)\n    from ligo.lw.param import get_param\n\n    # read document\n    xmldoc = read_ligolw(source, contenthandler=series_contenthandler())\n\n    # parse match dict\n    if match is None:\n        match = dict()\n\n    def _is_match(elem):\n        try:\n            if elem.Name != name:\n                return False\n        except AttributeError:  # Name is not set\n            return False\n        for key, value in match.items():\n            try:\n                if get_param(elem, key).pcdata != value:\n                    return False\n            except ValueError:  # no Param with this Name\n                return False\n        return True\n\n    # parse out correct element\n    matches = filter(_is_match, xmldoc.getElementsByTagName(LIGO_LW.tagName))\n    try:\n        elem, = matches\n    except ValueError as exc:\n        if not matches:\n            exc.args = (\"no LIGO_LW elements found matching request\",)\n        else:\n            exc.args = ('multiple LIGO_LW elements found matching request, '\n                        'please consider using `match=` to select the '\n                        'correct element',)\n        raise\n\n    # get data\n    array, = elem.getElementsByTagName(Array.tagName)\n\n    # parse dimensions\n    dims = array.getElementsByTagName(Dim.tagName)\n    xdim = dims[0]\n    x0 = xdim.Start\n    dx = xdim.Scale\n    xunit = xdim.Unit\n    try:\n        ndim = dims[1].n\n    except IndexError:\n        pass\n    else:\n        if ndim > 2:\n            raise ValueError(\"Cannot parse LIGO_LW Array with {} \"\n                             \"dimensions\".format(ndim))\n\n    # parse metadata\n    array_kw = {\n        'name': array.Name,\n        'unit': array.Unit,\n        'xunit': xunit,\n    }\n    try:\n        array_kw['epoch'] = to_gps(\n            elem.getElementsByTagName(Time.tagName)[0].pcdata)\n    except IndexError:\n        pass\n    for key in ('channel',):\n        try:\n            array_kw[key] = get_param(elem, key)\n        except ValueError:\n            pass\n\n    # build Series\n    try:\n        xindex, value = array.array\n    except ValueError:  # not two dimensions stored\n        return Series(array.array[0], x0=x0, dx=dx, **array_kw)\n    return Series(value, xindex=xindex, **array_kw)", "response": "Read a Series from a LIGO_LW - format XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_plot(self):\n        args = self.args\n\n        fftlength = float(args.secpfft)\n        overlap = args.overlap\n        self.log(2, \"Calculating spectrum secpfft: %s, overlap: %s\" %\n                 (fftlength, overlap))\n        if overlap is not None:\n            overlap *= fftlength\n\n        self.log(3, 'Reference channel: ' + self.ref_chan)\n\n        # group data by segment\n        groups = OrderedDict()\n        for series in self.timeseries:\n            seg = series.span\n            try:\n                groups[seg][series.channel.name] = series\n            except KeyError:\n                groups[seg] = OrderedDict()\n                groups[seg][series.channel.name] = series\n\n        # -- plot\n\n        plot = Plot(figsize=self.figsize, dpi=self.dpi)\n        ax = plot.gca()\n        self.spectra = []\n\n        # calculate coherence\n        for seg in groups:\n            refts = groups[seg].pop(self.ref_chan)\n            for name in groups[seg]:\n                series = groups[seg][name]\n                coh = series.coherence(refts, fftlength=fftlength,\n                                       overlap=overlap, window=args.window)\n\n                label = name\n                if len(self.start_list) > 1:\n                    label += ', {0}'.format(series.epoch.gps)\n                if self.usetex:\n                    label = label_to_latex(label)\n\n                ax.plot(coh, label=label)\n                self.spectra.append(coh)\n\n        if args.xscale == 'log' and not args.xmin:\n            args.xmin = 1/fftlength\n\n        return plot", "response": "Generate the coherence plot from all time series and the time series."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_legend(self):\n        leg = super(Coherence, self).set_legend()\n        if leg is not None:\n            leg.set_title('Coherence with:')\n        return leg", "response": "Create a legend for this product"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_unit(name, parse_strict='warn', format='gwpy'):\n    if name is None or isinstance(name, units.UnitBase):\n        return name\n\n    try:  # have we already identified this unit as unrecognised?\n        return UNRECOGNIZED_UNITS[name]\n    except KeyError:  # no, this is new\n        # pylint: disable=unexpected-keyword-arg\n        try:\n            return units.Unit(name, parse_strict='raise')\n        except ValueError as exc:\n            if (parse_strict == 'raise' or\n                    'did not parse as unit' not in str(exc)):\n                raise\n            # try again using out own lenient parser\n            GWpyFormat.warn = parse_strict != 'silent'\n            return units.Unit(name, parse_strict='silent', format=format)\n        finally:\n            GWpyFormat.warn = True", "response": "Attempt to intelligently parse a str into a ~astropy. units. Unit object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _row_from_frevent(frevent, columns, selection):\n    # read params\n    params = dict(frevent.GetParam())\n    params['time'] = float(LIGOTimeGPS(*frevent.GetGTime()))\n    params['amplitude'] = frevent.GetAmplitude()\n    params['probability'] = frevent.GetProbability()\n    params['timeBefore'] = frevent.GetTimeBefore()\n    params['timeAfter'] = frevent.GetTimeAfter()\n    params['comment'] = frevent.GetComment()\n    # filter\n    if not all(op_(params[c], t) for c, op_, t in selection):\n        return None\n    # return event as list\n    return [params[c] for c in columns]", "response": "Generate a table row from a FrEvent object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a Table from a FrEvent file or file.", "response": "def table_from_gwf(filename, name, columns=None, selection=None):\n    \"\"\"Read a Table from FrEvent structures in a GWF file (or files)\n\n    Parameters\n    ----------\n    filename : `str`\n        path of GWF file to read\n\n    name : `str`\n        name associated with the `FrEvent` structures\n\n    columns : `list` of `str`\n        list of column names to read\n\n    selection : `str`, `list` of `str`\n        one or more column selection strings to apply, e.g. ``'snr>6'``\n    \"\"\"\n    # open frame file\n    if isinstance(filename, FILE_LIKE):\n        filename = filename.name\n    stream = io_gwf.open_gwf(filename)\n\n    # parse selections and map to column indices\n    if selection is None:\n        selection = []\n    selection = parse_column_filters(selection)\n\n    # read events row by row\n    data = []\n    i = 0\n    while True:\n        try:\n            frevent = stream.ReadFrEvent(i, name)\n        except IndexError:\n            break\n        i += 1\n        # read first event to get column names\n        if columns is None:\n            columns = _columns_from_frevent(frevent)\n        # read row with filter\n        row = _row_from_frevent(frevent, columns, selection)\n        if row is not None:  # if passed selection\n            data.append(row)\n\n    return Table(rows=data, names=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a table to a GWF file.", "response": "def table_to_gwf(table, filename, name, **kwargs):\n    \"\"\"Create a new `~frameCPP.FrameH` and fill it with data\n\n    Parameters\n    ----------\n    table : `~astropy.table.Table`\n        the data to write\n\n    filename : `str`\n        the name of the file to write into\n\n    **kwargs\n        other keyword arguments (see below for references)\n\n    See Also\n    --------\n    gwpy.io.gwf.create_frame\n    gwpy.io.gwf.write_frames\n        for documentation of keyword arguments\n    \"\"\"\n    from LDAStools.frameCPP import (FrEvent, GPSTime)\n\n    # create frame\n    write_kw = {key: kwargs.pop(key) for\n                key in ('compression', 'compression_level') if key in kwargs}\n    frame = io_gwf.create_frame(name=name, **kwargs)\n\n    # append row by row\n    names = table.dtype.names\n    for row in table:\n        rowd = dict((n, row[n]) for n in names)\n        gps = LIGOTimeGPS(rowd.pop('time', 0))\n        frame.AppendFrEvent(FrEvent(\n            str(name),\n            str(rowd.pop('comment', '')),\n            str(rowd.pop('inputs', '')),\n            GPSTime(gps.gpsSeconds, gps.gpsNanoSeconds),\n            float(rowd.pop('timeBefore', 0)),\n            float(rowd.pop('timeAfter', 0)),\n            int(rowd.pop('eventStatus', 0)),\n            float(rowd.pop('amplitude', 0)),\n            float(rowd.pop('probability', -1)),\n            str(rowd.pop('statistics', '')),\n            list(rowd.items()),  # remaining params as tuple\n        ))\n\n    # write frame to file\n    io_gwf.write_frames(filename, [frame], **write_kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_fetcher(data_format, data_class, function, force=False,\n                     usage=None):\n    \"\"\"Register a new method to EventTable.fetch() for a given format\n\n    Parameters\n    ----------\n    data_format : `str`\n        name of the format to be registered\n\n    data_class : `type`\n        the class that the fetcher returns\n\n    function : `callable`\n        the method to call from :meth:`EventTable.fetch`\n\n    force : `bool`, optional\n        overwrite existing registration for ``data_format`` if found,\n        default: `False`\n    \"\"\"\n    key = (data_format, data_class)\n    if key not in _FETCHERS or force:\n        _FETCHERS[key] = (function, usage)\n    else:\n        raise IORegistryError(\"Fetcher for format '{0}' and class '{1}' \"\n                              \"has already been \" \"defined\".format(\n                                  data_format, data_class))\n    _update__doc__(data_class)", "response": "Register a new method to EventTable. fetch for a given format and class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the fetcher function for the given data_format and data_class.", "response": "def get_fetcher(data_format, data_class):\n    \"\"\"Return the :meth:`~EventTable.fetch` function for the given format\n\n    Parameters\n    ----------\n    data_format : `str`\n        name of the format\n\n    data_class : `type`\n        the class that the fetcher returns\n\n    Raises\n    ------\n    astropy.io.registry.IORegistryError\n        if not registration is found matching ``data_format``\n    \"\"\"\n    # this is a copy of astropy.io.regsitry.get_reader\n    fetchers = [(fmt, cls) for fmt, cls in _FETCHERS if fmt == data_format]\n    for fetch_fmt, fetch_cls in fetchers:\n        if io_registry._is_best_match(data_class, fetch_cls, fetchers):\n            return _FETCHERS[(fetch_fmt, fetch_cls)][0]\n    else:\n        formats = [fmt for fmt, cls in _FETCHERS if\n                   io_registry._is_best_match(fmt, cls, fetchers)]\n        formatstr = '\\n'.join(sorted(formats))\n        raise IORegistryError(\n            \"No fetcher definer for format '{0}' and class '{1}'.\\n\"\n            \"The available formats are:\\n{2}\".format(\n                data_format, data_class.__name__, formatstr))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread data into a frequency series object.", "response": "def read(cls, source, *args, **kwargs):\n        \"\"\"Read data into a `FrequencySeries`\n\n        Arguments and keywords depend on the output format, see the\n        online documentation for full details for each format, the\n        parameters below are common to most formats.\n\n        Parameters\n        ----------\n        source : `str`, `list`\n            Source of data, any of the following:\n\n            - `str` path of single data file,\n            - `str` path of LAL-format cache file,\n            - `list` of paths.\n\n        *args\n            Other arguments are (in general) specific to the given\n            ``format``.\n\n        format : `str`, optional\n            Source format identifier. If not given, the format will be\n            detected if possible. See below for list of acceptable\n            formats.\n\n        **kwargs\n            Other keywords are (in general) specific to the given ``format``.\n\n        Notes\n        -----\"\"\"\n        return io_registry.read(cls, source, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the one - dimensional discrete inverse Fourier transform of this FrequencySeries.", "response": "def ifft(self):\n        \"\"\"Compute the one-dimensional discrete inverse Fourier\n        transform of this `FrequencySeries`.\n\n        Returns\n        -------\n        out : :class:`~gwpy.timeseries.TimeSeries`\n            the normalised, real-valued `TimeSeries`.\n\n        See Also\n        --------\n        :mod:`scipy.fftpack` for the definition of the DFT and conventions\n        used.\n\n        Notes\n        -----\n        This method applies the necessary normalisation such that the\n        condition holds:\n\n        >>> timeseries = TimeSeries([1.0, 0.0, -1.0, 0.0], sample_rate=1.0)\n        >>> timeseries.fft().ifft() == timeseries\n        \"\"\"\n        from ..timeseries import TimeSeries\n        nout = (self.size - 1) * 2\n        # Undo normalization from TimeSeries.fft\n        # The DC component does not have the factor of two applied\n        # so we account for it here\n        dift = npfft.irfft(self.value * nout) / 2\n        new = TimeSeries(dift, epoch=self.epoch, channel=self.channel,\n                         unit=self.unit, dx=1/self.dx/nout)\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interpolate(self, df):\n        f0 = self.f0.decompose().value\n        N = (self.size - 1) * (self.df.decompose().value / df) + 1\n        fsamples = numpy.arange(0, numpy.rint(N), dtype=self.dtype) * df + f0\n        out = type(self)(numpy.interp(fsamples, self.frequencies.value,\n                                      self.value))\n        out.__array_finalize__(self)\n        out.f0 = f0\n        out.df = df\n        return out", "response": "Interpolate this frequency series to a new resolution."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a new frequency series from a LAL FrequencySeries object.", "response": "def from_lal(cls, lalfs, copy=True):\n        \"\"\"Generate a new `FrequencySeries` from a LAL `FrequencySeries` of any type\n        \"\"\"\n        from ..utils.lal import from_lal_unit\n        try:\n            unit = from_lal_unit(lalfs.sampleUnits)\n        except TypeError:\n            unit = None\n        channel = Channel(lalfs.name, unit=unit,\n                          dtype=lalfs.data.data.dtype)\n        return cls(lalfs.data.data, channel=channel, f0=lalfs.f0,\n                   df=lalfs.deltaF, epoch=float(lalfs.epoch),\n                   dtype=lalfs.data.data.dtype, copy=copy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a PyCBC frequency series into a new frequency set.", "response": "def from_pycbc(cls, fs, copy=True):\n        \"\"\"Convert a `pycbc.types.frequencyseries.FrequencySeries` into\n        a `FrequencySeries`\n\n        Parameters\n        ----------\n        fs : `pycbc.types.frequencyseries.FrequencySeries`\n            the input PyCBC `~pycbc.types.frequencyseries.FrequencySeries`\n            array\n\n        copy : `bool`, optional, default: `True`\n            if `True`, copy these data to a new array\n\n        Returns\n        -------\n        spectrum : `FrequencySeries`\n            a GWpy version of the input frequency series\n        \"\"\"\n        return cls(fs.data, f0=0, df=fs.delta_f, epoch=fs.epoch, copy=copy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_pycbc(self, copy=True):\n        from pycbc import types\n\n        if self.epoch is None:\n            epoch = None\n        else:\n            epoch = self.epoch.gps\n        return types.FrequencySeries(self.value,\n                                     delta_f=self.df.to('Hz').value,\n                                     epoch=epoch, copy=copy)", "response": "Convert this FrequencySeries into a PyCBC representation of it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fetch_losc_data_file(url, *args, **kwargs):\n    cls = kwargs.pop('cls', TimeSeries)\n    cache = kwargs.pop('cache', None)\n    verbose = kwargs.pop('verbose', False)\n\n    # match file format\n    if url.endswith('.gz'):\n        ext = os.path.splitext(url[:-3])[-1]\n    else:\n        ext = os.path.splitext(url)[-1]\n    if ext == '.hdf5':\n        kwargs.setdefault('format', 'hdf5.losc')\n    elif ext == '.txt':\n        kwargs.setdefault('format', 'ascii.losc')\n    elif ext == '.gwf':\n        kwargs.setdefault('format', 'gwf')\n\n    with _download_file(url, cache, verbose=verbose) as rem:\n        # get channel for GWF if not given\n        if ext == \".gwf\" and (not args or args[0] is None):\n            args = (_gwf_channel(rem, cls, kwargs.get(\"verbose\")),)\n        if verbose:\n            print('Reading data...', end=' ')\n        try:\n            series = cls.read(rem, *args, **kwargs)\n        except Exception as exc:\n            if verbose:\n                print('')\n            exc.args = (\"Failed to read LOSC data from %r: %s\"\n                        % (url, str(exc)),)\n            raise\n        else:\n            # parse bits from unit in GWF\n            if ext == '.gwf' and isinstance(series, StateVector):\n                try:\n                    bits = {}\n                    for bit in str(series.unit).split():\n                        a, b = bit.split(':', 1)\n                        bits[int(a)] = b\n                    series.bits = bits\n                    series.override_unit('')\n                except (TypeError, ValueError):  # don't care, bad LOSC\n                    pass\n\n            if verbose:\n                print('[Done]')\n            return series", "response": "Internal function for fetching a single LOSC file and returning a Series\nInsights"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _overlapping(files):\n    segments = set()\n    for path in files:\n        seg = file_segment(path)\n        for s in segments:\n            if seg.intersects(s):\n                return True\n        segments.add(seg)\n    return False", "response": "Quick method to see if a file list contains overlapping files\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch LOSC data for a given detector.", "response": "def fetch_losc_data(detector, start, end, cls=TimeSeries, **kwargs):\n    \"\"\"Fetch LOSC data for a given detector\n\n    This function is for internal purposes only, all users should instead\n    use the interface provided by `TimeSeries.fetch_open_data` (and similar\n    for `StateVector.fetch_open_data`).\n    \"\"\"\n    # format arguments\n    start = to_gps(start)\n    end = to_gps(end)\n    span = Segment(start, end)\n    kwargs.update({\n        'start': start,\n        'end': end,\n    })\n\n    # find URLs (requires gwopensci)\n    url_kw = {key: kwargs.pop(key) for key in GWOSC_LOCATE_KWARGS if\n              key in kwargs}\n    if 'sample_rate' in url_kw:  # format as Hertz\n        url_kw['sample_rate'] = Quantity(url_kw['sample_rate'], 'Hz').value\n    cache = get_urls(detector, int(start), int(ceil(end)), **url_kw)\n    # if event dataset, pick shortest file that covers the request\n    # -- this is a bit hacky, and presumes that only an event dataset\n    # -- would be produced with overlapping files.\n    # -- This should probably be improved to use dataset information\n    if len(cache) and _overlapping(cache):\n        cache.sort(key=lambda x: abs(file_segment(x)))\n        for url in cache:\n            a, b = file_segment(url)\n            if a <= start and b >= end:\n                cache = [url]\n                break\n    if kwargs.get('verbose', False):  # get_urls() guarantees len(cache) >= 1\n        host = urlparse(cache[0]).netloc\n        print(\"Fetched {0} URLs from {1} for [{2} .. {3}))\".format(\n            len(cache), host, int(start), int(ceil(end))))\n\n    is_gwf = cache[0].endswith('.gwf')\n    if is_gwf and len(cache):\n        args = (kwargs.pop('channel', None),)\n    else:\n        args = ()\n\n    # read data\n    out = None\n    kwargs['cls'] = cls\n    for url in cache:\n        keep = file_segment(url) & span\n        new = _fetch_losc_data_file(url, *args, **kwargs).crop(\n            *keep, copy=False)\n        if is_gwf and (not args or args[0] is None):\n            args = (new.name,)\n        if out is None:\n            out = new.copy()\n        else:\n            out.append(new, resize=True)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_losc_hdf5(h5f, path='strain/Strain',\n                   start=None, end=None, copy=False):\n    \"\"\"Read a `TimeSeries` from a LOSC-format HDF file.\n\n    Parameters\n    ----------\n    h5f : `str`, `h5py.HLObject`\n        path of HDF5 file, or open `H5File`\n\n    path : `str`\n        name of HDF5 dataset to read.\n\n    Returns\n    -------\n    data : `~gwpy.timeseries.TimeSeries`\n        a new `TimeSeries` containing the data read from disk\n    \"\"\"\n    dataset = io_hdf5.find_dataset(h5f, path)\n    # read data\n    nddata = dataset[()]\n    # read metadata\n    xunit = parse_unit(dataset.attrs['Xunits'])\n    epoch = dataset.attrs['Xstart']\n    dt = Quantity(dataset.attrs['Xspacing'], xunit)\n    unit = dataset.attrs['Yunits']\n    # build and return\n    return TimeSeries(nddata, epoch=epoch, sample_rate=(1/dt).to('Hertz'),\n                      unit=unit, name=path.rsplit('/', 1)[1],\n                      copy=copy).crop(start=start, end=end)", "response": "Read a TimeSeries from a LOSC - format HDF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_losc_hdf5_state(f, path='quality/simple', start=None, end=None,\n                         copy=False):\n    \"\"\"Read a `StateVector` from a LOSC-format HDF file.\n\n    Parameters\n    ----------\n    f : `str`, `h5py.HLObject`\n        path of HDF5 file, or open `H5File`\n\n    path : `str`\n        path of HDF5 dataset to read.\n\n    start : `Time`, `~gwpy.time.LIGOTimeGPS`, optional\n        start GPS time of desired data\n\n    end : `Time`, `~gwpy.time.LIGOTimeGPS`, optional\n        end GPS time of desired data\n\n    copy : `bool`, default: `False`\n        create a fresh-memory copy of the underlying array\n\n    Returns\n    -------\n    data : `~gwpy.timeseries.TimeSeries`\n        a new `TimeSeries` containing the data read from disk\n    \"\"\"\n    # find data\n    dataset = io_hdf5.find_dataset(f, '%s/DQmask' % path)\n    maskset = io_hdf5.find_dataset(f, '%s/DQDescriptions' % path)\n    # read data\n    nddata = dataset[()]\n    bits = [bytes.decode(bytes(b), 'utf-8') for b in maskset[()]]\n    # read metadata\n    epoch = dataset.attrs['Xstart']\n    try:\n        dt = dataset.attrs['Xspacing']\n    except KeyError:\n        dt = Quantity(1, 's')\n    else:\n        xunit = parse_unit(dataset.attrs['Xunits'])\n        dt = Quantity(dt, xunit)\n    return StateVector(nddata, bits=bits, t0=epoch, name='Data quality',\n                       dx=dt, copy=copy).crop(start=start, end=end)", "response": "Read a StateVector from a LOSC - format HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _gwf_channel(path, series_class=TimeSeries, verbose=False):\n    channels = list(io_gwf.iter_channel_names(file_path(path)))\n    if issubclass(series_class, StateVector):\n        regex = DQMASK_CHANNEL_REGEX\n    else:\n        regex = STRAIN_CHANNEL_REGEX\n    found, = list(filter(regex.match, channels))\n    if verbose:\n        print(\"Using channel {0!r}\".format(found))\n    return found", "response": "Find the right channel name for a LOSC GWF file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread segments from a segwizard format file into a SegmentList object.", "response": "def from_segwizard(source, gpstype=LIGOTimeGPS, strict=True):\n    \"\"\"Read segments from a segwizard format file into a `SegmentList`\n\n    Parameters\n    ----------\n    source : `file`, `str`\n        An open file, or file path, from which to read\n\n    gpstype : `type`, optional\n        The numeric type to which to cast times (from `str`) when reading.\n\n    strict : `bool`, optional\n        Check that recorded duration matches ``end-start`` for all segments;\n        only used when reading from a 3+-column file.\n\n    Returns\n    -------\n    segments : `~gwpy.segments.SegmentList`\n        The list of segments as parsed from the file.\n\n    Notes\n    -----\n    This method is adapted from original code written by Kipp Cannon and\n    distributed under GPLv3.\n    \"\"\"\n    # read file path\n    if isinstance(source, string_types):\n        with open(source, 'r') as fobj:\n            return from_segwizard(fobj, gpstype=gpstype, strict=strict)\n\n    # read file object\n    out = SegmentList()\n    fmt_pat = None\n    for line in source:\n        if line.startswith(('#', ';')):  # comment\n            continue\n        # determine line format\n        if fmt_pat is None:\n            fmt_pat = _line_format(line)\n        # parse line\n        tokens, = fmt_pat.findall(line)\n        out.append(_format_segment(tokens[-3:], gpstype=gpstype,\n                                   strict=strict))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _line_format(line):\n    for pat in (FOUR_COL_REGEX, THREE_COL_REGEX, TWO_COL_REGEX):\n        if pat.match(line):\n            return pat\n    raise ValueError(\"unable to parse segment from line {!r}\".format(line))", "response": "Determine the column format pattern for a line in an ASCII segment file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _format_segment(tokens, strict=True, gpstype=LIGOTimeGPS):\n    try:\n        start, end, dur = tokens\n    except ValueError:  # two-columns\n        return Segment(*map(gpstype, tokens))\n    seg = Segment(gpstype(start), gpstype(end))\n    if strict and not float(abs(seg)) == float(dur):\n        raise ValueError(\n            \"segment {0!r} has incorrect duration {1!r}\".format(seg, dur),\n        )\n    return seg", "response": "Format a list of tokens parsed from an ASCII file into a segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_segwizard(segs, target, header=True, coltype=LIGOTimeGPS):\n    # write file path\n    if isinstance(target, string_types):\n        with open(target, 'w') as fobj:\n            return to_segwizard(segs, fobj, header=header, coltype=coltype)\n\n    # write file object\n    if header:\n        print('# seg\\tstart\\tstop\\tduration', file=target)\n    for i, seg in enumerate(segs):\n        a = coltype(seg[0])\n        b = coltype(seg[1])\n        c = float(b - a)\n        print(\n            '\\t'.join(map(str, (i, a, b, c))),\n            file=target,\n        )", "response": "Writes the given list of segments to a file in SegWizard format."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens a file handling optional gzipping", "response": "def gopen(name, *args, **kwargs):\n    \"\"\"Open a file handling optional gzipping\n\n    If ``name`` endswith ``'.gz'``, or if the GZIP file signature is\n    found at the beginning of the file, the file will be opened with\n    `gzip.open`, otherwise a regular file will be returned from `open`.\n\n    Parameters\n    ----------\n    name : `str`\n        path (name) of file to open.\n\n    *args, **kwargs\n        other arguments to pass to either `open` for regular files, or\n        `gzip.open` for gzipped files.\n\n    Returns\n    -------\n    file : `io.TextIoBase`, `file`, `gzip.GzipFile`\n        the open file object\n    \"\"\"\n    # filename declares gzip\n    if name.endswith('.gz'):\n        return gzip.open(name, *args, **kwargs)\n\n    # open regular file\n    fobj = open(name, *args, **kwargs)\n    sig = fobj.read(3)\n    fobj.seek(0)\n    if sig == GZIP_SIGNATURE:  # file signature declares gzip\n        fobj.close()  # GzipFile won't close orig file when it closes\n        return gzip.open(name, *args, **kwargs)\n    return fobj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a number of possible input types into a list of filepaths.", "response": "def file_list(flist):\n    \"\"\"Parse a number of possible input types into a list of filepaths.\n\n    Parameters\n    ----------\n    flist : `file-like` or `list-like` iterable\n        the input data container, normally just a single file path, or a list\n        of paths, but can generally be any of the following\n\n        - `str` representing a single file path (or comma-separated collection)\n        - open `file` or `~gzip.GzipFile` object\n        - :class:`~lal.utils.CacheEntry`\n        - `str` with ``.cache`` or ``.lcf`` extension\n        - simple `list` or `tuple` of `str` paths\n\n    Returns\n    -------\n    files : `list`\n        `list` of `str` file paths\n\n    Raises\n    ------\n    ValueError\n        if the input `flist` cannot be interpreted as any of the above inputs\n    \"\"\"\n    # open a cache file and return list of paths\n    if (isinstance(flist, string_types) and\n            flist.endswith(('.cache', '.lcf', '.ffl'))):\n        from .cache import read_cache\n        return read_cache(flist)\n\n    # separate comma-separate list of names\n    if isinstance(flist, string_types):\n        return flist.split(',')\n\n    # parse list of entries (of some format)\n    if isinstance(flist, (list, tuple)):\n        return list(map(file_path, flist))\n\n    # otherwise parse a single entry\n    try:\n        return [file_path(flist)]\n    except ValueError as exc:\n        exc.args = (\n            \"Could not parse input {!r} as one or more \"\n            \"file-like objects\".format(flist),\n        )\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the path of a file.", "response": "def file_path(fobj):\n    \"\"\"Determine the path of a file.\n\n    This doesn't do any sanity checking to check that the file\n    actually exists, or is readable.\n\n    Parameters\n    ----------\n    fobj : `file`, `str`, `CacheEntry`, ...\n        the file object or path to parse\n\n    Returns\n    -------\n    path : `str`\n        the path of the underlying file\n\n    Raises\n    ------\n    ValueError\n        if a file path cannnot be determined\n\n    Examples\n    --------\n    >>> from gwpy.io.utils import file_path\n    >>> file_path(\"test.txt\")\n    'test.txt'\n    >>> file_path(open(\"test.txt\", \"r\"))\n    'test.txt'\n    >>> file_path(\"file:///home/user/test.txt\")\n    '/home/user/test.txt'\n    \"\"\"\n    if isinstance(fobj, string_types) and fobj.startswith(\"file:\"):\n        return urlparse(fobj).path\n    if isinstance(fobj, string_types):\n        return fobj\n    if (isinstance(fobj, FILE_LIKE) and hasattr(fobj, \"name\")):\n        return fobj.name\n    try:\n        return fobj.path\n    except AttributeError:\n        raise ValueError(\"Cannot parse file name for {!r}\".format(fobj))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate through a Queue call func and put the result in the output Queue", "response": "def process_in_out_queues(func, q_in, q_out):\n    \"\"\"Iterate through a Queue, call, ``func`, and Queue the result\n\n    Parameters\n    ----------\n    func : `callable`\n        any function that can take an element of the input `Queue` as\n        the only argument\n\n    q_in : `multiprocessing.queue.Queue`\n        the input `Queue`\n\n    q_out : `multiprocessing.queue.Queue`\n        the output `Queue`\n\n    Notes\n    -----\n    To close the input `Queue`, add ``(None, None)` as the last item\n    \"\"\"\n    while True:\n        # pick item out of input wqueue\n        idx, arg = q_in.get()\n        if idx is None:  # sentinel\n            break\n        # execute method and put the result in the output queue\n        q_out.put((idx, func(arg)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiprocess_with_queues(nproc, func, inputs, verbose=False,\n                             **progress_kw):\n    \"\"\"Map a function over a list of inputs using multiprocess\n\n    This essentially duplicates `multiprocess.map` but allows for\n    arbitrary functions (that aren't necessarily importable)\n\n    Parameters\n    ----------\n    nproc : `int`\n        number of processes to use, if ``1`` is given, the current process\n        is used, and no child processes are forked\n\n    func : `callable`\n        the function to call in each iteration, should take a single\n        argument that is the next element from ``inputs``\n\n    inputs : `iterable`\n        iterable (e.g. `list`) of inputs, each element of which is\n        passed to ``func`` in one of the child processes\n\n    verbose : `bool`, `str`, optional\n        if `True`, print progress to the console as a bar, pass a\n        `str` to customise the heading for the progress bar, default: `False`,\n        (default heading ``'Processing:'`` if ``verbose=True`)\n\n    Returns\n    -------\n    outputs : `list`\n        the `list` of results from calling ``func(x)`` for each element\n        of ``inputs``\n    \"\"\"\n    if nproc != 1 and os.name == 'nt':\n        warnings.warn(\n            \"multiprocessing is currently not supported on Windows, see \"\n            \"https://github.com/gwpy/gwpy/issues/880, will continue with \"\n            \"serial procesing (nproc=1)\")\n        nproc = 1\n\n    if progress_kw.pop('raise_exceptions', None) is not None:\n        warnings.warn(\"the `raise_exceptions` keyword to \"\n                      \"multiprocess_with_queues is deprecated, and will be \"\n                      \"removed in a future release, all exceptions will be \"\n                      \"raised if they occur\", DeprecationWarning)\n\n    # create progress bar for verbose output\n    if bool(verbose):\n        if not isinstance(verbose, bool):\n            progress_kw['desc'] = str(verbose)\n        if isinstance(inputs, (list, tuple)):\n            progress_kw.setdefault('total', len(inputs))\n        pbar = progress_bar(**progress_kw)\n    else:\n        pbar = None\n\n    # -------------------------------------------\n\n    def _inner(x):\n        \"\"\"Run function capturing errors\n        \"\"\"\n        try:\n            return func(x)\n        except Exception as exc:  # pylint: disable=broad-except\n            if nproc == 1:\n                raise\n            return exc\n        finally:\n            if pbar and nproc == 1:\n                pbar.update()\n\n    # -------------------------------------------\n\n    # shortcut single process\n    if nproc == 1:\n        return list(map(_inner, inputs))\n\n    # -------------------------------------------\n\n    # create input and output queues\n    q_in = Queue()\n    q_out = Queue()\n\n    # create child processes and start\n    proclist = [Process(target=process_in_out_queues,\n                        args=(_inner, q_in, q_out)) for _ in range(nproc)]\n\n    for proc in proclist:\n        proc.daemon = True\n        proc.start()\n\n    # populate queue (no need to block in serial put())\n    sent = [q_in.put(x, block=False) for x in enumerate(inputs)]\n    for _ in range(nproc):  # add sentinel for each process\n        q_in.put((None, None))\n\n    # get results\n    res = []\n    for _ in range(len(sent)):\n        x = q_out.get()\n        if pbar:\n            pbar.update()\n        res.append(x)\n\n    # close processes and unwrap results\n    for proc in proclist:\n        proc.join()\n\n    if pbar:\n        pbar.close()\n\n    # unwrap results in order\n    results = [out for _, out in sorted(res, key=itemgetter(0))]\n\n    # raise exceptions here\n    for res in results:\n        if isinstance(res, Exception):\n            raise res\n\n    return results", "response": "Map a function over a list of inputs using multiprocess."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading the omega scans of the current object.", "response": "def download(self, **kwargs):\n        \"\"\"If table contains Gravity Spy triggers `EventTable`\n\n        Parameters\n        ----------\n        nproc : `int`, optional, default: 1\n            number of CPUs to use for parallel file reading\n\n        download_path : `str` optional, default: 'download'\n            Specify where the images end up.\n\n        download_durs : `list` optional, default: [0.5, 1.0, 2.0, 4.0]\n            Specify exactly which durations you want to download\n            default is to download all the avaialble GSpy durations.\n\n        kwargs: Optional training_set and labelled_samples args\n            that will download images in a special way\n            ./\"ml_label\"/\"sample_type\"/\"image\"\n\n        Returns\n        -------\n        Folder containing omega scans sorted by label\n        \"\"\"\n        from six.moves.urllib.request import urlopen\n        import os\n        # back to pandas\n        try:\n            images_db = self.to_pandas()\n        except ImportError as exc:\n            exc.args = ('pandas is required to download triggers',)\n            raise\n\n        # Remove any broken links\n        images_db = images_db.loc[images_db.url1 != '']\n\n        training_set = kwargs.pop('training_set', 0)\n        labelled_samples = kwargs.pop('labelled_samples', 0)\n        download_location = kwargs.pop('download_path',\n                                       os.path.join('download'))\n        duration_values = np.array([0.5, 1.0, 2.0, 4.0])\n        download_durs = kwargs.pop('download_durs', duration_values)\n\n        duration_idx = []\n        for idur in download_durs:\n            duration_idx.append(np.argwhere(duration_values == idur)[0][0])\n\n        duration_values = duration_values[duration_idx]\n        duration_values = np.array([duration_values]).astype(str)\n\n        # labelled_samples are only available when requesting the\n        if labelled_samples:\n            if 'sample_type' not in images_db.columns:\n                raise ValueError('You have requested ml_labelled Samples '\n                                 'for a Table which does not have '\n                                 'this column. Did you fetch a '\n                                 'trainingset* table?')\n\n        # If someone wants labelled samples they are\n        # Definitely asking for the training set but\n        # may hve forgotten\n        if labelled_samples and not training_set:\n            training_set = 1\n\n        # Let us check what columns are needed\n        cols_for_download = ['url1', 'url2', 'url3', 'url4']\n        cols_for_download = [cols_for_download[idx] for idx in duration_idx]\n        cols_for_download_ext = ['ml_label', 'sample_type',\n                                 'ifo', 'gravityspy_id']\n\n        if not training_set:\n            images_db['ml_label'] = ''\n        if not labelled_samples:\n            images_db['sample_type'] = ''\n\n        if not os.path.isdir(download_location):\n            os.makedirs(download_location)\n\n        if training_set:\n            for ilabel in images_db.ml_label.unique():\n                if labelled_samples:\n                    for itype in images_db.sample_type.unique():\n                        if not os.path.isdir(os.path.join(\n                                             download_location,\n                                             ilabel, itype)):\n                            os.makedirs(os.path.join(download_location,\n                                        ilabel, itype))\n                else:\n                    if not os.path.isdir(os.path.join(download_location,\n                                                      ilabel)):\n                        os.makedirs(os.path.join(download_location,\n                                                 ilabel))\n\n        images_for_download = images_db[cols_for_download]\n        images = images_for_download.as_matrix().flatten()\n        images_for_download_ext = images_db[cols_for_download_ext]\n        duration = np.atleast_2d(\n                                 duration_values.repeat(\n                                   len(images_for_download_ext), 0).flatten(\n                                     )).T\n        images_for_download_ext = images_for_download_ext.as_matrix(\n                                       ).repeat(len(cols_for_download), 0)\n        images_for_for_download_path = np.array([[download_location]]).repeat(\n                                       len(images_for_download_ext), 0)\n        images = np.hstack((np.atleast_2d(images).T,\n                           images_for_download_ext, duration,\n                           images_for_for_download_path))\n\n        def get_image(url):\n            name = url[3] + '_' + url[4] + '_spectrogram_' + url[5] + '.png'\n            outfile = os.path.join(url[6], url[1], url[2], name)\n            with open(outfile, 'wb') as fout:\n                fout.write(urlopen(url[0]).read())\n\n        # calculate maximum number of processes\n        nproc = min(kwargs.pop('nproc', 1), len(images))\n\n        # define multiprocessing method\n        def _download_single_image(url):\n            try:\n                return url, get_image(url)\n            except Exception as exc:  # pylint: disable=broad-except\n                if nproc == 1:\n                    raise\n                else:\n                    return url, exc\n\n        # read files\n        output = mp_utils.multiprocess_with_queues(\n            nproc, _download_single_image, images)\n\n        # raise exceptions (from multiprocessing, single process raises inline)\n        for f, x in output:\n            if isinstance(x, Exception):\n                x.args = ('Failed to read %s: %s' % (f, str(x)),)\n                raise x"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a similar search for a given image and return a dictionary of similar events", "response": "def search(cls, gravityspy_id, howmany=10,\n               era='ALL', ifos='H1L1', remote_timeout=20):\n        \"\"\"perform restful API version of search available here:\n        https://gravityspytools.ciera.northwestern.edu/search/\n\n        Parameters\n        ----------\n        gravityspy_id : `str`,\n            This is the unique 10 character hash that identifies\n            a Gravity Spy Image\n\n        howmany : `int`, optional, default: 10\n            number of similar images you would like\n\n        Returns\n        -------\n        `GravitySpyTable` containing similar events based on\n        an evaluation of the Euclidean distance of the input image\n        to all other images in some Feature Space\n        \"\"\"\n        from astropy.utils.data import get_readable_fileobj\n        import json\n        from six.moves.urllib.error import HTTPError\n        from six.moves import urllib\n\n        # Need to build the url call for the restful API\n        base = 'https://gravityspytools.ciera.northwestern.edu' + \\\n            '/search/similarity_search_restful_API'\n\n        map_era_to_url = {\n            'ALL': \"event_time BETWEEN 1126400000 AND 1229176818\",\n            'O1': \"event_time BETWEEN 1126400000 AND 1137250000\",\n            'ER10': \"event_time BETWEEN 1161907217 AND 1164499217\",\n            'O2a': \"event_time BETWEEN 1164499217 AND 1219276818\",\n            'ER13': \"event_time BETWEEN 1228838418 AND 1229176818\",\n        }\n\n        parts = {\n            'howmany': howmany,\n            'imageid': gravityspy_id,\n            'era': map_era_to_url[era],\n            'ifo': \"{}\".format(\", \".join(\n                map(repr, [ifos[i:i+2] for i in range(0, len(ifos), 2)]),\n             )),\n            'database': 'updated_similarity_index_v2d0',\n        }\n\n        search = urllib.parse.urlencode(parts)\n\n        url = '{}/?{}'.format(base, search)\n\n        try:\n            with get_readable_fileobj(url, remote_timeout=remote_timeout) as f:\n                return GravitySpyTable(json.load(f))\n        except HTTPError as exc:\n            if exc.code == 500:\n                exc.msg += ', confirm the gravityspy_id is valid'\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef epoch(self):\n        try:\n            if self._epoch is None:\n                return None\n            return Time(*modf(self._epoch)[::-1], format='gps', scale='utc')\n        except AttributeError:\n            self._epoch = None\n            return self._epoch", "response": "Returns the time that the data was created for this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef override_unit(self, unit, parse_strict='raise'):\n        self._unit = parse_unit(unit, parse_strict=parse_strict)", "response": "Forcefully reset the unit of the data set to the given value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatten(self, order='C'):\n        return super(Array, self).flatten(order=order).view(Quantity)", "response": "Return a copy of the array collapsed into one dimension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a time - frequency coherence spectrogram from a pair of time - frequency series ts1 and ts2.", "response": "def _from_timeseries(ts1, ts2, stride, fftlength=None, overlap=None,\n                     window=None, **kwargs):\n    \"\"\"Generate a time-frequency coherence\n    :class:`~gwpy.spectrogram.Spectrogram` from a pair of\n    :class:`~gwpy.timeseries.TimeSeries`.\n\n    For each `stride`, a PSD :class:`~gwpy.frequencyseries.FrequencySeries`\n    is generated, with all resulting spectra stacked in time and returned.\n    \"\"\"\n    # check sampling rates\n    if ts1.sample_rate.to('Hertz') != ts2.sample_rate.to('Hertz'):\n        sampling = min(ts1.sample_rate.value, ts2.sample_rate.value)\n        # resample higher rate series\n        if ts1.sample_rate.value == sampling:\n            ts2 = ts2.resample(sampling)\n        else:\n            ts1 = ts1.resample(sampling)\n    else:\n        sampling = ts1.sample_rate.value\n\n    # format FFT parameters\n    if fftlength is None:\n        fftlength = stride\n    if overlap is None:\n        overlap = 0\n\n    nstride = int(stride * sampling)\n\n    # get size of spectrogram\n    nsteps = int(ts1.size // nstride)\n    nfreqs = int(fftlength * sampling // 2 + 1)\n\n    # generate output spectrogram\n    out = Spectrogram(zeros((nsteps, nfreqs)), epoch=ts1.epoch, dt=stride,\n                      f0=0, df=1/fftlength, copy=True, unit='coherence')\n\n    if not nsteps:\n        return out\n\n    # stride through TimeSeries, recording PSDs as columns of spectrogram\n    for step in range(nsteps):\n        # find step TimeSeries\n        idx = nstride * step\n        idx_end = idx + nstride\n        stepseries1 = ts1[idx:idx_end]\n        stepseries2 = ts2[idx:idx_end]\n        stepcoh = stepseries1.coherence(stepseries2, fftlength=fftlength,\n                                        overlap=overlap, window=window,\n                                        **kwargs)\n        out.value[step] = stepcoh.value\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the coherence spectrogram between two time - series.", "response": "def from_timeseries(ts1, ts2, stride, fftlength=None, overlap=None,\n                    window=None, nproc=1, **kwargs):\n    \"\"\"Calculate the coherence `Spectrogram` between two `TimeSeries`.\n\n    Parameters\n    ----------\n    timeseries : :class:`~gwpy.timeseries.TimeSeries`\n        input time-series to process.\n    stride : `float`\n        number of seconds in single PSD (column of spectrogram).\n    fftlength : `float`\n        number of seconds in single FFT.\n    overlap : `int`, optiona, default: fftlength\n        number of seconds of overlap between FFTs, defaults to no overlap\n    window : `timeseries.window.Window`, optional, default: `None`\n        window function to apply to timeseries prior to FFT.\n    nproc : `int`, default: ``1``\n        maximum number of independent frame reading processes, default\n        is set to single-process file reading.\n\n    Returns\n    -------\n    spectrogram : :class:`~gwpy.spectrogram.Spectrogram`\n        time-frequency power spectrogram as generated from the\n        input time-series.\n    \"\"\"\n    # format FFT parameters\n    if fftlength is None:\n        fftlength = stride / 2.\n\n    # get size of spectrogram\n    nsteps = int(ts1.size // (stride * ts1.sample_rate.value))\n    nproc = min(nsteps, nproc)\n\n    # single-process return\n    if nsteps == 0 or nproc == 1:\n        return _from_timeseries(ts1, ts2, stride, fftlength=fftlength,\n                                overlap=overlap, window=window, **kwargs)\n\n    # wrap spectrogram generator\n    def _specgram(queue_, tsa, tsb):\n        try:\n            queue_.put(_from_timeseries(tsa, tsb, stride, fftlength=fftlength,\n                                        overlap=overlap, window=window,\n                                        **kwargs))\n        except Exception as exc:  # pylint: disable=broad-except\n            queue_.put(exc)\n\n    # otherwise build process list\n    stepperproc = int(ceil(nsteps / nproc))\n    nsamp = [stepperproc * ts.sample_rate.value * stride for ts in (ts1, ts2)]\n\n    queue = ProcessQueue(nproc)\n    processlist = []\n    for i in range(nproc):\n        process = Process(target=_specgram,\n                          args=(queue, ts1[i * nsamp[0]:(i + 1) * nsamp[0]],\n                                ts2[i * nsamp[1]:(i + 1) * nsamp[1]]))\n        process.daemon = True\n        processlist.append(process)\n        process.start()\n        if ((i + 1) * nsamp[0]) >= ts1.size:\n            break\n\n    # get data\n    data = []\n    for process in processlist:\n        result = queue.get()\n        if isinstance(result, Exception):\n            raise result\n        else:\n            data.append(result)\n\n    # and block\n    for process in processlist:\n        process.join()\n\n    # format and return\n    out = SpectrogramList(*data)\n    out.sort(key=lambda spec: spec.epoch.gps)\n    return out.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_channel_list_file(*source):\n    # read file(s)\n    config = configparser.ConfigParser(dict_type=OrderedDict)\n    source = file_list(source)\n    success_ = config.read(*source)\n    if len(success_) != len(source):\n        raise IOError(\"Failed to read one or more CLF files\")\n    # create channel list\n    out = ChannelList()\n    out.source = source\n    append = out.append\n    # loop over all groups and channels\n    for group in config.sections():\n        params = OrderedDict(config.items(group))\n        channels = params.pop('channels').strip('\\n').split('\\n')\n        if 'flow' in params or 'fhigh' in params:\n            low = params.pop('flow', 0)\n            high = params.pop('fhigh', inf)\n            if isinstance(high, string_types) and high.lower() == 'nyquist':\n                high = inf\n            frange = float(low), float(high)\n        else:\n            frange = None\n        for channel in channels:\n            try:\n                match = CHANNEL_DEFINITION.match(channel).groupdict()\n            except AttributeError as exc:\n                exc.args = ('Cannot parse %r as channel list entry' % channel,)\n                raise\n            # remove Nones from match\n            match = dict((k, v) for k, v in match.items() if v is not None)\n            match.setdefault('safe', 'safe')\n            match.setdefault('fidelity', 'clean')\n            # create channel and copy group params\n            safe = match.get('safe', 'safe').lower() != 'unsafe'\n            channel = Channel(match.pop('name'), frequency_range=frange,\n                              safe=safe, sample_rate=match.pop('sample_rate'))\n            channel.params = params.copy()\n            channel.params.update(match)\n            channel.group = group\n            # extract those params for which the Channel has an attribute\n            for key in ['frametype']:\n                setattr(channel, key, channel.params.pop(key, None))\n            append(channel)\n    return out", "response": "Read a ~gwpy. detector. ChannelList from a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_channel_list_file(channels, fobj):\n    if not isinstance(fobj, FILE_LIKE):\n        with open(fobj, \"w\") as fobj:\n            return write_channel_list_file(channels, fobj)\n\n    out = configparser.ConfigParser(dict_type=OrderedDict)\n    for channel in channels:\n        group = channel.group\n        if not out.has_section(group):\n            out.add_section(group)\n        for param, value in channel.params.items():\n            out.set(group, param, value)\n        if channel.sample_rate is not None:\n            entry = '%s %s' % (str(channel),\n                               str(channel.sample_rate.to('Hz').value))\n        else:\n            entry = str(channel)\n        entry += ' %s' % channel.params.get('safe', 'safe')\n        entry += ' %s' % channel.params.get('fidelity', 'clean')\n        try:\n            clist = out.get(group, 'channels')\n        except configparser.NoOptionError:\n            out.set(group, 'channels', '\\n%s' % entry)\n        else:\n            out.set(group, 'channels', clist + '\\n%s' % entry)\n\n    out.write(fobj)", "response": "Write a ~gwpy. detector. ChannelList to a INI - format channel list file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_method(func, name=None, deprecated=False):\n    # warn about deprecated functions\n    if deprecated:\n        func = deprecated_function(\n            func,\n            \"the {0!r} PSD methods is deprecated, and will be removed \"\n            \"in a future release, please consider using {1!r} instead\".format(\n                name, name.split('-', 1)[1],\n            ),\n        )\n\n    if name is None:\n        name = func.__name__\n    name = _format_name(name)\n    METHODS[name] = func\n    return name", "response": "Register a function to calculate an average spectrogram."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the PSD method registered with the given name.", "response": "def get_method(name):\n    \"\"\"Return the PSD method registered with the given name.\n    \"\"\"\n    # find method\n    name = _format_name(name)\n    try:\n        return METHODS[name]\n    except KeyError as exc:\n        exc.args = (\"no PSD method registered with name {0!r}\".format(name),)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inspiral_range_psd(psd, snr=8, mass1=1.4, mass2=1.4, horizon=False):\n    # compute chirp mass and symmetric mass ratio\n    mass1 = units.Quantity(mass1, 'solMass').to('kg')\n    mass2 = units.Quantity(mass2, 'solMass').to('kg')\n    mtotal = mass1 + mass2\n    mchirp = (mass1 * mass2) ** (3/5.) / mtotal ** (1/5.)\n\n    # compute ISCO\n    fisco = (constants.c ** 3 / (constants.G * 6**1.5 * pi * mtotal)).to('Hz')\n\n    # calculate integral pre-factor\n    prefactor = (\n        (1.77**2 * 5 * constants.c ** (1/3.) *\n         (mchirp * constants.G / constants.c ** 2) ** (5/3.)) /\n        (96 * pi ** (4/3.) * snr ** 2)\n    )\n\n    # calculate inspiral range ASD in m^2/Hz\n    integrand = 1 / psd * psd.frequencies ** (-7/3.) * prefactor\n\n    # restrict to ISCO\n    integrand = integrand[psd.frequencies.value < fisco.value]\n\n    # normalize and return\n    if integrand.f0.value == 0.0:\n        integrand[0] = 0.0\n    if horizon:\n        integrand *= 2.26 ** 2\n    return integrand.to('Mpc^2 / Hz')", "response": "Compute the inspiral sensitive distance PSD from a GW strain PSD."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inspiral_range(psd, snr=8, mass1=1.4, mass2=1.4, fmin=None, fmax=None,\n                   horizon=False):\n    \"\"\"Calculate the inspiral sensitive distance from a GW strain PSD\n\n    The method returns the distance (in megaparsecs) to which an compact\n    binary inspiral with the given component masses would be detectable\n    given the instrumental PSD. The calculation is as defined in:\n\n    https://dcc.ligo.org/LIGO-T030276/public\n\n    Parameters\n    ----------\n    psd : `~gwpy.frequencyseries.FrequencySeries`\n        the instrumental power-spectral-density data\n\n    snr : `float`, optional\n        the signal-to-noise ratio for which to calculate range,\n        default: `8`\n\n    mass1 : `float`, `~astropy.units.Quantity`, optional\n        the mass (`float` assumed in solar masses) of the first binary\n        component, default: `1.4`\n\n    mass2 : `float`, `~astropy.units.Quantity`, optional\n        the mass (`float` assumed in solar masses) of the second binary\n        component, default: `1.4`\n\n    fmin : `float`, optional\n        the lower frequency cut-off of the integral, default: `psd.df`\n\n    fmax : `float`, optional\n        the maximum frequency limit of the integral, defaults to\n        innermost stable circular orbit (ISCO) frequency\n\n    horizon : `bool`, optional\n        if `True`, return the maximal 'horizon' sensitive distance, otherwise\n        return the angle-averaged range, default: `False`\n\n    Returns\n    -------\n    range : `~astropy.units.Quantity`\n        the calculated inspiral range [Mpc]\n\n    Examples\n    --------\n    Grab some data for LIGO-Livingston around GW150914 and generate a PSD\n\n    >>> from gwpy.timeseries import TimeSeries\n    >>> hoft = TimeSeries.fetch_open_data('H1', 1126259446, 1126259478)\n    >>> hoff = hoft.psd(fftlength=4)\n\n    Now we can calculate the :func:`inspiral_range`:\n\n    >>> from gwpy.astro import inspiral_range\n    >>> r = inspiral_range(hoff, fmin=30)\n    >>> print(r)\n    70.4612102889 Mpc\n    \"\"\"\n    mass1 = units.Quantity(mass1, 'solMass').to('kg')\n    mass2 = units.Quantity(mass2, 'solMass').to('kg')\n    mtotal = mass1 + mass2\n\n    # compute ISCO\n    fisco = (constants.c ** 3 / (constants.G * 6**1.5 * pi * mtotal)).to('Hz')\n\n    # format frequency limits\n    fmax = units.Quantity(fmax or fisco, 'Hz')\n    if fmax > fisco:\n        warnings.warn(\"Upper frequency bound greater than %s-%s ISCO \"\n                      \"frequency of %s, using ISCO\" % (mass1, mass2, fisco))\n        fmax = fisco\n    if fmin is None:\n        fmin = psd.df  # avoid using 0 as lower limit\n    fmin = units.Quantity(fmin, 'Hz')\n\n    # integrate\n    f = psd.frequencies.to('Hz')\n    condition = (f >= fmin) & (f < fmax)\n    integrand = inspiral_range_psd(psd[condition], snr=snr, mass1=mass1,\n                                   mass2=mass2, horizon=horizon)\n    result = units.Quantity(\n        integrate.trapz(integrand.value, f.value[condition]),\n        unit=integrand.unit * units.Hertz)\n\n    return (result ** (1/2.)).to('Mpc')", "response": "Calculate the inspiral sensitive distance from a GW strain PSD"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the frequency - dependent GW burst range from a strain PSD", "response": "def burst_range_spectrum(psd, snr=8, energy=1e-2):\n    \"\"\"Calculate the frequency-dependent GW burst range from a strain PSD\n\n    Parameters\n    ----------\n    psd : `~gwpy.frequencyseries.FrequencySeries`\n        the instrumental power-spectral-density data\n\n    snr : `float`, optional\n        the signal-to-noise ratio for which to calculate range,\n        default: `8`\n\n    energy : `float`, optional\n        the relative energy output of the GW burst,\n        default: `0.01` (GRB-like burst)\n\n    Returns\n    -------\n    rangespec : `~gwpy.frequencyseries.FrequencySeries`\n        the burst range `FrequencySeries` [Mpc (default)]\n    \"\"\"\n    # calculate frequency dependent range in parsecs\n    a = (constants.G * energy * constants.M_sun * 0.4 /\n         (pi**2 * constants.c))**(1/2.)\n    dspec = psd ** (-1/2.) * a / (snr * psd.frequencies)\n\n    # convert to output unit\n    rspec = dspec.to('Mpc')\n\n    # rescale 0 Hertz (which has 0 range always)\n    if rspec.f0.value == 0.0:\n        rspec[0] = 0.0\n\n    return rspec"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the integrated GRB - like GW burst range from a strain PSD.", "response": "def burst_range(psd, snr=8, energy=1e-2, fmin=100, fmax=500):\n    \"\"\"Calculate the integrated GRB-like GW burst range from a strain PSD\n\n    Parameters\n    ----------\n    psd : `~gwpy.frequencyseries.FrequencySeries`\n        the instrumental power-spectral-density data\n\n    snr : `float`, optional\n        the signal-to-noise ratio for which to calculate range,\n        default: ``8``\n\n    energy : `float`, optional\n        the relative energy output of the GW burst, defaults to ``1e-2``\n        for a GRB-like burst\n\n    fmin : `float`, optional\n        the lower frequency cutoff of the burst range integral,\n        default: ``100 Hz``\n\n    fmax : `float`, optional\n        the upper frequency cutoff of the burst range integral,\n        default: ``500 Hz``\n\n    Returns\n    -------\n    range : `~astropy.units.Quantity`\n        the GRB-like-burst sensitive range [Mpc (default)]\n\n    Examples\n    --------\n    Grab some data for LIGO-Livingston around GW150914 and generate a PSD\n\n    >>> from gwpy.timeseries import TimeSeries\n    >>> hoft = TimeSeries.fetch_open_data('H1', 1126259446, 1126259478)\n    >>> hoff = hoft.psd(fftlength=4)\n\n    Now we can calculate the :func:`burst_range`:\n\n    >>> from gwpy.astro import burst_range\n    >>> r = burst_range(hoff, fmin=30)\n    >>> print(r)\n    42.5055584195 Mpc\n    \"\"\"\n    freqs = psd.frequencies.value\n    # restrict integral\n    if not fmin:\n        fmin = psd.f0\n    if not fmax:\n        fmax = psd.span[1]\n    condition = (freqs >= fmin) & (freqs < fmax)\n    # calculate integrand and integrate\n    integrand = burst_range_spectrum(\n        psd[condition], snr=snr, energy=energy) ** 3\n    result = integrate.trapz(integrand.value, freqs[condition])\n    # normalize and return\n    r = units.Quantity(result / (fmax - fmin), unit=integrand.unit) ** (1/3.)\n    return r.to('Mpc')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntint a color returning a new RGB array", "response": "def tint(col, factor=1.0):\n    \"\"\"Tint a color (make it darker), returning a new RGB array\n    \"\"\"\n    # this method is more complicated than it need be to\n    # support matplotlib-1.x.\n    # for matplotlib-2.x this would just be\n    #     h, s, v = colors.rgb_to_hsv(colors.to_rgb(c))\n    #     v *= factor\n    #     return colors.hsv_to_rgb((h, s, v))\n    rgb = numpy.array(to_rgb(col), ndmin=3)\n    hsv = colors.rgb_to_hsv(rgb)\n    hsv[-1][-1][2] *= factor\n    return colors.hsv_to_rgb(hsv)[-1][-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat a ~matplotlib. colors. Normalize instance from a set of kwargs.", "response": "def format_norm(kwargs, current=None):\n    \"\"\"Format a `~matplotlib.colors.Normalize` from a set of kwargs\n\n    Returns\n    -------\n    norm, kwargs\n        the formatted `Normalize` instance, and the remaining keywords\n    \"\"\"\n    norm = kwargs.pop('norm', current) or 'linear'\n    vmin = kwargs.pop('vmin', None)\n    vmax = kwargs.pop('vmax', None)\n    clim = kwargs.pop('clim', (vmin, vmax)) or (None, None)\n    clip = kwargs.pop('clip', None)\n\n    if norm == 'linear':\n        norm = colors.Normalize()\n    elif norm == 'log':\n        norm = colors.LogNorm()\n    elif not isinstance(norm, colors.Normalize):\n        raise ValueError(\"unrecognised value for norm {!r}\".format(norm))\n\n    for attr, value in (('vmin', clim[0]), ('vmax', clim[1]), ('clip', clip)):\n        if value is not None:\n            setattr(norm, attr, value)\n\n    return norm, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nidentify a filename or file object as GWF", "response": "def identify_gwf(origin, filepath, fileobj, *args, **kwargs):\n    \"\"\"Identify a filename or file object as GWF\n\n    This function is overloaded in that it will also identify a cache file\n    as 'gwf' if the first entry in the cache contains a GWF file extension\n    \"\"\"\n    # pylint: disable=unused-argument\n\n    # try and read file descriptor\n    if fileobj is not None:\n        loc = fileobj.tell()\n        fileobj.seek(0)\n        try:\n            if fileobj.read(4) == GWF_SIGNATURE:\n                return True\n        finally:\n            fileobj.seek(loc)\n    if filepath is not None:\n        if filepath.endswith('.gwf'):\n            return True\n        if filepath.endswith(('.lcf', '.cache')):\n            try:\n                cache = read_cache(filepath)\n            except IOError:\n                return False\n            else:\n                if cache[0].path.endswith('.gwf'):\n                    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_gwf(filename, mode='r'):\n    if mode not in ('r', 'w'):\n        raise ValueError(\"mode must be either 'r' or 'w'\")\n    from LDAStools import frameCPP\n    filename = urlparse(filename).path  # strip file://localhost or similar\n    if mode == 'r':\n        return frameCPP.IFrameFStream(str(filename))\n    return frameCPP.OFrameFStream(str(filename))", "response": "Open a filename for reading or writing GWF format data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a list of frame objects to a file in a single node of the tree.", "response": "def write_frames(filename, frames, compression=257, compression_level=6):\n    \"\"\"Write a list of frame objects to a file\n\n    **Requires:** |LDAStools.frameCPP|_\n\n    Parameters\n    ----------\n    filename : `str`\n        path to write into\n\n    frames : `list` of `LDAStools.frameCPP.FrameH`\n        list of frames to write into file\n\n    compression : `int`, optional\n        enum value for compression scheme, default is ``GZIP``\n\n    compression_level : `int`, optional\n        compression level for given scheme\n    \"\"\"\n    from LDAStools import frameCPP\n\n    # open stream\n    stream = open_gwf(filename, 'w')\n\n    # write frames one-by-one\n    if isinstance(frames, frameCPP.FrameH):\n        frames = [frames]\n    for frame in frames:\n        stream.WriteFrame(frame, compression, compression_level)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new frame header that is a new one with the specified parameters.", "response": "def create_frame(time=0, duration=None, name='gwpy', run=-1, ifos=None):\n    \"\"\"Create a new :class:`~LDAStools.frameCPP.FrameH`\n\n    **Requires:** |LDAStools.frameCPP|_\n\n    Parameters\n    ----------\n    time : `float`, optional\n        frame start time in GPS seconds\n\n    duration : `float`, optional\n        frame length in seconds\n\n    name : `str`, optional\n        name of project or other experiment description\n\n    run : `int`, optional\n        run number (number < 0 reserved for simulated data); monotonic for\n        experimental runs\n\n    ifos : `list`, optional\n        list of interferometer prefices (e.g. ``'L1'``) associated with this\n        frame\n\n    Returns\n    -------\n    frame : :class:`~LDAStools.frameCPP.FrameH`\n        the newly created frame header\n    \"\"\"\n    from LDAStools import frameCPP\n\n    # create frame\n    frame = frameCPP.FrameH()\n\n    # add timing\n    gps = to_gps(time)\n    gps = frameCPP.GPSTime(gps.gpsSeconds, gps.gpsNanoSeconds)\n    frame.SetGTime(gps)\n    if duration is not None:\n        frame.SetDt(float(duration))\n\n    # add FrDetectors\n    for prefix in ifos or []:\n        idx = getattr(frameCPP, 'DETECTOR_LOCATION_%s' % prefix)\n        frame.AppendFrDetector(frameCPP.GetDetector(idx, gps))\n\n    # add descriptions\n    frame.SetName(name)\n    frame.SetRun(run)\n\n    return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the type of a given channel in a given GWF file.", "response": "def get_channel_type(channel, framefile):\n    \"\"\"Find the channel type in a given GWF file\n\n    **Requires:** |LDAStools.frameCPP|_\n\n    Parameters\n    ----------\n    channel : `str`, `~gwpy.detector.Channel`\n        name of data channel to find\n\n    framefile : `str`\n        path of GWF file in which to search\n\n    Returns\n    -------\n    ctype : `str`\n        the type of the channel ('adc', 'sim', or 'proc')\n\n    Raises\n    ------\n    ValueError\n        if the channel is not found in the table-of-contents\n    \"\"\"\n    channel = str(channel)\n    for name, type_ in _iter_channels(framefile):\n        if channel == name:\n            return type_\n    raise ValueError(\"%s not found in table-of-contents for %s\"\n                     % (channel, framefile))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines whether a channel is stored in this framefile", "response": "def channel_in_frame(channel, framefile):\n    \"\"\"Determine whether a channel is stored in this framefile\n\n    **Requires:** |LDAStools.frameCPP|_\n\n    Parameters\n    ----------\n    channel : `str`\n        name of channel to find\n\n    framefile : `str`\n        path of GWF file to test\n\n    Returns\n    -------\n    inframe : `bool`\n        whether this channel is included in the table of contents for\n        the given framefile\n    \"\"\"\n    channel = str(channel)\n    for name in iter_channel_names(framefile):\n        if channel == name:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _iter_channels(framefile):\n    from LDAStools import frameCPP\n    if not isinstance(framefile, frameCPP.IFrameFStream):\n        framefile = open_gwf(framefile, 'r')\n    toc = framefile.GetTOC()\n    for typename in ('Sim', 'Proc', 'ADC'):\n        typen = typename.lower()\n        for name in getattr(toc, 'Get{0}'.format(typename))():\n            yield name, typen", "response": "Yields the name and type of each channel in a GWF file TOC\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of segments containing data for a given channel in a single frame.", "response": "def data_segments(paths, channel, warn=True):\n    \"\"\"Returns the segments containing data for a channel\n\n    **Requires:** |LDAStools.frameCPP|_\n\n    A frame is considered to contain data if a valid FrData structure\n    (of any type) exists for the channel in that frame.  No checks\n    are directly made against the underlying FrVect structures.\n\n    Parameters\n    ----------\n    paths : `list` of `str`\n        a list of GWF file paths\n\n    channel : `str`\n        the name to check in each frame\n\n    warn : `bool`, optional\n        emit a `UserWarning` when a channel is not found in a frame\n\n    Returns\n    -------\n    segments : `~gwpy.segments.SegmentList`\n        the list of segments containing data\n    \"\"\"\n    segments = SegmentList()\n    for path in paths:\n        segments.extend(_gwf_channel_segments(path, channel, warn=warn))\n    return segments.coalesce()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding the segments containing data for a given channel in this GWF path.", "response": "def _gwf_channel_segments(path, channel, warn=True):\n    \"\"\"Yields the segments containing data for ``channel`` in this GWF path\n    \"\"\"\n    stream = open_gwf(path)\n    # get segments for frames\n    toc = stream.GetTOC()\n    secs = toc.GetGTimeS()\n    nano = toc.GetGTimeN()\n    dur = toc.GetDt()\n\n    readers = [getattr(stream, 'ReadFr{0}Data'.format(type_.title())) for\n               type_ in (\"proc\", \"sim\", \"adc\")]\n\n    # for each segment, try and read the data for this channel\n    for i, (s, ns, dt) in enumerate(zip(secs, nano, dur)):\n        for read in readers:\n            try:\n                read(i, channel)\n            except (IndexError, ValueError):\n                continue\n            readers = [read]  # use this one from now on\n            epoch = LIGOTimeGPS(s, ns)\n            yield Segment(epoch, epoch + dt)\n            break\n        else:  # none of the readers worked for this channel, warn\n            if warn:\n                warnings.warn(\n                    \"{0!r} not found in frame {1} of {2}\".format(\n                        channel, i, path),\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fdfilter(data, *filt, **kwargs):\n    # parse keyword args\n    inplace = kwargs.pop('inplace', False)\n    analog = kwargs.pop('analog', False)\n    fs = kwargs.pop('sample_rate', None)\n    if kwargs:\n        raise TypeError(\"filter() got an unexpected keyword argument '%s'\"\n                        % list(kwargs.keys())[0])\n\n    # parse filter\n    if fs is None:\n        fs = 2 * (data.shape[-1] * data.df).to('Hz').value\n    form, filt = parse_filter(filt, analog=analog, sample_rate=fs)\n    lti = signal.lti(*filt)\n\n    # generate frequency response\n    freqs = data.frequencies.value.copy()\n    fresp = numpy.nan_to_num(abs(lti.freqresp(w=freqs)[1]))\n\n    # apply to array\n    if inplace:\n        data *= fresp\n        return data\n    new = data * fresp\n    return new", "response": "Filter a frequency - domain data object by a frequency - domain filter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse command - line arguments tconvert inputs and print", "response": "def main(args=None):\n    \"\"\"Parse command-line arguments, tconvert inputs, and print\n    \"\"\"\n    # define command line arguments\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"-V\", \"--version\", action=\"version\",\n                        version=__version__,\n                        help=\"show version number and exit\")\n    parser.add_argument(\"-l\", \"--local\", action=\"store_true\", default=False,\n                        help=\"print datetimes in local timezone\")\n    parser.add_argument(\"-f\", \"--format\", type=str, action=\"store\",\n                        default=r\"%Y-%m-%d %H:%M:%S.%f %Z\",\n                        help=\"output datetime format (default: %(default)r)\")\n    parser.add_argument(\"input\", help=\"GPS or datetime string to convert\",\n                        nargs=\"*\")\n\n    # parse and convert\n    args = parser.parse_args(args)\n    input_ = \" \".join(args.input)\n    output = tconvert(input_)\n\n    # print (now with timezones!)\n    if isinstance(output, datetime.datetime):\n        output = output.replace(tzinfo=tz.tzutc())\n        if args.local:\n            output = output.astimezone(tz.tzlocal())\n        print(output.strftime(args.format))\n    else:\n        print(output)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntiming a method and print its duration after return", "response": "def timer(func):\n    \"\"\"Time a method and print its duration after return\n    \"\"\"\n    name = func.__name__\n\n    @wraps(func)\n    def timed_func(self, *args, **kwargs):  # pylint: disable=missing-docstring\n        _start = time.time()\n        out = func(self, *args, **kwargs)\n        self.log(2, '{0} took {1:.1f} sec'.format(name, time.time() - _start))\n        return out\n\n    return timed_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_float(unit):\n    def converter(x):\n        \"\"\"Convert the input to a `float` in %s\n        \"\"\"\n        return Quantity(x, unit).value\n\n    converter.__doc__ %= str(unit)  # pylint: disable=no-member\n    return converter", "response": "Factory to convert a quantity string to float"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log_norm(func):\n    @wraps(func)\n    def decorated_func(*args, **kwargs):\n        norm, kwargs = format_norm(kwargs)\n        kwargs['norm'] = norm\n        return func(*args, **kwargs)\n    return decorated_func", "response": "Wrap a function to handle custom gwpy keywords for a LogNorm colouring\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps func to handle pass limit inputs through gwpy. time. to_gps", "response": "def xlim_as_gps(func):\n    \"\"\"Wrap ``func`` to handle pass limit inputs through `gwpy.time.to_gps`\n    \"\"\"\n    @wraps(func)\n    def wrapped_func(self, left=None, right=None, **kw):\n        if right is None and numpy.iterable(left):\n            left, right = left\n        kw['left'] = left\n        kw['right'] = right\n        gpsscale = self.get_xscale() in GPS_SCALES\n        for key in ('left', 'right'):\n            if gpsscale:\n                try:\n                    kw[key] = numpy.longdouble(str(to_gps(kw[key])))\n                except TypeError:\n                    pass\n        return func(self, **kw)\n    return wrapped_func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore_grid(func):\n    @wraps(func)\n    def wrapped_func(self, *args, **kwargs):\n        grid = (self.xaxis._gridOnMinor, self.xaxis._gridOnMajor,\n                self.yaxis._gridOnMinor, self.yaxis._gridOnMajor)\n        try:\n            return func(self, *args, **kwargs)\n        finally:\n            # reset grid\n            self.xaxis.grid(grid[0], which=\"minor\")\n            self.xaxis.grid(grid[1], which=\"major\")\n            self.yaxis.grid(grid[2], which=\"minor\")\n            self.yaxis.grid(grid[3], which=\"major\")\n    return wrapped_func", "response": "Wrap func to restore the Axes current grid settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_epoch(self, epoch):\n        scale = self.get_xscale()\n        return self.set_xscale(scale, epoch=epoch)", "response": "Set the epoch for the current GPS scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imshow(self, array, *args, **kwargs):\n        if isinstance(array, Array2D):\n            return self._imshow_array2d(array, *args, **kwargs)\n\n        image = super(Axes, self).imshow(array, *args, **kwargs)\n        self.autoscale(enable=None, axis='both', tight=None)\n        return image", "response": "Display an image i. e. data on a 2D regular raster."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _imshow_array2d(self, array, origin='lower', interpolation='none',\n                        aspect='auto', **kwargs):\n        \"\"\"Render an `~gwpy.types.Array2D` using `Axes.imshow`\n        \"\"\"\n        # NOTE: If you change the defaults for this method, please update\n        #       the docstring for `imshow` above.\n\n        # calculate extent\n        extent = tuple(array.xspan) + tuple(array.yspan)\n        if self.get_xscale() == 'log' and extent[0] == 0.:\n            extent = (1e-300,) + extent[1:]\n        if self.get_yscale() == 'log' and extent[2] == 0.:\n            extent = extent[:2] + (1e-300,) + extent[3:]\n        kwargs.setdefault('extent', extent)\n\n        return self.imshow(array.value.T, origin=origin, aspect=aspect,\n                           interpolation=interpolation, **kwargs)", "response": "Render an ~gwpy. types. Array2D using Axes. imshow"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a pseudocolor plot with a non - regular rectangular grid.", "response": "def pcolormesh(self, *args, **kwargs):\n        \"\"\"Create a pseudocolor plot with a non-regular rectangular grid.\n\n        When using GWpy, this method can be called with a single argument\n        that is an :class:`~gwpy.types.Array2D`, for which the ``X`` and ``Y``\n        coordinate arrays will be determined from the indexing.\n\n        In all other usage, all ``args`` and ``kwargs`` are passed directly\n        to :meth:`~matplotlib.axes.Axes.pcolormesh`.\n\n        Notes\n        -----\n        Unlike the upstream :meth:`matplotlib.axes.Axes.pcolormesh`,\n        this method respects the current grid settings.\n\n        See Also\n        --------\n        matplotlib.axes.Axes.pcolormesh\n        \"\"\"\n        if len(args) == 1 and isinstance(args[0], Array2D):\n            return self._pcolormesh_array2d(*args, **kwargs)\n        return super(Axes, self).pcolormesh(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering an ~gwpy. types. Array2D using Axes. pcolormesh", "response": "def _pcolormesh_array2d(self, array, *args, **kwargs):\n        \"\"\"Render an `~gwpy.types.Array2D` using `Axes.pcolormesh`\n        \"\"\"\n        x = numpy.concatenate((array.xindex.value, array.xspan[-1:]))\n        y = numpy.concatenate((array.yindex.value, array.yspan[-1:]))\n        xcoord, ycoord = numpy.meshgrid(x, y, copy=False, sparse=True)\n        return self.pcolormesh(xcoord, ycoord, array.value.T, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_mmm(self, data, lower=None, upper=None, **kwargs):\n        alpha = kwargs.pop('alpha', .1)\n\n        # plot mean\n        line, = self.plot(data, **kwargs)\n        out = [line]\n\n        # modify keywords for shading\n        kwargs.update({\n            'label': '',\n            'linewidth': line.get_linewidth() / 2,\n            'color': line.get_color(),\n            'alpha': alpha * 2,\n        })\n\n        # plot lower and upper Series\n        fill = [data.xindex.value, data.value, data.value]\n        for i, bound in enumerate((lower, upper)):\n            if bound is not None:\n                out.extend(self.plot(bound, **kwargs))\n                fill[i+1] = bound.value\n\n        # fill between\n        out.append(self.fill_between(\n            *fill, alpha=alpha, color=kwargs['color'],\n            rasterized=kwargs.get('rasterized', True)))\n\n        return out", "response": "Plot a series as a line with a shaded region around it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tile(self, x, y, w, h, color=None,\n             anchor='center', edgecolors='face', linewidth=0.8,\n             **kwargs):\n        \"\"\"Plot rectanguler tiles based onto these `Axes`.\n\n        ``x`` and ``y`` give the anchor point for each tile, with\n        ``w`` and ``h`` giving the extent in the X and Y axis respectively.\n\n        Parameters\n        ----------\n        x, y, w, h : `array_like`, shape (n, )\n            Input data\n\n        color : `array_like`, shape (n, )\n            Array of amplitudes for tile color\n\n        anchor : `str`, optional\n            Anchor point for tiles relative to ``(x, y)`` coordinates, one of\n\n            - ``'center'`` - center tile on ``(x, y)``\n            - ``'ll'`` - ``(x, y)`` defines lower-left corner of tile\n            - ``'lr'`` - ``(x, y)`` defines lower-right corner of tile\n            - ``'ul'`` - ``(x, y)`` defines upper-left corner of tile\n            - ``'ur'`` - ``(x, y)`` defines upper-right corner of tile\n\n        **kwargs\n            Other keywords are passed to\n            :meth:`~matplotlib.collections.PolyCollection`\n\n        Returns\n        -------\n        collection : `~matplotlib.collections.PolyCollection`\n            the collection of tiles drawn\n\n        Examples\n        --------\n        >>> import numpy\n        >>> from matplotlib import pyplot\n        >>> import gwpy.plot  # to get gwpy's Axes\n\n        >>> x = numpy.arange(10)\n        >>> y = numpy.arange(x.size)\n        >>> w = numpy.ones_like(x) * .8\n        >>> h = numpy.ones_like(x) * .8\n\n        >>> fig = pyplot.figure()\n        >>> ax = fig.gca()\n        >>> ax.tile(x, y, w, h, anchor='ll')\n        >>> pyplot.show()\n        \"\"\"\n        # get color and sort\n        if color is not None and kwargs.get('c_sort', True):\n            sortidx = color.argsort()\n            x = x[sortidx]\n            y = y[sortidx]\n            w = w[sortidx]\n            h = h[sortidx]\n            color = color[sortidx]\n\n        # define how to make a polygon for each tile\n        if anchor == 'll':\n            def _poly(x, y, w, h):\n                return ((x, y), (x, y+h), (x+w, y+h), (x+w, y))\n        elif anchor == 'lr':\n            def _poly(x, y, w, h):\n                return ((x-w, y), (x-w, y+h), (x, y+h), (x, y))\n        elif anchor == 'ul':\n            def _poly(x, y, w, h):\n                return ((x, y-h), (x, y), (x+w, y), (x+w, y-h))\n        elif anchor == 'ur':\n            def _poly(x, y, w, h):\n                return ((x-w, y-h), (x-w, y), (x, y), (x, y-h))\n        elif anchor == 'center':\n            def _poly(x, y, w, h):\n                return ((x-w/2., y-h/2.), (x-w/2., y+h/2.),\n                        (x+w/2., y+h/2.), (x+w/2., y-h/2.))\n        else:\n            raise ValueError(\"Unrecognised tile anchor {!r}\".format(anchor))\n\n        # build collection\n        cmap = kwargs.pop('cmap', rcParams['image.cmap'])\n        coll = PolyCollection((_poly(*tile) for tile in zip(x, y, w, h)),\n                              edgecolors=edgecolors, linewidth=linewidth,\n                              **kwargs)\n        if color is not None:\n            coll.set_array(color)\n            coll.set_cmap(cmap)\n\n        out = self.add_collection(coll)\n        self.autoscale_view()\n        return out", "response": "Plot rectanguler tiles based onto these axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef colorbar(self, mappable=None, **kwargs):\n        fig = self.get_figure()\n        if kwargs.get('use_axesgrid', True):\n            kwargs.setdefault('fraction', 0.)\n        if kwargs.get('fraction', 0.) == 0.:\n            kwargs.setdefault('use_axesgrid', True)\n        mappable, kwargs = gcbar.process_colorbar_kwargs(\n            fig, mappable=mappable, ax=self, **kwargs)\n        if isinstance(fig, Plot):\n            # either we have created colorbar Axes using axesgrid1, or\n            # the user already gave use_axesgrid=False, so we forcefully\n            # disable axesgrid here in case fraction == 0., which causes\n            # gridspec colorbars to fail.\n            kwargs['use_axesgrid'] = False\n        return fig.colorbar(mappable, **kwargs)", "response": "Add a colorbar to these axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tconvert(gpsordate='now'):\n    # convert from GPS into datetime\n    try:\n        float(gpsordate)  # if we can 'float' it, then its probably a GPS time\n    except (TypeError, ValueError):\n        return to_gps(gpsordate)\n    return from_gps(gpsordate)", "response": "Convert GPS times to ISO - format date - times and vice - versa."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_gps(t, *args, **kwargs):\n    # -- convert input to Time, or something we can pass to LIGOTimeGPS\n\n    if isinstance(t, string_types):\n        try:  # if str represents a number, leave it for LIGOTimeGPS to handle\n            float(t)\n        except ValueError:  # str -> datetime.datetime\n            t = _str_to_datetime(t)\n\n    # tuple -> datetime.datetime\n    if isinstance(t, (tuple, list)):\n        t = datetime.datetime(*t)\n\n    # datetime.datetime -> Time\n    if isinstance(t, datetime.date):\n        t = _datetime_to_time(t)\n\n    # Quantity -> float\n    if isinstance(t, Quantity):\n        t = t.to('second').value\n\n    # Number/Decimal -> str\n    if isinstance(t, Decimal):\n        t = str(t)\n    if isinstance(t, Number):\n        # note, on python < 3, str(<float>) isn't very good, so we use repr\n        # for python > 3 we can just use str for both Decimal and Number\n        t = repr(t)\n\n    # -- convert to LIGOTimeGPS\n\n    if isinstance(t, Time):\n        return _time_to_gps(t, *args, **kwargs)\n    try:\n        return LIGOTimeGPS(t)\n    except (TypeError, ValueError):\n        return LIGOTimeGPS(float(t))", "response": "Convert any input date or time into a LIGOTimeGPS."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_gps(gps):\n    try:\n        gps = LIGOTimeGPS(gps)\n    except (ValueError, TypeError, RuntimeError):\n        gps = LIGOTimeGPS(float(gps))\n    sec, nano = gps.gpsSeconds, gps.gpsNanoSeconds\n    date = Time(sec, format='gps', scale='utc').datetime\n    return date + datetime.timedelta(microseconds=nano*1e-3)", "response": "Convert a GPS time into a datetime. datetime."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting str to datetime. datetime.", "response": "def _str_to_datetime(datestr):\n    \"\"\"Convert `str` to `datetime.datetime`.\n    \"\"\"\n    # try known string\n    try:\n        return DATE_STRINGS[str(datestr).lower()]()\n    except KeyError:  # any other string\n        pass\n\n    # use maya\n    try:\n        import maya\n        return maya.when(datestr).datetime()\n    except ImportError:\n        pass\n\n    # use dateutil.parse\n    with warnings.catch_warnings():\n        # don't allow lazy passing of time-zones\n        warnings.simplefilter(\"error\", RuntimeWarning)\n        try:\n            return dateparser.parse(datestr)\n        except RuntimeWarning:\n            raise ValueError(\"Cannot parse date string with timezone \"\n                             \"without maya, please install maya\")\n        except (ValueError, TypeError) as exc:  # improve error reporting\n            exc.args = (\"Cannot parse date string {0!r}: {1}\".format(\n                datestr, exc.args[0]),)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _time_to_gps(time):\n    time = time.utc\n    date = time.datetime\n    micro = date.microsecond if isinstance(date, datetime.datetime) else 0\n    return LIGOTimeGPS(int(time.gps), int(micro*1e3))", "response": "Convert a time object into a LIGOTimeGPS object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps to open a h5py. File from disk gracefully gracefully handling a few corner cases", "response": "def open_hdf5(filename, mode='r'):\n    \"\"\"Wrapper to open a :class:`h5py.File` from disk, gracefully\n    handling a few corner cases\n    \"\"\"\n    if isinstance(filename, (h5py.Group, h5py.Dataset)):\n        return filename\n    if isinstance(filename, FILE_LIKE):\n        return h5py.File(filename.name, mode)\n    return h5py.File(filename, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_read_hdf5(func):\n    @wraps(func)\n    def decorated_func(fobj, *args, **kwargs):\n        # pylint: disable=missing-docstring\n        if not isinstance(fobj, h5py.HLObject):\n            if isinstance(fobj, FILE_LIKE):\n                fobj = fobj.name\n            with h5py.File(fobj, 'r') as h5f:\n                return func(h5f, *args, **kwargs)\n        return func(fobj, *args, **kwargs)\n\n    return decorated_func", "response": "Decorate an HDF5 - reading function to open a filepath if needed\n\n    func should be written to presume an h5py. Group as the first positional argument."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind and return the relevant dataset within the given HDF5 object.", "response": "def find_dataset(h5o, path=None):\n    \"\"\"Find and return the relevant dataset inside the given H5 object\n\n    If ``path=None`` is given, and ``h5o`` contains a single dataset, that\n    will be returned\n\n    Parameters\n    ----------\n    h5o : `h5py.File`, `h5py.Group`\n        the HDF5 object in which to search\n\n    path : `str`, optional\n        the path (relative to ``h5o``) of the desired data set\n\n    Returns\n    -------\n    dset : `h5py.Dataset`\n        the recovered dataset object\n\n    Raises\n    ------\n    ValueError\n        if ``path=None`` and the HDF5 object contains multiple datasets\n    KeyError\n        if ``path`` is given but is not found within the HDF5 object\n    \"\"\"\n    # find dataset\n    if isinstance(h5o, h5py.Dataset):\n        return h5o\n    elif path is None and len(h5o) == 1:\n        path = list(h5o.keys())[0]\n    elif path is None:\n        raise ValueError(\"Please specify the HDF5 path via the \"\n                         \"``path=`` keyword argument\")\n    return h5o[path]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_write_hdf5(func):\n    @wraps(func)\n    def decorated_func(obj, fobj, *args, **kwargs):\n        # pylint: disable=missing-docstring\n        if not isinstance(fobj, h5py.HLObject):\n            append = kwargs.get('append', False)\n            overwrite = kwargs.get('overwrite', False)\n            if os.path.exists(fobj) and not (overwrite or append):\n                raise IOError(\"File exists: %s\" % fobj)\n            with h5py.File(fobj, 'a' if append else 'w') as h5f:\n                return func(obj, h5f, *args, **kwargs)\n        return func(obj, fobj, *args, **kwargs)\n\n    return decorated_func", "response": "Decorate an HDF5 - writing function to open a filepath if needed\n    func should be written to take the object to be written as the first argument and presume an h5py. Group as the second argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new dataset inside the parent HDF5 object", "response": "def create_dataset(parent, path, overwrite=False, **kwargs):\n    \"\"\"Create a new dataset inside the parent HDF5 object\n\n    Parameters\n    ----------\n    parent : `h5py.Group`, `h5py.File`\n        the object in which to create a new dataset\n\n    path : `str`\n        the path at which to create the new dataset\n\n    overwrite : `bool`\n        if `True`, delete any existing dataset at the desired path,\n        default: `False`\n\n    **kwargs\n        other arguments are passed directly to\n        :meth:`h5py.Group.create_dataset`\n\n    Returns\n    -------\n    dataset : `h5py.Dataset`\n        the newly created dataset\n    \"\"\"\n    # force deletion of existing dataset\n    if path in parent and overwrite:\n        del parent[path]\n\n    # create new dataset with improved error handling\n    try:\n        return parent.create_dataset(path, **kwargs)\n    except RuntimeError as exc:\n        if str(exc) == 'Unable to create link (Name already exists)':\n            exc.args = ('{0}: {1!r}, pass overwrite=True '\n                        'to ignore existing datasets'.format(str(exc), path),)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_db_selection(selection, engine=None):\n    # parse selection for SQL query\n    if selection is None:\n        return ''\n    selections = []\n    for col, op_, value in parse_column_filters(selection):\n        if engine and engine.name == 'postgresql':\n            col = '\"%s\"' % col\n        try:\n            opstr = [key for key in OPERATORS if OPERATORS[key] is op_][0]\n        except KeyError:\n            raise ValueError(\"Cannot format database 'WHERE' command with \"\n                             \"selection operator %r\" % op_)\n        selections.append('{0} {1} {2!r}'.format(col, opstr, value))\n    if selections:\n        return 'WHERE %s' % ' AND '.join(selections)\n    return ''", "response": "Format a column filter selection as a SQL database WHERE string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch data from an SQL table into an EventTable", "response": "def fetch(engine, tablename, columns=None, selection=None, **kwargs):\n    \"\"\"Fetch data from an SQL table into an `EventTable`\n\n    Parameters\n    ----------\n    engine : `sqlalchemy.engine.Engine`\n        the database engine to use when connecting\n\n    table : `str`,\n        The name of table you are attempting to receive triggers\n        from.\n\n    selection\n        other filters you would like to supply\n        underlying reader method for the given format\n\n    .. note::\n\n       For now it will attempt to automatically connect you\n       to a specific DB. In the future, this may be an input\n       argument.\n\n    Returns\n    -------\n    table : `GravitySpyTable`\n    \"\"\"\n    import pandas as pd\n\n    # parse columns for SQL query\n    if columns is None:\n        columnstr = '*'\n    else:\n        columnstr = ', '.join('\"%s\"' % c for c in columns)\n\n    # parse selection for SQL query\n    selectionstr = format_db_selection(selection, engine=engine)\n\n    # build SQL query\n    qstr = 'SELECT %s FROM %s %s' % (columnstr, tablename, selectionstr)\n\n    # perform query\n    tab = pd.read_sql(qstr, engine, **kwargs)\n\n    # Convert unicode columns to string\n    types = tab.apply(lambda x: pd.api.types.infer_dtype(x.values))\n\n    if not tab.empty:\n        for col in types[types == 'unicode'].index:\n            tab[col] = tab[col].astype(str)\n\n    return Table.from_pandas(tab).filled()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef q_scan(data, mismatch=DEFAULT_MISMATCH, qrange=DEFAULT_QRANGE,\n           frange=DEFAULT_FRANGE, duration=None, sampling=None,\n           **kwargs):\n    \"\"\"Transform data by scanning over a `QTiling`\n\n    This utility is provided mainly to allow direct manipulation of the\n    `QTiling.transform` output. Most users probably just want to use\n    :meth:`~gwpy.timeseries.TimeSeries.q_transform`, which wraps around this.\n\n    Parameters\n    ----------\n    data : `~gwpy.timeseries.TimeSeries` or `ndarray`\n        the time- or frequency-domain input data\n\n    mismatch : `float`, optional\n        maximum allowed fractional mismatch between neighbouring tiles\n\n    qrange : `tuple` of `float`, optional\n        `(low, high)` range of Qs to scan\n\n    frange : `tuple` of `float`, optional\n        `(low, high)` range of frequencies to scan\n\n    duration : `float`, optional\n        duration (seconds) of input, required if `data` is not a `TimeSeries`\n\n    sampling : `float`, optional\n        sample rate (Hertz) of input, required if `data` is not a `TimeSeries`\n\n    **kwargs\n        other keyword arguments to be passed to :meth:`QTiling.transform`,\n        including ``'epoch'`` and ``'search'``\n\n    Returns\n    -------\n    qgram : `QGram`\n        the raw output of :meth:`QTiling.transform`\n\n    far : `float`\n        expected false alarm rate (Hertz) of white Gaussian noise with the\n        same peak energy and total duration as `qgram`\n    \"\"\"\n    from gwpy.timeseries import TimeSeries\n    # prepare input\n    if isinstance(data, TimeSeries):\n        duration = abs(data.span)\n        sampling = data.sample_rate.to('Hz').value\n        kwargs.update({'epoch': data.t0.value})\n        data = data.fft().value\n    # return a raw Q-transform and its significance\n    qgram, N = QTiling(duration, sampling, mismatch=mismatch, qrange=qrange,\n                       frange=frange).transform(data, **kwargs)\n    far = 1.5 * N * numpy.exp(-qgram.peak['energy']) / duration\n    return (qgram, far)", "response": "Transform data by scanning over a QTiling object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the Q values in the current time series.", "response": "def _iter_qs(self):\n        \"\"\"Iterate over the Q values\n        \"\"\"\n        # work out how many Qs we need\n        cumum = log(self.qrange[1] / self.qrange[0]) / 2**(1/2.)\n        nplanes = int(max(ceil(cumum / self.deltam), 1))\n        dq = cumum / nplanes  # pylint: disable=invalid-name\n        for i in xrange(nplanes):\n            yield self.qrange[0] * exp(2**(1/2.) * dq * (i + .5))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the time - frequency plane at fixed Q with the most significant tile and return the result.", "response": "def transform(self, fseries, **kwargs):\n        \"\"\"Compute the time-frequency plane at fixed Q with the most\n        significant tile\n\n        Parameters\n        ----------\n        fseries : `~gwpy.timeseries.FrequencySeries`\n            the complex FFT of a time-series data set\n\n        **kwargs\n            other keyword arguments to pass to `QPlane.transform`\n\n        Returns\n        -------\n        out : `QGram`\n            signal energies over the time-frequency plane containing the most\n            significant tile\n\n        N : `int`\n            estimated number of statistically independent tiles\n\n        See Also\n        --------\n        QPlane.transform\n            compute the Q-transform over a single time-frequency plane\n        \"\"\"\n        weight = 1 + numpy.log10(self.qrange[1]/self.qrange[0]) / numpy.sqrt(2)\n        nind, nplanes, peak, result = (0, 0, 0, None)\n        # identify the plane with the loudest tile\n        for plane in self:\n            nplanes += 1\n            nind += sum([1 + row.ntiles * row.deltam for row in plane])\n            result = plane.transform(fseries, **kwargs)\n            if result.peak['energy'] > peak:\n                out = result\n                peak = out.peak['energy']\n        return (out, nind * weight / nplanes)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iter_frequencies(self):\n        # work out how many frequencies we need\n        minf, maxf = self.frange\n        fcum_mismatch = log(maxf / minf) * (2 + self.q**2)**(1/2.) / 2.\n        nfreq = int(max(1, ceil(fcum_mismatch / self.deltam)))\n        fstep = fcum_mismatch / nfreq\n        fstepmin = 1 / self.duration\n        # for each frequency, yield a QTile\n        for i in xrange(nfreq):\n            yield (minf *\n                   exp(2 / (2 + self.q**2)**(1/2.) * (i + .5) * fstep) //\n                   fstepmin * fstepmin)", "response": "Iterate over the frequencies of this QPlane."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\narraying of frequencies for the lower - edge of each frequency bin", "response": "def farray(self):\n        \"\"\"Array of frequencies for the lower-edge of each frequency bin\n\n        :type: `numpy.ndarray`\n        \"\"\"\n        bandwidths = 2 * pi ** (1/2.) * self.frequencies / self.q\n        return self.frequencies - bandwidths / 2."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, fseries, norm=True, epoch=None, search=None):\n        out = []\n        for qtile in self:\n            # get energy from transform\n            out.append(qtile.transform(fseries, norm=norm, epoch=epoch))\n        return QGram(self, out, search)", "response": "Calculate the energy time - series for the given frequency - series."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the bi - square window for this row", "response": "def get_window(self):\n        \"\"\"Generate the bi-square window for this row\n\n        Returns\n        -------\n        window : `numpy.ndarray`\n        \"\"\"\n        # real frequencies\n        wfrequencies = self._get_indices() / self.duration\n        # dimensionless frequencies\n        xfrequencies = wfrequencies * self.qprime / self.frequency\n        # normalize and generate bi-square window\n        norm = self.ntiles / (self.duration * self.sampling) * (\n            315 * self.qprime / (128 * self.frequency)) ** (1/2.)\n        return (1 - xfrequencies ** 2) ** 2 * norm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_data_indices(self):\n        return numpy.round(self._get_indices() + 1 +\n                           self.frequency * self.duration).astype(int)", "response": "Returns the index array of interesting frequencies for this row\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef padding(self):\n        pad = self.ntiles - self.windowsize\n        return (int((pad - 1)/2.), int((pad + 1)/2.))", "response": "The left and right padding required for the IFFT\n       ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, fseries, norm=True, epoch=None):\n        from ..timeseries import TimeSeries\n\n        windowed = fseries[self.get_data_indices()] * self.get_window()\n        # pad data, move negative frequencies to the end, and IFFT\n        padded = numpy.pad(windowed, self.padding, mode='constant')\n        wenergy = npfft.ifftshift(padded)\n        # return a `TimeSeries`\n        if epoch is None:\n            epoch = fseries.epoch\n        tdenergy = npfft.ifft(wenergy)\n        cenergy = TimeSeries(tdenergy, x0=epoch,\n                             dx=self.duration/tdenergy.size, copy=False)\n        energy = type(cenergy)(\n            cenergy.value.real ** 2. + cenergy.value.imag ** 2.,\n            x0=cenergy.x0, dx=cenergy.dx, copy=False)\n\n        if norm:\n            norm = norm.lower() if isinstance(norm, string_types) else norm\n            if norm in (True, 'median'):\n                narray = energy / energy.median()\n            elif norm in ('mean',):\n                narray = energy / energy.mean()\n            else:\n                raise ValueError(\"Invalid normalisation %r\" % norm)\n            return narray.astype(\"float32\", casting=\"same_kind\", copy=False)\n        return energy", "response": "Calculate the energy of the time - series with the complex FFT of the given fseries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninterpolates this QGram over a regularly - gridded spectrogram.", "response": "def interpolate(self, tres=\"<default>\", fres=\"<default>\", logf=False,\n                    outseg=None):\n        \"\"\"Interpolate this `QGram` over a regularly-gridded spectrogram\n\n        Parameters\n        ----------\n        tres : `float`, optional\n            desired time resolution (seconds) of output `Spectrogram`,\n            default is `abs(outseg) / 1000.`\n\n        fres : `float`, `int`, `None`, optional\n            desired frequency resolution (Hertz) of output `Spectrogram`,\n            or, if ``logf=True``, the number of frequency samples;\n            give `None` to skip this step and return the original resolution,\n            default is 0.5 Hz or 500 frequency samples\n\n        logf : `bool`, optional\n            boolean switch to enable (`True`) or disable (`False`) use of\n            log-sampled frequencies in the output `Spectrogram`\n\n        outseg : `~gwpy.segments.Segment`, optional\n            GPS `[start, stop)` segment for output `Spectrogram`,\n            default is the full duration of the input\n\n        Returns\n        -------\n        out : `~gwpy.spectrogram.Spectrogram`\n            output `Spectrogram` of normalised Q energy\n\n        See Also\n        --------\n        scipy.interpolate\n            this method uses `~scipy.interpolate.InterpolatedUnivariateSpline`\n            to cast all frequency rows to a common time-axis, and then\n            `~scipy.interpolate.interp2d` to apply the desired frequency\n            resolution across the band\n\n        Notes\n        -----\n        This method will return a `Spectrogram` of dtype ``float32`` if\n        ``norm`` is given, and ``float64`` otherwise.\n\n        To optimize plot rendering with `~matplotlib.axes.Axes.pcolormesh`,\n        the output `~gwpy.spectrogram.Spectrogram` can be given a log-sampled\n        frequency axis by passing `logf=True` at runtime. The `fres` argument\n        is then the number of points on the frequency axis. Note, this is\n        incompatible with `~matplotlib.axes.Axes.imshow`.\n\n        It is also highly recommended to use the `outseg` keyword argument\n        when only a small window around a given GPS time is of interest.\n        \"\"\"\n        from scipy.interpolate import (interp2d, InterpolatedUnivariateSpline)\n        from ..spectrogram import Spectrogram\n        if outseg is None:\n            outseg = self.energies[0].span\n        frequencies = self.plane.frequencies\n        dtype = self.energies[0].dtype\n        # build regular Spectrogram from peak-Q data by interpolating each\n        # (Q, frequency) `TimeSeries` to have the same time resolution\n        if tres == \"<default>\":\n            tres = abs(Segment(outseg)) / 1000.\n        xout = numpy.arange(*outseg, step=tres)\n        nx = xout.size\n        ny = frequencies.size\n        out = Spectrogram(numpy.empty((nx, ny), dtype=dtype),\n                          t0=outseg[0], dt=tres, frequencies=frequencies)\n        # record Q in output\n        out.q = self.plane.q\n        # interpolate rows\n        for i, row in enumerate(self.energies):\n            xrow = numpy.arange(row.x0.value, (row.x0 + row.duration).value,\n                                row.dx.value)\n            interp = InterpolatedUnivariateSpline(xrow, row.value)\n            out[:, i] = interp(xout).astype(dtype, casting=\"same_kind\",\n                                            copy=False)\n        if fres is None:\n            return out\n        # interpolate the spectrogram to increase its frequency resolution\n        # --- this is done because Duncan doesn't like interpolated images\n        #     since they don't support log scaling\n        interp = interp2d(xout, frequencies, out.value.T, kind='cubic')\n        if not logf:\n            if fres == \"<default>\":\n                fres = .5\n            outfreq = numpy.arange(\n                self.plane.frange[0], self.plane.frange[1], fres,\n                dtype=dtype)\n        else:\n            if fres == \"<default>\":\n                fres = 500\n            # using `~numpy.logspace` here to support numpy-1.7.1 for EPEL7,\n            # but numpy-1.12.0 introduced the function `~numpy.geomspace`\n            logfmin = numpy.log10(self.plane.frange[0])\n            logfmax = numpy.log10(self.plane.frange[1])\n            outfreq = numpy.logspace(logfmin, logfmax, num=int(fres))\n        new = type(out)(\n            interp(xout, outfreq).T.astype(\n                dtype, casting=\"same_kind\", copy=False),\n            t0=outseg[0], dt=tres, frequencies=outfreq,\n        )\n        new.q = self.plane.q\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrepresent this QPlane as an EventTable.", "response": "def table(self, snrthresh=5.5):\n        \"\"\"Represent this `QPlane` as an `EventTable`\n\n        Parameters\n        ----------\n        snrthresh : `float`, optional\n            lower inclusive threshold on individual tile SNR to keep in the\n            table, default: 5.5\n\n        Returns\n        -------\n        out : `~gwpy.table.EventTable`\n            a table of time-frequency tiles on this `QPlane`\n\n        Notes\n        -----\n        Only tiles with signal energy greater than or equal to\n        `snrthresh ** 2 / 2` will be stored in the output `EventTable`.\n        \"\"\"\n        from ..table import EventTable\n        # get plane properties\n        freqs = self.plane.frequencies\n        bws = 2 * (freqs - self.plane.farray)\n        # collect table data as a recarray\n        names = ('time', 'frequency', 'duration', 'bandwidth', 'energy')\n        rec = numpy.recarray((0,), names=names, formats=['f8'] * len(names))\n        for f, bw, row in zip(freqs, bws, self.energies):\n            ind, = (row.value >= snrthresh ** 2 / 2.).nonzero()\n            new = ind.size\n            if new > 0:\n                rec.resize((rec.size + new,), refcheck=False)\n                rec['time'][-new:] = row.times.value[ind]\n                rec['frequency'][-new:] = f\n                rec['duration'][-new:] = row.dt.to('s').value\n                rec['bandwidth'][-new:] = bw\n                rec['energy'][-new:] = row.value[ind]\n        # save to a table\n        out = EventTable(rec, copy=False)\n        out.meta['q'] = self.plane.q\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefining a new index.", "response": "def define(cls, start, step, num, dtype=None):\n        \"\"\"Define a new `Index`.\n\n        The output is basically::\n\n            start + numpy.arange(num) * step\n\n        Parameters\n        ----------\n        start : `Number`\n            The starting value of the index.\n\n        step : `Number`\n            The step size of the index.\n\n        num : `int`\n            The size of the index (number of samples).\n\n        dtype : `numpy.dtype`, `None`, optional\n            The desired dtype of the index, if not given, defaults\n            to the higher-precision dtype from ``start`` and ``step``.\n\n        Returns\n        -------\n        index : `Index`\n            A new `Index` created from the given parameters.\n        \"\"\"\n        if dtype is None:\n            dtype = max(\n                numpy.array(start, subok=True, copy=False).dtype,\n                numpy.array(step, subok=True, copy=False).dtype,\n            )\n        start = start.astype(dtype, copy=False)\n        step = step.astype(dtype, copy=False)\n        return cls(start + numpy.arange(num, dtype=dtype) * step, copy=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef regular(self):\n        try:\n            return self.info.meta['regular']\n        except (TypeError, KeyError):\n            if self.info.meta is None:\n                self.info.meta = {}\n            self.info.meta['regular'] = self.is_regular()\n            return self.info.meta['regular']", "response": "True if this index is linearly increasing\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine whether this Index contains linearly increasing samples", "response": "def is_regular(self):\n        \"\"\"Determine whether this `Index` contains linearly increasing samples\n\n        This also works for linear decrease\n        \"\"\"\n        if self.size <= 1:\n            return False\n        return numpy.isclose(numpy.diff(self.value, n=2), 0).all()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread an EventTable from an Omicron ROOT file", "response": "def table_from_omicron(source, *args, **kwargs):\n    \"\"\"Read an `EventTable` from an Omicron ROOT file\n\n    This function just redirects to the format='root' reader with appropriate\n    defaults.\n    \"\"\"\n    if not args:  # only default treename if args not given\n        kwargs.setdefault('treename', 'triggers')\n    return EventTable.read(source, *args, format='root', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot(self, *args, **kwargs):\n        out = []\n        args = list(args)\n        while args:\n            try:\n                plotter = self._plot_method(args[0])\n            except TypeError:\n                break\n            out.append(plotter(args[0], **kwargs))\n            args.pop(0)\n        if args:\n            out.extend(super(SegmentAxes, self).plot(*args, **kwargs))\n        self.autoscale(enable=None, axis='both', tight=False)\n        return out", "response": "Plot data onto these axes returning a list of Line2D objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots a ~gwpy. segments. DataQualityDict onto these axes.", "response": "def plot_dict(self, flags, label='key', known='x', **kwargs):\n        \"\"\"Plot a `~gwpy.segments.DataQualityDict` onto these axes\n\n        Parameters\n        ----------\n        flags : `~gwpy.segments.DataQualityDict`\n            data-quality dict to display\n\n        label : `str`, optional\n            labelling system to use, or fixed label for all `DataQualityFlags`.\n            Special values include\n\n            - ``'key'``: use the key of the `DataQualityDict`,\n            - ``'name'``: use the :attr:`~DataQualityFlag.name` of the\n              `DataQualityFlag`\n\n            If anything else, that fixed label will be used for all lines.\n\n        known : `str`, `dict`, `None`, default: '/'\n            display `known` segments with the given hatching, or give a\n            dict of keyword arguments to pass to\n            :meth:`~SegmentAxes.plot_segmentlist`, or `None` to hide.\n\n        **kwargs\n            any other keyword arguments acceptable for\n            `~matplotlib.patches.Rectangle`\n\n        Returns\n        -------\n        collection : `~matplotlib.patches.PatchCollection`\n            list of `~matplotlib.patches.Rectangle` patches\n        \"\"\"\n        out = []\n        for lab, flag in flags.items():\n            if label.lower() == 'name':\n                lab = flag.name\n            elif label.lower() != 'key':\n                lab = label\n            out.append(self.plot_flag(flag, label=to_string(lab), known=known,\n                                      **kwargs))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots a ~gwpy. segments. DataQualityFlag onto these axes.", "response": "def plot_flag(self, flag, y=None, **kwargs):\n        \"\"\"Plot a `~gwpy.segments.DataQualityFlag` onto these axes.\n\n        Parameters\n        ----------\n        flag : `~gwpy.segments.DataQualityFlag`\n            Data-quality flag to display.\n\n        y : `float`, optional\n            Y-axis value for new segments.\n\n        height : `float`, optional,\n            Height for each segment, default: `0.8`.\n\n        known : `str`, `dict`, `None`\n            One of the following\n\n            - ``'fancy'`` - to use fancy format (try it and see)\n            - ``'x'`` (or similar) - to use hatching\n            - `str` to specify ``facecolor`` for known segmentlist\n            - `dict` of kwargs to use\n            - `None` to ignore known segmentlist\n\n        **kwargs\n            Any other keyword arguments acceptable for\n            `~matplotlib.patches.Rectangle`.\n\n        Returns\n        -------\n        collection : `~matplotlib.patches.PatchCollection`\n            list of `~matplotlib.patches.Rectangle` patches for active\n            segments\n        \"\"\"\n        # get y axis position\n        if y is None:\n            y = self.get_next_y()\n\n        # default a 'good' flag to green segments and vice-versa\n        if flag.isgood:\n            kwargs.setdefault('facecolor', '#33cc33')\n            kwargs.setdefault('known', '#ff0000')\n        else:\n            kwargs.setdefault('facecolor', '#ff0000')\n            kwargs.setdefault('known', '#33cc33')\n        known = kwargs.pop('known')\n\n        # get flag name\n        name = kwargs.pop('label', flag.label or flag.name)\n\n        # make active collection\n        kwargs.setdefault('zorder', 0)\n        coll = self.plot_segmentlist(flag.active, y=y, label=name,\n                                     **kwargs)\n\n        # make known collection\n        if known not in (None, False):\n            known_kw = {\n                'facecolor': coll.get_facecolor()[0],\n                'collection': 'ignore',\n                'zorder': -1000,\n            }\n            if isinstance(known, dict):\n                known_kw.update(known)\n            elif known == 'fancy':\n                known_kw.update(height=kwargs.get('height', .8)*.05)\n            elif known in HATCHES:\n                known_kw.update(fill=False, hatch=known)\n            else:\n                known_kw.update(fill=True, facecolor=known,\n                                height=kwargs.get('height', .8)*.5)\n            self.plot_segmentlist(flag.known, y=y, label=name, **known_kw)\n\n        return coll"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_segmentlist(self, segmentlist, y=None, height=.8, label=None,\n                         collection=True, rasterized=None, **kwargs):\n        \"\"\"Plot a `~gwpy.segments.SegmentList` onto these axes\n\n        Parameters\n        ----------\n        segmentlist : `~gwpy.segments.SegmentList`\n            list of segments to display\n\n        y : `float`, optional\n            y-axis value for new segments\n\n        collection : `bool`, default: `True`\n            add all patches as a\n            `~matplotlib.collections.PatchCollection`, doesn't seem\n            to work for hatched rectangles\n\n        label : `str`, optional\n            custom descriptive name to print as y-axis tick label\n\n        **kwargs\n            any other keyword arguments acceptable for\n            `~matplotlib.patches.Rectangle`\n\n        Returns\n        -------\n        collection : `~matplotlib.patches.PatchCollection`\n            list of `~matplotlib.patches.Rectangle` patches\n        \"\"\"\n        # get colour\n        facecolor = kwargs.pop('facecolor', kwargs.pop('color', '#629fca'))\n        if is_color_like(facecolor):\n            kwargs.setdefault('edgecolor', tint(facecolor, factor=.5))\n\n        # get y\n        if y is None:\n            y = self.get_next_y()\n\n        # build patches\n        patches = [SegmentRectangle(seg, y, height=height, facecolor=facecolor,\n                                    **kwargs) for seg in segmentlist]\n\n        if collection:  # map to PatchCollection\n            coll = PatchCollection(patches, match_original=patches,\n                                   zorder=kwargs.get('zorder', 1))\n            coll.set_rasterized(rasterized)\n            coll._ignore = collection == 'ignore'\n            coll._ypos = y\n            out = self.add_collection(coll)\n            # reset label with tex-formatting now\n            #   matplotlib default label is applied by add_collection\n            #   so we can only replace the leading underscore after\n            #   this point\n            if label is None:\n                label = coll.get_label()\n            coll.set_label(to_string(label))\n        else:\n            out = []\n            for patch in patches:\n                patch.set_label(label)\n                patch.set_rasterized(rasterized)\n                label = ''\n                out.append(self.add_patch(patch))\n        self.autoscale(enable=None, axis='both', tight=False)\n        return out", "response": "Plot a segmentlist onto the current figure."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a ~gwpy. segments. SegmentListDict onto y - axis and return a list of ~matplotlib. patches. PatchCollection objects for each segmentlist.", "response": "def plot_segmentlistdict(self, segmentlistdict, y=None, dy=1, **kwargs):\n        \"\"\"Plot a `~gwpy.segments.SegmentListDict` onto\n        these axes\n\n        Parameters\n        ----------\n        segmentlistdict : `~gwpy.segments.SegmentListDict`\n            (name, `~gwpy.segments.SegmentList`) dict\n\n        y : `float`, optional\n            starting y-axis value for new segmentlists\n\n        **kwargs\n            any other keyword arguments acceptable for\n            `~matplotlib.patches.Rectangle`\n\n        Returns\n        -------\n        collections : `list`\n            list of `~matplotlib.patches.PatchCollection` sets for\n            each segmentlist\n        \"\"\"\n        if y is None:\n            y = self.get_next_y()\n        collections = []\n        for name, segmentlist in segmentlistdict.items():\n            collections.append(self.plot_segmentlist(segmentlist, y=y,\n                                                     label=name, **kwargs))\n            y += dy\n        return collections"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the collections that match the _ignore value.", "response": "def get_collections(self, ignore=None):\n        \"\"\"Return the collections matching the given `_ignore` value\n\n        Parameters\n        ----------\n        ignore : `bool`, or `None`\n            value of `_ignore` to match\n\n        Returns\n        -------\n        collections : `list`\n            if `ignore=None`, simply returns all collections, otherwise\n            returns those collections matching the `ignore` parameter\n        \"\"\"\n        if ignore is None:\n            return self.collections\n        return [c for c in self.collections if\n                getattr(c, '_ignore', None) == ignore]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kinit(username=None, password=None, realm=None, exe=None, keytab=None,\n          krb5ccname=None, verbose=None):\n    \"\"\"Initialise a kerberos (krb5) ticket.\n\n    This allows authenticated connections to, amongst others, NDS2\n    services.\n\n    Parameters\n    ----------\n    username : `str`, optional\n        name of user, will be prompted for if not given.\n\n    password : `str`, optional\n        cleartext password of user for given realm, will be prompted for\n        if not given.\n\n    realm : `str`, optional\n        name of realm to authenticate against, read from keytab if available,\n        defaults to ``'LIGO.ORG'``.\n\n    exe : `str`, optional\n        path to kinit executable.\n\n    keytab : `str`, optional\n        path to keytab file. If not given this will be read from the\n        ``KRB5_KTNAME`` environment variable. See notes for more details.\n\n    krb5ccname : `str`, optional\n        path to Kerberos credentials cache.\n\n    verbose : `bool`, optional\n        print verbose output (if `True`), or not (`False)`; default is `True`\n        if any user-prompting is needed, otherwise `False`.\n\n    Notes\n    -----\n    If a keytab is given, or is read from the ``KRB5_KTNAME`` environment\n    variable, this will be used to guess the username and realm, if it\n    contains only a single credential.\n\n    Examples\n    --------\n    Example 1: standard user input, with password prompt::\n\n    >>> kinit('albert.einstein')\n    Password for albert.einstein@LIGO.ORG:\n    Kerberos ticket generated for albert.einstein@LIGO.ORG\n\n    Example 2: extract username and realm from keytab, and use that\n    in authentication::\n\n    >>> kinit(keytab='~/.kerberos/ligo.org.keytab', verbose=True)\n    Kerberos ticket generated for albert.einstein@LIGO.ORG\n    \"\"\"\n    # get kinit path\n    if exe is None:\n        exe = which('kinit')\n\n    # get keytab\n    if keytab is None:\n        keytab = os.environ.get('KRB5_KTNAME', None)\n        if keytab is None or not os.path.isfile(keytab):\n            keytab = None\n    if keytab:\n        try:\n            principals = parse_keytab(keytab)\n        except KerberosError:\n            pass\n        else:\n            # is there's only one entry in the keytab, use that\n            if username is None and len(principals) == 1:\n                username = principals[0][0]\n            # or if the given username is in the keytab, find the realm\n            if username in list(zip(*principals))[0]:\n                idx = list(zip(*principals))[0].index(username)\n                realm = principals[idx][1]\n            # otherwise this keytab is useless, so remove it\n            else:\n                keytab = None\n\n    # refuse to prompt if we can't get an answer\n    # note: jupyter streams are not recognised as interactive\n    #       (isatty() returns False) so we have a special case here\n    if not sys.stdout.isatty() and not _IPYTHON and (\n            username is None or\n            (not keytab and password is None)\n    ):\n        raise KerberosError(\"cannot generate kerberos ticket in a \"\n                            \"non-interactive session, please manually create \"\n                            \"a ticket, or consider using a keytab file\")\n\n    # get credentials\n    if realm is None:\n        realm = 'LIGO.ORG'\n    if username is None:\n        verbose = True\n        username = input(\"Please provide username for the {} kerberos \"\n                         \"realm: \".format(realm))\n    identity = '{}@{}'.format(username, realm)\n    if not keytab and password is None:\n        verbose = True\n        password = getpass.getpass(prompt=\"Password for {}: \".format(identity))\n\n    # format kinit command\n    if keytab:\n        cmd = [exe, '-k', '-t', keytab, identity]\n    else:\n        cmd = [exe, identity]\n    if krb5ccname:\n        krbenv = {'KRB5CCNAME': krb5ccname}\n    else:\n        krbenv = None\n\n    # execute command\n    kget = subprocess.Popen(cmd, env=krbenv, stdout=subprocess.PIPE,\n                            stdin=subprocess.PIPE)\n    if not keytab:\n        kget.communicate(password.encode('utf-8'))\n    kget.wait()\n    retcode = kget.poll()\n    if retcode:\n        raise subprocess.CalledProcessError(kget.returncode, ' '.join(cmd))\n    if verbose:\n        print(\"Kerberos ticket generated for {}\".format(identity))", "response": "Initialises a NDS2\n    with the given username password realm and keytab."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the contents of a KRB5 keytab file and return a list of tuples containing the username realm kvno", "response": "def parse_keytab(keytab):\n    \"\"\"Read the contents of a KRB5 keytab file, returning a list of\n    credentials listed within\n\n    Parameters\n    ----------\n    keytab : `str`\n        path to keytab file\n\n    Returns\n    -------\n    creds : `list` of `tuple`\n        the (unique) list of `(username, realm, kvno)` as read from the\n        keytab file\n\n    Examples\n    --------\n    >>> from gwpy.io.kerberos import parse_keytab\n    >>> print(parse_keytab(\"creds.keytab\"))\n    [('albert.einstein', 'LIGO.ORG', 1)]\n    \"\"\"\n    try:\n        out = subprocess.check_output(['klist', '-k', keytab],\n                                      stderr=subprocess.PIPE)\n    except OSError:\n        raise KerberosError(\"Failed to locate klist, cannot read keytab\")\n    except subprocess.CalledProcessError:\n        raise KerberosError(\"Cannot read keytab {!r}\".format(keytab))\n    principals = []\n    for line in out.splitlines():\n        if isinstance(line, bytes):\n            line = line.decode('utf-8')\n        try:\n            kvno, principal, = re.split(r'\\s+', line.strip(' '), 1)\n        except ValueError:\n            continue\n        else:\n            if not kvno.isdigit():\n                continue\n            principals.append(tuple(principal.split('@')) + (int(kvno),))\n    # return unique, ordered list\n    return list(OrderedDict.fromkeys(principals).keys())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the y - axis coordinate of the first data point in the current calendar.", "response": "def y0(self):\n        \"\"\"Y-axis coordinate of the first data point\n\n        :type: `~astropy.units.Quantity` scalar\n        \"\"\"\n        try:\n            return self._y0\n        except AttributeError:\n            self._y0 = Quantity(0, self.yunit)\n            return self._y0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dy(self):\n        try:\n            return self._dy\n        except AttributeError:\n            try:\n                self._yindex\n            except AttributeError:\n                self._dy = Quantity(1, self.yunit)\n            else:\n                if not self.yindex.regular:\n                    raise AttributeError(\n                        \"This series has an irregular y-axis \"\n                        \"index, so 'dy' is not well defined\")\n                self._dy = self.yindex[1] - self.yindex[0]\n            return self._dy", "response": "get the y - axis sample separation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef yindex(self):\n        try:\n            return self._yindex\n        except AttributeError:\n            self._yindex = Index.define(self.y0, self.dy, self.shape[1])\n            return self._yindex", "response": "Returns the index of the y - axis of the data on the y - axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether this array and other have compatible metadata", "response": "def is_compatible(self, other):\n        \"\"\"Check whether this array and ``other`` have compatible metadata\n        \"\"\"\n        super(Array2D, self).is_compatible(other)\n        # check y-axis metadata\n        if isinstance(other, type(self)):\n            try:\n                if not self.dy == other.dy:\n                    raise ValueError(\"%s sample sizes do not match: \"\n                                     \"%s vs %s.\" % (type(self).__name__,\n                                                    self.dy, other.dy))\n            except AttributeError:\n                raise ValueError(\"Series with irregular y-indexes cannot \"\n                                 \"be compatible\")\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef value_at(self, x, y):\n        x = Quantity(x, self.xindex.unit).value\n        y = Quantity(y, self.yindex.unit).value\n        try:\n            idx = (self.xindex.value == x).nonzero()[0][0]\n        except IndexError as exc:\n            exc.args = (\"Value %r not found in array xindex\" % x,)\n            raise\n        try:\n            idy = (self.yindex.value == y).nonzero()[0][0]\n        except IndexError as exc:\n            exc.args = (\"Value %r not found in array yindex\",)\n            raise\n        return self[idx, idy]", "response": "Return the value of this Series at the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all HDF5 Groups under the given group that contain a flag", "response": "def find_flag_groups(h5group, strict=True):\n    \"\"\"Returns all HDF5 Groups under the given group that contain a flag\n\n    The check is just that the sub-group has a ``'name'`` attribute, so its\n    not fool-proof by any means.\n\n    Parameters\n    ----------\n    h5group : `h5py.Group`\n        the parent group in which to search\n\n    strict : `bool`, optional, default: `True`\n        if `True` raise an exception for any sub-group that doesn't have a\n        name, otherwise just return all of those that do\n\n    Raises\n    ------\n    KeyError\n        if a sub-group doesn't have a ``'name'`` attribtue and ``strict=True``\n    \"\"\"\n    names = []\n    for group in h5group:\n        try:\n            names.append(h5group[group].attrs['name'])\n        except KeyError:\n            if strict:\n                raise\n            continue\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_flag_group(obj):\n    return (\n        isinstance(obj, h5py.Group) and\n        isinstance(obj.get(\"active\"), h5py.Dataset) and\n        isinstance(obj.get(\"known\"), h5py.Dataset)\n    )", "response": "Returns True if obj is an h5py. Group that looks like\n    if contains a flag\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all flag groups in h5f that look like flags", "response": "def _find_flag_groups(h5f):\n    \"\"\"Return all groups in `h5f` that look like flags\n    \"\"\"\n    flag_groups = []\n\n    def _find(name, obj):\n        if _is_flag_group(obj):\n            flag_groups.append(name)\n\n    h5f.visititems(_find)\n    return flag_groups"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the group to use in order to read a flag", "response": "def _get_flag_group(h5f, path):\n    \"\"\"Determine the group to use in order to read a flag\n    \"\"\"\n    # if user chose the path, just use it\n    if path:\n        return h5f[path]\n\n    # if the user gave us the group directly, use it\n    if _is_flag_group(h5f):\n        return h5f\n\n    # otherwise try and find a single group that matches\n    try:\n        path, = _find_flag_groups(h5f)\n    except ValueError:\n        pass\n    else:\n        return h5f[path]\n\n    # if not exactly 1 valid group in the file, complain\n    raise ValueError(\n        \"please pass a valid HDF5 Group, or specify the HDF5 Group \"\n        \"path via the ``path=`` keyword argument\",\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a DataQualityFlag object from an HDF5 file or group.", "response": "def read_hdf5_flag(h5f, path=None, gpstype=LIGOTimeGPS):\n    \"\"\"Read a `DataQualityFlag` object from an HDF5 file or group.\n    \"\"\"\n    # extract correct group\n    dataset = _get_flag_group(h5f, path)\n\n    # read dataset\n    active = SegmentList.read(dataset['active'], format='hdf5',\n                              gpstype=gpstype)\n    try:\n        known = SegmentList.read(dataset['known'], format='hdf5',\n                                 gpstype=gpstype)\n    except KeyError as first_keyerror:\n        try:\n            known = SegmentList.read(dataset['valid'], format='hdf5',\n                                     gpstype=gpstype)\n        except KeyError:\n            raise first_keyerror\n\n    return DataQualityFlag(active=active, known=known, **dict(dataset.attrs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a SegmentList object from an HDF5 file or group.", "response": "def read_hdf5_segmentlist(h5f, path=None, gpstype=LIGOTimeGPS, **kwargs):\n    \"\"\"Read a `SegmentList` object from an HDF5 file or group.\n    \"\"\"\n    # find dataset\n    dataset = io_hdf5.find_dataset(h5f, path=path)\n\n    segtable = Table.read(dataset, format='hdf5', **kwargs)\n    out = SegmentList()\n    for row in segtable:\n        start = LIGOTimeGPS(int(row['start_time']), int(row['start_time_ns']))\n        end = LIGOTimeGPS(int(row['end_time']), int(row['end_time_ns']))\n        if gpstype is LIGOTimeGPS:\n            out.append(Segment(start, end))\n        else:\n            out.append(Segment(gpstype(start), gpstype(end)))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a DataQualityDict from an HDF5 file containing a list of flag names and a list of HDF5 file containing the data.", "response": "def read_hdf5_dict(h5f, names=None, path=None, on_missing='error', **kwargs):\n    \"\"\"Read a `DataQualityDict` from an HDF5 file\n    \"\"\"\n    if path:\n        h5f = h5f[path]\n\n    # allow alternative keyword argument name (FIXME)\n    if names is None:\n        names = kwargs.pop('flags', None)\n\n    # try and get list of names automatically\n    if names is None:\n        try:\n            names = find_flag_groups(h5f, strict=True)\n        except KeyError:\n            names = None\n        if not names:\n            raise ValueError(\"Failed to automatically parse available flag \"\n                             \"names from HDF5, please give a list of names \"\n                             \"to read via the ``names=`` keyword\")\n\n    # read data\n    out = DataQualityDict()\n    for name in names:\n        try:\n            out[name] = read_hdf5_flag(h5f, name, **kwargs)\n        except KeyError as exc:\n            if on_missing == 'ignore':\n                pass\n            elif on_missing == 'warn':\n                warnings.warn(str(exc))\n            else:\n                raise ValueError('no H5Group found for flag '\n                                 '{0!r}'.format(name))\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_hdf5_flag_group(flag, h5group, **kwargs):\n    # write segmentlists\n    flag.active.write(h5group, 'active', **kwargs)\n    kwargs['append'] = True\n    flag.known.write(h5group, 'known', **kwargs)\n\n    # store metadata\n    for attr in ['name', 'label', 'category', 'description', 'isgood',\n                 'padding']:\n        value = getattr(flag, attr)\n        if value is None:\n            continue\n        elif isinstance(value, Quantity):\n            h5group.attrs[attr] = value.value\n        elif isinstance(value, UnitBase):\n            h5group.attrs[attr] = str(value)\n        else:\n            h5group.attrs[attr] = value\n\n    return h5group", "response": "Write a DataQualityFlag into the given HDF5 group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_hdf5_dict(flags, output, path=None, append=False, overwrite=False,\n                    **kwargs):\n    \"\"\"Write this `DataQualityFlag` to a `h5py.Group`.\n\n    This allows writing to an HDF5-format file.\n\n    Parameters\n    ----------\n    output : `str`, :class:`h5py.Group`\n        path to new output file, or open h5py `Group` to write to.\n\n    path : `str`\n        the HDF5 group path in which to write a new group for this flag\n\n    **kwargs\n        other keyword arguments passed to :meth:`h5py.Group.create_dataset`\n\n    Returns\n    -------\n    dqfgroup : :class:`h5py.Group`\n        HDF group containing these data. This group contains 'active'\n        and 'known' datasets, and metadata attrs.\n\n    See also\n    --------\n    astropy.io\n        for details on acceptable keyword arguments when writing a\n        :class:`~astropy.table.Table` to HDF5\n    \"\"\"\n    if path:\n        try:\n            parent = output[path]\n        except KeyError:\n            parent = output.create_group(path)\n    else:\n        parent = output\n\n    for name in flags:\n        # handle existing group\n        if name in parent:\n            if not (overwrite and append):\n                raise IOError(\"Group '%s' already exists, give ``append=True, \"\n                              \"overwrite=True`` to overwrite it\"\n                              % os.path.join(parent.name, name))\n            del parent[name]\n        # create group\n        group = parent.create_group(name)\n        # write flag\n        write_hdf5_flag_group(flags[name], group, **kwargs)", "response": "Write this DataQualityFlag to a HDF5 - format file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a DataQualityFlag to an HDF5 file.", "response": "def write_hdf5_flag(flag, output, path=None, **kwargs):\n    \"\"\"Write a `DataQualityFlag` to an HDF5 file/group\n    \"\"\"\n    # verify path (default to flag name)\n    if path is None:\n        path = flag.name\n    if path is None:\n        raise ValueError(\"Cannot determine target group name for flag in HDF5 \"\n                         \"structure, please set `name` for each flag, or \"\n                         \"specify the ``path`` keyword when writing\")\n\n    return write_hdf5_dict({path: flag}, output, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_hdf5_segmentlist(seglist, output, path=None, **kwargs):\n    if path is None:\n        raise ValueError(\"Please specify the HDF5 path via the \"\n                         \"``path=`` keyword argument\")\n\n    # convert segmentlist to Table\n    data = numpy.zeros((len(seglist), 4), dtype=int)\n    for i, seg in enumerate(seglist):\n        start, end = map(LIGOTimeGPS, seg)\n        data[i, :] = (start.gpsSeconds, start.gpsNanoSeconds,\n                      end.gpsSeconds, end.gpsNanoSeconds)\n    segtable = Table(data, names=['start_time', 'start_time_ns',\n                                  'end_time', 'end_time_ns'])\n\n    # write table to HDF5\n    return segtable.write(output, path=path, format='hdf5', **kwargs)", "response": "Write a segmentlist to an HDF5 file or group of segments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a floating point number to a latex representation.", "response": "def float_to_latex(x, format=\"%.2g\"):  # pylint: disable=redefined-builtin\n    # pylint: disable=anomalous-backslash-in-string\n    r\"\"\"Convert a floating point number to a latex representation.\n\n    In particular, scientific notation is handled gracefully: e -> 10^\n\n    Parameters\n    ----------\n    x : `float`\n        the number to represent\n\n    format : `str`, optional\n        the output string format\n\n    Returns\n    -------\n    tex : `str`\n        a TeX representation of the input\n\n    Examples\n    --------\n    >>> from gwpy.plot.tex import float_to_latex\n    >>> float_to_latex(1)\n    '1'\n    >>> float_to_latex(2000)\n    '2\\times 10^{3}'\n    >>> float_to_latex(100)\n    '10^{2}'\n    >>> float_to_latex(-500)\n    r'-5\\!\\!\\times\\!\\!10^{2}'\n    \"\"\"\n    if x == 0.:\n        return '0'\n    base_str = format % x\n    if \"e\" not in base_str:\n        return base_str\n    mantissa, exponent = base_str.split(\"e\")\n    if float(mantissa).is_integer():\n        mantissa = int(float(mantissa))\n    exponent = exponent.lstrip(\"0+\")\n    if exponent.startswith('-0'):\n        exponent = '-' + exponent[2:]\n    if float(mantissa) == 1.0:\n        return r\"10^{%s}\" % exponent\n    return r\"%s\\!\\!\\times\\!\\!10^{%s}\" % (mantissa, exponent)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef label_to_latex(text):\n    # pylint: disable=anomalous-backslash-in-string\n    r\"\"\"Convert text into a latex-passable representation.\n\n    This method just escapes the following reserved LaTeX characters:\n    % \\ _ ~ &, whilst trying to avoid doubly-escaping already escaped\n    characters\n\n    Parameters\n    ----------\n    text : `str`\n        input text to convert\n\n    Returns\n    -------\n    tex : `str`\n        a modified version of the input text with all unescaped reserved\n        latex characters escaped\n\n    Examples\n    --------\n    >>> from gwpy.plot.tex import label_to_latex\n    >>> label_to_latex('normal text')\n    'normal text'\n    >>> label_to_latex('$1 + 2 = 3$')\n    '$1 + 2 = 3$'\n    >>> label_to_latex('H1:ABC-DEF_GHI')\n    'H1:ABC-DEF\\\\_GHI'\n    >>> label_to_latex('H1:ABC-DEF\\_GHI')\n    'H1:ABC-DEF\\\\_GHI'\n    \"\"\"\n    if text is None:\n        return ''\n    out = []\n    x = None\n    # loop over matches in reverse order and replace\n    for m in re_latex_control.finditer(text):\n        a, b = m.span()\n        char = m.group()[0]\n        out.append(text[x:a])\n        out.append(r'\\%s' % char)\n        x = b\n    if not x:  # no match\n        return text\n    # append prefix and return joined components\n    out.append(text[b:])\n    return ''.join(out)", "response": "Convert text into a latex - passable representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preformat_cache(cache, start=None, end=None):\n    # open cache file\n    if isinstance(cache, FILE_LIKE + string_types):\n        return read_cache(cache, sort=file_segment,\n                          segment=Segment(start, end))\n\n    # format existing cache file\n    cache = type(cache)(cache)  # copy cache\n\n    # sort cache\n    try:\n        cache.sort(key=file_segment)  # sort\n    except ValueError:\n        # if this failed, then the sieving will also fail, but lets proceed\n        # anyway, since the user didn't actually ask us to do this (but\n        # its a very good idea)\n        return cache\n\n    # sieve cache\n    if start is None:  # start time of earliest file\n        start = file_segment(cache[0])[0]\n    if end is None:  # end time of latest file\n        end = file_segment(cache[-1])[-1]\n    return sieve(cache, segment=Segment(start, end))", "response": "Preprocess a list of file paths for reading."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a tqdm progress bar", "response": "def progress_bar(**kwargs):\n    \"\"\"Create a `tqdm.tqdm` progress bar\n\n    This is just a thin wrapper around `tqdm.tqdm` to set some updated defaults\n    \"\"\"\n    tqdm_kw = {\n        'desc': 'Processing',\n        'file': sys.stdout,\n        'bar_format': TQDM_BAR_FORMAT,\n    }\n    tqdm_kw.update(kwargs)\n    pbar = tqdm(**tqdm_kw)\n    if not pbar.disable:\n        pbar.desc = pbar.desc.rstrip(': ')\n        pbar.refresh()\n    return pbar"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the number of taps for a given filter with the given sample rate transitionwidth gpass and gstop", "response": "def num_taps(sample_rate, transitionwidth, gpass, gstop):\n    \"\"\"Returns the number of taps for an FIR filter with the given shape\n\n    Parameters\n    ----------\n    sample_rate : `float`\n        sampling rate of target data\n\n    transitionwidth : `float`\n        the width (in the same units as `sample_rate` of the transition\n        from stop-band to pass-band\n\n    gpass : `float`\n        the maximum loss in the passband (dB)\n\n    gstop : `float`\n        the minimum attenuation in the stopband (dB)\n\n    Returns\n    -------\n    numtaps : `int`\n       the number of taps for an FIR filter\n\n    Notes\n    -----\n    Credit: http://dsp.stackexchange.com/a/31077/8223\n    \"\"\"\n    gpass = 10 ** (-gpass / 10.)\n    gstop = 10 ** (-gstop / 10.)\n    return int(2/3. * log10(1 / (10 * gpass * gstop)) *\n               sample_rate / transitionwidth)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_zpk(zpktup):\n    return (\n        isinstance(zpktup, (tuple, list)) and\n        len(zpktup) == 3 and\n        isinstance(zpktup[0], (list, tuple, numpy.ndarray)) and\n        isinstance(zpktup[1], (list, tuple, numpy.ndarray)) and\n        isinstance(zpktup[2], float))", "response": "Determines whether the given tuple is a ZPK - format filter definition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef truncate_impulse(impulse, ntaps, window='hanning'):\n    out = impulse.copy()\n    trunc_start = int(ntaps / 2)\n    trunc_stop = out.size - trunc_start\n    window = signal.get_window(window, ntaps)\n    out[0:trunc_start] *= window[trunc_start:ntaps]\n    out[trunc_stop:out.size] *= window[0:trunc_start]\n    out[trunc_start:trunc_stop] = 0\n    return out", "response": "Smoothly truncate a time domain impulse response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fir_from_transfer(transfer, ntaps, window='hanning', ncorner=None):\n    # truncate and highpass the transfer function\n    transfer = truncate_transfer(transfer, ncorner=ncorner)\n    # compute and truncate the impulse response\n    impulse = npfft.irfft(transfer)\n    impulse = truncate_impulse(impulse, ntaps=ntaps, window=window)\n    # wrap around and normalise to construct the filter\n    out = numpy.roll(impulse, int(ntaps/2 - 1))[0:ntaps]\n    return out", "response": "Design a type II FIR filter given an arbitrary transfer function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bilinear_zpk(zeros, poles, gain, fs=1.0, unit='Hz'):\n    zeros = numpy.array(zeros, dtype=float, copy=False)\n    zeros = zeros[numpy.isfinite(zeros)]\n    poles = numpy.array(poles, dtype=float, copy=False)\n    gain = gain\n\n    # convert from Hz to rad/s if needed\n    unit = Unit(unit)\n    if unit == Unit('Hz'):\n        zeros *= -2 * pi\n        poles *= -2 * pi\n    elif unit != Unit('rad/s'):\n        raise ValueError(\"zpk can only be given with unit='Hz' \"\n                         \"or 'rad/s'\")\n\n    # convert to Z-domain via bilinear transform\n    fs = 2 * Quantity(fs, 'Hz').value\n    dpoles = (1 + poles/fs) / (1 - poles/fs)\n    dzeros = (1 + zeros/fs) / (1 - zeros/fs)\n    dzeros = numpy.concatenate((\n        dzeros, -numpy.ones(len(dpoles) - len(dzeros)),\n    ))\n    dgain = gain * numpy.prod(fs - zeros)/numpy.prod(fs - poles)\n    return dzeros, dpoles, dgain", "response": "Convert an analogue ZPK filter to digital using a bilinear transform"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse arbitrary input args into a TF or ZPK filter definition.", "response": "def parse_filter(args, analog=False, sample_rate=None):\n    \"\"\"Parse arbitrary input args into a TF or ZPK filter definition\n\n    Parameters\n    ----------\n    args : `tuple`, `~scipy.signal.lti`\n        filter definition, normally just captured positional ``*args``\n        from a function call\n\n    analog : `bool`, optional\n        `True` if filter definition has analogue coefficients\n\n    sample_rate : `float`, optional\n        sampling frequency at which to convert analogue filter to digital\n        via bilinear transform, required if ``analog=True``\n\n    Returns\n    -------\n    ftype : `str`\n        either ``'ba'`` or ``'zpk'``\n    filt : `tuple`\n        the filter components for the returned `ftype`, either a 2-tuple\n        for with transfer function components, or a 3-tuple for ZPK\n    \"\"\"\n    if analog and not sample_rate:\n        raise ValueError(\"Must give sample_rate frequency to convert \"\n                         \"analog filter to digital\")\n\n    # unpack filter\n    if isinstance(args, tuple) and len(args) == 1:\n        # either packed defintion ((z, p, k)) or simple definition (lti,)\n        args = args[0]\n\n    # parse FIR filter\n    if isinstance(args, numpy.ndarray) and args.ndim == 1:  # fir\n        b, a = args, [1.]\n        if analog:\n            return 'ba', signal.bilinear(b, a)\n        return 'ba', (b, a)\n\n    # parse IIR filter\n    if isinstance(args, LinearTimeInvariant):\n        lti = args\n    elif (isinstance(args, numpy.ndarray) and\n            args.ndim == 2 and args.shape[1] == 6):\n        lti = signal.lti(*signal.sos2zpk(args))\n    else:\n        lti = signal.lti(*args)\n\n    # convert to zpk format\n    try:\n        lti = lti.to_zpk()\n    except AttributeError:  # scipy < 0.18, doesn't matter\n        pass\n\n    # convert to digital components\n    if analog:\n        return 'zpk', bilinear_zpk(lti.zeros, lti.poles, lti.gain,\n                                   fs=sample_rate)\n    # return zpk\n    return 'zpk', (lti.zeros, lti.poles, lti.gain)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lowpass(frequency, sample_rate, fstop=None, gpass=2, gstop=30, type='iir',\n            **kwargs):\n    \"\"\"Design a low-pass filter for the given cutoff frequency\n\n    Parameters\n    ----------\n    frequency : `float`\n        corner frequency of low-pass filter (Hertz)\n\n    sample_rate : `float`\n        sampling rate of target data (Hertz)\n\n    fstop : `float`, optional\n        edge-frequency of stop-band (Hertz)\n\n    gpass : `float`, optional, default: 2\n        the maximum loss in the passband (dB)\n\n    gstop : `float`, optional, default: 30\n        the minimum attenuation in the stopband (dB)\n\n    type : `str`, optional, default: ``'iir'``\n        the filter type, either ``'iir'`` or ``'fir'``\n\n    **kwargs\n        other keyword arguments are passed directly to\n        :func:`~scipy.signal.iirdesign` or :func:`~scipy.signal.firwin`\n\n    Returns\n    -------\n    filter\n        the formatted filter. the output format for an IIR filter depends\n        on the input arguments, default is a tuple of `(zeros, poles, gain)`\n\n    Notes\n    -----\n    By default a digital filter is returned, meaning the zeros and poles\n    are given in the Z-domain in units of radians/sample.\n\n    Examples\n    --------\n    To create a low-pass filter at 1000 Hz for 4096 Hz-sampled data:\n\n    >>> from gwpy.signal.filter_design import lowpass\n    >>> lp = lowpass(1000, 4096)\n\n    To view the filter, you can use the `~gwpy.plot.BodePlot`:\n\n    >>> from gwpy.plot import BodePlot\n    >>> plot = BodePlot(lp, sample_rate=4096)\n    >>> plot.show()\n    \"\"\"\n    sample_rate = _as_float(sample_rate)\n    frequency = _as_float(frequency)\n    if fstop is None:\n        fstop = min(frequency * 1.5, sample_rate/2.)\n    if type == 'iir':\n        return _design_iir(frequency, fstop, sample_rate, gpass, gstop,\n                           **kwargs)\n    return _design_fir(frequency, fstop, sample_rate, gpass, gstop, **kwargs)", "response": "Design a low - pass filter for the given frequency sample_rate gpass and gstop."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef highpass(frequency, sample_rate, fstop=None, gpass=2, gstop=30, type='iir',\n             **kwargs):\n    \"\"\"Design a high-pass filter for the given cutoff frequency\n\n    Parameters\n    ----------\n    frequency : `float`\n        corner frequency of high-pass filter\n\n    sample_rate : `float`\n        sampling rate of target data\n\n    fstop : `float`, optional\n        edge-frequency of stop-band\n\n    gpass : `float`, optional, default: 2\n        the maximum loss in the passband (dB)\n\n    gstop : `float`, optional, default: 30\n        the minimum attenuation in the stopband (dB)\n\n    type : `str`, optional, default: ``'iir'``\n        the filter type, either ``'iir'`` or ``'fir'``\n\n    **kwargs\n        other keyword arguments are passed directly to\n        :func:`~scipy.signal.iirdesign` or :func:`~scipy.signal.firwin`\n\n    Returns\n    -------\n    filter\n        the formatted filter. the output format for an IIR filter depends\n        on the input arguments, default is a tuple of `(zeros, poles, gain)`\n\n    Notes\n    -----\n    By default a digital filter is returned, meaning the zeros and poles\n    are given in the Z-domain in units of radians/sample.\n\n    Examples\n    --------\n    To create a high-pass filter at 100 Hz for 4096 Hz-sampled data:\n\n    >>> from gwpy.signal.filter_design import highpass\n    >>> hp = highpass(100, 4096)\n\n    To view the filter, you can use the `~gwpy.plot.BodePlot`:\n\n    >>> from gwpy.plot import BodePlot\n    >>> plot = BodePlot(hp, sample_rate=4096)\n    >>> plot.show()\n    \"\"\"\n    sample_rate = _as_float(sample_rate)\n    frequency = _as_float(frequency)\n    if fstop is None:\n        fstop = frequency * 2/3.\n    if type == 'iir':\n        return _design_iir(frequency, fstop, sample_rate, gpass, gstop,\n                           **kwargs)\n    return _design_fir(frequency, fstop, sample_rate, gpass, gstop,\n                       **kwargs)", "response": "Design a high - pass filter for the given cutoff frequency sample_rate gpass and gstop."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndesign a band - pass filter for the given cutoff frequencies.", "response": "def bandpass(flow, fhigh, sample_rate, fstop=None, gpass=2, gstop=30,\n             type='iir', **kwargs):\n    \"\"\"Design a band-pass filter for the given cutoff frequencies\n\n    Parameters\n    ----------\n    flow : `float`\n        lower corner frequency of pass band\n\n    fhigh : `float`\n        upper corner frequency of pass band\n\n    sample_rate : `float`\n        sampling rate of target data\n\n    fstop : `tuple` of `float`, optional\n        `(low, high)` edge-frequencies of stop band\n\n    gpass : `float`, optional, default: 2\n        the maximum loss in the passband (dB)\n\n    gstop : `float`, optional, default: 30\n        the minimum attenuation in the stopband (dB)\n\n    type : `str`, optional, default: ``'iir'``\n        the filter type, either ``'iir'`` or ``'fir'``\n\n    **kwargs\n        other keyword arguments are passed directly to\n        :func:`~scipy.signal.iirdesign` or :func:`~scipy.signal.firwin`\n\n    Returns\n    -------\n    filter\n        the formatted filter. the output format for an IIR filter depends\n        on the input arguments, default is a tuple of `(zeros, poles, gain)`\n\n    Notes\n    -----\n    By default a digital filter is returned, meaning the zeros and poles\n    are given in the Z-domain in units of radians/sample.\n\n    Examples\n    --------\n    To create a band-pass filter for 100-1000 Hz for 4096 Hz-sampled data:\n\n    >>> from gwpy.signal.filter_design import bandpass\n    >>> bp = bandpass(100, 1000, 4096)\n\n    To view the filter, you can use the `~gwpy.plot.BodePlot`:\n\n    >>> from gwpy.plot import BodePlot\n    >>> plot = BodePlot(bp, sample_rate=4096)\n    >>> plot.show()\n    \"\"\"\n    sample_rate = _as_float(sample_rate)\n    flow = _as_float(flow)\n    fhigh = _as_float(fhigh)\n    if fstop is None:\n        fstop = (flow * 2/3.,\n                 min(fhigh * 1.5, sample_rate/2.))\n    fstop = (_as_float(fstop[0]), _as_float(fstop[1]))\n    if type == 'iir':\n        return _design_iir((flow, fhigh), fstop, sample_rate, gpass, gstop,\n                           **kwargs)\n    return _design_fir((flow, fhigh), fstop, sample_rate, gpass, gstop,\n                       pass_zero=False, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndesign a ZPK notch filter for the given frequency and sampling rate.", "response": "def notch(frequency, sample_rate, type='iir', **kwargs):\n    \"\"\"Design a ZPK notch filter for the given frequency and sampling rate\n\n    Parameters\n    ----------\n    frequency : `float`, `~astropy.units.Quantity`\n        frequency (default in Hertz) at which to apply the notch\n    sample_rate : `float`, `~astropy.units.Quantity`\n        number of samples per second for `TimeSeries` to which this notch\n        filter will be applied\n    type : `str`, optional, default: 'iir'\n        type of filter to apply, currently only 'iir' is supported\n    **kwargs\n        other keyword arguments to pass to `scipy.signal.iirdesign`\n\n    Returns\n    -------\n    zpk : `tuple` of `complex` or `float`\n       the filter components in digital zero-pole-gain format\n\n    See Also\n    --------\n    scipy.signal.iirdesign\n        for details on the IIR filter design method\n\n    Notes\n    -----\n    By default a digital filter is returned, meaning the zeros and poles\n    are given in the Z-domain in units of radians/sample.\n\n    Examples\n    --------\n    To create a low-pass filter at 1000 Hz for 4096 Hz-sampled data:\n\n    >>> from gwpy.signal.filter_design import notch\n    >>> n = notch(100, 4096)\n\n    To view the filter, you can use the `~gwpy.plot.BodePlot`:\n\n    >>> from gwpy.plot import BodePlot\n    >>> plot = BodePlot(n, sample_rate=4096)\n    >>> plot.show()\n    \"\"\"\n    frequency = Quantity(frequency, 'Hz').value\n    sample_rate = Quantity(sample_rate, 'Hz').value\n    nyq = 0.5 * sample_rate\n    df = 1.0  # pylint: disable=invalid-name\n    df2 = 0.1\n    low1 = (frequency - df)/nyq\n    high1 = (frequency + df)/nyq\n    low2 = (frequency - df2)/nyq\n    high2 = (frequency + df2)/nyq\n    if type == 'iir':\n        kwargs.setdefault('gpass', 1)\n        kwargs.setdefault('gstop', 10)\n        kwargs.setdefault('ftype', 'ellip')\n        return signal.iirdesign([low1, high1], [low2, high2], output='zpk',\n                                **kwargs)\n    else:\n        raise NotImplementedError(\"Generating %r notch filters has not been \"\n                                  \"implemented yet\" % type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconcatenates a list of zero - pole - gain ( ZPKs.", "response": "def concatenate_zpks(*zpks):\n    \"\"\"Concatenate a list of zero-pole-gain (ZPK) filters\n\n    Parameters\n    ----------\n    *zpks\n        one or more zero-pole-gain format, each one should be a 3-`tuple`\n        containing an array of zeros, an array of poles, and a gain `float`\n\n    Returns\n    -------\n    zeros : `numpy.ndarray`\n        the concatenated array of zeros\n    poles : `numpy.ndarray`\n        the concatenated array of poles\n    gain : `float`\n        the overall gain\n\n    Examples\n    --------\n    Create a lowpass and a highpass filter, and combine them:\n\n    >>> from gwpy.signal.filter_design import (\n    ...     highpass, lowpass, concatenate_zpks)\n    >>> hp = highpass(100, 4096)\n    >>> lp = lowpass(1000, 4096)\n    >>> zpk = concatenate_zpks(hp, lp)\n\n    Plot the filter:\n\n    >>> from gwpy.plot import BodePlot\n    >>> plot = BodePlot(zpk, sample_rate=4096)\n    >>> plot.show()\n    \"\"\"\n    zeros, poles, gains = zip(*zpks)\n    return (numpy.concatenate(zeros),\n            numpy.concatenate(poles),\n            reduce(operator.mul, gains, 1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef welch(timeseries, segmentlength, noverlap=None, **kwargs):\n    # calculate PSD\n    freqs, psd_ = scipy.signal.welch(\n        timeseries.value,\n        noverlap=noverlap,\n        fs=timeseries.sample_rate.decompose().value,\n        nperseg=segmentlength,\n        **kwargs\n    )\n    # generate FrequencySeries and return\n    unit = scale_timeseries_unit(\n        timeseries.unit,\n        kwargs.get('scaling', 'density'),\n    )\n    return FrequencySeries(\n        psd_,\n        unit=unit,\n        frequencies=freqs,\n        name=timeseries.name,\n        epoch=timeseries.epoch,\n        channel=timeseries.channel,\n    )", "response": "Calculate a PSD of this TimeSeries using Welch s method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bartlett(timeseries, segmentlength, **kwargs):\n    kwargs.pop('noverlap', None)\n    return welch(timeseries, segmentlength, noverlap=0, **kwargs)", "response": "Calculate a PSD using Bartlett s method\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef median(timeseries, segmentlength, **kwargs):\n    if scipy_version <= '1.1.9999':\n        raise ValueError(\n            \"median average PSD estimation requires scipy >= 1.2.0\",\n        )\n    kwargs.setdefault('average', 'median')\n    return welch(timeseries, segmentlength, **kwargs)", "response": "Calculate a PSD using Welch s method with a median average\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates a Rayleigh statistic spectrum of a single average segment.", "response": "def rayleigh(timeseries, segmentlength, noverlap=0):\n    \"\"\"Calculate a Rayleigh statistic spectrum\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n    \"\"\"\n    stepsize = segmentlength - noverlap\n    if noverlap:\n        numsegs = 1 + int((timeseries.size - segmentlength) / float(noverlap))\n    else:\n        numsegs = int(timeseries.size // segmentlength)\n    tmpdata = numpy.ndarray((numsegs, int(segmentlength//2 + 1)))\n    for i in range(numsegs):\n        tmpdata[i, :] = welch(\n            timeseries[i*stepsize:i*stepsize+segmentlength],\n            segmentlength)\n    std = tmpdata.std(axis=0)\n    mean = tmpdata.mean(axis=0)\n    return FrequencySeries(std/mean, unit='', copy=False, f0=0,\n                           epoch=timeseries.epoch,\n                           df=timeseries.sample_rate.value/segmentlength,\n                           channel=timeseries.channel,\n                           name='Rayleigh spectrum of %s' % timeseries.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef csd(timeseries, other, segmentlength, noverlap=None, **kwargs):\n    # calculate CSD\n    try:\n        freqs, csd_ = scipy.signal.csd(\n            timeseries.value, other.value, noverlap=noverlap,\n            fs=timeseries.sample_rate.decompose().value,\n            nperseg=segmentlength, **kwargs)\n    except AttributeError as exc:\n        exc.args = ('{}, scipy>=0.16 is required'.format(str(exc)),)\n        raise\n\n    # generate FrequencySeries and return\n    unit = scale_timeseries_unit(timeseries.unit,\n                                 kwargs.get('scaling', 'density'))\n    return FrequencySeries(\n        csd_, unit=unit, frequencies=freqs,\n        name=str(timeseries.name)+'---'+str(other.name),\n        epoch=timeseries.epoch, channel=timeseries.channel)", "response": "Calculate the CSD of two TimeSeries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(cls, source, *args, **kwargs):\n        from .io.core import read as timeseries_reader\n        return timeseries_reader(cls, source, *args, **kwargs)", "response": "Read data into a TimeSeries object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches data from NDS data channel", "response": "def fetch(cls, channel, start, end, host=None, port=None, verbose=False,\n              connection=None, verify=False, pad=None, allow_tape=None,\n              scaled=None, type=None, dtype=None):\n        \"\"\"Fetch data from NDS\n\n        Parameters\n        ----------\n        channel : `str`, `~gwpy.detector.Channel`\n            the data channel for which to query\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS start time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS end time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        host : `str`, optional\n            URL of NDS server to use, if blank will try any server\n            (in a relatively sensible order) to get the data\n\n        port : `int`, optional\n            port number for NDS server query, must be given with `host`\n\n        verify : `bool`, optional, default: `False`\n            check channels exist in database before asking for data\n\n        scaled : `bool`, optional\n            apply slope and bias calibration to ADC data, for non-ADC data\n            this option has no effect\n\n        connection : `nds2.connection`, optional\n            open NDS connection to use\n\n        verbose : `bool`, optional\n            print verbose output about NDS progress, useful for debugging;\n            if ``verbose`` is specified as a string, this defines the\n            prefix for the progress meter\n\n        type : `int`, optional\n            NDS2 channel type integer\n\n        dtype : `type`, `numpy.dtype`, `str`, optional\n            identifier for desired output data type\n        \"\"\"\n        return cls.DictClass.fetch(\n            [channel], start, end, host=host, port=port, verbose=verbose,\n            connection=connection, verify=verify, pad=pad, scaled=scaled,\n            allow_tape=allow_tape, type=type, dtype=dtype)[str(channel)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_open_data(cls, ifo, start, end, sample_rate=4096,\n                        tag=None, version=None,\n                        format='hdf5', host=GWOSC_DEFAULT_HOST,\n                        verbose=False, cache=None, **kwargs):\n        \"\"\"Fetch open-access data from the LIGO Open Science Center\n\n        Parameters\n        ----------\n        ifo : `str`\n            the two-character prefix of the IFO in which you are interested,\n            e.g. `'L1'`\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS start time of required data, defaults to start of data found;\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS end time of required data, defaults to end of data found;\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        sample_rate : `float`, optional,\n            the sample rate of desired data; most data are stored\n            by LOSC at 4096 Hz, however there may be event-related\n            data releases with a 16384 Hz rate, default: `4096`\n\n        tag : `str`, optional\n            file tag, e.g. ``'CLN'`` to select cleaned data, or ``'C00'``\n            for 'raw' calibrated data.\n\n        version : `int`, optional\n            version of files to download, defaults to highest discovered\n            version\n\n        format : `str`, optional\n            the data format to download and parse, default: ``'h5py'``\n\n            - ``'hdf5'``\n            - ``'gwf'`` - requires |LDAStools.frameCPP|_\n\n        host : `str`, optional\n            HTTP host name of LOSC server to access\n\n        verbose : `bool`, optional, default: `False`\n            print verbose output while fetching data\n\n        cache : `bool`, optional\n            save/read a local copy of the remote URL, default: `False`;\n            useful if the same remote data are to be accessed multiple times.\n            Set `GWPY_CACHE=1` in the environment to auto-cache.\n\n        **kwargs\n            any other keyword arguments are passed to the `TimeSeries.read`\n            method that parses the file that was downloaded\n\n        Examples\n        --------\n        >>> from gwpy.timeseries import (TimeSeries, StateVector)\n        >>> print(TimeSeries.fetch_open_data('H1', 1126259446, 1126259478))\n        TimeSeries([  2.17704028e-19,  2.08763900e-19,  2.39681183e-19,\n                    ...,   3.55365541e-20,  6.33533516e-20,\n                      7.58121195e-20]\n                   unit: Unit(dimensionless),\n                   t0: 1126259446.0 s,\n                   dt: 0.000244140625 s,\n                   name: Strain,\n                   channel: None)\n        >>> print(StateVector.fetch_open_data('H1', 1126259446, 1126259478))\n        StateVector([127,127,127,127,127,127,127,127,127,127,127,127,\n                     127,127,127,127,127,127,127,127,127,127,127,127,\n                     127,127,127,127,127,127,127,127]\n                    unit: Unit(dimensionless),\n                    t0: 1126259446.0 s,\n                    dt: 1.0 s,\n                    name: Data quality,\n                    channel: None,\n                    bits: Bits(0: data present\n                               1: passes cbc CAT1 test\n                               2: passes cbc CAT2 test\n                               3: passes cbc CAT3 test\n                               4: passes burst CAT1 test\n                               5: passes burst CAT2 test\n                               6: passes burst CAT3 test,\n                               channel=None,\n                               epoch=1126259446.0))\n\n        For the `StateVector`, the naming of the bits will be\n        ``format``-dependent, because they are recorded differently by LOSC\n        in different formats.\n\n        For events published in O2 and later, LOSC typically provides\n        multiple data sets containing the original (``'C00'``) and cleaned\n        (``'CLN'``) data.\n        To select both data sets and plot a comparison, for example:\n\n        >>> orig = TimeSeries.fetch_open_data('H1', 1187008870, 1187008896,\n        ...                                   tag='C00')\n        >>> cln = TimeSeries.fetch_open_data('H1', 1187008870, 1187008896,\n        ...                                  tag='CLN')\n        >>> origasd = orig.asd(fftlength=4, overlap=2)\n        >>> clnasd = cln.asd(fftlength=4, overlap=2)\n        >>> plot = origasd.plot(label='Un-cleaned')\n        >>> ax = plot.gca()\n        >>> ax.plot(clnasd, label='Cleaned')\n        >>> ax.set_xlim(10, 1400)\n        >>> ax.set_ylim(1e-24, 1e-20)\n        >>> ax.legend()\n        >>> plot.show()\n\n        Notes\n        -----\n        `StateVector` data are not available in ``txt.gz`` format.\n        \"\"\"\n        from .io.losc import fetch_losc_data\n        return fetch_losc_data(ifo, start, end, sample_rate=sample_rate,\n                               tag=tag, version=version, format=format,\n                               verbose=verbose, cache=cache,\n                               host=host, cls=cls, **kwargs)", "response": "Fetch open - access data from the LIGO Open Science Center."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(cls, channel, start, end, frametype=None, pad=None,\n             scaled=None, dtype=None, nproc=1, verbose=False, **readargs):\n        \"\"\"Find and read data from frames for a channel\n\n        Parameters\n        ----------\n        channel : `str`, `~gwpy.detector.Channel`\n            the name of the channel to read, or a `Channel` object.\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS start time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS end time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        frametype : `str`, optional\n            name of frametype in which this channel is stored, will search\n            for containing frame types if necessary\n\n        pad : `float`, optional\n            value with which to fill gaps in the source data,\n            by default gaps will result in a `ValueError`.\n\n        scaled : `bool`, optional\n            apply slope and bias calibration to ADC data, for non-ADC data\n            this option has no effect.\n\n        nproc : `int`, optional, default: `1`\n            number of parallel processes to use, serial process by\n            default.\n\n        dtype : `numpy.dtype`, `str`, `type`, or `dict`\n            numeric data type for returned data, e.g. `numpy.float`, or\n            `dict` of (`channel`, `dtype`) pairs\n\n        allow_tape : `bool`, optional, default: `True`\n            allow reading from frame files on (slow) magnetic tape\n\n        verbose : `bool`, optional\n            print verbose output about read progress, if ``verbose``\n            is specified as a string, this defines the prefix for the\n            progress meter\n\n        **readargs\n            any other keyword arguments to be passed to `.read()`\n        \"\"\"\n        return cls.DictClass.find(\n            [channel], start, end,\n            frametype=frametype,\n            verbose=verbose,\n            pad=pad,\n            scaled=scaled,\n            dtype=dtype,\n            nproc=nproc,\n            **readargs\n        )[str(channel)]", "response": "Find and read data from frames for a specific channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting data for this channel from frames or NDS2 server.", "response": "def get(cls, channel, start, end, pad=None, scaled=None,\n            dtype=None, verbose=False, allow_tape=None, **kwargs):\n        \"\"\"Get data for this channel from frames or NDS\n\n        This method dynamically accesses either frames on disk, or a\n        remote NDS2 server to find and return data for the given interval\n\n        Parameters\n        ----------\n        channel : `str`, `~gwpy.detector.Channel`\n            the name of the channel to read, or a `Channel` object.\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS start time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`\n            GPS end time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        pad : `float`, optional\n            value with which to fill gaps in the source data,\n            by default gaps will result in a `ValueError`.\n\n        scaled : `bool`, optional\n            apply slope and bias calibration to ADC data, for non-ADC data\n            this option has no effect\n\n        dtype : `numpy.dtype`, `str`, `type`, or `dict`\n            numeric data type for returned data, e.g. `numpy.float`, or\n            `dict` of (`channel`, `dtype`) pairs\n\n        nproc : `int`, optional, default: `1`\n            number of parallel processes to use, serial process by\n            default.\n\n        allow_tape : `bool`, optional, default: `None`\n            allow the use of frames that are held on tape, default is `None`\n            to attempt to allow the `TimeSeries.fetch` method to\n            intelligently select a server that doesn't use tapes for\n            data storage (doesn't always work), but to eventually allow\n            retrieving data from tape if required\n\n        verbose : `bool`, optional\n            print verbose output about data access progress, if ``verbose``\n            is specified as a string, this defines the prefix for the\n            progress meter\n\n        **kwargs\n            other keyword arguments to pass to either\n            :meth:`.find` (for direct GWF file access) or\n            :meth:`.fetch` for remote NDS2 access\n\n        See Also\n        --------\n        TimeSeries.fetch\n            for grabbing data from a remote NDS2 server\n        TimeSeries.find\n            for discovering and reading data from local GWF files\n        \"\"\"\n        return cls.DictClass.get(\n            [channel], start, end, pad=pad, scaled=scaled, dtype=dtype,\n            verbose=verbose, allow_tape=allow_tape, **kwargs)[str(channel)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the data for this timeseries", "response": "def plot(self, method='plot', figsize=(12, 4), xscale='auto-gps',\n             **kwargs):\n        \"\"\"Plot the data for this timeseries\n\n        Returns\n        -------\n        figure : `~matplotlib.figure.Figure`\n            the newly created figure, with populated Axes.\n\n        See Also\n        --------\n        matplotlib.pyplot.figure\n            for documentation of keyword arguments used to create the\n            figure\n        matplotlib.figure.Figure.add_subplot\n            for documentation of keyword arguments used to create the\n            axes\n        matplotlib.axes.Axes.plot\n            for documentation of keyword arguments used in rendering the data\n        \"\"\"\n        kwargs.update(figsize=figsize, xscale=xscale)\n        return super(TimeSeriesBase, self).plot(method=method, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_nds2_buffer(cls, buffer_, scaled=None, copy=True, **metadata):\n        # get Channel from buffer\n        channel = Channel.from_nds2(buffer_.channel)\n\n        # set default metadata\n        metadata.setdefault('channel', channel)\n        metadata.setdefault('epoch', LIGOTimeGPS(buffer_.gps_seconds,\n                                                 buffer_.gps_nanoseconds))\n        metadata.setdefault('sample_rate', channel.sample_rate)\n        metadata.setdefault('unit', channel.unit)\n        metadata.setdefault('name', buffer_.name)\n\n        # unwrap data\n        scaled = _dynamic_scaled(scaled, channel.name)\n        slope = buffer_.signal_slope\n        offset = buffer_.signal_offset\n        null_scaling = slope == 1. and offset == 0.\n        if scaled and not null_scaling:\n            data = buffer_.data.copy() * slope + offset\n            copy = False\n        else:\n            data = buffer_.data\n\n        # construct new TimeSeries-like object\n        return cls(data, copy=copy, **metadata)", "response": "Construct a new TimeSeries from an NDS2 - client buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_lal(cls, lalts, copy=True):\n        from ..utils.lal import from_lal_unit\n        try:\n            unit = from_lal_unit(lalts.sampleUnits)\n        except (TypeError, ValueError) as exc:\n            warnings.warn(\"%s, defaulting to 'dimensionless'\" % str(exc))\n            unit = None\n        channel = Channel(lalts.name, sample_rate=1/lalts.deltaT, unit=unit,\n                          dtype=lalts.data.data.dtype)\n        out = cls(lalts.data.data, channel=channel, t0=lalts.epoch,\n                  dt=lalts.deltaT, unit=unit, name=lalts.name, copy=False)\n        if copy:\n            return out.copy()\n        return out", "response": "Generate a new TimeSeries from a LAL TimeSeries of any type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting this TimeSeries into a LAL TimeSeries.", "response": "def to_lal(self):\n        \"\"\"Convert this `TimeSeries` into a LAL TimeSeries.\n        \"\"\"\n        import lal\n        from ..utils.lal import (find_typed_function, to_lal_unit)\n\n        # map unit\n        try:\n            unit = to_lal_unit(self.unit)\n        except ValueError as e:\n            warnings.warn(\"%s, defaulting to lal.DimensionlessUnit\" % str(e))\n            unit = lal.DimensionlessUnit\n\n        # create TimeSeries\n        create = find_typed_function(self.dtype, 'Create', 'TimeSeries')\n        lalts = create(self.name, lal.LIGOTimeGPS(self.epoch.gps), 0,\n                       self.dt.value, unit, self.shape[0])\n        lalts.data.data = self.value\n        return lalts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a PyCBC Series into a TimeSeries", "response": "def from_pycbc(cls, pycbcseries, copy=True):\n        \"\"\"Convert a `pycbc.types.timeseries.TimeSeries` into a `TimeSeries`\n\n        Parameters\n        ----------\n        pycbcseries : `pycbc.types.timeseries.TimeSeries`\n            the input PyCBC `~pycbc.types.timeseries.TimeSeries` array\n\n        copy : `bool`, optional, default: `True`\n            if `True`, copy these data to a new array\n\n        Returns\n        -------\n        timeseries : `TimeSeries`\n            a GWpy version of the input timeseries\n        \"\"\"\n        return cls(pycbcseries.data, t0=pycbcseries.start_time,\n                   dt=pycbcseries.delta_t, copy=copy)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert this TimeSeries into a PyCBC object.", "response": "def to_pycbc(self, copy=True):\n        \"\"\"Convert this `TimeSeries` into a PyCBC\n        `~pycbc.types.timeseries.TimeSeries`\n\n        Parameters\n        ----------\n        copy : `bool`, optional, default: `True`\n            if `True`, copy these data to a new array\n\n        Returns\n        -------\n        timeseries : `~pycbc.types.timeseries.TimeSeries`\n            a PyCBC representation of this `TimeSeries`\n        \"\"\"\n        from pycbc import types\n        return types.TimeSeries(self.value,\n                                delta_t=self.dt.to('s').value,\n                                epoch=self.epoch.gps, copy=copy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges contiguous elements of this list into single objects.", "response": "def coalesce(self):\n        \"\"\"Merge contiguous elements of this list into single objects\n\n        This method implicitly sorts and potentially shortens this list.\n        \"\"\"\n        self.sort(key=lambda ts: ts.t0.value)\n        i = j = 0\n        N = len(self)\n        while j < N:\n            this = self[j]\n            j += 1\n            if j < N and this.is_contiguous(self[j]) == 1:\n                while j < N and this.is_contiguous(self[j]):\n                    try:\n                        this = self[i] = this.append(self[j])\n                    except ValueError as exc:\n                        if 'cannot resize this array' in str(exc):\n                            this = this.copy()\n                            this = self[i] = this.append(self[j])\n                        else:\n                            raise\n                    j += 1\n            else:\n                self[i] = this\n            i += 1\n        del self[i:]\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconcatenate all of the elements of this list into a single object containing all data from each individual entry in the individual.", "response": "def join(self, pad=None, gap=None):\n        \"\"\"Concatenate all of the elements of this list into a single object\n\n        Parameters\n        ----------\n        pad : `float`, optional, default: `0.0`\n            value with which to pad gaps\n\n        gap : `str`, optional, default: `'raise'`\n            what to do if there are gaps in the data, one of\n\n            - ``'raise'`` - raise a `ValueError`\n            - ``'ignore'`` - remove gap and join data\n            - ``'pad'`` - pad gap with zeros\n\n            If `pad` is given and is not `None`, the default is ``'pad'``,\n            otherwise ``'raise'``.\n\n        Returns\n        -------\n        series : `gwpy.types.TimeSeriesBase` subclass\n             a single series containing all data from each entry in this list\n\n        See Also\n        --------\n        TimeSeries.append\n            for details on how the individual series are concatenated together\n        \"\"\"\n        if not self:\n            return self.EntryClass(numpy.empty((0,) * self.EntryClass._ndim))\n        self.sort(key=lambda t: t.epoch.gps)\n        out = self[0].copy()\n        for series in self[1:]:\n            out.append(series, gap=gap, pad=pad)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n        out = type(self)()\n        for series in self:\n            out.append(series.copy())\n        return out", "response": "Return a copy of this list with each element copied to new memory\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_lal_type_str(pytype):\n    # noop\n    if pytype in LAL_TYPE_FROM_STR:\n        return pytype\n\n    # convert type code\n    if pytype in LAL_TYPE_STR:\n        return LAL_TYPE_STR[pytype]\n\n    # convert python type\n    try:\n        dtype = numpy.dtype(pytype)\n        return LAL_TYPE_STR_FROM_NUMPY[dtype.type]\n    except (TypeError, KeyError):\n        raise ValueError(\"Failed to map {!r} to LAL type string\")", "response": "Convert the input python type to a LAL type string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the lal method for the correct type", "response": "def find_typed_function(pytype, prefix, suffix, module=lal):\n    \"\"\"Returns the lal method for the correct type\n\n    Parameters\n    ----------\n    pytype : `type`, `numpy.dtype`\n        the python type, or dtype, to map\n\n    prefix : `str`\n        the function name prefix (before the type tag)\n\n    suffix : `str`\n        the function name suffix (after the type tag)\n\n    Raises\n    ------\n    AttributeError\n        if the function is not found\n\n    Examples\n    --------\n    >>> from gwpy.utils.lal import find_typed_function\n    >>> find_typed_function(float, 'Create', 'Sequence')\n    <built-in function CreateREAL8Sequence>\n    \"\"\"\n    laltype = to_lal_type_str(pytype)\n    return getattr(module, '{0}{1}{2}'.format(prefix, laltype, suffix))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the input unit into a LALUnit.", "response": "def to_lal_unit(aunit):\n    \"\"\"Convert the input unit into a `LALUnit`\n\n    For example::\n\n       >>> u = to_lal_unit('m**2 / kg ** 4')\n       >>> print(u)\n       m^2 kg^-4\n\n    Parameters\n    ----------\n    aunit : `~astropy.units.Unit`, `str`\n        the input unit\n\n    Returns\n    -------\n    unit : `LALUnit`\n        the LALUnit representation of the input\n\n    Raises\n    ------\n    ValueError\n        if LAL doesn't understand the base units for the input\n    \"\"\"\n    if isinstance(aunit, string_types):\n        aunit = units.Unit(aunit)\n    aunit = aunit.decompose()\n    lunit = lal.Unit()\n    for base, power in zip(aunit.bases, aunit.powers):\n        # try this base\n        try:\n            lalbase = LAL_UNIT_FROM_ASTROPY[base]\n        except KeyError:\n            lalbase = None\n            # otherwise loop through the equivalent bases\n            for eqbase in base.find_equivalent_units():\n                try:\n                    lalbase = LAL_UNIT_FROM_ASTROPY[eqbase]\n                except KeyError:\n                    continue\n        # if we didn't find anything, raise an exception\n        if lalbase is None:\n            raise ValueError(\"LAL has no unit corresponding to %r\" % base)\n        lunit *= lalbase ** power\n    return lunit"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_lal_unit(lunit):\n    return reduce(operator.mul, (\n        units.Unit(str(LAL_UNIT_INDEX[i])) ** exp for\n        i, exp in enumerate(lunit.unitNumerator)))", "response": "Convert a LALUnit into a ~astropy. units. Unit object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_lal_ligotimegps(gps):\n    gps = to_gps(gps)\n    return lal.LIGOTimeGPS(gps.gpsSeconds, gps.gpsNanoSeconds)", "response": "Convert the given GPS time to a SWIG - LAL object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn list of GPS columns required to read GPS properties for a table", "response": "def _get_property_columns(tabletype, columns):\n    \"\"\"Returns list of GPS columns required to read gpsproperties for a table\n\n    Examples\n    --------\n    >>> _get_property_columns(lsctables.SnglBurstTable, ['peak'])\n    ['peak_time', 'peak_time_ns']\n    \"\"\"\n    from ligo.lw.lsctables import gpsproperty as GpsProperty\n    # get properties for row object\n    rowvars = vars(tabletype.RowType)\n    # build list of real column names for fancy properties\n    extracols = {}\n    for key in columns:\n        prop = rowvars[key]\n        if isinstance(prop, GpsProperty):\n            extracols[key] = (prop.s_name, prop.ns_name)\n    return extracols"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_astropy_table(llwtable, apytable, copy=False, columns=None,\n                     use_numpy_dtypes=False, rename=None):\n    \"\"\"Convert a :class:`~ligo.lw.table.Table` to an `~astropy.tableTable`\n\n    This method is designed as an internal method to be attached to\n    :class:`~ligo.lw.table.Table` objects as `__astropy_table__`.\n\n    Parameters\n    ----------\n    llwtable : :class:`~ligo.lw.table.Table`\n        the LIGO_LW table to convert from\n\n    apytable : `type`\n        `astropy.table.Table` class or subclass\n\n    copy : `bool`, optional\n        if `True` copy the input data, otherwise return a reference,\n        default: `False`\n\n    columns : `list` of `str`, optional\n        the columns to populate, if not given, all columns present in the\n        table are mapped\n\n    use_map_dtypes : `bool`, optional\n        force column `dtypes\n\n    rename : `dict`, optional\n        dict of ('old name', 'new name') pairs to rename columns\n        from the original LIGO_LW table\n\n    Returns\n    -------\n    table : `EventTable`\n        a view of the original data\n    \"\"\"\n    # set default keywords\n    if rename is None:\n        rename = {}\n    if columns is None:\n        columns = llwtable.columnnames\n\n    # extract columns from LIGO_LW table as astropy.table.Column\n    data = []\n    for colname in columns:\n        arr = _get_column(llwtable, colname)\n\n        # transform to astropy.table.Column\n        copythis = isinstance(arr, numpy.ndarray)\n        data.append(to_astropy_column(arr, apytable.Column, copy=copythis,\n                                      use_numpy_dtype=use_numpy_dtypes,\n                                      name=rename.get(colname, colname)))\n\n    # build table and return\n    return apytable(data, copy=False, meta={'tablename': str(llwtable.Name)})", "response": "Convert a LIGO_LW table to an astropy table table"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_astropy_column(llwcol, cls, copy=False, dtype=None,\n                      use_numpy_dtype=False, **kwargs):\n    \"\"\"Convert a :class:`~ligo.lw.table.Column` to `astropy.table.Column`\n\n    Parameters\n    -----------\n    llwcol : :class:`~ligo.lw.table.Column`, `numpy.ndarray`, iterable\n        the LIGO_LW column to convert, or an iterable\n\n    cls : `~astropy.table.Column`\n        the Astropy `~astropy.table.Column` or subclass to convert to\n\n    copy : `bool`, optional\n        if `True` copy the input data, otherwise return a reference,\n        default: `False`\n\n    dtype : `type`, optional\n        the data type to convert to when creating the `~astropy.table.Column`\n\n    use_numpy_dtype : `bool`, optional\n        convert object type to numpy dtype, default: `False`, only used\n        with ``dtype=None``\n\n    **kwargs\n        other keyword arguments are passed to the `~astropy.table.Column`\n        creator\n\n    Returns\n    -------\n    column : `~astropy.table.Column`\n        an Astropy version of the given LIGO_LW column\n    \"\"\"\n    if dtype is None:  # try and find dtype\n        dtype = _get_column_dtype(llwcol)\n        if use_numpy_dtype and numpy.dtype(dtype).type is numpy.object_:\n            # dtype maps to 'object' in numpy, try and resolve real numpy type\n            try:\n                dtype = NUMPY_TYPE_MAP[dtype]\n            except KeyError:\n                # try subclass matches (mainly for ilwdchar)\n                for key in NUMPY_TYPE_MAP:\n                    if issubclass(dtype, key):\n                        dtype = NUMPY_TYPE_MAP[key]\n                        break\n                else:  # no subclass matches, raise\n                    raise TypeError(\"no mapping from object type %r to numpy \"\n                                    \"type\" % dtype)\n    try:\n        return cls(data=llwcol, copy=copy, dtype=dtype, **kwargs)\n    except TypeError:\n        # numpy tries to cast ilwdchar to int via long, which breaks\n        if dtype is numpy.int_ and isinstance(llwcol[0], ilwdchar_types):\n            return cls(data=map(dtype, llwcol),\n                       copy=False, dtype=dtype, **kwargs)\n        # any other error, raise\n        raise", "response": "Convert a numpy array or class to an astropy. table. Column"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the data type of a LIGO_LW column.", "response": "def _get_column_dtype(llwcol):\n    \"\"\"Get the data type of a LIGO_LW `Column`\n\n    Parameters\n    ----------\n    llwcol : :class:`~ligo.lw.table.Column`, `numpy.ndarray`, iterable\n        a LIGO_LW column, a numpy array, or an iterable\n\n    Returns\n    -------\n    dtype : `type`, None\n        the object data type for values in the given column, `None` is\n        returned if ``llwcol`` is a `numpy.ndarray` with `numpy.object_`\n        dtype, or no data type can be parsed (e.g. empty list)\n    \"\"\"\n    try:  # maybe its a numpy array already!\n        dtype = llwcol.dtype\n        if dtype is numpy.dtype('O'):  # don't convert\n            raise AttributeError\n        return dtype\n    except AttributeError:  # dang\n        try:  # ligo.lw.table.Column\n            llwtype = llwcol.parentNode.validcolumns[llwcol.Name]\n        except AttributeError:  # not a column\n            try:\n                return type(llwcol[0])\n            except IndexError:\n                return None\n        else:  # map column type str to python type\n            from ligo.lw.types import (ToPyType, ToNumPyType)\n            try:\n                return ToNumPyType[llwtype]\n            except KeyError:\n                return ToPyType[llwtype]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an astropy. table. Table to a LIGO_LW table.", "response": "def table_to_ligolw(table, tablename):\n    \"\"\"Convert a `astropy.table.Table` to a :class:`ligo.lw.table.Table`\n    \"\"\"\n    from ligo.lw import lsctables\n\n    # create new LIGO_LW table\n    columns = table.columns.keys()\n    cls = lsctables.TableByName[tablename]\n    llwcolumns = list(columns)\n    for col, llwcols in _get_property_columns(cls, columns).items():\n        idx = llwcolumns.index(col)\n        llwcolumns.pop(idx)\n        for name in llwcols[::-1]:\n            llwcolumns.insert(idx, name)\n    llwtable = lsctables.New(cls, columns=llwcolumns)\n\n    # map rows across\n    for row in table:\n        llwrow = llwtable.RowType()\n        for name in columns:\n            setattr(llwrow, name,\n                    to_ligolw_table_type(row[name], llwtable, name))\n        llwtable.append(llwrow)\n\n    return llwtable"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a table from one or more LIGO_LW XML documents or a list of tables.", "response": "def read_table(source, tablename=None, **kwargs):\n    \"\"\"Read a `Table` from one or more LIGO_LW XML documents\n\n    source : `file`, `str`, :class:`~ligo.lw.ligolw.Document`, `list`\n        one or more open files, file paths, or LIGO_LW `Document` objects\n\n    tablename : `str`, optional\n        the `Name` of the relevant `Table` to read, if not given a table will\n        be returned if only one exists in the document(s)\n\n    **kwargs\n        keyword arguments for the read, or conversion functions\n\n    See Also\n    --------\n    gwpy.io.ligolw.read_table\n        for details of keyword arguments for the read operation\n    gwpy.table.io.ligolw.to_astropy_table\n        for details of keyword arguments for the conversion operation\n    \"\"\"\n    from ligo.lw import table as ligolw_table\n    from ligo.lw.lsctables import TableByName\n\n    # -- keyword handling -----------------------\n\n    # separate keywords for reading and converting from LIGO_LW to Astropy\n    read_kw = kwargs  # rename for readability\n    convert_kw = {\n        'rename': None,\n        'use_numpy_dtypes': False,\n    }\n    for key in filter(kwargs.__contains__, convert_kw):\n        convert_kw[key] = kwargs.pop(key)\n    if convert_kw['rename'] is None:\n        convert_kw['rename'] = {}\n\n    # allow user to specify LIGO_LW columns to read to provide the\n    # desired output columns\n    try:\n        columns = list(kwargs.pop('columns'))\n    except KeyError:\n        columns = None\n    try:\n        read_kw['columns'] = list(kwargs.pop('ligolw_columns'))\n    except KeyError:\n        read_kw['columns'] = columns\n    convert_kw['columns'] = columns or read_kw['columns']\n\n    if tablename:\n        tableclass = TableByName[ligolw_table.Table.TableName(tablename)]\n        # work out if fancy property columns are required\n        #     means 'peak_time' and 'peak_time_ns' will get read if 'peak'\n        #     is requested\n        if convert_kw['columns'] is not None:\n            readcols = set(read_kw['columns'])\n            propcols = _get_property_columns(tableclass, convert_kw['columns'])\n            for col in propcols:\n                try:\n                    readcols.remove(col)\n                except KeyError:\n                    continue\n                readcols.update(propcols[col])\n            read_kw['columns'] = list(readcols)\n\n    # -- read -----------------------------------\n\n    return Table(read_ligolw_table(source, tablename=tablename, **read_kw),\n                 **convert_kw)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a ~astropy. table. Table to file in LIGO_LW XML format.", "response": "def write_table(table, target, tablename=None, ilwdchar_compat=None,\n                **kwargs):\n    \"\"\"Write a `~astropy.table.Table` to file in LIGO_LW XML format\n\n    This method will attempt to write in the new `ligo.lw` format\n    (if ``ilwdchar_compat`` is ``None`` or ``False``),\n    but will fall back to the older `glue.ligolw` (in that order) if that\n    fails (if ``ilwdchar_compat`` is ``None`` or ``True``).\n    \"\"\"\n    if tablename is None:  # try and get tablename from metadata\n        tablename = table.meta.get('tablename', None)\n    if tablename is None:  # panic\n        raise ValueError(\"please pass ``tablename=`` to specify the target \"\n                         \"LIGO_LW Table Name\")\n    try:\n        llwtable = table_to_ligolw(\n            table,\n            tablename,\n            ilwdchar_compat=ilwdchar_compat or False,\n        )\n    except LigolwElementError as exc:\n        if ilwdchar_compat is not None:\n            raise\n        try:\n            llwtable = table_to_ligolw(table, tablename, ilwdchar_compat=True)\n        except Exception:\n            raise exc\n    return write_ligolw_tables(target, [llwtable], **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_ascii_series(input_, array_type=Series, unpack=True, **kwargs):\n    xarr, yarr = loadtxt(input_, unpack=unpack, **kwargs)\n    return array_type(yarr, xindex=xarr)", "response": "Read a Series from an ASCII file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_ascii_series(series, output, **kwargs):\n    xarr = series.xindex.value\n    yarr = series.value\n    return savetxt(output, column_stack((xarr, yarr)), **kwargs)", "response": "Write a Series to a file in ASCII format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering ascii read and write methods for the given array", "response": "def register_ascii_series_io(array_type, format='txt', identify=True,\n                             **defaults):\n    \"\"\"Register ASCII read/write/identify methods for the given array\n    \"\"\"\n    def _read(filepath, **kwargs):\n        kwgs = defaults.copy()\n        kwgs.update(kwargs)\n        return read_ascii_series(filepath, array_type=array_type, **kwgs)\n\n    def _write(series, output, **kwargs):\n        kwgs = defaults.copy()\n        kwgs.update(kwargs)\n        return write_ascii_series(series, output, **kwgs)\n\n    io_registry.register_reader(format, array_type, _read)\n    io_registry.register_writer(format, array_type, _write)\n    if identify:\n        io_registry.register_identifier(format, array_type,\n                                        identify_factory(format))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef channel_dict_kwarg(value, channels, types=None, astype=None):\n    if types is not None and isinstance(value, tuple(types)):\n        out = dict((c, value) for c in channels)\n    elif isinstance(value, (tuple, list)):\n        out = dict(zip(channels, value))\n    elif value is None:\n        out = dict()\n    elif isinstance(value, dict):\n        out = value.copy()\n    else:\n        return None\n    if astype is not None:\n        return dict((key, astype(out[key])) for key in out)\n    return out", "response": "Format the given kwarg value in a dict with one value per channel key per channel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_default_gwf_api():\n    for lib in APIS:\n        try:\n            import_gwf_library(lib)\n        except ImportError:\n            continue\n        else:\n            return lib\n    raise ImportError(\"no GWF API available, please install a third-party GWF \"\n                      \"library ({}) and try again\".format(', '.join(APIS)))", "response": "Return the preferred GWF API for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a full set of GWF I / O methods for the given frame library.", "response": "def register_gwf_api(library):\n    \"\"\"Register a full set of GWF I/O methods for the given library\n\n    The given frame library must define the following methods\n\n    - `read` : which receives one of more frame files which can be assumed\n               to be contiguous, and should return a `TimeSeriesDict`\n    - `write` : which receives an output frame file path an a `TimeSeriesDict`\n                and does all of the work\n\n    Additionally, the library must store the name of the third-party\n    dependency using the ``FRAME_LIBRARY`` variable.\n    \"\"\"\n    # import library to get details (don't require library to importable)\n    try:\n        lib = import_gwf_library(library)\n    except ImportError:\n        pass  # means any reads will fail at run-time\n    else:\n        libread_ = lib.read\n        libwrite_ = lib.write\n\n    # set I/O format name\n    fmt = 'gwf.%s' % library\n\n    # -- read -----------------------------------\n\n    def read_timeseriesdict(source, channels, start=None, end=None,\n                            dtype=None, resample=None,\n                            gap=None, pad=None, nproc=1,\n                            series_class=TimeSeries, **kwargs):\n        \"\"\"Read the data for a list of channels from a GWF data source\n\n        Parameters\n        ----------\n        source : `str`, `list`\n            Source of data, any of the following:\n\n            - `str` path of single data file,\n            - `str` path of LAL-format cache file,\n            - `list` of paths.\n\n        channels : `list`\n            list of channel names (or `Channel` objects) to read from frame.\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS start time of required data, defaults to start of data found;\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS end time of required data, defaults to end of data found;\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        pad : `float`, optional\n            value with which to fill gaps in the source data, if not\n            given gaps will result in an exception being raised\n\n        Returns\n        -------\n        dict : :class:`~gwpy.timeseries.TimeSeriesDict`\n            dict of (channel, `TimeSeries`) data pairs\n        \"\"\"\n        # import the frame library here to have any ImportErrors occur early\n        import_gwf_library(library)\n\n        # -- from here read data\n\n        if start:\n            start = to_gps(start)\n        if end:\n            end = to_gps(end)\n\n        # parse output format kwargs -- DEPRECATED\n        if resample is not None:\n            warnings.warn('the resample keyword for is deprecated, instead '\n                          'you should manually resample after reading',\n                          DeprecationWarning)\n        if not isinstance(resample, dict):\n            resample = dict((c, resample) for c in channels)\n        if dtype is not None:\n            warnings.warn('the dtype keyword for is deprecated, instead '\n                          'you should manually call astype() after reading',\n                          DeprecationWarning)\n        if not isinstance(dtype, dict):\n            dtype = dict((c, dtype) for c in channels)\n\n        # format gap handling\n        if gap is None and pad is not None:\n            gap = 'pad'\n        elif gap is None:\n            gap = 'raise'\n\n        # read cache file up-front\n        if (isinstance(source, string_types) and\n                source.endswith(('.lcf', '.cache'))) or (\n                    isinstance(source, io_cache.FILE_LIKE) and\n                    source.name.endswith(('.lcf', '.cache'))):\n            source = io_cache.read_cache(source)\n        # separate cache into contiguous segments\n        if io_cache.is_cache(source):\n            if start is not None and end is not None:\n                source = io_cache.sieve(source, segment=Segment(start, end))\n            source = list(io_cache.find_contiguous(source))\n        # convert everything else into a list if needed\n        if not isinstance(source, (list, tuple)):\n            source = [source]\n\n        # now read the data\n        out = series_class.DictClass()\n        for i, src in enumerate(source):\n            if i == 1:  # force data into fresh memory so that append works\n                for name in out:\n                    out[name] = numpy.require(out[name], requirements=['O'])\n            out.append(libread_(src, channels, start=start, end=end,\n                                series_class=series_class, **kwargs),\n                       gap=gap, pad=pad, copy=False)\n\n        # apply resampling and dtype-casting -- DEPRECATED\n        for name in out:\n            if (resample.get(name) and\n                    resample[name] != out[name].sample_rate.value):\n                out[name] = out[name].resample(resample[name])\n            if dtype.get(name) is not None and (\n                    numpy.dtype(dtype[name]) != out[name].dtype):\n                out[name] = out[name].astype(dtype[name])\n        return out\n\n    def read_timeseries(source, channel, *args, **kwargs):\n        \"\"\"Read `TimeSeries` from GWF source\n        \"\"\"\n        return read_timeseriesdict(source, [channel], *args, **kwargs)[channel]\n\n    def read_statevector(source, channel, *args, **kwargs):\n        \"\"\"Read `StateVector` from GWF source\n        \"\"\"\n        bits = kwargs.pop('bits', None)\n        kwargs.setdefault('series_class', StateVector)\n        statevector = read_timeseries(source, channel, *args, **kwargs)\n        statevector.bits = bits\n        return statevector\n\n    def read_statevectordict(source, channels, *args, **kwargs):\n        \"\"\"Read `StateVectorDict` from GWF source\n        \"\"\"\n        bitss = channel_dict_kwarg(kwargs.pop('bits', {}), channels)\n        # read data as timeseriesdict and repackage with bits\n        kwargs.setdefault('series_class', StateVector)\n        svd = StateVectorDict(\n            read_timeseriesdict(source, channels, *args, **kwargs))\n        for (channel, bits) in bitss.items():\n            svd[channel].bits = bits\n        return svd\n\n    # -- write ----------------------------------\n\n    def write_timeseriesdict(data, outfile, start=None, end=None,\n                             name='gwpy', run=0):\n        \"\"\"Write a `TimeSeriesDict` to disk in GWF format\n\n        Parameters\n        ----------\n        tsdict : `TimeSeriesDict`\n            the data to write\n\n        outfile : `str`\n            the path of the output frame file\n\n        start : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS start time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        end : `~gwpy.time.LIGOTimeGPS`, `float`, `str`, optional\n            GPS end time of required data,\n            any input parseable by `~gwpy.time.to_gps` is fine\n\n        name : `str`, optional\n            name of the project that created this GWF\n\n        run : `int`, optional\n            run number to write into frame header\n        \"\"\"\n        # import the frame library here to have any ImportErrors occur early\n        import_gwf_library(library)\n\n        # then write using the relevant API\n        return libwrite_(data, outfile, start=start, end=end,\n                         name=name, run=run)\n\n    def write_timeseries(series, *args, **kwargs):\n        \"\"\"Write a `TimeSeries` to disk in GWF format\n\n        See also\n        --------\n        write_timeseriesdict\n            for available arguments and keyword arguments\n        \"\"\"\n        return write_timeseriesdict({None: series}, *args, **kwargs)\n\n    # -- register -------------------------------\n\n    # register specific format\n    register_reader(fmt, TimeSeriesDict, read_timeseriesdict)\n    register_reader(fmt, TimeSeries, read_timeseries)\n    register_reader(fmt, StateVectorDict, read_statevectordict)\n    register_reader(fmt, StateVector, read_statevector)\n    register_writer(fmt, TimeSeriesDict, write_timeseriesdict)\n    register_writer(fmt, TimeSeries, write_timeseries)\n    register_writer(fmt, StateVectorDict, write_timeseriesdict)\n    register_writer(fmt, StateVector, write_timeseries)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_gwf_format(container):\n    def read_(*args, **kwargs):\n        fmt = 'gwf.{}'.format(get_default_gwf_api())\n        reader = get_reader(fmt, container)\n        return reader(*args, **kwargs)\n\n    def write_(*args, **kwargs):\n        fmt = 'gwf.{}'.format(get_default_gwf_api())\n        writer = get_writer(fmt, container)\n        return writer(*args, **kwargs)\n\n    register_identifier('gwf', container, identify_gwf)\n    register_reader('gwf', container, read_)\n    register_writer('gwf', container, write_)", "response": "Register I / O methods for format = gfw"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a parameter for the current resource.", "response": "def set_parameter(connection, parameter, value, verbose=False):\n    \"\"\"Set a parameter for the connection, handling errors as warnings\n    \"\"\"\n    value = str(value)\n    try:\n        if not connection.set_parameter(parameter, value):\n            raise ValueError(\"invalid parameter or value\")\n    except (AttributeError, ValueError) as exc:\n        warnings.warn(\n            'failed to set {}={!r}: {}'.format(parameter, value, str(exc)),\n            io_nds2.NDSWarning)\n    else:\n        print_verbose(\n            '    [{}] set {}={!r}'.format(\n                connection.get_host(), parameter, value),\n            verbose=verbose,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches a dict of data series from NDS2 database.", "response": "def fetch(channels, start, end, type=None, dtype=None, allow_tape=None,\n          connection=None, host=None, port=None, pad=None, scaled=True,\n          verbose=False, series_class=TimeSeries):\n    # host and port keywords are used by the decorator only\n    # pylint: disable=unused-argument\n    \"\"\"Fetch a dict of data series from NDS2\n\n    This method sits underneath `TimeSeries.fetch` and related methods,\n    and isn't really designed to be called directly.\n    \"\"\"\n    # set ALLOW_DATA_ON_TAPE\n    if allow_tape is not None:\n        set_parameter(connection, 'ALLOW_DATA_ON_TAPE', str(allow_tape),\n                      verbose=verbose)\n\n    type = _parse_nds_enum_dict_param(channels, 'type', type)\n    dtype = _parse_nds_enum_dict_param(channels, 'dtype', dtype)\n\n    # verify channels exist\n    print_verbose(\"Checking channels list against NDS2 database...\", end=' ',\n                  verbose=verbose)\n    utype = reduce(operator.or_, type.values())  # logical OR of types\n    udtype = reduce(operator.or_, dtype.values())\n    epoch = (start, end) if connection.get_protocol() > 1 else None\n    ndschannels = io_nds2.find_channels(channels, connection=connection,\n                                        epoch=epoch, type=utype, dtype=udtype,\n                                        unique=True)\n\n    names = [Channel.from_nds2(c).ndsname for c in ndschannels]\n    print_verbose('done', verbose=verbose)\n\n    # handle minute trend timing\n    if (any(c.endswith('m-trend') for c in names) and\n            (start % 60 or end % 60)):\n        warnings.warn(\"Requested at least one minute trend, but \"\n                      \"start and stop GPS times are not multiples of \"\n                      \"60. Times will be expanded outwards to compensate\")\n        start, end = io_nds2.minute_trend_times(start, end)\n\n    # get data availability\n    span = SegmentList([Segment(start, end)])\n    if pad is None:\n        qsegs = span\n        gap = 'raise'\n    elif connection.get_protocol() == 1:\n        qsegs = span\n        gap = 'pad'\n    else:\n        print_verbose(\"Querying for data availability...\", end=' ',\n                      verbose=verbose)\n        pad = float(pad)\n        gap = 'pad'\n        qsegs = _get_data_segments(ndschannels, start, end, connection) & span\n        print_verbose('done\\nFound {0} viable segments of data with {1:.2f}% '\n                      'coverage'.format(len(qsegs),\n                                        abs(qsegs) / abs(span) * 100),\n                      verbose=verbose)\n        if span - qsegs:\n            warnings.warn(\"Gaps were found in data available from {0}, \"\n                          \"but will be padded with {1}\".format(\n                              connection.get_host(), pad))\n\n    # query for each segment\n    out = series_class.DictClass()\n    desc = verbose if isinstance(verbose, str) else 'Downloading data'\n    with progress_bar(total=float(abs(qsegs)), desc=desc,\n                      unit='s', disable=not bool(verbose)) as bar:\n        for seg in qsegs:\n            total = 0.\n            for buffers in connection.iterate(int(seg[0]), int(seg[1]), names):\n                for buffer_, chan in zip(buffers, channels):\n                    series = series_class.from_nds2_buffer(\n                        buffer_,\n                        scaled=scaled,\n                        copy=chan not in out,  # only copy if first buffer\n                    )\n                    out.append({chan: series}, pad=pad, gap=gap)\n                new = buffer_.length / buffer_.channel.sample_rate\n                total += new\n                bar.update(new)\n            # sometimes NDS2 returns no data at all\n            if not total and gap != 'pad':\n                raise RuntimeError(\"no data received from {0} for {1}\".format(\n                    connection.get_host(), seg))\n\n    # finalise timeseries to make sure each channel has the correct limits\n    # only if user asked to pad gaps\n    if pad is not None:\n        for chan, ndschan in zip(channels, ndschannels):\n            try:\n                ts = out[chan]\n            except KeyError:\n                out[chan] = _create_series(ndschan, pad, start, end,\n                                           series_class=series_class)\n            else:\n                out[chan] = _pad_series(ts, pad, start, end)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npad a timeseries to match the specified start and end limits", "response": "def _pad_series(ts, pad, start, end):\n    \"\"\"Pad a timeseries to match the specified [start, end) limits\n\n    To cover a gap in data returned from NDS\n    \"\"\"\n    span = ts.span\n    pada = max(int((span[0] - start) * ts.sample_rate.value), 0)\n    padb = max(int((end - span[1]) * ts.sample_rate.value), 0)\n    if pada or padb:\n        return ts.pad((pada, padb), mode='constant', constant_values=(pad,))\n    return ts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a timeseries to cover the specified start and end limits", "response": "def _create_series(ndschan, value, start, end, series_class=TimeSeries):\n    \"\"\"Create a timeseries to cover the specified [start, end) limits\n\n    To cover a gap in data returned from NDS\n    \"\"\"\n    channel = Channel.from_nds2(ndschan)\n    nsamp = int((end - start) * channel.sample_rate.value)\n    return series_class(numpy_ones(nsamp) * value, t0=start,\n                        sample_rate=channel.sample_rate, unit=channel.unit,\n                        channel=channel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_data_segments(channels, start, end, connection):\n    allsegs = io_nds2.get_availability(channels, start, end,\n                                       connection=connection)\n    return allsegs.intersection(allsegs.keys())", "response": "Get the data segments for the given channels"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef in_git_clone():\n    gitdir = '.git'\n    return os.path.isdir(gitdir) and (\n        os.path.isdir(os.path.join(gitdir, 'objects')) and\n        os.path.isdir(os.path.join(gitdir, 'refs')) and\n        os.path.exists(os.path.join(gitdir, 'HEAD'))\n    )", "response": "Returns True if the current directory is a git repository and if the current directory is a git repository and if the current directory is a git repository and if the current directory is a git repository and the current directory is a git repository and the current directory is a git repository and the current directory is a git repository."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if a distribution file can be reused otherwise it should be regenerated", "response": "def reuse_dist_file(filename):\n    \"\"\"Returns `True` if a distribution file can be reused\n\n    Otherwise it should be regenerated\n    \"\"\"\n    # if target file doesn't exist, we must generate it\n    if not os.path.isfile(filename):\n        return False\n\n    # if we can interact with git, we can regenerate it, so we may as well\n    try:\n        import git\n    except ImportError:\n        return True\n    else:\n        try:\n            git.Repo().tags\n        except (TypeError, git.GitError):\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the required version of GitPython", "response": "def get_gitpython_version():\n    \"\"\"Determine the required version of GitPython\n\n    Because of target systems running very, very old versions of setuptools,\n    we only specify the actual version we need when we need it.\n    \"\"\"\n    # if not in git clone, it doesn't matter\n    if not in_git_clone():\n        return 'GitPython'\n\n    # otherwise, call out to get the git version\n    try:\n        gitv = subprocess.check_output('git --version', shell=True)\n    except (OSError, IOError, subprocess.CalledProcessError):\n        # no git installation, most likely\n        git_version = '0.0.0'\n    else:\n        if isinstance(gitv, bytes):\n            gitv = gitv.decode('utf-8')\n        git_version = gitv.strip().split()[2]\n\n    # if git>=2.15, we need GitPython>=2.1.8\n    if LooseVersion(git_version) >= '2.15':\n        return 'GitPython>=2.1.8'\n    return 'GitPython'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_setup_requires():\n    # don't force requirements if just asking for help\n    if {'--help', '--help-commands'}.intersection(sys.argv):\n        return list()\n\n    # otherwise collect all requirements for all known commands\n    reqlist = []\n    for cmd, dependencies in SETUP_REQUIRES.items():\n        if cmd in sys.argv:\n            reqlist.extend(dependencies)\n\n    return reqlist", "response": "Return the list of packages required for this setup. py run\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all files under the scripts_dir.", "response": "def get_scripts(scripts_dir='bin'):\n    \"\"\"Get relative file paths for all files under the ``scripts_dir``\n    \"\"\"\n    scripts = []\n    for (dirname, _, filenames) in os.walk(scripts_dir):\n        scripts.extend([os.path.join(dirname, fn) for fn in filenames])\n    return scripts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_years(years):\n    result = []\n    for part in years.split(','):\n        if '-' in part:\n            a, b = part.split('-')\n            a, b = int(a), int(b)\n            result.extend(range(a, b + 1))\n        else:\n            a = int(part)\n            result.append(a)\n    return result", "response": "Parse string of ints include ranges into a list of int"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _format_years(years):\n    def sub(x):\n        return x[1] - x[0]\n\n    ranges = []\n    for k, iterable in groupby(enumerate(sorted(years)), sub):\n        rng = list(iterable)\n        if len(rng) == 1:\n            s = str(rng[0][1])\n        else:\n            s = \"{}-{}\".format(rng[0][1], rng[-1][1])\n        ranges.append(s)\n    return \", \".join(ranges)", "response": "Format a list of ints into a string including ranges"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_copyright(path, year):\n    with open(path, \"r\") as fobj:\n        text = fobj.read().rstrip()\n    match = COPYRIGHT_REGEX.search(text)\n    x = match.start(\"years\")\n    y = match.end(\"years\")\n    if text[y-1] == \" \":  # don't strip trailing whitespace\n        y -= 1\n    yearstr = match.group(\"years\")\n    years = set(_parse_years(yearstr)) | {year}\n    with open(path, \"w\") as fobj:\n        print(text[:x] + _format_years(years) + text[y:], file=fobj)", "response": "Update a file s copyright statement to include the given year"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates a new SpectralVariance from a list of spectrograms.", "response": "def from_spectrogram(cls, *spectrograms, **kwargs):\n        \"\"\"Calculate a new `SpectralVariance` from a\n        :class:`~gwpy.spectrogram.Spectrogram`\n\n        Parameters\n        ----------\n        spectrogram : `~gwpy.spectrogram.Spectrogram`\n            input `Spectrogram` data\n\n        bins : `~numpy.ndarray`, optional\n            array of histogram bin edges, including the rightmost edge\n\n        low : `float`, optional\n            left edge of lowest amplitude bin, only read\n            if ``bins`` is not given\n\n        high : `float`, optional\n            right edge of highest amplitude bin, only read\n            if ``bins`` is not given\n\n        nbins : `int`, optional\n            number of bins to generate, only read if ``bins`` is not\n            given, default: `500`\n\n        log : `bool`, optional\n            calculate amplitude bins over a logarithmic scale, only\n            read if ``bins`` is not given, default: `False`\n\n        norm : `bool`, optional\n            normalise bin counts to a unit sum, default: `False`\n\n        density : `bool`, optional\n            normalise bin counts to a unit integral, default: `False`\n\n        Returns\n        -------\n        specvar : `SpectralVariance`\n            2D-array of spectral frequency-amplitude counts\n\n        See Also\n        --------\n        :func:`numpy.histogram`\n            for details on specifying bins and weights\n        \"\"\"\n        # parse args and kwargs\n        if not spectrograms:\n            raise ValueError(\"Must give at least one Spectrogram\")\n        bins = kwargs.pop('bins', None)\n        low = kwargs.pop('low', None)\n        high = kwargs.pop('high', None)\n        nbins = kwargs.pop('nbins', 500)\n        log = kwargs.pop('log', False)\n        norm = kwargs.pop('norm', False)\n        density = kwargs.pop('density', False)\n        if norm and density:\n            raise ValueError(\"Cannot give both norm=True and density=True, \"\n                             \"please pick one\")\n\n        # get data and bins\n        spectrogram = spectrograms[0]\n        data = numpy.vstack(s.value for s in spectrograms)\n        if bins is None:\n            if low is None and log:\n                low = numpy.log10(data.min() / 2)\n            elif low is None:\n                low = data.min()/2\n            elif log:\n                low = numpy.log10(low)\n            if high is None and log:\n                high = numpy.log10(data.max() * 2)\n            elif high is None:\n                high = data.max() * 2\n            elif log:\n                high = numpy.log10(high)\n            if log:\n                bins = numpy.logspace(low, high, num=nbins+1)\n            else:\n                bins = numpy.linspace(low, high, num=nbins+1)\n        nbins = bins.size-1\n        bins = bins * spectrogram.unit\n\n        # loop over frequencies\n        out = numpy.zeros((data.shape[1], nbins))\n        for i in range(data.shape[1]):\n            out[i, :], bins = numpy.histogram(data[:, i], bins,\n                                              density=density)\n            if norm and out[i, :].sum():  # normalise\n                out[i, :] /= out[i, :].sum()\n\n        # return SpectralVariance\n        name = '%s variance' % spectrogram.name\n        new = cls(out, bins, epoch=spectrogram.epoch, name=name,\n                  channel=spectrogram.channel, f0=spectrogram.f0,\n                  df=spectrogram.df)\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating a given spectral percentile for this SpectralVariance object.", "response": "def percentile(self, percentile):\n        \"\"\"Calculate a given spectral percentile for this `SpectralVariance`\n\n        Parameters\n        ----------\n        percentile : `float`\n            percentile (0 - 100) of the bins to compute\n\n        Returns\n        -------\n        spectrum : `~gwpy.frequencyseries.FrequencySeries`\n            the given percentile `FrequencySeries` calculated from this\n            `SpectralVaraicence`\n        \"\"\"\n        rows, columns = self.shape\n        out = numpy.zeros(rows)\n        # Loop over frequencies\n        for i in range(rows):\n            # Calculate cumulative sum for array\n            cumsumvals = numpy.cumsum(self.value[i, :])\n\n            # Find value nearest requested percentile\n            abs_cumsumvals_minus_percentile = numpy.abs(cumsumvals -\n                                                        percentile)\n            minindex = abs_cumsumvals_minus_percentile.argmin()\n            val = self.bins[minindex]\n            out[i] = val\n\n        name = '%s %s%% percentile' % (self.name, percentile)\n        return FrequencySeries(out, epoch=self.epoch, channel=self.channel,\n                               frequencies=self.bins[:-1], name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of this channel as stored in the NDS database.", "response": "def ndsname(self):\n        \"\"\"Name of this channel as stored in the NDS database\n        \"\"\"\n        if self.type not in [None, 'raw', 'reduced', 'online']:\n            return '%s,%s' % (self.name, self.type)\n        return self.name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the LIGO Channel Information System for the given name.", "response": "def query(cls, name, use_kerberos=None, debug=False):\n        \"\"\"Query the LIGO Channel Information System for the `Channel`\n        matching the given name\n\n        Parameters\n        ----------\n        name : `str`\n            name of channel\n\n        use_kerberos : `bool`, optional\n            use an existing Kerberos ticket as the authentication credential,\n            default behaviour will check for credentials and request username\n            and password if none are found (`None`)\n\n        debug : `bool`, optional\n            print verbose HTTP connection status for debugging,\n            default: `False`\n\n        Returns\n        -------\n        c : `Channel`\n             a new `Channel` containing all of the attributes set from\n             its entry in the CIS\n        \"\"\"\n        channellist = ChannelList.query(name, use_kerberos=use_kerberos,\n                                        debug=debug)\n        if not channellist:\n            raise ValueError(\"No channels found matching '%s'\" % name)\n        if len(channellist) > 1:\n            raise ValueError(\"%d channels found matching '%s', please refine \"\n                             \"search, or use `ChannelList.query` to return \"\n                             \"all results\" % (len(channellist), name))\n        return channellist[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_nds2(cls, name, host=None, port=None, connection=None,\n                   type=None):\n        \"\"\"Query an NDS server for channel information\n\n        Parameters\n        ----------\n        name : `str`\n            name of requested channel\n        host : `str`, optional\n            name of NDS2 server.\n        port : `int`, optional\n            port number for NDS2 connection\n        connection : `nds2.connection`\n            open connection to use for query\n        type : `str`, `int`\n            NDS2 channel type with which to restrict query\n\n        Returns\n        -------\n        channel : `Channel`\n            channel with metadata retrieved from NDS2 server\n\n        Raises\n        ------\n        ValueError\n            if multiple channels are found for a given name\n\n        Notes\n        -----\n        .. warning::\n\n           A `host` is required if an open `connection` is not given\n        \"\"\"\n        return ChannelList.query_nds2([name], host=host, port=port,\n                                      connection=connection, type=type,\n                                      unique=True)[0]", "response": "Query an NDS server for channel information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a new channel using an existing nds2. channel object.", "response": "def from_nds2(cls, nds2channel):\n        \"\"\"Generate a new channel using an existing nds2.channel object\n        \"\"\"\n        # extract metadata\n        name = nds2channel.name\n        sample_rate = nds2channel.sample_rate\n        unit = nds2channel.signal_units\n        if not unit:\n            unit = None\n        ctype = nds2channel.channel_type_to_string(nds2channel.channel_type)\n        # get dtype\n        dtype = {  # pylint: disable: no-member\n            nds2channel.DATA_TYPE_INT16: numpy.int16,\n            nds2channel.DATA_TYPE_INT32: numpy.int32,\n            nds2channel.DATA_TYPE_INT64: numpy.int64,\n            nds2channel.DATA_TYPE_FLOAT32: numpy.float32,\n            nds2channel.DATA_TYPE_FLOAT64: numpy.float64,\n            nds2channel.DATA_TYPE_COMPLEX32: numpy.complex64,\n        }.get(nds2channel.data_type)\n        return cls(name, sample_rate=sample_rate, unit=unit, dtype=dtype,\n                   type=ctype)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecompose a channel name into its components and return a dict of the channel name components.", "response": "def parse_channel_name(cls, name, strict=True):\n        \"\"\"Decompose a channel name string into its components\n\n        Parameters\n        ----------\n        name : `str`\n            name to parse\n        strict : `bool`, optional\n            require exact matching of format, with no surrounding text,\n            default `True`\n\n        Returns\n        -------\n        match : `dict`\n            `dict` of channel name components with the following keys:\n\n            - `'ifo'`: the letter-number interferometer prefix\n            - `'system'`: the top-level system name\n            - `'subsystem'`: the second-level sub-system name\n            - `'signal'`: the remaining underscore-delimited signal name\n            - `'trend'`: the trend type\n            - `'ndstype'`: the NDS2 channel suffix\n\n            Any optional keys that aren't found will return a value of `None`\n\n        Raises\n        ------\n        ValueError\n            if the name cannot be parsed with at least an IFO and SYSTEM\n\n        Examples\n        --------\n        >>> Channel.parse_channel_name('L1:LSC-DARM_IN1_DQ')\n        {'ifo': 'L1',\n         'ndstype': None,\n         'signal': 'IN1_DQ',\n         'subsystem': 'DARM',\n         'system': 'LSC',\n         'trend': None}\n\n        >>> Channel.parse_channel_name(\n            'H1:ISI-BS_ST1_SENSCOR_GND_STS_X_BLRMS_100M_300M.rms,m-trend')\n        {'ifo': 'H1',\n         'ndstype': 'm-trend',\n         'signal': 'ST1_SENSCOR_GND_STS_X_BLRMS_100M_300M',\n         'subsystem': 'BS',\n         'system': 'ISI',\n         'trend': 'rms'}\n        \"\"\"\n        match = cls.MATCH.search(name)\n        if match is None or (strict and (\n                match.start() != 0 or match.end() != len(name))):\n            raise ValueError(\"Cannot parse channel name according to LIGO \"\n                             \"channel-naming convention T990033\")\n        return match.groupdict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_frametype(self, gpstime=None, frametype_match=None,\n                       host=None, port=None, return_all=False,\n                       allow_tape=True):\n        \"\"\"Find the containing frametype(s) for this `Channel`\n\n        Parameters\n        ----------\n        gpstime : `int`\n            a reference GPS time at which to search for frame files\n        frametype_match : `str`\n            a regular expression string to use to down-select from the\n            list of all available frametypes\n        host : `str`\n            the name of the datafind server to use for frame file discovery\n        port : `int`\n            the port of the datafind server on the given host\n        return_all: `bool`, default: `False`\n            return all matched frame types, otherwise only the first match is\n            returned\n        allow_tape : `bool`, default: `True`\n            include frame files on (slow) magnetic tape in the search\n\n        Returns\n        -------\n        frametype : `str`, `list`\n            the first matching frametype containing the this channel\n            (`return_all=False`, or a `list` of all matches\n        \"\"\"\n        return datafind.find_frametype(\n            self, gpstime=gpstime, frametype_match=frametype_match,\n            host=host, port=port, return_all=return_all,\n            allow_tape=allow_tape)", "response": "Find the frametype of this Channel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a copy of this channel", "response": "def copy(self):\n        \"\"\"Returns a copy of this channel\n        \"\"\"\n        new = type(self)(str(self))\n        new._init_from_channel(self)\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new ChannelList from a list of names.", "response": "def from_names(cls, *names):\n        \"\"\"Create a new `ChannelList` from a list of names\n\n        The list of names can include comma-separated sets of names,\n        in which case the return will be a flattened list of all parsed\n        channel names.\n        \"\"\"\n        new = cls()\n        for namestr in names:\n            for name in cls._split_names(namestr):\n                new.append(Channel(name))\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a comma - separated list of channel names.", "response": "def _split_names(namestr):\n        \"\"\"Split a comma-separated list of channel names.\n        \"\"\"\n        out = []\n        namestr = QUOTE_REGEX.sub('', namestr)\n        while True:\n            namestr = namestr.strip('\\' \\n')\n            if ',' not in namestr:\n                break\n            for nds2type in io_nds2.Nds2ChannelType.names() + ['']:\n                if nds2type and ',%s' % nds2type in namestr:\n                    try:\n                        channel, ctype, namestr = namestr.split(',', 2)\n                    except ValueError:\n                        channel, ctype = namestr.split(',')\n                        namestr = ''\n                    out.append('%s,%s' % (channel, ctype))\n                    break\n                elif nds2type == '' and ',' in namestr:\n                    channel, namestr = namestr.split(',', 1)\n                    out.append(channel)\n                    break\n        if namestr:\n            out.append(namestr)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, name):\n        for i, chan in enumerate(self):\n            if name == chan.name:\n                return i\n        raise ValueError(name)", "response": "Find the first Channel with a specific name in this ChannelList."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new list containing all the Channels <Channel > objects matching the specified criteria.", "response": "def sieve(self, name=None, sample_rate=None, sample_range=None,\n              exact_match=False, **others):\n        \"\"\"Find all `Channels <Channel>` in this list matching the\n        specified criteria.\n\n        Parameters\n        ----------\n        name : `str`, or regular expression\n            any part of the channel name against which to match\n            (or full name if `exact_match=False` is given)\n        sample_rate : `float`\n            rate (number of samples per second) to match exactly\n        sample_range : 2-`tuple`\n            `[low, high]` closed interval or rates to match within\n        exact_match : `bool`\n            return channels matching `name` exactly, default: `False`\n\n        Returns\n        -------\n        new : `ChannelList`\n            a new `ChannelList` containing the matching channels\n        \"\"\"\n        # format name regex\n        if isinstance(name, Pattern):\n            flags = name.flags\n            name = name.pattern\n        else:\n            flags = 0\n        if exact_match:\n            name = name if name.startswith(r'\\A') else r\"\\A%s\" % name\n            name = name if name.endswith(r'\\Z') else r\"%s\\Z\" % name\n        name_regexp = re.compile(name, flags=flags)\n\n        matched = list(self)\n\n        if name is not None:\n            matched = [entry for entry in matched if\n                       name_regexp.search(entry.name) is not None]\n\n        if sample_rate is not None:\n            sample_rate = (sample_rate.value if\n                           isinstance(sample_rate, units.Quantity) else\n                           float(sample_rate))\n            matched = [entry for entry in matched if entry.sample_rate and\n                       entry.sample_rate.value == sample_rate]\n\n        if sample_range is not None:\n            matched = [entry for entry in matched if\n                       sample_range[0] <= entry.sample_rate.value <=\n                       sample_range[1]]\n\n        for attr, val in others.items():\n            if val is not None:\n                matched = [entry for entry in matched if\n                           (hasattr(entry, attr) and\n                            getattr(entry, attr) == val)]\n\n        return self.__class__(matched)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying the LIGO Channel Information System a ChannelList.", "response": "def query(cls, name, use_kerberos=None, debug=False):\n        \"\"\"Query the LIGO Channel Information System a `ChannelList`.\n\n        Parameters\n        ----------\n        name : `str`\n            name of channel, or part of it.\n\n        use_kerberos : `bool`, optional\n            use an existing Kerberos ticket as the authentication credential,\n            default behaviour will check for credentials and request username\n            and password if none are found (`None`)\n\n        debug : `bool`, optional\n            print verbose HTTP connection status for debugging,\n            default: `False`\n\n        Returns\n        -------\n        channels : `ChannelList`\n            a new list containing all `Channels <Channel>` found.\n        \"\"\"\n        from .io import cis\n        return cis.query(name, use_kerberos=use_kerberos, debug=debug)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying an NDS server for channel information.", "response": "def query_nds2(cls, names, host=None, port=None, connection=None,\n                   type=io_nds2.Nds2ChannelType.any(), unique=False):\n        \"\"\"Query an NDS server for channel information\n\n        Parameters\n        ----------\n        name : `str`\n            name of requested channel\n        host : `str`, optional\n            name of NDS2 server.\n        port : `int`, optional\n            port number for NDS2 connection\n        connection : `nds2.connection`\n            open connection to use for query\n        type : `str`, `int`\n            NDS2 channel type with which to restrict query\n        unique : `bool`, optional\n            require a unique query result for each name given, default `False`\n\n        Returns\n        -------\n        channellist : `ChannelList`\n            list of `Channels <Channel>` with metadata retrieved from\n            NDS2 server\n\n        Raises\n        ------\n        ValueError\n            if multiple channels are found for a given name and `unique=True`\n            is given\n\n        Notes\n        -----\n        .. warning::\n\n           A `host` is required if an open `connection` is not given\n        \"\"\"\n        ndschannels = io_nds2.find_channels(names, host=host, port=port,\n                                            connection=connection, type=type,\n                                            unique=unique)\n        return cls(map(Channel.from_nds2, ndschannels))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries for when data are available for these channels in NDS2", "response": "def query_nds2_availability(cls, channels, start, end, ctype=126,\n                                connection=None, host=None, port=None):\n        \"\"\"Query for when data are available for these channels in NDS2\n\n        Parameters\n        ----------\n        channels : `list`\n            list of `Channel` or `str` for which to search\n\n        start : `int`\n            GPS start time of search, or any acceptable input to\n            :meth:`~gwpy.time.to_gps`\n\n        end : `int`\n            GPS end time of search, or any acceptable input to\n            :meth:`~gwpy.time.to_gps`\n\n        connection : `nds2.connection`, optional\n            open connection to an NDS(2) server, if not given, one will be\n            created based on ``host`` and ``port`` keywords\n\n        host : `str`, optional\n            name of NDS server host\n\n        port : `int`, optional\n            port number for NDS connection\n\n        Returns\n        -------\n        segdict : `~gwpy.segments.SegmentListDict`\n            dict of ``(name, SegmentList)`` pairs\n        \"\"\"\n        start = int(to_gps(start))\n        end = int(ceil(to_gps(end)))\n        chans = io_nds2.find_channels(channels, connection=connection,\n                                      unique=True, epoch=(start, end),\n                                      type=ctype)\n        availability = io_nds2.get_availability(chans, start, end,\n                                                connection=connection)\n        return type(availability)(zip(channels, availability.values()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch data into an GravitySpyTable object.", "response": "def get_gravityspy_triggers(tablename, engine=None, **kwargs):\n    \"\"\"Fetch data into an `GravitySpyTable`\n\n    Parameters\n    ----------\n    table : `str`,\n        The name of table you are attempting to receive triggers\n        from.\n\n    selection\n        other filters you would like to supply\n        underlying reader method for the given format\n\n    .. note::\n\n       For now it will attempt to automatically connect you\n       to a specific DB. In the future, this may be an input\n       argument.\n\n    Returns\n    -------\n    table : `GravitySpyTable`\n    \"\"\"\n    from sqlalchemy.engine import create_engine\n    from sqlalchemy.exc import ProgrammingError\n\n    # connect if needed\n    if engine is None:\n        conn_kw = {}\n        for key in ('db', 'host', 'user', 'passwd'):\n            try:\n                conn_kw[key] = kwargs.pop(key)\n            except KeyError:\n                pass\n        engine = create_engine(get_connection_str(**conn_kw))\n\n    try:\n        return GravitySpyTable(fetch(engine, tablename, **kwargs))\n    except ProgrammingError as exc:\n        if 'relation \"%s\" does not exist' % tablename in str(exc):\n            msg = exc.args[0]\n            msg = msg.replace(\n                'does not exist',\n                'does not exist, the following tablenames are '\n                'acceptable:\\n    %s\\n' % '\\n    '.join(engine.table_names()))\n            exc.args = (msg,)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_connection_str(db='gravityspy',\n                       host='gravityspy.ciera.northwestern.edu',\n                       user=None,\n                       passwd=None):\n    \"\"\"Create string to pass to create_engine\n\n    Parameters\n    ----------\n    db : `str`, default: ``gravityspy``\n        The name of the SQL database your connecting to.\n\n    host : `str`, default: ``gravityspy.ciera.northwestern.edu``\n        The name of the server the database you are connecting to\n        lives on.\n\n    user : `str`, default: `None`\n        Your username for authentication to this database.\n\n    passwd : `str`, default: `None`\n        Your password for authentication to this database.\n\n    .. note::\n\n       `user` and `passwd` should be given together, otherwise they will be\n       ignored and values will be resolved from the\n       ``GRAVITYSPY_DATABASE_USER`` and ``GRAVITYSPY_DATABASE_PASSWD``\n       environment variables.\n\n    Returns\n    -------\n    conn_string : `str`\n        A SQLAlchemy engine compliant connection string\n    \"\"\"\n    if (not user) or (not passwd):\n        user = os.getenv('GRAVITYSPY_DATABASE_USER', None)\n        passwd = os.getenv('GRAVITYSPY_DATABASE_PASSWD', None)\n\n    if (not user) or (not passwd):\n        raise ValueError('Remember to either pass '\n                         'or export GRAVITYSPY_DATABASE_USER '\n                         'and export GRAVITYSPY_DATABASE_PASSWD in order '\n                         'to access the Gravity Spy Data: '\n                         'https://secrets.ligo.org/secrets/144/'\n                         ' description is username and secret is password.')\n\n    return 'postgresql://{0}:{1}@{2}:5432/{3}'.format(user, passwd, host, db)", "response": "Create a SQLAlchemy engine compliant connection string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the offset in seconds between UTC and the given interferometer", "response": "def get_timezone_offset(ifo, dt=None):\n    \"\"\"Return the offset in seconds between UTC and the given interferometer\n\n    Parameters\n    ----------\n    ifo : `str`\n        prefix of interferometer, e.g. ``'X1'``\n\n    dt : `datetime.datetime`, optional\n        the time at which to calculate the offset, defaults to now\n\n    Returns\n    -------\n    offset : `int`\n        the offset in seconds between the timezone of the interferometer\n        and UTC\n    \"\"\"\n    import pytz\n    dt = dt or datetime.datetime.now()\n    offset = pytz.timezone(get_timezone(ifo)).utcoffset(dt)\n    return offset.days * 86400 + offset.seconds + offset.microseconds * 1e-6"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize a set of FFT parameters for processing This method reads the ``fftlength`` and ``overlap`` keyword arguments (presumed to be values in seconds), works out sensible defaults, then updates ``kwargs`` in place to include ``nfft`` and ``noverlap`` as values in sample counts. If a ``window`` is given, the ``noverlap`` parameter will be set to the recommended overlap for that window type, if ``overlap`` is not given. If a ``window`` is given as a `str`, it will be converted to a `numpy.ndarray` containing the correct window (of the correct length). Parameters ---------- series : `gwpy.timeseries.TimeSeries` the data that will be processed using an FFT-based method kwargs : `dict` the dict of keyword arguments passed by the user func : `callable`, optional the FFT method that will be called Examples -------- >>> from numpy.random import normal >>> from gwpy.timeseries import TimeSeries >>> normalize_fft_params(TimeSeries(normal(size=1024), sample_rate=256)) {'nfft': 1024, 'noverlap': 0} >>> normalize_fft_params(TimeSeries(normal(size=1024), sample_rate=256), ... {'window': 'hann'}) {'window': array([ 0.00000000e+00, 9.41235870e-06, ..., 3.76490804e-05, 9.41235870e-06]), 'noverlap': 0, 'nfft': 1024}", "response": "def normalize_fft_params(series, kwargs=None, func=None):\n    \"\"\"Normalize a set of FFT parameters for processing\n\n    This method reads the ``fftlength`` and ``overlap`` keyword arguments\n    (presumed to be values in seconds), works out sensible defaults,\n    then updates ``kwargs`` in place to include ``nfft`` and ``noverlap``\n    as values in sample counts.\n\n    If a ``window`` is given, the ``noverlap`` parameter will be set to the\n    recommended overlap for that window type, if ``overlap`` is not given.\n\n    If a ``window`` is given as a `str`, it will be converted to a\n    `numpy.ndarray` containing the correct window (of the correct length).\n\n    Parameters\n    ----------\n    series : `gwpy.timeseries.TimeSeries`\n        the data that will be processed using an FFT-based method\n\n    kwargs : `dict`\n        the dict of keyword arguments passed by the user\n\n    func : `callable`, optional\n        the FFT method that will be called\n\n    Examples\n    --------\n    >>> from numpy.random import normal\n    >>> from gwpy.timeseries import TimeSeries\n    >>> normalize_fft_params(TimeSeries(normal(size=1024), sample_rate=256))\n    {'nfft': 1024, 'noverlap': 0}\n    >>> normalize_fft_params(TimeSeries(normal(size=1024), sample_rate=256),\n    ...                      {'window': 'hann'})\n    {'window': array([  0.00000000e+00,   9.41235870e-06, ...,\n         3.76490804e-05,   9.41235870e-06]), 'noverlap': 0, 'nfft': 1024}\n    \"\"\"\n    # parse keywords\n    if kwargs is None:\n        kwargs = dict()\n    samp = series.sample_rate\n    fftlength = kwargs.pop('fftlength', None) or series.duration\n    overlap = kwargs.pop('overlap', None)\n    window = kwargs.pop('window', None)\n\n    # parse function library and name\n    if func is None:\n        method = library = None\n    else:\n        method = func.__name__\n        library = _fft_library(func)\n\n    # fftlength -> nfft\n    nfft = seconds_to_samples(fftlength, samp)\n\n    # overlap -> noverlap\n    noverlap = _normalize_overlap(overlap, window, nfft, samp, method=method)\n\n    # create window\n    window = _normalize_window(window, nfft, library, series.dtype)\n    if window is not None:  # allow FFT methods to use their own defaults\n        kwargs['window'] = window\n\n    # create FFT plan for LAL\n    if library == 'lal' and kwargs.get('plan', None) is None:\n        from ._lal import generate_fft_plan\n        kwargs['plan'] = generate_fft_plan(nfft, dtype=series.dtype)\n\n    kwargs.update({\n        'nfft': nfft,\n        'noverlap': noverlap,\n    })\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing an overlap in physical units to a number of samples", "response": "def _normalize_overlap(overlap, window, nfft, samp, method='welch'):\n    \"\"\"Normalise an overlap in physical units to a number of samples\n\n    Parameters\n    ----------\n    overlap : `float`, `Quantity`, `None`\n        the overlap in some physical unit (seconds)\n\n    window : `str`\n        the name of the window function that will be used, only used\n        if `overlap=None` is given\n\n    nfft : `int`\n        the number of samples that will be used in the fast Fourier\n        transform\n\n    samp : `Quantity`\n        the sampling rate (Hz) of the data that will be transformed\n\n    method : `str`\n        the name of the averaging method, default: `'welch'`, only\n        used to return `0` for `'bartlett'` averaging\n\n    Returns\n    -------\n    noverlap : `int`\n        the number of samples to be be used for the overlap\n    \"\"\"\n    if method == 'bartlett':\n        return 0\n    if overlap is None and isinstance(window, string_types):\n        return recommended_overlap(window, nfft)\n    if overlap is None:\n        return 0\n    return seconds_to_samples(overlap, samp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes a window specification for a PSD calculation", "response": "def _normalize_window(window, nfft, library, dtype):\n    \"\"\"Normalise a window specification for a PSD calculation\n\n    Parameters\n    ----------\n    window : `str`, `numpy.ndarray`, `None`\n        the input window specification\n\n    nfft : `int`\n        the length of the Fourier transform, in samples\n\n    library : `str`\n        the name of the library that provides the PSD routine\n\n    dtype : `type`\n        the required type of the window array, only used if\n        `library='lal'` is given\n\n    Returns\n    -------\n    window : `numpy.ndarray`, `lal.REAL8Window`\n        a numpy-, or `LAL`-format window array\n    \"\"\"\n    if library == '_lal' and isinstance(window, numpy.ndarray):\n        from ._lal import window_from_array\n        return window_from_array(window)\n    if library == '_lal':\n        from ._lal import generate_window\n        return generate_window(nfft, window=window, dtype=dtype)\n    if isinstance(window, string_types):\n        window = canonical_name(window)\n    if isinstance(window, string_types + (tuple,)):\n        return get_window(window, nfft)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_fft_params(func):\n    @wraps(func)\n    def wrapped_func(series, method_func, *args, **kwargs):\n        \"\"\"Wrap function to normalize FFT params before execution\n        \"\"\"\n        if isinstance(series, tuple):\n            data = series[0]\n        else:\n            data = series\n\n        # normalise FFT parmeters for all libraries\n        normalize_fft_params(data, kwargs=kwargs, func=method_func)\n\n        return func(series, method_func, *args, **kwargs)\n\n    return wrapped_func", "response": "Decorate a method to automatically convert quantities to samples\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef psd(timeseries, method_func, *args, **kwargs):\n    # decorator has translated the arguments for us, so just call psdn()\n    return _psdn(timeseries, method_func, *args, **kwargs)", "response": "Generates a PSD using a method function on the specified time series."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a PSD using a method function with FFT arguments in samples", "response": "def _psdn(timeseries, method_func, *args, **kwargs):\n    \"\"\"Generate a PSD using a method function with FFT arguments in samples\n\n    All arguments are presumed to be in sample counts, not physical units\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`, `tuple`\n        the data to process, or a 2-tuple of series to correlate\n\n    method_func : `callable`\n        the function that will be called to perform the signal processing\n\n    *args, **kwargs\n        other arguments to pass to ``method_func`` when calling\n    \"\"\"\n    # unpack tuple of timeseries for cross spectrum\n    try:\n        timeseries, other = timeseries\n    # or just calculate PSD\n    except ValueError:\n        return method_func(timeseries, kwargs.pop('nfft'), *args, **kwargs)\n    else:\n        return method_func(timeseries, other, kwargs.pop('nfft'),\n                           *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef average_spectrogram(timeseries, method_func, stride, *args, **kwargs):\n    # unpack CSD TimeSeries pair, or single timeseries\n    try:\n        timeseries, other = timeseries\n    except ValueError:\n        timeseries = timeseries\n        other = None\n\n    from ...spectrogram import Spectrogram\n\n    nproc = kwargs.pop('nproc', 1)\n\n    # get params\n    epoch = timeseries.t0.value\n    nstride = seconds_to_samples(stride, timeseries.sample_rate)\n    kwargs['fftlength'] = kwargs.pop('fftlength', stride) or stride\n    normalize_fft_params(timeseries, kwargs=kwargs, func=method_func)\n    nfft = kwargs['nfft']\n    noverlap = kwargs['noverlap']\n\n    # sanity check parameters\n    if nstride > timeseries.size:\n        raise ValueError(\"stride cannot be greater than the duration of \"\n                         \"this TimeSeries\")\n    if nfft > nstride:\n        raise ValueError(\"fftlength cannot be greater than stride\")\n    if noverlap >= nfft:\n        raise ValueError(\"overlap must be less than fftlength\")\n\n    # set up single process Spectrogram method\n    def _psd(series):\n        \"\"\"Calculate a single PSD for a spectrogram\n        \"\"\"\n        psd_ = _psdn(series, method_func, *args, **kwargs)\n        del psd_.epoch  # fixes Segmentation fault (no idea why it faults)\n        return psd_\n\n    # define chunks\n    tschunks = _chunk_timeseries(timeseries, nstride, noverlap)\n    if other is not None:\n        otherchunks = _chunk_timeseries(other, nstride, noverlap)\n        tschunks = zip(tschunks, otherchunks)\n\n    # calculate PSDs\n    psds = mp_utils.multiprocess_with_queues(nproc, _psd, tschunks)\n\n    # recombobulate PSDs into a spectrogram\n    return Spectrogram.from_spectra(*psds, epoch=epoch, dt=stride)", "response": "Generate an average Spectrogram using a method function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a single - process Spectrogram using a method function.", "response": "def spectrogram(timeseries, method_func, **kwargs):\n    \"\"\"Generate a spectrogram using a method function\n\n    Each time bin of the resulting spectrogram is a PSD estimate using\n    a single FFT\n    \"\"\"\n    from ...spectrogram import Spectrogram\n\n    # get params\n    sampling = timeseries.sample_rate.to('Hz').value\n    nproc = kwargs.pop('nproc', 1)\n    nfft = kwargs.pop('nfft')\n    noverlap = kwargs.pop('noverlap')\n    nstride = nfft - noverlap\n\n    # sanity check parameters\n    if noverlap >= nfft:\n        raise ValueError(\"overlap must be less than fftlength\")\n\n    # set up single process Spectrogram method\n    def _psd(series):\n        \"\"\"Calculate a single PSD for a spectrogram\n        \"\"\"\n        return method_func(series, nfft=nfft, **kwargs)[1]\n\n    # define chunks\n    chunks = []\n    x = 0\n    while x + nfft <= timeseries.size:\n        y = min(timeseries.size, x + nfft)\n        chunks.append((x, y))\n        x += nstride\n\n    tschunks = (timeseries.value[i:j] for i, j in chunks)\n\n    # calculate PSDs with multiprocessing\n    psds = mp_utils.multiprocess_with_queues(nproc, _psd, tschunks)\n\n    # convert PSDs to array with spacing for averages\n    numtimes = 1 + int((timeseries.size - nstride) / nstride)\n    numfreqs = int(nfft / 2 + 1)\n    data = numpy.zeros((numtimes, numfreqs), dtype=timeseries.dtype)\n    data[:len(psds)] = psds\n\n    # create output spectrogram\n    unit = fft_utils.scale_timeseries_unit(\n        timeseries.unit, scaling=kwargs.get('scaling', 'density'))\n    out = Spectrogram(numpy.empty((numtimes, numfreqs),\n                                  dtype=timeseries.dtype),\n                      copy=False, dt=nstride * timeseries.dt, t0=timeseries.t0,\n                      f0=0, df=sampling/nfft, unit=unit,\n                      name=timeseries.name, channel=timeseries.channel)\n\n    # normalize over-dense grid\n    density = nfft // nstride\n    weights = get_window('triangle', density)\n    for i in range(numtimes):\n        # get indices of overlapping columns\n        x = max(0, i+1-density)\n        y = min(i+1, numtimes-density+1)\n        if x == 0:\n            wgt = weights[-y:]\n        elif y == numtimes - density + 1:\n            wgt = weights[:y-x]\n        else:\n            wgt = weights\n        # calculate weighted average\n        out.value[i, :] = numpy.average(data[x:y], axis=0, weights=wgt)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cols(self, lines):\n        re_name_def = re.compile(r'^\\s*%\\s+(?P<colname>\\w+)')\n        self.names = []\n        for line in lines:\n            if not line:  # ignore empty lines in header (windows)\n                continue\n            if not line.startswith('%'):  # end of header lines\n                break\n            match = re_name_def.search(line)\n            if match:\n                self.names.append(match.group('colname'))\n\n        if not self.names:\n            raise core.InconsistentTableError(\n                'No column names found in Omega header')\n\n        self.cols = []  # pylint: disable=attribute-defined-outside-init\n        for name in self.names:\n            col = core.Column(name=name)\n            self.cols.append(col)", "response": "Initialize Column objects from a multi - line ASCII header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the stride for the spectrogram This method returns the stride as a float or None to indicate the spectrogram2 is not a valid time series.", "response": "def get_stride(self):\n        \"\"\"Calculate the stride for the spectrogram\n\n        This method returns the stride as a `float`, or `None` to indicate\n        selected usage of `TimeSeries.spectrogram2`.\n        \"\"\"\n        fftlength = float(self.args.secpfft)\n        overlap = fftlength * self.args.overlap\n        stride = fftlength - overlap\n        nfft = self.duration / stride  # number of FFTs\n        ffps = int(nfft / (self.width * 0.8))  # FFTs per second\n        if ffps > 3:\n            return max(2 * fftlength, ffps * stride + fftlength - 1)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_spectrogram(self):\n        args = self.args\n\n        fftlength = float(args.secpfft)\n        overlap = fftlength * args.overlap\n        self.log(2, \"Calculating spectrogram secpfft: %s, overlap: %s\" %\n                 (fftlength, overlap))\n\n        stride = self.get_stride()\n\n        if stride:\n            specgram = self.timeseries[0].spectrogram(\n                stride, fftlength=fftlength, overlap=overlap,\n                window=args.window)\n            nfft = stride * (stride // (fftlength - overlap))\n            self.log(3, 'Spectrogram calc, stride: %s, fftlength: %s, '\n                        'overlap: %sf, #fft: %d' % (stride, fftlength,\n                                                    overlap, nfft))\n        else:\n            specgram = self.timeseries[0].spectrogram2(\n                fftlength=fftlength, overlap=overlap, window=args.window)\n            nfft = specgram.shape[0]\n            self.log(3, 'HR-Spectrogram calc, fftlength: %s, overlap: %s, '\n                        '#fft: %d' % (fftlength, overlap, nfft))\n\n        return specgram ** (1/2.)", "response": "Calculate the spectrogram to be plotted\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the plot from the time series and arguments.", "response": "def make_plot(self):\n        \"\"\"Generate the plot from time series and arguments\n        \"\"\"\n        args = self.args\n\n        # constant input causes unhelpful (weird) error messages\n        # translate them to English\n        inmin = self.timeseries[0].min().value\n        if inmin == self.timeseries[0].max().value:\n            if not self.got_error:\n                self.log(0, 'ERROR: Input has constant values [{:g}]. '\n                            'Spectrogram-like products cannot process '\n                            'them.'.format(inmin))\n            self.got_error = True\n        else:\n            # create 'raw' spectrogram\n            specgram = self.get_spectrogram()\n\n            # there may be data that can't be processed\n            if specgram is not None:  # <-DMM: why is this here?\n                # apply normalisation\n                if args.norm:\n                    specgram = specgram.ratio(args.norm)\n\n                self.result = specgram\n\n                # -- update plot defaults\n\n                if not args.ymin:\n                    args.ymin = 1/args.secpfft if args.yscale == 'log' else 0\n\n                norm = 'log' if args.color_scale == 'log' else None\n                # vmin/vmax set in scale_axes_from_data()\n                return specgram.plot(figsize=self.figsize, dpi=self.dpi,\n                                     norm=norm, cmap=args.cmap)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ylabel(self):\n        if len(self.units) == 1:\n            return r'ASD $\\left({0}\\right)$'.format(\n                self.units[0].to_string('latex').strip('$'))\n        return 'ASD'", "response": "Text for y - axis label\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the plot from time series and arguments.", "response": "def make_plot(self):\n        \"\"\"Generate the plot from time series and arguments\n        \"\"\"\n        args = self.args\n\n        fftlength = float(args.secpfft)\n        overlap = args.overlap\n        self.log(2, \"Calculating spectrum secpfft: {0}, overlap: {1}\".format(\n            fftlength, overlap))\n        overlap *= fftlength\n\n        # create plot\n        plot = Plot(figsize=self.figsize, dpi=self.dpi)\n        ax = plot.gca()\n\n        # handle user specified plot labels\n        if self.args.legend:\n            nlegargs = len(self.args.legend[0])\n        else:\n            nlegargs = 0\n        if nlegargs > 0 and nlegargs != self.n_datasets:\n            warnings.warn('The number of legends specified must match '\n                          'the number of time series'\n                          ' (channels * start times).  '\n                          'There are {:d} series and {:d} legends'.format(\n                            len(self.timeseries), len(self.args.legend)))\n            nlegargs = 0  # don't use  themm\n\n        for i in range(0, self.n_datasets):\n            series = self.timeseries[i]\n            if nlegargs:\n                label = self.args.legend[0][i]\n            else:\n                label = series.channel.name\n                if len(self.start_list) > 1:\n                    label += ', {0}'.format(series.epoch.gps)\n\n            asd = series.asd(fftlength=fftlength, overlap=overlap)\n            self.spectra.append(asd)\n\n            if self.usetex:\n                label = label_to_latex(label)\n\n            ax.plot(asd, label=label)\n\n        if args.xscale == 'log' and not args.xmin:\n            args.xmin = 1/fftlength\n\n        return plot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestricting data limits for X - axis based on what you can see", "response": "def scale_axes_from_data(self):\n        \"\"\"Restrict data limits for Y-axis based on what you can see\n        \"\"\"\n        # get tight limits for X-axis\n        if self.args.xmin is None:\n            self.args.xmin = min(fs.xspan[0] for fs in self.spectra)\n        if self.args.xmax is None:\n            self.args.xmax = max(fs.xspan[1] for fs in self.spectra)\n\n        # autoscale view for Y-axis\n        cropped = [fs.crop(self.args.xmin, self.args.xmax) for\n                   fs in self.spectra]\n        ymin = min(fs.value.min() for fs in cropped)\n        ymax = max(fs.value.max() for fs in cropped)\n        self.plot.gca().yaxis.set_data_interval(ymin, ymax, ignore=True)\n        self.plot.gca().autoscale_view(scalex=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread data from a source into a gwpy. timeseries object.", "response": "def read(cls, source, *args, **kwargs):\n    \"\"\"Read data from a source into a `gwpy.timeseries` object.\n\n    This method is just the internal worker for `TimeSeries.read`, and\n    `TimeSeriesDict.read`, and isn't meant to be called directly.\n    \"\"\"\n    # if reading a cache, read it now and sieve\n    if io_cache.is_cache(source):\n        from .cache import preformat_cache\n        source = preformat_cache(source, *args[1:],\n                                 start=kwargs.get('start'),\n                                 end=kwargs.get('end'))\n\n    # get join arguments\n    pad = kwargs.pop('pad', None)\n    gap = kwargs.pop('gap', 'raise' if pad is None else 'pad')\n    joiner = _join_factory(cls, gap, pad)\n\n    # read\n    return io_read_multi(joiner, cls, source, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _join_factory(cls, gap, pad):\n    if issubclass(cls, dict):\n        def _join(data):\n            out = cls()\n            data = list(data)\n            while data:\n                tsd = data.pop(0)\n                out.append(tsd, gap=gap, pad=pad)\n                del tsd\n            return out\n    else:\n        from .. import TimeSeriesBaseList\n\n        def _join(arrays):\n            list_ = TimeSeriesBaseList(*arrays)\n            return list_.join(pad=pad, gap=gap)\n    return _join", "response": "Build a joiner for the given cls and the given padding options\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a table from a PyCBC live HDF5 file.", "response": "def table_from_file(source, ifo=None, columns=None, selection=None,\n                    loudest=False, extended_metadata=True):\n    \"\"\"Read a `Table` from a PyCBC live HDF5 file\n\n    Parameters\n    ----------\n    source : `str`, `h5py.File`, `h5py.Group`\n        the file path of open `h5py` object from which to read the data\n\n    ifo : `str`, optional\n        the interferometer prefix (e.g. ``'G1'``) to read; this is required\n        if reading from a file path or `h5py.File` and the containing file\n        stores data for multiple interferometers\n\n    columns : `list` or `str`, optional\n        the list of column names to read, defaults to all in group\n\n    loudest : `bool`, optional\n        read only those events marked as 'loudest',\n        default: `False` (read all)\n\n    extended_metadata : `bool`, optional\n        record non-column datasets found in the H5 group (e.g. ``'psd'``)\n        in the ``meta`` dict, default: `True`\n\n    Returns\n    -------\n    table : `~gwpy.table.EventTable`\n    \"\"\"\n    # find group\n    if isinstance(source, h5py.File):\n        source, ifo = _find_table_group(source, ifo=ifo)\n\n    # -- by this point 'source' is guaranteed to be an h5py.Group\n\n    # parse default columns\n    if columns is None:\n        columns = list(_get_columns(source))\n    readcols = set(columns)\n\n    # parse selections\n    selection = parse_column_filters(selection or [])\n    if selection:\n        readcols.update(list(zip(*selection))[0])\n\n    # set up meta dict\n    meta = {'ifo': ifo}\n    meta.update(source.attrs)\n    if extended_metadata:\n        meta.update(_get_extended_metadata(source))\n\n    if loudest:\n        loudidx = source['loudest'][:]\n\n    # map data to columns\n    data = []\n    for name in readcols:\n        # convert hdf5 dataset into Column\n        try:\n            arr = source[name][:]\n        except KeyError:\n            if name in GET_COLUMN:\n                arr = GET_COLUMN[name](source)\n            else:\n                raise\n        if loudest:\n            arr = arr[loudidx]\n        data.append(Table.Column(arr, name=name))\n\n    # read, applying selection filters, and column filters\n    return filter_table(Table(data, meta=meta), selection)[columns]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the right table group within the given HDF5 file.", "response": "def _find_table_group(h5file, ifo=None):\n    \"\"\"Find the right `h5py.Group` within the given `h5py.File`\n    \"\"\"\n    exclude = ('background',)\n    if ifo is None:\n        try:\n            ifo, = [key for key in h5file if key not in exclude]\n        except ValueError as exc:\n            exc.args = (\"PyCBC live HDF5 file contains dataset groups \"\n                        \"for multiple interferometers, please specify \"\n                        \"the prefix of the relevant interferometer via \"\n                        \"the `ifo` keyword argument, e.g: `ifo=G1`\",)\n            raise\n    try:\n        return h5file[ifo], ifo\n    except KeyError as exc:\n        exc.args = (\"No group for ifo %r in PyCBC live HDF5 file\" % ifo,)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_columns(h5group):\n    columns = set()\n    for name in sorted(h5group):\n        if (not isinstance(h5group[name], h5py.Dataset) or\n                name == 'template_boundaries'):\n            continue\n        if name.endswith('_template') and name[:-9] in columns:\n            continue\n        columns.add(name)\n    return columns - META_COLUMNS", "response": "Find valid column names from a PyCBC HDF5 Group\n    Returns a set of names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_extended_metadata(h5group):\n    meta = dict()\n\n    # get PSD\n    try:\n        psd = h5group['psd']\n    except KeyError:\n        pass\n    else:\n        from gwpy.frequencyseries import FrequencySeries\n        meta['psd'] = FrequencySeries(\n            psd[:], f0=0, df=psd.attrs['delta_f'], name='pycbc_live')\n\n    # get everything else\n    for key in META_COLUMNS - {'psd'}:\n        try:\n            value = h5group[key][:]\n        except KeyError:\n            pass\n        else:\n            meta[key] = value\n\n    return meta", "response": "Extract the extended metadata for a PyCBC table in HDF5\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_empty_files(files, ifo=None):\n    return type(files)([f for f in files if not empty_hdf5_file(f, ifo=ifo)])", "response": "Remove empty PyCBC - HDF5 files from a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef empty_hdf5_file(h5f, ifo=None):\n    # the decorator opens the HDF5 file for us, so h5f is guaranteed to\n    # be an h5py.Group object\n    h5f = h5f.file\n    if list(h5f) == []:\n        return True\n    if ifo is not None and (ifo not in h5f or list(h5f[ifo]) == ['psd']):\n        return True\n    return False", "response": "Determine whether PyCBC - HDF5 file is empty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nidentify a PyCBC Live file as an HDF5 with the correct name", "response": "def identify_pycbc_live(origin, filepath, fileobj, *args, **kwargs):\n    \"\"\"Identify a PyCBC Live file as an HDF5 with the correct name\n    \"\"\"\n    if identify_hdf5(origin, filepath, fileobj, *args, **kwargs) and (\n            filepath is not None and PYCBC_FILENAME.match(basename(filepath))):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_new_snr(h5group, q=6., n=2.):  # pylint:  disable=invalid-name\n    newsnr = h5group['snr'][:].copy()\n    rchisq = h5group['chisq'][:]\n    idx = numpy.where(rchisq > 1.)[0]\n    newsnr[idx] *= _new_snr_scale(rchisq[idx], q=q, n=n)\n    return newsnr", "response": "Calculate the new SNR column for this PyCBC HDF5 table group\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mchirp(h5group):\n    mass1 = h5group['mass1'][:]\n    mass2 = h5group['mass2'][:]\n    return (mass1 * mass2) ** (3/5.) / (mass1 + mass2) ** (1/5.)", "response": "Calculate the chipr mass column for this PyCBC HDF5 table group\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slice_axis_attributes(old, oldaxis, new, newaxis, slice_):\n    slice_ = as_slice(slice_)\n\n    # attribute names\n    index = '{}index'.format\n    origin = '{}0'.format\n    delta = 'd{}'.format\n\n    # if array has an index set already, use it\n    if hasattr(old, '_{}index'.format(oldaxis)):\n        setattr(new, index(newaxis), getattr(old, index(oldaxis))[slice_])\n\n    # otherwise if using a slice, use origin and delta properties\n    elif isinstance(slice_, slice) or not numpy.sum(slice_):\n        if isinstance(slice_, slice):\n            offset = slice_.start or 0\n            step = slice_.step or 1\n        else:  # empty ndarray slice (so just set attributes)\n            offset = 0\n            step = 1\n\n        dx = getattr(old, delta(oldaxis))\n        x0 = getattr(old, origin(oldaxis))\n\n        # set new.x0 / new.y0\n        setattr(new, origin(newaxis), x0 + offset * dx)\n\n        # set new.dx / new.dy\n        setattr(new, delta(newaxis), dx * step)\n\n    # otherwise slice with an index array\n    else:\n        setattr(new, index(newaxis), getattr(old, index(oldaxis))[slice_])\n\n    return new", "response": "Set axis metadata for new by slicing an axis of old array."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef null_slice(slice_):\n    try:\n        slice_ = as_slice(slice_)\n    except TypeError:\n        return False\n\n    if isinstance(slice_, numpy.ndarray) and numpy.all(slice_):\n        return True\n    if isinstance(slice_, slice) and slice_ in (\n            slice(None, None, None), slice(0, None, 1)\n    ):\n        return True", "response": "Returns True if a slice will have no affect\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an object to a slice if possible", "response": "def as_slice(slice_):\n    \"\"\"Convert an object to a slice, if possible\n    \"\"\"\n    if isinstance(slice_, (Integral, numpy.integer, type(None))):\n        return slice(0, None, 1)\n\n    if isinstance(slice_, (slice, numpy.ndarray)):\n        return slice_\n\n    if isinstance(slice_, (list, tuple)):\n        return tuple(map(as_slice, slice_))\n\n    raise TypeError(\"Cannot format {!r} as slice\".format(slice_))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query(name, use_kerberos=None, debug=False):\n    url = '%s/?q=%s' % (CIS_API_URL, name)\n    more = True\n    out = ChannelList()\n    while more:\n        reply = _get(url, use_kerberos=use_kerberos, debug=debug)\n        try:\n            out.extend(map(parse_json, reply[u'results']))\n        except KeyError:\n            pass\n        except TypeError:  # reply is a list\n            out.extend(map(parse_json, reply))\n            break\n        more = 'next' in reply and reply['next'] is not None\n        if more:\n            url = reply['next']\n        else:\n            break\n    out.sort(key=lambda c: c.name)\n    return out", "response": "Query the Channel Information System for details on the given channel name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get(url, use_kerberos=None, debug=False):\n    from ligo.org import request\n\n    # perform query\n    try:\n        response = request(url, debug=debug, use_kerberos=use_kerberos)\n    except HTTPError:\n        raise ValueError(\"Channel not found at URL %s \"\n                         \"Information System. Please double check the \"\n                         \"name and try again.\" % url)\n\n    if isinstance(response, bytes):\n        response = response.decode('utf-8')\n    return json.loads(response)", "response": "Perform a GET query against the CIS\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_json(data):\n    sample_rate = data['datarate']\n    unit = data['units']\n    dtype = CIS_DATA_TYPE[data['datatype']]\n    model = data['source']\n    url = data['displayurl']\n    return Channel(data['name'], sample_rate=sample_rate, unit=unit,\n                   dtype=dtype, model=model, url=url)", "response": "Parse the input data dict into a Channel object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ylabel(self):\n        units = self.units\n        if len(units) == 1 and str(units[0]) == '':  # dimensionless\n            return ''\n        if len(units) == 1 and self.usetex:\n            return units[0].to_string('latex')\n        elif len(units) == 1:\n            return units[0].to_string()\n        elif len(units) > 1:\n            return 'Multiple units'\n        return super(TimeSeries, self).get_ylabel()", "response": "Text for y - axis label"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_plot(self):\n        plot = Plot(figsize=self.figsize, dpi=self.dpi)\n        ax = plot.gca(xscale='auto-gps')\n\n        # handle user specified plot labels\n        if self.args.legend:\n            nlegargs = len(self.args.legend[0])\n        else:\n            nlegargs = 0\n        if nlegargs > 0 and nlegargs != self.n_datasets:\n            warnings.warn('The number of legends specified must match '\n                          'the number of time series'\n                          ' (channels * start times).  '\n                          'There are {:d} series and {:d} legends'.format(\n                            len(self.timeseries), len(self.args.legend)))\n            nlegargs = 0    # don't use  them\n\n        for i in range(0, self.n_datasets):\n            series = self.timeseries[i]\n            if nlegargs:\n                label = self.args.legend[0][i]\n            else:\n                label = series.channel.name\n            if self.usetex:\n                label = label_to_latex(label)\n            ax.plot(series, label=label)\n\n        return plot", "response": "Generate the plot from time series and arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestricts data limits for X - axis based on what you can see", "response": "def scale_axes_from_data(self):\n        \"\"\"Restrict data limits for Y-axis based on what you can see\n        \"\"\"\n        # get tight limits for X-axis\n        if self.args.xmin is None:\n            self.args.xmin = min(ts.xspan[0] for ts in self.timeseries)\n        if self.args.xmax is None:\n            self.args.xmax = max(ts.xspan[1] for ts in self.timeseries)\n\n        # autoscale view for Y-axis\n        cropped = [ts.crop(self.args.xmin, self.args.xmax) for\n                   ts in self.timeseries]\n        ymin = min(ts.value.min() for ts in cropped)\n        ymax = max(ts.value.max() for ts in cropped)\n        self.plot.gca().yaxis.set_data_interval(ymin, ymax, ignore=True)\n        self.plot.gca().autoscale_view(scalex=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a real 8 - bit FFT for a fast Fourier transform.", "response": "def generate_fft_plan(length, level=None, dtype='float64', forward=True):\n    \"\"\"Build a `REAL8FFTPlan` for a fast Fourier transform.\n\n    Parameters\n    ----------\n    length : `int`\n        number of samples to plan for in each FFT.\n\n    level : `int`, optional\n        amount of work to do when planning the FFT, default set by\n        `LAL_FFTPLAN_LEVEL` module variable.\n\n    dtype : :class:`numpy.dtype`, `type`, `str`, optional\n        numeric type of data to plan for\n\n    forward : bool, optional, default: `True`\n        whether to create a forward or reverse FFT plan\n\n    Returns\n    -------\n    plan : `REAL8FFTPlan` or similar\n        FFT plan of the relevant data type\n    \"\"\"\n    from ...utils.lal import (find_typed_function, to_lal_type_str)\n\n    # generate key for caching plan\n    laltype = to_lal_type_str(dtype)\n    key = (length, bool(forward), laltype)\n\n    # find existing plan\n    try:\n        return LAL_FFTPLANS[key]\n    # or create one\n    except KeyError:\n        create = find_typed_function(dtype, 'Create', 'FFTPlan')\n        if level is None:\n            level = LAL_FFTPLAN_LEVEL\n        LAL_FFTPLANS[key] = create(length, int(bool(forward)), level)\n        return LAL_FFTPLANS[key]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_window(length, window=None, dtype='float64'):\n    from ...utils.lal import (find_typed_function, to_lal_type_str)\n\n    if window is None:\n        window = ('kaiser', 24)\n\n    # generate key for caching window\n    laltype = to_lal_type_str(dtype)\n    key = (length, str(window), laltype)\n\n    # find existing window\n    try:\n        return LAL_WINDOWS[key]\n    # or create one\n    except KeyError:\n        # parse window as name and arguments, e.g. ('kaiser', 24)\n        if isinstance(window, (list, tuple)):\n            window, beta = window\n        else:\n            beta = 0\n        window = canonical_name(window)\n        # create window\n        create = find_typed_function(dtype, 'CreateNamed', 'Window')\n        LAL_WINDOWS[key] = create(window, beta, length)\n        return LAL_WINDOWS[key]", "response": "Generate a time - domain window for use in a LAL FFT."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef window_from_array(array):\n    from ...utils.lal import (find_typed_function)\n\n    dtype = array.dtype\n\n    # create sequence\n    seq = find_typed_function(dtype, 'Create', 'Sequence')(array.size)\n    seq.data = array\n\n    # create window from sequence\n    return find_typed_function(dtype, 'Create', 'WindowFromSequence')(seq)", "response": "Convert a numpy. ndarray into a LAL. Window object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _lal_spectrum(timeseries, segmentlength, noverlap=None, method='welch',\n                  window=None, plan=None):\n    \"\"\"Generate a PSD `FrequencySeries` using |lal|_\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    method : `str`\n        average PSD method\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    window : `lal.REAL8Window`, optional\n        window to apply to timeseries prior to FFT\n\n    plan : `lal.REAL8FFTPlan`, optional\n        LAL FFT plan to use when generating average spectrum\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n    \"\"\"\n    import lal\n    from ...utils.lal import find_typed_function\n\n    # default to 50% overlap\n    if noverlap is None:\n        noverlap = int(segmentlength // 2)\n    stride = segmentlength - noverlap\n\n    # get window\n    if window is None:\n        window = generate_window(segmentlength, dtype=timeseries.dtype)\n\n    # get FFT plan\n    if plan is None:\n        plan = generate_fft_plan(segmentlength, dtype=timeseries.dtype)\n\n    method = method.lower()\n\n    # check data length\n    size = timeseries.size\n    numsegs = 1 + int((size - segmentlength) / stride)\n    if method == 'median-mean' and numsegs % 2:\n        numsegs -= 1\n        if not numsegs:\n            raise ValueError(\"Cannot calculate median-mean spectrum with \"\n                             \"this small a TimeSeries.\")\n\n    required = int((numsegs - 1) * stride + segmentlength)\n    if size != required:\n        warnings.warn(\"Data array is the wrong size for the correct number \"\n                      \"of averages given the input parameters. The trailing \"\n                      \"%d samples will not be used in this calculation.\"\n                      % (size - required))\n        timeseries = timeseries[:required]\n\n    # generate output spectrum\n    create = find_typed_function(timeseries.dtype, 'Create', 'FrequencySeries')\n    lalfs = create(timeseries.name, lal.LIGOTimeGPS(timeseries.epoch.gps), 0,\n                   1 / segmentlength, lal.StrainUnit,\n                   int(segmentlength // 2 + 1))\n\n    # find LAL method (e.g. median-mean -> lal.REAL8AverageSpectrumMedianMean)\n    methodname = ''.join(map(str.title, re.split('[-_]', method)))\n    spec_func = find_typed_function(timeseries.dtype, '',\n                                    'AverageSpectrum{}'.format(methodname))\n\n    # calculate spectrum\n    spec_func(lalfs, timeseries.to_lal(), segmentlength, stride, window, plan)\n\n    # format and return\n    spec = FrequencySeries.from_lal(lalfs)\n    spec.name = timeseries.name\n    spec.channel = timeseries.channel\n    spec.override_unit(scale_timeseries_unit(\n        timeseries.unit, scaling='density'))\n    return spec", "response": "Generate a PSD for a small a TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef welch(timeseries, segmentlength, noverlap=None, window=None, plan=None):\n    return _lal_spectrum(timeseries, segmentlength, noverlap=noverlap,\n                         method='welch', window=window, plan=plan)", "response": "Calculate an PSD of this TimeSeries using Welch s method\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bartlett(timeseries, segmentlength, noverlap=None, window=None, plan=None):\n    # pylint: disable=unused-argument\n    \"\"\"Calculate an PSD of this `TimeSeries` using Bartlett's method\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    window : `tuple`, `str`, optional\n        window parameters to apply to timeseries prior to FFT\n\n    plan : `REAL8FFTPlan`, optional\n        LAL FFT plan to use when generating average spectrum\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n\n    See also\n    --------\n    lal.REAL8AverageSpectrumWelch\n    \"\"\"\n    return _lal_spectrum(timeseries, segmentlength, noverlap=0,\n                         method='welch', window=window, plan=plan)", "response": "Calculate an PSD of this TimeSeries using Bartlett s method\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating a PSD of this TimeSeries using a median average method.", "response": "def median(timeseries, segmentlength, noverlap=None, window=None, plan=None):\n    \"\"\"Calculate a PSD of this `TimeSeries` using a median average method\n\n    The median average is similar to Welch's method, using a median average\n    rather than mean.\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    window : `tuple`, `str`, optional\n        window parameters to apply to timeseries prior to FFT\n\n    plan : `REAL8FFTPlan`, optional\n        LAL FFT plan to use when generating average spectrum\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n\n    See also\n    --------\n    lal.REAL8AverageSpectrumMedian\n    \"\"\"\n    return _lal_spectrum(timeseries, segmentlength, noverlap=noverlap,\n                         method='median', window=window, plan=plan)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef median_mean(timeseries, segmentlength, noverlap=None,\n                window=None, plan=None):\n    \"\"\"Calculate a PSD of this `TimeSeries` using a median-mean average method\n\n    The median-mean average method divides overlapping segments into \"even\"\n    and \"odd\" segments, and computes the bin-by-bin median of the \"even\"\n    segments and the \"odd\" segments, and then takes the bin-by-bin average\n    of these two median averages.\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    window : `tuple`, `str`, optional\n        window parameters to apply to timeseries prior to FFT\n\n    plan : `REAL8FFTPlan`, optional\n        LAL FFT plan to use when generating average spectrum\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n\n    See also\n    --------\n    lal.REAL8AverageSpectrumMedianMean\n    \"\"\"\n    return _lal_spectrum(timeseries, segmentlength, noverlap=noverlap,\n                         method='median-mean', window=window, plan=plan)", "response": "Calculate a PSD of this TimeSeries using a median - mean average method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a GWF file source into a lalframe. XLALFrStream object.", "response": "def open_data_source(source):\n    \"\"\"Open a GWF file source into a `lalframe.XLALFrStream` object\n\n    Parameters\n    ----------\n    source : `str`, `file`, `list`\n        Data source to read.\n\n    Returns\n    -------\n    stream : `lalframe.FrStream`\n        An open `FrStream`.\n\n    Raises\n    ------\n    ValueError\n        If the input format cannot be identified.\n    \"\"\"\n    if isinstance(source, FILE_LIKE):\n        source = source.name\n    if isinstance(source, CacheEntry):\n        source = source.path\n\n    # read cache file\n    if (isinstance(source, string_types) and\n            source.endswith(('.lcf', '.cache'))):\n        return lalframe.FrStreamCacheOpen(lal.CacheImport(source))\n\n    # read glue cache object\n    if isinstance(source, list) and is_cache(source):\n        cache = lal.Cache()\n        for entry in file_list(source):\n            cache = lal.CacheMerge(cache, lal.CacheGlob(*os.path.split(entry)))\n        return lalframe.FrStreamCacheOpen(cache)\n\n    # read lal cache object\n    if isinstance(source, lal.Cache):\n        return lalframe.FrStreamCacheOpen(source)\n\n    # read single file\n    if isinstance(source, string_types):\n        return lalframe.FrStreamOpen(*map(str, os.path.split(source)))\n\n    raise ValueError(\"Don't know how to open data source of type %r\"\n                     % type(source))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stream_duration(stream):\n    epoch = lal.LIGOTimeGPS(stream.epoch.gpsSeconds,\n                            stream.epoch.gpsNanoSeconds)\n    # loop over each file in the stream cache and query its duration\n    nfile = stream.cache.length\n    duration = 0\n    for dummy_i in range(nfile):\n        for dummy_j in range(lalframe.FrFileQueryNFrame(stream.file)):\n            duration += lalframe.FrFileQueryDt(stream.file, 0)\n            lalframe.FrStreamNext(stream)\n    # rewind stream and return\n    lalframe.FrStreamSeek(stream, epoch)\n    return duration", "response": "Find the duration of time stored in a frame stream\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data from one or more GWF files using the LALFrame API.", "response": "def read(source, channels, start=None, end=None, series_class=TimeSeries,\n         scaled=None):\n    \"\"\"Read data from one or more GWF files using the LALFrame API\n    \"\"\"\n    # scaled must be provided to provide a consistent API with frameCPP\n    if scaled is not None:\n        warnings.warn(\n            \"the `scaled` keyword argument is not supported by lalframe, \"\n            \"if you require ADC scaling, please install \"\n            \"python-ldas-tools-framecpp\",\n        )\n\n    stream = open_data_source(source)\n\n    # parse times and restrict to available data\n    epoch = lal.LIGOTimeGPS(stream.epoch.gpsSeconds,\n                            stream.epoch.gpsNanoSeconds)\n    streamdur = get_stream_duration(stream)\n    if start is None:\n        start = epoch\n    else:\n        start = max(epoch, lalutils.to_lal_ligotimegps(start))\n    if end is None:\n        offset = float(start - epoch)\n        duration = streamdur - offset\n    else:\n        end = min(epoch + streamdur, lalutils.to_lal_ligotimegps(end))\n        duration = float(end - start)\n\n    # read data\n    out = series_class.DictClass()\n    for name in channels:\n        out[name] = series_class.from_lal(\n            _read_channel(stream, str(name), start=start, duration=duration),\n            copy=False)\n        lalframe.FrStreamSeek(stream, epoch)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite data to a GWF file using the LALFrame API.", "response": "def write(tsdict, outfile, start=None, end=None,\n          name='gwpy', run=0):\n    \"\"\"Write data to a GWF file using the LALFrame API\n    \"\"\"\n    if not start:\n        start = list(tsdict.values())[0].xspan[0]\n    if not end:\n        end = list(tsdict.values())[0].xspan[1]\n    duration = end - start\n\n    # get ifos list\n    detectors = 0\n    for series in tsdict.values():\n        try:\n            idx = list(lalutils.LAL_DETECTORS.keys()).index(series.channel.ifo)\n            detectors |= 1 << 2*idx\n        except (KeyError, AttributeError):\n            continue\n\n    # create new frame\n    frame = lalframe.FrameNew(start, duration, name, run, 0, detectors)\n\n    for series in tsdict.values():\n        # convert to LAL\n        lalseries = series.to_lal()\n\n        # find adder\n        add_ = lalutils.find_typed_function(\n            series.dtype, 'FrameAdd', 'TimeSeriesProcData', module=lalframe)\n\n        # add time series to frame\n        add_(frame, lalseries)\n\n    # write frame\n    lalframe.FrameWrite(frame, outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef segment_content_handler():\n    from ligo.lw.lsctables import (SegmentTable, SegmentDefTable,\n                                   SegmentSumTable)\n    from ligo.lw.ligolw import PartialLIGOLWContentHandler\n\n    def _filter(name, attrs):\n        return reduce(\n            operator.or_,\n            [table_.CheckProperties(name, attrs) for\n             table_ in (SegmentTable, SegmentDefTable, SegmentSumTable)])\n\n    return build_content_handler(PartialLIGOLWContentHandler, _filter)", "response": "Build a ~xml. sax. handlers. ContentHandler to read segment XML tables\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_ligolw_dict(source, names=None, coalesce=False, **kwargs):\n    xmldoc = read_ligolw(source, contenthandler=segment_content_handler())\n\n    # parse tables\n    with patch_ligotimegps(type(xmldoc.childNodes[0]).__module__):\n        out = DataQualityDict.from_ligolw_tables(\n            *xmldoc.childNodes,\n            names=names,\n            **kwargs\n        )\n\n    # coalesce\n    if coalesce:\n        for flag in out:\n            out[flag].coalesce()\n\n    return out", "response": "Read segments for the given flag from the LIGO_LW XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_ligolw_flag(source, name=None, **kwargs):\n    name = [name] if name is not None else None\n    return list(read_ligolw_dict(source, names=name, **kwargs).values())[0]", "response": "Read a single DataQualityFlag from a LIGO_LW XML file containing a single LIGO_LW XML file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite this DataQualityFlag to the given LIGO_LW Document.", "response": "def write_ligolw(flags, target, attrs=None, ilwdchar_compat=None, **kwargs):\n    \"\"\"Write this `DataQualityFlag` to the given LIGO_LW Document\n\n    Parameters\n    ----------\n    flags : `DataQualityFlag`, `DataQualityDict`\n        `gwpy.segments` object to write\n\n    target : `str`, `file`, :class:`~ligo.lw.ligolw.Document`\n        the file or document to write into\n\n    attrs : `dict`, optional\n        extra attributes to write into segment tables\n\n    **kwargs\n        keyword arguments to use when writing\n\n    See also\n    --------\n    gwpy.io.ligolw.write_ligolw_tables\n        for details of acceptable keyword arguments\n    \"\"\"\n    if isinstance(flags, DataQualityFlag):\n        flags = DataQualityDict({flags.name: flags})\n    return write_tables(\n        target,\n        flags.to_ligolw_tables(ilwdchar_compat=ilwdchar_compat,\n                               **attrs or dict()),\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscale the unit of a TimeSeries to match that of a FrequencySeries.", "response": "def scale_timeseries_unit(tsunit, scaling='density'):\n    \"\"\"Scale the unit of a `TimeSeries` to match that of a `FrequencySeries`\n\n    Parameters\n    ----------\n    tsunit : `~astropy.units.UnitBase`\n        input unit from `TimeSeries`\n    scaling : `str`\n        type of frequency series, either 'density' for a PSD, or\n        'spectrum' for a power spectrum.\n\n    Returns\n    -------\n    unit : `~astropy.units.Unit`\n        unit to be applied to the resulting `FrequencySeries`.\n    \"\"\"\n    # set units\n    if scaling == 'density':\n        baseunit = units.Hertz\n    elif scaling == 'spectrum':\n        baseunit = units.dimensionless_unscaled\n    else:\n        raise ValueError(\"Unknown scaling: %r\" % scaling)\n    if tsunit:\n        specunit = tsunit ** 2 / baseunit\n    else:\n        specunit = baseunit ** -1\n    return specunit"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_cache(cachefile, coltype=LIGOTimeGPS, sort=None, segment=None):\n    # open file\n    if not isinstance(cachefile, FILE_LIKE):\n        with open(file_path(cachefile), 'r') as fobj:\n            return read_cache(fobj, coltype=coltype, sort=sort,\n                              segment=segment)\n\n    # read file\n    cache = [x.path for x in _iter_cache(cachefile, gpstype=coltype)]\n\n    # sieve and sort\n    if segment:\n        cache = sieve(cache, segment=segment)\n    if sort:\n        cache.sort(key=sort)\n\n    # read simple paths\n    return cache", "response": "Read a LAL - or FFL - format cache file and return a list of file paths as a list of file paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_cache(cache, fobj, format=None):\n    # open file\n    if isinstance(fobj, string_types):\n        with open(fobj, 'w') as fobj2:\n            return write_cache(cache, fobj2, format=format)\n\n    if format is None:\n        formatter = str\n    elif format.lower() == \"lal\":\n        formatter = _format_entry_lal\n    elif format.lower() == \"ffl\":\n        formatter = _format_entry_ffl\n    else:\n        raise ValueError(\"Unrecognised cache format {!r}\".format(format))\n\n    # write file\n    for line in map(formatter, cache):\n        try:\n            print(line, file=fobj)\n        except TypeError:  # bytes-mode\n            fobj.write(\"{}\\n\".format(line).encode(\"utf-8\"))", "response": "Write a list of cache entries to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_cache(cache):\n    if isinstance(cache, string_types + FILE_LIKE):\n        try:\n            return bool(len(read_cache(cache)))\n        except (TypeError, ValueError, UnicodeDecodeError, ImportError):\n            # failed to parse cache\n            return False\n    if HAS_CACHE and isinstance(cache, Cache):\n        return True\n    if (isinstance(cache, (list, tuple)) and cache and\n            all(map(is_cache_entry, cache))):\n        return True\n\n    return False", "response": "Returns True if the input object is a cache file or a list of cache entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting whether the input can be represented as a cache entry.", "response": "def is_cache_entry(path):\n    \"\"\"Returns `True` if ``path`` can be represented as a cache entry\n\n    In practice this just tests whether the input is |LIGO-T050017|_ compliant.\n\n    Parameters\n    ----------\n    path : `str`, :class:`lal.utils.CacheEntry`\n        The input to test\n\n    Returns\n    -------\n    isentry : `bool`\n        `True` if ``path`` is an instance of `CacheEntry`, or can be parsed\n        using |LIGO-T050017|_.\n    \"\"\"\n    if HAS_CACHEENTRY and isinstance(path, CacheEntry):\n        return True\n    try:\n        file_segment(path)\n    except (ValueError, TypeError, AttributeError):\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning metadata parsed from a filename following LIGO - T050017 - compatible format.", "response": "def filename_metadata(filename):\n    \"\"\"Return metadata parsed from a filename following LIGO-T050017\n\n    This method is lenient with regards to integers in the GPS start time of\n    the file, as opposed to `gwdatafind.utils.filename_metadata`, which is\n    strict.\n\n    Parameters\n    ----------\n    filename : `str`\n        the path name of a file\n\n    Returns\n    -------\n    obs : `str`\n        the observatory metadata\n\n    tag : `str`\n        the file tag\n\n    segment : `gwpy.segments.Segment`\n        the GPS ``[float, float)`` interval for this file\n\n    Notes\n    -----\n    `LIGO-T050017 <https://dcc.ligo.org/LIGO-T050017>`__ declares a\n    file naming convention that includes documenting the GPS start integer\n    and integer duration of a file, see that document for more details.\n\n    Examples\n    --------\n    >>> from gwpy.io.cache import filename_metadata\n    >>> filename_metadata(\"A-B-0-1.txt\")\n    ('A', 'B', Segment(0, 1))\n    >>> filename_metadata(\"A-B-0.456-1.345.txt\")\n    (\"A\", \"B\", Segment(0.456, 1.801))\n    \"\"\"\n    from ..segments import Segment\n    name = Path(filename).name\n    try:\n        obs, desc, start, dur = name.split('-')\n    except ValueError as exc:\n        exc.args = ('Failed to parse {!r} as LIGO-T050017-compatible '\n                    'filename'.format(name),)\n        raise\n    start = float(start)\n    dur = dur.rsplit('.', 1)[0]\n    while True:  # recursively remove extension components\n        try:\n            dur = float(dur)\n        except ValueError:\n            if '.' not in dur:\n                raise\n            dur = dur.rsplit('.', 1)[0]\n        else:\n            break\n    return obs, desc, Segment(start, start+dur)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the data segment for a given filename following T050017", "response": "def file_segment(filename):\n    \"\"\"Return the data segment for a filename following T050017\n\n    Parameters\n    ---------\n    filename : `str`, :class:`~lal.utils.CacheEntry`\n        the path name of a file\n\n    Returns\n    -------\n    segment : `~gwpy.segments.Segment`\n        the ``[start, stop)`` GPS segment covered by the given file\n\n    Notes\n    -----\n    |LIGO-T050017|_ declares a filenaming convention that includes\n    documenting the GPS start integer and integer duration of a file,\n    see that document for more details.\n    \"\"\"\n    from ..segments import Segment\n    try:  # CacheEntry\n        return Segment(filename.segment)\n    except AttributeError:  # file path (str)\n        return filename_metadata(filename)[2]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cache_segments(*caches):\n    from ..segments import SegmentList\n    out = SegmentList()\n    for cache in caches:\n        out.extend(file_segment(e) for e in cache)\n    return out.coalesce()", "response": "Returns the segments of data covered by entries in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening a nested list of cache entries into a single list containing the unique set of entries across the base directory.", "response": "def flatten(*caches):\n    \"\"\"Flatten a nested list of cache entries\n\n    Parameters\n    ----------\n    *caches : `list`\n        One or more lists of file paths\n        (`str` or :class:`~lal.utils.CacheEntry`).\n\n    Returns\n    -------\n    flat : `list`\n        A flat `list` containing the unique set of entries across\n        each input.\n    \"\"\"\n    return list(OrderedDict.fromkeys(e for c in caches for e in c))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_contiguous(*caches):\n    flat = flatten(*caches)\n    for segment in cache_segments(flat):\n        yield sieve(flat, segment=segment)", "response": "Separate one or more cache entry lists into time - contiguous sub - lists of file paths\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering the cache to find those entries that overlap segment.", "response": "def sieve(cache, segment=None):\n    \"\"\"Filter the cache to find those entries that overlap ``segment``\n\n    Parameters\n    ----------\n    cache : `list`\n        Input list of file paths\n\n    segment : `~gwpy.segments.Segment`\n        The ``[start, stop)`` interval to match against.\n    \"\"\"\n    return type(cache)(e for e in cache if segment.intersects(file_segment(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arg_qxform(cls, parser):\n        group = parser.add_argument_group('Q-transform options')\n        group.add_argument('--plot', nargs='+', type=float, default=[.5],\n                           help='One or more times to plot')\n        group.add_argument('--frange', nargs=2, type=float,\n                           help='Frequency range to plot')\n        group.add_argument('--qrange', nargs=2, type=float,\n                           help='Search Q range')\n\n        group.add_argument('--nowhiten', action='store_true',\n                           help='do not whiten input before transform')", "response": "Add an argument group for Q - transform options"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _finalize_arguments(self, args):\n        gps = args.gps\n        search = args.search\n        # ensure we have enough data for filter settling\n        max_plot = max(args.plot)\n        search = max(search, max_plot * 2 + 8)\n        args.search = search\n        self.log(3, \"Search window: {0:.0f} sec, max plot window {1:.0f}\".\n                 format(search, max_plot))\n\n        # make sure we don't create too big interpolations\n\n        xpix = 1200.\n        if args.geometry:\n            m = re.match('(\\\\d+)x(\\\\d+)', args.geometry)\n            if m:\n                xpix = float(m.group(1))\n        # save output x for individual tres calulation\n        args.nx = xpix\n        self.args.tres = search / xpix / 2\n        self.log(3, 'Max time resolution (tres) set to {:.4f}'.format(\n                self.args.tres))\n\n        args.start = [[int(gps - search/2)]]\n        if args.epoch is None:\n            args.epoch = args.gps\n        args.duration = search\n\n        args.chan = [[args.chan]]\n\n        if args.color_scale is None:\n            args.color_scale = 'linear'\n\n        args.overlap = 0  # so that FFTMixin._finalize_arguments doesn't fail\n\n        xmin = args.xmin\n        xmax = args.xmax\n\n        super(Qtransform, self)._finalize_arguments(args)\n\n        # unset defaults from `TimeDomainProduct`\n        args.xmin = xmin\n        args.xmax = xmax", "response": "Set up the standard arguments for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_title(self):\n        def fformat(x):  # float format\n            if isinstance(x, (list, tuple)):\n                return '[{0}]'.format(', '.join(map(fformat, x)))\n            if isinstance(x, Quantity):\n                x = x.value\n            elif isinstance(x, str):\n                warnings.warn('WARNING: fformat called with a' +\n                              ' string. This has ' +\n                              'been depricated and may disappear ' +\n                              'in a future release.')\n                x = float(x)\n            return '{0:.2f}'.format(x)\n\n        bits = [('Q', fformat(self.result.q))]\n        bits.append(('tres', '{:.3g}'.format(self.qxfrm_args['tres'])))\n        if self.qxfrm_args.get('qrange'):\n            bits.append(('q-range', fformat(self.qxfrm_args['qrange'])))\n        if self.qxfrm_args['whiten']:\n            bits.append(('whitened',))\n        bits.extend([\n            ('f-range', fformat(self.result.yspan)),\n            ('e-range', '[{:.3g}, {:.3g}]'.format(self.result.min(),\n                                                  self.result.max())),\n        ])\n        return ', '.join([': '.join(bit) for bit in bits])", "response": "Default title for plot\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nworks on a single timesharing and generates a single Q-transform spectrogram", "response": "def get_spectrogram(self):\n        \"\"\"Worked on a single timesharing and generates a single Q-transform\n        spectrogram\"\"\"\n        args = self.args\n\n        asd = self.timeseries[0].asd().value\n        if (asd.min() == 0):\n            self.log(0, 'Input data has a zero in ASD. '\n                     'Q-transform not possible.')\n            self.got_error = True\n            qtrans = None\n        else:\n            gps = self.qxfrm_args['gps']\n            outseg = Segment(gps, gps).protract(args.plot[self.plot_num])\n\n            # This section tries to optimize the amount of data that is\n            # processed and the time resolution needed to create a good\n            # image. NB:For each time span specified\n            # NB: the timeseries h enough data for the longest plot\n            inseg = outseg.protract(4) & self.timeseries[0].span\n            proc_ts = self.timeseries[0].crop(*inseg)\n\n            #  time resolution is calculated to provide about 4 times\n            # the number of output pixels for interpolation\n            tres = float(outseg.end - outseg.start) / 4 / self.args.nx\n            self.qxfrm_args['tres'] = tres\n            self.qxfrm_args['search'] = int(len(proc_ts) * proc_ts.dt.value)\n\n            self.log(3, 'Q-transform arguments:')\n            self.log(3, '{0:>15s} = {1}'.format('outseg', outseg))\n            for key in sorted(self.qxfrm_args):\n                self.log(3, '{0:>15s} = {1}'.format(key, self.qxfrm_args[key]))\n\n            qtrans = proc_ts.q_transform(outseg=outseg, **self.qxfrm_args)\n\n            if args.ymin is None:  # set before Spectrogram.make_plot\n                args.ymin = qtrans.yspan[0]\n\n        return qtrans"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ligotimegps(s, ns=0):\n    from lal import LIGOTimeGPS\n    try:\n        return LIGOTimeGPS(s, ns)\n    except TypeError:\n        return LIGOTimeGPS(int(s), int(ns))", "response": "Catch TypeError and cast s and ns to int"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patch_ligotimegps(module=\"ligo.lw.lsctables\"):\n    module = import_module(module)\n    orig = module.LIGOTimeGPS\n    module.LIGOTimeGPS = _ligotimegps\n    try:\n        yield\n    finally:\n        module.LIGOTimeGPS = orig", "response": "Context manager to patch LIGOTimeGPS to accept all int types"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a PartialLIGOLWContentHandler to read only this element", "response": "def get_partial_contenthandler(element):\n    \"\"\"Build a `PartialLIGOLWContentHandler` to read only this element\n\n    Parameters\n    ----------\n    element : `type`, subclass of :class:`~ligo.lw.ligolw.Element`\n        the element class to be read,\n\n    Returns\n    -------\n    contenthandler : `type`\n        a subclass of :class:`~ligo.lw.ligolw.PartialLIGOLWContentHandler`\n        to read only the given `element`\n    \"\"\"\n    from ligo.lw.ligolw import PartialLIGOLWContentHandler\n    from ligo.lw.table import Table\n\n    if issubclass(element, Table):\n        def _element_filter(name, attrs):\n            return element.CheckProperties(name, attrs)\n    else:\n        def _element_filter(name, _):\n            return name == element.tagName\n\n    return build_content_handler(PartialLIGOLWContentHandler, _element_filter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a FilteringLIGOLWContentHandler to exclude this element and its children.", "response": "def get_filtering_contenthandler(element):\n    \"\"\"Build a `FilteringLIGOLWContentHandler` to exclude this element\n\n    Parameters\n    ----------\n    element : `type`, subclass of :class:`~ligo.lw.ligolw.Element`\n        the element to exclude (and its children)\n\n    Returns\n    -------\n    contenthandler : `type`\n        a subclass of\n        :class:`~ligo.lw.ligolw.FilteringLIGOLWContentHandler` to\n        exclude an element and its children\n    \"\"\"\n    from ligo.lw.ligolw import FilteringLIGOLWContentHandler\n    from ligo.lw.table import Table\n\n    if issubclass(element, Table):\n        def _element_filter(name, attrs):\n            return ~element.CheckProperties(name, attrs)\n    else:\n        def _element_filter(name, _):\n            # pylint: disable=unused-argument\n            return name != element.tagName\n\n    return build_content_handler(FilteringLIGOLWContentHandler,\n                                 _element_filter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_content_handler(parent, filter_func):\n    from ligo.lw.lsctables import use_in\n\n    class _ContentHandler(parent):\n        # pylint: disable=too-few-public-methods\n        def __init__(self, document):\n            super(_ContentHandler, self).__init__(document, filter_func)\n\n    return use_in(_ContentHandler)", "response": "Build a ~xml. sax. handler. ContentHandler with a given filter\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread one or more LIGO_LW format files into a single Document object.", "response": "def read_ligolw(source, contenthandler=LIGOLWContentHandler, **kwargs):\n    \"\"\"Read one or more LIGO_LW format files\n\n    Parameters\n    ----------\n    source : `str`, `file`\n        the open file or file path to read\n\n    contenthandler : `~xml.sax.handler.ContentHandler`, optional\n        content handler used to parse document\n\n    verbose : `bool`, optional\n        be verbose when reading files, default: `False`\n\n    Returns\n    -------\n    xmldoc : :class:`~ligo.lw.ligolw.Document`\n        the document object as parsed from the file(s)\n    \"\"\"\n    from ligo.lw.ligolw import Document\n    from ligo.lw import types\n    from ligo.lw.lsctables import use_in\n    from ligo.lw.utils import (load_url, ligolw_add)\n\n    # mock ToPyType to link to numpy dtypes\n    topytype = types.ToPyType.copy()\n    for key in types.ToPyType:\n        if key in types.ToNumPyType:\n            types.ToPyType[key] = numpy.dtype(types.ToNumPyType[key]).type\n\n    contenthandler = use_in(contenthandler)\n\n    # read one or more files into a single Document\n    source = file_list(source)\n    try:\n        if len(source) == 1:\n            return load_url(\n                source[0],\n                contenthandler=contenthandler,\n                **kwargs\n            )\n        return ligolw_add.ligolw_add(\n            Document(),\n            source,\n            contenthandler=contenthandler,\n            **kwargs\n        )\n    except LigolwElementError as exc:\n        # failed to read with ligo.lw,\n        # try again with glue.ligolw (ilwdchar_compat)\n        if LIGO_LW_COMPAT_ERROR.search(str(exc)):\n            try:\n                return read_ligolw(\n                    source,\n                    contenthandler=contenthandler,\n                    ilwdchar_compat=True,\n                    **kwargs\n                )\n            except Exception:  # if fails for any reason, use original error\n                pass\n        raise\n    finally:  # replace ToPyType\n        types.ToPyType = topytype"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecorates a LIGO_LW - reading function to open a filepath if needed func should be written to presume a", "response": "def with_read_ligolw(func=None, contenthandler=None):\n    \"\"\"Decorate a LIGO_LW-reading function to open a filepath if needed\n\n    ``func`` should be written to presume a\n    :class:`~ligo.lw.ligolw.Document` as the first positional argument\n    \"\"\"\n    def decorator(func_):\n        # pylint: disable=missing-docstring\n        @wraps(func_)\n        def decorated_func(source, *args, **kwargs):\n            # pylint: disable=missing-docstring\n            from ligo.lw.ligolw import Document\n            from glue.ligolw.ligolw import Document as GlueDocument\n            if not isinstance(source, (Document, GlueDocument)):\n                read_kw = {\n                    'contenthandler': kwargs.pop('contenthandler',\n                                                 contenthandler),\n                    'verbose': kwargs.pop('verbose', False),\n                }\n                return func_(read_ligolw(source, **read_kw), *args, **kwargs)\n            return func_(source, *args, **kwargs)\n\n        return decorated_func\n\n    if func is not None:\n        return decorator(func)\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a LIGO_LW table from one or more files.", "response": "def read_table(source, tablename=None, columns=None, contenthandler=None,\n               **kwargs):\n    \"\"\"Read a :class:`~ligo.lw.table.Table` from one or more LIGO_LW files\n\n    Parameters\n    ----------\n    source : `Document`, `file`, `str`, `CacheEntry`, `list`\n        object representing one or more files. One of\n\n        - a LIGO_LW :class:`~ligo.lw.ligolw.Document`\n        - an open `file`\n        - a `str` pointing to a file path on disk\n        - a formatted :class:`~lal.utils.CacheEntry` representing one file\n        - a `list` of `str` file paths or :class:`~lal.utils.CacheEntry`\n\n    tablename : `str`\n        name of the table to read.\n\n    columns : `list`, optional\n        list of column name strings to read, default all.\n\n    contenthandler : `~xml.sax.handler.ContentHandler`, optional\n        SAX content handler for parsing LIGO_LW documents.\n\n    **kwargs\n        other keyword arguments are passed to `~gwpy.io.ligolw.read_ligolw`\n\n    Returns\n    -------\n    table : :class:`~ligo.lw.table.Table`\n        `Table` of data\n    \"\"\"\n    from ligo.lw.ligolw import Document\n    from ligo.lw import (table, lsctables)\n\n    # get ilwdchar_compat to pass to read_ligolw()\n    if Document.__module__.startswith(\"glue\"):\n        kwargs[\"ilwdchar_compat\"] = True\n\n    # get content handler to read only this table (if given)\n    if tablename is not None:\n        tableclass = lsctables.TableByName[\n            table.Table.TableName(tablename)\n        ]\n        if contenthandler is None:\n            contenthandler = get_partial_contenthandler(tableclass)\n\n        # overwrite loading column names to get just what was asked for\n        _oldcols = tableclass.loadcolumns\n        if columns is not None:\n            tableclass.loadcolumns = columns\n\n    # read document\n    if isinstance(source, Document):\n        xmldoc = source\n    else:\n        if contenthandler is None:\n            contenthandler = lsctables.use_in(LIGOLWContentHandler)\n        try:\n            xmldoc = read_ligolw(source, contenthandler=contenthandler,\n                                 **kwargs)\n        finally:  # reinstate original set of loading column names\n            if tablename is not None:\n                tableclass.loadcolumns = _oldcols\n\n    # now find the right table\n    if tablename is None:\n        tables = list_tables(xmldoc)\n        if not tables:\n            raise ValueError(\"No tables found in LIGO_LW document(s)\")\n        if len(tables) > 1:\n            tlist = \"'{}'\".format(\"', '\".join(tables))\n            raise ValueError(\"Multiple tables found in LIGO_LW document(s), \"\n                             \"please specify the table to read via the \"\n                             \"``tablename=`` keyword argument. The following \"\n                             \"tables were found: {}\".format(tlist))\n        tableclass = lsctables.TableByName[table.Table.TableName(tables[0])]\n\n    # extract table\n    return tableclass.get_table(xmldoc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying and open an existing LIGO_LW - format file or create a new Document with the same content as the original one.", "response": "def open_xmldoc(fobj, **kwargs):\n    \"\"\"Try and open an existing LIGO_LW-format file, or create a new Document\n\n    Parameters\n    ----------\n    fobj : `str`, `file`\n        file path or open file object to read\n\n    **kwargs\n        other keyword arguments to pass to\n        :func:`~ligo.lw.utils.load_filename`, or\n        :func:`~ligo.lw.utils.load_fileobj` as appropriate\n\n    Returns\n    --------\n    xmldoc : :class:`~ligo.lw.ligolw.Document`\n        either the `Document` as parsed from an existing file, or a new, empty\n        `Document`\n    \"\"\"\n    from ligo.lw.ligolw import (Document, LIGOLWContentHandler)\n    from ligo.lw.lsctables import use_in\n    from ligo.lw.utils import (load_filename, load_fileobj)\n\n    use_in(kwargs.setdefault('contenthandler', LIGOLWContentHandler))\n\n    try:  # try and load existing file\n        if isinstance(fobj, string_types):\n            return load_filename(fobj, **kwargs)\n        if isinstance(fobj, FILE_LIKE):\n            return load_fileobj(fobj, **kwargs)[0]\n    except (OSError, IOError):  # or just create a new Document\n        return Document()\n    except LigolwElementError as exc:\n        if LIGO_LW_COMPAT_ERROR.search(str(exc)):\n            try:\n                return open_xmldoc(fobj, ilwdchar_compat=True, **kwargs)\n            except Exception:  # for any reason, raise original\n                pass\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ligolw_element(xmldoc):\n    from ligo.lw.ligolw import LIGO_LW\n    try:\n        from glue.ligolw.ligolw import LIGO_LW as LIGO_LW2\n    except ImportError:\n        ligolw_types = (LIGO_LW,)\n    else:\n        ligolw_types = (LIGO_LW, LIGO_LW2)\n\n    if isinstance(xmldoc, ligolw_types):\n        return xmldoc\n    else:\n        for node in xmldoc.childNodes:\n            if isinstance(node, ligolw_types):\n                return node\n    raise ValueError(\"Cannot find LIGO_LW element in XML Document\")", "response": "Find an existing LIGO_LW element in this XML Document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the given list of tables into a LIGO_LW document.", "response": "def write_tables_to_document(xmldoc, tables, overwrite=False):\n    \"\"\"Write the given LIGO_LW table into a :class:`Document`\n\n    Parameters\n    ----------\n    xmldoc : :class:`~ligo.lw.ligolw.Document`\n        the document to write into\n\n    tables : `list` of :class:`~ligo.lw.table.Table`\n        the set of tables to write\n\n    overwrite : `bool`, optional, default: `False`\n        if `True`, delete an existing instance of the table type, otherwise\n        append new rows\n    \"\"\"\n    from ligo.lw.ligolw import LIGO_LW\n    from ligo.lw import lsctables\n\n    # find or create LIGO_LW tag\n    try:\n        llw = get_ligolw_element(xmldoc)\n    except ValueError:\n        llw = LIGO_LW()\n        xmldoc.appendChild(llw)\n\n    for table in tables:\n        try:  # append new data to existing table\n            old = lsctables.TableByName[\n                table.TableName(table.Name)].get_table(xmldoc)\n        except ValueError:  # or create a new table\n            llw.appendChild(table)\n        else:\n            if overwrite:\n                llw.removeChild(old)\n                old.unlink()\n                llw.appendChild(table)\n            else:\n                old.extend(table)\n\n    return xmldoc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a list of tables to a file or XML document.", "response": "def write_tables(target, tables, append=False, overwrite=False, **kwargs):\n    \"\"\"Write an LIGO_LW table to file\n\n    Parameters\n    ----------\n    target : `str`, `file`, :class:`~ligo.lw.ligolw.Document`\n        the file or document to write into\n\n    tables : `list`, `tuple` of :class:`~ligo.lw.table.Table`\n        the tables to write\n\n    append : `bool`, optional, default: `False`\n        if `True`, append to an existing file/table, otherwise `overwrite`\n\n    overwrite : `bool`, optional, default: `False`\n        if `True`, delete an existing instance of the table type, otherwise\n        append new rows\n\n    **kwargs\n        other keyword arguments to pass to\n        :func:`~ligo.lw.utils.load_filename`, or\n        :func:`~ligo.lw.utils.load_fileobj` as appropriate\n    \"\"\"\n    from ligo.lw.ligolw import (Document, LIGO_LW, LIGOLWContentHandler)\n    from ligo.lw import utils as ligolw_utils\n\n    # allow writing directly to XML\n    if isinstance(target, (Document, LIGO_LW)):\n        xmldoc = target\n    # open existing document, if possible\n    elif append:\n        xmldoc = open_xmldoc(\n            target, contenthandler=kwargs.pop('contenthandler',\n                                              LIGOLWContentHandler))\n    # fail on existing document and not overwriting\n    elif (not overwrite and isinstance(target, string_types) and\n          os.path.isfile(target)):\n        raise IOError(\"File exists: {}\".format(target))\n    else:  # or create a new document\n        xmldoc = Document()\n\n    # convert table to format\n    write_tables_to_document(xmldoc, tables, overwrite=overwrite)\n\n    # write file\n    if isinstance(target, string_types):\n        kwargs.setdefault('gz', target.endswith('.gz'))\n        ligolw_utils.write_filename(xmldoc, target, **kwargs)\n    elif isinstance(target, FILE_LIKE):\n        kwargs.setdefault('gz', target.name.endswith('.gz'))\n        ligolw_utils.write_fileobj(xmldoc, target, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_tables(source):\n    # pylint: disable=line-too-long\n    \"\"\"List the names of all tables in this file(s)\n\n    Parameters\n    ----------\n    source : `file`, `str`, :class:`~ligo.lw.ligolw.Document`, `list`\n        one or more open files, file paths, or LIGO_LW `Document`s\n\n    Examples\n    --------\n    >>> from gwpy.io.ligolw import list_tables\n    >>> print(list_tables('H1-LDAS_STRAIN-968654552-10.xml.gz'))\n    ['process', 'process_params', 'sngl_burst', 'search_summary', 'segment_definer', 'segment_summary', 'segment']\n    \"\"\"  # noqa: E501\n    try:\n        from ligo.lw.ligolw import (Document, Stream)\n    except ImportError:  # no python-ligo-lw\n        from glue.ligolw.ligolw import Document, Stream\n\n    # read file object\n    if isinstance(source, Document):\n        xmldoc = source\n    else:\n        filt = get_filtering_contenthandler(Stream)\n        xmldoc = read_ligolw(source, contenthandler=filt)\n\n    # get list of table names\n    tables = []\n    for tbl in xmldoc.childNodes[0].childNodes:\n        try:\n            tables.append(tbl.TableName(tbl.Name))\n        except AttributeError:  # not a table\n            continue\n    return tables", "response": "List the names of all tables in this file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_table_type(val, cls, colname):\n    from ligo.lw.types import (\n        ToNumPyType as numpytypes,\n        ToPyType as pytypes,\n    )\n\n    # if nothing to do...\n    if val is None or colname not in cls.validcolumns:\n        return val\n\n    llwtype = cls.validcolumns[colname]\n\n    # don't mess with formatted IlwdChar\n    if llwtype == 'ilwd:char':\n        return _to_ilwd(val, cls.tableName, colname,\n                        ilwdchar_compat=_is_glue_ligolw_object(cls))\n    # otherwise map to numpy or python types\n    try:\n        return numpy.typeDict[numpytypes[llwtype]](val)\n    except KeyError:\n        return pytypes[llwtype](val)", "response": "Cast a value to the correct type for inclusion in a LIGO_LW table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nidentify a file object as LIGO_LW - format XML", "response": "def is_ligolw(origin, filepath, fileobj, *args, **kwargs):\n    \"\"\"Identify a file object as LIGO_LW-format XML\n    \"\"\"\n    # pylint: disable=unused-argument\n    if fileobj is not None:\n        loc = fileobj.tell()\n        fileobj.seek(0)\n        try:\n            line1 = fileobj.readline().lower()\n            line2 = fileobj.readline().lower()\n            try:\n                return (line1.startswith(XML_SIGNATURE) and\n                        line2.startswith((LIGOLW_SIGNATURE, LIGOLW_ELEMENT)))\n            except TypeError:  # bytes vs str\n                return (line1.startswith(XML_SIGNATURE.decode('utf-8')) and\n                        line2.startswith((LIGOLW_SIGNATURE.decode('utf-8'),\n                                          LIGOLW_ELEMENT.decode('utf-8'))))\n        finally:\n            fileobj.seek(loc)\n    try:\n        from ligo.lw.ligolw import Element\n    except ImportError:\n        return False\n    try:\n        from glue.ligolw.ligolw import Element as GlueElement\n    except ImportError:\n        element_types = (Element,)\n    else:\n        element_types = (Element, GlueElement)\n    return len(args) > 0 and isinstance(args[0], element_types)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nidentifying a file object as XML", "response": "def is_xml(origin, filepath, fileobj, *args, **kwargs):\n    \"\"\"Identify a file object as XML (any format)\n    \"\"\"\n    # pylint: disable=unused-argument\n    if fileobj is not None:\n        loc = fileobj.tell()\n        fileobj.seek(0)\n        try:\n            sig = fileobj.read(5).lower()\n            return sig == XML_SIGNATURE\n        finally:\n            fileobj.seek(loc)\n    elif filepath is not None:\n        return filepath.endswith(('.xml', '.xml.gz'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_hdf5_timeseries(h5f, path=None, start=None, end=None, **kwargs):\n    # read data\n    kwargs.setdefault('array_type', TimeSeries)\n    series = read_hdf5_array(h5f, path=path, **kwargs)\n    # crop if needed\n    if start is not None or end is not None:\n        return series.crop(start, end)\n    return series", "response": "Read a TimeSeries from HDF5 file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a TimeSeriesDict from HDF5 file", "response": "def read_hdf5_dict(h5f, names=None, group=None, **kwargs):\n    \"\"\"Read a `TimeSeriesDict` from HDF5\n    \"\"\"\n    # find group from which to read\n    if group:\n        h5g = h5f[group]\n    else:\n        h5g = h5f\n\n    # find list of names to read\n    if names is None:\n        names = [key for key in h5g if _is_timeseries_dataset(h5g[key])]\n\n    # read names\n    out = kwargs.pop('dict_type', TimeSeriesDict)()\n    kwargs.setdefault('array_type', out.EntryClass)\n    for name in names:\n        out[name] = read_hdf5_timeseries(h5g[name], **kwargs)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a TimeSeriesBaseDict to HDF5 file.", "response": "def write_hdf5_dict(tsdict, h5f, group=None, **kwargs):\n    \"\"\"Write a `TimeSeriesBaseDict` to HDF5\n\n    Each series in the dict is written as a dataset in the group\n    \"\"\"\n    # create group if needed\n    if group and group not in h5f:\n        h5g = h5f.create_group(group)\n    elif group:\n        h5g = h5f[group]\n    else:\n        h5g = h5f\n\n    # write each timeseries\n    kwargs.setdefault('format', 'hdf5')\n    for key, series in tsdict.items():\n        series.write(h5g, path=str(key), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate a PSD using Welch s method with a mean average average.", "response": "def welch(timeseries, segmentlength, noverlap=None, scheme=None, **kwargs):\n    \"\"\"Calculate a PSD using Welch's method with a mean average\n\n    Parameters\n    ----------\n    timeseries : `~gwpy.timeseries.TimeSeries`\n        input `TimeSeries` data.\n\n    segmentlength : `int`\n        number of samples in single average.\n\n    noverlap : `int`\n        number of samples to overlap between segments, defaults to 50%.\n\n    scheme : `pycbc.scheme.Scheme`, optional\n        processing scheme in which to execute FFT, default: `None`\n\n    **kwargs\n        other keyword arguments to pass to :func:`pycbc.psd.welch`\n\n    Returns\n    -------\n    spectrum : `~gwpy.frequencyseries.FrequencySeries`\n        average power `FrequencySeries`\n\n    See also\n    --------\n    pycbc.psd.welch\n    \"\"\"\n    from pycbc.psd import welch as pycbc_welch\n\n    # default to 'standard' welch\n    kwargs.setdefault('avg_method', 'mean')\n\n    # get scheme\n    if scheme is None:\n        scheme = null_context()\n\n    # generate pycbc FrequencySeries\n    with scheme:\n        pycbc_fseries = pycbc_welch(timeseries.to_pycbc(copy=False),\n                                    seg_len=segmentlength,\n                                    seg_stride=segmentlength-noverlap,\n                                    **kwargs)\n\n    # return GWpy FrequencySeries\n    fseries = FrequencySeries.from_pycbc(pycbc_fseries, copy=False)\n    fseries.name = timeseries.name\n    fseries.override_unit(scale_timeseries_unit(\n        timeseries.unit, scaling='density'))\n    return fseries"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the ordinal string for a given integer", "response": "def _ordinal(n):\n    \"\"\"Returns the ordinal string for a given integer\n\n    See https://stackoverflow.com/a/20007730/1307974\n\n    Parameters\n    ----------\n    n : `int`\n        the number to convert to ordinal\n\n    Examples\n    --------\n    >>> _ordinal(11)\n    '11th'\n    >>> _ordinal(102)\n    '102nd'\n    \"\"\"\n    idx = int((n//10 % 10 != 1) * (n % 10 < 4) * n % 10)\n    return '{}{}'.format(n, \"tsnrhtdd\"[idx::4])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the ratio of this Spectrogram against a reference frequency series or quantity.", "response": "def ratio(self, operand):\n        \"\"\"Calculate the ratio of this `Spectrogram` against a reference\n\n        Parameters\n        ----------\n        operand : `str`, `FrequencySeries`, `Quantity`\n            a `~gwpy.frequencyseries.FrequencySeries` or\n            `~astropy.units.Quantity` to weight against, or one of\n\n            - ``'mean'`` : weight against the mean of each spectrum\n              in this Spectrogram\n            - ``'median'`` : weight against the median of each spectrum\n              in this Spectrogram\n\n        Returns\n        -------\n        spectrogram : `Spectrogram`\n            a new `Spectrogram`\n\n        Raises\n        ------\n        ValueError\n            if ``operand`` is given as a `str` that isn't supported\n        \"\"\"\n        if isinstance(operand, string_types):\n            if operand == 'mean':\n                operand = self.mean(axis=0)\n            elif operand == 'median':\n                operand = self.median(axis=0)\n            else:\n                raise ValueError(\"operand %r unrecognised, please give a \"\n                                 \"Quantity or one of: 'mean', 'median'\"\n                                 % operand)\n        out = self / operand\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot(self, figsize=(12, 6), xscale='auto-gps', **kwargs):\n        if 'imshow' in kwargs:\n            warnings.warn('the imshow keyword for Spectrogram.plot was '\n                          'removed, please pass method=\\'imshow\\' instead',\n                          DeprecationWarning)\n            kwargs.setdefault('method', 'imshow' if kwargs.pop('imshow') else\n                                        'pcolormesh')\n        kwargs.update(figsize=figsize, xscale=xscale)\n        return super(Spectrogram, self).plot(**kwargs)", "response": "Plot the data for this Spectrogram object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a new Spectrogram object from a list of frequency series.", "response": "def from_spectra(cls, *spectra, **kwargs):\n        \"\"\"Build a new `Spectrogram` from a list of spectra.\n\n        Parameters\n        ----------\n        *spectra\n            any number of `~gwpy.frequencyseries.FrequencySeries` series\n        dt : `float`, `~astropy.units.Quantity`, optional\n            stride between given spectra\n\n        Returns\n        -------\n        Spectrogram\n            a new `Spectrogram` from a vertical stacking of the spectra\n            The new object takes the metadata from the first given\n            `~gwpy.frequencyseries.FrequencySeries` if not given explicitly\n\n        Notes\n        -----\n        Each `~gwpy.frequencyseries.FrequencySeries` passed to this\n        constructor must be the same length.\n        \"\"\"\n        data = numpy.vstack([s.value for s in spectra])\n        spec1 = list(spectra)[0]\n        if not all(s.f0 == spec1.f0 for s in spectra):\n            raise ValueError(\"Cannot stack spectra with different f0\")\n        if not all(s.df == spec1.df for s in spectra):\n            raise ValueError(\"Cannot stack spectra with different df\")\n        kwargs.setdefault('name', spec1.name)\n        kwargs.setdefault('channel', spec1.channel)\n        kwargs.setdefault('epoch', spec1.epoch)\n        kwargs.setdefault('f0', spec1.f0)\n        kwargs.setdefault('df', spec1.df)\n        kwargs.setdefault('unit', spec1.unit)\n        if not ('dt' in kwargs or 'times' in kwargs):\n            try:\n                kwargs.setdefault('dt', spectra[1].epoch.gps - spec1.epoch.gps)\n            except (AttributeError, IndexError):\n                raise ValueError(\"Cannot determine dt (time-spacing) for \"\n                                 \"Spectrogram from inputs\")\n        return Spectrogram(data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating a given spectral percentile for this Spectrogram.", "response": "def percentile(self, percentile):\n        \"\"\"Calculate a given spectral percentile for this `Spectrogram`.\n\n        Parameters\n        ----------\n        percentile : `float`\n            percentile (0 - 100) of the bins to compute\n\n        Returns\n        -------\n        spectrum : `~gwpy.frequencyseries.FrequencySeries`\n            the given percentile `FrequencySeries` calculated from this\n            `SpectralVaraicence`\n        \"\"\"\n        out = scipy.percentile(self.value, percentile, axis=0)\n        if self.name is not None:\n            name = '{}: {} percentile'.format(self.name, _ordinal(percentile))\n        else:\n            name = None\n        return FrequencySeries(out, epoch=self.epoch, channel=self.channel,\n                               name=name, f0=self.f0, df=self.df,\n                               frequencies=(hasattr(self, '_frequencies') and\n                                            self.frequencies or None))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the SpectralVariance of this Spectrogram.", "response": "def variance(self, bins=None, low=None, high=None, nbins=500,\n                 log=False, norm=False, density=False):\n        \"\"\"Calculate the `SpectralVariance` of this `Spectrogram`.\n\n        Parameters\n        ----------\n        bins : `~numpy.ndarray`, optional, default `None`\n            array of histogram bin edges, including the rightmost edge\n        low : `float`, optional, default: `None`\n            left edge of lowest amplitude bin, only read\n            if ``bins`` is not given\n        high : `float`, optional, default: `None`\n            right edge of highest amplitude bin, only read\n            if ``bins`` is not given\n        nbins : `int`, optional, default: `500`\n            number of bins to generate, only read if ``bins`` is not\n            given\n        log : `bool`, optional, default: `False`\n            calculate amplitude bins over a logarithmic scale, only\n            read if ``bins`` is not given\n        norm : `bool`, optional, default: `False`\n            normalise bin counts to a unit sum\n        density : `bool`, optional, default: `False`\n            normalise bin counts to a unit integral\n\n        Returns\n        -------\n        specvar : `SpectralVariance`\n            2D-array of spectral frequency-amplitude counts\n\n        See Also\n        --------\n        :func:`numpy.histogram`\n            for details on specifying bins and weights\n        \"\"\"\n        from ..frequencyseries import SpectralVariance\n        return SpectralVariance.from_spectrogram(\n            self, bins=bins, low=low, high=high, nbins=nbins, log=log,\n            norm=norm, density=density)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncrop this Spectrogram to the specified frequencies.", "response": "def crop_frequencies(self, low=None, high=None, copy=False):\n        \"\"\"Crop this `Spectrogram` to the specified frequencies\n\n        Parameters\n        ----------\n        low : `float`\n            lower frequency bound for cropped `Spectrogram`\n        high : `float`\n            upper frequency bound for cropped `Spectrogram`\n        copy : `bool`\n            if `False` return a view of the original data, otherwise create\n            a fresh memory copy\n\n        Returns\n        -------\n        spec : `Spectrogram`\n            A new `Spectrogram` with a subset of data from the frequency\n            axis\n        \"\"\"\n        if low is not None:\n            low = units.Quantity(low, self._default_yunit)\n        if high is not None:\n            high = units.Quantity(high, self._default_yunit)\n        # check low frequency\n        if low is not None and low == self.f0:\n            low = None\n        elif low is not None and low < self.f0:\n            warnings.warn('Spectrogram.crop_frequencies given low frequency '\n                          'cutoff below f0 of the input Spectrogram. Low '\n                          'frequency crop will have no effect.')\n        # check high frequency\n        if high is not None and high.value == self.band[1]:\n            high = None\n        elif high is not None and high.value > self.band[1]:\n            warnings.warn('Spectrogram.crop_frequencies given high frequency '\n                          'cutoff above cutoff of the input Spectrogram. High '\n                          'frequency crop will have no effect.')\n        # find low index\n        if low is None:\n            idx0 = None\n        else:\n            idx0 = int(float(low.value - self.f0.value) // self.df.value)\n        # find high index\n        if high is None:\n            idx1 = None\n        else:\n            idx1 = int(float(high.value - self.f0.value) // self.df.value)\n        # crop\n        if copy:\n            return self[:, idx0:idx1].copy()\n        return self[:, idx0:idx1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the most recently added mappable layer in the given axes.", "response": "def find_mappable(*axes):\n    \"\"\"Find the most recently added mappable layer in the given axes\n\n    Parameters\n    ----------\n    *axes : `~matplotlib.axes.Axes`\n        one or more axes to search for a mappable\n    \"\"\"\n    for ax in axes:\n        for aset in ('collections', 'images'):\n            try:\n                return getattr(ax, aset)[-1]\n            except (AttributeError, IndexError):\n                continue\n    raise ValueError(\"Cannot determine mappable layer on any axes \"\n                     \"for this colorbar\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef identify_with_list(identifier):\n    @wraps(identifier)\n    def decorated_func(origin, filepath, fileobj, *args, **kwargs):\n        # pylint: disable=missing-docstring\n        try:\n            filepath = file_list(filepath)[0]\n        except ValueError:\n            if filepath is None:\n                try:\n                    files = file_list(args[0])\n                except (IndexError, ValueError):\n                    pass\n                else:\n                    if files:\n                        filepath = files[0]\n        except IndexError:\n            pass\n        return identifier(origin, filepath, fileobj, *args, **kwargs)\n    return decorated_func", "response": "Decorate an I / O identifier to handle a list of files as input\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_read_format(cls, source, args, kwargs):\n    ctx = None\n    if isinstance(source, FILE_LIKE):\n        fileobj = source\n        filepath = source.name if hasattr(source, 'name') else None\n    else:\n        filepath = source\n        try:\n            ctx = get_readable_fileobj(filepath, encoding='binary')\n            fileobj = ctx.__enter__()  # pylint: disable=no-member\n        except IOError:\n            raise\n        except Exception:  # pylint: disable=broad-except\n            fileobj = None\n    try:\n        return get_format('read', cls, filepath, fileobj, args, kwargs)\n    finally:\n        if ctx is not None:\n            ctx.__exit__(*sys.exc_info())", "response": "Determine the read format for a given source"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a WAV file into a TimeSeries object", "response": "def read(fobj, **kwargs):\n    \"\"\"Read a WAV file into a `TimeSeries`\n\n    Parameters\n    ----------\n    fobj : `file`, `str`\n        open file-like object or filename to read from\n\n    **kwargs\n        all keyword arguments are passed onto :func:`scipy.io.wavfile.read`\n\n    See also\n    --------\n    scipy.io.wavfile.read\n        for details on how the WAV file is actually read\n\n    Examples\n    --------\n    >>> from gwpy.timeseries import TimeSeries\n    >>> t = TimeSeries.read('test.wav')\n    \"\"\"\n    fsamp, arr = wavfile.read(fobj, **kwargs)\n    return TimeSeries(arr, sample_rate=fsamp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(series, output, scale=None):\n    fsamp = int(series.sample_rate.decompose().value)\n    if scale is None:\n        scale = 1 / numpy.abs(series.value).max()\n    data = (series.value * scale).astype('float32')\n    return wavfile.write(output, fsamp, data)", "response": "Write a TimeSeries to a WAV file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_wav(origin, filepath, fileobj, *args, **kwargs):\n    # pylint: disable=unused-argument\n    if origin == 'read' and fileobj is not None:\n        loc = fileobj.tell()\n        fileobj.seek(0)\n        try:\n            riff, _, fmt = struct.unpack('<4sI4s', fileobj.read(12))\n            if isinstance(riff, bytes):\n                riff = riff.decode('utf-8')\n                fmt = fmt.decode('utf-8')\n            return riff == WAV_SIGNATURE[0] and fmt == WAV_SIGNATURE[1]\n        except (UnicodeDecodeError, struct.error):\n            return False\n        finally:\n            fileobj.seek(loc)\n    elif filepath is not None:\n        return filepath.endswith(('.wav', '.wave'))\n    else:\n        try:\n            wave.open(args[0])\n        except (wave.Error, AttributeError):\n            return False\n        else:\n            return True", "response": "Identify a file as WAV\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a column filter definition into a list of tuples.", "response": "def parse_column_filter(definition):\n    \"\"\"Parse a `str` of the form 'column>50'\n\n    Parameters\n    ----------\n    definition : `str`\n        a column filter definition of the form ``<name><operator><threshold>``\n        or ``<threshold><operator><name><operator><threshold>``, e.g.\n        ``frequency >= 10``, or ``50 < snr < 100``\n\n    Returns\n    -------\n    filters : `list` of `tuple`\n        a `list` of filter 3-`tuple`s, where each `tuple` contains the\n        following elements:\n\n        - ``column`` (`str`) - the name of the column on which to operate\n        - ``operator`` (`callable`) - the operator to call when evaluating\n          the filter\n        - ``operand`` (`anything`) - the argument to the operator function\n\n    Raises\n    ------\n    ValueError\n        if the filter definition cannot be parsed\n\n    KeyError\n        if any parsed operator string cannnot be mapped to a function from\n        the `operator` module\n\n    Notes\n    -----\n    Strings that contain non-alphanumeric characters (e.g. hyphen `-`) should\n    be quoted inside the filter definition, to prevent such characters\n    being interpreted as operators, e.g. ``channel = X1:TEST`` should always\n    be passed as ``channel = \"X1:TEST\"``.\n\n    Examples\n    --------\n    >>> parse_column_filter(\"frequency>10\")\n    [('frequency', <function operator.gt>, 10.)]\n    >>> parse_column_filter(\"50 < snr < 100\")\n    [('snr', <function operator.gt>, 50.), ('snr', <function operator.lt>, 100.)]\n    >>> parse_column_filter(\"channel = \"H1:TEST\")\n    [('channel', <function operator.eq>, 'H1:TEST')]\n    \"\"\"  # noqa\n    # parse definition into parts (skipping null tokens)\n    parts = list(generate_tokens(StringIO(definition.strip()).readline))\n    while parts[-1][0] in (token.ENDMARKER, token.NEWLINE):\n        parts = parts[:-1]\n\n    # parse simple definition: e.g: snr > 5\n    if len(parts) == 3:\n        a, b, c = parts  # pylint: disable=invalid-name\n        if a[0] in [token.NAME, token.STRING]:  # string comparison\n            name = QUOTE_REGEX.sub('', a[1])\n            oprtr = OPERATORS[b[1]]\n            value = _float_or_str(c[1])\n            return [(name, oprtr, value)]\n        elif b[0] in [token.NAME, token.STRING]:\n            name = QUOTE_REGEX.sub('', b[1])\n            oprtr = OPERATORS_INV[b[1]]\n            value = _float_or_str(a[1])\n            return [(name, oprtr, value)]\n\n    # parse between definition: e.g: 5 < snr < 10\n    elif len(parts) == 5:\n        a, b, c, d, e = list(zip(*parts))[1]  # pylint: disable=invalid-name\n        name = QUOTE_REGEX.sub('', c)\n        return [(name, OPERATORS_INV[b], _float_or_str(a)),\n                (name, OPERATORS[d], _float_or_str(e))]\n\n    raise ValueError(\"Cannot parse filter definition from %r\" % definition)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing multiple compound column filter definitions.", "response": "def parse_column_filters(*definitions):\n    \"\"\"Parse multiple compound column filter definitions\n\n    Examples\n    --------\n    >>> parse_column_filters('snr > 10', 'frequency < 1000')\n    [('snr', <function operator.gt>, 10.), ('frequency', <function operator.lt>, 1000.)]\n    >>> parse_column_filters('snr > 10 && frequency < 1000')\n    [('snr', <function operator.gt>, 10.), ('frequency', <function operator.lt>, 1000.)]\n    \"\"\"  # noqa: E501\n    fltrs = []\n    for def_ in _flatten(definitions):\n        if is_filter_tuple(def_):\n            fltrs.append(def_)\n        else:\n            for splitdef in DELIM_REGEX.split(def_)[::2]:\n                fltrs.extend(parse_column_filter(splitdef))\n    return fltrs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflattening arbitrary nested list of filters into a 1 - D list", "response": "def _flatten(container):\n    \"\"\"Flatten arbitrary nested list of filters into a 1-D list\n    \"\"\"\n    if isinstance(container, string_types):\n        container = [container]\n    for elem in container:\n        if isinstance(elem, string_types) or is_filter_tuple(elem):\n            yield elem\n        else:\n            for elem2 in _flatten(elem):\n                yield elem2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_filter_tuple(tup):\n    return isinstance(tup, (tuple, list)) and (\n        len(tup) == 3 and\n        isinstance(tup[0], string_types) and\n        callable(tup[1]))", "response": "Return whether a tuple matches the format for a column filter\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying one or more column slice filters to a Table and return only those rows matching the filters", "response": "def filter_table(table, *column_filters):\n    \"\"\"Apply one or more column slice filters to a `Table`\n\n    Multiple column filters can be given, and will be applied\n    concurrently\n\n    Parameters\n    ----------\n    table : `~astropy.table.Table`\n        the table to filter\n\n    column_filter : `str`, `tuple`\n        a column slice filter definition, in one of two formats:\n\n        - `str` - e.g. ``'snr > 10``\n        - `tuple` - ``(<column>, <operator>, <operand>)``, e.g.\n          ``('snr', operator.gt, 10)``\n\n        multiple filters can be given and will be applied in order\n\n    Returns\n    -------\n    table : `~astropy.table.Table`\n        a view of the input table with only those rows matching the filters\n\n    Examples\n    --------\n    >>> filter(my_table, 'snr>10', 'frequency<1000')\n\n    custom operations can be defined using filter tuple definitions:\n\n    >>> from gwpy.table.filters import in_segmentlist\n    >>> filter(my_table, ('time', in_segmentlist, segs))\n    \"\"\"\n    keep = numpy.ones(len(table), dtype=bool)\n    for name, op_func, operand in parse_column_filters(*column_filters):\n        col = table[name].view(numpy.ndarray)\n        keep &= op_func(col, operand)\n    return table[keep]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread an Array from the given HDF5 object.", "response": "def read_hdf5_array(source, path=None, array_type=Array):\n    \"\"\"Read an `Array` from the given HDF5 object\n\n    Parameters\n    ----------\n    source : `str`, :class:`h5py.HLObject`\n        path to HDF file on disk, or open `h5py.HLObject`.\n\n    path : `str`\n        path in HDF hierarchy of dataset.\n\n    array_type : `type`\n        desired return type\n    \"\"\"\n    dataset = io_hdf5.find_dataset(source, path=path)\n    attrs = dict(dataset.attrs)\n    # unpickle channel object\n    try:\n        attrs['channel'] = _unpickle_channel(attrs['channel'])\n    except KeyError:  # no channel stored\n        pass\n    # unpack byte strings for python3\n    for key in attrs:\n        if isinstance(attrs[key], bytes):\n            attrs[key] = attrs[key].decode('utf-8')\n    return array_type(dataset[()], **attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unpickle_channel(raw):\n    try:\n        return pickle.loads(raw)\n    except (ValueError, pickle.UnpicklingError, EOFError, TypeError,\n            IndexError) as exc:\n        # maybe not pickled\n        if isinstance(raw, bytes):\n            raw = raw.decode('utf-8')\n        try:  # test if this is a valid channel name\n            Channel.MATCH.match(raw)\n        except ValueError:\n            raise exc\n        return raw", "response": "Try and unpickle a channel with sensible error handling\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _format_metadata_attribute(value):\n    if (value is None or\n            (isinstance(value, Index) and value.regular)):\n        raise IgnoredAttribute\n\n    # map type to something HDF5 can handle\n    for typekey, func in ATTR_TYPE_MAP.items():\n        if issubclass(type(value), typekey):\n            return func(value)\n    return value", "response": "Format a value for writing to HDF5 as a h5py. Dataset attribute\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_array_metadata(dataset, array):\n    for attr in ('unit',) + array._metadata_slots:\n        # format attribute\n        try:\n            value = _format_metadata_attribute(\n                getattr(array, '_%s' % attr, None))\n        except IgnoredAttribute:\n            continue\n\n        # store attribute\n        try:\n            dataset.attrs[attr] = value\n        except (TypeError, ValueError, RuntimeError) as exc:\n            exc.args = (\"Failed to store {} ({}) for {}: {}\".format(\n                attr, type(value).__name__, type(array).__name__, str(exc)))\n            raise", "response": "Write metadata for array into the h5py. Dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites an array to an HDF5 dataset.", "response": "def write_hdf5_array(array, h5g, path=None, attrs=None,\n                     append=False, overwrite=False,\n                     compression='gzip', **kwargs):\n    \"\"\"Write the ``array`` to an `h5py.Dataset`\n\n    Parameters\n    ----------\n    array : `gwpy.types.Array`\n        the data object to write\n\n    h5g : `str`, `h5py.Group`\n        a file path to write to, or an `h5py.Group` in which to create\n        a new dataset\n\n    path : `str`, optional\n        the path inside the group at which to create the new dataset,\n        defaults to ``array.name``\n\n    attrs : `dict`, optional\n        extra metadata to write into `h5py.Dataset.attrs`, on top of\n        the default metadata\n\n    append : `bool`, default: `False`\n        if `True`, write new dataset to existing file, otherwise an\n        exception will be raised if the output file exists (only used if\n        ``f`` is `str`)\n\n    overwrite : `bool`, default: `False`\n        if `True`, overwrite an existing dataset in an existing file,\n        otherwise an exception will be raised if a dataset exists with\n        the given name (only used if ``f`` is `str`)\n\n    compression : `str`, `int`, optional\n        compression option to pass to :meth:`h5py.Group.create_dataset`\n\n    **kwargs\n        other keyword arguments for :meth:`h5py.Group.create_dataset`\n\n    Returns\n    -------\n    datasets : `h5py.Dataset`\n        the newly created dataset\n    \"\"\"\n    if path is None:\n        path = array.name\n    if path is None:\n        raise ValueError(\"Cannot determine HDF5 path for %s, \"\n                         \"please set ``name`` attribute, or pass ``path=`` \"\n                         \"keyword when writing\" % type(array).__name__)\n\n    # create dataset\n    dset = io_hdf5.create_dataset(h5g, path, overwrite=overwrite,\n                                  data=array.value, compression=compression,\n                                  **kwargs)\n\n    # write default metadata\n    write_array_metadata(dset, array)\n\n    # allow caller to specify their own metadata dict\n    if attrs:\n        for key in attrs:\n            dset.attrs[key] = attrs[key]\n\n    return dset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_index_array_attrs(series):\n    attrs = {}\n    # loop through named axes\n    for i, axis in zip(range(series.ndim), ('x', 'y')):\n        # find property names\n        unit = '{}unit'.format(axis)\n        origin = '{}0'.format(axis)\n        delta = 'd{}'.format(axis)\n\n        # store attributes\n        aunit = getattr(series, unit)\n        attrs.update({\n            unit: str(aunit),\n            origin: getattr(series, origin).to(aunit).value,\n            delta: getattr(series, delta).to(aunit).value,\n        })\n    return attrs", "response": "Format metadata attributes for and indexed array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a Series to HDF5.", "response": "def write_hdf5_series(series, output, path=None, attrs=None, **kwargs):\n    \"\"\"Write a Series to HDF5.\n\n    See :func:`write_hdf5_array` for details of arguments and keywords.\n    \"\"\"\n    if attrs is None:\n        attrs = format_index_array_attrs(series)\n    return write_hdf5_array(series, output, path=path, attrs=attrs, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_hdf5_array_io(array_type, format='hdf5', identify=True):\n    def from_hdf5(*args, **kwargs):\n        \"\"\"Read an array from HDF5\n        \"\"\"\n        kwargs.setdefault('array_type', array_type)\n        return read_hdf5_array(*args, **kwargs)\n\n    io_registry.register_reader(format, array_type, from_hdf5)\n    if issubclass(array_type, Series):\n        io_registry.register_writer(format, array_type, write_hdf5_series)\n    else:\n        io_registry.register_writer(format, array_type, write_hdf5_array)\n\n    if identify:\n        io_registry.register_identifier(format, array_type,\n                                        io_hdf5.identify_hdf5)", "response": "Register the read and write methods for the HDF5 array type"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_multi(flatten, cls, source, *args, **kwargs):\n    verbose = kwargs.pop('verbose', False)\n\n    # parse input as a list of files\n    try:  # try and map to a list of file-like objects\n        files = file_list(source)\n    except ValueError:  # otherwise treat as single file\n        files = [source]\n        path = None  # to pass to get_read_format()\n    else:\n        path = files[0] if files else None\n\n    # determine input format (so we don't have to do it multiple times)\n    if kwargs.get('format', None) is None:\n        kwargs['format'] = get_read_format(cls, path, (source,) + args, kwargs)\n\n    # calculate maximum number of processes\n    nproc = min(kwargs.pop('nproc', 1), len(files))\n\n    # define multiprocessing method\n    def _read_single_file(fobj):\n        try:\n            return fobj, io_read(cls, fobj, *args, **kwargs)\n        # pylint: disable=broad-except,redefine-in-handler\n        except Exception as exc:\n            if nproc == 1:\n                raise\n            if isinstance(exc, SAXException):  # SAXExceptions don't pickle\n                return fobj, exc.getException()  # pylint: disable=no-member\n            return fobj, exc\n\n    # format verbosity\n    if verbose is True:\n        verbose = 'Reading ({})'.format(kwargs['format'])\n\n    # read files\n    output = mp_utils.multiprocess_with_queues(\n        nproc, _read_single_file, files, verbose=verbose, unit='files')\n\n    # raise exceptions (from multiprocessing, single process raises inline)\n    for fobj, exc in output:\n        if isinstance(exc, Exception):\n            exc.args = ('Failed to read %s: %s' % (fobj, str(exc)),)\n            raise exc\n\n    # return combined object\n    _, out = zip(*output)\n    return flatten(out)", "response": "Read multiple source files into a single cls with multiprocessing"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a DataQualityFlag from a segments - web. ligo. org JSON file", "response": "def read_json_flag(fobj):\n    \"\"\"Read a `DataQualityFlag` from a segments-web.ligo.org JSON file\n    \"\"\"\n    # read from filename\n    if isinstance(fobj, string_types):\n        with open(fobj, 'r') as fobj2:\n            return read_json_flag(fobj2)\n\n    # read from open file\n    txt = fobj.read()\n    if isinstance(txt, bytes):\n        txt = txt.decode('utf-8')\n    data = json.loads(txt)\n\n    # format flag\n    name = '{ifo}:{name}:{version}'.format(**data)\n    out = DataQualityFlag(name, active=data['active'],\n                          known=data['known'])\n\n    # parse 'metadata'\n    try:\n        out.description = data['metadata'].get('flag_description', None)\n    except KeyError:  # no metadata available, but that's ok\n        pass\n    else:\n        out.isgood = not data['metadata'].get(\n            'active_indicates_ifo_badness', False)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a DataQualityFlag to a JSON file containing the data of the current object.", "response": "def write_json_flag(flag, fobj, **kwargs):\n    \"\"\"Write a `DataQualityFlag` to a JSON file\n\n    Parameters\n    ----------\n    flag : `DataQualityFlag`\n        data to write\n\n    fobj : `str`, `file`\n        target file (or filename) to write\n\n    **kwargs\n        other keyword arguments to pass to :func:`json.dump`\n\n    See also\n    --------\n    json.dump\n        for details on acceptable keyword arguments\n    \"\"\"\n    # write to filename\n    if isinstance(fobj, string_types):\n        with open(fobj, 'w') as fobj2:\n            return write_json_flag(flag, fobj2, **kwargs)\n\n    # build json packet\n    data = {}\n    data['ifo'] = flag.ifo\n    data['name'] = flag.tag\n    data['version'] = flag.version\n    data['active'] = flag.active\n    data['known'] = flag.known\n    data['metadata'] = {}\n    data['metadata']['active_indicates_ifo_badness'] = not flag.isgood\n    data['metadata']['flag_description'] = flag.description\n\n    # write\n    json.dump(data, fobj, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the index of values lying inside the given segmentlist.", "response": "def in_segmentlist(column, segmentlist):\n    \"\"\"Return the index of values lying inside the given segmentlist\n\n    A `~gwpy.segments.Segment` represents a semi-open interval,\n    so for any segment `[a, b)`, a value `x` is 'in' the segment if\n\n    a <= x < b\n    \"\"\"\n    segmentlist = type(segmentlist)(segmentlist).coalesce()\n    idx = column.argsort()\n    contains = numpy.zeros(column.shape[0], dtype=bool)\n    j = 0\n    try:\n        segstart, segend = segmentlist[j]\n    except IndexError:  # no segments, return all False\n        return contains\n    i = 0\n    while i < contains.shape[0]:\n        # extract time for this index\n        x = idx[i]  # <- index in original column\n        time = column[x]\n        # if before start, move to next value\n        if time < segstart:\n            i += 1\n            continue\n        # if after end, find the next segment and check value again\n        if time >= segend:\n            j += 1\n            try:\n                segstart, segend = segmentlist[j]\n                continue\n            except IndexError:\n                break\n        # otherwise value must be in this segment\n        contains[x] = True\n        i += 1\n    return contains"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the URL corresponding to Python object", "response": "def linkcode_resolve(domain, info):\n    \"\"\"Determine the URL corresponding to Python object\n\n    This code is stolen with thanks from the scipy team.\n    \"\"\"\n    if domain != 'py':\n        return None\n\n    modname = info['module']\n    fullname = info['fullname']\n\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split('.'):\n        try:\n            obj = getattr(obj, part)\n        except:\n            return None\n    # try and sneak past a decorator\n    try:\n        obj = obj.im_func.func_closure[0].cell_contents\n    except (AttributeError, TypeError):\n        pass\n\n    try:\n        fn = inspect.getsourcefile(obj)\n    except:\n        fn = None\n    if not fn:\n        try:\n            fn = inspect.getsourcefile(sys.modules[obj.__module__])\n        except:\n            fn = None\n    if not fn:\n        return None\n\n    try:\n        source, lineno = inspect.findsource(obj)\n    except:\n        lineno = None\n\n    if lineno:\n        linespec = \"#L%d\" % (lineno + 1)\n    else:\n        linespec = \"\"\n\n    fn = os.path.relpath(fn, start=os.path.dirname(gwpy.__file__))\n    if fn.startswith(os.path.pardir):\n        return None\n\n    return (\"http://github.com/gwpy/gwpy/tree/%s/gwpy/%s%s\"\n            % (GWPY_VERSION['full-revisionid'], fn, linespec))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fft(self, nfft=None):\n        from ..frequencyseries import FrequencySeries\n        if nfft is None:\n            nfft = self.size\n        dft = npfft.rfft(self.value, n=nfft) / nfft\n        dft[1:] *= 2.0\n        new = FrequencySeries(dft, epoch=self.epoch, unit=self.unit,\n                              name=self.name, channel=self.channel)\n        try:\n            new.frequencies = npfft.rfftfreq(nfft, d=self.dx.value)\n        except AttributeError:\n            new.frequencies = numpy.arange(new.size) / (nfft * self.dx.value)\n        return new", "response": "Compute the one - dimensional discrete Fourier transform of this TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the average one - dimensional DFT of this TimeSeries.", "response": "def average_fft(self, fftlength=None, overlap=0, window=None):\n        \"\"\"Compute the averaged one-dimensional DFT of this `TimeSeries`.\n\n        This method computes a number of FFTs of duration ``fftlength``\n        and ``overlap`` (both given in seconds), and returns the mean\n        average. This method is analogous to the Welch average method\n        for power spectra.\n\n        Parameters\n        ----------\n        fftlength : `float`\n            number of seconds in single FFT, default, use\n            whole `TimeSeries`\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        Returns\n        -------\n        out : complex-valued `~gwpy.frequencyseries.FrequencySeries`\n            the transformed output, with populated frequencies array\n            metadata\n\n        See Also\n        --------\n        :mod:`scipy.fftpack` for the definition of the DFT and conventions\n        used.\n        \"\"\"\n        from gwpy.spectrogram import Spectrogram\n        # format lengths\n        if fftlength is None:\n            fftlength = self.duration\n        if isinstance(fftlength, units.Quantity):\n            fftlength = fftlength.value\n        nfft = int((fftlength * self.sample_rate).decompose().value)\n        noverlap = int((overlap * self.sample_rate).decompose().value)\n\n        navg = divmod(self.size-noverlap, (nfft-noverlap))[0]\n\n        # format window\n        if window is None:\n            window = 'boxcar'\n        if isinstance(window, (str, tuple)):\n            win = signal.get_window(window, nfft)\n        else:\n            win = numpy.asarray(window)\n            if len(win.shape) != 1:\n                raise ValueError('window must be 1-D')\n            elif win.shape[0] != nfft:\n                raise ValueError('Window is the wrong size.')\n        win = win.astype(self.dtype)\n        scaling = 1. / numpy.absolute(win).mean()\n\n        if nfft % 2:\n            nfreqs = (nfft + 1) // 2\n        else:\n            nfreqs = nfft // 2 + 1\n        ffts = Spectrogram(numpy.zeros((navg, nfreqs), dtype=numpy.complex),\n                           channel=self.channel, epoch=self.epoch, f0=0,\n                           df=1 / fftlength, dt=1, copy=True)\n        # stride through TimeSeries, recording FFTs as columns of Spectrogram\n        idx = 0\n        for i in range(navg):\n            # find step TimeSeries\n            idx_end = idx + nfft\n            if idx_end > self.size:\n                continue\n            stepseries = self[idx:idx_end].detrend() * win\n            # calculated FFT, weight, and stack\n            fft_ = stepseries.fft(nfft=nfft) * scaling\n            ffts.value[i, :] = fft_.value\n            idx += (nfft - noverlap)\n        mean = ffts.mean(0)\n        mean.name = self.name\n        mean.epoch = self.epoch\n        mean.channel = self.channel\n        return mean"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef psd(self, fftlength=None, overlap=None, window='hann',\n            method=DEFAULT_FFT_METHOD, **kwargs):\n        \"\"\"Calculate the PSD `FrequencySeries` for this `TimeSeries`\n\n        Parameters\n        ----------\n        fftlength : `float`\n            number of seconds in single FFT, defaults to a single FFT\n            covering the full duration\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        method : `str`, optional\n            FFT-averaging method, see *Notes* for more details\n\n        **kwargs\n            other keyword arguments are passed to the underlying\n            PSD-generation method\n\n        Returns\n        -------\n        psd :  `~gwpy.frequencyseries.FrequencySeries`\n            a data series containing the PSD.\n\n        Notes\n        -----\n        The accepted ``method`` arguments are:\n\n        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n        - ``'median'`` : a median average of overlapping periodograms\n        - ``'welch'`` : a mean average of overlapping periodograms\n        \"\"\"\n        # get method\n        method_func = spectral.get_method(method)\n\n        # calculate PSD using UI method\n        return spectral.psd(self, method_func, fftlength=fftlength,\n                            overlap=overlap, window=window, **kwargs)", "response": "Calculate the PSD for this TimeSeries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef asd(self, fftlength=None, overlap=None, window='hann',\n            method=DEFAULT_FFT_METHOD, **kwargs):\n        \"\"\"Calculate the ASD `FrequencySeries` of this `TimeSeries`\n\n        Parameters\n        ----------\n        fftlength : `float`\n            number of seconds in single FFT, defaults to a single FFT\n            covering the full duration\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        method : `str`, optional\n            FFT-averaging method, see *Notes* for more details\n\n        Returns\n        -------\n        psd :  `~gwpy.frequencyseries.FrequencySeries`\n            a data series containing the PSD.\n\n        See also\n        --------\n        TimeSeries.psd\n\n        Notes\n        -----\n        The accepted ``method`` arguments are:\n\n        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n        - ``'median'`` : a median average of overlapping periodograms\n        - ``'welch'`` : a mean average of overlapping periodograms\n        \"\"\"\n        return self.psd(method=method, fftlength=fftlength, overlap=overlap,\n                        window=window, **kwargs) ** (1/2.)", "response": "Calculate the ASD frequency series of this TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef csd(self, other, fftlength=None, overlap=None, window='hann',\n            **kwargs):\n        \"\"\"Calculate the CSD `FrequencySeries` for two `TimeSeries`\n\n        Parameters\n        ----------\n        other : `TimeSeries`\n            the second `TimeSeries` in this CSD calculation\n\n        fftlength : `float`\n            number of seconds in single FFT, defaults to a single FFT\n            covering the full duration\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        Returns\n        -------\n        csd :  `~gwpy.frequencyseries.FrequencySeries`\n            a data series containing the CSD.\n        \"\"\"\n        return spectral.psd(\n            (self, other),\n            spectral.csd,\n            fftlength=fftlength,\n            overlap=overlap,\n            window=window,\n            **kwargs\n        )", "response": "Calculate the CSD frequency series for two TimeSeries"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the average power spectrogram of this TimeSeries using the specified average spectrum method.", "response": "def spectrogram(self, stride, fftlength=None, overlap=None, window='hann',\n                    method=DEFAULT_FFT_METHOD, nproc=1, **kwargs):\n        \"\"\"Calculate the average power spectrogram of this `TimeSeries`\n        using the specified average spectrum method.\n\n        Each time-bin of the output `Spectrogram` is calculated by taking\n        a chunk of the `TimeSeries` in the segment\n        `[t - overlap/2., t + stride + overlap/2.)` and calculating the\n        :meth:`~gwpy.timeseries.TimeSeries.psd` of those data.\n\n        As a result, each time-bin is calculated using `stride + overlap`\n        seconds of data.\n\n        Parameters\n        ----------\n        stride : `float`\n            number of seconds in single PSD (column of spectrogram).\n\n        fftlength : `float`\n            number of seconds in single FFT.\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        method : `str`, optional\n            FFT-averaging method, see *Notes* for more details\n\n        nproc : `int`\n            number of CPUs to use in parallel processing of FFTs\n\n        Returns\n        -------\n        spectrogram : `~gwpy.spectrogram.Spectrogram`\n            time-frequency power spectrogram as generated from the\n            input time-series.\n\n        Notes\n        -----\n        The accepted ``method`` arguments are:\n\n        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n        - ``'median'`` : a median average of overlapping periodograms\n        - ``'welch'`` : a mean average of overlapping periodograms\n        \"\"\"\n        # get method\n        method_func = spectral.get_method(method)\n\n        # calculate PSD using UI method\n        return spectral.average_spectrogram(\n            self,\n            method_func,\n            stride,\n            fftlength=fftlength,\n            overlap=overlap,\n            window=window,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spectrogram2(self, fftlength, overlap=None, window='hann', **kwargs):\n        # set kwargs for periodogram()\n        kwargs.setdefault('fs', self.sample_rate.to('Hz').value)\n        # run\n        return spectral.spectrogram(self, signal.periodogram,\n                                    fftlength=fftlength, overlap=overlap,\n                                    window=window, **kwargs)", "response": "Calculate the non - averaged power spectrogram of this TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fftgram(self, fftlength, overlap=None, window='hann', **kwargs):\n        from ..spectrogram import Spectrogram\n        try:\n            from scipy.signal import spectrogram\n        except ImportError:\n            raise ImportError(\"Must have scipy>=0.16 to utilize \"\n                              \"this method.\")\n\n        # format lengths\n        if isinstance(fftlength, units.Quantity):\n            fftlength = fftlength.value\n\n        nfft = int((fftlength * self.sample_rate).decompose().value)\n\n        if not overlap:\n            # use scipy.signal.spectrogram noverlap default\n            noverlap = nfft // 8\n        else:\n            noverlap = int((overlap * self.sample_rate).decompose().value)\n\n        # generate output spectrogram\n        [frequencies, times, sxx] = spectrogram(self,\n                                                fs=self.sample_rate.value,\n                                                window=window,\n                                                nperseg=nfft,\n                                                noverlap=noverlap,\n                                                mode='complex',\n                                                **kwargs)\n        return Spectrogram(sxx.T,\n                           name=self.name, unit=self.unit,\n                           xindex=self.t0.value + times,\n                           yindex=frequencies)", "response": "Calculate the Fourier - gram of this TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the spectral variance of a single - process file reading.", "response": "def spectral_variance(self, stride, fftlength=None, overlap=None,\n                          method=DEFAULT_FFT_METHOD, window='hann', nproc=1,\n                          filter=None, bins=None, low=None, high=None,\n                          nbins=500, log=False, norm=False, density=False):\n        \"\"\"Calculate the `SpectralVariance` of this `TimeSeries`.\n\n        Parameters\n        ----------\n        stride : `float`\n            number of seconds in single PSD (column of spectrogram)\n\n        fftlength : `float`\n            number of seconds in single FFT\n\n        method : `str`, optional\n            FFT-averaging method, see *Notes* for more details\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        nproc : `int`\n            maximum number of independent frame reading processes, default\n            is set to single-process file reading.\n\n        bins : `numpy.ndarray`, optional, default `None`\n            array of histogram bin edges, including the rightmost edge\n\n        low : `float`, optional\n            left edge of lowest amplitude bin, only read\n            if ``bins`` is not given\n\n        high : `float`, optional\n            right edge of highest amplitude bin, only read\n            if ``bins`` is not given\n\n        nbins : `int`, optional\n            number of bins to generate, only read if ``bins`` is not\n            given\n\n        log : `bool`, optional\n            calculate amplitude bins over a logarithmic scale, only\n            read if ``bins`` is not given\n\n        norm : `bool`, optional\n            normalise bin counts to a unit sum\n\n        density : `bool`, optional\n            normalise bin counts to a unit integral\n\n        Returns\n        -------\n        specvar : `SpectralVariance`\n            2D-array of spectral frequency-amplitude counts\n\n        See Also\n        --------\n        :func:`numpy.histogram`\n            for details on specifying bins and weights\n\n        Notes\n        -----\n        The accepted ``method`` arguments are:\n\n        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n        - ``'median'`` : a median average of overlapping periodograms\n        - ``'welch'`` : a mean average of overlapping periodograms\n        \"\"\"\n        specgram = self.spectrogram(stride, fftlength=fftlength,\n                                    overlap=overlap, method=method,\n                                    window=window, nproc=nproc) ** (1/2.)\n        if filter:\n            specgram = specgram.filter(*filter)\n        return specgram.variance(bins=bins, low=low, high=high, nbins=nbins,\n                                 log=log, norm=norm, density=density)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rayleigh_spectrum(self, fftlength=None, overlap=None):\n        return spectral.psd(\n            self,\n            spectral.rayleigh,\n            fftlength=fftlength,\n            overlap=overlap,\n        )", "response": "Calculate the Rayleigh statistic for this TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the Rayleigh statistic spectrogram of this TimeSeries.", "response": "def rayleigh_spectrogram(self, stride, fftlength=None, overlap=0,\n                             nproc=1, **kwargs):\n        \"\"\"Calculate the Rayleigh statistic spectrogram of this `TimeSeries`\n\n        Parameters\n        ----------\n        stride : `float`\n            number of seconds in single PSD (column of spectrogram).\n\n        fftlength : `float`\n            number of seconds in single FFT.\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, default: ``0``\n\n        nproc : `int`, optional\n            maximum number of independent frame reading processes, default\n            default: ``1``\n\n        Returns\n        -------\n        spectrogram : `~gwpy.spectrogram.Spectrogram`\n            time-frequency Rayleigh spectrogram as generated from the\n            input time-series.\n\n        See Also\n        --------\n        TimeSeries.rayleigh\n            for details of the statistic calculation\n        \"\"\"\n        specgram = spectral.average_spectrogram(\n            self,\n            spectral.rayleigh,\n            stride,\n            fftlength=fftlength,\n            overlap=overlap,\n            nproc=nproc,\n            **kwargs\n        )\n        specgram.override_unit('')\n        return specgram"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the cross spectral density spectrogram of this TimeSeries with other.", "response": "def csd_spectrogram(self, other, stride, fftlength=None, overlap=0,\n                        window='hann', nproc=1, **kwargs):\n        \"\"\"Calculate the cross spectral density spectrogram of this\n           `TimeSeries` with 'other'.\n\n        Parameters\n        ----------\n        other : `~gwpy.timeseries.TimeSeries`\n            second time-series for cross spectral density calculation\n\n        stride : `float`\n            number of seconds in single PSD (column of spectrogram).\n\n        fftlength : `float`\n            number of seconds in single FFT.\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        nproc : `int`\n            maximum number of independent frame reading processes, default\n            is set to single-process file reading.\n\n        Returns\n        -------\n        spectrogram : `~gwpy.spectrogram.Spectrogram`\n            time-frequency cross spectrogram as generated from the\n            two input time-series.\n        \"\"\"\n        return spectral.average_spectrogram(\n            (self, other),\n            spectral.csd,\n            stride,\n            fftlength=fftlength,\n            overlap=overlap,\n            window=window,\n            nproc=nproc,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef highpass(self, frequency, gpass=2, gstop=30, fstop=None, type='iir',\n                 filtfilt=True, **kwargs):\n        \"\"\"Filter this `TimeSeries` with a high-pass filter.\n\n        Parameters\n        ----------\n        frequency : `float`\n            high-pass corner frequency\n\n        gpass : `float`\n            the maximum loss in the passband (dB).\n\n        gstop : `float`\n            the minimum attenuation in the stopband (dB).\n\n        fstop : `float`\n            stop-band edge frequency, defaults to `frequency * 1.5`\n\n        type : `str`\n            the filter type, either ``'iir'`` or ``'fir'``\n\n        **kwargs\n            other keyword arguments are passed to\n            :func:`gwpy.signal.filter_design.highpass`\n\n        Returns\n        -------\n        hpseries : `TimeSeries`\n            a high-passed version of the input `TimeSeries`\n\n        See Also\n        --------\n        gwpy.signal.filter_design.highpass\n            for details on the filter design\n        TimeSeries.filter\n            for details on how the filter is applied\n\n        .. note::\n\n           When using `scipy < 0.16.0` some higher-order filters may be\n           unstable. With `scipy >= 0.16.0` higher-order filters are\n           decomposed into second-order-sections, and so are much more stable.\n        \"\"\"\n        # design filter\n        filt = filter_design.highpass(frequency, self.sample_rate,\n                                      fstop=fstop, gpass=gpass, gstop=gstop,\n                                      analog=False, type=type, **kwargs)\n        # apply filter\n        return self.filter(*filt, filtfilt=filtfilt)", "response": "Filter this TimeSeries with a high - pass filter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering this TimeSeries with a band - pass filter.", "response": "def bandpass(self, flow, fhigh, gpass=2, gstop=30, fstop=None, type='iir',\n                 filtfilt=True, **kwargs):\n        \"\"\"Filter this `TimeSeries` with a band-pass filter.\n\n        Parameters\n        ----------\n        flow : `float`\n            lower corner frequency of pass band\n\n        fhigh : `float`\n            upper corner frequency of pass band\n\n        gpass : `float`\n            the maximum loss in the passband (dB).\n\n        gstop : `float`\n            the minimum attenuation in the stopband (dB).\n\n        fstop : `tuple` of `float`, optional\n            `(low, high)` edge-frequencies of stop band\n\n        type : `str`\n            the filter type, either ``'iir'`` or ``'fir'``\n\n        **kwargs\n            other keyword arguments are passed to\n            :func:`gwpy.signal.filter_design.bandpass`\n\n        Returns\n        -------\n        bpseries : `TimeSeries`\n            a band-passed version of the input `TimeSeries`\n\n        See Also\n        --------\n        gwpy.signal.filter_design.bandpass\n            for details on the filter design\n        TimeSeries.filter\n            for details on how the filter is applied\n\n        .. note::\n\n           When using `scipy < 0.16.0` some higher-order filters may be\n           unstable. With `scipy >= 0.16.0` higher-order filters are\n           decomposed into second-order-sections, and so are much more stable.\n        \"\"\"\n        # design filter\n        filt = filter_design.bandpass(flow, fhigh, self.sample_rate,\n                                      fstop=fstop, gpass=gpass, gstop=gstop,\n                                      analog=False, type=type, **kwargs)\n        # apply filter\n        return self.filter(*filt, filtfilt=filtfilt)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resample(self, rate, window='hamming', ftype='fir', n=None):\n        if n is None and ftype == 'iir':\n            n = 8\n        elif n is None:\n            n = 60\n\n        if isinstance(rate, units.Quantity):\n            rate = rate.value\n        factor = (self.sample_rate.value / rate)\n        # NOTE: use math.isclose when python >= 3.5\n        if numpy.isclose(factor, 1., rtol=1e-09, atol=0.):\n            warnings.warn(\n                \"resample() rate matches current sample_rate ({}), returning \"\n                \"input data unmodified; please double-check your \"\n                \"parameters\".format(self.sample_rate),\n                UserWarning,\n            )\n            return self\n        # if integer down-sampling, use decimate\n        if factor.is_integer():\n            if ftype == 'iir':\n                filt = signal.cheby1(n, 0.05, 0.8/factor, output='zpk')\n            else:\n                filt = signal.firwin(n+1, 1./factor, window=window)\n            return self.filter(filt, filtfilt=True)[::int(factor)]\n        # otherwise use Fourier filtering\n        else:\n            nsamp = int(self.shape[0] * self.dx.value * rate)\n            new = signal.resample(self.value, nsamp,\n                                  window=window).view(self.__class__)\n            new.__metadata_finalize__(self)\n            new._unit = self.unit\n            new.sample_rate = rate\n            return new", "response": "Resample this Series to a new rate and return a new Series with the resampled data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters this TimeSeries by applying a zero - pole - gain filter with a four - digit zero - pole - gain and a four - digit DC gain of 1e - 10.", "response": "def zpk(self, zeros, poles, gain, analog=True, **kwargs):\n        \"\"\"Filter this `TimeSeries` by applying a zero-pole-gain filter\n\n        Parameters\n        ----------\n        zeros : `array-like`\n            list of zero frequencies (in Hertz)\n\n        poles : `array-like`\n            list of pole frequencies (in Hertz)\n\n        gain : `float`\n            DC gain of filter\n\n        analog : `bool`, optional\n            type of ZPK being applied, if `analog=True` all parameters\n            will be converted in the Z-domain for digital filtering\n\n        Returns\n        -------\n        timeseries : `TimeSeries`\n            the filtered version of the input data\n\n        See Also\n        --------\n        TimeSeries.filter\n            for details on how a digital ZPK-format filter is applied\n\n        Examples\n        --------\n        To apply a zpk filter with file poles at 100 Hz, and five zeros at\n        1 Hz (giving an overall DC gain of 1e-10)::\n\n        >>> data2 = data.zpk([100]*5, [1]*5, 1e-10)\n        \"\"\"\n        return self.filter(zeros, poles, gain, analog=analog, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter(self, *filt, **kwargs):\n        # parse keyword arguments\n        filtfilt = kwargs.pop('filtfilt', False)\n\n        # parse filter\n        form, filt = filter_design.parse_filter(\n                filt, analog=kwargs.pop('analog', False),\n                sample_rate=self.sample_rate.to('Hz').value,\n        )\n        if form == 'zpk':\n            try:\n                sos = signal.zpk2sos(*filt)\n            except AttributeError:  # scipy < 0.16, no SOS filtering\n                sos = None\n                b, a = signal.zpk2tf(*filt)\n        else:\n            sos = None\n            b, a = filt\n\n        # perform filter\n        kwargs.setdefault('axis', 0)\n        if sos is not None and filtfilt:\n            out = signal.sosfiltfilt(sos, self, **kwargs)\n        elif sos is not None:\n            out = signal.sosfilt(sos, self, **kwargs)\n        elif filtfilt:\n            out = signal.filtfilt(b, a, self, **kwargs)\n        else:\n            out = signal.lfilter(b, a, self, **kwargs)\n\n        # format as type(self)\n        new = out.view(type(self))\n        new.__metadata_finalize__(self)\n        new._unit = self.unit\n        return new", "response": "Filter this TimeSeries with an IIR or FIR filter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coherence(self, other, fftlength=None, overlap=None,\n                  window='hann', **kwargs):\n        \"\"\"Calculate the frequency-coherence between this `TimeSeries`\n        and another.\n\n        Parameters\n        ----------\n        other : `TimeSeries`\n            `TimeSeries` signal to calculate coherence with\n\n        fftlength : `float`, optional\n            number of seconds in single FFT, defaults to a single FFT\n            covering the full duration\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        **kwargs\n            any other keyword arguments accepted by\n            :func:`matplotlib.mlab.cohere` except ``NFFT``, ``window``,\n            and ``noverlap`` which are superceded by the above keyword\n            arguments\n\n        Returns\n        -------\n        coherence : `~gwpy.frequencyseries.FrequencySeries`\n            the coherence `FrequencySeries` of this `TimeSeries`\n            with the other\n\n        Notes\n        -----\n        If `self` and `other` have difference\n        :attr:`TimeSeries.sample_rate` values, the higher sampled\n        `TimeSeries` will be down-sampled to match the lower.\n\n        See Also\n        --------\n        :func:`matplotlib.mlab.cohere`\n            for details of the coherence calculator\n        \"\"\"\n        from matplotlib import mlab\n        from ..frequencyseries import FrequencySeries\n        # check sampling rates\n        if self.sample_rate.to('Hertz') != other.sample_rate.to('Hertz'):\n            sampling = min(self.sample_rate.value, other.sample_rate.value)\n            # resample higher rate series\n            if self.sample_rate.value == sampling:\n                other = other.resample(sampling)\n                self_ = self\n            else:\n                self_ = self.resample(sampling)\n        else:\n            sampling = self.sample_rate.value\n            self_ = self\n        # check fft lengths\n        if overlap is None:\n            overlap = 0\n        else:\n            overlap = int((overlap * self_.sample_rate).decompose().value)\n        if fftlength is None:\n            fftlength = int(self_.size/2. + overlap/2.)\n        else:\n            fftlength = int((fftlength * self_.sample_rate).decompose().value)\n        if window is not None:\n            kwargs['window'] = signal.get_window(window, fftlength)\n        coh, freqs = mlab.cohere(self_.value, other.value, NFFT=fftlength,\n                                 Fs=sampling, noverlap=overlap, **kwargs)\n        out = coh.view(FrequencySeries)\n        out.xindex = freqs\n        out.epoch = self.epoch\n        out.name = 'Coherence between %s and %s' % (self.name, other.name)\n        out.unit = 'coherence'\n        return out", "response": "Calculates the frequency - coherence between this TimeSeries and another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the frequency - coherence between this TimeSeries and another TimeSeries.", "response": "def auto_coherence(self, dt, fftlength=None, overlap=None,\n                       window='hann', **kwargs):\n        \"\"\"Calculate the frequency-coherence between this `TimeSeries`\n        and a time-shifted copy of itself.\n\n        The standard :meth:`TimeSeries.coherence` is calculated between\n        the input `TimeSeries` and a :meth:`cropped <TimeSeries.crop>`\n        copy of itself. Since the cropped version will be shorter, the\n        input series will be shortened to match.\n\n        Parameters\n        ----------\n        dt : `float`\n            duration (in seconds) of time-shift\n\n        fftlength : `float`, optional\n            number of seconds in single FFT, defaults to a single FFT\n            covering the full duration\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        **kwargs\n            any other keyword arguments accepted by\n            :func:`matplotlib.mlab.cohere` except ``NFFT``, ``window``,\n            and ``noverlap`` which are superceded by the above keyword\n            arguments\n\n        Returns\n        -------\n        coherence : `~gwpy.frequencyseries.FrequencySeries`\n            the coherence `FrequencySeries` of this `TimeSeries`\n            with the other\n\n        Notes\n        -----\n        The :meth:`TimeSeries.auto_coherence` will perform best when\n        ``dt`` is approximately ``fftlength / 2``.\n\n        See Also\n        --------\n        :func:`matplotlib.mlab.cohere`\n            for details of the coherence calculator\n        \"\"\"\n        # shifting self backwards is the same as forwards\n        dt = abs(dt)\n        # crop inputs\n        self_ = self.crop(self.span[0], self.span[1] - dt)\n        other = self.crop(self.span[0] + dt, self.span[1])\n        return self_.coherence(other, fftlength=fftlength,\n                               overlap=overlap, window=window, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the coherence spectrogram between this CSD and other CSD.", "response": "def coherence_spectrogram(self, other, stride, fftlength=None,\n                              overlap=None, window='hann', nproc=1):\n        \"\"\"Calculate the coherence spectrogram between this `TimeSeries`\n        and other.\n\n        Parameters\n        ----------\n        other : `TimeSeries`\n            the second `TimeSeries` in this CSD calculation\n\n        stride : `float`\n            number of seconds in single PSD (column of spectrogram)\n\n        fftlength : `float`\n            number of seconds in single FFT\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        nproc : `int`\n            number of parallel processes to use when calculating\n            individual coherence spectra.\n\n        Returns\n        -------\n        spectrogram : `~gwpy.spectrogram.Spectrogram`\n            time-frequency coherence spectrogram as generated from the\n            input time-series.\n        \"\"\"\n        from ..spectrogram.coherence import from_timeseries\n        return from_timeseries(self, other, stride, fftlength=fftlength,\n                               overlap=overlap, window=window,\n                               nproc=nproc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rms(self, stride=1):\n        stridesamp = int(stride * self.sample_rate.value)\n        nsteps = int(self.size // stridesamp)\n        # stride through TimeSeries, recording RMS\n        data = numpy.zeros(nsteps)\n        for step in range(nsteps):\n            # find step TimeSeries\n            idx = int(stridesamp * step)\n            idx_end = idx + stridesamp\n            stepseries = self[idx:idx_end]\n            rms_ = numpy.sqrt(numpy.mean(numpy.abs(stepseries.value)**2))\n            data[step] = rms_\n        name = '%s %.2f-second RMS' % (self.name, stride)\n        return self.__class__(data, channel=self.channel, t0=self.t0,\n                              name=name, sample_rate=(1/float(stride)))", "response": "Calculate the root - mean - square value of this TimeSeries once per stride."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the average magnitude and phase of this TimeSeries at a given frequency.", "response": "def demodulate(self, f, stride=1, exp=False, deg=True):\n        \"\"\"Compute the average magnitude and phase of this `TimeSeries`\n        once per stride at a given frequency.\n\n        Parameters\n        ----------\n        f : `float`\n            frequency (Hz) at which to demodulate the signal\n\n        stride : `float`, optional\n            stride (seconds) between calculations, defaults to 1 second\n\n        exp : `bool`, optional\n            return the magnitude and phase trends as one `TimeSeries` object\n            representing a complex exponential, default: False\n\n        deg : `bool`, optional\n            if `exp=False`, calculates the phase in degrees\n\n        Returns\n        -------\n        mag, phase : `TimeSeries`\n            if `exp=False`, returns a pair of `TimeSeries` objects representing\n            magnitude and phase trends with `dt=stride`\n\n        out : `TimeSeries`\n            if `exp=True`, returns a single `TimeSeries` with magnitude and\n            phase trends represented as `mag * exp(1j*phase)` with `dt=stride`\n\n        Examples\n        --------\n        Demodulation is useful when trying to examine steady sinusoidal\n        signals we know to be contained within data. For instance,\n        we can download some data from LOSC to look at trends of the\n        amplitude and phase of LIGO Livingston's calibration line at 331.3 Hz:\n\n        >>> from gwpy.timeseries import TimeSeries\n        >>> data = TimeSeries.fetch_open_data('L1', 1131350417, 1131357617)\n\n        We can demodulate the `TimeSeries` at 331.3 Hz with a stride of one\n        minute:\n\n        >>> amp, phase = data.demodulate(331.3, stride=60)\n\n        We can then plot these trends to visualize fluctuations in the\n        amplitude of the calibration line:\n\n        >>> from gwpy.plot import Plot\n        >>> plot = Plot(amp)\n        >>> ax = plot.gca()\n        >>> ax.set_ylabel('Strain Amplitude at 331.3 Hz')\n        >>> plot.show()\n        \"\"\"\n        stridesamp = int(stride * self.sample_rate.value)\n        nsteps = int(self.size // stridesamp)\n        # stride through the TimeSeries and mix with a local oscillator,\n        # taking the average over each stride\n        out = type(self)(numpy.zeros(nsteps, dtype=complex))\n        out.__array_finalize__(self)\n        out.sample_rate = 1 / float(stride)\n        w = 2 * numpy.pi * f * self.dt.decompose().value\n        for step in range(nsteps):\n            istart = int(stridesamp * step)\n            iend = istart + stridesamp\n            idx = numpy.arange(istart, iend)\n            mixed = 2 * numpy.exp(-1j * w * idx) * self.value[idx]\n            out.value[step] = mixed.mean()\n        if exp:\n            return out\n        mag = out.abs()\n        phase = type(mag)(numpy.angle(out, deg=deg))\n        phase.__array_finalize__(out)\n        phase.override_unit('deg' if deg else 'rad')\n        return (mag, phase)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef taper(self, side='leftright'):\n        # check window properties\n        if side not in ('left', 'right', 'leftright'):\n            raise ValueError(\"side must be one of 'left', 'right', \"\n                             \"or 'leftright'\")\n        out = self.copy()\n        # identify the second stationary point away from each boundary,\n        # else default to half the TimeSeries width\n        nleft, nright = 0, 0\n        mini, = signal.argrelmin(out.value)\n        maxi, = signal.argrelmax(out.value)\n        if 'left' in side:\n            nleft = max(mini[0], maxi[0])\n            nleft = min(nleft, self.size/2)\n        if 'right' in side:\n            nright = out.size - min(mini[-1], maxi[-1])\n            nright = min(nright, self.size/2)\n        out *= planck(out.size, nleft=nleft, nright=nright)\n        return out", "response": "Taper the ends of this time series smoothly to zero."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef whiten(self, fftlength=None, overlap=0, method=DEFAULT_FFT_METHOD,\n               window='hanning', detrend='constant', asd=None,\n               fduration=2, highpass=None, **kwargs):\n        \"\"\"Whiten this `TimeSeries` using inverse spectrum truncation\n\n        Parameters\n        ----------\n        fftlength : `float`, optional\n            FFT integration length (in seconds) for ASD estimation,\n            default: choose based on sample rate\n\n        overlap : `float`, optional\n            number of seconds of overlap between FFTs, defaults to the\n            recommended overlap for the given window (if given), or 0\n\n        method : `str`, optional\n            FFT-averaging method\n\n        window : `str`, `numpy.ndarray`, optional\n            window function to apply to timeseries prior to FFT,\n            default: ``'hanning'``\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        detrend : `str`, optional\n            type of detrending to do before FFT (see `~TimeSeries.detrend`\n            for more details), default: ``'constant'``\n\n        asd : `~gwpy.frequencyseries.FrequencySeries`, optional\n            the amplitude spectral density using which to whiten the data,\n            overrides other ASD arguments, default: `None`\n\n        fduration : `float`, optional\n            duration (in seconds) of the time-domain FIR whitening filter,\n            must be no longer than `fftlength`, default: 2 seconds\n\n        highpass : `float`, optional\n            highpass corner frequency (in Hz) of the FIR whitening filter,\n            default: `None`\n\n        **kwargs\n            other keyword arguments are passed to the `TimeSeries.asd`\n            method to estimate the amplitude spectral density\n            `FrequencySeries` of this `TimeSeries`\n\n        Returns\n        -------\n        out : `TimeSeries`\n            a whitened version of the input data with zero mean and unit\n            variance\n\n        See Also\n        --------\n        TimeSeries.asd\n            for details on the ASD calculation\n        TimeSeries.convolve\n            for details on convolution with the overlap-save method\n        gwpy.signal.filter_design.fir_from_transfer\n            for FIR filter design through spectrum truncation\n\n        Notes\n        -----\n        The accepted ``method`` arguments are:\n\n        - ``'bartlett'`` : a mean average of non-overlapping periodograms\n        - ``'median'`` : a median average of overlapping periodograms\n        - ``'welch'`` : a mean average of overlapping periodograms\n\n        The ``window`` argument is used in ASD estimation, FIR filter design,\n        and in preventing spectral leakage in the output.\n\n        Due to filter settle-in, a segment of length ``0.5*fduration`` will be\n        corrupted at the beginning and end of the output. See\n        `~TimeSeries.convolve` for more details.\n\n        The input is detrended and the output normalised such that, if the\n        input is stationary and Gaussian, then the output will have zero mean\n        and unit variance.\n\n        For more on inverse spectrum truncation, see arXiv:gr-qc/0509116.\n        \"\"\"\n        # compute the ASD\n        fftlength = fftlength if fftlength else _fft_length_default(self.dt)\n        if asd is None:\n            asd = self.asd(fftlength, overlap=overlap,\n                           method=method, window=window, **kwargs)\n        asd = asd.interpolate(1./self.duration.decompose().value)\n        # design whitening filter, with highpass if requested\n        ncorner = int(highpass / asd.df.decompose().value) if highpass else 0\n        ntaps = int((fduration * self.sample_rate).decompose().value)\n        tdw = filter_design.fir_from_transfer(1/asd.value, ntaps=ntaps,\n                                              window=window, ncorner=ncorner)\n        # condition the input data and apply the whitening filter\n        in_ = self.copy().detrend(detrend)\n        out = in_.convolve(tdw, window=window)\n        return out * numpy.sqrt(2 * in_.dt.decompose().value)", "response": "Whiten this TimeSeries using inverse spectrum truncation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gate(self, tzero=1.0, tpad=0.5, whiten=True,\n             threshold=50., cluster_window=0.5, **whiten_kwargs):\n        \"\"\"Removes high amplitude peaks from data using inverse Planck window.\n        Points will be discovered automatically using a provided threshold\n        and clustered within a provided time window.\n\n        Parameters\n        ----------\n        tzero : `int`, optional\n            half-width time duration in which the time series is set to zero\n\n        tpad : `int`, optional\n            half-width time duration in which the Planck window is tapered\n\n        whiten : `bool`, optional\n            if True, data will be whitened before gating points are discovered,\n            use of this option is highly recommended\n\n        threshold : `float`, optional\n            amplitude threshold, if the data exceeds this value a gating window\n            will be placed\n\n        cluster_window : `float`, optional\n            time duration over which gating points will be clustered\n\n        **whiten_kwargs\n            other keyword arguments that will be passed to the\n            `TimeSeries.whiten` method if it is being used when discovering\n            gating points\n\n        Returns\n        -------\n        out : `~gwpy.timeseries.TimeSeries`\n            a copy of the original `TimeSeries` that has had gating windows\n            applied\n\n        Examples\n        --------\n\n        Read data into a `TimeSeries`\n        >>> from gwpy.timeseries import TimeSeries\n        >>> data = TimeSeries.fetch_open_data('H1', 1135148571, 1135148771)\n\n        Apply gating using custom arguments\n        >>> gated = data.gate(tzero=1.0, tpad=1.0, threshold=10.0,\n                              fftlength=4, overlap=2, method='median')\n\n        Plot the original data and the gated data, whiten both for\n        visualization purposes\n        >>> overlay = data.whiten(4,2,method='median').plot(dpi=150,\n                                  label='Ungated', color='dodgerblue',\n                                  zorder=2)\n        >>> ax = overlay.gca()\n        >>> ax.plot(gated.whiten(4,2,method='median'), label='Gated',\n                    color='orange', zorder=3)\n        >>> ax.set_xlim(1135148661, 1135148681)\n        >>> ax.legend()\n        >>> overlay.show()\n        \"\"\"\n        try:\n            from scipy.signal import find_peaks\n        except ImportError as exc:\n            exc.args = (\"Must have scipy>=1.1.0 to utilize this method.\",)\n            raise\n        # Find points to gate based on a threshold\n        data = self.whiten(**whiten_kwargs) if whiten else self\n        window_samples = cluster_window * data.sample_rate.value\n        gates = find_peaks(abs(data.value), height=threshold,\n                           distance=window_samples)[0]\n        out = self.copy()\n\n        # Iterate over list of indices to gate and apply each one\n        nzero = int(abs(tzero) * self.sample_rate.value)\n        npad = int(abs(tpad) * self.sample_rate.value)\n        half = nzero + npad\n        ntotal = 2 * half\n        for gate in gates:\n            # Set the boundaries for windowed data in the original time series\n            left_idx = max(0, gate - half)\n            right_idx = min(gate + half, len(self.value) - 1)\n\n            # Choose which part of the window will replace the data\n            # This must be done explicitly for edge cases where a window\n            # overlaps index 0 or the end of the time series\n            left_idx_window = half - (gate - left_idx)\n            right_idx_window = half + (right_idx - gate)\n\n            window = 1 - planck(ntotal, nleft=npad, nright=npad)\n            window = window[left_idx_window:right_idx_window]\n            out[left_idx:right_idx] *= window\n\n        return out", "response": "Gates the data of a specific time series with high amplitude peaks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convolve(self, fir, window='hanning'):\n        pad = int(numpy.ceil(fir.size/2))\n        nfft = min(8*fir.size, self.size)\n        # condition the input data\n        in_ = self.copy()\n        window = signal.get_window(window, fir.size)\n        in_.value[:pad] *= window[:pad]\n        in_.value[-pad:] *= window[-pad:]\n        # if FFT length is long enough, perform only one convolution\n        if nfft >= self.size/2:\n            conv = signal.fftconvolve(in_.value, fir, mode='same')\n        # else use the overlap-save algorithm\n        else:\n            nstep = nfft - 2*pad\n            conv = numpy.zeros(self.size)\n            # handle first chunk separately\n            conv[:nfft-pad] = signal.fftconvolve(in_.value[:nfft], fir,\n                                                 mode='same')[:nfft-pad]\n            # process chunks of length nstep\n            k = nfft - pad\n            while k < self.size - nfft + pad:\n                yk = signal.fftconvolve(in_.value[k-pad:k+nstep+pad], fir,\n                                        mode='same')\n                conv[k:k+yk.size-2*pad] = yk[pad:-pad]\n                k += nstep\n            # handle last chunk separately\n            conv[-nfft+pad:] = signal.fftconvolve(in_.value[-nfft:], fir,\n                                                  mode='same')[-nfft+pad:]\n        out = type(self)(conv)\n        out.__array_finalize__(self)\n        return out", "response": "Convolve this TimeSeries with an FIR filter using the overlap - save method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncross - correlate this TimeSeries with another signal.", "response": "def correlate(self, mfilter, window='hanning', detrend='linear',\n                  whiten=False, wduration=2, highpass=None, **asd_kw):\n        \"\"\"Cross-correlate this `TimeSeries` with another signal\n\n        Parameters\n        ----------\n        mfilter : `TimeSeries`\n            the time domain signal to correlate with\n\n        window : `str`, optional\n            window function to apply to timeseries prior to FFT,\n            default: ``'hanning'``\n            see :func:`scipy.signal.get_window` for details on acceptable\n            formats\n\n        detrend : `str`, optional\n            type of detrending to do before FFT (see `~TimeSeries.detrend`\n            for more details), default: ``'linear'``\n\n        whiten : `bool`, optional\n            boolean switch to enable (`True`) or disable (`False`) data\n            whitening, default: `False`\n\n        wduration : `float`, optional\n            duration (in seconds) of the time-domain FIR whitening filter,\n            only used if `whiten=True`, defaults to 2 seconds\n\n        highpass : `float`, optional\n            highpass corner frequency (in Hz) of the FIR whitening filter,\n            only used if `whiten=True`, default: `None`\n\n        **asd_kw\n            keyword arguments to pass to `TimeSeries.asd` to generate\n            an ASD, only used if `whiten=True`\n\n        Returns\n        -------\n        snr : `TimeSeries`\n            the correlated signal-to-noise ratio (SNR) timeseries\n\n        See Also\n        --------\n        TimeSeries.asd\n            for details on the ASD calculation\n        TimeSeries.convolve\n            for details on convolution with the overlap-save method\n\n        Notes\n        -----\n        The `window` argument is used in ASD estimation, whitening, and\n        preventing spectral leakage in the output. It is not used to condition\n        the matched-filter, which should be windowed before passing to this\n        method.\n\n        Due to filter settle-in, a segment half the length of `mfilter` will be\n        corrupted at the beginning and end of the output. See\n        `~TimeSeries.convolve` for more details.\n\n        The input and matched-filter will be detrended, and the output will be\n        normalised so that the SNR measures number of standard deviations from\n        the expected mean.\n        \"\"\"\n        self.is_compatible(mfilter)\n        # condition data\n        if whiten is True:\n            fftlength = asd_kw.pop('fftlength',\n                                   _fft_length_default(self.dt))\n            overlap = asd_kw.pop('overlap', None)\n            if overlap is None:\n                overlap = recommended_overlap(window) * fftlength\n            asd = self.asd(fftlength, overlap, window=window, **asd_kw)\n            # pad the matched-filter to prevent corruption\n            npad = int(wduration * mfilter.sample_rate.decompose().value / 2)\n            mfilter = mfilter.pad(npad)\n            # whiten (with errors on division by zero)\n            with numpy.errstate(all='raise'):\n                in_ = self.whiten(window=window, fduration=wduration, asd=asd,\n                                  highpass=highpass, detrend=detrend)\n                mfilter = mfilter.whiten(window=window, fduration=wduration,\n                                         asd=asd, highpass=highpass,\n                                         detrend=detrend)[npad:-npad]\n        else:\n            in_ = self.detrend(detrend)\n            mfilter = mfilter.detrend(detrend)\n        # compute matched-filter SNR and normalise\n        stdev = numpy.sqrt((mfilter.value**2).sum())\n        snr = in_.convolve(mfilter[::-1], window=window) / stdev\n        snr.__array_finalize__(self)\n        return snr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the trend from this TimeSeries.", "response": "def detrend(self, detrend='constant'):\n        \"\"\"Remove the trend from this `TimeSeries`\n\n        This method just wraps :func:`scipy.signal.detrend` to return\n        an object of the same type as the input.\n\n        Parameters\n        ----------\n        detrend : `str`, optional\n            the type of detrending.\n\n        Returns\n        -------\n        detrended : `TimeSeries`\n            the detrended input series\n\n        See Also\n        --------\n        scipy.signal.detrend\n            for details on the options for the `detrend` argument, and\n            how the operation is done\n        \"\"\"\n        data = signal.detrend(self.value, type=detrend).view(type(self))\n        data.__metadata_finalize__(self)\n        data._unit = self.unit\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnotches out a frequency in this TimeSeries.", "response": "def notch(self, frequency, type='iir', filtfilt=True, **kwargs):\n        \"\"\"Notch out a frequency in this `TimeSeries`.\n\n        Parameters\n        ----------\n        frequency : `float`, `~astropy.units.Quantity`\n            frequency (default in Hertz) at which to apply the notch\n\n        type : `str`, optional\n            type of filter to apply, currently only 'iir' is supported\n\n        **kwargs\n            other keyword arguments to pass to `scipy.signal.iirdesign`\n\n        Returns\n        -------\n        notched : `TimeSeries`\n           a notch-filtered copy of the input `TimeSeries`\n\n        See Also\n        --------\n        TimeSeries.filter\n           for details on the filtering method\n        scipy.signal.iirdesign\n            for details on the IIR filter design method\n        \"\"\"\n        zpk = filter_design.notch(frequency, self.sample_rate.value,\n                                  type=type, **kwargs)\n        return self.filter(*zpk, filtfilt=filtfilt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef q_gram(self,\n               qrange=qtransform.DEFAULT_QRANGE,\n               frange=qtransform.DEFAULT_FRANGE,\n               mismatch=qtransform.DEFAULT_MISMATCH,\n               snrthresh=5.5,\n               **kwargs):\n        \"\"\"Scan a `TimeSeries` using the multi-Q transform and return an\n        `EventTable` of the most significant tiles\n\n        Parameters\n        ----------\n        qrange : `tuple` of `float`, optional\n            `(low, high)` range of Qs to scan\n\n        frange : `tuple` of `float`, optional\n            `(low, high)` range of frequencies to scan\n\n        mismatch : `float`, optional\n            maximum allowed fractional mismatch between neighbouring tiles\n\n        snrthresh : `float`, optional\n            lower inclusive threshold on individual tile SNR to keep in the\n            table\n\n        **kwargs\n            other keyword arguments to be passed to :meth:`QTiling.transform`,\n            including ``'epoch'`` and ``'search'``\n\n        Returns\n        -------\n        qgram : `EventTable`\n            a table of time-frequency tiles on the most significant `QPlane`\n\n        See Also\n        --------\n        TimeSeries.q_transform\n            for a method to interpolate the raw Q-transform over a regularly\n            gridded spectrogram\n        gwpy.signal.qtransform\n            for code and documentation on how the Q-transform is implemented\n        gwpy.table.EventTable.tile\n            to render this `EventTable` as a collection of polygons\n\n        Notes\n        -----\n        Only tiles with signal energy greater than or equal to\n        `snrthresh ** 2 / 2` will be stored in the output `EventTable`. The\n        table columns are ``'time'``, ``'duration'``, ``'frequency'``,\n        ``'bandwidth'``, and ``'energy'``.\n        \"\"\"\n        qscan, _ = qtransform.q_scan(self, mismatch=mismatch, qrange=qrange,\n                                     frange=frange, **kwargs)\n        qgram = qscan.table(snrthresh=snrthresh)\n        return qgram", "response": "Return an EventTable of the most significant tiles in the given TimeSeries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef q_transform(self,\n                    qrange=qtransform.DEFAULT_QRANGE,\n                    frange=qtransform.DEFAULT_FRANGE,\n                    gps=None,\n                    search=.5,\n                    tres=\"<default>\",\n                    fres=\"<default>\",\n                    logf=False,\n                    norm='median',\n                    mismatch=qtransform.DEFAULT_MISMATCH,\n                    outseg=None,\n                    whiten=True,\n                    fduration=2,\n                    highpass=None,\n                    **asd_kw):\n        \"\"\"Scan a `TimeSeries` using the multi-Q transform and return an\n        interpolated high-resolution spectrogram\n\n        By default, this method returns a high-resolution spectrogram in\n        both time and frequency, which can result in a large memory\n        footprint. If you know that you only need a subset of the output\n        for, say, a figure, consider using ``outseg`` and the other\n        keyword arguments to restrict the size of the returned data.\n\n        Parameters\n        ----------\n        qrange : `tuple` of `float`, optional\n            `(low, high)` range of Qs to scan\n\n        frange : `tuple` of `float`, optional\n            `(log, high)` range of frequencies to scan\n\n        gps : `float`, optional\n            central time of interest for determine loudest Q-plane\n\n        search : `float`, optional\n            window around `gps` in which to find peak energies, only\n            used if `gps` is given\n\n        tres : `float`, optional\n            desired time resolution (seconds) of output `Spectrogram`,\n            default is `abs(outseg) / 1000.`\n\n        fres : `float`, `int`, `None`, optional\n            desired frequency resolution (Hertz) of output `Spectrogram`,\n            or, if ``logf=True``, the number of frequency samples;\n            give `None` to skip this step and return the original resolution,\n            default is 0.5 Hz or 500 frequency samples\n\n        logf : `bool`, optional\n            boolean switch to enable (`True`) or disable (`False`) use of\n            log-sampled frequencies in the output `Spectrogram`,\n            if `True` then `fres` is interpreted as a number of frequency\n            samples, default: `False`\n\n        norm : `bool`, `str`, optional\n            whether to normalize the returned Q-transform output, or how,\n            default: `True` (``'median'``), other options: `False`,\n            ``'mean'``\n\n        mismatch : `float`\n            maximum allowed fractional mismatch between neighbouring tiles\n\n        outseg : `~gwpy.segments.Segment`, optional\n            GPS `[start, stop)` segment for output `Spectrogram`,\n            default is the full duration of the input\n\n        whiten : `bool`, `~gwpy.frequencyseries.FrequencySeries`, optional\n            boolean switch to enable (`True`) or disable (`False`) data\n            whitening, or an ASD `~gwpy.freqencyseries.FrequencySeries`\n            with which to whiten the data\n\n        fduration : `float`, optional\n            duration (in seconds) of the time-domain FIR whitening filter,\n            only used if `whiten` is not `False`, defaults to 2 seconds\n\n        highpass : `float`, optional\n            highpass corner frequency (in Hz) of the FIR whitening filter,\n            used only if `whiten` is not `False`, default: `None`\n\n        **asd_kw\n            keyword arguments to pass to `TimeSeries.asd` to generate\n            an ASD to use when whitening the data\n\n        Returns\n        -------\n        out : `~gwpy.spectrogram.Spectrogram`\n            output `Spectrogram` of normalised Q energy\n\n        See Also\n        --------\n        TimeSeries.asd\n            for documentation on acceptable `**asd_kw`\n        TimeSeries.whiten\n            for documentation on how the whitening is done\n        gwpy.signal.qtransform\n            for code and documentation on how the Q-transform is implemented\n\n        Notes\n        -----\n        This method will return a `Spectrogram` of dtype ``float32`` if\n        ``norm`` is given, and ``float64`` otherwise.\n\n        To optimize plot rendering with `~matplotlib.axes.Axes.pcolormesh`,\n        the output `~gwpy.spectrogram.Spectrogram` can be given a log-sampled\n        frequency axis by passing `logf=True` at runtime. The `fres` argument\n        is then the number of points on the frequency axis. Note, this is\n        incompatible with `~matplotlib.axes.Axes.imshow`.\n\n        It is also highly recommended to use the `outseg` keyword argument\n        when only a small window around a given GPS time is of interest. This\n        will speed up this method a little, but can greatly speed up\n        rendering the resulting `Spectrogram` using `pcolormesh`.\n\n        If you aren't going to use `pcolormesh` in the end, don't worry.\n\n        Examples\n        --------\n        >>> from numpy.random import normal\n        >>> from scipy.signal import gausspulse\n        >>> from gwpy.timeseries import TimeSeries\n\n        Generate a `TimeSeries` containing Gaussian noise sampled at 4096 Hz,\n        centred on GPS time 0, with a sine-Gaussian pulse ('glitch') at\n        500 Hz:\n\n        >>> noise = TimeSeries(normal(loc=1, size=4096*4), sample_rate=4096, epoch=-2)\n        >>> glitch = TimeSeries(gausspulse(noise.times.value, fc=500) * 4, sample_rate=4096)\n        >>> data = noise + glitch\n\n        Compute and plot the Q-transform of these data:\n\n        >>> q = data.q_transform()\n        >>> plot = q.plot()\n        >>> ax = plot.gca()\n        >>> ax.set_xlim(-.2, .2)\n        >>> ax.set_epoch(0)\n        >>> plot.show()\n        \"\"\"  # noqa: E501\n        from ..frequencyseries import FrequencySeries\n        # condition data\n        if whiten is True:  # generate ASD dynamically\n            window = asd_kw.pop('window', 'hann')\n            fftlength = asd_kw.pop('fftlength',\n                                   _fft_length_default(self.dt))\n            overlap = asd_kw.pop('overlap', None)\n            if overlap is None and fftlength == self.duration.value:\n                asd_kw['method'] = DEFAULT_FFT_METHOD\n                overlap = 0\n            elif overlap is None:\n                overlap = recommended_overlap(window) * fftlength\n            whiten = self.asd(fftlength, overlap, window=window, **asd_kw)\n        if isinstance(whiten, FrequencySeries):\n            # apply whitening (with error on division by zero)\n            with numpy.errstate(all='raise'):\n                data = self.whiten(asd=whiten, fduration=fduration,\n                                   highpass=highpass)\n        else:\n            data = self\n        # determine search window\n        if gps is None:\n            search = None\n        elif search is not None:\n            search = Segment(gps-search/2, gps+search/2) & self.span\n        qgram, _ = qtransform.q_scan(\n            data, frange=frange, qrange=qrange, norm=norm,\n            mismatch=mismatch, search=search)\n        return qgram.interpolate(\n            tres=tres, fres=fres, logf=logf, outseg=outseg)", "response": "This method returns an interpolated high - resolution spectrogram of the given time - series and frequency."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the index of the current axis based on a given key or value.", "response": "def _update_index(self, axis, key, value):\n        \"\"\"Update the current axis index based on a given key or value\n\n        This is an internal method designed to set the origin or step for\n        an index, whilst updating existing Index arrays as appropriate\n\n        Examples\n        --------\n        >>> self._update_index(\"x0\", 0)\n        >>> self._update_index(\"dx\", 0)\n\n        To actually set an index array, use `_set_index`\n        \"\"\"\n        # delete current value if given None\n        if value is None:\n            return delattr(self, key)\n\n        _key = \"_{}\".format(key)\n        index = \"{[0]}index\".format(axis)\n        unit = \"{[0]}unit\".format(axis)\n\n        # convert float to Quantity\n        if not isinstance(value, Quantity):\n            try:\n                value = Quantity(value, getattr(self, unit))\n            except TypeError:\n                value = Quantity(float(value), getattr(self, unit))\n\n        # if value is changing, delete current index\n        try:\n            curr = getattr(self, _key)\n        except AttributeError:\n            delattr(self, index)\n        else:\n            if (\n                    value is None or\n                    getattr(self, key) is None or\n                    not value.unit.is_equivalent(curr.unit) or\n                    value != curr\n            ):\n                delattr(self, index)\n\n        # set new value\n        setattr(self, _key, value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a new index array for this series", "response": "def _set_index(self, key, index):\n        \"\"\"Set a new index array for this series\n        \"\"\"\n        axis = key[0]\n        origin = \"{}0\".format(axis)\n        delta = \"d{}\".format(axis)\n        if index is None:\n            return delattr(self, key)\n        if not isinstance(index, Index):\n            try:\n                unit = index.unit\n            except AttributeError:\n                unit = getattr(self, \"_default_{}unit\".format(axis))\n            index = Index(index, unit=unit, copy=False)\n        setattr(self, origin, index[0])\n        if index.regular:\n            setattr(self, delta, index[1] - index[0])\n        else:\n            delattr(self, delta)\n        setattr(self, \"_{}\".format(key), index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the index of the x - axis of the data on the x - axis.", "response": "def xindex(self):\n        \"\"\"Positions of the data on the x-axis\n\n        :type: `~astropy.units.Quantity` array\n        \"\"\"\n        try:\n            return self._xindex\n        except AttributeError:\n            self._xindex = Index.define(self.x0, self.dx, self.shape[0])\n            return self._xindex"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xunit(self):\n        try:\n            return self._dx.unit\n        except AttributeError:\n            try:\n                return self._x0.unit\n            except AttributeError:\n                return self._default_xunit", "response": "Unit of x - axis index"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the data for this series and return a figure with populated Axes.", "response": "def plot(self, method='plot', **kwargs):\n        \"\"\"Plot the data for this series\n\n        Returns\n        -------\n        figure : `~matplotlib.figure.Figure`\n            the newly created figure, with populated Axes.\n\n        See Also\n        --------\n        matplotlib.pyplot.figure\n            for documentation of keyword arguments used to create the\n            figure\n        matplotlib.figure.Figure.add_subplot\n            for documentation of keyword arguments used to create the\n            axes\n        matplotlib.axes.Axes.plot\n            for documentation of keyword arguments used in rendering the data\n        \"\"\"\n        from ..plot import Plot\n        from ..plot.text import default_unit_label\n\n        # correct for log scales and zeros\n        if kwargs.get('xscale') == 'log' and self.x0.value == 0:\n            kwargs.setdefault('xlim', (self.dx.value, self.xspan[1]))\n\n        # make plot\n        plot = Plot(self, method=method, **kwargs)\n\n        # set default y-axis label (xlabel is set by Plot())\n        default_unit_label(plot.gca().yaxis, self.unit)\n\n        return plot"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a step plot of this series", "response": "def step(self, **kwargs):\n        \"\"\"Create a step plot of this series\n        \"\"\"\n        kwargs.setdefault('linestyle', kwargs.pop('where', 'steps-post'))\n        data = self.append(self.value[-1:], inplace=False)\n        return data.plot(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shift(self, delta):\n        self.x0 = self.x0 + Quantity(delta, self.xunit)", "response": "Shift this Series forward on the X - axis by delta"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value_at(self, x):\n        x = Quantity(x, self.xindex.unit).value\n        try:\n            idx = (self.xindex.value == x).nonzero()[0][0]\n        except IndexError as e:\n            e.args = (\"Value %r not found in array index\" % x,)\n            raise\n        return self[idx]", "response": "Return the value of this Series at the given xindex value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diff(self, n=1, axis=-1):\n        out = super(Array, self).diff(n=n, axis=axis)\n        try:\n            out.x0 = self.x0 + self.dx * n\n        except AttributeError:  # irregular xindex\n            out.x0 = self.xindex[n]\n        return out", "response": "Calculate the n - th order discrete difference along given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether this series is contiguous with another series.", "response": "def is_contiguous(self, other, tol=1/2.**18):\n        \"\"\"Check whether other is contiguous with self.\n\n        Parameters\n        ----------\n        other : `Series`, `numpy.ndarray`\n            another series of the same type to test for contiguity\n\n        tol : `float`, optional\n            the numerical tolerance of the test\n\n        Returns\n        -------\n        1\n            if `other` is contiguous with this series, i.e. would attach\n            seamlessly onto the end\n        -1\n            if `other` is anti-contiguous with this seires, i.e. would attach\n            seamlessly onto the start\n        0\n            if `other` is completely dis-contiguous with thie series\n\n        Notes\n        -----\n        if a raw `numpy.ndarray` is passed as other, with no metadata, then\n        the contiguity check will always pass\n        \"\"\"\n        self.is_compatible(other)\n        if isinstance(other, type(self)):\n            if abs(float(self.xspan[1] - other.xspan[0])) < tol:\n                return 1\n            elif abs(float(other.xspan[1] - self.xspan[0])) < tol:\n                return -1\n            return 0\n        elif type(other) in [list, tuple, numpy.ndarray]:\n            return 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_compatible(self, other):\n        if isinstance(other, type(self)):\n            # check step size, if possible\n            try:\n                if not self.dx == other.dx:\n                    raise ValueError(\"%s sample sizes do not match: \"\n                                     \"%s vs %s.\" % (type(self).__name__,\n                                                    self.dx, other.dx))\n            except AttributeError:\n                raise ValueError(\"Series with irregular xindexes cannot \"\n                                 \"be compatible\")\n            # check units\n            if not self.unit == other.unit and not (\n                    self.unit in [dimensionless_unscaled, None] and\n                    other.unit in [dimensionless_unscaled, None]):\n                raise ValueError(\"%s units do not match: %s vs %s.\"\n                                 % (type(self).__name__, str(self.unit),\n                                    str(other.unit)))\n        else:\n            # assume an array-like object, and just check that the shape\n            # and dtype match\n            arr = numpy.asarray(other)\n            if arr.ndim != self.ndim:\n                raise ValueError(\"Dimensionality does not match\")\n            if arr.dtype != self.dtype:\n                warn(\"Array data types do not match: %s vs %s\"\n                     % (self.dtype, other.dtype))\n        return True", "response": "Check whether this series and other have compatible metadata."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self, other, inplace=True, pad=None, gap=None, resize=True):\n        if gap is None:\n            gap = 'raise' if pad is None else 'pad'\n        if pad is None and gap == 'pad':\n            pad = 0.\n\n        # check metadata\n        self.is_compatible(other)\n        # make copy if needed\n        if not inplace:\n            self = self.copy()\n        # fill gap\n        if self.is_contiguous(other) != 1:\n            if gap == 'pad':\n                ngap = floor(\n                    (other.xspan[0] - self.xspan[1]) / self.dx.value + 0.5)\n                if ngap < 1:\n                    raise ValueError(\n                        \"Cannot append {0} that starts before this one:\\n\"\n                        \"    {0} 1 span: {1}\\n    {0} 2 span: {2}\".format(\n                            type(self).__name__, self.xspan, other.xspan))\n                gapshape = list(self.shape)\n                gapshape[0] = int(ngap)\n                padding = (numpy.ones(gapshape) * pad).astype(self.dtype)\n                self.append(padding, inplace=True, resize=resize)\n            elif gap == 'ignore':\n                pass\n            elif self.xspan[0] < other.xspan[0] < self.xspan[1]:\n                raise ValueError(\n                    \"Cannot append overlapping {0}s:\\n\"\n                    \"    {0} 1 span: {1}\\n    {0} 2 span: {2}\".format(\n                        type(self).__name__, self.xspan, other.xspan))\n            else:\n                raise ValueError(\n                    \"Cannot append discontiguous {0}\\n\"\n                    \"    {0} 1 span: {1}\\n    {0} 2 span: {2}\".format(\n                        type(self).__name__, self.xspan, other.xspan))\n\n        # check empty other\n        if not other.size:\n            return self\n\n        # resize first\n        if resize:\n            N = other.shape[0]\n            s = list(self.shape)\n            s[0] = self.shape[0] + other.shape[0]\n            try:\n                self.resize(s, refcheck=False)\n            except ValueError as e:\n                if 'resize only works on single-segment arrays' in str(e):\n                    self = self.copy()\n                    self.resize(s)\n                else:\n                    raise\n        elif other.shape[0] < self.shape[0]:\n            N = other.shape[0]\n            self.value[:-N] = self.value[N:]\n        else:\n            N = min(self.shape[0], other.shape[0])\n\n        # if units are the same, can shortcut\n        # NOTE: why not use isinstance here?\n        if type(other) == type(self) and other.unit == self.unit:\n            self.value[-N:] = other.value[-N:]\n        # otherwise if its just a numpy array\n        elif type(other) is type(self.value) or (  # noqa: E721\n                other.dtype.name.startswith('uint')):\n            self.value[-N:] = other[-N:]\n        else:\n            self[-N:] = other[-N:]\n        try:\n            self._xindex\n        except AttributeError:\n            if not resize:\n                self.x0 = self.x0.value + other.shape[0] * self.dx.value\n        else:\n            if resize:\n                try:\n                    self.xindex.resize((s[0],), refcheck=False)\n                except ValueError as exc:\n                    if 'cannot resize' in str(exc):\n                        self.xindex = self.xindex.copy()\n                        self.xindex.resize((s[0],))\n                    else:\n                        raise\n            else:\n                self.xindex[:-other.shape[0]] = self.xindex[other.shape[0]:]\n            try:\n                self.xindex[-other.shape[0]:] = other._xindex\n            except AttributeError:\n                del self.xindex\n                if not resize:\n                    self.x0 = self.x0 + self.dx * other.shape[0]\n            else:\n                try:\n                    self.dx = self.xindex[1] - self.xindex[0]\n                except IndexError:\n                    pass\n                self.x0 = self.xindex[0]\n        return self", "response": "Connect another series onto the end of the current series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting another series onto the start of the current one.", "response": "def prepend(self, other, inplace=True, pad=None, gap=None, resize=True):\n        \"\"\"Connect another series onto the start of the current one.\n\n        Parameters\n        ----------\n        other : `Series`\n            another series of the same type as this one\n\n        inplace : `bool`, optional\n            perform operation in-place, modifying current series,\n            otherwise copy data and return new series, default: `True`\n\n            .. warning::\n\n               `inplace` prepend bypasses the reference check in\n               `numpy.ndarray.resize`, so be carefully to only use this\n               for arrays that haven't been sharing their memory!\n\n        pad : `float`, optional\n            value with which to pad discontiguous series,\n            by default gaps will result in a `ValueError`.\n\n        gap : `str`, optional\n            action to perform if there's a gap between the other series\n            and this one. One of\n\n            - ``'raise'`` - raise a `ValueError`\n            - ``'ignore'`` - remove gap and join data\n            - ``'pad'`` - pad gap with zeros\n\n            If `pad` is given and is not `None`, the default is ``'pad'``,\n            otherwise ``'raise'``.\n\n        resize : `bool`, optional\n            resize this array to accommodate new data, otherwise shift the\n            old data to the left (potentially falling off the start) and\n            put the new data in at the end, default: `True`.\n\n        Returns\n        -------\n        series : `TimeSeries`\n            time-series containing joined data sets\n        \"\"\"\n        out = other.append(self, inplace=False, gap=gap, pad=pad,\n                           resize=resize)\n        if inplace:\n            self.resize(out.shape, refcheck=False)\n            self[:] = out[:]\n            self.x0 = out.x0.copy()\n            del out\n            return self\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate this series by appending new data from another series and dropping the same amount of data off the start of the other series.", "response": "def update(self, other, inplace=True):\n        \"\"\"Update this series by appending new data from an other\n        and dropping the same amount of data off the start.\n\n        This is a convenience method that just calls `~Series.append` with\n        `resize=False`.\n        \"\"\"\n        return self.append(other, inplace=inplace, resize=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crop(self, start=None, end=None, copy=False):\n        x0, x1 = self.xspan\n        xtype = type(x0)\n        if isinstance(start, Quantity):\n            start = start.to(self.xunit).value\n        if isinstance(end, Quantity):\n            end = end.to(self.xunit).value\n\n        # pin early starts to time-series start\n        if start == x0:\n            start = None\n        elif start is not None and xtype(start) < x0:\n            warn('%s.crop given start smaller than current start, '\n                 'crop will begin when the Series actually starts.'\n                 % type(self).__name__)\n            start = None\n\n        # pin late ends to time-series end\n        if end == x1:\n            end = None\n        if end is not None and xtype(end) > x1:\n            warn('%s.crop given end larger than current end, '\n                 'crop will end when the Series actually ends.'\n                 % type(self).__name__)\n            end = None\n\n        # find start index\n        if start is None:\n            idx0 = None\n        else:\n            idx0 = int((xtype(start) - x0) // self.dx.value)\n\n        # find end index\n        if end is None:\n            idx1 = None\n        else:\n            idx1 = int((xtype(end) - x0) // self.dx.value)\n            if idx1 >= self.size:\n                idx1 = None\n\n        # crop\n        if copy:\n            return self[idx0:idx1].copy()\n        return self[idx0:idx1]", "response": "Crop this series to the given x - axis extent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pad(self, pad_width, **kwargs):\n        # format arguments\n        kwargs.setdefault('mode', 'constant')\n        if isinstance(pad_width, int):\n            pad_width = (pad_width,)\n        # form pad and view to this type\n        new = numpy.pad(self, pad_width, **kwargs).view(type(self))\n        # numpy.pad has stripped all metadata, so copy it over\n        new.__metadata_finalize__(self)\n        new._unit = self.unit\n        # finally move the starting index based on the amount of left-padding\n        new.x0 -= self.dx * pad_width[0]\n        return new", "response": "Pad this series to a new size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inject(self, other):\n        # check Series compatibility\n        self.is_compatible(other)\n        if (self.xunit == second) and (other.xspan[0] < self.xspan[0]):\n            other = other.crop(start=self.xspan[0])\n        if (self.xunit == second) and (other.xspan[1] > self.xspan[1]):\n            other = other.crop(end=self.xspan[1])\n        ox0 = other.x0.to(self.x0.unit)\n        idx = ((ox0 - self.x0) / self.dx).value\n        if not idx.is_integer():\n            warn('Series have overlapping xspan but their x-axis values are '\n                 'uniformly offset. Returning a copy of the original Series.')\n            return self.copy()\n        # add the Series along their shared samples\n        slice_ = slice(int(idx), int(idx) + other.size)\n        out = self.copy()\n        out.value[slice_] += other.value\n        return out", "response": "Add two compatible Series together their shared x - axis values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _select_query_method(cls, url):\n    if urlparse(url).netloc.startswith('geosegdb.'):  # only DB2 server\n        return cls.query_segdb\n    return cls.query_dqsegdb", "response": "Select the correct query method based on the URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_query_segments(args, func):\n    # user passed SegmentList\n    if len(args) == 1 and isinstance(args[0], SegmentList):\n        return args[0]\n\n    # otherwise unpack two arguments as a segment\n    if len(args) == 1:\n        args = args[0]\n\n    # if not two arguments, panic\n    try:\n        start, end = args\n    except ValueError as exc:\n        exc.args = ('{0}() takes 2 arguments for start and end GPS time, '\n                    'or 1 argument containing a Segment or SegmentList'.format(\n                        func.__name__),)\n        raise\n\n    # return list with one Segment\n    return SegmentList([Segment(to_gps(start), to_gps(end))])", "response": "Parse args for query_dqsegdb or query_segdb"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(cls, flag, *args, **kwargs):\n        query_ = _select_query_method(\n            cls, kwargs.get('url', DEFAULT_SEGMENT_SERVER))\n        return query_(flag, *args, **kwargs)", "response": "Query for segments of a given flag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the initial LIGO segment database for the given flag.", "response": "def query_segdb(cls, flag, *args, **kwargs):\n        \"\"\"Query the initial LIGO segment database for the given flag\n\n        Parameters\n        ----------\n        flag : `str`\n            The name of the flag for which to query\n\n        *args\n            Either, two `float`-like numbers indicating the\n            GPS [start, stop) interval, or a `SegmentList`\n            defining a number of summary segments\n\n        url : `str`, optional\n            URL of the segment database, defaults to\n            ``$DEFAULT_SEGMENT_SERVER`` environment variable, or\n            ``'https://segments.ligo.org'``\n\n        Returns\n        -------\n        flag : `DataQualityFlag`\n            A new `DataQualityFlag`, with the `known` and `active` lists\n            filled appropriately.\n        \"\"\"\n        warnings.warn(\"query_segdb is deprecated and will be removed in a \"\n                      \"future release\", DeprecationWarning)\n\n        # parse arguments\n        qsegs = _parse_query_segments(args, cls.query_segdb)\n\n        # process query\n        try:\n            flags = DataQualityDict.query_segdb([flag], qsegs, **kwargs)\n        except TypeError as exc:\n            if 'DataQualityDict' in str(exc):\n                raise TypeError(str(exc).replace('DataQualityDict',\n                                                 cls.__name__))\n            else:\n                raise\n        if len(flags) > 1:\n            raise RuntimeError(\"Multiple flags returned for single query, \"\n                               \"something went wrong:\\n    %s\"\n                               % '\\n    '.join(flags.keys()))\n        elif len(flags) == 0:\n            raise RuntimeError(\"No flags returned for single query, \"\n                               \"something went wrong.\")\n        return flags[flag]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_dqsegdb(cls, flag, *args, **kwargs):\n        # parse arguments\n        qsegs = _parse_query_segments(args, cls.query_dqsegdb)\n\n        # get server\n        url = kwargs.pop('url', DEFAULT_SEGMENT_SERVER)\n\n        # parse flag\n        out = cls(name=flag)\n        if out.ifo is None or out.tag is None:\n            raise ValueError(\"Cannot parse ifo or tag (name) for flag %r\"\n                             % flag)\n\n        # process query\n        for start, end in qsegs:\n            # handle infinities\n            if float(end) == +inf:\n                end = to_gps('now').seconds\n\n            # query\n            try:\n                data = query_segments(flag, int(start), int(end), host=url)\n            except HTTPError as exc:\n                if exc.code == 404:  # if not found, annotate flag name\n                    exc.msg += ' [{0}]'.format(flag)\n                raise\n\n            # read from json buffer\n            new = cls.read(\n                BytesIO(json.dumps(data).encode('utf-8')),\n                format='json',\n            )\n\n            # restrict to query segments\n            segl = SegmentList([Segment(start, end)])\n            new.known &= segl\n            new.active &= segl\n            out += new\n            # replace metadata\n            out.description = new.description\n            out.isgood = new.isgood\n\n        return out", "response": "Query the advanced LIGO DQSegDB for the given flag."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_open_data(cls, flag, start, end, **kwargs):\n        start = to_gps(start).gpsSeconds\n        end = to_gps(end).gpsSeconds\n        known = [(start, end)]\n        active = timeline.get_segments(flag, start, end, **kwargs)\n        return cls(flag.replace('_', ':', 1), known=known, active=active,\n                   label=flag)", "response": "Fetch a flag s segments into a new flag with active segments filled from Open Data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(cls, source, *args, **kwargs):\n        if 'flag' in kwargs:  # pragma: no cover\n            warnings.warn('\\'flag\\' keyword was renamed \\'name\\', this '\n                          'warning will result in an error in the future')\n            kwargs.setdefault('name', kwargs.pop('flags'))\n        coalesce = kwargs.pop('coalesce', False)\n\n        def combiner(flags):\n            \"\"\"Combine `DataQualityFlag` from each file into a single object\n            \"\"\"\n            out = flags[0]\n            for flag in flags[1:]:\n                out.known += flag.known\n                out.active += flag.active\n            if coalesce:\n                return out.coalesce()\n            return out\n\n        return io_read_multi(combiner, cls, source, *args, **kwargs)", "response": "Read segments from file into a DataQualityFlag object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines a DataQualityFlag from a VetoDef object", "response": "def from_veto_def(cls, veto):\n        \"\"\"Define a `DataQualityFlag` from a `VetoDef`\n\n        Parameters\n        ----------\n        veto : :class:`~ligo.lw.lsctables.VetoDef`\n            veto definition to convert from\n        \"\"\"\n        name = '%s:%s' % (veto.ifo, veto.name)\n        try:\n            name += ':%d' % int(veto.version)\n        except TypeError:\n            pass\n        if veto.end_time == 0:\n            veto.end_time = +inf\n        known = Segment(veto.start_time, veto.end_time)\n        pad = (veto.start_pad, veto.end_pad)\n        return cls(name=name, known=[known], category=veto.category,\n                   description=veto.comment, padding=pad)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating the flag s active segments with the values from the segment database.", "response": "def populate(self, source=DEFAULT_SEGMENT_SERVER, segments=None,\n                 pad=True, **kwargs):\n        \"\"\"Query the segment database for this flag's active segments.\n\n        This method assumes all of the metadata for each flag have been\n        filled. Minimally, the following attributes must be filled\n\n        .. autosummary::\n\n           ~DataQualityFlag.name\n           ~DataQualityFlag.known\n\n        Segments will be fetched from the database, with any\n        :attr:`~DataQualityFlag.padding` added on-the-fly.\n\n        This `DataQualityFlag` will be modified in-place.\n\n        Parameters\n        ----------\n        source : `str`\n            source of segments for this flag. This must be\n            either a URL for a segment database or a path to a file on disk.\n\n        segments : `SegmentList`, optional\n            a list of segments during which to query, if not given,\n            existing known segments for this flag will be used.\n\n        pad : `bool`, optional, default: `True`\n            apply the `~DataQualityFlag.padding` associated with this\n            flag, default: `True`.\n\n        **kwargs\n            any other keyword arguments to be passed to\n            :meth:`DataQualityFlag.query` or :meth:`DataQualityFlag.read`.\n\n        Returns\n        -------\n        self : `DataQualityFlag`\n            a reference to this flag\n        \"\"\"\n        tmp = DataQualityDict()\n        tmp[self.name] = self\n        tmp.populate(source=source, segments=segments, pad=pad, **kwargs)\n        return tmp[self.name]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncontracting each of the active segments by x seconds.", "response": "def contract(self, x):\n        \"\"\"Contract each of the `active` `Segments` by ``x`` seconds.\n\n        This method adds ``x`` to each segment's lower bound, and subtracts\n        ``x`` from the upper bound.\n\n        The :attr:`~DataQualityFlag.active` `SegmentList` is modified\n        in place.\n\n        Parameters\n        ----------\n        x : `float`\n            number of seconds by which to contract each `Segment`.\n        \"\"\"\n        self.active = self.active.contract(x)\n        return self.active"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprotracting each of the active segments by x seconds.", "response": "def protract(self, x):\n        \"\"\"Protract each of the `active` `Segments` by ``x`` seconds.\n\n        This method subtracts ``x`` from each segment's lower bound,\n        and adds ``x`` to the upper bound, while maintaining that each\n        `Segment` stays within the `known` bounds.\n\n        The :attr:`~DataQualityFlag.active` `SegmentList` is modified\n        in place.\n\n        Parameters\n        ----------\n        x : `float`\n            number of seconds by which to protact each `Segment`.\n        \"\"\"\n        self.active = self.active.protract(x)\n        return self.active"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a padding to each segment in this DataQualityFlag.", "response": "def pad(self, *args, **kwargs):\n        \"\"\"Apply a padding to each segment in this `DataQualityFlag`\n\n        This method either takes no arguments, in which case the value of\n        the :attr:`~DataQualityFlag.padding` attribute will be used,\n        or two values representing the padding for the start and end of\n        each segment.\n\n        For both the `start` and `end` paddings, a positive value means\n        pad forward in time, so that a positive `start` pad or negative\n        `end` padding will contract a segment at one or both ends,\n        and vice-versa.\n\n        This method will apply the same padding to both the\n        `~DataQualityFlag.known` and `~DataQualityFlag.active` lists,\n        but will not :meth:`~DataQualityFlag.coalesce` the result.\n\n        Parameters\n        ----------\n        start : `float`\n            padding to apply to the start of the each segment\n        end : `float`\n            padding to apply to the end of each segment\n        inplace : `bool`, optional, default: `False`\n            modify this object in-place, default is `False`, i.e. return\n            a copy of the original object with padded segments\n\n        Returns\n        -------\n        paddedflag : `DataQualityFlag`\n            a view of the modified flag\n        \"\"\"\n        if not args:\n            start, end = self.padding\n        else:\n            start, end = args\n\n        if kwargs.pop('inplace', False):\n            new = self\n        else:\n            new = self.copy()\n        if kwargs:\n            raise TypeError(\"unexpected keyword argument %r\"\n                            % list(kwargs.keys())[0])\n        new.known = [(s[0]+start, s[1]+end) for s in self.known]\n        new.active = [(s[0]+start, s[1]+end) for s in self.active]\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef round(self, contract=False):\n        def _round(seg):\n            if contract:  # round inwards\n                a = type(seg[0])(ceil(seg[0]))\n                b = type(seg[1])(floor(seg[1]))\n            else:  # round outwards\n                a = type(seg[0])(floor(seg[0]))\n                b = type(seg[1])(ceil(seg[1]))\n            if a >= b:  # if segment is too short, return 'null' segment\n                return type(seg)(0, 0)  # will get coalesced away\n            return type(seg)(a, b)\n\n        new = self.copy()\n        new.active = type(new.active)(map(_round, new.active))\n        new.known = type(new.known)(map(_round, new.known))\n        return new.coalesce()", "response": "Round this flag to integer segments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef coalesce(self):\n        self.known = self.known.coalesce()\n        self.active = self.active.coalesce()\n        self.active = (self.known & self.active).coalesce()\n        return self", "response": "Coalesce the segments for this flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots this flag on a segments projection.", "response": "def plot(self, figsize=(12, 4), xscale='auto-gps', **kwargs):\n        \"\"\"Plot this flag on a segments projection.\n\n        Parameters\n        ----------\n        **kwargs\n            all keyword arguments are passed to the\n            :class:`~gwpy.plot.Plot` constructor.\n\n        Returns\n        -------\n        figure : `~matplotlib.figure.Figure`\n            the newly created figure, with populated Axes.\n\n        See Also\n        --------\n        matplotlib.pyplot.figure\n            for documentation of keyword arguments used to create the\n            figure\n        matplotlib.figure.Figure.add_subplot\n            for documentation of keyword arguments used to create the\n            axes\n        gwpy.plot.SegmentAxes.plot_segmentlist\n            for documentation of keyword arguments used in rendering the data\n        \"\"\"\n        from matplotlib import rcParams\n        from ..plot import Plot\n\n        if self.label:\n            kwargs.setdefault('label', self.label)\n        elif rcParams['text.usetex']:\n            kwargs.setdefault('label', self.texname)\n        else:\n            kwargs.setdefault('label', self.name)\n\n        kwargs.update(figsize=figsize, xscale=xscale)\n        return Plot(self, projection='segments', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_name(self, name):\n        if name is None:\n            self.ifo = None\n            self.tag = None\n            self.version = None\n        elif re_IFO_TAG_VERSION.match(name):\n            match = re_IFO_TAG_VERSION.match(name).groupdict()\n            self.ifo = match['ifo']\n            self.tag = match['tag']\n            self.version = int(match['version'])\n        elif re_IFO_TAG.match(name):\n            match = re_IFO_TAG.match(name).groupdict()\n            self.ifo = match['ifo']\n            self.tag = match['tag']\n            self.version = None\n        elif re_TAG_VERSION.match(name):\n            match = re_TAG_VERSION.match(name).groupdict()\n            self.ifo = None\n            self.tag = match['tag']\n            self.version = int(match['version'])\n        else:\n            raise ValueError(\"No flag name structure detected in '%s', flags \"\n                             \"should be named as '{ifo}:{tag}:{version}'. \"\n                             \"For arbitrary strings, use the \"\n                             \"`DataQualityFlag.label` attribute\" % name)\n        return self.ifo, self.tag, self.version", "response": "Internal method to parse a string name into constituent\n           ifo name and version components."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the inital LIGO segment database for a list of flags.", "response": "def query_segdb(cls, flags, *args, **kwargs):\n        \"\"\"Query the inital LIGO segment database for a list of flags.\n\n        Parameters\n        ----------\n        flags : `iterable`\n            A list of flag names for which to query.\n        *args\n            Either, two `float`-like numbers indicating the\n            GPS [start, stop) interval, or a `SegmentList`\n            defining a number of summary segments.\n        url : `str`, optional\n            URL of the segment database, defaults to\n            ``$DEFAULT_SEGMENT_SERVER`` environment variable, or\n            ``'https://segments.ligo.org'``\n\n        Returns\n        -------\n        flagdict : `DataQualityDict`\n            An ordered `DataQualityDict` of (name, `DataQualityFlag`)\n            pairs.\n        \"\"\"\n        warnings.warn(\"query_segdb is deprecated and will be removed in a \"\n                      \"future release\", DeprecationWarning)\n\n        # parse segments\n        qsegs = _parse_query_segments(args, cls.query_segdb)\n\n        url = kwargs.pop('url', DEFAULT_SEGMENT_SERVER)\n        if kwargs.pop('on_error', None) is not None:\n            warnings.warn(\"DataQualityDict.query_segdb doesn't accept the \"\n                          \"on_error keyword argument\")\n        if kwargs.keys():\n            raise TypeError(\"DataQualityDict.query_segdb has no keyword \"\n                            \"argument '%s'\" % list(kwargs.keys()[0]))\n\n        # process query\n        from glue.segmentdb import (segmentdb_utils as segdb_utils,\n                                    query_engine as segdb_engine)\n        connection = segdb_utils.setup_database(url)\n        engine = segdb_engine.LdbdQueryEngine(connection)\n        segdefs = []\n        for flag in flags:\n            dqflag = DataQualityFlag(name=flag)\n            ifo = dqflag.ifo\n            name = dqflag.tag\n            if dqflag.version is None:\n                vers = '*'\n            else:\n                vers = dqflag.version\n            for gpsstart, gpsend in qsegs:\n                if float(gpsend) == +inf:\n                    gpsend = to_gps('now').seconds\n                gpsstart = float(gpsstart)\n                if not gpsstart.is_integer():\n                    raise ValueError(\"Segment database queries can only\"\n                                     \"operate on integer GPS times\")\n                gpsend = float(gpsend)\n                if not gpsend.is_integer():\n                    raise ValueError(\"Segment database queries can only\"\n                                     \"operate on integer GPS times\")\n                segdefs += segdb_utils.expand_version_number(\n                    engine, (ifo, name, vers, gpsstart, gpsend, 0, 0))\n        segs = segdb_utils.query_segments(engine, 'segment', segdefs)\n        segsum = segdb_utils.query_segments(engine, 'segment_summary', segdefs)\n        # build output\n        out = cls()\n        for definition, segments, summary in zip(segdefs, segs, segsum):\n            # parse flag name\n            flag = ':'.join(map(str, definition[:3]))\n            name = flag.rsplit(':', 1)[0]\n            # if versionless\n            if flag.endswith('*'):\n                flag = name\n                key = name\n            # if asked for versionless, but returned a version\n            elif flag not in flags and name in flags:\n                key = name\n            # other\n            else:\n                key = flag\n            # define flag\n            if key not in out:\n                out[key] = DataQualityFlag(name=flag)\n            # add segments\n            out[key].known.extend(summary)\n            out[key].active.extend(segments)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying the advanced LIGO DQSegDB for a list of flags.", "response": "def query_dqsegdb(cls, flags, *args, **kwargs):\n        \"\"\"Query the advanced LIGO DQSegDB for a list of flags.\n\n        Parameters\n        ----------\n        flags : `iterable`\n            A list of flag names for which to query.\n\n        *args\n            Either, two `float`-like numbers indicating the\n            GPS [start, stop) interval, or a `SegmentList`\n            defining a number of summary segments.\n\n        on_error : `str`\n            how to handle an error querying for one flag, one of\n\n            - `'raise'` (default): raise the Exception\n            - `'warn'`: print a warning\n            - `'ignore'`: move onto the next flag as if nothing happened\n\n        url : `str`, optional\n            URL of the segment database, defaults to\n            ``$DEFAULT_SEGMENT_SERVER`` environment variable, or\n            ``'https://segments.ligo.org'``\n\n        Returns\n        -------\n        flagdict : `DataQualityDict`\n            An ordered `DataQualityDict` of (name, `DataQualityFlag`)\n            pairs.\n        \"\"\"\n        # check on_error flag\n        on_error = kwargs.pop('on_error', 'raise').lower()\n        if on_error not in ['raise', 'warn', 'ignore']:\n            raise ValueError(\"on_error must be one of 'raise', 'warn', \"\n                             \"or 'ignore'\")\n\n        # parse segments\n        qsegs = _parse_query_segments(args, cls.query_dqsegdb)\n\n        # set up threading\n        inq = Queue()\n        outq = Queue()\n        for i in range(len(flags)):\n            t = _QueryDQSegDBThread(inq, outq, qsegs, **kwargs)\n            t.setDaemon(True)\n            t.start()\n        for i, flag in enumerate(flags):\n            inq.put((i, flag))\n\n        # capture output\n        inq.join()\n        outq.join()\n        new = cls()\n        results = list(zip(*sorted([outq.get() for i in range(len(flags))],\n                                   key=lambda x: x[0])))[1]\n        for result, flag in zip(results, flags):\n            if isinstance(result, Exception):\n                result.args = ('%s [%s]' % (str(result), str(flag)),)\n                if on_error == 'ignore':\n                    pass\n                elif on_error == 'warn':\n                    warnings.warn(str(result))\n                else:\n                    raise result\n            else:\n                new[flag] = result\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads segments from file into a DataQualityDict.", "response": "def read(cls, source, names=None, format=None, **kwargs):\n        \"\"\"Read segments from file into a `DataQualityDict`\n\n        Parameters\n        ----------\n        source : `str`\n            path of file to read\n\n        format : `str`, optional\n            source format identifier. If not given, the format will be\n            detected if possible. See below for list of acceptable\n            formats.\n\n        names : `list`, optional, default: read all names found\n            list of names to read, by default all names are read separately.\n\n        coalesce : `bool`, optional\n            if `True` coalesce the all segment lists before returning,\n            otherwise return exactly as contained in file(s).\n\n        nproc : `int`, optional, default: 1\n            number of CPUs to use for parallel reading of multiple files\n\n        verbose : `bool`, optional, default: `False`\n            print a progress bar showing read status\n\n        Returns\n        -------\n        flagdict : `DataQualityDict`\n            a new `DataQualityDict` of `DataQualityFlag` entries with\n            ``active`` and ``known`` segments seeded from the XML tables\n            in the given file.\n\n        Notes\n        -----\"\"\"\n        on_missing = kwargs.pop('on_missing', 'error')\n        coalesce = kwargs.pop('coalesce', False)\n\n        if 'flags' in kwargs:  # pragma: no cover\n            warnings.warn('\\'flags\\' keyword was renamed \\'names\\', this '\n                          'warning will result in an error in the future')\n            names = kwargs.pop('flags')\n\n        def combiner(inputs):\n            out = cls()\n\n            # check all names are contained\n            required = set(names or [])\n            found = set(name for dqdict in inputs for name in dqdict)\n            for name in required - found:  # validate all names are found once\n                msg = '{!r} not found in any input file'.format(name)\n                if on_missing == 'ignore':\n                    continue\n                if on_missing == 'warn':\n                    warnings.warn(msg)\n                else:\n                    raise ValueError(msg)\n\n            # combine flags\n            for dqdict in inputs:\n                for flag in dqdict:\n                    try:  # repeated occurence\n                        out[flag].known.extend(dqdict[flag].known)\n                        out[flag].active.extend(dqdict[flag].active)\n                    except KeyError:  # first occurence\n                        out[flag] = dqdict[flag]\n            if coalesce:\n                return out.coalesce()\n            return out\n\n        return io_read_multi(combiner, cls, source, names=names,\n                             format=format, on_missing='ignore', **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a DataQualityDict from a LIGO_LW XML VetoDefinerTable.", "response": "def from_veto_definer_file(cls, fp, start=None, end=None, ifo=None,\n                               format='ligolw'):\n        \"\"\"Read a `DataQualityDict` from a LIGO_LW XML VetoDefinerTable.\n\n        Parameters\n        ----------\n        fp : `str`\n            path of veto definer file to read\n        start : `~gwpy.time.LIGOTimeGPS`, `int`, optional\n            GPS start time at which to restrict returned flags\n        end : `~gwpy.time.LIGOTimeGPS`, `int`, optional\n            GPS end time at which to restrict returned flags\n        ifo : `str`, optional\n            interferometer prefix whose flags you want to read\n        format : `str`, optional\n            format of file to read, currently only 'ligolw' is supported\n\n        Returns\n        -------\n        flags : `DataQualityDict`\n            a `DataQualityDict` of flags parsed from the `veto_def_table`\n            of the input file.\n\n        Notes\n        -----\n        This method does not automatically `~DataQualityDict.populate`\n        the `active` segment list of any flags, a separate call should\n        be made for that as follows\n\n        >>> flags = DataQualityDict.from_veto_definer_file('/path/to/file.xml')\n        >>> flags.populate()\n\n        \"\"\"\n        if format != 'ligolw':\n            raise NotImplementedError(\"Reading veto definer from non-ligolw \"\n                                      \"format file is not currently \"\n                                      \"supported\")\n\n        # read veto definer file\n        with get_readable_fileobj(fp, show_progress=False) as fobj:\n            from ..io.ligolw import read_table as read_ligolw_table\n            veto_def_table = read_ligolw_table(fobj, 'veto_definer')\n\n        if start is not None:\n            start = to_gps(start)\n        if end is not None:\n            end = to_gps(end)\n\n        # parse flag definitions\n        out = cls()\n        for row in veto_def_table:\n            if ifo and row.ifo != ifo:\n                continue\n            if start and 0 < row.end_time <= start:\n                continue\n            elif start:\n                row.start_time = max(row.start_time, start)\n            if end and row.start_time >= end:\n                continue\n            elif end and not row.end_time:\n                row.end_time = end\n            elif end:\n                row.end_time = min(row.end_time, end)\n            flag = DataQualityFlag.from_veto_def(row)\n            if flag.name in out:\n                out[flag.name].known.extend(flag.known)\n                out[flag.name].known.coalesce()\n            else:\n                out[flag.name] = flag\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a DataQualityDict from a set of LIGO_LW segment tables and a list of flag names and optional GPS times.", "response": "def from_ligolw_tables(cls, segmentdeftable, segmentsumtable,\n                           segmenttable, names=None, gpstype=LIGOTimeGPS,\n                           on_missing='error'):\n        \"\"\"Build a `DataQualityDict` from a set of LIGO_LW segment tables\n\n        Parameters\n        ----------\n        segmentdeftable : :class:`~ligo.lw.lsctables.SegmentDefTable`\n            the ``segment_definer`` table to read\n\n        segmentsumtable : :class:`~ligo.lw.lsctables.SegmentSumTable`\n            the ``segment_summary`` table to read\n\n        segmenttable : :class:`~ligo.lw.lsctables.SegmentTable`\n            the ``segment`` table to read\n\n        names : `list` of `str`, optional\n            a list of flag names to read, defaults to returning all\n\n        gpstype : `type`, `callable`, optional\n            class to use for GPS times in returned objects, can be a function\n            to convert GPS time to something else, default is\n            `~gwpy.time.LIGOTimeGPS`\n\n        on_missing : `str`, optional\n            action to take when a one or more ``names`` are not found in\n            the ``segment_definer`` table, one of\n\n            - ``'ignore'`` : do nothing\n            - ``'warn'`` : print a warning\n            - ``error'`` : raise a `ValueError`\n\n        Returns\n        -------\n        dqdict : `DataQualityDict`\n            a dict of `DataQualityFlag` objects populated from the LIGO_LW\n            tables\n        \"\"\"\n        out = cls()\n\n        id_ = dict()  # need to record relative IDs from LIGO_LW\n\n        # read segment definers and generate DataQualityFlag object\n        for row in segmentdeftable:\n            ifos = sorted(row.instruments)\n            ifo = ''.join(ifos) if ifos else None\n            tag = row.name\n            version = row.version\n            name = ':'.join([str(k) for k in (ifo, tag, version) if\n                             k is not None])\n            if names is None or name in names:\n                out[name] = DataQualityFlag(name)\n                thisid = int(row.segment_def_id)\n                try:\n                    id_[name].append(thisid)\n                except (AttributeError, KeyError):\n                    id_[name] = [thisid]\n\n        # verify all requested flags were found\n        for flag in names or []:\n            if flag not in out and on_missing != 'ignore':\n                msg = (\"no segment definition found for flag={0!r} in \"\n                       \"file\".format(flag))\n                if on_missing == 'warn':\n                    warnings.warn(msg)\n                else:\n                    raise ValueError(msg)\n\n        # parse a table into the target DataQualityDict\n        def _parse_segments(table, listattr):\n            for row in table:\n                for flag in out:\n                    # match row ID to list of IDs found for this flag\n                    if int(row.segment_def_id) in id_[flag]:\n                        getattr(out[flag], listattr).append(\n                            Segment(*map(gpstype, row.segment)),\n                        )\n                        break\n\n        # read segment summary table as 'known'\n        _parse_segments(segmentsumtable, \"known\")\n\n        # read segment table as 'active'\n        _parse_segments(segmenttable, \"active\")\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_ligolw_tables(self, ilwdchar_compat=None, **attrs):\n        if ilwdchar_compat is None:\n            warnings.warn(\"ilwdchar_compat currently defaults to `True`, \"\n                          \"but this will change to `False` in the future, to \"\n                          \"maintain compatibility in future releases, \"\n                          \"manually specify `ilwdchar_compat=True`\",\n                          PendingDeprecationWarning)\n            ilwdchar_compat = True\n\n        if ilwdchar_compat:\n            from glue.ligolw import lsctables\n        else:\n            from ligo.lw import lsctables\n        from ..io.ligolw import to_table_type as to_ligolw_table_type\n\n        SegmentDefTable = lsctables.SegmentDefTable\n        SegmentSumTable = lsctables.SegmentSumTable\n        SegmentTable = lsctables.SegmentTable\n        segdeftab = lsctables.New(SegmentDefTable)\n        segsumtab = lsctables.New(SegmentSumTable)\n        segtab = lsctables.New(SegmentTable)\n\n        def _write_attrs(table, row):\n            for key, val in attrs.items():\n                setattr(row, key, to_ligolw_table_type(val, table, key))\n\n        # write flags to tables\n        for flag in self.values():\n            # segment definer\n            segdef = segdeftab.RowType()\n            for col in segdeftab.columnnames:  # default all columns to None\n                setattr(segdef, col, None)\n            segdef.instruments = {flag.ifo}\n            segdef.name = flag.tag\n            segdef.version = flag.version\n            segdef.comment = flag.description\n            segdef.insertion_time = to_gps(datetime.datetime.now()).gpsSeconds\n            segdef.segment_def_id = SegmentDefTable.get_next_id()\n            _write_attrs(segdeftab, segdef)\n            segdeftab.append(segdef)\n\n            # write segment summary (known segments)\n            for vseg in flag.known:\n                segsum = segsumtab.RowType()\n                for col in segsumtab.columnnames:  # default columns to None\n                    setattr(segsum, col, None)\n                segsum.segment_def_id = segdef.segment_def_id\n                segsum.segment = map(LIGOTimeGPS, vseg)\n                segsum.comment = None\n                segsum.segment_sum_id = SegmentSumTable.get_next_id()\n                _write_attrs(segsumtab, segsum)\n                segsumtab.append(segsum)\n\n            # write segment table (active segments)\n            for aseg in flag.active:\n                seg = segtab.RowType()\n                for col in segtab.columnnames:  # default all columns to None\n                    setattr(seg, col, None)\n                seg.segment_def_id = segdef.segment_def_id\n                seg.segment = map(LIGOTimeGPS, aseg)\n                seg.segment_id = SegmentTable.get_next_id()\n                _write_attrs(segtab, seg)\n                segtab.append(seg)\n\n        return segdeftab, segsumtab, segtab", "response": "Convert this DataQualityDict into a trio of LIGO_LW segment tables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef populate(self, source=DEFAULT_SEGMENT_SERVER,\n                 segments=None, pad=True, on_error='raise', **kwargs):\n        \"\"\"Query the segment database for each flag's active segments.\n\n        This method assumes all of the metadata for each flag have been\n        filled. Minimally, the following attributes must be filled\n\n        .. autosummary::\n\n           ~DataQualityFlag.name\n           ~DataQualityFlag.known\n\n        Segments will be fetched from the database, with any\n        :attr:`~DataQualityFlag.padding` added on-the-fly.\n\n        Entries in this dict will be modified in-place.\n\n        Parameters\n        ----------\n        source : `str`\n            source of segments for this flag. This must be\n            either a URL for a segment database or a path to a file on disk.\n\n        segments : `SegmentList`, optional\n            a list of known segments during which to query, if not given,\n            existing known segments for flags will be used.\n\n        pad : `bool`, optional, default: `True`\n            apply the `~DataQualityFlag.padding` associated with each\n            flag, default: `True`.\n\n        on_error : `str`\n            how to handle an error querying for one flag, one of\n\n            - `'raise'` (default): raise the Exception\n            - `'warn'`: print a warning\n            - `'ignore'`: move onto the next flag as if nothing happened\n\n        **kwargs\n            any other keyword arguments to be passed to\n            :meth:`DataQualityFlag.query` or :meth:`DataQualityFlag.read`.\n\n        Returns\n        -------\n        self : `DataQualityDict`\n            a reference to the modified DataQualityDict\n        \"\"\"\n        # check on_error flag\n        if on_error not in ['raise', 'warn', 'ignore']:\n            raise ValueError(\"on_error must be one of 'raise', 'warn', \"\n                             \"or 'ignore'\")\n        # format source\n        source = urlparse(source)\n        # perform query for all segments\n        if source.netloc and segments is not None:\n            segments = SegmentList(map(Segment, segments))\n            tmp = type(self).query(self.keys(), segments, url=source.geturl(),\n                                   on_error=on_error, **kwargs)\n        elif not source.netloc:\n            tmp = type(self).read(source.geturl(), **kwargs)\n        # apply padding and wrap to given known segments\n        for key in self:\n            if segments is None and source.netloc:\n                try:\n                    tmp = {key: self[key].query(\n                        self[key].name, self[key].known, **kwargs)}\n                except URLError as exc:\n                    if on_error == 'ignore':\n                        pass\n                    elif on_error == 'warn':\n                        warnings.warn('Error querying for %s: %s' % (key, exc))\n                    else:\n                        raise\n                    continue\n            self[key].known &= tmp[key].known\n            self[key].active = tmp[key].active\n            if pad:\n                self[key] = self[key].pad(inplace=True)\n                if segments is not None:\n                    self[key].known &= segments\n                    self[key].active &= segments\n        return self", "response": "Query the segment database for each flag s active segments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self, deep=False):\n        if deep:\n            return deepcopy(self)\n        return super(DataQualityDict, self).copy()", "response": "Build a copy of this dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the union of all flags in this dict", "response": "def union(self):\n        \"\"\"Return the union of all flags in this dict\n\n        Returns\n        -------\n        union : `DataQualityFlag`\n            a new `DataQualityFlag` who's active and known segments\n            are the union of those of the values of this dict\n        \"\"\"\n        usegs = reduce(operator.or_, self.values())\n        usegs.name = ' | '.join(self.keys())\n        return usegs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the intersection of all flags in this dict and the known segments .", "response": "def intersection(self):\n        \"\"\"Return the intersection of all flags in this dict\n\n        Returns\n        -------\n        intersection : `DataQualityFlag`\n            a new `DataQualityFlag` who's active and known segments\n            are the intersection of those of the values of this dict\n        \"\"\"\n        isegs = reduce(operator.and_, self.values())\n        isegs.name = ' & '.join(self.keys())\n        return isegs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot this flag on a segments projection.", "response": "def plot(self, label='key', **kwargs):\n        \"\"\"Plot this flag on a segments projection.\n\n        Parameters\n        ----------\n        label : `str`, optional\n            Labelling system to use, or fixed label for all flags,\n            special values include\n\n            - ``'key'``: use the key of the `DataQualityDict`,\n            - ``'name'``: use the :attr:`~DataQualityFlag.name` of the flag\n\n            If anything else, that fixed label will be used for all lines.\n\n        **kwargs\n            all keyword arguments are passed to the\n            :class:`~gwpy.plot.Plot` constructor.\n\n        Returns\n        -------\n        figure : `~matplotlib.figure.Figure`\n            the newly created figure, with populated Axes.\n\n        See Also\n        --------\n        matplotlib.pyplot.figure\n            for documentation of keyword arguments used to create the\n            figure\n        matplotlib.figure.Figure.add_subplot\n            for documentation of keyword arguments used to create the\n            axes\n        gwpy.plot.SegmentAxes.plot_segmentlist\n            for documentation of keyword arguments used in rendering the data\n        \"\"\"\n        # make plot\n        from ..plot import Plot\n        plot = Plot(self, projection='segments', **kwargs)\n\n        # update labels\n        artists = [x for ax in plot.axes for x in ax.collections]\n        for key, artist in zip(self, artists):\n            if label.lower() == 'name':\n                lab = self[key].name\n            elif label.lower() != 'key':\n                lab = key\n            else:\n                lab = label\n            artist.set_label(lab)\n\n        return plot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new matplotlib. RcParams object with updated GWpy parameters and TeX parameters.", "response": "def rc_params(usetex=None):\n    \"\"\"Returns a new `matplotlib.RcParams` with updated GWpy parameters\n\n    The updated parameters are globally stored as\n    `gwpy.plot.rc.GWPY_RCPARAMS`, with the updated TeX parameters as\n    `gwpy.plot.rc.GWPY_TEX_RCPARAMS`.\n\n    .. note::\n\n       This function doesn't apply the new `RcParams` in any way, just\n       creates something that can be used to set `matplotlib.rcParams`.\n\n    Parameters\n    ----------\n    usetex : `bool`, `None`\n        value to set for `text.usetex`; if `None` determine automatically\n        using the ``GWPY_USETEX`` environment variable, and whether `tex`\n        is available on the system. If `True` is given (or determined)\n        a number of other parameters are updated to improve TeX formatting.\n\n    Examples\n    --------\n    >>> import matplotlib\n    >>> from gwpy.plot.rc import rc_params as gwpy_rc_params()\n    >>> matplotlib.rcParams.update(gwpy_rc_params(usetex=False))\n    \"\"\"\n    # if user didn't specify to use tex or not, guess based on\n    # the `GWPY_USETEX` environment variable, or whether tex is\n    # installed at all.\n    if usetex is None:\n        usetex = bool_env(\n            'GWPY_USETEX',\n            default=rcParams['text.usetex'] or tex.has_tex())\n\n    # build RcParams from matplotlib.rcParams with GWpy extras\n    rcp = GWPY_RCPARAMS.copy()\n    if usetex:\n        rcp.update(GWPY_TEX_RCPARAMS)\n    return rcp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subplot_params(figsize):\n    width, height, = figsize\n    try:\n        left, right = SUBPLOT_WIDTH[width]\n    except KeyError:\n        left = right = None\n    try:\n        bottom, top = SUBPLOT_HEIGHT[height]\n    except KeyError:\n        bottom = top = None\n    return SubplotParams(left=left, bottom=bottom, right=right, top=top)", "response": "Return sensible default set of subplot parameters for a given figure size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats an input for representation as text", "response": "def to_string(input_):\n    \"\"\"Format an input for representation as text\n\n    This method is just a convenience that handles default LaTeX formatting\n    \"\"\"\n    usetex = rcParams['text.usetex']\n    if isinstance(input_, units.UnitBase):\n        return input_.to_string('latex_inline')\n    if isinstance(input_, (float, int)) and usetex:\n        return tex.float_to_latex(input_)\n    if usetex:\n        return tex.label_to_latex(input_)\n    return str(input_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default_unit_label(axis, unit):\n    if not axis.isDefault_label:\n        return\n    label = axis.set_label_text(unit.to_string('latex_inline_dimensional'))\n    axis.isDefault_label = True\n    return label.get_text()", "response": "Set default label for an axis from a ~astropy. units. Unit object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the application for use with this is . This is the main entry point for LDAP authentication.", "response": "def init_app(app):\n        \"\"\"Initialize the `app` for use with this :class:`~LDAP`. This is\n        called automatically if `app` is passed to :meth:`~LDAP.__init__`.\n\n        :param flask.Flask app: the application to configure for use with\n           this :class:`~LDAP`\n        \"\"\"\n\n        app.config.setdefault('LDAP_HOST', 'localhost')\n        app.config.setdefault('LDAP_PORT', 389)\n        app.config.setdefault('LDAP_SCHEMA', 'ldap')\n        app.config.setdefault('LDAP_USERNAME', None)\n        app.config.setdefault('LDAP_PASSWORD', None)\n        app.config.setdefault('LDAP_TIMEOUT', 10)\n        app.config.setdefault('LDAP_USE_SSL', False)\n        app.config.setdefault('LDAP_USE_TLS', False)\n        app.config.setdefault('LDAP_REQUIRE_CERT', False)\n        app.config.setdefault('LDAP_CERT_PATH', '/path/to/cert')\n        app.config.setdefault('LDAP_BASE_DN', None)\n        app.config.setdefault('LDAP_OBJECTS_DN', 'distinguishedName')\n        app.config.setdefault('LDAP_USER_FIELDS', [])\n        app.config.setdefault('LDAP_USER_OBJECT_FILTER',\n                              '(&(objectclass=Person)(userPrincipalName=%s))')\n        app.config.setdefault('LDAP_USER_GROUPS_FIELD', 'memberOf')\n        app.config.setdefault('LDAP_GROUP_FIELDS', [])\n        app.config.setdefault('LDAP_GROUP_OBJECT_FILTER',\n                              '(&(objectclass=Group)(userPrincipalName=%s))')\n        app.config.setdefault('LDAP_GROUP_MEMBERS_FIELD', 'member')\n        app.config.setdefault('LDAP_LOGIN_VIEW', 'login')\n        app.config.setdefault('LDAP_REALM_NAME', 'LDAP authentication')\n        app.config.setdefault('LDAP_OPENLDAP', False)\n        app.config.setdefault('LDAP_GROUP_MEMBER_FILTER', '*')\n        app.config.setdefault('LDAP_GROUP_MEMBER_FILTER_FIELD', '*')\n        app.config.setdefault('LDAP_CUSTOM_OPTIONS', None)\n\n        if app.config['LDAP_USE_SSL'] or app.config['LDAP_USE_TLS']:\n            ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT,\n                            ldap.OPT_X_TLS_NEVER)\n\n        if app.config['LDAP_REQUIRE_CERT']:\n            ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT,\n                            ldap.OPT_X_TLS_DEMAND)\n            ldap.set_option(ldap.OPT_X_TLS_CACERTFILE,\n                            current_app.config['LDAP_CERT_PATH'])\n\n        for option in ['USERNAME', 'PASSWORD', 'BASE_DN']:\n            if app.config['LDAP_{0}'.format(option)] is None:\n                raise LDAPException('LDAP_{0} cannot be None!'.format(option))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize(self):\n\n        try:\n            conn = ldap.initialize('{0}://{1}:{2}'.format(\n                current_app.config['LDAP_SCHEMA'],\n                current_app.config['LDAP_HOST'],\n                current_app.config['LDAP_PORT']))\n            conn.set_option(ldap.OPT_NETWORK_TIMEOUT,\n                            current_app.config['LDAP_TIMEOUT'])\n            conn = self._set_custom_options(conn)\n            conn.protocol_version = ldap.VERSION3\n            if current_app.config['LDAP_USE_TLS']:\n                conn.start_tls_s()\n            return conn\n        except ldap.LDAPError as e:\n            raise LDAPException(self.error(e.args))", "response": "Initialize a connection to the LDAP server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind(self):\n\n        conn = self.initialize\n        try:\n            conn.simple_bind_s(\n                current_app.config['LDAP_USERNAME'],\n                current_app.config['LDAP_PASSWORD'])\n            return conn\n        except ldap.LDAPError as e:\n            raise LDAPException(self.error(e.args))", "response": "Attempts to bind to the LDAP server using the credentials of the\n            service account."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind_user(self, username, password):\n\n        user_dn = self.get_object_details(user=username, dn_only=True)\n\n        if user_dn is None:\n            return\n        try:\n            conn = self.initialize\n            conn.simple_bind_s(user_dn.decode('utf-8'), password)\n            return True\n        except ldap.LDAPError:\n            return", "response": "Attempts to bind a user to the LDAP server using the credentials\n            supplied."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_object_details(self, user=None, group=None, dn_only=False):\n\n        query = None\n        fields = None\n        if user is not None:\n            if not dn_only:\n                fields = current_app.config['LDAP_USER_FIELDS']\n            query = ldap_filter.filter_format(\n                current_app.config['LDAP_USER_OBJECT_FILTER'], (user,))\n        elif group is not None:\n            if not dn_only:\n                fields = current_app.config['LDAP_GROUP_FIELDS']\n            query = ldap_filter.filter_format(\n                current_app.config['LDAP_GROUP_OBJECT_FILTER'], (group,))\n        conn = self.bind\n        try:\n            records = conn.search_s(current_app.config['LDAP_BASE_DN'],\n                                    ldap.SCOPE_SUBTREE, query, fields)\n\n            conn.unbind_s()\n            result = {}\n            if records:\n                if dn_only:\n                    if current_app.config['LDAP_OPENLDAP']:\n                        if records:\n                            return records[0][0]\n                    else:\n                        if current_app.config['LDAP_OBJECTS_DN'] \\\n                                in records[0][1]:\n                            dn = records[0][1][\n                                current_app.config['LDAP_OBJECTS_DN']]\n                            return dn[0]\n                for k, v in list(records[0][1].items()):\n                    result[k] = v\n                return result\n        except ldap.LDAPError as e:\n            raise LDAPException(self.error(e.args))", "response": "Returns a dict with the object s details."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_user_groups(self, user):\n\n        conn = self.bind\n        try:\n            if current_app.config['LDAP_OPENLDAP']:\n                fields = \\\n                    [str(current_app.config['LDAP_GROUP_MEMBER_FILTER_FIELD'])]\n                records = conn.search_s(\n                    current_app.config['LDAP_BASE_DN'], ldap.SCOPE_SUBTREE,\n                    ldap_filter.filter_format(\n                        current_app.config['LDAP_GROUP_MEMBER_FILTER'],\n                        (self.get_object_details(user, dn_only=True),)),\n                    fields)\n            else:\n                records = conn.search_s(\n                    current_app.config['LDAP_BASE_DN'], ldap.SCOPE_SUBTREE,\n                    ldap_filter.filter_format(\n                        current_app.config['LDAP_USER_OBJECT_FILTER'],\n                        (user,)),\n                    [current_app.config['LDAP_USER_GROUPS_FIELD']])\n\n            conn.unbind_s()\n            if records:\n                if current_app.config['LDAP_OPENLDAP']:\n                    group_member_filter = \\\n                        current_app.config['LDAP_GROUP_MEMBER_FILTER_FIELD']\n                    if sys.version_info[0] > 2:\n                        groups = [record[1][group_member_filter][0].decode(\n                            'utf-8') for record in records]\n                    else:\n                        groups = [record[1][group_member_filter][0] for\n                                  record in records]\n                    return groups\n                else:\n                    if current_app.config['LDAP_USER_GROUPS_FIELD'] in \\\n                            records[0][1]:\n                        groups = records[0][1][\n                            current_app.config['LDAP_USER_GROUPS_FIELD']]\n                        result = [re.findall(b'(?:cn=|CN=)(.*?),', group)[0]\n                                  for group in groups]\n                        if sys.version_info[0] > 2:\n                            result = [r.decode('utf-8') for r in result]\n                        return result\n        except ldap.LDAPError as e:\n            raise LDAPException(self.error(e.args))", "response": "Returns a list with the user s groups or None if unsuccessful."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_group_members(self, group):\n\n        conn = self.bind\n        try:\n            records = conn.search_s(\n                current_app.config['LDAP_BASE_DN'], ldap.SCOPE_SUBTREE,\n                ldap_filter.filter_format(\n                    current_app.config['LDAP_GROUP_OBJECT_FILTER'], (group,)),\n                [current_app.config['LDAP_GROUP_MEMBERS_FIELD']])\n            conn.unbind_s()\n            if records:\n                if current_app.config['LDAP_GROUP_MEMBERS_FIELD'] in \\\n                        records[0][1]:\n                    members = records[0][1][\n                        current_app.config['LDAP_GROUP_MEMBERS_FIELD']]\n                    if sys.version_info[0] > 2:\n                        members = [m.decode('utf-8') for m in members]\n                    return members\n        except ldap.LDAPError as e:\n            raise LDAPException(self.error(e.args))", "response": "Returns a list with the group s members or None if unsuccessful."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_required(groups=None):\n\n        def wrapper(func):\n            @wraps(func)\n            def wrapped(*args, **kwargs):\n                if g.user is None:\n                    return redirect(\n                        url_for(current_app.config['LDAP_LOGIN_VIEW'],\n                                next=request.path))\n                match = [group for group in groups if group in g.ldap_groups]\n                if not match:\n                    abort(401)\n\n                return func(*args, **kwargs)\n\n            return wrapped\n\n        return wrapper", "response": "Decorator that allows the user to access the specified LDAP_LOGIN_VIEW s LDAP_USER_MEMBERS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef basic_auth_required(self, func):\n\n        def make_auth_required_response():\n            response = make_response('Unauthorized', 401)\n            response.www_authenticate.set_basic(\n                current_app.config['LDAP_REALM_NAME'])\n            return response\n\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            if request.authorization is None:\n                req_username = None\n                req_password = None\n            else:\n                req_username = request.authorization.username\n                req_password = request.authorization.password\n\n            # Many LDAP servers will grant you anonymous access if you log in\n            # with an empty password, even if you supply a non-anonymous user\n            # ID, causing .bind_user() to return True. Therefore, only accept\n            # non-empty passwords.\n            if req_username in ['', None] or req_password in ['', None]:\n                current_app.logger.debug('Got a request without auth data')\n                return make_auth_required_response()\n\n            if not self.bind_user(req_username, req_password):\n                current_app.logger.debug('User {0!r} gave wrong '\n                                         'password'.format(req_username))\n                return make_auth_required_response()\n\n            g.ldap_username = req_username\n            g.ldap_password = req_password\n\n            return func(*args, **kwargs)\n\n        return wrapped", "response": "Decorator to make sure that a request is authenticated via HTTP Basic Authentication system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nauthenticating through duolingo. com. login.", "response": "def _login(self):\n        \"\"\"\n        Authenticate through ``https://www.duolingo.com/login``.\n        \"\"\"\n        login_url = \"https://www.duolingo.com/login\"\n        data = {\"login\": self.username, \"password\": self.password}\n        request = self._make_req(login_url, data)\n        attempt = request.json()\n\n        if attempt.get('response') == 'OK':\n            self.jwt = request.headers['jwt']\n            return True\n\n        raise Exception(\"Login failed\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting user s activity stream from duolingo. com.", "response": "def get_activity_stream(self, before=None):\n        \"\"\"\n        Get user's activity stream from\n        ``https://www.duolingo.com/stream/<user_id>?before=<date> if before\n        date is given or else\n        ``https://www.duolingo.com/activity/<user_id>``\n\n        :param before: Datetime in format '2015-07-06 05:42:24'\n        :type before: str\n        :rtype: dict\n        \"\"\"\n        if before:\n            url = \"https://www.duolingo.com/stream/{}?before={}\"\n            url = url.format(self.user_data.id, before)\n        else:\n            url = \"https://www.duolingo.com/activity/{}\"\n            url = url.format(self.user_data.id)\n        request = self._make_req(url)\n        try:\n            return request.json()\n        except:\n            raise Exception('Could not get activity stream')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the leaderboard for a given unit", "response": "def get_leaderboard(self, unit=None, before=None):\n        \"\"\"\n        Get user's rank in the week in descending order, stream from\n        ``https://www.duolingo.com/friendships/leaderboard_activity?unit=week&_=time\n\n        :param before: Datetime in format '2015-07-06 05:42:24'\n        :param unit: maybe week or month\n        :type before: str\n        :type unit: str\n        :rtype: List\n        \"\"\"\n        if unit:\n            url = 'https://www.duolingo.com/friendships/leaderboard_activity?unit={}&_={}'\n        else:\n            raise Exception('Needs unit as argument (week or month)')\n\n        if before:\n            url = url.format(unit, before)\n        else:\n            raise Exception('Needs str in Datetime format \"%Y.%m.%d %H:%M:%S\"')\n\n        self.leader_data = self._make_req(url).json()\n        data = []\n        for result in iter(self.get_friends()):\n            for value in iter(self.leader_data['ranking']):\n                if result['id'] == int(value):\n                    temp = {'points': int(self.leader_data['ranking'][value]),\n                            'unit': unit,\n                            'id': result['id'],\n                            'username': result['username']}\n                    data.append(temp)\n\n        return sorted(data, key=lambda user: user['points'], reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuy an item from the store.", "response": "def buy_item(self, item_name, abbr):\n        url = 'https://www.duolingo.com/2017-06-30/users/{}/purchase-store-item'\n        url = url.format(self.user_data.id)\n\n        data = {'name': item_name, 'learningLanguage': abbr}\n        request = self._make_req(url, data)\n\n        \"\"\"\n        status code '200' indicates that the item was purchased\n        returns a text like: {\"streak_freeze\":\"2017-01-10 02:39:59.594327\"}\n        \"\"\"\n\n        if request.status_code == 400 and request.json()['error'] == 'ALREADY_HAVE_STORE_ITEM':\n            raise AlreadyHaveStoreItemException('Already equipped with ' + item_name + '.')\n        if not request.ok:\n            # any other error:\n            raise Exception('Not possible to buy item.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuying the user s current learning language", "response": "def buy_streak_freeze(self):\n        \"\"\"\n        figure out the users current learning language\n        use this one as parameter for the shop\n        \"\"\"\n        lang = self.get_abbreviation_of(self.get_user_info()['learning_language_string'])\n        if lang is None:\n            raise Exception('No learning language found')\n        try:\n            self.buy_item('streak_freeze', lang)\n            return True\n        except AlreadyHaveStoreItemException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the learned language with .", "response": "def _switch_language(self, lang):\n        \"\"\"\n        Change the learned language with\n        ``https://www.duolingo.com/switch_language``.\n\n        :param lang: Wanted language abbreviation (example: ``'fr'``)\n        :type lang: str\n        \"\"\"\n        data = {\"learning_language\": lang}\n        url = \"https://www.duolingo.com/switch_language\"\n        request = self._make_req(url, data)\n\n        try:\n            parse = request.json()['tracking_properties']\n            if parse['learning_language'] == lang:\n                self.user_data = Struct(**self._get_data())\n        except:\n            raise Exception('Failed to switch language')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the order of the dependencies of the skills in the order they were learned in.", "response": "def _compute_dependency_order(skills):\n        \"\"\"\n        Add a field to each skill indicating the order it was learned\n        based on the skill's dependencies. Multiple skills will have the same\n        position if they have the same dependencies.\n        \"\"\"\n        # Key skills by first dependency. Dependency sets can be uniquely\n        # identified by one dependency in the set.\n        dependency_to_skill = MultiDict([(skill['dependencies_name'][0]\n                                          if skill['dependencies_name']\n                                          else '',\n                                          skill)\n                                         for skill in skills])\n\n        # Start with the first skill and trace the dependency graph through\n        # skill, setting the order it was learned in.\n        index = 0\n        previous_skill = ''\n        while True:\n            for skill in dependency_to_skill.getlist(previous_skill):\n                skill['dependency_order'] = index\n            index += 1\n\n            # Figure out the canonical dependency for the next set of skills.\n            skill_names = set([skill['name']\n                               for skill in\n                               dependency_to_skill.getlist(previous_skill)])\n            canonical_dependency = skill_names.intersection(\n                set(dependency_to_skill.keys()))\n            if canonical_dependency:\n                previous_skill = canonical_dependency.pop()\n            else:\n                # Nothing depends on these skills, so we're done.\n                break\n\n        return skills"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget praticed languages. :param abbreviations: Get language as abbreviation or not :type abbreviations: bool :return: List of languages :rtype: list of str", "response": "def get_languages(self, abbreviations=False):\n        \"\"\"\n        Get praticed languages.\n\n        :param abbreviations: Get language as abbreviation or not\n        :type abbreviations: bool\n        :return: List of languages\n        :rtype: list of str\n        \"\"\"\n        data = []\n\n        for lang in self.user_data.languages:\n            if lang['learning']:\n                if abbreviations:\n                    data.append(lang['language'])\n                else:\n                    data.append(lang['language_string'])\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_language_from_abbr(self, abbr):\n        for language in self.user_data.languages:\n            if language['language'] == abbr:\n                return language['language_string']\n        return None", "response": "Get language full name from abbreviation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the abbreviation of a language.", "response": "def get_abbreviation_of(self, name):\n        \"\"\"Get abbreviation of a language.\"\"\"\n        for language in self.user_data.languages:\n            if language['language_string'] == name:\n                return language['language']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_language_details(self, language):\n        for lang in self.user_data.languages:\n            if language == lang['language_string']:\n                return lang\n\n        return {}", "response": "Get user s status about a language."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_certificates(self):\n        for certificate in self.user_data.certificates:\n            certificate['datetime'] = certificate['datetime'].strip()\n\n        return self.user_data.certificates", "response": "Get user s certificates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_calendar(self, language_abbr=None):\n        if language_abbr:\n            if not self._is_current_language(language_abbr):\n                self._switch_language(language_abbr)\n            return self.user_data.language_data[language_abbr]['calendar']\n        else:\n            return self.user_data.calendar", "response": "Get user s last actions."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget informations about user s progression in a language.", "response": "def get_language_progress(self, lang):\n        \"\"\"Get informations about user's progression in a language.\"\"\"\n        if not self._is_current_language(lang):\n            self._switch_language(lang)\n\n        fields = ['streak', 'language_string', 'level_progress',\n                  'num_skills_learned', 'level_percent', 'level_points',\n                  'points_rank', 'next_level', 'level_left', 'language',\n                  'points', 'fluency_score', 'level']\n\n        return self._make_dict(fields, self.user_data.language_data[lang])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget user s friends.", "response": "def get_friends(self):\n        \"\"\"Get user's friends.\"\"\"\n        for k, v in iter(self.user_data.language_data.items()):\n            data = []\n            for friend in v['points_ranking_data']:\n                temp = {'username': friend['username'],\n                        'id': friend['id'],\n                        'points': friend['points_data']['total'],\n                        'languages': [i['language_string'] for i in\n                                      friend['points_data']['languages']]}\n                data.append(temp)\n\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_known_words(self, lang):\n        words = []\n        for topic in self.user_data.language_data[lang]['skills']:\n            if topic['learned']:\n                words += topic['words']\n        return set(words)", "response": "Get a list of all words learned by user in a language."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_learned_skills(self, lang):\n        skills = [skill for skill in\n                  self.user_data.language_data[lang]['skills']]\n\n        self._compute_dependency_order(skills)\n\n        return [skill for skill in\n                sorted(skills, key=lambda skill: skill['dependency_order'])\n                if skill['learned']]", "response": "Return the learned skills in the specified language sorted by the order they were learned in."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_known_topics(self, lang):\n        return [topic['title']\n                for topic in self.user_data.language_data[lang]['skills']\n                if topic['learned']]", "response": "Return the topics learned by a user in a language."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the unknown topics in a language.", "response": "def get_unknown_topics(self, lang):\n        \"\"\"Return the topics remaining to learn by a user in a language.\"\"\"\n        return [topic['title']\n                for topic in self.user_data.language_data[lang]['skills']\n                if not topic['learned']]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_golden_topics(self, lang):\n        return [topic['title']\n                for topic in self.user_data.language_data[lang]['skills']\n                if topic['learned'] and topic['strength'] == 1.0]", "response": "Return the topics mastered by a user in a language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the topics learned but not golden by a user in a language.", "response": "def get_reviewable_topics(self, lang):\n        \"\"\"Return the topics learned but not golden by a user in a language.\"\"\"\n        return [topic['title']\n                for topic in self.user_data.language_data[lang]['skills']\n                if topic['learned'] and topic['strength'] < 1.0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget words translations from Duolingo API", "response": "def get_translations(self, words, source=None, target=None):\n        \"\"\"\n        Get words' translations from\n        ``https://d2.duolingo.com/api/1/dictionary/hints/<source>/<target>?tokens=``<words>``\n\n        :param words: A single word or a list\n        :type: str or list of str\n        :param source: Source language as abbreviation\n        :type source: str\n        :param target: Destination language as abbreviation\n        :type target: str\n        :return: Dict with words as keys and translations as values\n        \"\"\"\n        if not source:\n            source = self.user_data.ui_language\n        if not target:\n            target = list(self.user_data.language_data.keys())[0]\n\n        word_parameter = json.dumps(words, separators=(',', ':'))\n        url = \"https://d2.duolingo.com/api/1/dictionary/hints/{}/{}?tokens={}\" \\\n            .format(target, source, word_parameter)\n\n        request = self.session.get(url)\n        try:\n            return request.json()\n        except:\n            raise Exception('Could not get translations')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting overview of user s vocabulary in a language.", "response": "def get_vocabulary(self, language_abbr=None):\n        \"\"\"Get overview of user's vocabulary in a language.\"\"\"\n        if not self.password:\n            raise Exception(\"You must provide a password for this function\")\n        if language_abbr and not self._is_current_language(language_abbr):\n            self._switch_language(language_abbr)\n\n        overview_url = \"https://www.duolingo.com/vocabulary/overview\"\n        overview_request = self._make_req(overview_url)\n        overview = overview_request.json()\n\n        return overview"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fire_update_event(self, *args, **kwargs):\n        for _handler in self._on_update:\n            _handler(*args, **kwargs)", "response": "Trigger the update event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload the current configuration from the cloud returns the downloaded configuration or an error code", "response": "def download_configuration(self) -> str:\r\n        \"\"\"downloads the current configuration from the cloud\r\n\r\n        Returns\r\n            the downloaded configuration or an errorCode\r\n        \"\"\"\r\n        return self._restCall(\r\n            \"home/getCurrentState\", json.dumps(self._connection.clientCharacteristics)\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_current_state(self, clearConfig: bool = False):\r\n        json_state = self.download_configuration()\r\n\r\n        if \"errorCode\" in json_state:\r\n            LOGGER.error(\r\n                \"Could not get the current configuration. Error: %s\",\r\n                json_state[\"errorCode\"],\r\n            )\r\n            return False\r\n\r\n        if clearConfig:\r\n            self.devices = []\r\n            self.clients = []\r\n            self.groups = []\r\n            self.rules = []\r\n            self.functionalHomes = []\r\n\r\n        js_home = json_state[\"home\"]\r\n\r\n        self.from_json(js_home)\r\n\r\n        self._get_devices(json_state)\r\n        self._get_clients(json_state)\r\n        self._get_groups(json_state)\r\n\r\n        self._get_functionalHomes(js_home)\r\n        self._load_functionalChannels()\r\n\r\n        return True", "response": "downloads the current configuration and parses it into self. devices self. clients self. rules self. functionalHomes self. rules self. functionalChannels self. functions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the first functionalHome which is of the specified type", "response": "def get_functionalHome(self, functionalHomeType: type) -> FunctionalHome:\r\n        \"\"\" gets the specified functionalHome\r\n        \r\n        Args:\r\n            functionalHome(type): the type of the functionalHome which should be returned\r\n\r\n        Returns:\r\n            the FunctionalHome or None if it couldn't be found\r\n        \"\"\"\r\n        for x in self.functionalHomes:\r\n            if isinstance(x, functionalHomeType):\r\n                return x\r\n\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching a device by the given id", "response": "def search_device_by_id(self, deviceID) -> Device:\r\n        \"\"\" searches a device by given id\r\n        \r\n        Args:\r\n          deviceID(str): the device to search for\r\n          \r\n        Returns\r\n          the Device object or None if it couldn't find a device\r\n        \"\"\"\r\n        for d in self.devices:\r\n            if d.id == deviceID:\r\n                return d\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch a group by the ID of the highest related entry in the group. Returns None if no such entry is found.", "response": "def search_group_by_id(self, groupID) -> Group:\r\n        \"\"\" searches a group by given id\r\n        \r\n        Args:\r\n          groupID(str): groupID the group to search for\r\n          \r\n        Returns\r\n          the group object or None if it couldn't find a group\r\n        \"\"\"\r\n        for g in self.groups:\r\n            if g.id == groupID:\r\n                return g\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching a client by its id and returns the latest client object or None if it couldn t find a client object", "response": "def search_client_by_id(self, clientID) -> Client:\r\n        \"\"\" searches a client by given id\r\n        \r\n        Args:\r\n          clientID(str): the client to search for\r\n        \r\n        Returns\r\n          the client object or None if it couldn't find a client\r\n        \"\"\"\r\n        for c in self.clients:\r\n            if c.id == clientID:\r\n                return c\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_rule_by_id(self, ruleID) -> Rule:\r\n        for r in self.rules:\r\n            if r.id == ruleID:\r\n                return r\r\n        return None", "response": "Searches a rule by the given id returns a new rule object or None if no such rule exists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the value of the security zones if they are armed or not", "response": "def get_security_zones_activation(self) -> (bool, bool):\r\n        \"\"\" returns the value of the security zones if they are armed or not\r\n        \r\n        Returns\r\n            internal\r\n              True if the internal zone is armed\r\n            external\r\n              True if the external zone is armed\r\n        \"\"\"\r\n        internal_active = False\r\n        external_active = False\r\n        for g in self.groups:\r\n            if isinstance(g, SecurityZoneGroup):\r\n                if g.label == \"EXTERNAL\":\r\n                    external_active = g.active\r\n                elif g.label == \"INTERNAL\":\r\n                    internal_active = g.active\r\n        return internal_active, external_active"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_intrusion_alert_through_smoke_detectors(self, activate: bool = True):\r\n        data = {\"intrusionAlertThroughSmokeDetectors\": activate}\r\n        return self._restCall(\r\n            \"home/security/setIntrusionAlertThroughSmokeDetectors\", json.dumps(data)\r\n        )", "response": "Activate or deactivate if smoke detectors should ring during an alarm\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef activate_absence_with_period(self, endtime: datetime):\r\n        data = {\"endTime\": endtime.strftime(\"%Y_%m_%d %H:%M\")}\r\n        return self._restCall(\r\n            \"home/heating/activateAbsenceWithPeriod\", json.dumps(data)\r\n        )", "response": "activates the absence mode until the given time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nactivating the absence mode for a given time", "response": "def activate_absence_with_duration(self, duration: int):\r\n        \"\"\" activates the absence mode for a given time\r\n\r\n        Args:\r\n            duration(int): the absence duration in minutes\r\n        \"\"\"\r\n        data = {\"duration\": duration}\r\n        return self._restCall(\r\n            \"home/heating/activateAbsenceWithDuration\", json.dumps(data)\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef activate_vacation(self, endtime: datetime, temperature: float):\r\n        data = {\r\n            \"endtime\": endtime.strftime(\"%Y_%m_%d %H:%M\"),\r\n            \"temperature\": temperature,\r\n        }\r\n        return self._restCall(\"home/heating/activateVacation\", json.dumps(data))", "response": "activates the vacation mode until the given time"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a new pin for the home", "response": "def set_pin(self, newPin: str, oldPin: str = None) -> dict:\r\n        \"\"\" sets a new pin for the home\r\n\r\n        Args:\r\n            newPin(str): the new pin\r\n            oldPin(str): optional, if there is currently a pin active it must be given here.\r\n                        Otherwise it will not be possible to set the new pin\r\n\r\n        Returns:\r\n            the result of the call\r\n        \"\"\"\r\n        if newPin == None:\r\n            newPin = \"\"\r\n        data = {\"pin\": newPin}\r\n        if oldPin:\r\n            self._connection.headers[\"PIN\"] = str(oldPin)\r\n        result = self._restCall(\"home/setPin\", body=json.dumps(data))\r\n        if oldPin:\r\n            del self._connection.headers[\"PIN\"]\r\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_timezone(self, timezone: str):\r\n        data = {\"timezoneId\": timezone}\r\n        return self._restCall(\"home/setTimezone\", body=json.dumps(data))", "response": "sets the timezone for the AP. e. European Berlin"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the devices for the security zones Args: internal_devices(List[Device]): the devices which should be used for the internal zone external_devices(List[Device]): the devices which should be used for the external(hull) zone Returns: the result of _restCall", "response": "def set_zones_device_assignment(self, internal_devices, external_devices) -> dict:\r\n        \"\"\" sets the devices for the security zones\r\n        Args:\r\n            internal_devices(List[Device]): the devices which should be used for the internal zone\r\n            external_devices(List[Device]):  the devices which should be used for the external(hull) zone\r\n        \r\n        Returns:\r\n            the result of _restCall\r\n        \"\"\"\r\n        internal = [x.id for x in internal_devices]\r\n        external = [x.id for x in external_devices]\r\n        data = {\"zonesDeviceAssignment\": {\"INTERNAL\": internal, \"EXTERNAL\": external}}\r\n        return self._restCall(\r\n            \"home/security/setZonesDeviceAssignment\", body=json.dumps(data)\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config_file(config_file: str) -> HmipConfig:\n    _config = configparser.ConfigParser()\n    with open(config_file, \"r\") as fl:\n        _config.read_file(fl)\n        logging_filename = _config.get(\"LOGGING\", \"FileName\", fallback=\"hmip.log\")\n        if logging_filename == \"None\":\n            logging_filename = None\n\n        _hmip_config = HmipConfig(\n            _config[\"AUTH\"][\"AuthToken\"],\n            _config[\"AUTH\"][\"AccessPoint\"],\n            int(_config.get(\"LOGGING\", \"Level\", fallback=30)),\n            logging_filename,\n            _config._sections,\n        )\n        return _hmip_config", "response": "Loads the config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def enable_events(self) -> asyncio.Task:\n        return await self._connection.ws_connect(\n            on_message=self._ws_on_message, on_error=self._ws_on_error\n        )", "response": "Connects to the websocket. Returns a listening task."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the color and dimlevel of the lamp Args: channelIndex(int): the channelIndex of the lamp. Use self.topLightChannelIndex or self.bottomLightChannelIndex rgb(RGBColorState): the color of the lamp dimLevel(float): the dimLevel of the lamp. 0.0 = off, 1.0 = MAX Returns: the result of the _restCall", "response": "def set_rgb_dim_level(self, channelIndex: int, rgb: RGBColorState, dimLevel: float):\n        \"\"\" sets the color and dimlevel of the lamp\n\n        Args:\n            channelIndex(int): the channelIndex of the lamp. Use self.topLightChannelIndex or self.bottomLightChannelIndex\n            rgb(RGBColorState): the color of the lamp\n            dimLevel(float): the dimLevel of the lamp. 0.0 = off, 1.0 = MAX\n\n        Returns:\n            the result of the _restCall\n        \"\"\"\n        data = {\n            \"channelIndex\": channelIndex,\n            \"deviceId\": self.id,\n            \"simpleRGBColorState\": rgb,\n            \"dimLevel\": dimLevel,\n        }\n        return self._restCall(\n            \"device/control/setSimpleRGBColorDimLevel\", body=json.dumps(data)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_rgb_dim_level_with_time(\n        self,\n        channelIndex: int,\n        rgb: RGBColorState,\n        dimLevel: float,\n        onTime: float,\n        rampTime: float,\n    ):\n        \"\"\" sets the color and dimlevel of the lamp\n\n        Args:\n            channelIndex(int): the channelIndex of the lamp. Use self.topLightChannelIndex or self.bottomLightChannelIndex\n            rgb(RGBColorState): the color of the lamp\n            dimLevel(float): the dimLevel of the lamp. 0.0 = off, 1.0 = MAX\n            onTime(float):\n            rampTime(float):\n        Returns:\n            the result of the _restCall\n        \"\"\"\n        data = {\n            \"channelIndex\": channelIndex,\n            \"deviceId\": self.id,\n            \"simpleRGBColorState\": rgb,\n            \"dimLevel\": dimLevel,\n            \"onTime\": onTime,\n            \"rampTime\": rampTime,\n        }\n        return self._restCall(\n            \"device/control/setSimpleRGBColorDimLevelWithTime\", body=json.dumps(data)\n        )", "response": "This function sets the color and dimlevel of the lamp using the time specified in onTime and rampTime."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_shutter_level(self, level=0.0):\n        data = {\"channelIndex\": 1, \"deviceId\": self.id, \"shutterLevel\": level}\n        return self._restCall(\"device/control/setShutterLevel\", body=json.dumps(data))", "response": "sets the shutter level of the current channel"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the slats and shutter level", "response": "def set_slats_level(self, slatsLevel=0.0, shutterLevel=None):\n        \"\"\" sets the slats and shutter level\n\n        Args:\n            slatsLevel(float): the new level of the slats. 0.0 = open, 1.0 = closed,\n            shutterLevel(float): the new level of the shutter. 0.0 = open, 1.0 = closed, None = use the current value\n        Returns:\n            the result of the _restCall\n        \"\"\"\n        if shutterLevel is None:\n            shutterLevel = self.shutterLevel\n        data = {\n            \"channelIndex\": 1,\n            \"deviceId\": self.id,\n            \"slatsLevel\": slatsLevel,\n            \"shutterLevel\": shutterLevel,\n        }\n        return self._restCall(\"device/control/setSlatsLevel\", json.dumps(data))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_label(self, label):\r\n        data = {\"ruleId\": self.id, \"label\": label}\r\n        return self._restCall(\"rule/setRuleLabel\", json.dumps(data))", "response": "sets the label of the rule"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable or disables this rule", "response": "def set_rule_enabled_state(self, enabled):\r\n        \"\"\" enables/disables this rule\"\"\"\r\n        data = {\"ruleId\": self.id, \"enabled\": enabled}\r\n        return self._restCall(\"rule/enableSimpleRule\", json.dumps(data))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def api_call(self, path, body=None, full_url=False):\r\n        result = None\r\n        if not full_url:\r\n            path = self.full_url(path)\r\n        for i in range(self._restCallRequestCounter):\r\n            try:\r\n                with async_timeout.timeout(self._restCallTimout, loop=self._loop):\r\n                    result = await self._websession.post(\r\n                        path, data=body, headers=self.headers\r\n                    )\r\n                    if result.status == 200:\r\n                        if result.content_type == \"application/json\":\r\n                            ret = await result.json()\r\n                        else:\r\n                            ret = True\r\n                        return ret\r\n                    else:\r\n                        raise HmipWrongHttpStatusError\r\n            except (asyncio.TimeoutError, aiohttp.ClientConnectionError):\r\n                # Both exceptions occur when connecting to the server does\r\n                # somehow not work.\r\n                logger.debug(\"Connection timed out or another error occurred %s\" % path)\r\n            except JSONDecodeError as err:\r\n                logger.exception(err)\r\n            finally:\r\n                if result is not None:\r\n                    await result.release()\r\n        raise HmipConnectionError(\"Failed to connect to HomeMaticIp server\")", "response": "Make the actual call to the HMIP server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef perform_master_login(email, password, android_id,\n                         service='ac2dm', device_country='us',\n                         operatorCountry='us', lang='en', sdk_version=17):\n    \"\"\"\n    Perform a master login, which is what Android does when you first add a\n    Google account.\n\n    Return a dict, eg::\n\n        {\n            'Auth': '...',\n            'Email': 'email@gmail.com',\n            'GooglePlusUpgrade': '1',\n            'LSID': '...',\n            'PicasaUser': 'My Name',\n            'RopRevision': '1',\n            'RopText': ' ',\n            'SID': '...',\n            'Token': 'oauth2rt_1/...',\n            'firstName': 'My',\n            'lastName': 'Name',\n            'services': 'hist,mail,googleme,...'\n        }\n    \"\"\"\n\n    data = {\n        'accountType': 'HOSTED_OR_GOOGLE',\n        'Email':   email,\n        'has_permission':  1,\n        'add_account': 1,\n        'EncryptedPasswd':\n            google.signature(email, password, android_key_7_3_29),\n        'service': service,\n        'source':  'android',\n        'androidId':   android_id,\n        'device_country':  device_country,\n        'operatorCountry': device_country,\n        'lang':    lang,\n        'sdk_version': sdk_version,\n        }\n\n    return _perform_auth_request(data)", "response": "Perform a master login."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform_oauth(email, master_token, android_id, service, app, client_sig,\n                  device_country='us', operatorCountry='us', lang='en',\n                  sdk_version=17):\n    \"\"\"\n    Use a master token from master_login to perform OAuth to a specific Google\n    service.\n\n    Return a dict, eg::\n\n        {\n            'Auth': '...',\n            'LSID': '...',\n            'SID': '..',\n            'issueAdvice': 'auto',\n            'services': 'hist,mail,googleme,...'\n        }\n\n    To authenticate requests to this service, include a header\n    ``Authorization: GoogleLogin auth=res['Auth']``.\n    \"\"\"\n\n    data = {\n        'accountType': 'HOSTED_OR_GOOGLE',\n        'Email':   email,\n        'has_permission':  1,\n        'EncryptedPasswd': master_token,\n        'service': service,\n        'source':  'android',\n        'androidId':   android_id,\n        'app': app,\n        'client_sig': client_sig,\n        'device_country':  device_country,\n        'operatorCountry': device_country,\n        'lang':    lang,\n        'sdk_version': sdk_version\n        }\n\n    return _perform_auth_request(data)", "response": "Perform OAuth to a specific Google\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_prime(n, rnd=default_pseudo_random, k=DEFAULT_ITERATION,\n             algorithm=None):\n    '''Test if n is a prime number\n\n       m - the integer to test\n       rnd - the random number generator to use for the probalistic primality\n       algorithms,\n       k - the number of iterations to use for the probabilistic primality\n       algorithms,\n       algorithm - the primality algorithm to use, default is Miller-Rabin. The\n       gmpy implementation is used if gmpy is installed.\n\n       Return value: True is n seems prime, False otherwise.\n    '''\n\n    if algorithm is None:\n        algorithm = PRIME_ALGO\n    if algorithm == 'gmpy-miller-rabin':\n        if not gmpy:\n            raise NotImplementedError\n        return gmpy.is_prime(n, k)\n    elif algorithm == 'miller-rabin':\n        # miller rabin probability of primality is 1/4**k\n        return miller_rabin(n, k, rnd=rnd)\n    elif algorithm == 'solovay-strassen':\n        # for jacobi it's 1/2**k\n        return randomized_primality_testing(n, rnd=rnd, k=k*2)\n    else:\n        raise NotImplementedError", "response": "Test if n is a prime number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_prime(size=128, rnd=default_crypto_random, k=DEFAULT_ITERATION,\n              algorithm=None):\n    '''Generate a prime number of the giver size using the is_prime() helper\n       function.\n\n       size - size in bits of the prime, default to 128\n       rnd - a random generator to use\n       k - the number of iteration to use for the probabilistic primality\n           algorithms.\n       algorithm - the name of the primality algorithm to use, default is the\n       probabilistic Miller-Rabin algorithm.\n\n       Return value: a prime number, as a long integer\n    '''\n    while True:\n        n = rnd.getrandbits(size-2)\n        n = 2 ** (size-1) + n * 2 + 1\n        if is_prime(n, rnd=rnd, k=k, algorithm=algorithm):\n            return n\n        if algorithm == 'gmpy-miller-rabin':\n            return gmpy.next_prime(n)", "response": "Generate a prime number of the giver size using the is_prime function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef jacobi(a, b):\n    '''Calculates the value of the Jacobi symbol (a/b) where both a and b are\n    positive integers, and b is odd\n\n    :returns: -1, 0 or 1\n    '''\n\n    assert a > 0\n    assert b > 0\n\n    if a == 0:\n        return 0\n    result = 1\n    while a > 1:\n        if a & 1:\n            if ((a-1)*(b-1) >> 2) & 1:\n                result = -result\n            a, b = b % a, a\n        else:\n            if (((b * b) - 1) >> 3) & 1:\n                result = -result\n            a >>= 1\n    if a == 0:\n        return 0\n    return result", "response": "Calculates the value of the Jacobi symbol ( a / b where both a and b are positive integers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jacobi_witness(x, n):\n    '''Returns False if n is an Euler pseudo-prime with base x, and\n    True otherwise.\n    '''\n    j = jacobi(x, n) % n\n    f = pow(x, n >> 1, n)\n    return j != f", "response": "Returns False if n is an Euler pseudo - prime with base x and True otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef miller_rabin(n, k, rnd=default_pseudo_random):\n    '''\n       Pure python implementation of the Miller-Rabin algorithm.\n\n       n - the integer number to test,\n       k - the number of iteration, the probability of n being prime if the\n       algorithm returns True is 1/2**k,\n       rnd - a random generator\n   '''\n    s = 0\n    d = n-1\n    # Find nearest power of 2\n    s = primitives.integer_bit_size(n)\n    # Find greatest factor which is a power of 2\n    s = fractions.gcd(2**s, n-1)\n    d = (n-1) // s\n    s = primitives.integer_bit_size(s) - 1\n    while k:\n        k = k - 1\n        a = rnd.randint(2, n-2)\n        x = pow(a, d, n)\n        if x == 1 or x == n - 1:\n            continue\n        for r in range(1, s-1):\n            x = pow(x, 2, n)\n            if x == 1:\n                return False\n            if x == n - 1:\n                break\n        else:\n            return False\n    return True", "response": "Pure python implementation of the Miller - Rabin algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npacks the passed in long into a byte string.", "response": "def long_to_bytes(lnum, padmultiple=1):\n    \"\"\"Packs the lnum (which must be convertable to a long) into a\n       byte string 0 padded to a multiple of padmultiple bytes in size. 0\n       means no padding whatsoever, so that packing 0 result in an empty\n       string.  The resulting byte string is the big-endian two's\n       complement representation of the passed in long.\"\"\"\n\n    # source: http://stackoverflow.com/a/14527004/1231454\n\n    if lnum == 0:\n        return b'\\0' * padmultiple\n    elif lnum < 0:\n        raise ValueError(\"Can only convert non-negative numbers.\")\n    s = hex(lnum)[2:]\n    s = s.rstrip('L')\n    if len(s) & 1:\n        s = '0' + s\n    s = binascii.unhexlify(s)\n    if (padmultiple != 1) and (padmultiple != 0):\n        filled_so_far = len(s) % padmultiple\n        if filled_so_far != 0:\n            s = b'\\0' * (padmultiple - filled_so_far) + s\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding closest match to target track", "response": "def find_closest_match(target_track, tracks):\n    \"\"\"\n    Return closest match to target track\n    \"\"\"\n    track = None\n    # Get a list of (track, artist match ratio, name match ratio)\n    tracks_with_match_ratio = [(\n        track,\n        get_similarity(target_track.artist, track.artist),\n        get_similarity(target_track.name, track.name),\n    ) for track in tracks]\n    # Sort by artist then by title\n    sorted_tracks = sorted(\n        tracks_with_match_ratio,\n        key=lambda t: (t[1], t[2]),\n        reverse=True  # Descending, highest match ratio first\n    )\n    if sorted_tracks:\n        track = sorted_tracks[0][0]  # Closest match to query\n    return track"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mgf1(mgf_seed, mask_len, hash_class=hashlib.sha1):\n    '''\n       Mask Generation Function v1 from the PKCS#1 v2.0 standard.\n\n       mgs_seed - the seed, a byte string\n       mask_len - the length of the mask to generate\n       hash_class - the digest algorithm to use, default is SHA1\n\n       Return value: a pseudo-random mask, as a byte string\n       '''\n    h_len = hash_class().digest_size\n    if mask_len > 0x10000:\n        raise ValueError('mask too long')\n    T = b''\n    for i in range(0, integer_ceil(mask_len, h_len)):\n        C = i2osp(i, 4)\n        T = T + hash_class(mgf_seed + C).digest()\n    return T[:mask_len]", "response": "Generate a pseudo - random mask from the PKCS#1 v2. 0 standard."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the ceil integer of a div b.", "response": "def integer_ceil(a, b):\n    '''Return the ceil integer of a div b.'''\n    quanta, mod = divmod(a, b)\n    if mod:\n        quanta += 1\n    return quanta"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef integer_byte_size(n):\n    '''Returns the number of bytes necessary to store the integer n.'''\n    quanta, mod = divmod(integer_bit_size(n), 8)\n    if mod or n == 0:\n        quanta += 1\n    return quanta", "response": "Returns the number of bytes necessary to store the integer n."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bezout(a, b):\n    '''Compute the bezout algorithm of a and b, i.e. it returns u, v, p such as:\n\n          p = GCD(a,b)\n          a * u + b * v = p\n\n       Copied from http://www.labri.fr/perso/betrema/deug/poly/euclide.html.\n    '''\n    u = 1\n    v = 0\n    s = 0\n    t = 1\n    while b > 0:\n        q = a // b\n        r = a % b\n        a = b\n        b = r\n        tmp = s\n        s = u - q * s\n        u = tmp\n        tmp = t\n        t = v - q * t\n        v = tmp\n    return u, v, a", "response": "Compute the bezout algorithm of a and b."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef i2osp(x, x_len):\n    '''Converts the integer x to its big-endian representation of length\n       x_len.\n    '''\n    if x > 256**x_len:\n        raise exceptions.IntegerTooLarge\n    h = hex(x)[2:]\n    if h[-1] == 'L':\n        h = h[:-1]\n    if len(h) & 1 == 1:\n        h = '0%s' % h\n    x = binascii.unhexlify(h)\n    return b'\\x00' * int(x_len-len(x)) + x", "response": "Converts the integer x to its big - endian representation of length\n       x_len."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef string_xor(a, b):\n    '''Computes the XOR operator between two byte strings. If the strings are\n       of different lengths, the result string is as long as the shorter.\n    '''\n    if sys.version_info[0] < 3:\n        return ''.join((chr(ord(x) ^ ord(y)) for (x, y) in zip(a, b)))\n    else:\n        return bytes(x ^ y for (x, y) in zip(a, b))", "response": "Computes the XOR operator between two byte strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naccumulates random bit string and remove \\ 0 bytes until the needed length is obtained.", "response": "def get_nonzero_random_bytes(length, rnd=default_crypto_random):\n    '''\n       Accumulate random bit string and remove \\0 bytes until the needed length\n       is obtained.\n    '''\n    result = []\n    i = 0\n    while i < length:\n        rnd = rnd.getrandbits(12*length)\n        s = i2osp(rnd, 3*length)\n        s = s.replace('\\x00', '')\n        result.append(s)\n        i += len(s)\n    return (''.join(result))[:length]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompares two strings using constant time.", "response": "def constant_time_cmp(a, b):\n    '''Compare two strings using constant time.'''\n    result = True\n    for x, y in zip(a, b):\n        result &= (x == y)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encrypt(public_key, message, label=b'', hash_class=hashlib.sha1,\n            mgf=mgf.mgf1, seed=None, rnd=default_crypto_random):\n    '''Encrypt a byte message using a RSA public key and the OAEP wrapping\n       algorithm,\n\n       Parameters:\n       public_key - an RSA public key\n       message - a byte string\n       label - a label a per-se PKCS#1 standard\n       hash_class - a Python class for a message digest algorithme respecting\n         the hashlib interface\n       mgf1 - a mask generation function\n       seed - a seed to use instead of generating it using a random generator\n       rnd - a random generator class, respecting the random generator\n       interface from the random module, if seed is None, it is used to\n       generate it.\n\n       Return value:\n       the encrypted string of the same length as the public key\n    '''\n\n    hash = hash_class()\n    h_len = hash.digest_size\n    k = public_key.byte_size\n    max_message_length = k - 2 * h_len - 2\n    if len(message) > max_message_length:\n        raise exceptions.MessageTooLong\n    hash.update(label)\n    label_hash = hash.digest()\n    ps = b'\\0' * int(max_message_length - len(message))\n    db = b''.join((label_hash, ps, b'\\x01', message))\n    if not seed:\n        seed = primitives.i2osp(rnd.getrandbits(h_len*8), h_len)\n    db_mask = mgf(seed, k - h_len - 1, hash_class=hash_class)\n    masked_db = primitives.string_xor(db, db_mask)\n    seed_mask = mgf(masked_db, h_len, hash_class=hash_class)\n    masked_seed = primitives.string_xor(seed, seed_mask)\n    em = b''.join((b'\\x00', masked_seed, masked_db))\n    m = primitives.os2ip(em)\n    c = public_key.rsaep(m)\n    output = primitives.i2osp(c, k)\n    return output", "response": "Encrypt a byte message using a RSA public key and the OAEP wrapping algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt(private_key, message, label=b'', hash_class=hashlib.sha1,\n            mgf=mgf.mgf1):\n    '''Decrypt a byte message using a RSA private key and the OAEP wrapping\n       algorithm\n\n       Parameters:\n       public_key - an RSA public key\n       message - a byte string\n       label - a label a per-se PKCS#1 standard\n       hash_class - a Python class for a message digest algorithme respecting\n         the hashlib interface\n       mgf1 - a mask generation function\n\n       Return value:\n       the string before encryption (decrypted)\n    '''\n    hash = hash_class()\n    h_len = hash.digest_size\n    k = private_key.byte_size\n    # 1. check length\n    if len(message) != k or k < 2 * h_len + 2:\n        raise ValueError('decryption error')\n    # 2. RSA decryption\n    c = primitives.os2ip(message)\n    m = private_key.rsadp(c)\n    em = primitives.i2osp(m, k)\n    # 4. EME-OAEP decoding\n    hash.update(label)\n    label_hash = hash.digest()\n    y, masked_seed, masked_db = em[0], em[1:h_len+1], em[1+h_len:]\n    if y != b'\\x00' and y != 0:\n        raise ValueError('decryption error')\n    seed_mask = mgf(masked_db, h_len)\n    seed = primitives.string_xor(masked_seed, seed_mask)\n    db_mask = mgf(seed, k - h_len - 1)\n    db = primitives.string_xor(masked_db, db_mask)\n    label_hash_prime, rest = db[:h_len], db[h_len:]\n    i = rest.find(b'\\x01')\n    if i == -1:\n        raise exceptions.DecryptionError\n    if rest[:i].strip(b'\\x00') != b'':\n        print(rest[:i].strip(b'\\x00'))\n        raise exceptions.DecryptionError\n    m = rest[i+1:]\n    if label_hash_prime != label_hash:\n        raise exceptions.DecryptionError\n    return m", "response": "Decrypt a byte message using a RSA private key and the OAEP wrapping the algorithm specified by the RSA private key and the OAEP wrapping the algorithm specified by the parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_key_pair(size=512, number=2, rnd=default_crypto_random,\n                      k=DEFAULT_ITERATION, primality_algorithm=None,\n                      strict_size=True, e=0x10001):\n    '''Generates an RSA key pair.\n\n       size:\n           the bit size of the modulus, default to 512.\n       number:\n           the number of primes to use, default to 2.\n       rnd:\n           the random number generator to use, default to SystemRandom from the\n           random library.\n       k:\n           the number of iteration to use for the probabilistic primality\n           tests.\n       primality_algorithm:\n           the primality algorithm to use.\n       strict_size:\n           whether to use size as a lower bound or a strict goal.\n       e:\n           the public key exponent.\n\n       Returns the pair (public_key, private_key).\n    '''\n    primes = []\n    lbda = 1\n    bits = size // number + 1\n    n = 1\n    while len(primes) < number:\n        if number - len(primes) == 1:\n            bits = size - primitives.integer_bit_size(n) + 1\n        prime = get_prime(bits, rnd, k, algorithm=primality_algorithm)\n        if prime in primes:\n            continue\n        if e is not None and fractions.gcd(e, lbda) != 1:\n            continue\n        if (strict_size and number - len(primes) == 1 and\n                primitives.integer_bit_size(n*prime) != size):\n            continue\n        primes.append(prime)\n        n *= prime\n        lbda *= prime - 1\n    if e is None:\n        e = 0x10001\n        while e < lbda:\n            if fractions.gcd(e, lbda) == 1:\n                break\n            e += 2\n    assert 3 <= e <= n-1\n    public = RsaPublicKey(n, e)\n    private = MultiPrimeRsaPrivateKey(primes, e, blind=True, rnd=rnd)\n    return public, private", "response": "Generates an RSA key pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes the zsh completion of the current language", "response": "def do_zsh_complete(cli, prog_name):\n    \"\"\"Do the zsh completion\n\n    Parameters\n    ----------\n    cli : click.Command\n        The main click Command of the program\n    prog_name : str\n        The program name on the command line\n\n    Returns\n    -------\n    bool\n        True if the completion was successful, False otherwise\n    \"\"\"\n    commandline = os.environ['COMMANDLINE']\n    args = split_args(commandline)[1:]\n    if args and not commandline.endswith(' '):\n        incomplete = args[-1]\n        args = args[:-1]\n    else:\n        incomplete = ''\n\n    def escape(s):\n        return s.replace('\"', '\"\"').replace(\"'\", \"''\").replace('$', '\\\\$').replace('`', '\\\\`')\n    res = []\n    for item, help in get_choices(cli, prog_name, args, incomplete):\n        if help:\n            res.append(r'\"%s\"\\:\"%s\"' % (escape(item), escape(help)))\n        else:\n            res.append('\"%s\"' % escape(item))\n    if res:\n        echo(\"_arguments '*: :((%s))'\" % '\\n'.join(res))\n    else:\n        echo(\"_files\")\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a link to the sitemap", "response": "def add_html_link(app, pagename, templatename, context, doctree):\n    \"\"\"As each page is built, collect page names for the sitemap\"\"\"\n    base_url = app.config['html_theme_options'].get('base_url', '')\n    if base_url:\n        app.sitemap_links.append(base_url + pagename + \".html\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_sitemap(app, exception):\n    if (not app.config['html_theme_options'].get('base_url', '') or\n           exception is not None or\n           not app.sitemap_links):\n        return\n\n    filename = app.outdir + \"/sitemap.xml\"\n    print(\"Generating sitemap.xml in %s\" % filename)\n\n    root = ET.Element(\"urlset\")\n    root.set(\"xmlns\", \"http://www.sitemaps.org/schemas/sitemap/0.9\")\n\n    for link in app.sitemap_links:\n        url = ET.SubElement(root, \"url\")\n        ET.SubElement(url, \"loc\").text = link\n\n    ET.ElementTree(root).write(filename)", "response": "Generates the sitemap. xml from the collected HTML page links"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef objectlanguage(parser, token):\n    bits = token.split_contents()\n    if len(bits) == 2:\n        object_var = parser.compile_filter(bits[1])\n        language_var = None\n    elif len(bits) == 3:\n        object_var = parser.compile_filter(bits[1])\n        language_var = parser.compile_filter(bits[2])\n    else:\n        raise TemplateSyntaxError(\"'%s' takes one argument (object) and has one optional argument (language)\" % bits[0])\n\n    nodelist = parser.parse(('endobjectlanguage',))\n    parser.delete_first_token()\n    return ObjectLanguageNode(nodelist, object_var, language_var)", "response": "Switches the language of an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_translated_url(context, lang_code, object=None):\n    view = context.get('view', None)\n    request = context['request']\n\n    if object is not None:\n        # Cannot reliable determine whether the current page is being translated,\n        # or the template code provides a custom object to translate.\n        # Hence, not passing the querystring of the current page\n        qs = ''\n    else:\n        # Try a few common object variables, the SingleObjectMixin object,\n        # The Django CMS \"current_page\" variable, or the \"page\" from django-fluent-pages and Mezzanine.\n        # This makes this tag work with most CMSes out of the box.\n        object = context.get('object', None) \\\n              or context.get('current_page', None) \\\n              or context.get('page', None)\n\n        # Assuming current page, preserve query string filters.\n        qs = request.META.get('QUERY_STRING', '')\n\n    try:\n        if view is not None:\n            # Allow a view to specify what the URL should be.\n            # This handles situations where the slug might be translated,\n            # and gives you complete control over the results of this template tag.\n            get_view_url = getattr(view, 'get_view_url', None)\n            if get_view_url:\n                with smart_override(lang_code):\n                    return _url_qs(view.get_view_url(), qs)\n\n            # Now, the \"best effort\" part starts.\n            # See if it's a DetailView that exposes the object.\n            if object is None:\n                object = getattr(view, 'object', None)\n\n        if object is not None and hasattr(object, 'get_absolute_url'):\n            # There is an object, get the URL in the different language.\n            # NOTE: this *assumes* that there is a detail view, not some edit view.\n            # In such case, a language menu would redirect a user from the edit page\n            # to a detail page; which is still way better a 404 or homepage.\n            if isinstance(object, TranslatableModel):\n                # Need to handle object URL translations.\n                # Just using smart_override() should be enough, as a translated object\n                # should use `switch_language(self)` internally before returning an URL.\n                # However, it doesn't hurt to help a bit here.\n                with switch_language(object, lang_code):\n                    return _url_qs(object.get_absolute_url(), qs)\n            else:\n                # Always switch the language before resolving, so i18n_patterns() are supported.\n                with smart_override(lang_code):\n                    return _url_qs(object.get_absolute_url(), qs)\n    except TranslationDoesNotExist:\n        # Typically projects have a fallback language, so even unknown languages will return something.\n        # This either means fallbacks are disabled, or the fallback language is not found!\n        return ''\n\n    # Just reverse the current URL again in a new language, and see where we end up.\n    # This doesn't handle translated slugs, but will resolve to the proper view name.\n    resolver_match = request.resolver_match\n    if resolver_match is None:\n        # Can't resolve the page itself, the page is apparently a 404.\n        # This can also happen for the homepage in an i18n_patterns situation.\n        return ''\n\n    with smart_override(lang_code):\n        clean_kwargs = _cleanup_urlpattern_kwargs(resolver_match.kwargs)\n        return _url_qs(reverse(resolver_match.view_name, args=resolver_match.args, kwargs=clean_kwargs, current_app=resolver_match.app_name), qs)", "response": "Get the URL for the translated page in a different language."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the language parameter from the current request.", "response": "def get_language_parameter(request, query_language_key='language', object=None, default=None):\n    \"\"\"\n    Get the language parameter from the current request.\n    \"\"\"\n    # This is the same logic as the django-admin uses.\n    # The only difference is the origin of the request parameter.\n    if not is_multilingual_project():\n        # By default, the objects are stored in a single static language.\n        # This makes the transition to multilingual easier as well.\n        # The default language can operate as fallback language too.\n        return default or appsettings.PARLER_LANGUAGES.get_default_language()\n    else:\n        # In multilingual mode, take the provided language of the request.\n        code = request.GET.get(query_language_key)\n\n        if not code:\n            # forms: show first tab by default\n            code = default or appsettings.PARLER_LANGUAGES.get_first_language()\n\n        return normalize_language_code(code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining the language tabs to show.", "response": "def get_language_tabs(request, current_language, available_languages, css_class=None):\n    \"\"\"\n    Determine the language tabs to show.\n    \"\"\"\n    tabs = TabsList(css_class=css_class)\n    get = request.GET.copy()  # QueryDict object\n    tab_languages = []\n\n    site_id = getattr(settings, 'SITE_ID', None)\n    for lang_dict in appsettings.PARLER_LANGUAGES.get(site_id, ()):\n        code = lang_dict['code']\n        title = get_language_title(code)\n        get['language'] = code\n        url = '?{0}'.format(get.urlencode())\n\n        if code == current_language:\n            status = 'current'\n        elif code in available_languages:\n            status = 'available'\n        else:\n            status = 'empty'\n\n        tabs.append((url, title, code, status))\n        tab_languages.append(code)\n\n    # Additional stale translations in the database?\n    if appsettings.PARLER_SHOW_EXCLUDED_LANGUAGE_TABS:\n        for code in available_languages:\n            if code not in tab_languages:\n                get['language'] = code\n                url = '?{0}'.format(get.urlencode())\n\n                if code == current_language:\n                    status = 'current'\n                else:\n                    status = 'available'\n\n                tabs.append((url, get_language_title(code), code, status))\n\n    tabs.current_is_translated = current_language in available_languages\n    tabs.allow_deletion = len(available_languages) > 1\n    return tabs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the cache keys associated with an object.", "response": "def get_object_cache_keys(instance):\n    \"\"\"\n    Return the cache keys associated with an object.\n    \"\"\"\n    if instance.pk is None or instance._state.adding:\n        return []\n\n    keys = []\n    tr_models = instance._parler_meta.get_all_models()\n\n    # TODO: performs a query to fetch the language codes. Store that in memcached too.\n    for language in instance.get_available_languages():\n        for tr_model in tr_models:\n            keys.append(get_translation_cache_key(tr_model, instance.pk, language))\n\n    return keys"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the cache key for a translation.", "response": "def get_translation_cache_key(translated_model, master_id, language_code):\n    \"\"\"\n    The low-level function to get the cache key for a translation.\n    \"\"\"\n    # Always cache the entire object, as this already produces\n    # a lot of queries. Don't go for caching individual fields.\n    return 'parler.{0}.{1}.{2}.{3}'.format(translated_model._meta.app_label, translated_model.__name__, master_id, language_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a cached translation.", "response": "def get_cached_translation(instance, language_code=None, related_name=None, use_fallback=False):\n    \"\"\"\n    Fetch an cached translation.\n\n    .. versionadded 1.2 Added the ``related_name`` parameter.\n    \"\"\"\n    if language_code is None:\n        language_code = instance.get_current_language()\n\n    translated_model = instance._parler_meta.get_model_by_related_name(related_name)\n    values = _get_cached_values(instance, translated_model, language_code, use_fallback)\n    if not values:\n        return None\n\n    try:\n        translation = translated_model(**values)\n    except TypeError:\n        # Some model field was removed, cache entry is no longer working.\n        return None\n\n    translation._state.adding = False\n    return translation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cached_translated_field(instance, field_name, language_code=None, use_fallback=False):\n    if language_code is None:\n        language_code = instance.get_current_language()\n\n    # In django-parler 1.1 the order of the arguments was fixed, It used to be language_code, field_name\n    # This serves as detection against backwards incompatibility issues.\n    if len(field_name) <= 5 and len(language_code) > 5:\n        raise RuntimeError(\"Unexpected language code, did you swap field_name, language_code?\")\n\n    translated_model = instance._parler_meta.get_model_by_field(field_name)\n    values = _get_cached_values(instance, translated_model, language_code, use_fallback)\n    if not values:\n        return None\n\n    # Allow older cached versions where the field didn't exist yet.\n    return values.get(field_name, None)", "response": "Fetch a translated field from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_cached_values(instance, translated_model, language_code, use_fallback=False):\n    if not appsettings.PARLER_ENABLE_CACHING or not instance.pk or instance._state.adding:\n        return None\n\n    key = get_translation_cache_key(translated_model, instance.pk, language_code)\n    values = cache.get(key)\n    if not values:\n        return None\n\n    # Check for a stored fallback marker\n    if values.get('__FALLBACK__', False):\n        # Internal trick, already set the fallback marker, so no query will be performed.\n        instance._translations_cache[translated_model][language_code] = MISSING\n\n        # Allow to return the fallback language instead.\n        if use_fallback:\n            lang_dict = get_language_settings(language_code)\n            # iterate over list of fallback languages, which should be already\n            # in proper order\n            for fallback_lang in lang_dict['fallbacks']:\n                if fallback_lang != language_code:\n                    return _get_cached_values(\n                        instance, translated_model, fallback_lang,\n                        use_fallback=False\n                    )\n        return None\n\n    values['master'] = instance\n    values['language_code'] = language_code\n    return values", "response": "Get the values from the cache for a single language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cache_translation(translation, timeout=cache.default_timeout):\n    if not appsettings.PARLER_ENABLE_CACHING:\n        return\n\n    if translation.master_id is None:\n        raise ValueError(\"Can't cache unsaved translation\")\n\n    # Cache a translation object.\n    # For internal usage, object parameters are not suited for outside usage.\n    fields = translation.get_translated_fields()\n    values = {'id': translation.id}\n    for name in fields:\n        values[name] = getattr(translation, name)\n\n    key = get_translation_cache_key(translation.__class__, translation.master_id, translation.language_code)\n    cache.set(key, values, timeout=timeout)", "response": "Cache a translation object in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cache_translation_needs_fallback(instance, language_code, related_name, timeout=cache.default_timeout):\n    if not appsettings.PARLER_ENABLE_CACHING or not instance.pk or instance._state.adding:\n        return\n\n    tr_model = instance._parler_meta.get_model_by_related_name(related_name)\n    key = get_translation_cache_key(tr_model, instance.pk, language_code)\n    cache.set(key, {'__FALLBACK__': True}, timeout=timeout)", "response": "Store the fact that a translation doesn t exist and the fallback should be used."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a list of template names find the first one that exists.", "response": "def select_template_name(template_name_list, using=None):\n    \"\"\"\n    Given a list of template names, find the first one that exists.\n    \"\"\"\n    if not isinstance(template_name_list, tuple):\n        template_name_list = tuple(template_name_list)\n\n    try:\n        return _cached_name_lookups[template_name_list]\n    except KeyError:\n        # Find which template of the template_names is selected by the Django loader.\n        for template_name in template_name_list:\n            try:\n                get_template(template_name, using=using)\n            except TemplateDoesNotExist:\n                continue\n            else:\n                template_name = six.text_type(template_name)  # consistent value for lazy() function.\n                _cached_name_lookups[template_name_list] = template_name\n                return template_name\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the object using a translated slug.", "response": "def get_object(self, queryset=None):\n        \"\"\"\n        Fetch the object using a translated slug.\n        \"\"\"\n        if queryset is None:\n            queryset = self.get_queryset()\n\n        slug = self.kwargs[self.slug_url_kwarg]\n        choices = self.get_language_choices()\n\n        obj = None\n        using_fallback = False\n        prev_choices = []\n        for lang_choice in choices:\n            try:\n                # Get the single item from the filtered queryset\n                # NOTE. Explicitly set language to the state the object was fetched in.\n                filters = self.get_translated_filters(slug=slug)\n                obj = queryset.translated(lang_choice, **filters).language(lang_choice).get()\n            except ObjectDoesNotExist:\n                # Translated object not found, next object is marked as fallback.\n                using_fallback = True\n                prev_choices.append(lang_choice)\n            else:\n                break\n\n        if obj is None:\n            tried_msg = \", tried languages: {0}\".format(\", \".join(choices))\n            error_message = translation.ugettext(\"No %(verbose_name)s found matching the query\") % {'verbose_name': queryset.model._meta.verbose_name}\n            raise Http404(error_message + tried_msg)\n\n        # Object found!\n        if using_fallback:\n            # It could happen that objects are resolved using their fallback language,\n            # but the actual translation also exists. Either that means this URL should\n            # raise a 404, or a redirect could be made as service to the users.\n            # It's possible that the old URL was active before in the language domain/subpath\n            # when there was no translation yet.\n            for prev_choice in prev_choices:\n                if obj.has_translation(prev_choice):\n                    # Only dispatch() and render_to_response() can return a valid response,\n                    # By breaking out here, this functionality can't be broken by users overriding render_to_response()\n                    raise FallbackLanguageResolved(obj, prev_choice)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_object(self, queryset=None):\n        object = super(LanguageChoiceMixin, self).get_object(queryset)\n        if isinstance(object, TranslatableModelMixin):\n            object.set_current_language(self.get_language(), initialize=True)\n        return object", "response": "Assign the language for the retrieved object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the language parameter from the current request.", "response": "def get_language(self):\n        \"\"\"\n        Get the language parameter from the current request.\n        \"\"\"\n        return get_language_parameter(self.request, self.query_language_key, default=self.get_default_language(object=object))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_language_tabs(self):\n        current_language = self.get_current_language()\n        if self.object:\n            available_languages = list(self.object.get_available_languages())\n        else:\n            available_languages = []\n\n        return get_language_tabs(self.request, current_language, available_languages)", "response": "Determine the language tabs to show."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a TranslatableModelForm by default if no form_class is set.", "response": "def get_form_class(self):\n        \"\"\"\n        Return a ``TranslatableModelForm`` by default if no form_class is set.\n        \"\"\"\n        super_method = super(TranslatableModelFormMixin, self).get_form_class\n        # no \"__func__\" on the class level function in python 3\n        default_method = getattr(ModelFormMixin.get_form_class, '__func__', ModelFormMixin.get_form_class)\n        if not (super_method.__func__ is default_method):\n            # Don't get in your way, if you've overwritten stuff.\n            return super_method()\n        else:\n            # Same logic as ModelFormMixin.get_form_class, but using the right form base class.\n            if self.form_class:\n                return self.form_class\n            else:\n                model = _get_view_model(self)\n                if self.fields:\n                    fields = self.fields\n                    return modelform_factory(model, form=TranslatableModelForm, fields=fields)\n                else:\n                    return modelform_factory(model, form=TranslatableModelForm)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_form_kwargs(self):\n        kwargs = super(TranslatableModelFormMixin, self).get_form_kwargs()\n        # The TranslatableAdmin can set form.language_code, because the modeladmin always creates a fresh subclass.\n        # If that would be done here, the original globally defined form class would be updated.\n        kwargs['_current_language'] = self.get_form_language()\n        return kwargs", "response": "Pass the current language to the form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_default_language_settings(languages_list, var_name='PARLER_LANGUAGES', **extra_defaults):\n    languages_list = LanguagesSetting(languages_list)\n\n    languages_list.setdefault('default', {})\n    defaults = languages_list['default']\n    defaults.setdefault('hide_untranslated', False)   # Whether queries with .active_translations() may or may not return the fallback language.\n\n    if 'fallback' in defaults:\n        #warnings.warn(\"Please use 'fallbacks' instead of 'fallback' in the 'defaults' section of {0}\".format(var_name), DeprecationWarning)\n        defaults['fallbacks'] = [defaults.pop('fallback')]\n    if 'fallback' in extra_defaults:\n        #warnings.warn(\"Please use 'fallbacks' instead of 'fallback' in parameters for {0} = add_default_language_settings(..)\".format(var_name), DeprecationWarning)\n        extra_defaults['fallbacks'] = [extra_defaults.pop('fallback')]\n\n    defaults.update(extra_defaults)  # Also allow to override code and fallback this way.\n\n    # This function previously existed in appsettings, where it could reference the defaults directly.\n    # However, this module is a more logical place for this function. To avoid circular import problems,\n    # the 'code' and 'fallback' parameters are always passed by the appsettings module.\n    # In case these are missing, default to the original behavior for backwards compatibility.\n    if 'code' not in defaults:\n        from parler import appsettings\n        defaults['code'] = appsettings.PARLER_DEFAULT_LANGUAGE_CODE\n    if 'fallbacks' not in defaults:\n        from parler import appsettings\n        defaults['fallbacks'] = [appsettings.PARLER_DEFAULT_LANGUAGE_CODE]\n\n    if not is_supported_django_language(defaults['code']):\n        raise ImproperlyConfigured(\"The value for {0}['defaults']['code'] ('{1}') does not exist in LANGUAGES\".format(var_name, defaults['code']))\n\n    for site_id, lang_choices in six.iteritems(languages_list):\n        if site_id == 'default':\n            continue\n\n        if not isinstance(lang_choices, (list, tuple)):\n            raise ImproperlyConfigured(\"{0}[{1}] should be a tuple of language choices!\".format(var_name, site_id))\n        for i, choice in enumerate(lang_choices):\n            if not is_supported_django_language(choice['code']):\n                raise ImproperlyConfigured(\"{0}[{1}][{2}]['code'] does not exist in LANGUAGES\".format(var_name, site_id, i))\n\n            # Copy all items from the defaults, so you can provide new fields too.\n            for key, value in six.iteritems(defaults):\n                choice.setdefault(key, value)\n\n    return languages_list", "response": "Adds extra defaults to the language settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_parler_languages_from_django_cms(cms_languages=None):\n    valid_keys = ['code', 'fallbacks', 'hide_untranslated',\n                  'redirect_on_fallback']\n    if cms_languages:\n        if sys.version_info < (3, 0, 0):\n            int_types = (int, long)\n        else:\n            int_types = int\n\n        parler_languages = copy.deepcopy(cms_languages)\n        for site_id, site_config in cms_languages.items():\n            if site_id and (\n                    not isinstance(site_id, int_types) and\n                    site_id != 'default'\n            ):\n                del parler_languages[site_id]\n                continue\n\n            if site_id == 'default':\n                for key, value in site_config.items():\n                    if key not in valid_keys:\n                        del parler_languages['default'][key]\n            else:\n                for i, lang_config in enumerate(site_config):\n                    for key, value in lang_config.items():\n                        if key not in valid_keys:\n                            del parler_languages[site_id][i][key]\n        return parler_languages\n    return None", "response": "Converts django CMS settings CMS_LANGUAGES into PARLER_LANGUAGES."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the language settings for the current site.", "response": "def get_language(self, language_code, site_id=None):\n        \"\"\"\n        Return the language settings for the current site\n\n        This function can be used with other settings variables\n        to support modules which create their own variation of the ``PARLER_LANGUAGES`` setting.\n        For an example, see :func:`~parler.appsettings.add_default_language_settings`.\n        \"\"\"\n        if language_code is None:\n            raise ValueError(get_null_language_error())\n\n        if site_id is None:\n            site_id = getattr(settings, 'SITE_ID', None)\n\n        for lang_dict in self.get(site_id, ()):\n            if lang_dict['code'] == language_code:\n                return lang_dict\n\n        # no language match, search for variant: fr-ca falls back to fr\n        for lang_dict in self.get(site_id, ()):\n            if lang_dict['code'].split('-')[0] == language_code.split('-')[0]:\n                return lang_dict\n\n        return self['default']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of active choices.", "response": "def get_active_choices(self, language_code=None, site_id=None):\n        \"\"\"\n        Find out which translations should be visible in the site.\n        It returns a list with either a single choice (the current language),\n        or a list with the current language + fallback language.\n        \"\"\"\n        if language_code is None:\n            language_code = get_language()\n\n        lang_dict = self.get_language(language_code, site_id=site_id)\n        if not lang_dict['hide_untranslated']:\n            return [language_code] + [lang for lang in lang_dict['fallbacks'] if lang != language_code]\n        else:\n            return [language_code]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fallback_languages(self, language_code=None, site_id=None):\n        choices = self.get_active_choices(language_code, site_id=site_id)\n        return choices[1:]", "response": "Get the fallback languages for a given language code."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the fallback language for a given language choice.", "response": "def get_fallback_language(self, language_code=None, site_id=None):\n        \"\"\"\n        Find out what the fallback language is for a given language choice.\n\n        .. deprecated:: 1.5\n           Use :func:`get_fallback_languages` instead.\n        \"\"\"\n        choices = self.get_active_choices(language_code, site_id=site_id)\n        if choices and len(choices) > 1:\n            # Still take the last, like previous code.\n            # With multiple fallback languages that means taking the base language.\n            # Hence, upgrade the code to use get_fallback_languages() instead.\n            return choices[-1]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the first language for the current site.", "response": "def get_first_language(self, site_id=None):\n        \"\"\"\n        Return the first language for the current site.\n        This can be used for user interfaces, where the languages are displayed in tabs.\n        \"\"\"\n        if site_id is None:\n            site_id = getattr(settings, 'SITE_ID', None)\n\n        try:\n            return self[site_id][0]['code']\n        except (KeyError, IndexError):\n            # No configuration, always fallback to default language.\n            # This is essentially a non-multilingual configuration.\n            return self['default']['code']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave all translated fields.", "response": "def save_translated_fields(self):\n        \"\"\"\n        Save all translated fields.\n        \"\"\"\n        fields = {}\n\n        # Collect all translated fields {'name': 'value'}\n        for field in self._translated_fields:\n            try:\n                value = self.cleaned_data[field]\n            except KeyError:  # Field has a ValidationError\n                continue\n            fields[field] = value\n\n        # Set the field values on their relevant models\n        translations = self.instance._set_translated_fields(**fields)\n\n        # Perform full clean on models\n        non_translated_fields = set(('id', 'master_id', 'language_code'))\n        for translation in translations:\n            self._post_clean_translation(translation)\n\n            # Assign translated fields to the model (using the TranslatedAttribute descriptor)\n            for field in translation._get_field_names():\n                if field in non_translated_fields:\n                    continue\n                setattr(self.instance, field, getattr(translation, field))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_translations_model(shared_model, related_name, meta, **fields):\n    if not meta:\n        meta = {}\n\n    if shared_model._meta.abstract:\n        # This can't be done, because `master = ForeignKey(shared_model)` would fail.\n        raise TypeError(\"Can't create TranslatedFieldsModel for abstract class {0}\".format(shared_model.__name__))\n\n    # Define inner Meta class\n    meta['app_label'] = shared_model._meta.app_label\n    meta['db_tablespace'] = shared_model._meta.db_tablespace\n    meta['managed'] = shared_model._meta.managed\n    meta['unique_together'] = list(meta.get('unique_together', [])) + [('language_code', 'master')]\n    meta.setdefault('db_table', '{0}_translation'.format(shared_model._meta.db_table))\n    meta.setdefault('verbose_name', _lazy_verbose_name(shared_model))\n\n    # Avoid creating permissions for the translated model, these are not used at all.\n    # This also avoids creating lengthy permission names above 50 chars.\n    meta.setdefault('default_permissions', ())\n\n    # Define attributes for translation table\n    name = str('{0}Translation'.format(shared_model.__name__))  # makes it bytes, for type()\n\n    attrs = {}\n    attrs.update(fields)\n    attrs['Meta'] = type(str('Meta'), (object,), meta)\n    attrs['__module__'] = shared_model.__module__\n    attrs['objects'] = models.Manager()\n    attrs['master'] = TranslationsForeignKey(shared_model, related_name=related_name, editable=False, null=True,\n                                             on_delete=models.CASCADE)\n\n    # Create and return the new model\n    translations_model = TranslatedFieldsModelBase(name, (TranslatedFieldsModel,), attrs)\n\n    # Register it as a global in the shared model's module.\n    # This is needed so that Translation model instances, and objects which refer to them, can be properly pickled and unpickled.\n    # The Django session and caching frameworks, in particular, depend on this behaviour.\n    mod = sys.modules[shared_model.__module__]\n    setattr(mod, name, translations_model)\n\n    return translations_model", "response": "Dynamically create the translations model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_translated_fields(self, language_code=None, **fields):\n        objects = []  # no generator, make sure objects are all filled first\n        for parler_meta, model_fields in self._parler_meta._split_fields(**fields):\n            translation = self._get_translated_model(language_code=language_code, auto_create=True, meta=parler_meta)\n            for field, value in six.iteritems(model_fields):\n                setattr(translation, field, value)\n\n            objects.append(translation)\n        return objects", "response": "Assign fields to the translated models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_translation(self, language_code, **fields):\n        if language_code is None:\n            raise ValueError(get_null_language_error())\n\n        meta = self._parler_meta\n        if self._translations_cache[meta.root_model].get(language_code, None):  # MISSING evaluates to False too\n            raise ValueError(\"Translation already exists: {0}\".format(language_code))\n\n        # Save all fields in the proper translated model.\n        for translation in self._set_translated_fields(language_code, **fields):\n            self.save_translation(translation)", "response": "Add a translation to the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a translation from a model.", "response": "def delete_translation(self, language_code, related_name=None):\n        \"\"\"\n        Delete a translation from a model.\n\n        :param language_code: The language to remove.\n        :param related_name: If given, only the model matching that related_name is removed.\n        \"\"\"\n        if language_code is None:\n            raise ValueError(get_null_language_error())\n\n        if related_name is None:\n            metas = self._parler_meta\n        else:\n            metas = [self._parler_meta[related_name]]\n\n        num_deleted = 0\n        for meta in metas:\n            try:\n                translation = self._get_translated_model(language_code, meta=meta)\n            except meta.model.DoesNotExist:\n                continue\n\n            # By using the regular model delete, the cache is properly cleared\n            # (via _delete_cached_translation) and signals are emitted.\n            translation.delete()\n            num_deleted += 1\n\n            # Clear other local caches\n            try:\n                del self._translations_cache[meta.model][language_code]\n            except KeyError:\n                pass\n            try:\n                del self._prefetched_objects_cache[meta.rel_name]\n            except (AttributeError, KeyError):\n                pass\n\n        if not num_deleted:\n            raise ValueError(\"Translation does not exist: {0}\".format(language_code))\n\n        return num_deleted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nswitching the currently activated language of the object.", "response": "def set_current_language(self, language_code, initialize=False):\n        \"\"\"\n        Switch the currently activate language of the object.\n        \"\"\"\n        self._current_language = normalize_language_code(language_code or get_language())\n\n        # Ensure the translation is present for __get__ queries.\n        if initialize:\n            self._get_translated_model(use_fallback=False, auto_create=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the fallback language codes which are used in case there is no translation for the currently active language.", "response": "def get_fallback_languages(self):\n        \"\"\"\n        Return the fallback language codes,\n        which are used in case there is no translation for the currently active language.\n        \"\"\"\n        lang_dict = get_language_settings(self._current_language)\n        fallbacks = [lang for lang in lang_dict['fallbacks'] if lang != self._current_language]\n        return fallbacks or []"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether a translation for the given language exists.", "response": "def has_translation(self, language_code=None, related_name=None):\n        \"\"\"\n        Return whether a translation for the given language exists.\n        Defaults to the current language code.\n\n        .. versionadded 1.2 Added the ``related_name`` parameter.\n        \"\"\"\n        if language_code is None:\n            language_code = self._current_language\n            if language_code is None:\n                raise ValueError(get_null_language_error())\n\n        meta = self._parler_meta._get_extension_by_related_name(related_name)\n\n        try:\n            # Check the local cache directly, and the answer is known.\n            # NOTE this may also return newly auto created translations which are not saved yet.\n            return not is_missing(self._translations_cache[meta.model][language_code])\n        except KeyError:\n            # If there is a prefetch, will be using that.\n            # However, don't assume the prefetch contains all possible languages.\n            # With Django 1.8, there are custom Prefetch objects.\n            # TODO: improve this, detect whether this is the case.\n            if language_code in self._read_prefetched_translations(meta=meta):\n                return True\n\n            # Try to fetch from the cache first.\n            # If the cache returns the fallback, it means the original does not exist.\n            object = get_cached_translation(self, language_code, related_name=related_name, use_fallback=True)\n            if object is not None:\n                return object.language_code == language_code\n\n            try:\n                # Fetch from DB, fill the cache.\n                self._get_translated_model(language_code, use_fallback=False, auto_create=False, meta=meta)\n            except meta.model.DoesNotExist:\n                return False\n            else:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the language codes of all available translations.", "response": "def get_available_languages(self, related_name=None, include_unsaved=False):\n        \"\"\"\n        Return the language codes of all translated variations.\n\n        .. versionadded 1.2 Added the ``include_unsaved`` and ``related_name`` parameters.\n        \"\"\"\n        meta = self._parler_meta._get_extension_by_related_name(related_name)\n\n        prefetch = self._get_prefetched_translations(meta=meta)\n        if prefetch is not None:\n            # TODO: this will break when using custom Django 1.8 Prefetch objects?\n            db_languages = sorted(obj.language_code for obj in prefetch)\n        else:\n            qs = self._get_translated_queryset(meta=meta)\n            db_languages = qs.values_list('language_code', flat=True).order_by('language_code')\n\n        if include_unsaved:\n            local_languages = (k for k, v in six.iteritems(self._translations_cache[meta.model]) if not is_missing(v))\n            return list(set(db_languages) | set(local_languages))\n        else:\n            return db_languages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the translated model for the given language code.", "response": "def get_translation(self, language_code, related_name=None):\n        \"\"\"\n        Fetch the translated model\n        \"\"\"\n        meta = self._parler_meta._get_extension_by_related_name(related_name)\n        return self._get_translated_model(language_code, meta=meta)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_translated_model(self, language_code=None, use_fallback=False, auto_create=False, meta=None):\n        if self._parler_meta is None:\n            raise ImproperlyConfigured(\"No translation is assigned to the current model!\")\n        if self._translations_cache is None:\n            raise RuntimeError(\"Accessing translated fields before super.__init__() is not possible.\")\n\n        if not language_code:\n            language_code = self._current_language\n            if language_code is None:\n                raise ValueError(get_null_language_error())\n\n        if meta is None:\n            meta = self._parler_meta.root  # work on base model by default\n\n        local_cache = self._translations_cache[meta.model]\n\n        # 1. fetch the object from the local cache\n        try:\n            object = local_cache[language_code]\n\n            # If cached object indicates the language doesn't exist, need to query the fallback.\n            if not is_missing(object):\n                return object\n        except KeyError:\n            # 2. No cache, need to query\n            # Check that this object already exists, would be pointless otherwise to check for a translation.\n            if not self._state.adding and self.pk is not None:\n                prefetch = self._get_prefetched_translations(meta=meta)\n                if prefetch is not None:\n                    # 2.1, use prefetched data\n                    # If the object is not found in the prefetched data (which contains all translations),\n                    # it's pointless to check for memcached (2.2) or perform a single query (2.3)\n                    for object in prefetch:\n                        if object.language_code == language_code:\n                            local_cache[language_code] = object\n                            _cache_translation(object)  # Store in memcached\n                            return object\n                else:\n                    # 2.2, fetch from memcached\n                    object = get_cached_translation(self, language_code, related_name=meta.rel_name, use_fallback=use_fallback)\n                    if object is not None:\n                        # Track in local cache\n                        if object.language_code != language_code:\n                            local_cache[language_code] = MISSING  # Set fallback marker\n                        local_cache[object.language_code] = object\n                        return object\n                    elif is_missing(local_cache.get(language_code, None)):\n                        # If get_cached_translation() explicitly set the \"does not exist\" marker,\n                        # there is no need to try a database query.\n                        pass\n                    else:\n                        # 2.3, fetch from database\n                        try:\n                            object = self._get_translated_queryset(meta).get(language_code=language_code)\n                        except meta.model.DoesNotExist:\n                            pass\n                        else:\n                            local_cache[language_code] = object\n                            _cache_translation(object)  # Store in memcached\n                            return object\n\n        # Not in cache, or default.\n        # Not fetched from DB\n\n        # 3. Auto create?\n        if auto_create:\n            # Auto create policy first (e.g. a __set__ call)\n            kwargs = {\n                'language_code': language_code,\n            }\n            if self.pk:\n                # ID might be None at this point, and Django does not allow that.\n                kwargs['master'] = self\n\n            object = meta.model(**kwargs)\n            local_cache[language_code] = object\n            # Not stored in memcached here yet, first fill + save it.\n            return object\n\n        # 4. Fallback?\n        fallback_msg = None\n        lang_dict = get_language_settings(language_code)\n\n        if language_code not in local_cache:\n            # Explicitly set a marker for the fact that this translation uses the fallback instead.\n            # Avoid making that query again.\n            local_cache[language_code] = MISSING  # None value is the marker.\n            if not self._state.adding or self.pk is not None:\n                _cache_translation_needs_fallback(self, language_code, related_name=meta.rel_name)\n\n        fallback_choices = [lang_dict['code']] + list(lang_dict['fallbacks'])\n        if use_fallback and fallback_choices:\n            # Jump to fallback language, return directly.\n            # Don't cache under this language_code\n            for fallback_lang in fallback_choices:\n                if fallback_lang == language_code:  # Skip the current language, could also be fallback 1 of 2 choices\n                    continue\n\n                try:\n                    return self._get_translated_model(fallback_lang, use_fallback=False, auto_create=auto_create, meta=meta)\n                except meta.model.DoesNotExist:\n                    pass\n\n            fallback_msg = \" (tried fallbacks {0})\".format(', '.join(lang_dict['fallbacks']))\n\n        # None of the above, bail out!\n        raise meta.model.DoesNotExist(\n            \"{0} does not have a translation for the current language!\\n\"\n            \"{0} ID #{1}, language={2}{3}\".format(self._meta.verbose_name, self.pk, language_code, fallback_msg or ''\n        ))", "response": "Fetch the translated fields model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_any_translated_model(self, meta=None):\n        if meta is None:\n            meta = self._parler_meta.root\n\n        tr_model = meta.model\n        local_cache = self._translations_cache[tr_model]\n        if local_cache:\n            # There is already a language available in the case. No need for queries.\n            # Give consistent answers if they exist.\n            check_languages = [self._current_language] + self.get_fallback_languages()\n            try:\n                for fallback_lang in check_languages:\n                    trans = local_cache.get(fallback_lang, None)\n                    if trans and not is_missing(trans):\n                        return trans\n                return next(t for t in six.itervalues(local_cache) if not is_missing(t))\n            except StopIteration:\n                pass\n\n        try:\n            # Use prefetch if available, otherwise perform separate query.\n            prefetch = self._get_prefetched_translations(meta=meta)\n            if prefetch is not None:\n                translation = prefetch[0]  # Already a list\n            else:\n                translation = self._get_translated_queryset(meta=meta)[0]\n        except IndexError:\n            return None\n        else:\n            local_cache[translation.language_code] = translation\n            _cache_translation(translation)\n            return translation", "response": "Return any available translation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_translated_queryset(self, meta=None):\n        # Get via self.TRANSLATIONS_FIELD.get(..) so it also uses the prefetch/select_related cache.\n        if meta is None:\n            meta = self._parler_meta.root\n\n        accessor = getattr(self, meta.rel_name)  # RelatedManager\n        return accessor.get_queryset()", "response": "Get the translated queryset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the queryset with prefetch results.", "response": "def _get_prefetched_translations(self, meta=None):\n        \"\"\"\n        Return the queryset with prefetch results.\n        \"\"\"\n        if meta is None:\n            meta = self._parler_meta.root\n\n        related_name = meta.rel_name\n        try:\n            # Read the list directly, avoid QuerySet construction.\n            # Accessing self._get_translated_queryset(parler_meta)._prefetch_done is more expensive.\n            return self._prefetched_objects_cache[related_name]\n        except (AttributeError, KeyError):\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_unique(self, exclude=None):\n        # This is called from ModelForm._post_clean() or Model.full_clean()\n        errors = {}\n        try:\n            super(TranslatableModelMixin, self).validate_unique(exclude=exclude)\n        except ValidationError as e:\n            errors = e.message_dict\n\n        for local_cache in six.itervalues(self._translations_cache):\n            for translation in six.itervalues(local_cache):\n                if is_missing(translation):  # Skip fallback markers\n                    continue\n\n                try:\n                    translation.validate_unique(exclude=exclude)\n                except ValidationError as e:\n                    errors.update(e.message_dict)\n\n        if errors:\n            raise ValidationError(errors)", "response": "Validate the unique_together of the translated model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave all translations for all available languages.", "response": "def save_translations(self, *args, **kwargs):\n        \"\"\"\n        The method to save all translations.\n        This can be overwritten to implement any custom additions.\n        This method calls :func:`save_translation` for every fetched language.\n\n        :param args: Any custom arguments to pass to :func:`save`.\n        :param kwargs: Any custom arguments to pass to :func:`save`.\n        \"\"\"\n        # Copy cache, new objects (e.g. fallbacks) might be fetched if users override save_translation()\n        # Not looping over the cache, but using _parler_meta so the translations are processed in the order of inheritance.\n        local_caches = self._translations_cache.copy()\n        for meta in self._parler_meta:\n            local_cache = local_caches[meta.model]\n            translations = list(local_cache.values())\n\n            # Save all translated objects which were fetched.\n            # This also supports switching languages several times, and save everything in the end.\n            for translation in translations:\n                if is_missing(translation):  # Skip fallback markers\n                    continue\n\n                self.save_translation(translation, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the translation when it s modified or unsaved.", "response": "def save_translation(self, translation, *args, **kwargs):\n        \"\"\"\n        Save the translation when it's modified, or unsaved.\n\n        .. note::\n\n           When a derived model provides additional translated fields,\n           this method receives both the original and extended translation.\n           To distinguish between both objects, check for ``translation.related_name``.\n\n        :param translation: The translation\n        :type translation: TranslatedFieldsModel\n        :param args: Any custom arguments to pass to :func:`save`.\n        :param kwargs: Any custom arguments to pass to :func:`save`.\n        \"\"\"\n        if self.pk is None or self._state.adding:\n            raise RuntimeError(\"Can't save translations when the master object is not yet saved.\")\n\n        # Translation models without any fields are also supported.\n        # This is useful for parent objects that have inlines;\n        # the parent object defines how many translations there are.\n        if translation.pk is None or translation.is_modified:\n            if not translation.master_id:  # Might not exist during first construction\n                translation._state.db = self._state.db\n                translation.master = self\n            translation.save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a value from a translated property and return a default value.", "response": "def safe_translation_getter(self, field, default=None, language_code=None, any_language=False):\n        \"\"\"\n        Fetch a translated property, and return a default value\n        when both the translation and fallback language are missing.\n\n        When ``any_language=True`` is used, the function also looks\n        into other languages to find a suitable value. This feature can be useful\n        for \"title\" attributes for example, to make sure there is at least something being displayed.\n        Also consider using ``field = TranslatedField(any_language=True)`` in the model itself,\n        to make this behavior the default for the given field.\n\n        .. versionchanged 1.5:: The *default* parameter may also be a callable.\n        \"\"\"\n        meta = self._parler_meta._get_extension_by_field(field)\n\n        # Extra feature: query a single field from a other translation.\n        if language_code and language_code != self._current_language:\n            try:\n                tr_model = self._get_translated_model(language_code, meta=meta, use_fallback=True)\n                return getattr(tr_model, field)\n            except TranslationDoesNotExist:\n                pass\n        else:\n            # By default, query via descriptor (TranslatedFieldDescriptor)\n            # which also attempts the fallback language if configured to do so.\n            try:\n                return getattr(self, field)\n            except TranslationDoesNotExist:\n                pass\n\n        if any_language:\n            translation = self._get_any_translated_model(meta=meta)\n            if translation is not None:\n                try:\n                    return getattr(translation, field)\n                except KeyError:\n                    pass\n\n        if callable(default):\n            return default()\n        else:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_model_by_field(self, name):\n        try:\n            return self._fields_to_model[name]\n        except KeyError:\n            raise FieldError(\"Translated field does not exist: '{0}'\".format(name))", "response": "Returns the translated field model that contains the given field name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the ParlerOptions object that corresponds with the given translated field name.", "response": "def _get_extension_by_field(self, name):\n        \"\"\"\n        Find the ParlerOptions object that corresponds with the given translated field.\n        \"\"\"\n        if name is None:\n            raise TypeError(\"Expected field name\")\n\n        # Reuse existing lookups.\n        tr_model = self.get_model_by_field(name)\n        for meta in self._extensions:\n            if meta.model == tr_model:\n                return meta"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_extension_by_related_name(self, related_name):\n        if related_name is None:\n            return self._extensions[0]\n\n        for meta in self._extensions:\n            if meta.rel_name == related_name:\n                return meta\n\n        raise ValueError(\"No translated model of '{0}' has a reverse name of '{1}'\".format(\n            self.root.shared_model.__name__, related_name\n        ))", "response": "Returns the extension with the given related name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_master(new_class):\n    if not new_class.master or not isinstance(new_class.master, ForwardManyToOneDescriptor):\n        raise ImproperlyConfigured(\"{0}.master should be a ForeignKey to the shared table.\".format(new_class.__name__))\n\n    remote_field = new_class.master.field.remote_field\n    shared_model = remote_field.model\n\n    meta = shared_model._parler_meta\n    if meta is not None:\n        if meta._has_translations_model(new_class):\n            raise ImproperlyConfigured(\"The model '{0}' already has an associated translation table!\".format(shared_model.__name__))\n        if meta._has_translations_field(remote_field.related_name):\n            raise ImproperlyConfigured(\"The model '{0}' already has an associated translation field named '{1}'!\".format(shared_model.__name__, remote_field.related_name))\n\n    return shared_model", "response": "Validate that the master field on a TranslatedFieldsModel is correctly configured."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the short description of the translated field.", "response": "def short_description(self):\n        \"\"\"\n        Ensure that the admin ``list_display`` renders the correct verbose name for translated fields.\n\n        The :func:`~django.contrib.admin.utils.label_for_field` function\n        uses :func:`~django.db.models.Options.get_field_by_name` to find the find and ``verbose_name``.\n        However, for translated fields, this option does not exist,\n        hence it falls back to reading the attribute and trying ``short_description``.\n        Ideally, translated fields should also appear in this list, to be treated like regular fields.\n        \"\"\"\n        translations_model = self.field.meta.model\n        if translations_model is None:\n            # This only happens with abstract models. The code is accessing the descriptor at the base model directly,\n            # not the upgraded descriptor version that contribute_translations() installed.\n            # Fallback to what the admin label_for_field() would have done otherwise.\n            return pretty_name(self.field.name)\n\n        field = translations_model._meta.get_field(self.field.name)\n        return field.verbose_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_form_language(self, request, obj=None):\n        if obj is not None:\n            return obj.get_current_language()\n        else:\n            return self._language(request)", "response": "Returns the current language for the currently displayed object fields."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a QuerySet that is consistent with the current language.", "response": "def get_queryset(self, request):\n        \"\"\"\n        Make sure the current language is selected.\n        \"\"\"\n        qs = super(BaseTranslatableAdmin, self).get_queryset(request)\n\n        if self._has_translatable_model():\n            if not isinstance(qs, TranslatableQuerySet):\n                raise ImproperlyConfigured(\"{0} class does not inherit from TranslatableQuerySet\".format(qs.__class__.__name__))\n\n            # Apply a consistent language to all objects.\n            qs_language = self.get_queryset_language(request)\n            if qs_language:\n                qs = qs.language(qs_language)\n\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_language_tabs(self, request, obj, available_languages, css_class=None):\n        current_language = self.get_form_language(request, obj)\n        return get_language_tabs(request, current_language, available_languages, css_class=css_class)", "response": "Returns a list of the language tabs that are available for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_languages_column(self, object):\n        all_languages = [code for code, __ in settings.LANGUAGES]\n        return mark_safe(\n            self._languages_column(\n                object, all_languages, span_classes='all-languages'\n            )\n        )", "response": "Returns a string that can be used as a column of all languages."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the available languages as queryset.", "response": "def get_available_languages(self, obj):\n        \"\"\"\n        Fetching the available languages as queryset.\n        \"\"\"\n        if obj:\n            return obj.get_available_languages()\n        else:\n            return self.model._parler_meta.root_model.objects.none()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding get_object to set the current language.", "response": "def get_object(self, request, object_id, *args, **kwargs):\n        \"\"\"\n        Make sure the object is fetched in the correct language.\n        \"\"\"\n        obj = super(TranslatableAdmin, self).get_object(request, object_id, *args, **kwargs)\n\n        if obj is not None and self._has_translatable_model():  # Allow fallback to regular models.\n            obj.set_current_language(self._language(request, obj), initialize=True)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_form(self, request, obj=None, **kwargs):\n        form_class = super(TranslatableAdmin, self).get_form(request, obj, **kwargs)\n        if self._has_translatable_model():\n            form_class.language_code = self.get_form_language(request, obj)\n\n        return form_class", "response": "Returns the form class for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_urls(self):\n        urlpatterns = super(TranslatableAdmin, self).get_urls()\n        if not self._has_translatable_model():\n            return urlpatterns\n        else:\n            opts = self.model._meta\n            info = opts.app_label, opts.model_name\n            return [url(\n                r'^(.+)/change/delete-translation/(.+)/$',\n                self.admin_site.admin_view(self.delete_translation),\n                name='{0}_{1}_delete_translation'.format(*info)\n            )] + urlpatterns", "response": "Add a delete - translation view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_change_form(self, request, context, add=False, change=False, form_url='', obj=None):\n        if self._has_translatable_model():\n            lang_code = self.get_form_language(request, obj)\n            lang = get_language_title(lang_code)\n\n            available_languages = self.get_available_languages(obj)\n            language_tabs = self.get_language_tabs(request, obj, available_languages)\n            context['language_tabs'] = language_tabs\n            if language_tabs:\n                context['title'] = '%s (%s)' % (context['title'], lang)\n            if not language_tabs.current_is_translated:\n                add = True  # lets prepopulated_fields_js work.\n\n            # Patch form_url to contain the \"language\" GET parameter.\n            # Otherwise AdminModel.render_change_form will clean the URL\n            # and remove the \"language\" when coming from a filtered object\n            # list causing the wrong translation to be changed.\n\n            params = request.GET.dict()\n            params['language'] = lang_code\n            form_url = add_preserved_filters({\n                'preserved_filters': urlencode(params),\n                'opts': self.model._meta\n            }, form_url)\n\n        # django-fluent-pages uses the same technique\n        if 'default_change_form_template' not in context:\n            context['default_change_form_template'] = self.default_change_form_template\n\n        #context['base_template'] = self.get_change_form_base_template()\n        return super(TranslatableAdmin, self).render_change_form(request, context, add, change, form_url, obj)", "response": "Adds the language tabs and the change form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_translation(self, request, object_id, language_code):\n        opts = self.model._meta\n        root_model = self.model._parler_meta.root_model\n\n        # Get object and translation\n        shared_obj = self.get_object(request, unquote(object_id))\n        if shared_obj is None:\n            raise Http404\n\n        shared_obj.set_current_language(language_code)\n        try:\n            translation = root_model.objects.get(master=shared_obj, language_code=language_code)\n        except root_model.DoesNotExist:\n            raise Http404\n\n        if not self.has_delete_permission(request, translation):\n            raise PermissionDenied\n\n        if len(self.get_available_languages(shared_obj)) <= 1:\n            return self.deletion_not_allowed(request, translation, language_code)\n\n        # Populate deleted_objects, a data structure of all related objects that\n        # will also be deleted.\n\n        using = router.db_for_write(root_model)  # NOTE: all same DB for now.\n        lang = get_language_title(language_code)\n\n        # There are potentially multiple objects to delete;\n        # the translation object at the base level,\n        # and additional objects that can be added by inherited models.\n        deleted_objects = []\n        perms_needed = False\n        protected = []\n\n        # Extend deleted objects with the inlines.\n        for qs in self.get_translation_objects(request, translation.language_code, obj=shared_obj, inlines=self.delete_inline_translations):\n            if isinstance(qs, (list, tuple)):\n                qs_opts = qs[0]._meta\n            else:\n                qs_opts = qs.model._meta\n\n            if django.VERSION >= (2, 1):\n                deleted_result = get_deleted_objects(qs, request, self.admin_site)\n            else:\n                deleted_result = get_deleted_objects(qs, qs_opts, request.user, self.admin_site, using)\n            (del2, model_counts, perms2, protected2) = deleted_result\n\n            deleted_objects += del2\n            perms_needed = perms_needed or perms2\n            protected += protected2\n\n        if request.POST: # The user has already confirmed the deletion.\n            if perms_needed:\n                raise PermissionDenied\n            obj_display = _('{0} translation of {1}').format(lang, force_text(translation))  # in hvad: (translation.master)\n\n            self.log_deletion(request, translation, obj_display)\n            self.delete_model_translation(request, translation)\n            self.message_user(request, _('The %(name)s \"%(obj)s\" was deleted successfully.') % dict(\n                name=force_text(opts.verbose_name), obj=force_text(obj_display)\n            ))\n\n            if self.has_change_permission(request, None):\n                info = opts.app_label, opts.model_name\n                return HttpResponseRedirect(reverse('admin:{0}_{1}_change'.format(*info), args=(object_id,), current_app=self.admin_site.name))\n            else:\n                return HttpResponseRedirect(reverse('admin:index', current_app=self.admin_site.name))\n\n        object_name = _('{0} Translation').format(force_text(opts.verbose_name))\n        if perms_needed or protected:\n            title = _(\"Cannot delete %(name)s\") % {\"name\": object_name}\n        else:\n            title = _(\"Are you sure?\")\n\n        context = {\n            \"title\": title,\n            \"object_name\": object_name,\n            \"object\": translation,\n            \"deleted_objects\": deleted_objects,\n            \"perms_lacking\": perms_needed,\n            \"protected\": protected,\n            \"opts\": opts,\n            \"app_label\": opts.app_label,\n        }\n\n        # Small hack for django-polymorphic-tree.\n        # This makes sure the breadcrumb renders correctly,\n        # and avoids errors when the child model is not registered in the admin.\n        if hasattr(self, 'base_model'):\n            context.update({\n                'base_opts': self.base_model._meta,\n            })\n\n        return render(request, self.delete_confirmation_template or [\n            \"admin/%s/%s/delete_confirmation.html\" % (opts.app_label, opts.object_name.lower()),\n            \"admin/%s/delete_confirmation.html\" % opts.app_label,\n            \"admin/delete_confirmation.html\"\n        ], context)", "response": "Delete a translation object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_model_translation(self, request, translation):\n        master = translation.master\n        for qs in self.get_translation_objects(request, translation.language_code, obj=master, inlines=self.delete_inline_translations):\n            if isinstance(qs, (tuple, list)):\n                # The objects are deleted one by one.\n                # This triggers the post_delete signals and such.\n                for obj in qs:\n                    obj.delete()\n            else:\n                # Also delete translations of inlines which the user has access to.\n                # This doesn't trigger signals, just like the regular\n                qs.delete()", "response": "Hook for deleting a translation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields all objects that should be deleted when a translation is deleted.", "response": "def get_translation_objects(self, request, language_code, obj=None, inlines=True):\n        \"\"\"\n        Return all objects that should be deleted when a translation is deleted.\n        This method can yield all QuerySet objects or lists for the objects.\n        \"\"\"\n        if obj is not None:\n            # A single model can hold multiple TranslatedFieldsModel objects.\n            # Return them all.\n            for translations_model in obj._parler_meta.get_all_models():\n                try:\n                    translation = translations_model.objects.get(master=obj, language_code=language_code)\n                except translations_model.DoesNotExist:\n                    continue\n                yield [translation]\n\n        if inlines:\n            for inline, qs in self._get_inline_translations(request, language_code, obj=obj):\n                yield qs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching the inline translations", "response": "def _get_inline_translations(self, request, language_code, obj=None):\n        \"\"\"\n        Fetch the inline translations\n        \"\"\"\n        inline_instances = self.get_inline_instances(request, obj=obj)\n        for inline in inline_instances:\n            if issubclass(inline.model, TranslatableModelMixin):\n                # leverage inlineformset_factory() to find the ForeignKey.\n                # This also resolves the fk_name if it's set.\n                fk = inline.get_formset(request, obj).fk\n\n                rel_name = 'master__{0}'.format(fk.name)\n                filters = {\n                    'language_code': language_code,\n                    rel_name: obj\n                }\n\n                for translations_model in inline.model._parler_meta.get_all_models():\n                    qs = translations_model.objects.filter(**filters)\n                    if obj is not None:\n                        qs = qs.using(obj._state.db)\n\n                    yield inline, qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining what the actual change_form_template should be.", "response": "def default_change_form_template(self):\n        \"\"\"\n        Determine what the actual `change_form_template` should be.\n        \"\"\"\n        opts = self.model._meta\n        app_label = opts.app_label\n        return select_template_name((\n            \"admin/{0}/{1}/change_form.html\".format(app_label, opts.object_name.lower()),\n            \"admin/{0}/change_form.html\".format(app_label),\n            \"admin/change_form.html\"\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_formset(self, request, obj=None, **kwargs):\n        FormSet = super(TranslatableInlineModelAdmin, self).get_formset(request, obj, **kwargs)\n        # Existing objects already got the language code from the queryset().language() method.\n        # For new objects, the language code should be set here.\n        FormSet.language_code = self.get_form_language(request, obj)\n\n        if self.inline_tabs:\n            # Need to pass information to the template, this can only happen via the FormSet object.\n            available_languages = self.get_available_languages(obj, FormSet)\n            FormSet.language_tabs = self.get_language_tabs(request, obj, available_languages, css_class='parler-inline-language-tabs')\n            FormSet.language_tabs.allow_deletion = self._has_translatable_parent_model()   # Views not available otherwise.\n\n        return FormSet", "response": "Returns the formset and provide the language information to the formset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_form_language(self, request, obj=None):\n        if self._has_translatable_parent_model():\n            return super(TranslatableInlineModelAdmin, self).get_form_language(request, obj=obj)\n        else:\n            # Follow the ?language parameter\n            return self._language(request)", "response": "Returns the current language for the currently displayed object fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_available_languages(self, obj, formset):\n        if obj:\n            # Inlines dictate language code, not the parent model.\n            # Hence, not looking at obj.get_available_languages(), but see what languages\n            # are used by the inline objects that point to it.\n            filter = {\n                'master__{0}'.format(formset.fk.name): obj\n            }\n            return self.model._parler_meta.root_model.objects.using(obj._state.db).filter(**filter) \\\n                   .values_list('language_code', flat=True).distinct().order_by('language_code')\n        else:\n            return self.model._parler_meta.root_model.objects.none()", "response": "Fetch the available inline languages as queryset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef language(self, language_code=None):\n        if language_code is None:\n            language_code = appsettings.PARLER_LANGUAGES.get_default_language()\n\n        self._language = language_code\n        return self", "response": "Sets the language code to assign to objects retrieved using this QuerySet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef active_translations(self, language_code=None, **translated_fields):\n        # Default:     (language, fallback) when hide_translated == False\n        # Alternative: (language,)          when hide_untranslated == True\n        language_codes = get_active_language_choices(language_code)\n        return self.translated(*language_codes, **translated_fields)", "response": "Return a new QuerySet of objects which are translated or have a fallback that should be displayed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_language_title(language_code):\n    from parler import appsettings\n    # Avoid weird lookup errors.\n    if not language_code:\n        raise ValueError(\"Missing language_code in get_language_title()\")\n\n    if appsettings.PARLER_SHOW_EXCLUDED_LANGUAGE_TABS:\n        # this allows to edit languages that are not enabled in current project but are already\n        # in database\n        languages = ALL_LANGUAGES_DICT\n    else:\n        languages = LANGUAGES_DICT\n\n    try:\n        return _(languages[language_code])\n    except KeyError:\n        language_code = language_code.split('-')[0]  # e.g. if fr-ca is not supported fallback to fr\n        language_title = languages.get(language_code, None)\n        if language_title is not None:\n            return _(language_title)\n        else:\n            return language_code", "response": "Return the verbose_name for a language code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_language_settings(language_code, site_id=None):\n    # This method mainly exists for ease-of-use.\n    # the body is part of the settings, to allow third party packages\n    # to have their own variation of the settings with this method functionality included.\n    from parler import appsettings\n    return appsettings.PARLER_LANGUAGES.get_language(language_code, site_id)", "response": "Returns the language settings for the current site."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if the current Django project is configured for multilingual support.", "response": "def is_multilingual_project(site_id=None):\n    \"\"\"\n    Whether the current Django project is configured for multilingual support.\n    \"\"\"\n    from parler import appsettings\n    if site_id is None:\n        site_id = getattr(settings, 'SITE_ID', None)\n    return appsettings.PARLER_SHOW_EXCLUDED_LANGUAGE_TABS or site_id in appsettings.PARLER_LANGUAGES"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap around Django s get_language utility.", "response": "def get_language():\n    \"\"\"\n    Wrapper around Django's `get_language` utility.\n    For Django >= 1.8, `get_language` returns None in case no translation is activate.\n    Here we patch this behavior e.g. for back-end functionality requiring access to translated fields\n    \"\"\"\n    from parler import appsettings\n    language = dj_get_language()\n    if language is None and appsettings.PARLER_DEFAULT_ACTIVATE:\n        return appsettings.PARLER_DEFAULT_LANGUAGE_CODE\n    else:\n        return language"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __timestamp():\n    today = time.time()\n    ret = struct.pack(b'=L', int(today))\n    return ret", "response": "Generate timestamp data for pyc header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the PYTHONSCRIPT resource entry.", "response": "def _get_scripts_resource(pe):\n    \"\"\"Return the PYTHONSCRIPT resource entry.\"\"\"\n    res = None\n    for entry in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n        if entry.name and entry.name.string == b\"PYTHONSCRIPT\":\n            res = entry.directory.entries[0].directory.entries[0]\n            break\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _resource_dump(pe, res):\n    rva = res.data.struct.OffsetToData\n    size = res.data.struct.Size\n\n    dump = pe.get_data(rva, size)\n    return dump", "response": "Return the dump of the given resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_co_from_dump(data):\n    # Read py2exe header\n    current = struct.calcsize(b'iiii')\n    metadata = struct.unpack(b'iiii', data[:current])\n\n    # check py2exe magic number\n    # assert(metadata[0] == 0x78563412)\n    logging.info(\"Magic value: %x\", metadata[0])\n    logging.info(\"Code bytes length: %d\", metadata[3])\n\n    arcname = ''\n    while six.indexbytes(data, current) != 0:\n        arcname += chr(six.indexbytes(data, current))\n        current += 1\n    logging.info(\"Archive name: %s\", arcname or '-')\n\n    code_bytes = data[current + 1:]\n    # verify code bytes count and metadata info\n    # assert(len(code_bytes) == metadata[3])\n\n    code_objects = marshal.loads(code_bytes)\n    return code_objects", "response": "Return the code objects from the dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if file is a py2exe executable.", "response": "def check_py2exe_file(pe):\n    \"\"\"Check file is a py2exe executable.\"\"\"\n    py2exe_resource = _get_scripts_resource(pe)\n\n    if py2exe_resource is None:\n        logging.info('This is not a py2exe executable.')\n        if pe.__data__.find(b'pyi-windows-manifest-filename'):\n            logging.info('This seems a pyinstaller executable (unsupported).')\n\n    return bool(py2exe_resource)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting Python code objects from a py2exe executable.", "response": "def extract_code_objects(pe):\n    \"\"\"Extract Python code objects from a py2exe executable.\"\"\"\n    script_res = _get_scripts_resource(pe)\n    dump = _resource_dump(pe, script_res)\n    return _get_co_from_dump(dump)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave given code_object as a. pyc file.", "response": "def dump_to_pyc(co, python_version, output_dir):\n    \"\"\"Save given code_object as a .pyc file.\"\"\"\n    # assume Windows path information from the .exe\n    pyc_basename = ntpath.basename(co.co_filename)\n    pyc_name = pyc_basename + '.pyc'\n\n    if pyc_name not in IGNORE:\n        logging.info(\"Extracting %s\", pyc_name)\n        pyc_header = _generate_pyc_header(python_version, len(co.co_code))\n        destination = os.path.join(output_dir, pyc_name)\n        pyc = open(destination, 'wb')\n        pyc.write(pyc_header)\n        marshaled_code = marshal.dumps(co)\n        pyc.write(marshaled_code)\n        pyc.close()\n    else:\n        logging.info(\"Skipping %s\", pyc_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing input params and produce output pyc files.", "response": "def unpy2exe(filename, python_version=None, output_dir=None):\n    \"\"\"Process input params and produce output pyc files.\"\"\"\n    if output_dir is None:\n        output_dir = '.'\n    elif not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    pe = pefile.PE(filename)\n\n    is_py2exe = check_py2exe_file(pe)\n    if not is_py2exe:\n        raise ValueError('Not a py2exe executable.')\n\n    code_objects = extract_code_objects(pe)\n    for co in code_objects:\n        dump_to_pyc(co, python_version, output_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator over iterable that tells whether the current item is the last one.", "response": "def enum_mark_last(iterable, start=0):\n    \"\"\"\n    Returns a generator over iterable that tells whether the current item is the last one.\n    Usage:\n        >>> iterable = range(10)\n        >>> for index, is_last, item in enum_mark_last(iterable):\n        >>>     print(index, item, end='\\n' if is_last else ', ')\n    \"\"\"\n    it = iter(iterable)\n    count = start\n    try:\n        last = next(it)\n    except StopIteration:\n        return\n    for val in it:\n        yield count, False, last\n        last = val\n        count += 1\n    yield count, True, last"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting an arbitrary CLI command on the SLCAN adapter.", "response": "def execute_cli_command(self, command, callback, timeout=None):\n        \"\"\"\n        Executes an arbitrary CLI command on the SLCAN adapter, assuming that the adapter supports CLI commands.\n        The callback will be invoked from the method receive() using same thread.\n        If the command times out, the callback will be invoked anyway, with 'expired' flag set.\n        Args:\n            command:    Command as unicode string or bytes\n            callback:   A callable that accepts one argument.\n                        The argument is an instance of IPCCommandLineExecutionResponse\n            timeout:    Timeout in seconds. None to use default timeout.\n        \"\"\"\n        self._check_alive()\n        request = IPCCommandLineExecutionRequest(command, timeout)\n        try:\n            self._tx_queue.put(request, timeout=timeout)\n        except queue.Full:\n            raise TxQueueFullError()\n        # The command could be modified by the IPCCommandLineExecutionRequest\n        self._cli_command_requests.append((request.command, callback))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_update_handler(self, callback):\n        self._update_callbacks.append(callback)\n        return self.UpdateHandlerRemover(lambda: self._update_callbacks.remove(callback))", "response": "Add a callback to be invoked when a new node is updated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, node_id):\n        if (self._registry[node_id].monotonic_timestamp + self.TIMEOUT) < time.monotonic():\n            self._call_event_handlers(self.UpdateEvent(self._registry[node_id],\n                                                       self.UpdateEvent.EVENT_ID_OFFLINE))\n            del self._registry[node_id]\n        return self._registry[node_id]", "response": "Returns an Entry instance for the given node ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_all(self, predicate):\n        for _nid, entry in self._registry.items():\n            if predicate(entry):\n                yield entry", "response": "Returns a generator that yields a sequence of Entry objects for which the predicate returns True."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports whether there are nodes whose node info is still unknown.", "response": "def are_all_nodes_discovered(self):\n        \"\"\"Reports whether there are nodes whose node info is still unknown.\"\"\"\n        undiscovered = self.find_all(lambda e: not e.discovered)\n        return len(list(undiscovered)) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_io_hook(self, hook):\n        def proxy(*args):\n            hook(*args)\n\n        self._io_hooks.append(proxy)\n\n        return self.HookRemover(lambda: self._io_hooks.remove(proxy))", "response": "Adds a hook to be invoked for every incoming and outgoing CAN frames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the source clock value with the new value.", "response": "def update(self, source_clock_sample, target_clock_sample):\n        \"\"\"\n        Args:\n            source_clock_sample: Sample of the source clock, in seconds\n            target_clock_sample: Sample of the target clock, in seconds\n\n        Returns: Resolved absolute source clock value\n        \"\"\"\n        if self._resolved_time is None or self.source_clock_overflow_period is None:\n            self._resolved_time = decimal.Decimal(source_clock_sample)\n            self._prev_source_sample = source_clock_sample\n            self._prev_target_sample = target_clock_sample\n        else:\n            # Time between updates in the target clock domain\n            tgt_delta = target_clock_sample - self._prev_target_sample\n            self._prev_target_sample = target_clock_sample\n            assert tgt_delta >= 0\n\n            # Time between updates in the source clock domain\n            src_delta = source_clock_sample - self._prev_source_sample\n            self._prev_source_sample = source_clock_sample\n\n            # Using the target clock we can resolve the integer ambiguity (number of overflows)\n            full_cycles = int(round((tgt_delta - src_delta) / float(self.source_clock_overflow_period), 0))\n\n            # Updating the source clock now; in two steps, in order to avoid error accumulation in floats\n            self._resolved_time += decimal.Decimal(full_cycles * self.source_clock_overflow_period)\n            self._resolved_time += decimal.Decimal(src_delta)\n\n        return self._resolved_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_yaml(obj):\n    if not isinstance(obj, CompoundValue) and hasattr(obj, 'transfer'):\n        if hasattr(obj, 'message'):\n            payload = obj.message\n            header = 'Message'\n        elif hasattr(obj, 'request'):\n            payload = obj.request\n            header = 'Request'\n        elif hasattr(obj, 'response'):\n            payload = obj.response\n            header = 'Response'\n        else:\n            raise ValueError('Cannot generate YAML representation for %r' % type(obj))\n\n        prefix = '### %s from %s to %s  ts_mono=%.6f  ts_real=%.6f\\n' % \\\n                 (header,\n                  obj.transfer.source_node_id or 'Anon',\n                  obj.transfer.dest_node_id or 'All',\n                  obj.transfer.ts_monotonic, obj.transfer.ts_real)\n\n        return prefix + _to_yaml_impl(payload)\n    else:\n        return _to_yaml_impl(obj)", "response": "Convert an object to a YAML representation of a UAVCAN structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an instance of CAN driver based on the device_name.", "response": "def make_driver(device_name, **kwargs):\n    \"\"\"Creates an instance of CAN driver.\n    The right driver class will be selected automatically based on the device_name.\n    :param device_name: This parameter is used to select driver class. E.g. \"/dev/ttyACM0\", \"COM9\", \"can0\".\n    :param kwargs: Passed directly to the constructor.\n    \"\"\"\n    windows_com_port = device_name.replace('\\\\', '').replace('.', '').lower().startswith('com')\n    unix_tty = device_name.startswith('/dev/')\n\n    if windows_com_port or unix_tty:\n        return SLCAN(device_name, **kwargs)\n    elif SocketCAN is not None:\n        return SocketCAN(device_name, **kwargs)\n    else:\n        raise DriverError('Unrecognized device name: %r' % device_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the DSDL files under the given directory and creates the types for each of them in the current module s namespace.", "response": "def load_dsdl(*paths, **args):\n    \"\"\"\n    Loads the DSDL files under the given directory/directories, and creates\n    types for each of them in the current module's namespace.\n\n    If the exclude_dist argument is not present, or False, the DSDL\n    definitions installed with this package will be loaded first.\n\n    Also adds entries for all datatype (ID, kind)s to the DATATYPES\n    dictionary, which maps datatype (ID, kind)s to their respective type\n    classes.\n    \"\"\"\n    global DATATYPES, TYPENAMES\n\n    paths = list(paths)\n\n    # Try to prepend the built-in DSDL files\n    # TODO: why do we need try/except here?\n    # noinspection PyBroadException\n    try:\n        if not args.get(\"exclude_dist\", None):\n            dsdl_path = pkg_resources.resource_filename(__name__, \"dsdl_files\")  # @UndefinedVariable\n            paths = [os.path.join(dsdl_path, \"uavcan\")] + paths\n            custom_path = os.path.join(os.path.expanduser(\"~\"), \"uavcan_vendor_specific_types\")\n            if os.path.isdir(custom_path):\n                paths += [f for f in [os.path.join(custom_path, f) for f in os.listdir(custom_path)]\n                          if os.path.isdir(f)]\n    except Exception:\n        pass\n\n    root_namespace = Namespace()\n    dtypes = dsdl.parse_namespaces(paths)\n    for dtype in dtypes:\n        namespace, _, typename = dtype.full_name.rpartition(\".\")\n        root_namespace._path(namespace).__dict__[typename] = dtype\n        TYPENAMES[dtype.full_name] = dtype\n\n        if dtype.default_dtid:\n            DATATYPES[(dtype.default_dtid, dtype.kind)] = dtype\n            # Add the base CRC to each data type capable of being transmitted\n            dtype.base_crc = dsdl.crc16_from_bytes(struct.pack(\"<Q\", dtype.get_data_type_signature()))\n            logger.debug(\"DSDL Load {: >30} DTID: {: >4} base_crc:{: >8}\"\n                         .format(typename, dtype.default_dtid, hex(dtype.base_crc)))\n\n        def create_instance_closure(closure_type, _mode=None):\n            # noinspection PyShadowingNames\n            def create_instance(*args, **kwargs):\n                if _mode:\n                    assert '_mode' not in kwargs, 'Mode cannot be supplied to service type instantiation helper'\n                    kwargs['_mode'] = _mode\n                return transport.CompoundValue(closure_type, *args, **kwargs)\n            return create_instance\n\n        dtype._instantiate = create_instance_closure(dtype)\n\n        if dtype.kind == dtype.KIND_SERVICE:\n            dtype.Request = create_instance_closure(dtype, _mode='request')\n            dtype.Response = create_instance_closure(dtype, _mode='response')\n\n    namespace = root_namespace._path(\"uavcan\")\n    for top_namespace in namespace._namespaces():\n        MODULE.__dict__[str(top_namespace)] = namespace.__dict__[top_namespace]\n\n    MODULE.__dict__[\"thirdparty\"] = Namespace()\n    for ext_namespace in root_namespace._namespaces():\n        if str(ext_namespace) != \"uavcan\":\n            # noinspection PyUnresolvedReferences\n            MODULE.thirdparty.__dict__[str(ext_namespace)] = root_namespace.__dict__[ext_namespace]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _path(self, attrpath):\n\n        attr, _, subpath = attrpath.partition(\".\")\n        if attr not in self.__dict__:\n            self.__dict__[attr] = Namespace()\n            self.__namespaces.add(attr)\n\n        if subpath:\n            return self.__dict__[attr]._path(subpath)\n        else:\n            return self.__dict__[attr]", "response": "Returns the namespace object at the given. - separated path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_node(can_device_name, **kwargs):\n    can = driver.make_driver(can_device_name, **kwargs)\n    return Node(can, **kwargs)", "response": "Creates a node instance with specified CAN device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a handler for the specified data type.", "response": "def add_handler(self, uavcan_type, handler, **kwargs):\n        \"\"\"\n        Adds a handler for the specified data type.\n        :param uavcan_type: DSDL data type. Only transfers of this type will be accepted for this handler.\n        :param handler:     The handler. This must be either a callable or a class.\n        :param **kwargs:    Extra arguments for the handler.\n        :return: A remover object that can be used to unregister the handler as follows:\n            x = node.add_handler(...)\n            # Remove the handler like this:\n            x.remove()\n            # Or like this:\n            if x.try_remove():\n                print('The handler has been removed successfully')\n            else:\n                print('There is no such handler')\n        \"\"\"\n        return self._handler_dispatcher.add_handler(uavcan_type, handler, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns background processes until timeout expires.", "response": "def spin(self, timeout=None):\n        \"\"\"\n        Runs background processes until timeout expires.\n        Note that all processing is implemented in one thread.\n        :param timeout: The method will return once this amount of time expires.\n                        If None, the method will never return.\n                        If zero, the method will handle only those events that are ready, then return immediately.\n        \"\"\"\n        if timeout != 0:\n            deadline = (time.monotonic() + timeout) if timeout is not None else sys.float_info.max\n\n            def execute_once():\n                next_event_at = self._poll_scheduler_and_get_next_deadline()\n                if next_event_at is None:\n                    next_event_at = sys.float_info.max\n\n                read_timeout = min(next_event_at, deadline) - time.monotonic()\n                read_timeout = max(read_timeout, 0)\n                read_timeout = min(read_timeout, 1)\n\n                frame = self._can_driver.receive(read_timeout)\n                if frame:\n                    self._recv_frame(frame)\n\n            execute_once()\n            while time.monotonic() < deadline:\n                execute_once()\n        else:\n            while True:\n                frame = self._can_driver.receive(0)\n                if frame:\n                    self._recv_frame(frame)\n                else:\n                    break\n            self._poll_scheduler_and_get_next_deadline()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfeed ASCII string or bytes to the signature function", "response": "def add(self, data_bytes):\n        '''Feed ASCII string or bytes to the signature function'''\n        try:\n            if isinstance(data_bytes, basestring):  # Python 2.7 compatibility\n                data_bytes = map(ord, data_bytes)\n        except NameError:\n            if isinstance(data_bytes, str):  # This branch will be taken on Python 3\n                data_bytes = map(ord, data_bytes)\n\n        for b in data_bytes:\n            self._crc ^= (b << 56) & Signature.MASK64\n            for _ in range(8):\n                if self._crc & (1 << 63):\n                    self._crc = ((self._crc << 1) & Signature.MASK64) ^ Signature.POLY\n                else:\n                    self._crc <<= 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the DSDL definitions in source_dirs and return a list of type definitions in the order they appear.", "response": "def parse_namespaces(source_dirs, search_dirs=None):\n    \"\"\"\n    Use only this function to parse DSDL definitions.\n    This function takes a list of root namespace directories (containing DSDL definition files to parse) and an\n    optional list of search directories (containing DSDL definition files that can be referenced from the types\n    that are going to be parsed).\n\n    Returns the list of parsed type definitions, where type of each element is CompoundType.\n\n    Args:\n        source_dirs:   List of root namespace directories to parse.\n        search_dirs:   List of root namespace directories with referenced types (optional). This list is\n                       automatically extended with source_dirs.\n    Example:\n        >>> import uavcan\n        >>> a = uavcan.dsdl.parse_namespaces(['../dsdl/uavcan'])\n        >>> len(a)\n        77\n        >>> a[0]\n        uavcan.Timestamp\n        >>> a[0].fields\n        [truncated uint48 husec]\n        >>> a[0].constants\n        [saturated uint48 UNKNOWN = 0, saturated uint48 USEC_PER_LSB = 100]\n    \"\"\"\n\n    # noinspection PyShadowingNames\n    def walk():\n        import fnmatch\n        from functools import partial\n\n        def on_walk_error(directory, ex):\n            raise DsdlException('OS error in [%s]: %s' % (directory, str(ex)))\n        for source_dir in source_dirs:\n            walker = os.walk(source_dir, onerror=partial(on_walk_error, source_dir), followlinks=True)\n            for root, _dirnames, filenames in walker:\n                for filename in fnmatch.filter(filenames, '*.uavcan'):\n                    filename = os.path.join(root, filename)\n                    yield filename\n\n    all_default_dtid = {}  # (kind, dtid) : filename\n\n    # noinspection PyShadowingNames\n    def ensure_unique_dtid(t, filename):\n        if t.default_dtid is None:\n            return\n        key = t.kind, t.default_dtid\n        if key in all_default_dtid:\n            first = pretty_filename(all_default_dtid[key])\n            second = pretty_filename(filename)\n            error('Default data type ID collision: [%s] [%s]', first, second)\n        all_default_dtid[key] = filename\n\n    parser = Parser(source_dirs + (search_dirs or []))\n    output_types = []\n    for filename in walk():\n        t = parser.parse(filename)\n        ensure_unique_dtid(t, filename)\n        output_types.append(t)\n    return output_types"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_normalized_definition(self):\n        cast_mode = 'saturated' if self.cast_mode == PrimitiveType.CAST_MODE_SATURATED else 'truncated'\n        primary_type = {\n            PrimitiveType.KIND_BOOLEAN: 'bool',\n            PrimitiveType.KIND_UNSIGNED_INT: 'uint' + str(self.bitlen),\n            PrimitiveType.KIND_SIGNED_INT: 'int' + str(self.bitlen),\n            PrimitiveType.KIND_FLOAT: 'float' + str(self.bitlen)\n        }[self.kind]\n        return cast_mode + ' ' + primary_type", "response": "Returns the normalized definition of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_value_range(self, value):\n        low, high = self.value_range\n        if not low <= value <= high:\n            error('Value [%s] is out of range %s', value, self.value_range)", "response": "Validates that the value is in the range of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the normalized definition of the array type.", "response": "def get_normalized_definition(self):\n        \"\"\"Please refer to the specification for details about normalized definitions.\"\"\"\n        typedef = self.value_type.get_normalized_definition()\n        return ('%s[<=%d]' if self.mode == ArrayType.MODE_DYNAMIC else '%s[%d]') % (typedef, self.max_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_max_bitlen(self):\n        payload_max_bitlen = self.max_size * self.value_type.get_max_bitlen()\n        return {\n            self.MODE_DYNAMIC: payload_max_bitlen + self.max_size.bit_length(),\n            self.MODE_STATIC: payload_max_bitlen\n        }[self.mode]", "response": "Returns the maximum bit length of the array including length field if applicable."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns normalized DSDL definition text.", "response": "def get_dsdl_signature_source_definition(self):\n        \"\"\"\n        Returns normalized DSDL definition text.\n        Please refer to the specification for details about normalized DSDL definitions.\n        \"\"\"\n        txt = StringIO()\n        txt.write(self.full_name + '\\n')\n\n        def adjoin(attrs):\n            return txt.write('\\n'.join(x.get_normalized_definition() for x in attrs) + '\\n')\n\n        if self.kind == CompoundType.KIND_SERVICE:\n            if self.request_union:\n                txt.write('\\n@union\\n')\n            adjoin(self.request_fields)\n            txt.write('\\n---\\n')\n            if self.response_union:\n                txt.write('\\n@union\\n')\n            adjoin(self.response_fields)\n        elif self.kind == CompoundType.KIND_MESSAGE:\n            if self.union:\n                txt.write('\\n@union\\n')\n            adjoin(self.fields)\n        else:\n            error('Compound type of unknown kind [%s]', self.kind)\n        return txt.getvalue().strip().replace('\\n\\n\\n', '\\n').replace('\\n\\n', '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the data type signature of this type.", "response": "def get_data_type_signature(self):\n        \"\"\"\n        Computes data type signature of this type. The data type signature is\n        guaranteed to match only if all nested data structures are compatible.\n        Please refer to the specification for details about signatures.\n        \"\"\"\n        if self._data_type_signature is None:\n            sig = Signature(self.get_dsdl_signature())\n            fields = self.request_fields + self.response_fields if self.kind == CompoundType.KIND_SERVICE else self.fields\n            for field in fields:\n                field_sig = field.type.get_data_type_signature()\n                if field_sig is not None:\n                    sig_value = sig.get_value()\n                    sig.add(bytes_from_crc64(field_sig))\n                    sig.add(bytes_from_crc64(sig_value))\n            self._data_type_signature = sig.get_value()\n        return self._data_type_signature"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(self):\n        self._handle.remove()\n        self._node_monitor_event_handle.remove()\n        self._allocation_table.close()", "response": "Stops the instance and closes the allocation table storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a nice human readable path to filename.", "response": "def pretty_filename(filename):\n    '''Returns a nice human readable path to 'filename'.'''\n    try:\n        a = os.path.abspath(filename)\n        r = os.path.relpath(filename)\n    except ValueError:\n        # Catch relpath exception. Happens, because it can not produce relative path\n        # if wroking directory is on different drive.\n        a = r = filename\n    return a if '..' in r else r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_event(self, event):\n        # Check if event is of type event_pb2.Event proto.\n        if not isinstance(event, event_pb2.Event):\n            raise TypeError(\"expected an event_pb2.Event proto, \"\n                            \" but got %s\" % type(event))\n        return self._write_serialized_event(event.SerializeToString())", "response": "Appends an event to the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflushes the event file to disk.", "response": "def flush(self):\n        \"\"\"Flushes the event file to disk.\"\"\"\n        if self._num_outstanding_events == 0 or self._recordio_writer is None:\n            return\n        self._recordio_writer.flush()\n        if self._logger is not None:\n            self._logger.info('wrote %d %s to disk', self._num_outstanding_events,\n                              'event' if self._num_outstanding_events == 1 else 'events')\n        self._num_outstanding_events = 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        self.flush()\n        if self._recordio_writer is not None:\n            self._recordio_writer.close()\n            self._recordio_writer = None", "response": "Flushes the pending events and closes the writer after it is done."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reopen(self):\n        if self._closed:\n            self._worker = _EventLoggerThread(self._event_queue, self._ev_writer,\n                                              self._flush_secs, self._sentinel_event)\n            self._worker.start()\n            self._closed = False", "response": "Reopens the EventFileWriter.\n        Can be called after `close()` to add more events in the same directory.\n        The events will go into a new events file.\n        Does nothing if the `EventFileWriter` was not closed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nflush the event file to disk and closes the file.", "response": "def close(self):\n        \"\"\"Flushes the event file to disk and close the file.\n        Call this method when you do not need the summary writer anymore.\n        \"\"\"\n        if not self._closed:\n            self.add_event(self._sentinel_event)\n            self.flush()\n            self._worker.join()\n            self._ev_writer.close()\n            self._closed = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a serialized event to file.", "response": "def write_record(self, event_str):\n        \"\"\"Writes a serialized event to file.\"\"\"\n        header = struct.pack('Q', len(event_str))\n        header += struct.pack('I', masked_crc32c(header))\n        footer = struct.pack('I', masked_crc32c(event_str))\n        self._writer.write(header + event_str + footer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the record writer.", "response": "def close(self):\n        \"\"\"Closes the record writer.\"\"\"\n        if self._writer is not None:\n            self.flush()\n            self._writer.close()\n            self._writer = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a Summary protocol buffer to the event file.", "response": "def add_summary(self, summary, global_step=None):\n        \"\"\"Adds a `Summary` protocol buffer to the event file.\n        This method wraps the provided summary in an `Event` protocol buffer and adds it\n        to the event file.\n\n        Parameters\n        ----------\n          summary : A `Summary` protocol buffer\n              Optionally serialized as a string.\n          global_step: Number\n              Optional global step value to record with the summary.\n        \"\"\"\n        if isinstance(summary, bytes):\n            summ = summary_pb2.Summary()\n            summ.ParseFromString(summary)\n            summary = summ\n\n        # We strip metadata from values with tags that we have seen before in order\n        # to save space - we just store the metadata on the first value with a\n        # specific tag.\n        for value in summary.value:\n            if not value.metadata:\n                continue\n\n            if value.tag in self._seen_summary_tags:\n                # This tag has been encountered before. Strip the metadata.\n                value.ClearField(\"metadata\")\n                continue\n\n            # We encounter a value with a tag we have not encountered previously. And\n            # it has metadata. Remember to strip metadata from future values with this\n            # tag string.\n            self._seen_summary_tags.add(value.tag)\n\n        event = event_pb2.Event(summary=summary)\n        self._add_event(event, global_step)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a Graph protocol buffer to the event file.", "response": "def add_graph(self, graph):\n        \"\"\"Adds a `Graph` protocol buffer to the event file.\"\"\"\n        event = event_pb2.Event(graph_def=graph.SerializeToString())\n        self._add_event(event, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of default bin numbers for the given class.", "response": "def _get_default_bins(self):\n        \"\"\"Ported from the C++ function InitDefaultBucketsInner() in the following file.\n        https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/histogram/histogram.cc\n        See the following tutorial for more details on how TensorFlow initialize bin distribution.\n        https://www.tensorflow.org/programmers_guide/tensorboard_histograms\"\"\"\n        if self._default_bins is None:\n            v = 1E-12\n            buckets = []\n            neg_buckets = []\n            while v < 1E20:\n                buckets.append(v)\n                neg_buckets.append(-v)\n                v *= 1.1\n            self._default_bins = neg_buckets[::-1] + [0] + buckets\n        return self._default_bins"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _append_to_scalar_dict(self, tag, scalar_value, global_step, timestamp):\n        if tag not in self._scalar_dict.keys():\n            self._scalar_dict[tag] = []\n        self._scalar_dict[tag].append([timestamp, global_step, float(scalar_value)])", "response": "Adds a list [ timestamp step value to the value of self. _scalar_dict [ tag ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_scalar(self, tag, value, global_step=None):\n        if isinstance(value, (tuple, list, dict)):\n            if isinstance(value, (tuple, list)):\n                if len(value) != 2:\n                    raise ValueError('expected two elements in value, while received %d'\n                                     % len(value))\n                value = {value[0]: value[1]}\n            self._add_scalars(tag, value, global_step)\n        else:\n            self._file_writer.add_summary(scalar_summary(tag, value), global_step)\n            self._append_to_scalar_dict(self.get_logdir() + '/' + tag,\n                                        value, global_step, time.time())", "response": "Adds scalar data to the event file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_scalars(self, tag, scalar_dict, global_step=None):\n        timestamp = time.time()\n        fw_logdir = self._file_writer.get_logdir()\n        for scalar_name, scalar_value in scalar_dict.items():\n            fw_tag = fw_logdir + '/' + tag + '/' + scalar_name\n            if fw_tag in self._all_writers.keys():\n                fw = self._all_writers[fw_tag]\n            else:\n                fw = FileWriter(logdir=fw_tag, max_queue=self._max_queue,\n                                flush_secs=self._flush_secs, filename_suffix=self._filename_suffix,\n                                verbose=self._verbose)\n                self._all_writers[fw_tag] = fw\n            fw.add_summary(scalar_summary(tag, scalar_value), global_step)\n            self._append_to_scalar_dict(fw_tag, scalar_value, global_step, timestamp)", "response": "Adds multiple scalars to summary. This enables drawing multiple curves in one plot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_scalars(self, path):\n        if os.path.exists(path) and os.path.isfile(path):\n            logging.warning('%s already exists and will be overwritten by scalar dict', path)\n        with open(path, \"w\") as f:\n            json.dump(self._scalar_dict, f)", "response": "Exports all the scalars written by this instance to the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_histogram(self, tag, values, global_step=None, bins='default'):\n        if bins == 'default':\n            bins = self._get_default_bins()\n        self._file_writer.add_summary(histogram_summary(tag, values, bins), global_step)", "response": "Add histogram data to the event file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding image data to the event file.", "response": "def add_image(self, tag, image, global_step=None):\n        \"\"\"Add image data to the event file.\n        This function supports input as a 2D, 3D, or 4D image.\n        If the input image is 2D, a channel axis is prepended as the first dimension\n        and image will be replicated three times and concatenated along the channel axis.\n        If the input image is 3D, it will be replicated three times and concatenated along\n        the channel axis. If the input image is 4D, which is a batch images, all the\n        images will be spliced as a sprite image for display.\n\n        Note: This function requires the ``pillow`` package.\n\n        Note: This function internally calls `asnumpy()` for MXNet `NDArray` inputs.\n        Since `asnumpy()` is a blocking function call, this function would block the main\n        thread till it returns. It may consequently affect the performance of async execution\n        of the MXNet engine.\n\n        Parameters\n        ----------\n            tag : str\n                Name for the `image`.\n            image : MXNet `NDArray` or `numpy.ndarray`\n                Image is one of the following formats: (H, W), (C, H, W), (N, C, H, W).\n                If the input is a batch of images, a grid of images is made by stitching them\n                together.\n                If data type is float, values must be in range [0, 1], and then they are\n                rescaled to range [0, 255]. Note that this does not change the values of the\n                input `image`. A copy of the input `image` is created instead.\n                If data type is 'uint8`, values are unchanged.\n            global_step : int\n                Global step value to record.\n        \"\"\"\n        self._file_writer.add_summary(image_summary(tag, image), global_step)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding audio data to the event file.", "response": "def add_audio(self, tag, audio, sample_rate=44100, global_step=None):\n        \"\"\"Add audio data to the event file.\n\n        Note: This function internally calls `asnumpy()` for MXNet `NDArray` inputs.\n        Since `asnumpy()` is a blocking function call, this function would block the main\n        thread till it returns. It may consequently affect the performance of async execution\n        of the MXNet engine.\n\n        Parameters\n        ----------\n            tag : str\n                Name for the `audio`.\n            audio : MXNet `NDArray` or `numpy.ndarray`\n                Audio data squeezable to a 1D tensor. The values of the tensor are in the range\n                `[-1, 1]`.\n            sample_rate : int\n                Sample rate in Hz.\n            global_step : int\n                Global step value to record.\n        \"\"\"\n        self._file_writer.add_summary(audio_summary(tag, audio, sample_rate=sample_rate),\n                                      global_step)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_text(self, tag, text, global_step=None):\n        self._file_writer.add_summary(text_summary(tag, text), global_step)\n        if tag not in self._text_tags:\n            self._text_tags.append(tag)\n            extension_dir = self.get_logdir() + '/plugins/tensorboard_text/'\n            if not os.path.exists(extension_dir):\n                os.makedirs(extension_dir)\n            with open(extension_dir + 'tensors.json', 'w') as fp:\n                json.dump(self._text_tags, fp)", "response": "Add text data to the event file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_embedding(self, tag, embedding, labels=None, images=None, global_step=None):\n        embedding_shape = embedding.shape\n        if len(embedding_shape) != 2:\n            raise ValueError('expected 2D NDArray as embedding data, while received an array with'\n                             ' ndim=%d' % len(embedding_shape))\n        data_dir = _get_embedding_dir(tag, global_step)\n        save_path = os.path.join(self.get_logdir(), data_dir)\n        try:\n            os.makedirs(save_path)\n        except OSError:\n            logging.warning('embedding dir %s exists, files under this dir will be overwritten',\n                            save_path)\n        if labels is not None:\n            if (embedding_shape[0] != len(labels) and\n                    (not _is_2D_matrix(labels) or len(labels) != embedding_shape[0] + 1)):\n                raise ValueError('expected equal values of embedding first dim and length of '\n                                 'labels or embedding first dim + 1 for 2d labels '\n                                 ', while received %d and %d for each'\n                                 % (embedding_shape[0], len(labels)))\n            if self._logger is not None:\n                self._logger.info('saved embedding labels to %s', save_path)\n            _make_metadata_tsv(labels, save_path)\n        if images is not None:\n            img_labels_shape = images.shape\n            if embedding_shape[0] != img_labels_shape[0]:\n                raise ValueError('expected equal first dim size of embedding and images,'\n                                 ' while received %d and %d for each' % (embedding_shape[0],\n                                                                         img_labels_shape[0]))\n            if self._logger is not None:\n                self._logger.info('saved embedding images to %s', save_path)\n            _make_sprite_image(images, save_path)\n        if self._logger is not None:\n            self._logger.info('saved embedding data to %s', save_path)\n        _save_embedding_tsv(embedding, save_path)\n        _add_embedding_config(self.get_logdir(), data_dir, labels is not None,\n                              images.shape if images is not None else None)", "response": "Adds embedding data to the event file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_pr_curve(self, tag, labels, predictions, num_thresholds,\n                     global_step=None, weights=None):\n        \"\"\"Adds precision-recall curve.\n\n        Note: This function internally calls `asnumpy()` for MXNet `NDArray` inputs.\n        Since `asnumpy()` is a blocking function call, this function would block the main\n        thread till it returns. It may consequently affect the performance of async execution\n        of the MXNet engine.\n\n        Parameters\n        ----------\n            tag : str\n                A tag attached to the summary. Used by TensorBoard for organization.\n            labels : MXNet `NDArray` or `numpy.ndarray`.\n                The ground truth values. A tensor of 0/1 values with arbitrary shape.\n            predictions : MXNet `NDArray` or `numpy.ndarray`.\n                A float32 tensor whose values are in the range `[0, 1]`. Dimensions must match\n                those of `labels`.\n            num_thresholds : int\n                Number of thresholds, evenly distributed in `[0, 1]`, to compute PR metrics for.\n                Should be `>= 2`. This value should be a constant integer value, not a tensor\n                that stores an integer.\n                The thresholds for computing the pr curves are calculated in the following way:\n                `width = 1.0 / (num_thresholds - 1),\n                thresholds = [0.0, 1*width, 2*width, 3*width, ..., 1.0]`.\n            global_step : int\n                Global step value to record.\n            weights : MXNet `NDArray` or `numpy.ndarray`.\n                Optional float32 tensor. Individual counts are multiplied by this value.\n                This tensor must be either the same shape as or broadcastable to the `labels`\n                tensor.\n        \"\"\"\n        if num_thresholds < 2:\n            raise ValueError('num_thresholds must be >= 2')\n        labels = _make_numpy_array(labels)\n        predictions = _make_numpy_array(predictions)\n        self._file_writer.add_summary(pr_curve_summary(tag, labels, predictions,\n                                                       num_thresholds, weights), global_step)", "response": "Adds a precision - recall curve to the summary file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck to see if a 2D list is a valid 2D matrix", "response": "def _rectangular(n):\n    \"\"\"Checks to see if a 2D list is a valid 2D matrix\"\"\"\n    for i in n:\n        if len(i) != len(n[0]):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking to see if a matrix is 2D or a list of lists is 2D", "response": "def _is_2D_matrix(matrix):\n    \"\"\"Checks to see if a ndarray is 2D or a list of lists is 2D\"\"\"\n    return ((isinstance(matrix[0], list) and _rectangular(matrix) and\n             not isinstance(matrix[0][0], list)) or\n            (not isinstance(matrix, list) and matrix.shape == 2))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_image_grid(tensor, nrow=8, padding=2, normalize=False, norm_range=None,\n                    scale_each=False, pad_value=0, square_image=False):\n    \"\"\"Make a grid of images. This is an MXNet version of torchvision.utils.make_grid\n    Ref: https://github.com/pytorch/vision/blob/master/torchvision/utils.py\n\n    Parameters\n    ----------\n        tensor : `NDArray` or list of `NDArray`s\n            Input image(s) in the format of HW, CHW, or NCHW.\n        nrow : int\n            Number of images displayed in each row of the grid. The Final grid size is\n            (batch_size / `nrow`, `nrow`) when square_image is False; otherwise, (`nrow`, `nrow`).\n        padding : int\n            Padding value for each image in the grid.\n        normalize : bool\n            If True, shift the image to the range (0, 1), by subtracting the\n            minimum and dividing by the maximum pixel value.\n        norm_range : tuple\n            Tuple of (min, max) where min and max are numbers. These numbers are used\n            to normalize the image. By default, `min` and `max` are computed from the `tensor`.\n        scale_each : bool\n            If True, scale each image in the batch of images separately rather than the\n            `(min, max)` over all images.\n        pad_value : float\n            Value for the padded pixels.\n        square_image : bool\n            If True, force the generated image grid to be strictly square (the last\n            row of the image grid may be entire blank as a result).\n\n    Returns\n    -------\n    NDArray\n        A image grid made of the input images.\n    \"\"\"\n    if not isinstance(tensor, NDArray) or not (isinstance(tensor, NDArray) and\n                                               all(isinstance(t, NDArray) for t in tensor)):\n        raise TypeError('MXNet NDArray or list of NDArrays expected, got {}'.format(\n            str(type(tensor))))\n\n    # if list of tensors, convert to a 4D mini-batch Tensor\n    if isinstance(tensor, list):\n        tensor = op.stack(tensor, axis=0)\n\n    if tensor.ndim <= 1 or tensor.ndim > 4:\n        raise ValueError('expected 2D, 3D, or 4D NDArrays, while received ndim={}'.format(\n            tensor.ndim))\n\n    if tensor.ndim == 2:  # single image H x W\n        tensor = tensor.reshape(((1,) + tensor.shape))\n    if tensor.ndim == 3:  # single image\n        if tensor.shape[0] == 1:  # if single-channel, convert to 3-channel\n            tensor = op.concat(*(tensor, tensor, tensor), dim=0)\n        tensor = tensor.reshape((1,) + tensor.shape)\n    if tensor.ndim == 4 and tensor.shape[1] == 1:  # single-channel images\n        tensor = op.concat(*(tensor, tensor, tensor), dim=1)\n\n    if normalize is True:\n        tensor = tensor.copy()  # avoid modifying tensor in-place\n        if norm_range is not None:\n            assert isinstance(norm_range, tuple) and len(norm_range) == 2, \\\n                \"norm_range has to be a tuple (min, max) if specified. min and max are numbers\"\n\n        def norm_ip(img, val_min, val_max):\n            op.clip(img, a_min=val_min, a_max=val_max, out=img)\n            img -= val_min\n            img /= (val_max - val_min)\n\n        def norm_range_helper(t, val_range):\n            if val_range is not None:\n                norm_ip(t, val_range[0], val_range[1])\n            else:\n                norm_ip(t, t.min().asscalar(), t.max().asscalar())\n\n        if scale_each is True:\n            for t in tensor:  # loop over mini-batch dimension\n                norm_range_helper(t, norm_range)\n        else:\n            norm_range_helper(tensor, norm_range)\n\n    # if single image, just return\n    if tensor.shape[0] == 1:\n        return tensor.squeeze(axis=0)\n\n    # make the batch of images into a grid\n    nmaps = tensor.shape[0]\n    xmaps = min(nrow, nmaps)\n    ymaps = xmaps if square_image else int(np.ceil(float(nmaps) / xmaps))\n    height, width = int(tensor.shape[2] + padding), int(tensor.shape[3] + padding)\n    grid = nd.empty(shape=(3, height * ymaps + padding, width * xmaps + padding),\n                    dtype=tensor.dtype, ctx=tensor.context)\n    grid[:] = pad_value\n    k = 0\n    for y in range(ymaps):\n        for x in range(xmaps):\n            if k >= nmaps:\n                break\n            start1 = y * height + padding\n            end1 = start1 + height - padding\n            start2 = x * width + padding\n            end2 = start2 + width - padding\n            grid[:, start1:end1, start2:end2] = tensor[k]\n            k = k + 1\n    return grid", "response": "This function creates a grid of images."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _save_image(image, filename, nrow=8, padding=2, square_image=True):\n    if not isinstance(image, NDArray):\n        raise TypeError('MXNet NDArray expected, received {}'.format(str(type(image))))\n    image = _prepare_image(image, nrow=nrow, padding=padding, square_image=square_image)\n    if Image is None:\n        raise ImportError('saving image failed because PIL is not found')\n    im = Image.fromarray(image.asnumpy())\n    im.save(filename)", "response": "Saves a given Tensor into an image file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an image of format HW CHW or NCHW returns a single image of format HWC.", "response": "def _prepare_image(img, nrow=8, padding=2, square_image=False):\n    \"\"\"Given an image of format HW, CHW, or NCHW, returns a image of format HWC.\n    If the input is a batch of images, a grid of images is made by stitching them together.\n    If data type is float, values must be in the range [0, 1], and then they are rescaled to\n    range [0, 255]. If data type is 'uint8`, values are unchanged.\n    \"\"\"\n    if isinstance(img, np.ndarray):\n        img = nd.array(img, dtype=img.dtype, ctx=current_context())\n    if not isinstance(img, NDArray):\n        raise TypeError('expected MXNet NDArray or numpy.ndarray, '\n                        'while received type {}'.format(str(type(img))))\n    assert img.ndim == 2 or img.ndim == 3 or img.ndim == 4\n\n    if img.dtype == np.uint8:\n        return make_image_grid(\n            img, nrow=nrow, padding=padding, square_image=square_image).transpose((1, 2, 0))\n    elif img.dtype == np.float32 or img.dtype == np.float64:\n        min_val = img.min().asscalar()\n        max_val = img.max().asscalar()\n        if min_val < 0.0:\n            raise ValueError('expected non-negative min value from img, '\n                             'while received {}'.format(min_val))\n        if max_val > 1.0:\n            raise ValueError('expected max value from img not greater than 1, '\n                             'while received {}'.format(max_val))\n        img = make_image_grid(img, nrow=nrow, padding=padding, square_image=square_image) * 255.0\n        return img.astype(np.uint8).transpose((1, 2, 0))\n    else:\n        raise ValueError('expected input image dtype is one of uint8, float32, '\n                         'and float64, received dtype {}'.format(str(img.dtype)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_metadata_tsv(metadata, save_path):\n    if isinstance(metadata, NDArray):\n        metadata = metadata.asnumpy()\n    elif isinstance(metadata, list):\n        metadata = np.array(metadata)\n    elif not isinstance(metadata, np.ndarray):\n        raise TypeError('expected NDArray or np.ndarray or 1D/2D list, while received '\n                        'type {}'.format(str(type(metadata))))\n\n    if len(metadata.shape) > 2:\n        raise TypeError('expected a 1D/2D NDArray, np.ndarray or list, while received '\n                        'shape {}'.format(str(metadata.shape)))\n\n    if len(metadata.shape) == 1:\n        metadata = metadata.reshape(-1, 1)\n    with open(os.path.join(save_path, 'metadata.tsv'), 'w') as f:\n        for row in metadata:\n            f.write('\\t'.join([str(x) for x in row]) + '\\n')", "response": "Given an NDArray or a list of metadata e. g. labels save the flattened array into the metadata. tsv under the path provided by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_sprite_image(images, save_path):\n    if isinstance(images, np.ndarray):\n        images = nd.array(images, dtype=images.dtype, ctx=current_context())\n    elif not isinstance(images, (NDArray, np.ndarray)):\n        raise TypeError('images must be an MXNet NDArray or numpy.ndarray,'\n                        ' while received type {}'.format(str(type(images))))\n\n    assert isinstance(images, NDArray)\n    shape = images.shape\n    nrow = int(np.ceil(np.sqrt(shape[0])))\n    _save_image(\n        images, os.path.join(save_path, 'sprite.png'), nrow=nrow, padding=0, square_image=True)", "response": "Given an NDArray as a batch images make a sprite image out of it following the rule\n    defined in\n    https://www. tensorflow. org / programmers_guide / embedding\n    and save it in sprite. png under the path provided by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_embedding_config(file_path, data_dir, has_metadata=False, label_img_shape=None):\n    with open(os.path.join(file_path, 'projector_config.pbtxt'), 'a') as f:\n        s = 'embeddings {\\n'\n        s += 'tensor_name: \"{}\"\\n'.format(data_dir)\n        s += 'tensor_path: \"{}\"\\n'.format(os.path.join(data_dir, 'tensors.tsv'))\n        if has_metadata:\n            s += 'metadata_path: \"{}\"\\n'.format(os.path.join(data_dir, 'metadata.tsv'))\n        if label_img_shape is not None:\n            if len(label_img_shape) != 4:\n                logging.warning('expected 4D sprite image in the format NCHW, while received image'\n                                ' ndim=%d, skipping saving sprite'\n                                ' image info', len(label_img_shape))\n            else:\n                s += 'sprite {\\n'\n                s += 'image_path: \"{}\"\\n'.format(os.path.join(data_dir, 'sprite.png'))\n                s += 'single_image_dim: {}\\n'.format(label_img_shape[3])\n                s += 'single_image_dim: {}\\n'.format(label_img_shape[2])\n                s += '}\\n'\n        s += '}\\n'\n        f.write(s)", "response": "Adds the embedding config file to the embedding projector."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a 2D array or a numpy. ndarray as embeding save it in tensors. tsv under the path provided by the user.", "response": "def _save_embedding_tsv(data, file_path):\n    \"\"\"Given a 2D `NDarray` or a `numpy.ndarray` as embeding,\n    save it in tensors.tsv under the path provided by the user.\"\"\"\n    if isinstance(data, np.ndarray):\n        data_list = data.tolist()\n    elif isinstance(data, NDArray):\n        data_list = data.asnumpy().tolist()\n    else:\n        raise TypeError('expected NDArray of np.ndarray, while received type {}'.format(\n            str(type(data))))\n    with open(os.path.join(file_path, 'tensors.tsv'), 'w') as f:\n        for x in data_list:\n            x = [str(i) for i in x]\n            f.write('\\t'.join(x) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclean a tag. Removes illegal characters for instance.", "response": "def _clean_tag(name):\n    \"\"\"Cleans a tag. Removes illegal characters for instance.\n    Adapted from the TensorFlow function `clean_tag()` at\n    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/summary_op_util.py\n\n    Parameters\n    ----------\n        name : str\n            The original tag name to be processed.\n\n    Returns\n    -------\n        The cleaned tag name.\n    \"\"\"\n    # In the past, the first argument to summary ops was a tag, which allowed\n    # arbitrary characters. Now we are changing the first argument to be the node\n    # name. This has a number of advantages (users of summary ops now can\n    # take advantage of the tf name scope system) but risks breaking existing\n    # usage, because a much smaller set of characters are allowed in node names.\n    # This function replaces all illegal characters with _s, and logs a warning.\n    # It also strips leading slashes from the name.\n    if name is not None:\n        new_name = _INVALID_TAG_CHARACTERS.sub('_', name)\n        new_name = new_name.lstrip('/')  # Remove leading slashes\n        if new_name != name:\n            logging.warning('Summary name %s is illegal; using %s instead.', name, new_name)\n            name = new_name\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noutputs a Summary protobuf containing a single scalar value.", "response": "def scalar_summary(tag, scalar):\n    \"\"\"Outputs a `Summary` protocol buffer containing a single scalar value.\n    The generated Summary has a Tensor.proto containing the input Tensor.\n    Adapted from the TensorFlow function `scalar()` at\n    https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/summary/summary.py\n\n    Parameters\n    ----------\n      tag : str\n          A name for the generated summary. Will also serve as the series name in TensorBoard.\n      scalar : int, MXNet `NDArray`, or `numpy.ndarray`\n          A scalar value or an ndarray of shape (1,).\n\n    Returns\n    -------\n      A `Summary` protobuf of the `scalar` value.\n\n    Raises\n    ------\n      ValueError: If the scalar has the wrong shape or type.\n    \"\"\"\n    tag = _clean_tag(tag)\n    scalar = _make_numpy_array(scalar)\n    assert(scalar.squeeze().ndim == 0), 'scalar should be 0D'\n    scalar = float(scalar)\n    return Summary(value=[Summary.Value(tag=tag, simple_value=scalar)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noutputting a Summary protobuf with a histogram.", "response": "def histogram_summary(tag, values, bins):\n    \"\"\"Outputs a `Summary` protocol buffer with a histogram.\n    Adding a histogram summary makes it possible to visualize the data's distribution in\n    TensorBoard. See detailed explanation of the TensorBoard histogram dashboard at\n    https://www.tensorflow.org/get_started/tensorboard_histograms\n    This op reports an `InvalidArgument` error if any value is not finite.\n    Adapted from the TensorFlow function `histogram()` at\n    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/summary/summary.py\n\n    Parameters\n    ----------\n        tag : str\n            A name for the summary of the histogram. Will also serve as a series name in\n            TensorBoard.\n        values : MXNet `NDArray` or `numpy.ndarray`\n            Values for building the histogram.\n\n    Returns\n    -------\n        A `Summary` protobuf of the histogram.\n    \"\"\"\n    tag = _clean_tag(tag)\n    values = _make_numpy_array(values)\n    hist = _make_histogram(values.astype(float), bins)\n    return Summary(value=[Summary.Value(tag=tag, histo=hist)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_histogram(values, bins):\n    values = values.reshape(-1)\n    counts, limits = np.histogram(values, bins=bins)\n    limits = limits[1:]\n\n    sum_sq = values.dot(values)\n    return HistogramProto(min=values.min(),\n                          max=values.max(),\n                          num=len(values),\n                          sum=values.sum(),\n                          sum_squares=sum_sq,\n                          bucket_limit=limits,\n                          bucket=counts)", "response": "Converts values into a histogram proto using logic from\n    https://github. com / tensorflow / tensorflow / blob / master / lib / histogram / histogram. cc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_summary(tag, image):\n    tag = _clean_tag(tag)\n    image = _prepare_image(image)\n    image = _make_image(image)\n    return Summary(value=[Summary.Value(tag=tag, image=image)])", "response": "Outputs a Summary protobuf of the image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_image(tensor):\n    assert isinstance(tensor, NDArray)\n    if Image is None:\n        raise ImportError('need to install PIL for visualizing images')\n    height, width, channel = tensor.shape\n    tensor = _make_numpy_array(tensor)\n    image = Image.fromarray(tensor)\n    output = io.BytesIO()\n    image.save(output, format='PNG')\n    image_string = output.getvalue()\n    output.close()\n    return Summary.Image(height=height, width=width, colorspace=channel,\n                         encoded_image_string=image_string)", "response": "Converts an NDArray type image to Image protobuf"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef audio_summary(tag, audio, sample_rate=44100):\n    audio = audio.squeeze()\n    if audio.ndim != 1:\n        raise ValueError('input audio must be squeezable to 1D, input audio squeezed '\n                         'shape is {}'.format(audio.shape))\n    audio = _make_numpy_array(audio)\n    tensor_list = [int(32767.0 * x) for x in audio]\n    fio = io.BytesIO()\n    wave_writer = wave.open(fio, 'wb')\n    wave_writer.setnchannels(1)\n    wave_writer.setsampwidth(2)\n    wave_writer.setframerate(sample_rate)\n    tensor_enc = b''\n    for v in tensor_list:  # pylint: disable=invalid-name\n        tensor_enc += struct.pack('<h', v)\n    wave_writer.writeframes(tensor_enc)\n    wave_writer.close()\n    audio_string = fio.getvalue()\n    fio.close()\n    audio = Summary.Audio(sample_rate=sample_rate,\n                          num_channels=1,\n                          length_frames=len(tensor_list),\n                          encoded_audio_string=audio_string,\n                          content_type='audio/wav')\n    return Summary(value=[Summary.Value(tag=tag, audio=audio)])", "response": "Generates a Summary protobuf for the audio data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting a Summary protobuf with audio data.", "response": "def text_summary(tag, text):\n    \"\"\"Outputs a `Summary` protocol buffer with audio data.\n\n    Parameters\n    ----------\n        tag : str\n            A name for the generated summary. Will also serve as a series name in TensorBoard.\n        text : str\n            Text data.\n\n    Returns\n    -------\n        A `Summary` protobuf of the audio data.\n    \"\"\"\n    plugin_data = [SummaryMetadata.PluginData(plugin_name='text')]\n    smd = SummaryMetadata(plugin_data=plugin_data)\n    tensor = TensorProto(dtype='DT_STRING',\n                         string_val=[text.encode(encoding='utf_8')],\n                         tensor_shape=TensorShapeProto(dim=[TensorShapeProto.Dim(size=1)]))\n    return Summary(value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a summary protobuf for a precision - recall curve.", "response": "def pr_curve_summary(tag, labels, predictions, num_thresholds, weights=None):\n    \"\"\"Outputs a precision-recall curve `Summary` protocol buffer.\n\n    Parameters\n    ----------\n        tag : str\n            A tag attached to the summary. Used by TensorBoard for organization.\n        labels : MXNet `NDArray` or `numpy.ndarray`.\n            The ground truth values. A tensor of 0/1 values with arbitrary shape.\n        predictions : MXNet `NDArray` or `numpy.ndarray`.\n            A float32 tensor whose values are in the range `[0, 1]`. Dimensions must\n            match those of `labels`.\n        num_thresholds : int\n            Number of thresholds, evenly distributed in `[0, 1]`, to compute PR metrics for.\n            Should be `>= 2`. This value should be a constant integer value, not a tensor\n            that stores an integer.\n            The thresholds for computing the pr curves are calculated in the following way:\n            `width = 1.0 / (num_thresholds - 1),\n            thresholds = [0.0, 1*width, 2*width, 3*width, ..., 1.0]`.\n        weights : MXNet `NDArray` or `numpy.ndarray`.\n            Optional float32 tensor. Individual counts are multiplied by this value.\n            This tensor must be either the same shape as or broadcastable to the `labels` tensor.\n\n    Returns\n    -------\n        A `Summary` protobuf of the pr_curve.\n    \"\"\"\n    # num_thresholds > 127 results in failure of creating protobuf,\n    # probably a bug of protobuf\n    if num_thresholds > 127:\n        logging.warning('num_thresholds>127 would result in failure of creating pr_curve protobuf,'\n                        ' clipping it at 127')\n        num_thresholds = 127\n    labels = _make_numpy_array(labels)\n    predictions = _make_numpy_array(predictions)\n    if weights is not None:\n        weights = _make_numpy_array(weights)\n    data = _compute_curve(labels, predictions, num_thresholds=num_thresholds, weights=weights)\n    pr_curve_plugin_data = PrCurvePluginData(version=0,\n                                             num_thresholds=num_thresholds).SerializeToString()\n    plugin_data = [SummaryMetadata.PluginData(plugin_name='pr_curves',\n                                              content=pr_curve_plugin_data)]\n    smd = SummaryMetadata(plugin_data=plugin_data)\n    tensor = TensorProto(dtype='DT_FLOAT',\n                         float_val=data.reshape(-1).tolist(),\n                         tensor_shape=TensorShapeProto(\n                             dim=[TensorShapeProto.Dim(size=data.shape[0]),\n                                  TensorShapeProto.Dim(size=data.shape[1])]))\n    return Summary(value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_nodes_from_symbol(sym):\n    if not isinstance(sym, Symbol):\n        raise TypeError('sym must be an `mxnet.symbol.Symbol`,'\n                        ' received type {}'.format(str(type(sym))))\n    conf = json.loads(sym.tojson())\n    nodes = conf['nodes']\n    data2op = {}  # key: data id, value: list of ops to whom data is an input\n    for i, node in enumerate(nodes):\n        if node['op'] != 'null':  # node is an operator\n            input_list = node['inputs']\n            for idx in input_list:\n                if idx[0] == 0:  # do not include 'data' node in the op scope\n                    continue\n                if idx[0] in data2op:\n                    # nodes[idx[0]] is a data as an input to op nodes[i]\n                    data2op[idx[0]].append(i)\n                else:\n                    data2op[idx[0]] = [i]\n\n    # In the following, we group data with operators they belong to\n    # by attaching them with operator names as scope names.\n    # The parameters with the operator name as the prefix will be\n    # assigned with the scope name of that operator. For example,\n    # a convolution op has name 'conv', while its weight and bias\n    # have name 'conv_weight' and 'conv_bias'. In the end, the operator\n    # has scope name 'conv' prepended to its name, i.e. 'conv/conv'.\n    # The parameters are named 'conv/conv_weight' and 'conv/conv_bias'.\n    node_defs = []\n    for i, node in enumerate(nodes):\n        node_name = node['name']\n        op_name = node['op']\n        kwargs = {'op': op_name, 'name': node_name}\n        if op_name != 'null':  # node is an operator\n            inputs = []\n            input_list = node['inputs']\n            for idx in input_list:\n                input_node = nodes[idx[0]]\n                input_node_name = input_node['name']\n                if input_node['op'] != 'null':\n                    inputs.append(_scoped_name(input_node_name, input_node_name))\n                elif idx[0] in data2op and len(data2op[idx[0]]) == 1 and data2op[idx[0]][0] == i:\n                    # the data is only as an input to nodes[i], no else\n                    inputs.append(_scoped_name(node_name, input_node_name))\n                else:  # the data node has no scope name, e.g. 'data' as the input node\n                    inputs.append(input_node_name)\n            kwargs['input'] = inputs\n            kwargs['name'] = _scoped_name(node_name, node_name)\n        elif i in data2op and len(data2op[i]) == 1:\n            # node is a data node belonging to one op, find out which operator this node belongs to\n            op_node_name = nodes[data2op[i][0]]['name']\n            kwargs['name'] = _scoped_name(op_node_name, node_name)\n\n        if 'attrs' in node:\n            # TensorBoard would escape quotation marks, replace it with space\n            attr = json.dumps(node['attrs'], sort_keys=True).replace(\"\\\"\", ' ')\n            attr = {'param': AttrValue(s=attr.encode(encoding='utf-8'))}\n            kwargs['attr'] = attr\n        node_def = NodeDef(**kwargs)\n        node_defs.append(node_def)\n    return node_defs", "response": "Given a symbol and shapes return a list of NodeDef s for visualizing the\n    the graph in TensorBoard."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd spike regressors to a confound/nuisance matrix. Parameters ---------- data: pandas DataFrame object A tabulation of observations from which spike regressors should be estimated. criteria: dict{str: ('>' or '<', float)} Criteria for generating a spike regressor. If, for a given frame, the value of the variable corresponding to the key exceeds the threshold indicated by the value, then a spike regressor is created for that frame. By default, the strategy from Power 2014 is implemented: any frames with FD greater than 0.5 or standardised DV greater than 1.5 are flagged for censoring. header_prefix: str The prefix used to indicate spike regressors in the output data table. lags: list(int) A list indicating the frames to be censored relative to each flag. For instance, [0] censors the flagged frame, while [0, 1] censors both the flagged frame and the following frame. minimum_contiguous: int or None The minimum number of contiguous frames that must be unflagged for spike regression. If any series of contiguous unflagged frames is shorter than the specified minimum, then all of those frames will additionally have spike regressors implemented. concatenate: bool Indicates whether the returned object should include only spikes (if false) or all input time series and spikes (if true, default). output: str Indicates whether the output should be formatted as spike regressors ('spikes', a separate column for each outlier) or as a temporal mask ('mask', a single output column indicating the locations of outliers). Returns ------- data: pandas DataFrame object The input DataFrame with a column for each spike regressor. References ---------- Power JD, Mitra A, Laumann TO, Snyder AZ, Schlaggar BL, Petersen SE (2014) Methods to detect, characterize, and remove motion artifact in resting state fMRI. NeuroImage.", "response": "def spike_regressors(data, criteria=None, header_prefix='motion_outlier',\n                     lags=None, minimum_contiguous=None, concatenate=True,\n                     output='spikes'):\n    \"\"\"\n    Add spike regressors to a confound/nuisance matrix.\n\n    Parameters\n    ----------\n    data: pandas DataFrame object\n        A tabulation of observations from which spike regressors should be\n        estimated.\n    criteria: dict{str: ('>' or '<', float)}\n        Criteria for generating a spike regressor. If, for a given frame, the\n        value of the variable corresponding to the key exceeds the threshold\n        indicated by the value, then a spike regressor is created for that\n        frame. By default, the strategy from Power 2014 is implemented: any\n        frames with FD greater than 0.5 or standardised DV greater than 1.5\n        are flagged for censoring.\n    header_prefix: str\n        The prefix used to indicate spike regressors in the output data table.\n    lags: list(int)\n        A list indicating the frames to be censored relative to each flag.\n        For instance, [0] censors the flagged frame, while [0, 1] censors\n        both the flagged frame and the following frame.\n    minimum_contiguous: int or None\n        The minimum number of contiguous frames that must be unflagged for\n        spike regression. If any series of contiguous unflagged frames is\n        shorter than the specified minimum, then all of those frames will\n        additionally have spike regressors implemented.\n    concatenate: bool\n        Indicates whether the returned object should include only spikes\n        (if false) or all input time series and spikes (if true, default).\n    output: str\n        Indicates whether the output should be formatted as spike regressors\n        ('spikes', a separate column for each outlier) or as a temporal mask\n        ('mask', a single output column indicating the locations of outliers).\n\n    Returns\n    -------\n    data: pandas DataFrame object\n        The input DataFrame with a column for each spike regressor.\n\n    References\n    ----------\n    Power JD, Mitra A, Laumann TO, Snyder AZ, Schlaggar BL, Petersen SE (2014)\n        Methods to detect, characterize, and remove motion artifact in resting\n        state fMRI. NeuroImage.\n    \"\"\"\n    mask = {}\n    indices = range(data.shape[0])\n    lags = lags or [0]\n    criteria = criteria or {'framewise_displacement': ('>', 0.5),\n                            'std_dvars': ('>', 1.5)}\n    for metric, (criterion, threshold) in criteria.items():\n        if criterion == '<':\n            mask[metric] = set(np.where(data[metric] < threshold)[0])\n        elif criterion == '>':\n            mask[metric] = set(np.where(data[metric] > threshold)[0])\n    mask = reduce((lambda x, y: x | y), mask.values())\n\n    for lag in lags:\n        mask = set([m + lag for m in mask]) | mask\n\n    mask = mask.intersection(indices)\n    if minimum_contiguous is not None:\n        post_final = data.shape[0] + 1\n        epoch_length = np.diff(sorted(mask |\n                                      set([-1, post_final]))) - 1\n        epoch_end = sorted(mask | set([post_final]))\n        for end, length in zip(epoch_end, epoch_length):\n            if length < minimum_contiguous:\n                mask = mask | set(range(end - length, end))\n        mask = mask.intersection(indices)\n\n    if output == 'mask':\n        spikes = np.zeros(data.shape[0])\n        spikes[list(mask)] = 1\n        spikes = pd.DataFrame(data=spikes, columns=[header_prefix])\n    else:\n        spikes = np.zeros((max(indices)+1, len(mask)))\n        for i, m in enumerate(sorted(mask)):\n            spikes[m, i] = 1\n        header = ['{:s}{:02d}'.format(header_prefix, vol)\n                  for vol in range(len(mask))]\n        spikes = pd.DataFrame(data=spikes, columns=header)\n    if concatenate:\n        return pd.concat((data, spikes), axis=1)\n    else:\n        return spikes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef temporal_derivatives(order, variables, data):\n    variables_deriv = OrderedDict()\n    data_deriv = OrderedDict()\n    if 0 in order:\n        data_deriv[0] = data[variables]\n        variables_deriv[0] = variables\n        order = set(order) - set([0])\n    for o in order:\n        variables_deriv[o] = ['{}_derivative{}'.format(v, o)\n                              for v in variables]\n        data_deriv[o] = np.tile(np.nan, data[variables].shape)\n        data_deriv[o][o:, :] = np.diff(data[variables], n=o, axis=0)\n    variables_deriv = reduce((lambda x, y: x + y), variables_deriv.values())\n    data_deriv = pd.DataFrame(columns=variables_deriv,\n                              data=np.concatenate([*data_deriv.values()],\n                                                  axis=1))\n\n    return (variables_deriv, data_deriv)", "response": "Compute temporal derivative terms by the method of backwards differences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exponential_terms(order, variables, data):\n    variables_exp = OrderedDict()\n    data_exp = OrderedDict()\n    if 1 in order:\n        data_exp[1] = data[variables]\n        variables_exp[1] = variables\n        order = set(order) - set([1])\n    for o in order:\n        variables_exp[o] = ['{}_power{}'.format(v, o) for v in variables]\n        data_exp[o] = data[variables]**o\n    variables_exp = reduce((lambda x, y: x + y), variables_exp.values())\n    data_exp = pd.DataFrame(columns=variables_exp,\n                            data=np.concatenate([*data_exp.values()], axis=1))\n    return (variables_exp, data_exp)", "response": "Compute exponential expansions of the specified variables and data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a hyphenated string representing order for derivative or exponential terms into a range object that can be passed as input to the appropriate expansion function.", "response": "def _order_as_range(order):\n    \"\"\"Convert a hyphenated string representing order for derivative or\n    exponential terms into a range object that can be passed as input to the\n    appropriate expansion function.\"\"\"\n    order = order.split('-')\n    order = [int(o) for o in order]\n    if len(order) > 1:\n        order = range(order[0], (order[-1] + 1))\n    return order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_and_expand_exponential(expr, variables, data):\n    if re.search(r'\\^\\^[0-9]+$', expr):\n        order = re.compile(r'\\^\\^([0-9]+)$').findall(expr)\n        order = range(1, int(*order) + 1)\n        variables, data = exponential_terms(order, variables, data)\n    elif re.search(r'\\^[0-9]+[\\-]?[0-9]*$', expr):\n        order = re.compile(r'\\^([0-9]+[\\-]?[0-9]*)').findall(expr)\n        order = _order_as_range(*order)\n        variables, data = exponential_terms(order, variables, data)\n    return variables, data", "response": "Check if the current operation specifies exponential expansion."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_and_expand_derivative(expr, variables, data):\n    if re.search(r'^dd[0-9]+', expr):\n        order = re.compile(r'^dd([0-9]+)').findall(expr)\n        order = range(0, int(*order) + 1)\n        (variables, data) = temporal_derivatives(order, variables, data)\n    elif re.search(r'^d[0-9]+[\\-]?[0-9]*', expr):\n        order = re.compile(r'^d([0-9]+[\\-]?[0-9]*)').findall(expr)\n        order = _order_as_range(*order)\n        (variables, data) = temporal_derivatives(order, variables, data)\n    return variables, data", "response": "Check if the current operation specifies a temporal derivative. dd6x\n    specifies all derivatives up to the 6th and 5th only the\n    6th only the\n    6th only."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the current operation contains a suboperation and parse it where appropriate.", "response": "def _check_and_expand_subformula(expression, parent_data, variables, data):\n    \"\"\"Check if the current operation contains a suboperation, and parse it\n    where appropriate.\"\"\"\n    grouping_depth = 0\n    for i, char in enumerate(expression):\n        if char == '(':\n            if grouping_depth == 0:\n                formula_delimiter = i + 1\n            grouping_depth += 1\n        elif char == ')':\n            grouping_depth -= 1\n            if grouping_depth == 0:\n                expr = expression[formula_delimiter:i].strip()\n                return parse_formula(expr, parent_data)\n    return variables, data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_expression(expression, parent_data):\n    variables = None\n    data = None\n    variables, data = _check_and_expand_subformula(expression,\n                                                   parent_data,\n                                                   variables,\n                                                   data)\n    variables, data = _check_and_expand_exponential(expression,\n                                                    variables,\n                                                    data)\n    variables, data = _check_and_expand_derivative(expression,\n                                                   variables,\n                                                   data)\n    if variables is None:\n        expr = expression.strip()\n        variables = [expr]\n        data = parent_data[expr]\n    return variables, data", "response": "Parse an expression in a model formula."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _expand_shorthand(model_formula, variables):\n    wm = 'white_matter'\n    gsr = 'global_signal'\n    rps = 'trans_x + trans_y + trans_z + rot_x + rot_y + rot_z'\n    fd = 'framewise_displacement'\n    acc = _get_matches_from_data('a_comp_cor_[0-9]+', variables)\n    tcc = _get_matches_from_data('t_comp_cor_[0-9]+', variables)\n    dv = _get_matches_from_data('^std_dvars$', variables)\n    dvall = _get_matches_from_data('.*dvars', variables)\n    nss = _get_matches_from_data('non_steady_state_outlier[0-9]+',\n                                 variables)\n    spikes = _get_matches_from_data('motion_outlier[0-9]+', variables)\n\n    model_formula = re.sub('wm', wm, model_formula)\n    model_formula = re.sub('gsr', gsr, model_formula)\n    model_formula = re.sub('rps', rps, model_formula)\n    model_formula = re.sub('fd', fd, model_formula)\n    model_formula = re.sub('acc', acc, model_formula)\n    model_formula = re.sub('tcc', tcc, model_formula)\n    model_formula = re.sub('dv', dv, model_formula)\n    model_formula = re.sub('dvall', dvall, model_formula)\n    model_formula = re.sub('nss', nss, model_formula)\n    model_formula = re.sub('spikes', spikes, model_formula)\n\n    formula_variables = _get_variables_from_formula(model_formula)\n    others = ' + '.join(set(variables) - set(formula_variables))\n    model_formula = re.sub('others', others, model_formula)\n    return model_formula", "response": "Expand shorthand terms in the model formula."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreordering the columns of a confound matrix such that the columns are in the same order as the input data with any expansion columns inserted immediately after the originals.", "response": "def _unscramble_regressor_columns(parent_data, data):\n    \"\"\"Reorder the columns of a confound matrix such that the columns are in\n    the same order as the input data with any expansion columns inserted\n    immediately after the originals.\n    \"\"\"\n    matches = ['_power[0-9]+', '_derivative[0-9]+']\n    var = OrderedDict((c, deque()) for c in parent_data.columns)\n    for c in data.columns:\n        col = c\n        for m in matches:\n            col = re.sub(m, '', col)\n        if col == c:\n            var[col].appendleft(c)\n        else:\n            var[col].append(c)\n    unscrambled = reduce((lambda x, y: x + y), var.values())\n    return data[[*unscrambled]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_formula(model_formula, parent_data, unscramble=False):\n    variables = {}\n    data = {}\n    expr_delimiter = 0\n    grouping_depth = 0\n    model_formula = _expand_shorthand(model_formula, parent_data.columns)\n    for i, char in enumerate(model_formula):\n        if char == '(':\n            grouping_depth += 1\n        elif char == ')':\n            grouping_depth -= 1\n        elif grouping_depth == 0 and char == '+':\n            expression = model_formula[expr_delimiter:i].strip()\n            variables[expression] = None\n            data[expression] = None\n            expr_delimiter = i + 1\n    expression = model_formula[expr_delimiter:].strip()\n    variables[expression] = None\n    data[expression] = None\n    for expression in list(variables):\n        if expression[0] == '(' and expression[-1] == ')':\n            (variables[expression],\n             data[expression]) = parse_formula(expression[1:-1],\n                                               parent_data)\n        else:\n            (variables[expression],\n             data[expression]) = parse_expression(expression,\n                                                  parent_data)\n    variables = list(set(reduce((lambda x, y: x + y), variables.values())))\n    data = pd.concat((data.values()), axis=1)\n\n    if unscramble:\n        data = _unscramble_regressor_columns(parent_data, data)\n\n    return variables, data", "response": "Recursively parse a model formula and return a list of variables and dataframes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes a GIFTI surface workflow from a FreeSurfer subject directory.", "response": "def init_gifti_surface_wf(name='gifti_surface_wf',\n                          subjects_dir=getenv('SUBJECTS_DIR', None)):\n    \"\"\"\n    This workflow prepares GIFTI surfaces from a FreeSurfer subjects directory\n    If midthickness (or graymid) surfaces do not exist, they are generated and\n    saved to the subject directory as ``lh/rh.midthickness``.\n    These, along with the gray/white matter boundary (``lh/rh.smoothwm``), pial\n    sufaces (``lh/rh.pial``) and inflated surfaces (``lh/rh.inflated``) are\n    converted to GIFTI files.\n    Additionally, the vertex coordinates are :py:class:`recentered\n    <smriprep.interfaces.NormalizeSurf>` to align with native T1w space.\n\n    .. workflow::\n        :graph2use: orig\n        :simple_form: yes\n        from fmriprep.workflows.anatomical import init_gifti_surface_wf\n        wf = init_gifti_surface_wf()\n\n    **Parameters**\n\n        subjects_dir\n            FreeSurfer SUBJECTS_DIR\n        name\n            Name for the workflow hierarchy of Nipype\n\n    **Inputs**\n\n        in_t1w\n            original (pre-``recon-all``), reference T1w image.\n        subject_id\n            FreeSurfer subject ID\n\n    **Outputs**\n\n        surfaces\n            GIFTI surfaces for gray/white matter boundary, pial surface,\n            midthickness (or graymid) surface, and inflated surfaces.\n        surf_norm\n            Normalized (re-centered) GIFTI surfaces aligned in native T1w\n            space, corresponding to the ``surfaces`` output.\n        fsnative_to_t1w_xfm\n            LTA formatted affine transform file.\n\n    \"\"\"\n    if subjects_dir is None:\n        raise RuntimeError('``$SUBJECTS_DIR`` must be set')\n\n    workflow = pe.Workflow(name=name)\n\n    inputnode = pe.Node(niu.IdentityInterface(\n        ['in_t1w', 'subject_id']), name='inputnode')\n    outputnode = pe.Node(niu.IdentityInterface(\n        ['surfaces', 'surf_norm', 'fsnative_to_t1w_xfm']), name='outputnode')\n\n    fssource = pe.Node(nio.FreeSurferSource(subjects_dir=subjects_dir),\n                       name='fssource', run_without_submitting=True)\n\n    fsnative_2_t1_xfm = pe.Node(RobustRegister(auto_sens=True, est_int_scale=True),\n                                name='fsnative_2_t1_xfm')\n\n    midthickness = pe.MapNode(\n        MakeMidthickness(thickness=True, distance=0.5, out_name='midthickness'),\n        iterfield='in_file',\n        name='midthickness')\n\n    save_midthickness = pe.Node(nio.DataSink(\n        parameterization=False, base_directory=subjects_dir),\n        name='save_midthickness', run_without_submitting=True)\n\n    surface_list = pe.Node(niu.Merge(4, ravel_inputs=True),\n                           name='surface_list', run_without_submitting=True)\n    fs_2_gii = pe.MapNode(fs.MRIsConvert(out_datatype='gii'),\n                          iterfield='in_file', name='fs_2_gii')\n    fix_surfs = pe.MapNode(NormalizeSurf(), iterfield='in_file', name='fix_surfs')\n\n    workflow.connect([\n        (inputnode, fssource, [('subject_id', 'subject_id')]),\n        (inputnode, save_midthickness, [('subject_id', 'container')]),\n        # Generate fsnative-to-T1w transform\n        (inputnode, fsnative_2_t1_xfm, [('in_t1w', 'target_file')]),\n        (fssource, fsnative_2_t1_xfm, [('orig', 'source_file')]),\n        # Generate midthickness surfaces and save to FreeSurfer derivatives\n        (fssource, midthickness, [('smoothwm', 'in_file'),\n                                  ('graymid', 'graymid')]),\n        (midthickness, save_midthickness, [('out_file', 'surf.@graymid')]),\n        # Produce valid GIFTI surface files (dense mesh)\n        (fssource, surface_list, [('smoothwm', 'in1'),\n                                  ('pial', 'in2'),\n                                  ('inflated', 'in3')]),\n        (save_midthickness, surface_list, [('out_file', 'in4')]),\n        (surface_list, fs_2_gii, [('out', 'in_file')]),\n        (fs_2_gii, fix_surfs, [('converted', 'in_file')]),\n        (fsnative_2_t1_xfm, fix_surfs, [('out_reg_file', 'transform_file')]),\n        (fsnative_2_t1_xfm, outputnode, [('out_reg_file', 'fsnative_to_t1w_xfm')]),\n        (fix_surfs, outputnode, [('out_file', 'surf_norm')]),\n        (fs_2_gii, outputnode, [('converted', 'surfaces')]),\n    ])\n\n    return workflow"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a binary mask to an image.", "response": "def mask(in_file, mask_file, new_name):\n    \"\"\"\n    Apply a binary mask to an image.\n\n    Parameters\n    ----------\n    in_file : str\n        Path to a NIfTI file to mask\n    mask_file : str\n        Path to a binary mask\n    new_name : str\n        Path/filename for the masked output image.\n\n    Returns\n    -------\n    str\n        Absolute path of the masked output image.\n\n    Notes\n    -----\n    in_file and mask_file must be in the same\n    image space and have the same dimensions.\n    \"\"\"\n    import nibabel as nb\n    import os\n    # Load the input image\n    in_nii = nb.load(in_file)\n    # Load the mask image\n    mask_nii = nb.load(mask_file)\n    # Set all non-mask voxels in the input file to zero.\n    data = in_nii.get_data()\n    data[mask_nii.get_data() == 0] = 0\n    # Save the new masked image.\n    new_nii = nb.Nifti1Image(data, in_nii.affine, in_nii.header)\n    new_nii.to_filename(new_name)\n    return os.path.abspath(new_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_cfm(in_file, lesion_mask=None, global_mask=True, out_path=None):\n    import os\n    import numpy as np\n    import nibabel as nb\n    from nipype.utils.filemanip import fname_presuffix\n\n    if out_path is None:\n        out_path = fname_presuffix(in_file, suffix='_cfm', newpath=os.getcwd())\n    else:\n        out_path = os.path.abspath(out_path)\n\n    if not global_mask and not lesion_mask:\n        NIWORKFLOWS_LOG.warning(\n            'No lesion mask was provided and global_mask not requested, '\n            'therefore the original mask will not be modified.')\n\n    # Load the input image\n    in_img = nb.load(in_file)\n\n    # If we want a global mask, create one based on the input image.\n    data = np.ones(in_img.shape, dtype=np.uint8) if global_mask else in_img.get_data()\n    if set(np.unique(data)) - {0, 1}:\n        raise ValueError(\"`global_mask` must be true if `in_file` is not a binary mask\")\n\n    # If a lesion mask was provided, combine it with the secondary mask.\n    if lesion_mask is not None:\n        # Reorient the lesion mask and get the data.\n        lm_img = nb.as_closest_canonical(nb.load(lesion_mask))\n\n        # Subtract lesion mask from secondary mask, set negatives to 0\n        data = np.fmax(data - lm_img.get_data(), 0)\n        # Cost function mask will be created from subtraction\n    # Otherwise, CFM will be created from global mask\n\n    cfm_img = nb.Nifti1Image(data, in_img.affine, in_img.header)\n\n    # Save the cost function mask.\n    cfm_img.set_data_dtype(np.uint8)\n    cfm_img.to_filename(out_path)\n\n    return out_path", "response": "Create a new cost function mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_settings(self):\n        # If user-defined settings exist...\n        if isdefined(self.inputs.settings):\n            # Note this in the log and return those settings.\n            NIWORKFLOWS_LOG.info('User-defined settings, overriding defaults')\n            return self.inputs.settings\n\n        # Define a prefix for output files based on the modality of the moving image.\n        filestart = '{}-mni_registration_{}_'.format(\n            self.inputs.moving.lower(), self.inputs.flavor)\n\n        # Get a list of settings files that match the flavor.\n        filenames = [i for i in pkgr.resource_listdir('niworkflows', 'data')\n                     if i.startswith(filestart) and i.endswith('.json')]\n        # Return the settings files.\n        return [pkgr.resource_filename('niworkflows.data', f)\n                for f in sorted(filenames)]", "response": "Return any settings that exist for the user and any pre - defined settings files that exist for the image modalities to be registered."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_ants_args(self):\n        args = {'moving_image': self.inputs.moving_image,\n                'num_threads': self.inputs.num_threads,\n                'float': self.inputs.float,\n                'terminal_output': 'file',\n                'write_composite_transform': True,\n                'initial_moving_transform': self.inputs.initial_moving_transform}\n\n        \"\"\"\n        Moving image handling - The following truth table maps out the intended action\n        sequence. Future refactoring may more directly encode this.\n\n        moving_mask and lesion_mask are files\n        True = file\n        False = None\n\n        | moving_mask | explicit_masking | lesion_mask | action\n        |-------------|------------------|-------------|-------------------------------------------\n        | True        | True             | True        | Update `moving_image` after applying\n        |             |                  |             | mask.\n        |             |                  |             | Set `moving_image_masks` applying\n        |             |                  |             | `create_cfm` with `global_mask=True`.\n        |-------------|------------------|-------------|-------------------------------------------\n        | True        | True             | False       | Update `moving_image` after applying\n        |             |                  |             | mask.\n        |-------------|------------------|-------------|-------------------------------------------\n        | True        | False            | True        | Set `moving_image_masks` applying\n        |             |                  |             | `create_cfm` with `global_mask=False`\n        |-------------|------------------|-------------|-------------------------------------------\n        | True        | False            | False       | args['moving_image_masks'] = moving_mask\n        |-------------|------------------|-------------|-------------------------------------------\n        | False       | *                | True        | Set `moving_image_masks` applying\n        |             |                  |             | `create_cfm` with `global_mask=True`\n        |-------------|------------------|-------------|-------------------------------------------\n        | False       | *                | False       | No action\n        \"\"\"\n        # If a moving mask is provided...\n        if isdefined(self.inputs.moving_mask):\n            # If explicit masking is enabled...\n            if self.inputs.explicit_masking:\n                # Mask the moving image.\n                # Do not use a moving mask during registration.\n                args['moving_image'] = mask(\n                    self.inputs.moving_image,\n                    self.inputs.moving_mask,\n                    \"moving_masked.nii.gz\")\n\n            # If explicit masking is disabled...\n            else:\n                # Use the moving mask during registration.\n                # Do not mask the moving image.\n                args['moving_image_masks'] = self.inputs.moving_mask\n\n            # If a lesion mask is also provided...\n            if isdefined(self.inputs.lesion_mask):\n                # Create a cost function mask with the form:\n                # [global mask - lesion mask] (if explicit masking is enabled)\n                # [moving mask - lesion mask] (if explicit masking is disabled)\n                # Use this as the moving mask.\n                args['moving_image_masks'] = create_cfm(\n                    self.inputs.moving_mask,\n                    lesion_mask=self.inputs.lesion_mask,\n                    global_mask=self.inputs.explicit_masking)\n\n        # If no moving mask is provided...\n        # But a lesion mask *IS* provided...\n        elif isdefined(self.inputs.lesion_mask):\n            # Create a cost function mask with the form: [global mask - lesion mask]\n            # Use this as the moving mask.\n            args['moving_image_masks'] = create_cfm(\n                self.inputs.moving_image,\n                lesion_mask=self.inputs.lesion_mask,\n                global_mask=True)\n\n        \"\"\"\n        Reference image handling - The following truth table maps out the intended action\n        sequence. Future refactoring may more directly encode this.\n\n        reference_mask and lesion_mask are files\n        True = file\n        False = None\n\n        | reference_mask | explicit_masking | lesion_mask | action\n        |----------------|------------------|-------------|----------------------------------------\n        | True           | True             | True        | Update `fixed_image` after applying\n        |                |                  |             | mask.\n        |                |                  |             | Set `fixed_image_masks` applying\n        |                |                  |             | `create_cfm` with `global_mask=True`.\n        |----------------|------------------|-------------|----------------------------------------\n        | True           | True             | False       | Update `fixed_image` after applying\n        |                |                  |             | mask.\n        |----------------|------------------|-------------|----------------------------------------\n        | True           | False            | True        | Set `fixed_image_masks` applying\n        |                |                  |             | `create_cfm` with `global_mask=False`\n        |----------------|------------------|-------------|----------------------------------------\n        | True           | False            | False       | args['fixed_image_masks'] = fixed_mask\n        |----------------|------------------|-------------|----------------------------------------\n        | False          | *                | True        | Set `fixed_image_masks` applying\n        |                |                  |             | `create_cfm` with `global_mask=True`\n        |----------------|------------------|-------------|----------------------------------------\n        | False          | *                | False       | No action\n        \"\"\"\n        # If a reference image is provided...\n        if isdefined(self.inputs.reference_image):\n            # Use the reference image as the fixed image.\n            args['fixed_image'] = self.inputs.reference_image\n\n            # If a reference mask is provided...\n            if isdefined(self.inputs.reference_mask):\n                # If explicit masking is enabled...\n                if self.inputs.explicit_masking:\n                    # Mask the reference image.\n                    # Do not use a fixed mask during registration.\n                    args['fixed_image'] = mask(\n                        self.inputs.reference_image,\n                        self.inputs.reference_mask,\n                        \"fixed_masked.nii.gz\")\n\n                    # If a lesion mask is also provided...\n                    if isdefined(self.inputs.lesion_mask):\n                        # Create a cost function mask with the form: [global mask]\n                        # Use this as the fixed mask.\n                        args['fixed_image_masks'] = create_cfm(\n                            self.inputs.reference_mask,\n                            lesion_mask=None,\n                            global_mask=True)\n\n                # If a reference mask is provided...\n                # But explicit masking is disabled...\n                else:\n                    # Use the reference mask as the fixed mask during registration.\n                    # Do not mask the fixed image.\n                    args['fixed_image_masks'] = self.inputs.reference_mask\n\n            # If no reference mask is provided...\n            # But a lesion mask *IS* provided ...\n            elif isdefined(self.inputs.lesion_mask):\n                # Create a cost function mask with the form: [global mask]\n                # Use this as the fixed mask\n                args['fixed_image_masks'] = create_cfm(\n                    self.inputs.reference_image,\n                    lesion_mask=None,\n                    global_mask=True)\n\n        # If no reference image is provided, fall back to the default template.\n        else:\n            # Raise an error if the user specifies an unsupported image orientation.\n            if self.inputs.orientation == 'LAS':\n                raise NotImplementedError\n\n            # Set the template resolution.\n            resolution = self.inputs.template_resolution\n            # Get the template specified by the user.\n            ref_template = get_template(self.inputs.template, resolution=resolution,\n                                        desc=None, suffix=self.inputs.reference)\n            ref_mask = get_template(self.inputs.template, resolution=resolution,\n                                    desc='brain', suffix='mask')\n\n            # Default is explicit masking disabled\n            args['fixed_image'] = str(ref_template)\n            # Use the template mask as the fixed mask.\n            args['fixed_image_masks'] = str(ref_mask)\n\n            # Overwrite defaults if explicit masking\n            if self.inputs.explicit_masking:\n                # Mask the template image with the template mask.\n                args['fixed_image'] = mask(str(ref_template), str(ref_mask),\n                                           \"fixed_masked.nii.gz\")\n                # Do not use a fixed mask during registration.\n                args.pop('fixed_image_masks', None)\n\n                # If a lesion mask is provided...\n                if isdefined(self.inputs.lesion_mask):\n                    # Create a cost function mask with the form: [global mask]\n                    # Use this as the fixed mask.\n                    args['fixed_image_masks'] = create_cfm(\n                        str(ref_mask), lesion_mask=None, global_mask=True)\n\n        return args", "response": "Get the arguments for the antenna command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _post_run_hook(self, runtime):\n        self._fixed_image = self.inputs.after\n        self._moving_image = self.inputs.before\n        self._contour = self.inputs.wm_seg if isdefined(self.inputs.wm_seg) else None\n        NIWORKFLOWS_LOG.info(\n            'Report - setting before (%s) and after (%s) images',\n            self._fixed_image, self._moving_image)\n\n        return super(SimpleBeforeAfterRPT, self)._post_run_hook(runtime)", "response": "set internal variables based on the internal variables"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload a file from the specified url and store it in the specified dataset_dir.", "response": "def fetch_file(dataset_name, url, dataset_dir, dataset_prefix=None,\n               default_paths=None, filetype=None, resume=True, overwrite=False,\n               md5sum=None, username=None, password=None, retry=0,\n               verbose=1, temp_downloads=None):\n    \"\"\"Load requested file, downloading it if needed or requested.\n\n    :param str url: contains the url of the file to be downloaded.\n    :param str dataset_dir: path of the data directory. Used for data\n        storage in the specified location.\n    :param bool resume: if true, try to resume partially downloaded files\n    :param overwrite: if bool true and file already exists, delete it.\n    :param str md5sum: MD5 sum of the file. Checked if download of the file\n        is required\n    :param str username: username used for basic HTTP authentication\n    :param str password: password used for basic HTTP authentication\n    :param int verbose: verbosity level (0 means no message).\n    :returns: absolute path of downloaded file\n    :rtype: str\n\n    ..note::\n\n      If, for any reason, the download procedure fails, all downloaded files are\n      removed.\n\n\n    \"\"\"\n    final_path, cached = _get_dataset(dataset_name, dataset_prefix=dataset_prefix,\n                                      data_dir=dataset_dir, default_paths=default_paths,\n                                      verbose=verbose)\n    if cached and not overwrite:\n        return final_path\n\n    data_dir = final_path.parent\n\n    if temp_downloads is None:\n        temp_downloads = NIWORKFLOWS_CACHE_DIR / 'downloads'\n    temp_downloads = Path(temp_downloads)\n\n    temp_downloads.mkdir(parents=True, exist_ok=True)\n\n    # Determine filename using URL\n    parse = urlparse(url)\n    file_name = op.basename(parse.path)\n    if file_name == '':\n        file_name = _md5_hash(parse.path)\n\n        if filetype is not None:\n            file_name += filetype\n\n    temp_full_path = temp_downloads / file_name\n    temp_part_path = temp_full_path.with_name(file_name + '.part')\n\n    if overwrite:\n        shutil.rmtree(str(dataset_dir), ignore_errors=True)\n\n        if temp_full_path.exists():\n            temp_full_path.unlink()\n\n    t_0 = time.time()\n    local_file = None\n    initial_size = 0\n\n    # Download data\n    request = Request(url)\n    request.add_header('Connection', 'Keep-Alive')\n    if username is not None and password is not None:\n        if not url.startswith('https'):\n            raise ValueError(\n                'Authentication was requested on a non  secured URL ({0!s}).'\n                'Request has been blocked for security reasons.'.format(url))\n        # Note: HTTPBasicAuthHandler is not fitted here because it relies\n        # on the fact that the server will return a 401 error with proper\n        # www-authentication header, which is not the case of most\n        # servers.\n        encoded_auth = base64.b64encode(\n            (username + ':' + password).encode())\n        request.add_header(b'Authorization', b'Basic ' + encoded_auth)\n    if verbose > 0:\n        displayed_url = url.split('?')[0] if verbose == 1 else url\n        NIWORKFLOWS_LOG.info('Downloading data from %s ...', displayed_url)\n    if resume and temp_part_path.exists():\n        # Download has been interrupted, we try to resume it.\n        local_file_size = temp_part_path.stat().st_size\n        # If the file exists, then only download the remainder\n        request.add_header(\"Range\", \"bytes={}-\".format(local_file_size))\n        try:\n            data = urlopen(request)\n            content_range = data.info().get('Content-Range')\n            if (content_range is None or not content_range.startswith(\n                    'bytes {}-'.format(local_file_size))):\n                raise IOError('Server does not support resuming')\n        except Exception:\n            # A wide number of errors can be raised here. HTTPError,\n            # URLError... I prefer to catch them all and rerun without\n            # resuming.\n            if verbose > 0:\n                NIWORKFLOWS_LOG.warn(\n                    'Resuming failed, try to download the whole file.')\n            return fetch_file(\n                dataset_name, url, dataset_dir,\n                resume=False, overwrite=overwrite,\n                md5sum=md5sum, username=username, password=password,\n                verbose=verbose)\n        initial_size = local_file_size\n        mode = 'ab'\n    else:\n        try:\n            data = urlopen(request)\n        except (HTTPError, URLError):\n            if retry < MAX_RETRIES:\n                if verbose > 0:\n                    NIWORKFLOWS_LOG.warn('Download failed, retrying (attempt %d)',\n                                         retry + 1)\n                time.sleep(5)\n                return fetch_file(\n                    dataset_name, url, dataset_dir, resume=False, overwrite=overwrite,\n                    md5sum=md5sum, username=username, password=password,\n                    verbose=verbose, retry=retry + 1)\n            else:\n                raise\n        mode = 'wb'\n\n    with temp_part_path.open(mode) as local_file:\n        _chunk_read_(data, local_file, report_hook=(verbose > 0),\n                     initial_size=initial_size, verbose=verbose)\n    temp_part_path.replace(temp_full_path)\n    delta_t = time.time() - t_0\n    if verbose > 0:\n        # Complete the reporting hook\n        sys.stderr.write(' ...done. ({0:.0f} seconds, {1:.0f} min)\\n'\n                         .format(delta_t, delta_t // 60))\n\n    if md5sum is not None:\n        if _md5_sum_file(temp_full_path) != md5sum:\n            raise ValueError(\"File {!s} checksum verification has failed.\"\n                             \" Dataset fetching aborted.\".format(temp_full_path))\n\n    if filetype is None:\n        fname, filetype = op.splitext(temp_full_path.name)\n        if filetype == '.gz':\n            fname, ext = op.splitext(fname)\n            filetype = ext + filetype\n\n    if filetype.startswith('.'):\n        filetype = filetype[1:]\n\n    if filetype.startswith('tar'):\n        args = 'xf' if not filetype.endswith('gz') else 'xzf'\n        sp.check_call(['tar', args, str(temp_full_path)], cwd=data_dir)\n        temp_full_path.unlink()\n        return final_path\n\n    if filetype == 'zip':\n        import zipfile\n        sys.stderr.write('Unzipping package (%s) to data path (%s)...' % (\n            temp_full_path, data_dir))\n        with zipfile.ZipFile(str(temp_full_path), 'r') as zip_ref:\n            zip_ref.extractall(data_dir)\n        sys.stderr.write('done.\\n')\n        return final_path\n\n    return final_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget data storage directory fileinfo", "response": "def _get_data_path(data_dir=None):\n    \"\"\" Get data storage directory\n\n    data_dir: str\n      Path of the data directory. Used to force data storage in\n      a specified location.\n\n    :returns:\n        a list of paths where the dataset could be stored,\n        ordered by priority\n\n    \"\"\"\n    data_dir = data_dir or ''\n\n    default_dirs = [Path(d).expanduser().resolve()\n                    for d in os.getenv('CRN_SHARED_DATA', '').split(os.pathsep)\n                    if d.strip()]\n    default_dirs += [Path(d).expanduser().resolve()\n                     for d in os.getenv('CRN_DATA', '').split(os.pathsep)\n                     if d.strip()]\n    default_dirs += [NIWORKFLOWS_CACHE_DIR]\n\n    return [Path(d).expanduser()\n            for d in data_dir.split(os.pathsep) if d.strip()] or default_dirs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_dataset(dataset_name, dataset_prefix=None,\n                 data_dir=None, default_paths=None,\n                 verbose=1):\n    \"\"\" Create if necessary and returns data directory of given dataset.\n\n    data_dir: str\n      Path of the data directory. Used to force data storage in\n      a specified location.\n    default_paths: list(str)\n      Default system paths in which the dataset may already have been installed\n      by a third party software. They will be checked first.\n    verbose: int\n      verbosity level (0 means no message).\n\n    :returns: the path of the given dataset directory.\n    :rtype: str\n\n    .. note::\n\n      This function retrieves the datasets directory (or data directory) using\n      the following priority :\n\n        1. defaults system paths\n        2. the keyword argument data_dir\n        3. the global environment variable CRN_SHARED_DATA\n        4. the user environment variable CRN_DATA\n        5. ~/.cache/stanford-crn in the user home folder\n\n\n    \"\"\"\n\n    dataset_folder = dataset_name if not dataset_prefix \\\n        else '%s%s' % (dataset_prefix, dataset_name)\n    default_paths = default_paths or ''\n    paths = [p / dataset_folder for p in _get_data_path(data_dir)]\n    all_paths = [Path(p) / dataset_folder\n                 for p in default_paths.split(os.pathsep)] + paths\n\n    # Check if the dataset folder exists somewhere and is not empty\n    for path in all_paths:\n        if path.is_dir() and list(path.iterdir()):\n            if verbose > 1:\n                NIWORKFLOWS_LOG.info(\n                    'Dataset \"%s\" already cached in %s', dataset_name, path)\n            return path, True\n\n    for path in paths:\n        if verbose > 0:\n            NIWORKFLOWS_LOG.info(\n                'Dataset \"%s\" not cached, downloading to %s', dataset_name, path)\n        path.mkdir(parents=True, exist_ok=True)\n        return path, False", "response": "Create if necessary and returns data directory of given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an absolute path for the destination of a symlink", "response": "def readlinkabs(link):\n    \"\"\"\n    Return an absolute path for the destination\n    of a symlink\n    \"\"\"\n    path = os.readlink(link)\n    if op.isabs(path):\n        return path\n    return op.join(op.dirname(link), path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the MD5 sum of a file.", "response": "def _md5_sum_file(path):\n    \"\"\" Calculates the MD5 sum of a file.\n    \"\"\"\n    with Path(path).open('rb') as fhandle:\n        md5sum = hashlib.md5()\n        while True:\n            data = fhandle.read(8192)\n            if not data:\n                break\n            md5sum.update(data)\n    return md5sum.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload a file chunk by chunk and show it.", "response": "def _chunk_read_(response, local_file, chunk_size=8192, report_hook=None,\n                 initial_size=0, total_size=None, verbose=1):\n    \"\"\"Download a file chunk by chunk and show advancement\n\n    :param urllib.response.addinfourl response: response to the download\n        request in order to get file size\n    :param str local_file: hard disk file where data should be written\n    :param int chunk_size: size of downloaded chunks. Default: 8192\n    :param bool report_hook: whether or not to show downloading advancement\n    :param int initial_size: if resuming, indicate the initial size of the file\n    :param int total_size: Expected final size of download (None means it\n        is unknown).\n    :param int verbose: verbosity level (0 means no message).\n    :returns: the downloaded file path.\n    :rtype: string\n\n    \"\"\"\n    try:\n        if total_size is None:\n            total_size = response.info().get('Content-Length').strip()\n        total_size = int(total_size) + initial_size\n    except Exception as exc:\n        if verbose > 2:\n            NIWORKFLOWS_LOG.warn('Total size of chunk could not be determined')\n            if verbose > 3:\n                NIWORKFLOWS_LOG.warn(\"Full stack trace: %s\", str(exc))\n        total_size = None\n    bytes_so_far = initial_size\n\n    t_0 = time_last_display = time.time()\n    while True:\n        chunk = response.read(chunk_size)\n        bytes_so_far += len(chunk)\n        time_last_read = time.time()\n        if (report_hook and\n                # Refresh report every half second or when download is\n                # finished.\n                (time_last_read > time_last_display + 0.5 or not chunk)):\n            _chunk_report_(bytes_so_far,\n                           total_size, initial_size, t_0)\n            time_last_display = time_last_read\n        if chunk:\n            local_file.write(chunk)\n        else:\n            break\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _chunk_report_(bytes_so_far, total_size, initial_size, t_0):\n\n    if not total_size:\n        sys.stderr.write(\"\\rDownloaded {0:d} of ? bytes.\".format(bytes_so_far))\n\n    else:\n        # Estimate remaining download time\n        total_percent = float(bytes_so_far) / total_size\n\n        current_download_size = bytes_so_far - initial_size\n        bytes_remaining = total_size - bytes_so_far\n        delta_t = time.time() - t_0\n        download_rate = current_download_size / max(1e-8, float(delta_t))\n        # Minimum rate of 0.01 bytes/s, to avoid dividing by zero.\n        time_remaining = bytes_remaining / max(0.01, download_rate)\n\n        # Trailing whitespace is to erase extra char when message length\n        # varies\n        sys.stderr.write(\n            \"\\rDownloaded {0:d} of {1:d} bytes ({2:.1f}%, {3!s} remaining)\".format(\n                bytes_so_far, total_size, total_percent * 100, _format_time(time_remaining)))", "response": "Report the percentage of downloaded bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefine ANTs and FreeSurfer s brain masks.", "response": "def refine_aseg(aseg, ball_size=4):\n    \"\"\"\n    First step to reconcile ANTs' and FreeSurfer's brain masks.\n\n    Here, the ``aseg.mgz`` mask from FreeSurfer is refined in two\n    steps, using binary morphological operations:\n\n      1. With a binary closing operation the sulci are included\n         into the mask. This results in a smoother brain mask\n         that does not exclude deep, wide sulci.\n\n      2. Fill any holes (typically, there could be a hole next to\n         the pineal gland and the corpora quadrigemina if the great\n         cerebral brain is segmented out).\n\n\n    \"\"\"\n    # Read aseg data\n    bmask = aseg.copy()\n    bmask[bmask > 0] = 1\n    bmask = bmask.astype(np.uint8)\n\n    # Morphological operations\n    selem = sim.ball(ball_size)\n    newmask = sim.binary_closing(bmask, selem)\n    newmask = binary_fill_holes(newmask.astype(np.uint8), selem).astype(np.uint8)\n\n    return newmask.astype(np.uint8)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngrow the mask including pixels that have a high likelihood.", "response": "def grow_mask(anat, aseg, ants_segs=None, ww=7, zval=2.0, bw=4):\n    \"\"\"\n    Grow mask including pixels that have a high likelihood.\n    GM tissue parameters are sampled in image patches of ``ww`` size.\n\n    This is inspired on mindboggle's solution to the problem:\n    https://github.com/nipy/mindboggle/blob/master/mindboggle/guts/segment.py#L1660\n\n    \"\"\"\n    selem = sim.ball(bw)\n\n    if ants_segs is None:\n        ants_segs = np.zeros_like(aseg, dtype=np.uint8)\n\n    aseg[aseg == 42] = 3  # Collapse both hemispheres\n    gm = anat.copy()\n    gm[aseg != 3] = 0\n\n    refined = refine_aseg(aseg)\n    newrefmask = sim.binary_dilation(refined, selem) - refined\n    indices = np.argwhere(newrefmask > 0)\n    for pixel in indices:\n        # When ATROPOS identified the pixel as GM, set and carry on\n        if ants_segs[tuple(pixel)] == 2:\n            refined[tuple(pixel)] = 1\n            continue\n\n        window = gm[\n            pixel[0] - ww:pixel[0] + ww,\n            pixel[1] - ww:pixel[1] + ww,\n            pixel[2] - ww:pixel[2] + ww\n        ]\n        if np.any(window > 0):\n            mu = window[window > 0].mean()\n            sigma = max(window[window > 0].std(), 1.e-5)\n            zstat = abs(anat[tuple(pixel)] - mu) / sigma\n            refined[tuple(pixel)] = int(zstat < zval)\n\n    refined = sim.binary_opening(refined, selem)\n    return refined"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef medial_wall_to_nan(in_file, subjects_dir, target_subject, newpath=None):\n    import nibabel as nb\n    import numpy as np\n    import os\n\n    fn = os.path.basename(in_file)\n    if not target_subject.startswith('fs'):\n        return in_file\n\n    cortex = nb.freesurfer.read_label(os.path.join(\n        subjects_dir, target_subject, 'label', '{}.cortex.label'.format(fn[:2])))\n    func = nb.load(in_file)\n    medial = np.delete(np.arange(len(func.darrays[0].data)), cortex)\n    for darray in func.darrays:\n        darray.data[medial] = np.nan\n\n    out_file = os.path.join(newpath or os.getcwd(), fn)\n    func.to_filename(out_file)\n    return out_file", "response": "Convert values on medial wall to NaNs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngrabbing signature and summary", "response": "def _parse_summary(self):\n        \"\"\"Grab signature (if given) and summary\"\"\"\n        if self._is_at_section():\n            return\n\n        # If several signatures present, take the last one\n        while True:\n            summary = self._doc.read_to_next_empty_line()\n            summary_str = \" \".join([s.strip() for s in summary]).strip()\n            if re.compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\(.*\\)$').match(summary_str):\n                self['Signature'] = summary_str\n                if not self._is_at_section():\n                    continue\n            break\n\n        if summary is not None:\n            self['Summary'] = summary\n\n        if not self._is_at_section():\n            self['Extended Summary'] = self._read_to_next_section()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing nine slices, three per axis, of an\n        arbitrary volume of `in_files`, with the resulting segmentation\n        overlaid '''\n        outputs = self.aggregate_outputs(runtime=runtime)\n        self._anat_file = os.path.join(outputs.subjects_dir,\n                                       outputs.subject_id,\n                                       'mri', 'brain.mgz')\n        self._contour = os.path.join(outputs.subjects_dir,\n                                     outputs.subject_id,\n                                     'mri', 'ribbon.mgz')\n        self._masked = False\n\n        NIWORKFLOWS_LOG.info('Generating report for ReconAll (subject %s)',\n                             outputs.subject_id)\n\n        return super(ReconAllRPT, self)._post_run_hook(runtime)", "response": "Generate a report showing nine slices three per axis arbitrary volume of in_files and segmentation\n        overlaid"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a report showing nine slices, three per axis, of an arbitrary volume of `in_files`, with the resulting segmentation overlaid", "response": "def _post_run_hook(self, runtime):\n        ''' generates a report showing nine slices, three per axis, of an\n        arbitrary volume of `in_files`, with the resulting segmentation\n        overlaid '''\n        outputs = self.aggregate_outputs(runtime=runtime)\n        self._melodic_dir = outputs.out_dir\n\n        NIWORKFLOWS_LOG.info('Generating report for MELODIC')\n\n        return super(MELODICRPT, self)._post_run_hook(runtime)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_link_node(rawtext, app, type, slug, options):\n\n    try:\n        base = app.config.github_project_url\n        if not base:\n            raise AttributeError\n        if not base.endswith('/'):\n            base += '/'\n    except AttributeError as err:\n        raise ValueError('github_project_url configuration value is not set (%s)' % str(err))\n\n    ref = base + type + '/' + slug + '/'\n    set_classes(options)\n    prefix = \"#\"\n    if type == 'pull':\n        prefix = \"PR \" + prefix\n    node = nodes.reference(rawtext, prefix + utils.unescape(slug), refuri=ref,\n                           **options)\n    return node", "response": "Create a link node to a github resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlinks to a GitHub issue.", "response": "def ghissue_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"Link to a GitHub issue.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n\n    try:\n        issue_num = int(text)\n        if issue_num <= 0:\n            raise ValueError\n    except ValueError:\n        msg = inliner.reporter.error(\n            'GitHub issue number must be a number greater than or equal to 1; '\n            '\"%s\" is invalid.' % text, line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n    app = inliner.document.settings.env.app\n    #app.info('issue %r' % text)\n    if 'pull' in name.lower():\n        category = 'pull'\n    elif 'issue' in name.lower():\n        category = 'issues'\n    else:\n        msg = inliner.reporter.error(\n            'GitHub roles include \"ghpull\" and \"ghissue\", '\n            '\"%s\" is invalid.' % name, line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n    node = make_link_node(rawtext, app, category, str(issue_num), options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlink to a GitHub user.", "response": "def ghuser_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"Link to a GitHub user.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n    app = inliner.document.settings.env.app\n    #app.info('user link %r' % text)\n    ref = 'https://www.github.com/' + text\n    node = nodes.reference(rawtext, text, refuri=ref, **options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlinking to a GitHub commit role.", "response": "def ghcommit_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"Link to a GitHub commit.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n    app = inliner.document.settings.env.app\n    #app.info('user link %r' % text)\n    try:\n        base = app.config.github_project_url\n        if not base:\n            raise AttributeError\n        if not base.endswith('/'):\n            base += '/'\n    except AttributeError as err:\n        raise ValueError('github_project_url configuration value is not set (%s)' % str(err))\n\n    ref = base + text\n    node = nodes.reference(rawtext, text[:6], refuri=ref, **options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(app):\n    app.info('Initializing GitHub plugin')\n    app.add_role('ghissue', ghissue_role)\n    app.add_role('ghpull', ghissue_role)\n    app.add_role('ghuser', ghuser_role)\n    app.add_role('ghcommit', ghcommit_role)\n    app.add_config_value('github_project_url', None, 'env')\n    return", "response": "Install the plugin.\n    \n    :param app: Sphinx application context."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the package name of the current object.", "response": "def set_package_name(self, package_name):\n        ''' Set package_name\n\n        >>> docwriter = ApiDocWriter('sphinx')\n        >>> import sphinx\n        >>> docwriter.root_path == sphinx.__path__[0]\n        True\n        >>> docwriter.package_name = 'docutils'\n        >>> import docutils\n        >>> docwriter.root_path == docutils.__path__[0]\n        True\n        '''\n        # It's also possible to imagine caching the module parsing here\n        self._package_name = package_name\n        root_module = self._import(package_name)\n        self.root_path = root_module.__path__[-1]\n        self.written_modules = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of module names that are part of the current package.", "response": "def discover_modules(self):\n        ''' Return module sequence discovered from ``self.package_name``\n\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        mods : sequence\n            Sequence of module names within ``self.package_name``\n\n        Examples\n        --------\n        >>> dw = ApiDocWriter('sphinx')\n        >>> mods = dw.discover_modules()\n        >>> 'sphinx.util' in mods\n        True\n        >>> dw.package_skip_patterns.append('\\.util$')\n        >>> 'sphinx.util' in dw.discover_modules()\n        False\n        >>>\n        '''\n        modules = [self.package_name]\n        # raw directory parsing\n        for dirpath, dirnames, filenames in os.walk(self.root_path):\n            # Check directory names for packages\n            root_uri = self._path2uri(os.path.join(self.root_path,\n                                                   dirpath))\n\n            # Normally, we'd only iterate over dirnames, but since\n            # dipy does not import a whole bunch of modules we'll\n            # include those here as well (the *.py filenames).\n            filenames = [f[:-3] for f in filenames if\n                         f.endswith('.py') and not f.startswith('__init__')]\n            for filename in filenames:\n                package_uri = '/'.join((dirpath, filename))\n\n            for subpkg_name in dirnames + filenames:\n                package_uri = '.'.join((root_uri, subpkg_name))\n                package_path = self._uri2path(package_uri)\n                if (package_path and\n                    self._survives_exclude(package_uri, 'package')):\n                    modules.append(package_uri)\n\n        return sorted(modules)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect participants in a BIDS directory and return a list of participants.", "response": "def collect_participants(bids_dir, participant_label=None, strict=False,\n                         bids_validate=True):\n    \"\"\"\n    List the participants under the BIDS root and checks that participants\n    designated with the participant_label argument exist in that folder.\n    Returns the list of participants to be finally processed.\n    Requesting all subjects in a BIDS directory root:\n    >>> collect_participants(str(datadir / 'ds114'), bids_validate=False)\n    ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n\n    Requesting two subjects, given their IDs:\n    >>> collect_participants(str(datadir / 'ds114'), participant_label=['02', '04'],\n    ...                      bids_validate=False)\n    ['02', '04']\n\n    Requesting two subjects, given their IDs (works with 'sub-' prefixes):\n    >>> collect_participants(str(datadir / 'ds114'), participant_label=['sub-02', 'sub-04'],\n    ...                      bids_validate=False)\n    ['02', '04']\n\n    Requesting two subjects, but one does not exist:\n    >>> collect_participants(str(datadir / 'ds114'), participant_label=['02', '14'],\n    ...                      bids_validate=False)\n    ['02']\n    >>> collect_participants(\n    ...     str(datadir / 'ds114'), participant_label=['02', '14'],\n    ...     strict=True, bids_validate=False)  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n    fmriprep.utils.bids.BIDSError:\n    ...\n    \"\"\"\n\n    if isinstance(bids_dir, BIDSLayout):\n        layout = bids_dir\n    else:\n        layout = BIDSLayout(str(bids_dir), validate=bids_validate)\n\n    all_participants = set(layout.get_subjects())\n\n    # Error: bids_dir does not contain subjects\n    if not all_participants:\n        raise BIDSError(\n            'Could not find participants. Please make sure the BIDS data '\n            'structure is present and correct. Datasets can be validated online '\n            'using the BIDS Validator (http://bids-standard.github.io/bids-validator/).\\n'\n            'If you are using Docker for Mac or Docker for Windows, you '\n            'may need to adjust your \"File sharing\" preferences.', bids_dir)\n\n    # No --participant-label was set, return all\n    if not participant_label:\n        return sorted(all_participants)\n\n    if isinstance(participant_label, str):\n        participant_label = [participant_label]\n\n    # Drop sub- prefixes\n    participant_label = [sub[4:] if sub.startswith('sub-') else sub for sub in participant_label]\n    # Remove duplicates\n    participant_label = sorted(set(participant_label))\n    # Remove labels not found\n    found_label = sorted(set(participant_label) & all_participants)\n    if not found_label:\n        raise BIDSError('Could not find participants [{}]'.format(\n            ', '.join(participant_label)), bids_dir)\n\n    # Warn if some IDs were not found\n    notfound_label = sorted(set(participant_label) - all_participants)\n    if notfound_label:\n        exc = BIDSError('Some participants were not found: {}'.format(\n            ', '.join(notfound_label)), bids_dir)\n        if strict:\n            raise exc\n        warnings.warn(exc.msg, BIDSWarning)\n\n    return found_label"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollect the data for a given participant.", "response": "def collect_data(bids_dir, participant_label, task=None, echo=None,\n                 bids_validate=True):\n    \"\"\"\n    Uses pybids to retrieve the input data for a given participant\n    >>> bids_root, _ = collect_data(str(datadir / 'ds054'), '100185',\n    ...                             bids_validate=False)\n    >>> bids_root['fmap']  # doctest: +ELLIPSIS\n    ['.../ds054/sub-100185/fmap/sub-100185_magnitude1.nii.gz', \\\n'.../ds054/sub-100185/fmap/sub-100185_magnitude2.nii.gz', \\\n'.../ds054/sub-100185/fmap/sub-100185_phasediff.nii.gz']\n    >>> bids_root['bold']  # doctest: +ELLIPSIS\n    ['.../ds054/sub-100185/func/sub-100185_task-machinegame_run-01_bold.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-02_bold.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-03_bold.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-04_bold.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-05_bold.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-06_bold.nii.gz']\n    >>> bids_root['sbref']  # doctest: +ELLIPSIS\n    ['.../ds054/sub-100185/func/sub-100185_task-machinegame_run-01_sbref.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-02_sbref.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-03_sbref.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-04_sbref.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-05_sbref.nii.gz', \\\n'.../ds054/sub-100185/func/sub-100185_task-machinegame_run-06_sbref.nii.gz']\n    >>> bids_root['t1w']  # doctest: +ELLIPSIS\n    ['.../ds054/sub-100185/anat/sub-100185_T1w.nii.gz']\n    >>> bids_root['t2w']  # doctest: +ELLIPSIS\n    []\n    \"\"\"\n    if isinstance(bids_dir, BIDSLayout):\n        layout = bids_dir\n    else:\n        layout = BIDSLayout(str(bids_dir), validate=bids_validate)\n\n    queries = {\n        'fmap': {'datatype': 'fmap'},\n        'bold': {'datatype': 'func', 'suffix': 'bold'},\n        'sbref': {'datatype': 'func', 'suffix': 'sbref'},\n        'flair': {'datatype': 'anat', 'suffix': 'FLAIR'},\n        't2w': {'datatype': 'anat', 'suffix': 'T2w'},\n        't1w': {'datatype': 'anat', 'suffix': 'T1w'},\n        'roi': {'datatype': 'anat', 'suffix': 'roi'},\n    }\n\n    if task:\n        queries['bold']['task'] = task\n\n    if echo:\n        queries['bold']['echo'] = echo\n\n    subj_data = {\n        dtype: sorted(layout.get(return_type='file', subject=participant_label,\n                                 extensions=['nii', 'nii.gz'], **query))\n        for dtype, query in queries.items()}\n\n    # Special case: multi-echo BOLD, grouping echos\n    if any(['_echo-' in bold for bold in subj_data['bold']]):\n        subj_data['bold'] = group_multiecho(subj_data['bold'])\n\n    return subj_data, layout"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches metadata for a given nifti file", "response": "def get_metadata_for_nifti(in_file, bids_dir=None, validate=True):\n    \"\"\"Fetch metadata for a given nifti file\n\n    >>> metadata = get_metadata_for_nifti(\n    ...     datadir / 'ds054' / 'sub-100185' / 'fmap' / 'sub-100185_phasediff.nii.gz',\n    ...     validate=False)\n    >>> metadata['Manufacturer']\n    'SIEMENS'\n\n    >>>\n\n    \"\"\"\n    return _init_layout(in_file, bids_dir, validate).get_metadata(\n        str(in_file))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngroup multi - echo EPIs into arrays.", "response": "def group_multiecho(bold_sess):\n    \"\"\"\n    Multiplexes multi-echo EPIs into arrays. Dual-echo is a special\n    case of multi-echo, which is treated as single-echo data.\n\n    >>> bold_sess = [\"sub-01_task-rest_echo-1_run-01_bold.nii.gz\",\n    ...              \"sub-01_task-rest_echo-2_run-01_bold.nii.gz\",\n    ...              \"sub-01_task-rest_echo-1_run-02_bold.nii.gz\",\n    ...              \"sub-01_task-rest_echo-2_run-02_bold.nii.gz\",\n    ...              \"sub-01_task-rest_echo-3_run-02_bold.nii.gz\",\n    ...              \"sub-01_task-rest_run-03_bold.nii.gz\"]\n    >>> group_multiecho(bold_sess)\n    ['sub-01_task-rest_echo-1_run-01_bold.nii.gz',\n     'sub-01_task-rest_echo-2_run-01_bold.nii.gz',\n    ['sub-01_task-rest_echo-1_run-02_bold.nii.gz',\n     'sub-01_task-rest_echo-2_run-02_bold.nii.gz',\n     'sub-01_task-rest_echo-3_run-02_bold.nii.gz'],\n     'sub-01_task-rest_run-03_bold.nii.gz']\n\n    >>> bold_sess.insert(2, \"sub-01_task-rest_echo-3_run-01_bold.nii.gz\")\n    >>> group_multiecho(bold_sess)\n    [['sub-01_task-rest_echo-1_run-01_bold.nii.gz',\n      'sub-01_task-rest_echo-2_run-01_bold.nii.gz',\n      'sub-01_task-rest_echo-3_run-01_bold.nii.gz'],\n     ['sub-01_task-rest_echo-1_run-02_bold.nii.gz',\n      'sub-01_task-rest_echo-2_run-02_bold.nii.gz',\n      'sub-01_task-rest_echo-3_run-02_bold.nii.gz'],\n      'sub-01_task-rest_run-03_bold.nii.gz']\n\n    >>> bold_sess += [\"sub-01_task-beh_echo-1_run-01_bold.nii.gz\",\n    ...               \"sub-01_task-beh_echo-2_run-01_bold.nii.gz\",\n    ...               \"sub-01_task-beh_echo-1_run-02_bold.nii.gz\",\n    ...               \"sub-01_task-beh_echo-2_run-02_bold.nii.gz\",\n    ...               \"sub-01_task-beh_echo-3_run-02_bold.nii.gz\",\n    ...               \"sub-01_task-beh_run-03_bold.nii.gz\"]\n    >>> group_multiecho(bold_sess)\n    [['sub-01_task-rest_echo-1_run-01_bold.nii.gz',\n      'sub-01_task-rest_echo-2_run-01_bold.nii.gz',\n      'sub-01_task-rest_echo-3_run-01_bold.nii.gz'],\n     ['sub-01_task-rest_echo-1_run-02_bold.nii.gz',\n      'sub-01_task-rest_echo-2_run-02_bold.nii.gz',\n      'sub-01_task-rest_echo-3_run-02_bold.nii.gz'],\n      'sub-01_task-rest_run-03_bold.nii.gz',\n      'sub-01_task-beh_echo-1_run-01_bold.nii.gz',\n      'sub-01_task-beh_echo-2_run-01_bold.nii.gz',\n     ['sub-01_task-beh_echo-1_run-02_bold.nii.gz',\n      'sub-01_task-beh_echo-2_run-02_bold.nii.gz',\n      'sub-01_task-beh_echo-3_run-02_bold.nii.gz'],\n      'sub-01_task-beh_run-03_bold.nii.gz']\n\n    Some tests from https://neurostars.org/t/fmriprep-from\\\n-singularity-unboundlocalerror/3299/7\n\n    >>> bold_sess = ['sub-01_task-AudLoc_echo-1_bold.nii',\n    ...              'sub-01_task-AudLoc_echo-2_bold.nii',\n    ...              'sub-01_task-FJT_echo-1_bold.nii',\n    ...              'sub-01_task-FJT_echo-2_bold.nii',\n    ...              'sub-01_task-LDT_echo-1_bold.nii',\n    ...              'sub-01_task-LDT_echo-2_bold.nii',\n    ...              'sub-01_task-MotLoc_echo-1_bold.nii',\n    ...              'sub-01_task-MotLoc_echo-2_bold.nii']\n    >>> group_multiecho(bold_sess) == bold_sess\n    True\n\n    >>> bold_sess += ['sub-01_task-MotLoc_echo-3_bold.nii']\n    >>> groups = group_multiecho(bold_sess)\n    >>> len(groups[:-1])\n    6\n    >>> [isinstance(g, list) for g in groups]\n    [False, False, False, False, False, False, True]\n    >>> len(groups[-1])\n    3\n\n\n    \"\"\"\n    from itertools import groupby\n\n    def _grp_echos(x):\n        if '_echo-' not in x:\n            return x\n        echo = re.search(\"_echo-\\\\d*\", x).group(0)\n        return x.replace(echo, \"_echo-?\")\n\n    ses_uids = []\n    for _, bold in groupby(bold_sess, key=_grp_echos):\n        bold = list(bold)\n        # If single- or dual-echo, flatten list; keep list otherwise.\n        action = getattr(ses_uids, 'append' if len(bold) > 2 else 'extend')\n        action(bold)\n    return ses_uids"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _define_variant(self):\n        space = None\n        variants = {\n            # to be expanded once addtional spaces are supported\n            'space1': ['fsaverage5', 'MNI152NLin2009cAsym'],\n            'space2': ['fsaverage6', 'MNI152NLin2009cAsym'],\n        }\n        for sp, targets in variants.items():\n            if all(target in targets for target in\n                    [self.inputs.surface_target, self.inputs.volume_target]):\n                space = sp\n        if space is None:\n            raise NotImplementedError\n\n        variant_key = os.path.abspath('dtseries_variant.json')\n        with open(variant_key, 'w') as fp:\n            json.dump({space: variants[space]}, fp)\n        return variant_key, space", "response": "Assign arbitrary label to combination of CIFTI spaces"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts inputspec to files", "response": "def _fetch_data(self):\n        \"\"\"Converts inputspec to files\"\"\"\n        if (self.inputs.surface_target == \"fsnative\" or\n                self.inputs.volume_target != \"MNI152NLin2009cAsym\"):\n            # subject space is not support yet\n            raise NotImplementedError\n\n        annotation_files = sorted(glob(os.path.join(self.inputs.subjects_dir,\n                                                    self.inputs.surface_target,\n                                                    'label',\n                                                    '*h.aparc.annot')))\n        if not annotation_files:\n            raise IOError(\"Freesurfer annotations for %s not found in %s\" % (\n                          self.inputs.surface_target, self.inputs.subjects_dir))\n\n        label_file = str(get_template(\n            'MNI152NLin2009cAsym', resolution=2, desc='DKT31', suffix='dseg'))\n        return annotation_files, label_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_cifti_image(bold_file, label_file, annotation_files, gii_files,\n                            volume_target, surface_target, tr):\n        \"\"\"\n        Generate CIFTI image in target space\n\n        Parameters\n            bold_file : 4D BOLD timeseries\n            label_file : label atlas\n            annotation_files : FreeSurfer annotations\n            gii_files : 4D BOLD surface timeseries in GIFTI format\n            volume_target : label atlas space\n            surface_target : gii_files space\n            tr : repetition timeseries\n\n        Returns\n            out_file : BOLD data as CIFTI dtseries\n        \"\"\"\n\n        label_img = nb.load(label_file)\n        bold_img = resample_to_img(bold_file, label_img)\n\n        bold_data = bold_img.get_data()\n        timepoints = bold_img.shape[3]\n        label_data = label_img.get_data()\n\n        # set up CIFTI information\n        series_map = ci.Cifti2MatrixIndicesMap((0, ),\n                                               'CIFTI_INDEX_TYPE_SERIES',\n                                               number_of_series_points=timepoints,\n                                               series_exponent=0,\n                                               series_start=0.0,\n                                               series_step=tr,\n                                               series_unit='SECOND')\n        # Create CIFTI brain models\n        idx_offset = 0\n        brainmodels = []\n        bm_ts = np.empty((timepoints, 0))\n\n        for structure, labels in CIFTI_STRUCT_WITH_LABELS.items():\n            if labels is None:  # surface model\n                model_type = \"CIFTI_MODEL_TYPE_SURFACE\"\n                # use the corresponding annotation\n                hemi = structure.split('_')[-1]\n                annot = nb.freesurfer.read_annot(annotation_files[hemi == \"RIGHT\"])\n                # currently only supports L/R cortex\n                gii = nb.load(gii_files[hemi == \"RIGHT\"])\n                # calculate total number of vertices\n                surf_verts = len(annot[0])\n                # remove medial wall for CIFTI format\n                vert_idx = np.nonzero(annot[0] != annot[2].index(b'unknown'))[0]\n                # extract values across volumes\n                ts = np.array([tsarr.data[vert_idx] for tsarr in gii.darrays])\n\n                vert_idx = ci.Cifti2VertexIndices(vert_idx)\n                bm = ci.Cifti2BrainModel(index_offset=idx_offset,\n                                         index_count=len(vert_idx),\n                                         model_type=model_type,\n                                         brain_structure=structure,\n                                         vertex_indices=vert_idx,\n                                         n_surface_vertices=surf_verts)\n                bm_ts = np.column_stack((bm_ts, ts))\n                idx_offset += len(vert_idx)\n                brainmodels.append(bm)\n            else:\n                model_type = \"CIFTI_MODEL_TYPE_VOXELS\"\n                vox = []\n                ts = None\n                for label in labels:\n                    ijk = np.nonzero(label_data == label)\n                    ts = (bold_data[ijk] if ts is None\n                          else np.concatenate((ts, bold_data[ijk])))\n                    vox += [[ijk[0][ix], ijk[1][ix], ijk[2][ix]]\n                            for ix, row in enumerate(ts)]\n\n                bm_ts = np.column_stack((bm_ts, ts.T))\n\n                vox = ci.Cifti2VoxelIndicesIJK(vox)\n                bm = ci.Cifti2BrainModel(index_offset=idx_offset,\n                                         index_count=len(vox),\n                                         model_type=model_type,\n                                         brain_structure=structure,\n                                         voxel_indices_ijk=vox)\n                idx_offset += len(vox)\n                brainmodels.append(bm)\n\n        volume = ci.Cifti2Volume(\n            bold_img.shape[:3],\n            ci.Cifti2TransformationMatrixVoxelIndicesIJKtoXYZ(-3, bold_img.affine))\n        brainmodels.append(volume)\n\n        # create CIFTI geometry based on brainmodels\n        geometry_map = ci.Cifti2MatrixIndicesMap((1, ),\n                                                 'CIFTI_INDEX_TYPE_BRAIN_MODELS',\n                                                 maps=brainmodels)\n        # provide some metadata to CIFTI matrix\n        meta = {\n            \"target_surface\": surface_target,\n            \"target_volume\": volume_target,\n        }\n        # generate and save CIFTI image\n        matrix = ci.Cifti2Matrix()\n        matrix.append(series_map)\n        matrix.append(geometry_map)\n        matrix.metadata = ci.Cifti2MetaData(meta)\n        hdr = ci.Cifti2Header(matrix)\n        img = ci.Cifti2Image(bm_ts, hdr)\n        img.nifti_header.set_intent('NIFTI_INTENT_CONNECTIVITY_DENSE_SERIES')\n\n        _, out_base, _ = split_filename(bold_file)\n        out_file = \"{}.dtseries.nii\".format(out_base)\n        ci.save(img, out_file)\n        return os.path.join(os.getcwd(), out_file)", "response": "Generate CIFTI image in target space."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing slices from each axis of an arbitrary\n        volume of in_file, with the resulting binary brain mask overlaid '''\n\n        self._anat_file = self.inputs.in_file\n        self._mask_file = self.aggregate_outputs(runtime=runtime).mask_file\n        self._seg_files = [self._mask_file]\n        self._masked = self.inputs.mask\n\n        NIWORKFLOWS_LOG.info('Generating report for BET. file \"%s\", and mask file \"%s\"',\n                             self._anat_file, self._mask_file)\n\n        return super(BETRPT, self)._post_run_hook(runtime)", "response": "Generate a report showing slices from each axis of an arbitrary\n        volume of in_file and mask_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing slices from each axis '''\n\n        brain_extraction_mask = self.aggregate_outputs(runtime=runtime).BrainExtractionMask\n\n        if isdefined(self.inputs.keep_temporary_files) and self.inputs.keep_temporary_files == 1:\n            self._anat_file = self.aggregate_outputs(runtime=runtime).N4Corrected0\n        else:\n            self._anat_file = self.inputs.anatomical_image\n        self._mask_file = brain_extraction_mask\n        self._seg_files = [brain_extraction_mask]\n        self._masked = False\n\n        NIWORKFLOWS_LOG.info('Generating report for ANTS BrainExtraction. file \"%s\", mask \"%s\"',\n                             self._anat_file, self._mask_file)\n\n        return super(BrainExtractionRPT, self)._post_run_hook(runtime)", "response": "Generate a report showing slices from each axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing slices from each axis of an arbitrary\n        volume of in_file, with the resulting binary brain mask overlaid '''\n\n        self._anat_file = self.inputs.in_file\n        self._mask_file = self.aggregate_outputs(runtime=runtime).mask_file\n        self._seg_files = [self._mask_file]\n        self._masked = True\n\n        NIWORKFLOWS_LOG.info(\n            'Generating report for nilearn.compute_epi_mask. file \"%s\", and mask file \"%s\"',\n            self._anat_file, self._mask_file)\n\n        return super(ComputeEPIMask, self)._post_run_hook(runtime)", "response": "Generate a report showing slices from each axis of an arbitrary\n        volume of in_file and mask_file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing slices from each axis '''\n\n        assert len(self.inputs.mask_files) == 1, \\\n            \"ACompCorRPT only supports a single input mask. \" \\\n            \"A list %s was found.\" % self.inputs.mask_files\n        self._anat_file = self.inputs.realigned_file\n        self._mask_file = self.inputs.mask_files[0]\n        self._seg_files = self.inputs.mask_files\n        self._masked = False\n\n        NIWORKFLOWS_LOG.info('Generating report for aCompCor. file \"%s\", mask \"%s\"',\n                             self.inputs.realigned_file, self._mask_file)\n\n        return super(ACompCorRPT, self)._post_run_hook(runtime)", "response": "Generate a report showing slices from each axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _post_run_hook(self, runtime):\n        ''' generates a report showing slices from each axis '''\n\n        high_variance_masks = self.aggregate_outputs(runtime=runtime).high_variance_masks\n\n        assert not isinstance(high_variance_masks, list),\\\n            \"TCompCorRPT only supports a single output high variance mask. \" \\\n            \"A list %s was found.\" % str(high_variance_masks)\n        self._anat_file = self.inputs.realigned_file\n        self._mask_file = high_variance_masks\n        self._seg_files = [high_variance_masks]\n        self._masked = False\n\n        NIWORKFLOWS_LOG.info('Generating report for tCompCor. file \"%s\", mask \"%s\"',\n                             self.inputs.realigned_file,\n                             self.aggregate_outputs(runtime=runtime).high_variance_masks)\n\n        return super(TCompCorRPT, self)._post_run_hook(runtime)", "response": "Generate a report showing slices from each axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_versions():\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    root = os.path.realpath(__file__)\n\n    root_dir = os.path.dirname(root)\n    if os.path.isfile(os.path.join(root_dir, 'VERSION')):\n        with open(os.path.join(root_dir, 'VERSION')) as vfile:\n            version = vfile.readline().strip()\n\n        return {\n            \"version\": version,\n            \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": None,\n            \"date\": None\n        }\n\n    try:\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split('/'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find root of source tree\",\n                \"date\": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to compute version\", \"date\": None}", "response": "Get version information or return default if unable to do so."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_xform(img):\n    # Let nibabel convert from affine to quaternions, and recover xform\n    tmp_header = img.header.copy()\n    tmp_header.set_qform(img.affine)\n    xform = tmp_header.get_qform()\n    xform_code = 2\n\n    # Check desired codes\n    qform, qform_code = img.get_qform(coded=True)\n    sform, sform_code = img.get_sform(coded=True)\n    if all((qform is not None and np.allclose(qform, xform),\n            sform is not None and np.allclose(sform, xform),\n            int(qform_code) == xform_code, int(sform_code) == xform_code)):\n        return img\n\n    new_img = img.__class__(img.get_data(), xform, img.header)\n    # Unconditionally set sform/qform\n    new_img.set_sform(xform, xform_code)\n    new_img.set_qform(xform, xform_code)\n    return new_img", "response": "Normalizes the qform and sform matrices in an image and returns a new image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef demean(in_file, in_mask, only_mask=False, newpath=None):\n    import os\n    import numpy as np\n    import nibabel as nb\n    from nipype.utils.filemanip import fname_presuffix\n\n    out_file = fname_presuffix(in_file, suffix='_demeaned',\n                               newpath=os.getcwd())\n    nii = nb.load(in_file)\n    msk = nb.load(in_mask).get_data()\n    data = nii.get_data()\n    if only_mask:\n        data[msk > 0] -= np.median(data[msk > 0])\n    else:\n        data -= np.median(data[msk > 0])\n    nb.Nifti1Image(data, nii.affine, nii.header).to_filename(\n        out_file)\n    return out_file", "response": "Demean in_file within the mask defined by in_mask"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a NIfTI file filled with value matching properties of in_file.", "response": "def nii_ones_like(in_file, value, dtype, newpath=None):\n    \"\"\"Create a NIfTI file filled with ``value``, matching properties of ``in_file``\"\"\"\n    import os\n    import numpy as np\n    import nibabel as nb\n\n    nii = nb.load(in_file)\n    data = np.ones(nii.shape, dtype=float) * value\n\n    out_file = os.path.join(newpath or os.getcwd(), \"filled.nii.gz\")\n    nii = nb.Nifti1Image(data, nii.affine, nii.header)\n    nii.set_data_dtype(dtype)\n    nii.to_filename(out_file)\n\n    return out_file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a citation boilerplate by visiting all workflows and appending their __desc__ field.", "response": "def visit_desc(self):\n        \"\"\"\n        Builds a citation boilerplate by visiting all workflows\n        appending their ``__desc__`` field\n        \"\"\"\n        desc = []\n\n        if self.__desc__:\n            desc += [self.__desc__]\n\n        for node in pe.utils.topological_sort(self._graph)[0]:\n            if isinstance(node, LiterateWorkflow):\n                add_desc = node.visit_desc()\n                if add_desc not in desc:\n                    desc.append(add_desc)\n\n        if self.__postdesc__:\n            desc += [self.__postdesc__]\n\n        return ''.join(desc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gen_reference(fixed_image, moving_image, fov_mask=None, out_file=None,\n                   message=None, force_xform_code=None):\n    \"\"\"\n    Generates a sampling reference, and makes sure xform matrices/codes are\n    correct\n    \"\"\"\n\n    if out_file is None:\n        out_file = fname_presuffix(fixed_image,\n                                   suffix='_reference',\n                                   newpath=os.getcwd())\n\n    # Moving images may not be RAS/LPS (more generally, transverse-longitudinal-axial)\n    reoriented_moving_img = nb.as_closest_canonical(nb.load(moving_image))\n    new_zooms = reoriented_moving_img.header.get_zooms()[:3]\n\n    # Avoid small differences in reported resolution to cause changes to\n    # FOV. See https://github.com/poldracklab/fmriprep/issues/512\n    # A positive diagonal affine is RAS, hence the need to reorient above.\n    new_affine = np.diag(np.round(new_zooms, 3))\n\n    resampled = nli.resample_img(fixed_image,\n                                 target_affine=new_affine,\n                                 interpolation='nearest')\n\n    if fov_mask is not None:\n        # If we have a mask, resample again dropping (empty) samples\n        # out of the FoV.\n        fixednii = nb.load(fixed_image)\n        masknii = nb.load(fov_mask)\n\n        if np.all(masknii.shape[:3] != fixednii.shape[:3]):\n            raise RuntimeError(\n                'Fixed image and mask do not have the same dimensions.')\n\n        if not np.allclose(masknii.affine, fixednii.affine, atol=1e-5):\n            raise RuntimeError(\n                'Fixed image and mask have different affines')\n\n        # Get mask into reference space\n        masknii = nli.resample_img(fixed_image,\n                                   target_affine=new_affine,\n                                   interpolation='nearest')\n        res_shape = np.array(masknii.shape[:3])\n\n        # Calculate a bounding box for the input mask\n        # with an offset of 2 voxels per face\n        bbox = np.argwhere(masknii.get_data() > 0)\n        new_origin = np.clip(bbox.min(0) - 2, a_min=0, a_max=None)\n        new_end = np.clip(bbox.max(0) + 2, a_min=0,\n                          a_max=res_shape - 1)\n\n        # Find new origin, and set into new affine\n        new_affine_4 = resampled.affine.copy()\n        new_affine_4[:3, 3] = new_affine_4[:3, :3].dot(\n            new_origin) + new_affine_4[:3, 3]\n\n        # Calculate new shapes\n        new_shape = new_end - new_origin + 1\n        resampled = nli.resample_img(fixed_image,\n                                     target_affine=new_affine_4,\n                                     target_shape=new_shape.tolist(),\n                                     interpolation='nearest')\n\n    xform = resampled.affine  # nibabel will pick the best affine\n    _, qform_code = resampled.header.get_qform(coded=True)\n    _, sform_code = resampled.header.get_sform(coded=True)\n\n    xform_code = sform_code if sform_code > 0 else qform_code\n    if xform_code == 1:\n        xform_code = 2\n\n    if force_xform_code is not None:\n        xform_code = force_xform_code\n\n    # Keep 0, 2, 3, 4 unchanged\n    resampled.header.set_qform(xform, int(xform_code))\n    resampled.header.set_sform(xform, int(xform_code))\n    resampled.header['descrip'] = 'reference image generated by %s.' % (\n        message or '(unknown software)')\n    resampled.to_filename(out_file)\n    return out_file", "response": "Generate a sample reference for the given fixed image and moving image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting metadata from TSV format to JSON format.", "response": "def _tsv2json(in_tsv, out_json, index_column, additional_metadata=None,\n              drop_columns=None, enforce_case=True):\n    \"\"\"\n    Convert metadata from TSV format to JSON format.\n\n    Parameters\n    ----------\n    in_tsv: str\n        Path to the metadata in TSV format.\n    out_json: str\n        Path where the metadata should be saved in JSON format after\n        conversion. If this is None, then a dictionary is returned instead.\n    index_column: str\n        Name of the column in the TSV to be used as an index (top-level key in\n        the JSON).\n    additional_metadata: dict\n        Any additional metadata that should be applied to all entries in the\n        JSON.\n    drop_columns: list\n        List of columns from the input TSV to be dropped from the JSON.\n    enforce_case: bool\n        Indicates whether BIDS case conventions should be followed. Currently,\n        this means that index fields (column names in the associated data TSV)\n        use snake case and other fields use camel case.\n\n    Returns\n    -------\n    str\n        Path to the metadata saved in JSON format.\n    \"\"\"\n    import pandas as pd\n    # Adapted from https://dev.to/rrampage/snake-case-to-camel-case-and- ...\n    # back-using-regular-expressions-and-python-m9j\n    re_to_camel = r'(.*?)_([a-zA-Z0-9])'\n    re_to_snake = r'(^.+?|.*?)((?<![_A-Z])[A-Z]|(?<![_0-9])[0-9]+)'\n\n    def snake(match):\n        return '{}_{}'.format(match.group(1).lower(), match.group(2).lower())\n\n    def camel(match):\n        return '{}{}'.format(match.group(1), match.group(2).upper())\n\n    # from fmriprep\n    def less_breakable(a_string):\n        \"\"\" hardens the string to different envs (i.e. case insensitive, no\n        whitespace, '#' \"\"\"\n        return ''.join(a_string.split()).strip('#')\n\n    drop_columns = drop_columns or []\n    additional_metadata = additional_metadata or {}\n    tsv_data = pd.read_csv(in_tsv, '\\t')\n    for k, v in additional_metadata.items():\n        tsv_data[k] = v\n    for col in drop_columns:\n        tsv_data.drop(labels=col, axis='columns', inplace=True)\n    tsv_data.set_index(index_column, drop=True, inplace=True)\n    if enforce_case:\n        tsv_data.index = [re.sub(re_to_snake, snake,\n                                 less_breakable(i), 0).lower()\n                          for i in tsv_data.index]\n        tsv_data.columns = [re.sub(re_to_camel, camel,\n                                   less_breakable(i).title(), 0)\n                            for i in tsv_data.columns]\n    json_data = tsv_data.to_json(orient='index')\n    json_data = json.JSONDecoder(\n        object_pairs_hook=OrderedDict).decode(json_data)\n    if out_json is None:\n        return json_data\n\n    with open(out_json, 'w') as f:\n        json.dump(json_data, f, indent=4)\n    return out_json"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _tpm2roi(in_tpm, in_mask, mask_erosion_mm=None, erosion_mm=None,\n             mask_erosion_prop=None, erosion_prop=None, pthres=0.95,\n             newpath=None):\n    \"\"\"\n    Generate a mask from a tissue probability map\n    \"\"\"\n    tpm_img = nb.load(in_tpm)\n    roi_mask = (tpm_img.get_data() >= pthres).astype(np.uint8)\n\n    eroded_mask_file = None\n    erode_in = (mask_erosion_mm is not None and mask_erosion_mm > 0 or\n                mask_erosion_prop is not None and mask_erosion_prop < 1)\n    if erode_in:\n        eroded_mask_file = fname_presuffix(in_mask, suffix='_eroded',\n                                           newpath=newpath)\n        mask_img = nb.load(in_mask)\n        mask_data = mask_img.get_data().astype(np.uint8)\n        if mask_erosion_mm:\n            iter_n = max(int(mask_erosion_mm / max(mask_img.header.get_zooms())), 1)\n            mask_data = nd.binary_erosion(mask_data, iterations=iter_n)\n        else:\n            orig_vol = np.sum(mask_data > 0)\n            while np.sum(mask_data > 0) / orig_vol > mask_erosion_prop:\n                mask_data = nd.binary_erosion(mask_data, iterations=1)\n\n        # Store mask\n        eroded = nb.Nifti1Image(mask_data, mask_img.affine, mask_img.header)\n        eroded.set_data_dtype(np.uint8)\n        eroded.to_filename(eroded_mask_file)\n\n        # Mask TPM data (no effect if not eroded)\n        roi_mask[~mask_data] = 0\n\n    # shrinking\n    erode_out = (erosion_mm is not None and erosion_mm > 0 or\n                 erosion_prop is not None and erosion_prop < 1)\n    if erode_out:\n        if erosion_mm:\n            iter_n = max(int(erosion_mm / max(tpm_img.header.get_zooms())), 1)\n            iter_n = int(erosion_mm / max(tpm_img.header.get_zooms()))\n            roi_mask = nd.binary_erosion(roi_mask, iterations=iter_n)\n        else:\n            orig_vol = np.sum(roi_mask > 0)\n            while np.sum(roi_mask > 0) / orig_vol > erosion_prop:\n                roi_mask = nd.binary_erosion(roi_mask, iterations=1)\n\n    # Create image to resample\n    roi_fname = fname_presuffix(in_tpm, suffix='_roi', newpath=newpath)\n    roi_img = nb.Nifti1Image(roi_mask, tpm_img.affine, tpm_img.header)\n    roi_img.set_data_dtype(np.uint8)\n    roi_img.to_filename(roi_fname)\n    return roi_fname, eroded_mask_file or in_mask", "response": "Generate a mask from a tissue probability map."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the reports in the reportlets directory and creates a report in the output directory.", "response": "def run_reports(reportlets_dir, out_dir, subject_label, run_uuid, config=None,\n                packagename=None):\n    \"\"\"\n    Runs the reports\n\n    .. testsetup::\n\n    >>> from shutil import copytree\n    >>> from tempfile import TemporaryDirectory\n    >>> new_path = Path(__file__).resolve().parent.parent\n    >>> test_data_path = new_path / 'data' / 'tests' / 'work'\n    >>> tmpdir = TemporaryDirectory()\n    >>> os.chdir(tmpdir.name)  #noqa\n    >>> testdir = Path().resolve()\n    >>> data_dir = copytree(test_data_path, testdir / 'work')\n    >>> (testdir / 'fmriprep').mkdir(parents=True, exist_ok=True)\n\n    .. doctest::\n\n    >>> run_reports(str(testdir / 'work' / 'reportlets'),\n    ...             str(testdir / 'out'), '01', 'madeoutuuid')\n    0\n\n    .. testcleanup::\n\n    >>> tmpdir.cleanup()\n\n    \"\"\"\n    report = Report(Path(reportlets_dir), out_dir, run_uuid, config=config,\n                    subject_id=subject_label, packagename=packagename)\n    return report.generate_report()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index(self, config):\n        for subrep_cfg in config:\n            # First determine whether we need to split by some ordering\n            # (ie. sessions / tasks / runs), which are separated by commas.\n            orderings = [s for s in subrep_cfg.get('ordering', '').strip().split(',') if s]\n            queries = []\n            for key in orderings:\n                values = getattr(self.layout, 'get_%s%s' % (key, PLURAL_SUFFIX[key]))()\n                if values:\n                    queries.append((key, values))\n\n            if not queries:  # E.g. this is an anatomical reportlet\n                reportlets = [Reportlet(self.layout, self.out_dir, config=cfg)\n                              for cfg in subrep_cfg['reportlets']]\n            else:\n                # Do not use dictionary for queries, as we need to preserve ordering\n                # of ordering columns.\n                reportlets = []\n                entities, values = zip(*queries)\n                combinations = list(product(*values))  # e.g.: [('rest', 1), ('rest', 2)]\n\n                for c in combinations:\n                    # Set a common title for this particular combination c\n                    title = 'Reports for: %s.' % ', '.join(\n                        ['%s <span class=\"bids-entity\">%s</span>' % (entities[i], c[i])\n                         for i in range(len(c))])\n                    for cfg in subrep_cfg['reportlets']:\n                        cfg['bids'].update({entities[i]: c[i] for i in range(len(c))})\n                        rlet = Reportlet(self.layout, self.out_dir, config=cfg)\n                        if not rlet.is_empty():\n                            rlet.title = title\n                            title = None\n                            reportlets.append(rlet)\n\n            # Filter out empty reportlets\n            reportlets = [r for r in reportlets if not r.is_empty()]\n            if reportlets:\n                sub_report = SubReport(\n                    subrep_cfg['name'],\n                    isnested=len(queries) > 0,\n                    reportlets=reportlets,\n                    title=subrep_cfg.get('title'))\n                self.sections.append(sub_report)\n\n        # Populate errors sections\n        error_dir = self.out_dir / self.packagename / 'sub-{}'.format(self.subject_id) / \\\n            'log' / self.run_uuid\n        if error_dir.is_dir():\n            from ..utils.misc import read_crashfile\n            self.errors = [read_crashfile(str(f)) for f in error_dir.glob('crash*.*')]", "response": "Index the reports in the specified configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_report(self):\n        logs_path = self.out_dir / 'logs'\n\n        boilerplate = []\n        boiler_idx = 0\n\n        if (logs_path / 'CITATION.html').exists():\n            text = (logs_path / 'CITATION.html').read_text(encoding='UTF-8')\n            text = '<div class=\"boiler-html\">%s</div>' % re.compile(\n                '<body>(.*?)</body>',\n                re.DOTALL | re.IGNORECASE).findall(text)[0].strip()\n            boilerplate.append((boiler_idx, 'HTML', text))\n            boiler_idx += 1\n\n        if (logs_path / 'CITATION.md').exists():\n            text = '<pre>%s</pre>\\n' % (logs_path / 'CITATION.md').read_text(encoding='UTF-8')\n            boilerplate.append((boiler_idx, 'Markdown', text))\n            boiler_idx += 1\n\n        if (logs_path / 'CITATION.tex').exists():\n            text = (logs_path / 'CITATION.tex').read_text(encoding='UTF-8')\n            text = re.compile(\n                r'\\\\begin{document}(.*?)\\\\end{document}',\n                re.DOTALL | re.IGNORECASE).findall(text)[0].strip()\n            text = '<pre>%s</pre>\\n' % text\n            text += '<h3>Bibliography</h3>\\n'\n            text += '<pre>%s</pre>\\n' % Path(\n                pkgrf(self.packagename, 'data/boilerplate.bib')).read_text(encoding='UTF-8')\n            boilerplate.append((boiler_idx, 'LaTeX', text))\n            boiler_idx += 1\n\n        env = jinja2.Environment(\n            loader=jinja2.FileSystemLoader(searchpath=str(self.template_path.parent)),\n            trim_blocks=True, lstrip_blocks=True\n        )\n        report_tpl = env.get_template(self.template_path.name)\n        report_render = report_tpl.render(sections=self.sections, errors=self.errors,\n                                          boilerplate=boilerplate)\n\n        # Write out report\n        (self.out_dir / self.out_filename).write_text(report_render, encoding='UTF-8')\n        return len(self.errors)", "response": "Generate the final HTML report for the current page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _applytfms(args):\n    import nibabel as nb\n    from nipype.utils.filemanip import fname_presuffix\n    from niworkflows.interfaces.fixes import FixHeaderApplyTransforms as ApplyTransforms\n\n    in_file, in_xform, ifargs, index, newpath = args\n    out_file = fname_presuffix(in_file, suffix='_xform-%05d' % index,\n                               newpath=newpath, use_ext=True)\n\n    copy_dtype = ifargs.pop('copy_dtype', False)\n    xfm = ApplyTransforms(\n        input_image=in_file, transforms=in_xform, output_image=out_file, **ifargs)\n    xfm.terminal_output = 'allatonce'\n    xfm.resource_monitor = False\n    runtime = xfm.run().runtime\n\n    if copy_dtype:\n        nii = nb.load(out_file)\n        in_dtype = nb.load(in_file).get_data_dtype()\n\n        # Overwrite only iff dtypes don't match\n        if in_dtype != nii.get_data_dtype():\n            nii.set_data_dtype(in_dtype)\n            nii.to_filename(out_file)\n\n    return (out_file, runtime.cmdline)", "response": "Applies ANTs antsApplyTransforms to the input image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_surfs(in_file, transform_file, newpath=None):\n\n    img = nb.load(in_file)\n    transform = load_transform(transform_file)\n    pointset = img.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0]\n    coords = pointset.data.T\n    c_ras_keys = ('VolGeomC_R', 'VolGeomC_A', 'VolGeomC_S')\n    ras = np.array([[float(pointset.metadata[key])]\n                    for key in c_ras_keys])\n    ones = np.ones((1, coords.shape[1]), dtype=coords.dtype)\n    # Apply C_RAS translation to coordinates, then transform\n    pointset.data = transform.dot(np.vstack((coords + ras, ones)))[:3].T.astype(coords.dtype)\n\n    secondary = nb.gifti.GiftiNVPairs('AnatomicalStructureSecondary', 'MidThickness')\n    geom_type = nb.gifti.GiftiNVPairs('GeometricType', 'Anatomical')\n    has_ass = has_geo = False\n    for nvpair in pointset.meta.data:\n        # Remove C_RAS translation from metadata to avoid double-dipping in FreeSurfer\n        if nvpair.name in c_ras_keys:\n            nvpair.value = '0.000000'\n        # Check for missing metadata\n        elif nvpair.name == secondary.name:\n            has_ass = True\n        elif nvpair.name == geom_type.name:\n            has_geo = True\n    fname = os.path.basename(in_file)\n    # Update metadata for MidThickness/graymid surfaces\n    if 'midthickness' in fname.lower() or 'graymid' in fname.lower():\n        if not has_ass:\n            pointset.meta.data.insert(1, secondary)\n        if not has_geo:\n            pointset.meta.data.insert(2, geom_type)\n\n    if newpath is not None:\n        newpath = os.getcwd()\n    out_file = os.path.join(newpath, fname)\n    img.to_filename(out_file)\n    return out_file", "response": "Normalize GIFTI coordinates to fit align to native T1 space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading affine transform from file fname", "response": "def load_transform(fname):\n    \"\"\"Load affine transform from file\n\n    Parameters\n    ----------\n    fname : str or None\n        Filename of an LTA or FSL-style MAT transform file.\n        If ``None``, return an identity transform\n\n    Returns\n    -------\n    affine : (4, 4) numpy.ndarray\n    \"\"\"\n    if fname is None:\n        return np.eye(4)\n\n    if fname.endswith('.mat'):\n        return np.loadtxt(fname)\n    elif fname.endswith('.lta'):\n        with open(fname, 'rb') as fobj:\n            for line in fobj:\n                if line.startswith(b'1 4 4'):\n                    break\n            lines = fobj.readlines()[:4]\n        return np.genfromtxt(lines)\n\n    raise ValueError(\"Unknown transform type; pass FSL (.mat) or LTA (.lta)\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the normals of a triangular mesh", "response": "def vertex_normals(vertices, faces):\n    \"\"\"Calculates the normals of a triangular mesh\"\"\"\n\n    def normalize_v3(arr):\n        ''' Normalize a numpy array of 3 component vectors shape=(n,3) '''\n        lens = np.sqrt(arr[:, 0]**2 + arr[:, 1]**2 + arr[:, 2]**2)\n        arr /= lens[:, np.newaxis]\n\n    tris = vertices[faces]\n    facenorms = np.cross(tris[::, 1] - tris[::, 0], tris[::, 2] - tris[::, 0])\n    normalize_v3(facenorms)\n\n    norm = np.zeros(vertices.shape, dtype=vertices.dtype)\n    norm[faces[:, 0]] += facenorms\n    norm[faces[:, 1]] += facenorms\n    norm[faces[:, 2]] += facenorms\n    normalize_v3(norm)\n    return norm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pointcloud2ply(vertices, normals, out_file=None):\n    from pathlib import Path\n    import pandas as pd\n    from pyntcloud import PyntCloud\n    df = pd.DataFrame(np.hstack((vertices, normals)))\n    df.columns = ['x', 'y', 'z', 'nx', 'ny', 'nz']\n    cloud = PyntCloud(df)\n\n    if out_file is None:\n        out_file = Path('pointcloud.ply').resolve()\n\n    cloud.to_file(str(out_file))\n    return out_file", "response": "Converts the file from pointcloud format to PLY format"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ply2gii(in_file, metadata, out_file=None):\n    from pathlib import Path\n    from numpy import eye\n    from nibabel.gifti import (\n        GiftiMetaData, GiftiCoordSystem, GiftiImage, GiftiDataArray,\n    )\n    from pyntcloud import PyntCloud\n\n    in_file = Path(in_file)\n    surf = PyntCloud.from_file(str(in_file))\n\n    # Update centroid metadata\n    metadata.update(\n        zip(('SurfaceCenterX', 'SurfaceCenterY', 'SurfaceCenterZ'),\n            ['%.4f' % c for c in surf.centroid])\n    )\n\n    # Prepare data arrays\n    da = (\n        GiftiDataArray(\n            data=surf.xyz.astype('float32'),\n            datatype='NIFTI_TYPE_FLOAT32',\n            intent='NIFTI_INTENT_POINTSET',\n            meta=GiftiMetaData.from_dict(metadata),\n            coordsys=GiftiCoordSystem(xform=eye(4), xformspace=3)),\n        GiftiDataArray(\n            data=surf.mesh.values,\n            datatype='NIFTI_TYPE_INT32',\n            intent='NIFTI_INTENT_TRIANGLE',\n            coordsys=None))\n    surfgii = GiftiImage(darrays=da)\n\n    if out_file is None:\n        out_file = fname_presuffix(\n            in_file.name, suffix='.gii', use_ext=False, newpath=str(Path.cwd()))\n\n    surfgii.to_filename(str(out_file))\n    return out_file", "response": "Convert from ply to GIfTI"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fix_multi_T1w_source_name(in_files):\n    import os\n    from nipype.utils.filemanip import filename_to_list\n    base, in_file = os.path.split(filename_to_list(in_files)[0])\n    subject_label = in_file.split(\"_\", 1)[0].split(\"-\")[1]\n    return os.path.join(base, \"sub-%s_T1w.nii.gz\" % subject_label)", "response": "Fixes the name of a generic source when there are multiple T1s and there are multiple T1s."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps nipype s fname_presuffix to conveniently add a prefix to the list of files.", "response": "def add_suffix(in_files, suffix):\n    \"\"\"\n    Wrap nipype's fname_presuffix to conveniently just add a prefix\n\n    >>> add_suffix([\n    ...     '/path/to/sub-045_ses-test_T1w.nii.gz',\n    ...     '/path/to/sub-045_ses-retest_T1w.nii.gz'], '_test')\n    'sub-045_ses-test_T1w_test.nii.gz'\n\n    \"\"\"\n    import os.path as op\n    from nipype.utils.filemanip import fname_presuffix, filename_to_list\n    return op.basename(fname_presuffix(filename_to_list(in_files)[0],\n                                       suffix=suffix))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_txt(path):\n    from pathlib import Path\n    lines = Path(path).read_text().splitlines()\n    data = {'file': str(path)}\n    traceback_start = 0\n    if lines[0].startswith('Node'):\n        data['node'] = lines[0].split(': ', 1)[1].strip()\n        data['node_dir'] = lines[1].split(': ', 1)[1].strip()\n        inputs = []\n        cur_key = ''\n        cur_val = ''\n        for i, line in enumerate(lines[5:]):\n            if not line.strip():\n                continue\n\n            if line[0].isspace():\n                cur_val += line\n                continue\n\n            if cur_val:\n                inputs.append((cur_key, cur_val.strip()))\n\n            if line.startswith(\"Traceback (\"):\n                traceback_start = i + 5\n                break\n\n            cur_key, cur_val = tuple(line.split(' = ', 1))\n\n        data['inputs'] = sorted(inputs)\n    else:\n        data['node_dir'] = \"Node crashed before execution\"\n    data['traceback'] = '\\n'.join(lines[traceback_start:]).strip()\n    return data", "response": "Read a txt crashfile and return a dict of data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef splitext(fname):\n    from pathlib import Path\n    basename = str(Path(fname).name)\n    stem = Path(basename.rstrip('.gz')).stem\n    return stem, basename[len(stem):]", "response": "Splits a filename and extension into a stem and basename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_carpet(img, atlaslabels, detrend=True, nskip=0, size=(950, 800),\n                subplot=None, title=None, output_file=None, legend=False,\n                lut=None, tr=None):\n    \"\"\"\n    Plot an image representation of voxel intensities across time also know\n    as the \"carpet plot\" or \"Power plot\". See Jonathan Power Neuroimage\n    2017 Jul 1; 154:150-158.\n\n    Parameters\n    ----------\n\n        img : Niimg-like object\n            See http://nilearn.github.io/manipulating_images/input_output.html\n            4D input image\n        atlaslabels: ndarray\n            A 3D array of integer labels from an atlas, resampled into ``img`` space.\n        detrend : boolean, optional\n            Detrend and standardize the data prior to plotting.\n        nskip : int\n            Number of volumes at the beginning of the scan marked as nonsteady state.\n        long_cutoff : int\n            Number of TRs to consider img too long (and decimate the time direction\n            to save memory)\n        axes : matplotlib axes, optional\n            The axes used to display the plot. If None, the complete\n            figure is used.\n        title : string, optional\n            The title displayed on the figure.\n        output_file : string, or None, optional\n            The name of an image file to export the plot to. Valid extensions\n            are .png, .pdf, .svg. If output_file is not None, the plot\n            is saved to a file, and the display is closed.\n        legend : bool\n            Whether to render the average functional series with ``atlaslabels`` as\n            overlay.\n        tr : float , optional\n            Specify the TR, if specified it uses this value. If left as None,\n            # Frames is plotted instead of time.\n    \"\"\"\n\n    # Define TR and number of frames\n    notr = False\n    if tr is None:\n        notr = True\n        tr = 1.\n\n    img_nii = check_niimg_4d(img, dtype='auto',)\n    func_data = _safe_get_data(img_nii, ensure_finite=True)\n    ntsteps = func_data.shape[-1]\n\n    data = func_data[atlaslabels > 0].reshape(-1, ntsteps)\n    seg = atlaslabels[atlaslabels > 0].reshape(-1)\n\n    # Map segmentation\n    if lut is None:\n        lut = np.zeros((256, ), dtype='int')\n        lut[1:11] = 1\n        lut[255] = 2\n        lut[30:99] = 3\n        lut[100:201] = 4\n\n    # Apply lookup table\n    newsegm = lut[seg.astype(int)]\n\n    p_dec = 1 + data.shape[0] // size[0]\n    if p_dec:\n        data = data[::p_dec, :]\n        newsegm = newsegm[::p_dec]\n\n    t_dec = 1 + data.shape[1] // size[1]\n    if t_dec:\n        data = data[:, ::t_dec]\n\n    # Detrend data\n    v = (None, None)\n    if detrend:\n        data = clean(data.T, t_r=tr).T\n        v = (-2, 2)\n\n    # Order following segmentation labels\n    order = np.argsort(newsegm)[::-1]\n\n    # If subplot is not defined\n    if subplot is None:\n        subplot = mgs.GridSpec(1, 1)[0]\n\n    # Define nested GridSpec\n    wratios = [1, 100, 20]\n    gs = mgs.GridSpecFromSubplotSpec(1, 2 + int(legend), subplot_spec=subplot,\n                                     width_ratios=wratios[:2 + int(legend)],\n                                     wspace=0.0)\n\n    mycolors = ListedColormap(cm.get_cmap('tab10').colors[:4][::-1])\n\n    # Segmentation colorbar\n    ax0 = plt.subplot(gs[0])\n    ax0.set_yticks([])\n    ax0.set_xticks([])\n    ax0.imshow(newsegm[order, np.newaxis], interpolation='none', aspect='auto',\n               cmap=mycolors, vmin=1, vmax=4)\n    ax0.grid(False)\n    ax0.spines[\"left\"].set_visible(False)\n    ax0.spines[\"bottom\"].set_color('none')\n    ax0.spines[\"bottom\"].set_visible(False)\n\n    # Carpet plot\n    ax1 = plt.subplot(gs[1])\n    ax1.imshow(data[order, ...], interpolation='nearest', aspect='auto', cmap='gray',\n               vmin=v[0], vmax=v[1])\n\n    ax1.grid(False)\n    ax1.set_yticks([])\n    ax1.set_yticklabels([])\n\n    # Set 10 frame markers in X axis\n    interval = max((int(data.shape[-1] + 1) // 10, int(data.shape[-1] + 1) // 5, 1))\n    xticks = list(range(0, data.shape[-1])[::interval])\n    ax1.set_xticks(xticks)\n    if notr:\n        ax1.set_xlabel('time (frame #)')\n    else:\n        ax1.set_xlabel('time (s)')\n    labels = tr * (np.array(xticks)) * t_dec\n    ax1.set_xticklabels(['%.02f' % t for t in labels.tolist()], fontsize=5)\n\n    # Remove and redefine spines\n    for side in [\"top\", \"right\"]:\n        # Toggle the spine objects\n        ax0.spines[side].set_color('none')\n        ax0.spines[side].set_visible(False)\n        ax1.spines[side].set_color('none')\n        ax1.spines[side].set_visible(False)\n\n    ax1.yaxis.set_ticks_position('left')\n    ax1.xaxis.set_ticks_position('bottom')\n    ax1.spines[\"bottom\"].set_visible(False)\n    ax1.spines[\"left\"].set_color('none')\n    ax1.spines[\"left\"].set_visible(False)\n\n    if legend:\n        gslegend = mgs.GridSpecFromSubplotSpec(\n            5, 1, subplot_spec=gs[2], wspace=0.0, hspace=0.0)\n        epiavg = func_data.mean(3)\n        epinii = nb.Nifti1Image(epiavg, img_nii.affine, img_nii.header)\n        segnii = nb.Nifti1Image(lut[atlaslabels.astype(int)], epinii.affine, epinii.header)\n        segnii.set_data_dtype('uint8')\n\n        nslices = epiavg.shape[-1]\n        coords = np.linspace(int(0.10 * nslices), int(0.95 * nslices), 5).astype(np.uint8)\n        for i, c in enumerate(coords.tolist()):\n            ax2 = plt.subplot(gslegend[i])\n            plot_img(segnii, bg_img=epinii, axes=ax2, display_mode='z',\n                     annotate=False, cut_coords=[c], threshold=0.1, cmap=mycolors,\n                     interpolation='nearest')\n\n    if output_file is not None:\n        figure = plt.gcf()\n        figure.savefig(output_file, bbox_inches='tight')\n        plt.close(figure)\n        figure = None\n        return output_file\n\n    return [ax0, ax1], gs", "response": "Plots a single image representation of voxel intensities across time also knowing the time direction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the variance of the compartment metadata for a set of components.", "response": "def compcor_variance_plot(metadata_files, metadata_sources=None,\n                          output_file=None, varexp_thresh=(0.5, 0.7, 0.9),\n                          fig=None):\n    \"\"\"\n    Parameters\n    ----------\n    metadata_files: list\n        List of paths to files containing component metadata. If more than one\n        decomposition has been performed (e.g., anatomical and temporal\n        CompCor decompositions), then all metadata files can be provided in\n        the list. However, each metadata file should have a corresponding\n        entry in `metadata_sources`.\n    metadata_sources: list or None\n        List of source names (e.g., ['aCompCor']) for decompositions. This\n        list should be of the same length as `metadata_files`.\n    output_file: str or None\n        Path where the output figure should be saved. If this is not defined,\n        then the plotting axes will be returned instead of the saved figure\n        path.\n    varexp_thresh: tuple\n        Set of variance thresholds to include in the plot (default 0.5, 0.7,\n        0.9).\n    fig: figure or None\n        Existing figure on which to plot.\n\n    Returns\n    -------\n    ax: axes\n        Plotting axes. Returned only if the `output_file` parameter is None.\n    output_file: str\n        The file where the figure is saved.\n    \"\"\"\n    metadata = {}\n    if metadata_sources is None:\n        if len(metadata_files) == 1:\n            metadata_sources = ['CompCor']\n        else:\n            metadata_sources = ['Decomposition {:d}'.format(i)\n                                for i in range(len(metadata_files))]\n    for file, source in zip(metadata_files, metadata_sources):\n        metadata[source] = pd.read_table(str(file))\n        metadata[source]['source'] = source\n    metadata = pd.concat(list(metadata.values()))\n    bbox_txt = {\n        'boxstyle': 'round',\n        'fc': 'white',\n        'ec': 'none',\n        'color': 'none',\n        'linewidth': 0,\n        'alpha': 0.8\n    }\n\n    decompositions = []\n    data_sources = list(metadata.groupby(['source', 'mask']).groups.keys())\n    for source, mask in data_sources:\n        if not np.isnan(\n                metadata.loc[\n                    (metadata['source'] == source)\n                    & (metadata['mask'] == mask)\n                ]['singular_value'].values[0]):\n            decompositions.append((source, mask))\n\n    if fig is not None:\n        ax = [fig.add_subplot(1, len(decompositions), i+1)\n              for i in range(len(decompositions))]\n    elif len(decompositions) > 1:\n        fig, ax = plt.subplots(1, len(decompositions),\n                               figsize=(5*len(decompositions), 5))\n    else:\n        ax = [plt.axes()]\n\n    for m, (source, mask) in enumerate(decompositions):\n        components = metadata[(metadata['mask'] == mask)\n                              & (metadata['source'] == source)]\n        if len([m for s, m in decompositions if s == source]) > 1:\n            title_mask = ' ({} mask)'.format(mask)\n        else:\n            title_mask = ''\n        fig_title = '{}{}'.format(source, title_mask)\n\n        ax[m].plot(np.arange(components.shape[0]+1),\n                   [0] + list(\n                       100*components['cumulative_variance_explained']),\n                   color='purple',\n                   linewidth=2.5)\n        ax[m].grid(False)\n        ax[m].set_xlabel('number of components in model')\n        ax[m].set_ylabel('cumulative variance explained (%)')\n        ax[m].set_title(fig_title)\n\n        varexp = {}\n\n        for i, thr in enumerate(varexp_thresh):\n            varexp[thr] = np.searchsorted(\n                components['cumulative_variance_explained'], thr) + 1\n            ax[m].axhline(y=100*thr, color='lightgrey', linewidth=0.25)\n            ax[m].axvline(x=varexp[thr], color='C{}'.format(i),\n                          linewidth=2, linestyle=':')\n            ax[m].text(0, 100*thr, '{:.0f}'.format(100*thr),\n                       fontsize='x-small', bbox=bbox_txt)\n            ax[m].text(varexp[thr][0], 25,\n                       '{} components explain\\n{:.0f}% of variance'.format(\n                            varexp[thr][0], 100*thr),\n                       rotation=90,\n                       horizontalalignment='center',\n                       fontsize='xx-small',\n                       bbox=bbox_txt)\n\n        ax[m].set_yticks([])\n        ax[m].set_yticklabels([])\n        for tick in ax[m].xaxis.get_major_ticks():\n            tick.label.set_fontsize('x-small')\n            tick.label.set_rotation('vertical')\n        for side in ['top', 'right', 'left']:\n            ax[m].spines[side].set_color('none')\n            ax[m].spines[side].set_visible(False)\n\n    if output_file is not None:\n        figure = plt.gcf()\n        figure.savefig(output_file, bbox_inches='tight')\n        plt.close(figure)\n        figure = None\n        return output_file\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef confounds_correlation_plot(confounds_file, output_file=None, figure=None,\n                               reference='global_signal', max_dim=70):\n    \"\"\"\n    Parameters\n    ----------\n    confounds_file: str\n        File containing all confound regressors to be included in the\n        correlation plot.\n    output_file: str or None\n        Path where the output figure should be saved. If this is not defined,\n        then the plotting axes will be returned instead of the saved figure\n        path.\n    figure: figure or None\n        Existing figure on which to plot.\n    reference: str\n        `confounds_correlation_plot` prepares a bar plot of the correlations\n        of each confound regressor with a reference column. By default, this\n        is the global signal (so that collinearities with the global signal\n        can readily be assessed).\n    max_dim: int\n        The maximum number of regressors to be included in the output plot.\n        Reductions (e.g., CompCor) of high-dimensional data can yield so many\n        regressors that the correlation structure becomes obfuscated. This\n        criterion selects the `max_dim` regressors that have the largest\n        correlation magnitude with `reference` for inclusion in the plot.\n\n    Returns\n    -------\n    axes and gridspec\n        Plotting axes and gridspec. Returned only if `output_file` is None.\n    output_file: str\n        The file where the figure is saved.\n    \"\"\"\n    confounds_data = pd.read_table(confounds_file)\n    confounds_data = confounds_data.loc[:, np.logical_not(\n        np.isclose(confounds_data.var(skipna=True), 0))]\n    corr = confounds_data.corr()\n\n    gscorr = corr.copy()\n    gscorr['index'] = gscorr.index\n    gscorr[reference] = np.abs(gscorr[reference])\n    gs_descending = gscorr.sort_values(by=reference,\n                                       ascending=False)['index']\n\n    if corr.shape[0] > max_dim:\n        gs_descending = gs_descending[:max_dim]\n        features = [p for p in corr.columns if p in gs_descending]\n        corr = corr.loc[features, features]\n    n_vars = corr.shape[0]\n    np.fill_diagonal(corr.values, 0)\n\n    if figure is None:\n        plt.figure(figsize=(3*n_vars*0.3, n_vars*0.3))\n    gs = mgs.GridSpec(1, 15)\n    ax0 = plt.subplot(gs[0, :7])\n    ax1 = plt.subplot(gs[0, 7:])\n\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n    sns.heatmap(corr,\n                linewidths=0.5,\n                cmap='coolwarm',\n                center=0,\n                square=True,\n                ax=ax0)\n    ax0.tick_params(axis='both', which='both', width=0)\n\n    for tick in ax0.xaxis.get_major_ticks():\n        tick.label.set_fontsize('small')\n    for tick in ax0.yaxis.get_major_ticks():\n        tick.label.set_fontsize('small')\n    sns.barplot(data=gscorr,\n                x='index',\n                y=reference,\n                ax=ax1,\n                order=gs_descending,\n                palette='Reds_d',\n                saturation=.5)\n\n    ax1.set_xlabel('Confound time series')\n    ax1.set_ylabel('Magnitude of correlation with {}'.format(reference))\n    ax1.tick_params(axis='x', which='both', width=0)\n    ax1.tick_params(axis='y', which='both', width=5, length=5)\n\n    for tick in ax1.xaxis.get_major_ticks():\n        tick.label.set_fontsize('small')\n        tick.label.set_rotation('vertical')\n    for tick in ax1.yaxis.get_major_ticks():\n        tick.label.set_fontsize('small')\n    for side in ['top', 'right', 'left']:\n        ax1.spines[side].set_color('none')\n        ax1.spines[side].set_visible(False)\n\n    if output_file is not None:\n        figure = plt.gcf()\n        figure.savefig(output_file, bbox_inches='tight')\n        plt.close(figure)\n        figure = None\n        return output_file\n    return [ax0, ax1], gs", "response": "This function takes a confound file and plots the correlations of each confound regressor with the given reference column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot(self, figure=None):\n        sns.set_style(\"whitegrid\")\n        sns.set_context(\"paper\", font_scale=0.8)\n\n        if figure is None:\n            figure = plt.gcf()\n\n        nconfounds = len(self.confounds)\n        nspikes = len(self.spikes)\n        nrows = 1 + nconfounds + nspikes\n\n        # Create grid\n        grid = mgs.GridSpec(nrows, 1, wspace=0.0, hspace=0.05,\n                            height_ratios=[1] * (nrows - 1) + [5])\n\n        grid_id = 0\n        for tsz, name, iszs in self.spikes:\n            spikesplot(tsz, title=name, outer_gs=grid[grid_id], tr=self.tr,\n                       zscored=iszs)\n            grid_id += 1\n\n        if self.confounds:\n            palette = color_palette(\"husl\", nconfounds)\n\n        for i, (name, kwargs) in enumerate(self.confounds.items()):\n            tseries = kwargs.pop('values')\n            confoundplot(\n                tseries, grid[grid_id], tr=self.tr, color=palette[i],\n                name=name, **kwargs)\n            grid_id += 1\n\n        plot_carpet(self.func_file, self.seg_data, subplot=grid[-1], tr=self.tr)\n        # spikesplot_cb([0.7, 0.78, 0.2, 0.008])\n        return figure", "response": "Main plotter for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the visual report for the current entry.", "response": "def _generate_report(self):\n        \"\"\" Generates the visual report \"\"\"\n        from niworkflows.viz.utils import plot_registration\n        NIWORKFLOWS_LOG.info('Generating visual report')\n\n        fixed_image_nii = load_img(self._fixed_image)\n        moving_image_nii = load_img(self._moving_image)\n        contour_nii = load_img(self._contour) if self._contour is not None else None\n\n        if self._fixed_image_mask:\n            fixed_image_nii = unmask(apply_mask(fixed_image_nii,\n                                                self._fixed_image_mask),\n                                     self._fixed_image_mask)\n            # since the moving image is already in the fixed image space we\n            # should apply the same mask\n            moving_image_nii = unmask(apply_mask(moving_image_nii,\n                                                 self._fixed_image_mask),\n                                      self._fixed_image_mask)\n            mask_nii = load_img(self._fixed_image_mask)\n        else:\n            mask_nii = threshold_img(fixed_image_nii, 1e-3)\n\n        n_cuts = 7\n        if not self._fixed_image_mask and contour_nii:\n            cuts = cuts_from_bbox(contour_nii, cuts=n_cuts)\n        else:\n            cuts = cuts_from_bbox(mask_nii, cuts=n_cuts)\n\n        # Call composer\n        compose_view(\n            plot_registration(fixed_image_nii, 'fixed-image',\n                              estimate_brightness=True,\n                              cuts=cuts,\n                              label=self._fixed_image_label,\n                              contour=contour_nii,\n                              compress=self.inputs.compress_report),\n            plot_registration(moving_image_nii, 'moving-image',\n                              estimate_brightness=True,\n                              cuts=cuts,\n                              label=self._moving_image_label,\n                              contour=contour_nii,\n                              compress=self.inputs.compress_report),\n            out_file=self._out_report\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _generate_report(self):\n        from niworkflows.viz.utils import plot_registration\n        NIWORKFLOWS_LOG.info('Generating visual report')\n\n        anat = load_img(self._anat_file)\n        contour_nii = load_img(self._contour) if self._contour is not None else None\n\n        if self._mask_file:\n            anat = unmask(apply_mask(anat, self._mask_file), self._mask_file)\n            mask_nii = load_img(self._mask_file)\n        else:\n            mask_nii = threshold_img(anat, 1e-3)\n\n        n_cuts = 7\n        if not self._mask_file and contour_nii:\n            cuts = cuts_from_bbox(contour_nii, cuts=n_cuts)\n        else:\n            cuts = cuts_from_bbox(mask_nii, cuts=n_cuts)\n\n        # Call composer\n        compose_view(\n            plot_registration(anat, 'fixed-image',\n                              estimate_brightness=True,\n                              cuts=cuts,\n                              contour=contour_nii,\n                              compress=self.inputs.compress_report),\n            [],\n            out_file=self._out_report\n        )", "response": "Generates the visual report for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_atropos_wf(name='atropos_wf',\n                    use_random_seed=True,\n                    omp_nthreads=None,\n                    mem_gb=3.0,\n                    padding=10,\n                    in_segmentation_model=list(ATROPOS_MODELS['T1w'].values())):\n    \"\"\"\n    Implements supersteps 6 and 7 of ``antsBrainExtraction.sh``,\n    which refine the mask previously computed with the spatial\n    normalization to the template.\n\n    **Parameters**\n\n        use_random_seed : bool\n            Whether ATROPOS should generate a random seed based on the\n            system's clock\n        omp_nthreads : int\n            Maximum number of threads an individual process may use\n        mem_gb : float\n            Estimated peak memory consumption of the most hungry nodes\n            in the workflow\n        padding : int\n            Pad images with zeros before processing\n        in_segmentation_model : tuple\n            A k-means segmentation is run to find gray or white matter\n            around the edge of the initial brain mask warped from the\n            template.\n            This produces a segmentation image with :math:`$K$` classes,\n            ordered by mean intensity in increasing order.\n            With this option, you can control  :math:`$K$` and tell\n            the script which classes represent CSF, gray and white matter.\n            Format (K, csfLabel, gmLabel, wmLabel).\n            Examples:\n              - ``(3,1,2,3)`` for T1 with K=3, CSF=1, GM=2, WM=3 (default)\n              - ``(3,3,2,1)`` for T2 with K=3, CSF=3, GM=2, WM=1\n              - ``(3,1,3,2)`` for FLAIR with K=3, CSF=1 GM=3, WM=2\n              - ``(4,4,2,3)`` uses K=4, CSF=4, GM=2, WM=3\n        name : str, optional\n            Workflow name (default: atropos_wf)\n\n\n    **Inputs**\n\n        in_files\n            :abbr:`INU (intensity non-uniformity)`-corrected files.\n        in_mask\n            Brain mask calculated previously\n\n\n    **Outputs**\n        out_mask\n            Refined brain mask\n        out_segm\n            Output segmentation\n        out_tpms\n            Output :abbr:`TPMs (tissue probability maps)`\n\n    \"\"\"\n    wf = pe.Workflow(name)\n\n    inputnode = pe.Node(niu.IdentityInterface(\n        fields=['in_files', 'in_mask', 'in_mask_dilated']), name='inputnode')\n    outputnode = pe.Node(niu.IdentityInterface(\n        fields=['out_mask', 'out_segm', 'out_tpms']), name='outputnode')\n\n    # Run atropos (core node)\n    atropos = pe.Node(Atropos(\n        dimension=3,\n        initialization='KMeans',\n        number_of_tissue_classes=in_segmentation_model[0],\n        n_iterations=3,\n        convergence_threshold=0.0,\n        mrf_radius=[1, 1, 1],\n        mrf_smoothing_factor=0.1,\n        likelihood_model='Gaussian',\n        use_random_seed=use_random_seed),\n        name='01_atropos', n_procs=omp_nthreads, mem_gb=mem_gb)\n\n    # massage outputs\n    pad_segm = pe.Node(ImageMath(operation='PadImage', op2='%d' % padding),\n                       name='02_pad_segm')\n    pad_mask = pe.Node(ImageMath(operation='PadImage', op2='%d' % padding),\n                       name='03_pad_mask')\n\n    # Split segmentation in binary masks\n    sel_labels = pe.Node(niu.Function(\n        function=_select_labels, output_names=['out_wm', 'out_gm', 'out_csf']),\n        name='04_sel_labels')\n    sel_labels.inputs.labels = list(reversed(in_segmentation_model[1:]))\n\n    # Select largest components (GM, WM)\n    # ImageMath ${DIMENSION} ${EXTRACTION_WM} GetLargestComponent ${EXTRACTION_WM}\n    get_wm = pe.Node(ImageMath(operation='GetLargestComponent'),\n                     name='05_get_wm')\n    get_gm = pe.Node(ImageMath(operation='GetLargestComponent'),\n                     name='06_get_gm')\n\n    # Fill holes and calculate intersection\n    # ImageMath ${DIMENSION} ${EXTRACTION_TMP} FillHoles ${EXTRACTION_GM} 2\n    # MultiplyImages ${DIMENSION} ${EXTRACTION_GM} ${EXTRACTION_TMP} ${EXTRACTION_GM}\n    fill_gm = pe.Node(ImageMath(operation='FillHoles', op2='2'),\n                      name='07_fill_gm')\n    mult_gm = pe.Node(MultiplyImages(\n        dimension=3, output_product_image='08_mult_gm.nii.gz'), name='08_mult_gm')\n\n    # MultiplyImages ${DIMENSION} ${EXTRACTION_WM} ${ATROPOS_WM_CLASS_LABEL} ${EXTRACTION_WM}\n    # ImageMath ${DIMENSION} ${EXTRACTION_TMP} ME ${EXTRACTION_CSF} 10\n    relabel_wm = pe.Node(MultiplyImages(\n        dimension=3, second_input=in_segmentation_model[-1],\n        output_product_image='09_relabel_wm.nii.gz'), name='09_relabel_wm')\n    me_csf = pe.Node(ImageMath(operation='ME', op2='10'), name='10_me_csf')\n\n    # ImageMath ${DIMENSION} ${EXTRACTION_GM} addtozero ${EXTRACTION_GM} ${EXTRACTION_TMP}\n    # MultiplyImages ${DIMENSION} ${EXTRACTION_GM} ${ATROPOS_GM_CLASS_LABEL} ${EXTRACTION_GM}\n    # ImageMath ${DIMENSION} ${EXTRACTION_SEGMENTATION} addtozero ${EXTRACTION_WM} ${EXTRACTION_GM}\n    add_gm = pe.Node(ImageMath(operation='addtozero'),\n                     name='11_add_gm')\n    relabel_gm = pe.Node(MultiplyImages(\n        dimension=3, second_input=in_segmentation_model[-2],\n        output_product_image='12_relabel_gm.nii.gz'), name='12_relabel_gm')\n    add_gm_wm = pe.Node(ImageMath(operation='addtozero'),\n                        name='13_add_gm_wm')\n\n    # Superstep 7\n    # Split segmentation in binary masks\n    sel_labels2 = pe.Node(niu.Function(\n        function=_select_labels, output_names=['out_gm', 'out_wm']),\n        name='14_sel_labels2')\n    sel_labels2.inputs.labels = in_segmentation_model[2:]\n\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} addtozero ${EXTRACTION_MASK} ${EXTRACTION_TMP}\n    add_7 = pe.Node(ImageMath(operation='addtozero'), name='15_add_7')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} ME ${EXTRACTION_MASK} 2\n    me_7 = pe.Node(ImageMath(operation='ME', op2='2'), name='16_me_7')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} GetLargestComponent ${EXTRACTION_MASK}\n    comp_7 = pe.Node(ImageMath(operation='GetLargestComponent'),\n                     name='17_comp_7')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} MD ${EXTRACTION_MASK} 4\n    md_7 = pe.Node(ImageMath(operation='MD', op2='4'), name='18_md_7')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} FillHoles ${EXTRACTION_MASK} 2\n    fill_7 = pe.Node(ImageMath(operation='FillHoles', op2='2'),\n                     name='19_fill_7')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} addtozero ${EXTRACTION_MASK} \\\n    # ${EXTRACTION_MASK_PRIOR_WARPED}\n    add_7_2 = pe.Node(ImageMath(operation='addtozero'), name='20_add_7_2')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} MD ${EXTRACTION_MASK} 5\n    md_7_2 = pe.Node(ImageMath(operation='MD', op2='5'), name='21_md_7_2')\n    # ImageMath ${DIMENSION} ${EXTRACTION_MASK} ME ${EXTRACTION_MASK} 5\n    me_7_2 = pe.Node(ImageMath(operation='ME', op2='5'), name='22_me_7_2')\n\n    # De-pad\n    depad_mask = pe.Node(ImageMath(operation='PadImage', op2='-%d' % padding),\n                         name='23_depad_mask')\n    depad_segm = pe.Node(ImageMath(operation='PadImage', op2='-%d' % padding),\n                         name='24_depad_segm')\n    depad_gm = pe.Node(ImageMath(operation='PadImage', op2='-%d' % padding),\n                       name='25_depad_gm')\n    depad_wm = pe.Node(ImageMath(operation='PadImage', op2='-%d' % padding),\n                       name='26_depad_wm')\n    depad_csf = pe.Node(ImageMath(operation='PadImage', op2='-%d' % padding),\n                        name='27_depad_csf')\n\n    msk_conform = pe.Node(niu.Function(function=_conform_mask), name='msk_conform')\n    merge_tpms = pe.Node(niu.Merge(in_segmentation_model[0]), name='merge_tpms')\n    wf.connect([\n        (inputnode, pad_mask, [('in_mask', 'op1')]),\n        (inputnode, atropos, [('in_files', 'intensity_images'),\n                              ('in_mask_dilated', 'mask_image')]),\n        (inputnode, msk_conform, [(('in_files', _pop), 'in_reference')]),\n        (atropos, pad_segm, [('classified_image', 'op1')]),\n        (pad_segm, sel_labels, [('output_image', 'in_segm')]),\n        (sel_labels, get_wm, [('out_wm', 'op1')]),\n        (sel_labels, get_gm, [('out_gm', 'op1')]),\n        (get_gm, fill_gm, [('output_image', 'op1')]),\n        (get_gm, mult_gm, [('output_image', 'first_input')]),\n        (fill_gm, mult_gm, [('output_image', 'second_input')]),\n        (get_wm, relabel_wm, [('output_image', 'first_input')]),\n        (sel_labels, me_csf, [('out_csf', 'op1')]),\n        (mult_gm, add_gm, [('output_product_image', 'op1')]),\n        (me_csf, add_gm, [('output_image', 'op2')]),\n        (add_gm, relabel_gm, [('output_image', 'first_input')]),\n        (relabel_wm, add_gm_wm, [('output_product_image', 'op1')]),\n        (relabel_gm, add_gm_wm, [('output_product_image', 'op2')]),\n        (add_gm_wm, sel_labels2, [('output_image', 'in_segm')]),\n        (sel_labels2, add_7, [('out_wm', 'op1'),\n                              ('out_gm', 'op2')]),\n        (add_7, me_7, [('output_image', 'op1')]),\n        (me_7, comp_7, [('output_image', 'op1')]),\n        (comp_7, md_7, [('output_image', 'op1')]),\n        (md_7, fill_7, [('output_image', 'op1')]),\n        (fill_7, add_7_2, [('output_image', 'op1')]),\n        (pad_mask, add_7_2, [('output_image', 'op2')]),\n        (add_7_2, md_7_2, [('output_image', 'op1')]),\n        (md_7_2, me_7_2, [('output_image', 'op1')]),\n        (me_7_2, depad_mask, [('output_image', 'op1')]),\n        (add_gm_wm, depad_segm, [('output_image', 'op1')]),\n        (relabel_wm, depad_wm, [('output_product_image', 'op1')]),\n        (relabel_gm, depad_gm, [('output_product_image', 'op1')]),\n        (sel_labels, depad_csf, [('out_csf', 'op1')]),\n        (depad_csf, merge_tpms, [('output_image', 'in1')]),\n        (depad_gm, merge_tpms, [('output_image', 'in2')]),\n        (depad_wm, merge_tpms, [('output_image', 'in3')]),\n        (depad_mask, msk_conform, [('output_image', 'in_mask')]),\n        (msk_conform, outputnode, [('out', 'out_mask')]),\n        (depad_segm, outputnode, [('output_image', 'out_segm')]),\n        (merge_tpms, outputnode, [('out', 'out_tpms')]),\n    ])\n    return wf", "response": "Initializes the brain mask for the given workflow."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _conform_mask(in_mask, in_reference):\n    from pathlib import Path\n    import nibabel as nb\n    from nipype.utils.filemanip import fname_presuffix\n\n    ref = nb.load(in_reference)\n    nii = nb.load(in_mask)\n    hdr = nii.header.copy()\n    hdr.set_data_dtype('int16')\n    hdr.set_slope_inter(1, 0)\n\n    qform, qcode = ref.header.get_qform(coded=True)\n    if qcode is not None:\n        hdr.set_qform(qform, int(qcode))\n\n    sform, scode = ref.header.get_sform(coded=True)\n    if scode is not None:\n        hdr.set_sform(sform, int(scode))\n\n    if '_maths' in in_mask:  # Cut the name at first _maths occurrence\n        ext = ''.join(Path(in_mask).suffixes)\n        basename = Path(in_mask).name\n        in_mask = basename.split('_maths')[0] + ext\n\n    out_file = fname_presuffix(in_mask, suffix='_mask',\n                               newpath=str(Path()))\n    nii.__class__(nii.get_data().astype('int16'), ref.affine,\n                  hdr).to_filename(out_file)\n    return out_file", "response": "Ensures the mask headers make sense and match those of the T1w"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dataset(dataset_name, dataset_prefix=None, data_dir=None,\n                url=None, resume=True, verbose=1):\n    \"\"\"Download and load the BIDS-fied brainweb 1mm normal\n\n    :param str data_dir: path of the data directory. Used to force data storage\n        in a non-standard location.\n    :param str url: download URL of the dataset. Overwrite the default URL.\n\n    \"\"\"\n    warn(DEPRECATION_MSG)\n    file_id, md5 = OSF_RESOURCES[dataset_name]\n    if url is None:\n        url = '{}/{}'.format(OSF_PROJECT_URL, file_id)\n    return fetch_file(dataset_name, url, data_dir, dataset_prefix=dataset_prefix,\n                      filetype='tar', resume=resume, verbose=verbose, md5sum=md5)", "response": "Download and load the brainweb 1mm dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_template(template_name, data_dir=None, url=None, resume=True, verbose=1):\n    warn(DEPRECATION_MSG)\n    if template_name.startswith('tpl-'):\n        template_name = template_name[4:]\n\n    # An aliasing mechanism. Please avoid\n    template_name = TEMPLATE_ALIASES.get(template_name, template_name)\n    return get_dataset(template_name, dataset_prefix='tpl-', data_dir=data_dir,\n                       url=url, resume=resume, verbose=verbose)", "response": "Download and load a template"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload and load the brainweb 1mm normal dataset.", "response": "def get_brainweb_1mm_normal(data_dir=None, url=None, resume=True, verbose=1):\n    \"\"\"Download and load the BIDS-fied brainweb 1mm normal\n\n    :param str data_dir: path of the data directory. Used to force data storage\n        in a non-standard location.\n    :param str url: download URL of the dataset. Overwrite the default URL.\n\n    \"\"\"\n    warn(DEPRECATION_MSG)\n    return get_dataset('brainweb', data_dir=data_dir, url=url,\n                       resume=resume, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bids_examples(data_dir=None, url=None, resume=True, verbose=1,\n                      variant='BIDS-examples-1-1.0.0-rc3u5'):\n    \"\"\"Download BIDS-examples-1\"\"\"\n    warn(DEPRECATION_MSG)\n    variant = 'BIDS-examples-1-1.0.0-rc3u5' if variant not in BIDS_EXAMPLES else variant\n    if url is None:\n        url = BIDS_EXAMPLES[variant][0]\n    md5 = BIDS_EXAMPLES[variant][1]\n    return fetch_file(variant, url, data_dir, resume=resume, verbose=verbose,\n                      md5sum=md5)", "response": "Download and return the BIDS - examples - 1 file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake an image as created by nilearn. plotting and returns a blob svg.", "response": "def svg_compress(image, compress='auto'):\n    ''' takes an image as created by nilearn.plotting and returns a blob svg.\n    Performs compression (can be disabled). A bit hacky. '''\n\n    # Check availability of svgo and cwebp\n    has_compress = all((which('svgo'), which('cwebp')))\n    if compress is True and not has_compress:\n        raise RuntimeError('Compression is required, but svgo or cwebp are not installed')\n    else:\n        compress = (compress is True or compress == 'auto') and has_compress\n\n    # Compress the SVG file using SVGO\n    if compress:\n        cmd = 'svgo -i - -o - -q -p 3 --pretty --disable=cleanupNumericValues'\n        try:\n            pout = subprocess.run(cmd, input=image.encode('utf-8'), stdout=subprocess.PIPE,\n                                  shell=True, check=True, close_fds=True).stdout\n        except OSError as e:\n            from errno import ENOENT\n            if compress is True and e.errno == ENOENT:\n                raise e\n        else:\n            image = pout.decode('utf-8')\n\n    # Convert all of the rasters inside the SVG file with 80% compressed WEBP\n    if compress:\n        new_lines = []\n        with StringIO(image) as fp:\n            for line in fp:\n                if \"image/png\" in line:\n                    tmp_lines = [line]\n                    while \"/>\" not in line:\n                        line = fp.readline()\n                        tmp_lines.append(line)\n                    content = ''.join(tmp_lines).replace('\\n', '').replace(\n                        ',  ', ',')\n\n                    left = content.split('base64,')[0] + 'base64,'\n                    left = left.replace(\"image/png\", \"image/webp\")\n                    right = content.split('base64,')[1]\n                    png_b64 = right.split('\"')[0]\n                    right = '\"' + '\"'.join(right.split('\"')[1:])\n\n                    cmd = \"cwebp -quiet -noalpha -q 80 -o - -- -\"\n                    pout = subprocess.run(\n                        cmd, input=base64.b64decode(png_b64), shell=True,\n                        stdout=subprocess.PIPE, check=True, close_fds=True).stdout\n                    webpimg = base64.b64encode(pout).decode('utf-8')\n                    new_lines.append(left + webpimg + right)\n                else:\n                    new_lines.append(line)\n        lines = new_lines\n    else:\n        lines = image.splitlines()\n\n    svg_start = 0\n    for i, line in enumerate(lines):\n        if '<svg ' in line:\n            svg_start = i\n            continue\n\n    image_svg = lines[svg_start:]  # strip out extra DOCTYPE, etc headers\n    return ''.join(image_svg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes a nilearn display object as a string", "response": "def svg2str(display_object, dpi=300):\n    \"\"\"\n    Serializes a nilearn display object as a string\n    \"\"\"\n    from io import StringIO\n    image_buf = StringIO()\n    display_object.frame_axes.figure.savefig(\n        image_buf, dpi=dpi, format='svg',\n        facecolor='k', edgecolor='k')\n    return image_buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the SVG from the display object.", "response": "def extract_svg(display_object, dpi=300, compress='auto'):\n    \"\"\"\n    Removes the preamble of the svg files generated with nilearn\n    \"\"\"\n    image_svg = svg2str(display_object, dpi)\n    if compress is True or compress == 'auto':\n        image_svg = svg_compress(image_svg, compress)\n    image_svg = re.sub(' height=\"[0-9]+[a-z]*\"', '', image_svg, count=1)\n    image_svg = re.sub(' width=\"[0-9]+[a-z]*\"', '', image_svg, count=1)\n    image_svg = re.sub(' viewBox',\n                       ' preseveAspectRation=\"xMidYMid meet\" viewBox',\n                       image_svg, count=1)\n    start_tag = '<svg '\n    start_idx = image_svg.find(start_tag)\n    end_tag = '</svg>'\n    end_idx = image_svg.rfind(end_tag)\n    if start_idx is -1 or end_idx is -1:\n        NIWORKFLOWS_LOG.info('svg tags not found in extract_svg')\n    # rfind gives the start index of the substr. We want this substr\n    # included in our return value so we add its length to the index.\n    end_idx += len(end_tag)\n    return image_svg[start_idx:end_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cuts_from_bbox(mask_nii, cuts=3):\n    from nibabel.affines import apply_affine\n\n    mask_data = mask_nii.get_data() > 0.0\n\n    # First, project the number of masked voxels on each axes\n    ijk_counts = [\n        mask_data.sum(2).sum(1),  # project sagittal planes to transverse (i) axis\n        mask_data.sum(2).sum(0),  # project coronal planes to to longitudinal (j) axis\n        mask_data.sum(1).sum(0),  # project axial planes to vertical (k) axis\n    ]\n\n    # If all voxels are masked in a slice (say that happens at k=10),\n    # then the value for ijk_counts for the projection to k (ie. ijk_counts[2])\n    # at that element of the orthogonal axes (ijk_counts[2][10]) is\n    # the total number of voxels in that slice (ie. Ni x Nj).\n    # Here we define some thresholds to consider the plane as \"masked\"\n    # The thresholds vary because of the shape of the brain\n    # I have manually found that for the axial view requiring 30%\n    # of the slice elements to be masked drops almost empty boxes\n    # in the mosaic of axial planes (and also addresses #281)\n    ijk_th = [\n        int((mask_data.shape[1] * mask_data.shape[2]) * 0.2),   # sagittal\n        int((mask_data.shape[0] * mask_data.shape[2]) * 0.0),   # coronal\n        int((mask_data.shape[0] * mask_data.shape[1]) * 0.3),   # axial\n    ]\n\n    vox_coords = []\n    for ax, (c, th) in enumerate(zip(ijk_counts, ijk_th)):\n        B = np.argwhere(c > th)\n        if B.size:\n            smin, smax = B.min(), B.max()\n\n        # Avoid too narrow selections of cuts (very small masks)\n        if not B.size or (th > 0 and (smin + cuts + 1) >= smax):\n            B = np.argwhere(c > 0)\n\n        # Resort to full plane if mask is seemingly empty\n        smin, smax = B.min(), B.max() if B.size else (0, mask_data.shape[ax])\n        inc = (smax - smin) / (cuts + 1)\n        vox_coords.append([smin + (i + 1) * inc for i in range(cuts)])\n\n    ras_coords = []\n    for cross in np.array(vox_coords).T:\n        ras_coords.append(apply_affine(\n            mask_nii.affine, cross).tolist())\n    ras_cuts = [list(coords) for coords in np.transpose(ras_coords)]\n    return {k: v for k, v in zip(['x', 'y', 'z'], ras_cuts)}", "response": "Finds equi - spaced cuts for presenting images in a given bounding box."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next 3D or 4D file in the input file.", "response": "def _3d_in_file(in_file):\n    ''' if self.inputs.in_file is 3d, return it.\n    if 4d, pick an arbitrary volume and return that.\n\n    if in_file is a list of files, return an arbitrary file from\n    the list, and an arbitrary volume from that file\n    '''\n\n    in_file = filemanip.filename_to_list(in_file)[0]\n\n    try:\n        in_file = nb.load(in_file)\n    except AttributeError:\n        in_file = in_file\n\n    if in_file.get_data().ndim == 3:\n        return in_file\n\n    return nlimage.index_img(in_file, 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots segmentation as contours over the image.", "response": "def plot_segs(image_nii, seg_niis, out_file, bbox_nii=None, masked=False,\n              colors=None, compress='auto', **plot_params):\n    \"\"\" plot segmentation as contours over the image (e.g. anatomical).\n    seg_niis should be a list of files. mask_nii helps determine the cut\n    coordinates. plot_params will be passed on to nilearn plot_* functions. If\n    seg_niis is a list of size one, it behaves as if it was plotting the mask.\n    \"\"\"\n    plot_params = {} if plot_params is None else plot_params\n\n    image_nii = _3d_in_file(image_nii)\n    data = image_nii.get_data()\n\n    plot_params = robust_set_limits(data, plot_params)\n\n    bbox_nii = nb.load(image_nii if bbox_nii is None else bbox_nii)\n    if masked:\n        bbox_nii = nlimage.threshold_img(bbox_nii, 1e-3)\n\n    cuts = cuts_from_bbox(bbox_nii, cuts=7)\n    plot_params['colors'] = colors or plot_params.get('colors', None)\n    out_files = []\n    for d in plot_params.pop('dimensions', ('z', 'x', 'y')):\n        plot_params['display_mode'] = d\n        plot_params['cut_coords'] = cuts[d]\n        svg = _plot_anat_with_contours(image_nii, segs=seg_niis, compress=compress,\n                                       **plot_params)\n\n        # Find and replace the figure_1 id.\n        try:\n            xml_data = etree.fromstring(svg)\n        except etree.XMLSyntaxError as e:\n            NIWORKFLOWS_LOG.info(e)\n            return\n        find_text = etree.ETXPath(\"//{%s}g[@id='figure_1']\" % SVGNS)\n        find_text(xml_data)[0].set('id', 'segmentation-%s-%s' % (d, uuid4()))\n\n        svg_fig = SVGFigure()\n        svg_fig.root = xml_data\n        out_files.append(svg_fig)\n\n    return out_files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_registration(anat_nii, div_id, plot_params=None,\n                      order=('z', 'x', 'y'), cuts=None,\n                      estimate_brightness=False, label=None, contour=None,\n                      compress='auto'):\n    \"\"\"\n    Plots the foreground and background views\n    Default order is: axial, coronal, sagittal\n    \"\"\"\n    plot_params = {} if plot_params is None else plot_params\n\n    # Use default MNI cuts if none defined\n    if cuts is None:\n        raise NotImplementedError  # TODO\n\n    out_files = []\n    if estimate_brightness:\n        plot_params = robust_set_limits(anat_nii.get_data().reshape(-1),\n                                        plot_params)\n\n    # FreeSurfer ribbon.mgz\n    ribbon = contour is not None and np.array_equal(\n        np.unique(contour.get_data()), [0, 2, 3, 41, 42])\n\n    if ribbon:\n        contour_data = contour.get_data() % 39\n        white = nlimage.new_img_like(contour, contour_data == 2)\n        pial = nlimage.new_img_like(contour, contour_data >= 2)\n\n    # Plot each cut axis\n    for i, mode in enumerate(list(order)):\n        plot_params['display_mode'] = mode\n        plot_params['cut_coords'] = cuts[mode]\n        if i == 0:\n            plot_params['title'] = label\n        else:\n            plot_params['title'] = None\n\n        # Generate nilearn figure\n        display = plot_anat(anat_nii, **plot_params)\n        if ribbon:\n            kwargs = {'levels': [0.5], 'linewidths': 0.5}\n            display.add_contours(white, colors='b', **kwargs)\n            display.add_contours(pial, colors='r', **kwargs)\n        elif contour is not None:\n            display.add_contours(contour, colors='b', levels=[0.5],\n                                 linewidths=0.5)\n\n        svg = extract_svg(display, compress=compress)\n        display.close()\n\n        # Find and replace the figure_1 id.\n        try:\n            xml_data = etree.fromstring(svg)\n        except etree.XMLSyntaxError as e:\n            NIWORKFLOWS_LOG.info(e)\n            return\n        find_text = etree.ETXPath(\"//{%s}g[@id='figure_1']\" % SVGNS)\n        find_text(xml_data)[0].set('id', '%s-%s-%s' % (div_id, mode, uuid4()))\n\n        svg_fig = SVGFigure()\n        svg_fig.root = xml_data\n        out_files.append(svg_fig)\n\n    return out_files", "response": "Plot the registration of an anat."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomposing the input svgs into one standalone svg and inserts the CSS code for the flickering animation", "response": "def compose_view(bg_svgs, fg_svgs, ref=0, out_file='report.svg'):\n    \"\"\"\n    Composes the input svgs into one standalone svg and inserts\n    the CSS code for the flickering animation\n    \"\"\"\n    import svgutils.transform as svgt\n\n    if fg_svgs is None:\n        fg_svgs = []\n\n    # Merge SVGs and get roots\n    svgs = bg_svgs + fg_svgs\n    roots = [f.getroot() for f in svgs]\n\n    # Query the size of each\n    sizes = []\n    for f in svgs:\n        viewbox = [float(v) for v in f.root.get(\"viewBox\").split(\" \")]\n        width = int(viewbox[2])\n        height = int(viewbox[3])\n        sizes.append((width, height))\n    nsvgs = len(bg_svgs)\n\n    sizes = np.array(sizes)\n\n    # Calculate the scale to fit all widths\n    width = sizes[ref, 0]\n    scales = width / sizes[:, 0]\n    heights = sizes[:, 1] * scales\n\n    # Compose the views panel: total size is the width of\n    # any element (used the first here) and the sum of heights\n    fig = svgt.SVGFigure(width, heights[:nsvgs].sum())\n\n    yoffset = 0\n    for i, r in enumerate(roots):\n        r.moveto(0, yoffset, scale=scales[i])\n        if i == (nsvgs - 1):\n            yoffset = 0\n        else:\n            yoffset += heights[i]\n\n    # Group background and foreground panels in two groups\n    if fg_svgs:\n        newroots = [\n            svgt.GroupElement(roots[:nsvgs], {'class': 'background-svg'}),\n            svgt.GroupElement(roots[nsvgs:], {'class': 'foreground-svg'})\n        ]\n    else:\n        newroots = roots\n    fig.append(newroots)\n    fig.root.attrib.pop(\"width\")\n    fig.root.attrib.pop(\"height\")\n    fig.root.set(\"preserveAspectRatio\", \"xMidYMid meet\")\n    out_file = op.abspath(out_file)\n    fig.save(out_file)\n\n    # Post processing\n    with open(out_file, 'r' if PY3 else 'rb') as f:\n        svg = f.read().split('\\n')\n\n    # Remove <?xml... line\n    if svg[0].startswith(\"<?xml\"):\n        svg = svg[1:]\n\n    # Add styles for the flicker animation\n    if fg_svgs:\n        svg.insert(2, \"\"\"\\\n<style type=\"text/css\">\n@keyframes flickerAnimation%s { 0%% {opacity: 1;} 100%% { opacity: 0; }}\n.foreground-svg { animation: 1s ease-in-out 0s alternate none infinite paused flickerAnimation%s;}\n.foreground-svg:hover { animation-play-state: running;}\n</style>\"\"\" % tuple([uuid4()] * 2))\n\n    with open(out_file, 'w' if PY3 else 'wb') as f:\n        f.write('\\n'.join(svg))\n    return out_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform_to_2d(data, max_axis):\n    import numpy as np\n    # get the shape of the array we are projecting to\n    new_shape = list(data.shape)\n    del new_shape[max_axis]\n\n    # generate a 3D indexing array that points to max abs value in the\n    # current projection\n    a1, a2 = np.indices(new_shape)\n    inds = [a1, a2]\n    inds.insert(max_axis, np.abs(data).argmax(axis=max_axis))\n\n    # take the values where the absolute value of the projection\n    # is the highest\n    maximum_intensity_data = data[inds]\n\n    return np.rot90(maximum_intensity_data)", "response": "Project data to a 3D cube along one axis using maximum intensity preservation of the signs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the spatiotemporal components of the MRI dataset.", "response": "def plot_melodic_components(melodic_dir, in_file, tr=None,\n                            out_file='melodic_reportlet.svg',\n                            compress='auto', report_mask=None,\n                            noise_components_file=None):\n    \"\"\"\n    Plots the spatiotemporal components extracted by FSL MELODIC\n    from functional MRI data.\n\n    Parameters\n\n        melodic_dir : str\n            Path pointing to the outputs of MELODIC\n        in_file :  str\n            Path pointing to the reference fMRI dataset. This file\n            will be used to extract the TR value, if the ``tr`` argument\n            is not set. This file will be used to calculate a mask\n            if ``report_mask`` is not provided.\n        tr : float\n            Repetition time in seconds\n        out_file : str\n            Path where the resulting SVG file will be stored\n        compress : ``'auto'`` or bool\n            Whether SVG should be compressed. If ``'auto'``, compression\n            will be executed if dependencies are installed (SVGO)\n        report_mask : str\n            Path to a brain mask corresponding to ``in_file``\n        noise_components_file : str\n            A CSV file listing the indexes of components classified as noise\n            by some manual or automated (e.g. ICA-AROMA) procedure. If a\n            ``noise_components_file`` is provided, then components will be\n            plotted with red/green colors (correspondingly to whether they\n            are in the file -noise components, red-, or not -signal, green-).\n            When all or none of the components are in the file, a warning\n            is printed at the top.\n\n\n    \"\"\"\n    from nilearn.image import index_img, iter_img\n    import nibabel as nb\n    import numpy as np\n    import pylab as plt\n    import seaborn as sns\n    from matplotlib.gridspec import GridSpec\n    import os\n    import re\n    from io import StringIO\n    sns.set_style(\"white\")\n    current_palette = sns.color_palette()\n    in_nii = nb.load(in_file)\n    if not tr:\n        tr = in_nii.header.get_zooms()[3]\n        units = in_nii.header.get_xyzt_units()\n        if units:\n            if units[-1] == 'msec':\n                tr = tr / 1000.0\n            elif units[-1] == 'usec':\n                tr = tr / 1000000.0\n            elif units[-1] != 'sec':\n                NIWORKFLOWS_LOG.warning('Unknown repetition time units '\n                                        'specified - assuming seconds')\n        else:\n            NIWORKFLOWS_LOG.warning(\n                'Repetition time units not specified - assuming seconds')\n\n    from nilearn.input_data import NiftiMasker\n    from nilearn.plotting import cm\n\n    if not report_mask:\n        nifti_masker = NiftiMasker(mask_strategy='epi')\n        nifti_masker.fit(index_img(in_nii, range(2)))\n        mask_img = nifti_masker.mask_img_\n    else:\n        mask_img = nb.load(report_mask)\n\n    mask_sl = []\n    for j in range(3):\n        mask_sl.append(transform_to_2d(mask_img.get_data(), j))\n\n    timeseries = np.loadtxt(os.path.join(melodic_dir, \"melodic_mix\"))\n    power = np.loadtxt(os.path.join(melodic_dir, \"melodic_FTmix\"))\n    stats = np.loadtxt(os.path.join(melodic_dir, \"melodic_ICstats\"))\n    n_components = stats.shape[0]\n    Fs = 1.0 / tr\n    Ny = Fs / 2\n    f = Ny * (np.array(list(range(1, power.shape[0] + 1)))) / (power.shape[0])\n\n    # Set default colors\n    color_title = 'k'\n    color_time = current_palette[0]\n    color_power = current_palette[1]\n    classified_colors = None\n\n    warning_row = 0  # Do not allocate warning row\n    # Only if the components file has been provided, a warning banner will\n    # be issued if all or none of the components were classified as noise\n    if noise_components_file:\n        noise_components = np.loadtxt(noise_components_file,\n                                      dtype=int, delimiter=',', ndmin=1)\n        # Activate warning row if pertinent\n        warning_row = int(noise_components.size == 0 or\n                          noise_components.size == n_components)\n        classified_colors = {True: 'r', False: 'g'}\n\n    n_rows = int((n_components + (n_components % 2)) / 2)\n    fig = plt.figure(figsize=(6.5 * 1.5, (n_rows + warning_row) * 0.85))\n    gs = GridSpec(n_rows * 2 + warning_row, 9,\n                  width_ratios=[1, 1, 1, 4, 0.001, 1, 1, 1, 4, ],\n                  height_ratios=[5] * warning_row + [1.1, 1] * n_rows)\n\n    if warning_row:\n        ax = fig.add_subplot(gs[0, :])\n        ncomps = 'NONE of the'\n        if noise_components.size == n_components:\n            ncomps = 'ALL'\n        ax.annotate(\n            'WARNING: {} components were classified as noise'.format(ncomps),\n            xy=(0.0, 0.5), xycoords='axes fraction',\n            xytext=(0.01, 0.5), textcoords='axes fraction',\n            size=12, color='#ea8800',\n            bbox=dict(boxstyle=\"round\",\n                      fc='#f7dcb7',\n                      ec='#FC990E'))\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n\n    titlefmt = \"C{id:d}{noise}: Tot. var. expl. {var:.2g}%\".format\n    for i, img in enumerate(\n            iter_img(os.path.join(melodic_dir, \"melodic_IC.nii.gz\"))):\n\n        col = i % 2\n        row = i // 2\n        l_row = row * 2 + warning_row\n        is_noise = False\n\n        if classified_colors:\n            # If a noise components list is provided, assign red/green\n            is_noise = (i + 1) in noise_components\n            color_title = color_time = color_power = classified_colors[is_noise]\n\n        data = img.get_data()\n        for j in range(3):\n            ax1 = fig.add_subplot(gs[l_row:l_row + 2, j + col * 5])\n            sl = transform_to_2d(data, j)\n            m = np.abs(sl).max()\n            ax1.imshow(sl, vmin=-m, vmax=+m, cmap=cm.cold_white_hot,\n                       interpolation=\"nearest\")\n            ax1.contour(mask_sl[j], levels=[0.5], colors='k', linewidths=0.5)\n            plt.axis(\"off\")\n            ax1.autoscale_view('tight')\n            if j == 0:\n                ax1.set_title(\n                    titlefmt(id=i + 1,\n                             noise=' [noise]' * is_noise,\n                             var=stats[i, 1]),\n                    x=0, y=1.18, fontsize=7,\n                    horizontalalignment='left',\n                    verticalalignment='top',\n                    color=color_title)\n\n        ax2 = fig.add_subplot(gs[l_row, 3 + col * 5])\n        ax3 = fig.add_subplot(gs[l_row + 1, 3 + col * 5])\n\n        ax2.plot(np.arange(len(timeseries[:, i])) * tr, timeseries[:, i],\n                 linewidth=min(200 / len(timeseries[:, i]), 1.0),\n                 color=color_time)\n        ax2.set_xlim([0, len(timeseries[:, i]) * tr])\n        ax2.axes.get_yaxis().set_visible(False)\n        ax2.autoscale_view('tight')\n        ax2.tick_params(axis='both', which='major', pad=0)\n        sns.despine(left=True, bottom=True)\n        for tick in ax2.xaxis.get_major_ticks():\n            tick.label.set_fontsize(6)\n            tick.label.set_color(color_time)\n\n        ax3.plot(f[0:], power[0:, i], color=color_power,\n                 linewidth=min(100 / len(power[0:, i]), 1.0))\n        ax3.set_xlim([f[0], f.max()])\n        ax3.axes.get_yaxis().set_visible(False)\n        ax3.autoscale_view('tight')\n        ax3.tick_params(axis='both', which='major', pad=0)\n        for tick in ax3.xaxis.get_major_ticks():\n            tick.label.set_fontsize(6)\n            tick.label.set_color(color_power)\n        sns.despine(left=True, bottom=True)\n\n    plt.subplots_adjust(hspace=0.5)\n\n    image_buf = StringIO()\n    fig.savefig(image_buf, dpi=300, format='svg', transparent=True,\n                bbox_inches='tight', pad_inches=0.01)\n    fig.clf()\n    image_svg = image_buf.getvalue()\n\n    if compress is True or compress == 'auto':\n        image_svg = svg_compress(image_svg, compress)\n    image_svg = re.sub(' height=\"[0-9]+[a-z]*\"', '', image_svg, count=1)\n    image_svg = re.sub(' width=\"[0-9]+[a-z]*\"', '', image_svg, count=1)\n    image_svg = re.sub(' viewBox',\n                       ' preseveAspectRation=\"xMidYMid meet\" viewBox',\n                       image_svg, count=1)\n\n    Path(out_file).write_text(image_svg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    from os import path as op\n    from inspect import getfile, currentframe\n    from setuptools import setup, find_packages\n    from niworkflows.__about__ import (\n        __packagename__,\n        __author__,\n        __email__,\n        __maintainer__,\n        __license__,\n        __description__,\n        __longdesc__,\n        __url__,\n        DOWNLOAD_URL,\n        CLASSIFIERS,\n        REQUIRES,\n        SETUP_REQUIRES,\n        LINKS_REQUIRES,\n        TESTS_REQUIRES,\n        EXTRA_REQUIRES,\n    )\n\n    pkg_data = {\n        'niworkflows': [\n            'data/t1-mni_registration*.json',\n            'data/bold-mni_registration*.json',\n            'reports/figures.json',\n            'reports/fmriprep.yml',\n            'reports/report.tpl',\n        ]}\n\n    root_dir = op.dirname(op.abspath(getfile(currentframe())))\n    version = None\n    cmdclass = {}\n    if op.isfile(op.join(root_dir, __packagename__, 'VERSION')):\n        with open(op.join(root_dir, __packagename__, 'VERSION')) as vfile:\n            version = vfile.readline().strip()\n        pkg_data[__packagename__].insert(0, 'VERSION')\n\n    if version is None:\n        import versioneer\n        version = versioneer.get_version()\n        cmdclass = versioneer.get_cmdclass()\n\n    setup(\n        name=__packagename__,\n        version=version,\n        description=__description__,\n        long_description=__longdesc__,\n        author=__author__,\n        author_email=__email__,\n        maintainer=__maintainer__,\n        maintainer_email=__email__,\n        license=__license__,\n        url=__url__,\n        download_url=DOWNLOAD_URL,\n        classifiers=CLASSIFIERS,\n        packages=find_packages(exclude=['*.tests']),\n        zip_safe=False,\n        # Dependencies handling\n        setup_requires=SETUP_REQUIRES,\n        install_requires=list(set(REQUIRES)),\n        dependency_links=LINKS_REQUIRES,\n        tests_require=TESTS_REQUIRES,\n        extras_require=EXTRA_REQUIRES,\n        # Data\n        package_data=pkg_data,\n        include_package_data=True,\n        cmdclass=cmdclass,\n    )", "response": "Entry - point for the nii - internal versioneer package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_and_raise_exception(msg, data, cls=FoursquareException):\n  data = u'{0}'.format(data)\n  # We put data as a argument for log.error() so error tracking systems such\n  # as Sentry will properly group errors together by msg only\n  log.error(u'{0}: %s'.format(msg), data)\n  raise cls(u'{0}: {1}'.format(msg, data))", "response": "Calls log. error then raises an exception of class cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to GET data from an endpoint using retries", "response": "def _get(url, headers={}, params=None):\n    \"\"\"Tries to GET data from an endpoint using retries\"\"\"\n    param_string = _foursquare_urlencode(params)\n    for i in xrange(NUM_REQUEST_RETRIES):\n        try:\n            try:\n                response = requests.get(url, headers=headers, params=param_string, verify=VERIFY_SSL)\n                return _process_response(response)\n            except requests.exceptions.RequestException as e:\n                _log_and_raise_exception('Error connecting with foursquare API', e)\n        except FoursquareException as e:\n            # Some errors don't bear repeating\n            if e.__class__ in [InvalidAuth, ParamError, EndpointError, NotAuthorized, Deprecated]: raise\n            # If we've reached our last try, re-raise\n            if ((i + 1) == NUM_REQUEST_RETRIES): raise\n        time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _post(url, headers={}, data=None, files=None):\n    try:\n        response = requests.post(url, headers=headers, data=data, files=files, verify=VERIFY_SSL)\n        return _process_response(response)\n    except requests.exceptions.RequestException as e:\n        _log_and_raise_exception('Error connecting with foursquare API', e)", "response": "Tries to POST data to an endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking the request and handle exception processing", "response": "def _process_response(response):\n    \"\"\"Make the request and handle exception processing\"\"\"\n    # Read the response as JSON\n    try:\n        data = response.json()\n    except ValueError:\n        _log_and_raise_exception('Invalid response', response.text)\n\n    # Default case, Got proper response\n    if response.status_code == 200:\n        return { 'headers': response.headers, 'data': data }\n    return _raise_error_from_response(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _raise_error_from_response(data):\n    # Check the meta-data for why this request failed\n    meta = data.get('meta')\n    if meta:\n        # Account for foursquare conflicts\n        # see: https://developer.foursquare.com/overview/responses\n        if meta.get('code') in (200, 409): return data\n        exc = error_types.get(meta.get('errorType'))\n        if exc:\n            raise exc(meta.get('errorDetail'))\n        else:\n            _log_and_raise_exception('Unknown error. meta', meta)\n    else:\n        _log_and_raise_exception('Response format invalid, missing meta property. data', data)", "response": "Raises an exception if the response is not a 200 or 409 response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _attach_endpoints(self):\n        for name, endpoint in inspect.getmembers(self):\n            if inspect.isclass(endpoint) and issubclass(endpoint, self._Endpoint) and (endpoint is not self._Endpoint):\n                endpoint_instance = endpoint(self.base_requester)\n                setattr(self, endpoint_instance.endpoint, endpoint_instance)", "response": "Dynamically attach endpoint callables to this client"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the request should be permitted. Raises an appropriate exception if the request is not permitted.", "response": "def check_permissions(self, request):\n        \"\"\"\n        Check if the request should be permitted.\n        Raises an appropriate exception if the request is not permitted.\n        \"\"\"\n        permissions = [permission() for permission in self.permission_classes]\n        for permission in permissions:\n            if not permission.has_permission(request):\n                raise PermissionDenied()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, widget, basename, **parameters):\n        self.registry.append((widget, basename, parameters))", "response": "Register a widget with the given URL basename and any optional URL parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_to_json_response(self, context, **response_kwargs):\n        return HttpResponse(\n            self.convert_context_to_json(context),\n            content_type='application/json',\n            **response_kwargs\n        )", "response": "Returns a JSON response with the given context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterator(self):\n        for obj in (self.execute().json().get(\"items\") or []):\n            yield self.api_obj_class(self.api, obj)", "response": "Execute the API request and return an iterator over the objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the version of the Kubernetes API", "response": "def version(self):\n        \"\"\"\n        Get Kubernetes API version\n        \"\"\"\n        response = self.get(version=\"\", base=\"/version\")\n        response.raise_for_status()\n        data = response.json()\n        return (data[\"major\"], data[\"minor\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_kwargs(self, **kwargs):\n        version = kwargs.pop(\"version\", \"v1\")\n        if version == \"v1\":\n            base = kwargs.pop(\"base\", \"/api\")\n        elif \"/\" in version:\n            base = kwargs.pop(\"base\", \"/apis\")\n        else:\n            if \"base\" not in kwargs:\n                raise TypeError(\"unknown API version; base kwarg must be specified.\")\n            base = kwargs.pop(\"base\")\n        bits = [base, version]\n        # Overwrite (default) namespace from context if it was set\n        if \"namespace\" in kwargs:\n            n = kwargs.pop(\"namespace\")\n            if n is not None:\n                if n:\n                    namespace = n\n                else:\n                    namespace = self.config.namespace\n                if namespace:\n                    bits.extend([\n                        \"namespaces\",\n                        namespace,\n                    ])\n        url = kwargs.get(\"url\", \"\")\n        if url.startswith(\"/\"):\n            url = url[1:]\n        bits.append(url)\n        kwargs[\"url\"] = self.url + posixpath.join(*bits)\n        return kwargs", "response": "Creates a full URL to request based on arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, *args, **kwargs):\n        return self.session.request(*args, **self.get_kwargs(**kwargs))", "response": "Makes an API request based on arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute an HTTP GET.", "response": "def get(self, *args, **kwargs):\n        \"\"\"\n        Executes an HTTP GET.\n\n        :Parameters:\n           - `args`: Non-keyword arguments\n           - `kwargs`: Keyword arguments\n        \"\"\"\n        return self.session.get(*args, **self.get_kwargs(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef options(self, *args, **kwargs):\n        return self.session.options(*args, **self.get_kwargs(**kwargs))", "response": "Executes an HTTP OPTIONS."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute an HTTP HEAD.", "response": "def head(self, *args, **kwargs):\n        \"\"\"\n        Executes an HTTP HEAD.\n\n        :Parameters:\n           - `args`: Non-keyword arguments\n           - `kwargs`: Keyword arguments\n        \"\"\"\n        return self.session.head(*args, **self.get_kwargs(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post(self, *args, **kwargs):\n        return self.session.post(*args, **self.get_kwargs(**kwargs))", "response": "Executes an HTTP POST."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, *args, **kwargs):\n        return self.session.put(*args, **self.get_kwargs(**kwargs))", "response": "Executes an HTTP PUT."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef patch(self, *args, **kwargs):\n        return self.session.patch(*args, **self.get_kwargs(**kwargs))", "response": "Executes an HTTP PATCH."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, *args, **kwargs):\n        return self.session.delete(*args, **self.get_kwargs(**kwargs))", "response": "Executes an HTTP DELETE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_file(cls, filename, **kwargs):\n        filename = os.path.expanduser(filename)\n        if not os.path.isfile(filename):\n            raise exceptions.PyKubeError(\"Configuration file {} not found\".format(filename))\n        with open(filename) as f:\n            doc = yaml.safe_load(f.read())\n        self = cls(doc, **kwargs)\n        self.filename = filename\n        return self", "response": "Creates an instance of the KubeConfig class from a kubeconfig file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an instance of the KubeConfig class from a single URL.", "response": "def from_url(cls, url, **kwargs):\n        \"\"\"\n        Creates an instance of the KubeConfig class from a single URL (useful\n        for interacting with kubectl proxy).\n        \"\"\"\n        doc = {\n            \"clusters\": [\n                {\n                    \"name\": \"self\",\n                    \"cluster\": {\n                        \"server\": url,\n                    },\n                },\n            ],\n            \"contexts\": [\n                {\n                    \"name\": \"self\",\n                    \"context\": {\n                        \"cluster\": \"self\",\n                    },\n                }\n            ],\n            \"current-context\": \"self\",\n        }\n        self = cls(doc, **kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of known clusters by exposing as a read - only property.", "response": "def clusters(self):\n        \"\"\"\n        Returns known clusters by exposing as a read-only property.\n        \"\"\"\n        if not hasattr(self, \"_clusters\"):\n            cs = {}\n            for cr in self.doc[\"clusters\"]:\n                cs[cr[\"name\"]] = c = copy.deepcopy(cr[\"cluster\"])\n                if \"server\" not in c:\n                    c[\"server\"] = \"http://localhost\"\n                BytesOrFile.maybe_set(c, \"certificate-authority\")\n            self._clusters = cs\n        return self._clusters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef users(self):\n        if not hasattr(self, \"_users\"):\n            us = {}\n            if \"users\" in self.doc:\n                for ur in self.doc[\"users\"]:\n                    us[ur[\"name\"]] = u = copy.deepcopy(ur[\"user\"])\n                    BytesOrFile.maybe_set(u, \"client-certificate\")\n                    BytesOrFile.maybe_set(u, \"client-key\")\n            self._users = us\n        return self._users", "response": "Returns a list of known users by exposing as a read - only property."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contexts(self):\n        if not hasattr(self, \"_contexts\"):\n            cs = {}\n            for cr in self.doc[\"contexts\"]:\n                cs[cr[\"name\"]] = copy.deepcopy(cr[\"context\"])\n            self._contexts = cs\n        return self._contexts", "response": "Returns a list of known contexts by exposing as a read - only property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef user(self):\n        return self.users.get(self.contexts[self.current_context].get(\"user\", \"\"), {})", "response": "Returns the current user set by current context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bytes(self):\n        if self._filename:\n            with open(self._filename, \"rb\") as f:\n                return f.read()\n        else:\n            return self._bytes", "response": "Returns the provided data as bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filename(self):\n        if self._filename:\n            return self._filename\n        else:\n            with tempfile.NamedTemporaryFile(delete=False) as f:\n                f.write(self._bytes)\n            return f.name", "response": "Returns the provided data as a file location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef object_factory(api, api_version, kind):\n    resource_list = api.resource_list(api_version)\n    resource = next((resource for resource in resource_list[\"resources\"] if resource[\"kind\"] == kind), None)\n    base = NamespacedAPIObject if resource[\"namespaced\"] else APIObject\n    return type(kind, (base,), {\n        \"version\": api_version,\n        \"endpoint\": resource[\"name\"],\n        \"kind\": kind\n    })", "response": "Dynamically builds a Python class for the given Kubernetes object in an API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rollout_undo(self, target_revision=None):\n        if target_revision is None:\n            revision = {}\n        else:\n            revision = {\n                \"revision\": target_revision\n            }\n\n        params = {\n            \"kind\": \"DeploymentRollback\",\n            \"apiVersion\": self.version,\n            \"name\": self.name,\n            \"rollbackTo\": revision\n        }\n\n        kwargs = {\n            \"version\": self.version,\n            \"namespace\": self.namespace,\n            \"operation\": \"rollback\",\n        }\n        r = self.api.post(**self.api_kwargs(data=json.dumps(params), **kwargs))\n        r.raise_for_status()\n        return r.text", "response": "Produces same action as kubectl rollout undo deployment command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logs(self, container=None, pretty=None, previous=False,\n             since_seconds=None, since_time=None, timestamps=False,\n             tail_lines=None, limit_bytes=None):\n        \"\"\"\n        Produces the same result as calling kubectl logs pod/<pod-name>.\n        Check parameters meaning at\n        http://kubernetes.io/docs/api-reference/v1/operations/,\n        part 'read log of the specified Pod'. The result is plain text.\n        \"\"\"\n        log_call = \"log\"\n        params = {}\n        if container is not None:\n            params[\"container\"] = container\n        if pretty is not None:\n            params[\"pretty\"] = pretty\n        if previous:\n            params[\"previous\"] = \"true\"\n        if since_seconds is not None and since_time is None:\n            params[\"sinceSeconds\"] = int(since_seconds)\n        elif since_time is not None and since_seconds is None:\n            params[\"sinceTime\"] = since_time\n        if timestamps:\n            params[\"timestamps\"] = \"true\"\n        if tail_lines is not None:\n            params[\"tailLines\"] = int(tail_lines)\n        if limit_bytes is not None:\n            params[\"limitBytes\"] = int(limit_bytes)\n\n        query_string = urlencode(params)\n        log_call += \"?{}\".format(query_string) if query_string else \"\"\n        kwargs = {\n            \"version\": self.version,\n            \"namespace\": self.namespace,\n            \"operation\": log_call,\n        }\n        r = self.api.get(**self.api_kwargs(**kwargs))\n        r.raise_for_status()\n        return r.text", "response": "Returns the logs of the specified Pod."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _restart_thread(self):\n        while self.running['restart_thread']:\n            try:\n                endpoint = self.restart_q.get(timeout=.5)\n            except TimeoutError:\n                continue\n            log.info(\"_restart_thread(): Restarting Thread for endpoint %s\",\n                     endpoint)\n            self.unsubscribe(endpoint)\n            self.subscribe(endpoint)", "response": "Restarts subscription threads if their connection drops."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _subscription_thread(self, endpoint):\n        try:\n            conn = create_connection(self.addr + endpoint, timeout=5)\n        except WebSocketTimeoutException:\n            self.restart_q.put(endpoint)\n            return\n\n        while self.threads_running[endpoint]:\n            try:\n                msg = conn.recv()\n            except WebSocketTimeoutException:\n                self._controller_q.put(endpoint)\n\n            log.debug(\"%s, %s\", endpoint, msg)\n            ep, pair = endpoint.split('/')\n            log.debug(\"_subscription_thread(): Putting data on q..\")\n            try:\n                self.data_q.put((ep, pair, msg, time.time()), timeout=1)\n            except TimeoutError:\n                continue\n            finally:\n                log.debug(\"_subscription_thread(): Data Processed, looping back..\")\n        conn.close()\n        log.debug(\"_subscription_thread(): Thread Loop Ended.\")", "response": "This method is called by the thread that handles the incoming and outgoing messages from the server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting the basic facilities thread.", "response": "def start(self):\n        \"\"\"\n        Starts threads. Extend this in your child class.\n        :return:\n        \"\"\"\n        log.info(\"WSSAPI.start(): Starting Basic Facilities\")\n        self.running = True\n        if self._controller_thread is None or not self._controller_thread.is_alive():\n            self._controller_thread = Thread(target=self._controller,\n                                             daemon=True,\n                                             name='%s Controller Thread' %\n                                                  self.name)\n            self._controller_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate a command issued by internal threads.", "response": "def eval_command(self, cmd):\n        \"\"\"\n        Evaluates commands issued by internal threads. Extend this as necessary.\n        :param cmd:\n        :return:\n        \"\"\"\n        if cmd == 'restart':\n            self.restart()\n\n        elif cmd == 'stop':\n            self.stop()\n\n        else:\n            raise ValueError(\"Unknown Command passed to controller! %s\" % cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_pair(input_pair):\n        # There are some exceptions from the general formatting rule\n        # see https://api.kraken.com/0/public/AssetPairs\n        format_exceptions = ['BCHEUR', 'BCHUSD', 'BCHXBT', 'DASHEUR', 'DASHUSD', 'DASHXBT', 'EOSETH', 'EOSXBT', 'GNOETH', 'GNOXBT', 'USDTZUSD']\n        if input_pair.upper() in format_exceptions:\n            return input_pair.upper()\n\n        if len(input_pair) % 2 == 0:\n            base_cur, quote_cur = input_pair[:len(input_pair)//2], input_pair[len(input_pair)//2:]\n        else:\n            base_cur, quote_cur = input_pair.split(input_pair[len(input_pair)//2])\n\n        def add_prefix(input_string):\n            input_string = input_string.lower()\n            if any(x in input_string for x in ['usd', 'eur', 'jpy', 'gbp', 'cad']):\n                # appears to be fiat currency\n                if not input_string.startswith('z'):\n                    input_string = 'z' + input_string\n\n            else:\n                # Appears to be Crypto currency\n                if 'btc' in input_string:\n                    input_string = input_string.replace('btc', 'xbt')\n\n                if not input_string.startswith('x') or len(input_string) == 3:\n                    input_string = 'x' + input_string\n            return input_string\n\n        base_cur = add_prefix(base_cur)\n        quote_cur = add_prefix(quote_cur)\n\n        return (base_cur + quote_cur).upper()", "response": "Formats the input string to conform with kraken pair format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsigning the given payload dictionary with the key and secret.", "response": "def sign(self, payload):\n        \"\"\"\n        Signature method which wraps signature and nonce parameters around a\n        payload dictionary.\n        :param payload:\n        :return:\n        \"\"\"\n        nonce = str(int(time.time() * 1000))\n        package = {'apikey': self.key,\n                   'message': {'nonce': nonce, 'payload': payload}}\n\n        signature = hmac.new(self.secret, json.dumps(payload).hexdigest,\n                             hashlib.sha512).hexdigest()\n        package['signature'] = signature\n\n        return json.dumps(package)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n        super(BitstampWSS, self).start()\n\n        self.pusher = pusherclient.Pusher(self.addr, **self.__pusher_options)\n        self.pusher.connection.bind('pusher:connection_established',\n                                    self._register_bindings)\n        self.pusher.connect()", "response": "Start the pusher client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _register_bindings(self, data):\n        self._register_diff_order_book_channels()\n        self._register_live_orders_channels()\n        self._register_live_trades_channels()\n        self._register_order_book_channels()", "response": "This method is called when we connect to pusher. It is called when we connect to pusher and we connect to pusher."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _bind_channels(self, events, channels):\n        for channel_name in channels:\n            if channel_name in self.channels:\n                channel = self.pusher.subscribe(channel_name)\n                if isinstance(events, list):\n                    for event in events:\n                        channel.bind(event, channels[channel_name])\n                else:\n                    channel.bind(events, channels[channel_name])", "response": "Binds given events to callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _register_live_trades_channels(self):\n\n        channels = {'live_trades': self.btcusd_lt_callback,\n                    'live_trades_btceur': self.btceur_lt_callback,\n                    'live_trades_eurusd': self.eurusd_lt_callback,\n                    'live_trades_xrpusd': self.xrpusd_lt_callback,\n                    'live_trades_xrpeur': self.xrpeur_lt_callback,\n                    'live_trades_xrpbtc': self.xrpbtc_lt_callback}\n\n        event = 'trade'\n        self._bind_channels(event, channels)", "response": "Registers the live_trades_channels channels."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _register_order_book_channels(self):\n        channels = {'order_book': self.btcusd_ob_callback,\n                    'order_book_btceur': self.btceur_ob_callback,\n                    'order_book_eurusd': self.eurusd_ob_callback,\n                    'order_book_xrpusd': self.xrpusd_ob_callback,\n                    'order_book_xrpeur': self.xrpeur_ob_callback,\n                    'order_book_xrpbtc': self.xrpbtc_ob_callback}\n\n        event = 'data'\n        self._bind_channels(event, channels)", "response": "Registers the binding for the order_book channels."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _register_diff_order_book_channels(self):\n        channels = {'diff_order_book': self.btcusd_dob_callback,\n                    'diff_order_book_btceur': self.btceur_dob_callback,\n                    'diff_order_book_eurusd': self.eurusd_dob_callback,\n                    'diff_order_book_xrpusd': self.xrpusd_dob_callback,\n                    'diff_order_book_xrpeur': self.xrpeur_dob_callback,\n                    'diff_order_book_xrpbtc': self.xrpbtc_dob_callback}\n\n        event = 'data'\n        self._bind_channels(event, channels)", "response": "Registers the binding for the diff_order_book channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads key and secret from file.", "response": "def load_key(self, path):\n        \"\"\"\n        Load key and secret from file.\n        :param path: path to file with first two lines are key, secret respectively\n        \"\"\"\n        with open(path, 'r') as f:\n            self.key = f.readline().strip()\n            self.secret = f.readline().strip()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef api_request(*args, **kwargs):\n        r = requests.request(*args, **kwargs)\n        return APIResponse(r)", "response": "Wrapper which converts a requests. Response into our custom APIResponse object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign(self, url, endpoint, endpoint_path, method_verb, *args, **kwargs):\n        url = self.uri\n\n        return url, {'params': {'test_param': \"authenticated_chimichanga\"}}", "response": "This method is used to create a new URL for the current Kraken instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries exchange using given data.", "response": "def query(self, method_verb, endpoint, authenticate=False,\n              *args, **kwargs):\n        \"\"\"\n        Queries exchange using given data. Defaults to unauthenticated query.\n        :param method_verb: valid request type (PUT, GET, POST etc)\n        :param endpoint: endpoint path for the resource to query, sans the url &\n                         API version (i.e. '/btcusd/ticker/').\n        :param authenticate: Bool to determine whether or not a signature is\n                             required.\n        :param args: Optional args for requests.request()\n        :param kwargs: Optional Kwargs for self.sign() and requests.request()\n        :return: request.response() obj\n        \"\"\"\n        if self.version:\n            endpoint_path = join(self.version, endpoint)\n        else:\n            endpoint_path = endpoint\n\n        url = urljoin(self.uri, endpoint_path)\n        if authenticate:  # sign off kwargs and url before sending request\n            url, request_kwargs = self.sign(url, endpoint, endpoint_path,\n                                            method_verb, *args, **kwargs)\n        else:\n            request_kwargs = kwargs\n        log.debug(\"Making request to: %s, kwargs: %s\", url, request_kwargs)\n        r = self.api_request(method_verb, url, timeout=self.timeout,\n                             **request_kwargs)\n        log.debug(\"Made %s request made to %s, with headers %s and body %s. \"\n                  \"Status code %s\", r.request.method,\n                  r.request.url, r.request.headers,\n                  r.request.body, r.status_code)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval_command(self, cmd):\n        if cmd == 'restart':\n            self.restart(soft=True)\n        elif cmd == 'stop':\n            self.stop()", "response": "Thread func to allow restarting or stopping threads for example\n        when receiving a connection reset info message from the wss server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the heartbeats are on - time.", "response": "def _check_heartbeats(self, ts, *args, **kwargs):\n        \"\"\"\n        Checks if the heartbeats are on-time. If not, the channel id is escalated\n        to self._late_heartbeats and a warning is issued; once a hb is received\n        again from this channel, it'll be removed from this dict, and an Info\n        message logged.\n        :param ts: timestamp, declares when data was received by the client\n        :return:\n        \"\"\"\n        for chan_id in self._heartbeats:\n            if ts - self._heartbeats[chan_id] >= 10:\n                if chan_id not in self._late_heartbeats:\n                    try:\n                        # This is newly late; escalate\n                        log.warning(\"BitfinexWSS.heartbeats: Channel %s hasn't \"\n                                    \"sent a heartbeat in %s seconds!\",\n                                    self.channel_labels[chan_id],\n                                    ts - self._heartbeats[chan_id])\n                        self._late_heartbeats[chan_id] = ts\n                    except KeyError:\n                        # This channel ID Is not known to us - log and raise\n                        log.error(\"BitfinexWSS.heartbeats: Channel %s is not \"\n                                  \"registered in the connector's registry! \"\n                                  \"Restarting Connection to avoid errors..\",\n                                  chan_id)\n                        raise UnknownChannelError\n                else:\n                    # We know of this already\n                    continue\n            else:\n                # its not late\n                try:\n                    self._late_heartbeats.pop(chan_id)\n                except KeyError:\n                    # wasn't late before, check next channel\n                    continue\n                log.info(\"BitfinexWSS.heartbeats: Channel %s has sent a \"\n                         \"heartbeat again!\", self.channel_labels[chan_id])\n            self.ping()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n        super(BitfinexWSS, self).start()\n\n        log.info(\"BitfinexWSS.start(): Initializing Websocket connection..\")\n        while self.conn is None:\n            try:\n                self.conn = create_connection(self.addr, timeout=10)\n            except WebSocketTimeoutException:\n                self.conn = None\n                print(\"Couldn't create websocket connection - retrying!\")\n\n        log.info(\"BitfinexWSS.start(): Initializing receiver thread..\")\n        if not self.receiver_thread:\n            self.receiver_thread = Thread(target=self.receive, name='Receiver Thread')\n            self.receiver_thread.start()\n        else:\n            log.info(\"BitfinexWSS.start(): Thread not started! \"\n                     \"self.receiver_thread is populated!\")\n\n        log.info(\"BitfinexWSS.start(): Initializing processing thread..\")\n        if not self.processing_thread:\n            self.processing_thread = Thread(target=self.process, name='Processing Thread')\n            self.processing_thread.start()\n        else:\n            log.info(\"BitfinexWSS.start(): Thread not started! \"\n                     \"self.processing_thread is populated!\")\n\n        self.setup_subscriptions()", "response": "Start the websocket client threads\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        super(BitfinexWSS, self).stop()\n\n        log.info(\"BitfinexWSS.stop(): Stopping client..\")\n\n        log.info(\"BitfinexWSS.stop(): Joining receiver thread..\")\n        try:\n            self.receiver_thread.join()\n            if self.receiver_thread.is_alive():\n                time.time(1)\n        except AttributeError:\n            log.debug(\"BitfinexWSS.stop(): Receiver thread was not running!\")\n\n        log.info(\"BitfinexWSS.stop(): Joining processing thread..\")\n        try:\n            self.processing_thread.join()\n            if self.processing_thread.is_alive():\n                time.time(1)\n        except AttributeError:\n            log.debug(\"BitfinexWSS.stop(): Processing thread was not running!\")\n\n        log.info(\"BitfinexWSS.stop(): Closing websocket conection..\")\n        try:\n            self.conn.close()\n        except WebSocketConnectionClosedException:\n            pass\n        except AttributeError:\n            # Connection is None\n            pass\n\n        self.conn = None\n        self.processing_thread = None\n        self.receiver_thread = None\n\n        log.info(\"BitfinexWSS.stop(): Done!\")", "response": "Stop all threads and modules of the client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restart(self, soft=False):\n        log.info(\"BitfinexWSS.restart(): Restarting client..\")\n        super(BitfinexWSS, self).restart()\n\n        # cache channel labels temporarily if soft == True\n        channel_labels = [self.channel_labels[k] for k in self.channel_labels] if soft else None\n\n        # clear previous channel caches\n        self.channels = {}\n        self.channel_labels = {}\n        self.channel_states = {}\n\n        if channel_labels:\n            # re-subscribe to channels\n            for channel_name, kwargs in channel_labels:\n                self._subscribe(channel_name, **kwargs)", "response": "Restarts client. If soft is True, the client attempts to re-subscribe\n        to all channels which it was previously subscribed to.\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreceives incoming messages and puts them on the Client queue for processing.", "response": "def receive(self):\n        \"\"\"\n        Receives incoming websocket messages, and puts them on the Client queue\n        for processing.\n        :return:\n        \"\"\"\n        while self.running:\n            if self._receiver_lock.acquire(blocking=False):\n                try:\n                    raw = self.conn.recv()\n                except WebSocketTimeoutException:\n                    self._receiver_lock.release()\n                    continue\n                except WebSocketConnectionClosedException:\n                    # this needs to restart the client, while keeping track\n                    # of the currently subscribed channels!\n                    self.conn = None\n                    self._controller_q.put('restart')\n                except AttributeError:\n                    # self.conn is None, idle loop until shutdown of thread\n                    self._receiver_lock.release()\n                    continue\n                msg = time.time(), json.loads(raw)\n                log.debug(\"receiver Thread: Data Received: %s\", msg)\n                self.receiver_q.put(msg)\n                self._receiver_lock.release()\n            else:\n                # The receiver_lock was locked, idling until available\n                time.sleep(0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self):\n\n        while self.running:\n            if self._processor_lock.acquire(blocking=False):\n\n                if self.ping_timer:\n                    try:\n                        self._check_ping()\n                    except TimeoutError:\n                        log.exception(\"BitfinexWSS.ping(): TimedOut! (%ss)\" %\n                                      self.ping_timer)\n                    except (WebSocketConnectionClosedException,\n                            ConnectionResetError):\n                        log.exception(\"BitfinexWSS.ping(): Connection Error!\")\n                        self.conn = None\n                if not self.conn:\n                    # The connection was killed - initiate restart\n                    self._controller_q.put('restart')\n\n                skip_processing = False\n\n                try:\n                    ts, data = self.receiver_q.get(timeout=0.1)\n                except queue.Empty:\n                    skip_processing = True\n                    ts = time.time()\n                    data = None\n\n                if not skip_processing:\n                    log.debug(\"Processing Data: %s\", data)\n                    if isinstance(data, list):\n                        self.handle_data(ts, data)\n                    else:  # Not a list, hence it could be a response\n                        try:\n                            self.handle_response(ts, data)\n                        except UnknownEventError:\n\n                            # We don't know what event this is- Raise an\n                            # error & log data!\n                            log.exception(\"main() - UnknownEventError: %s\",\n                                          data)\n                            log.info(\"main() - Shutting Down due to \"\n                                     \"Unknown Error!\")\n                            self._controller_q.put('stop')\n                        except ConnectionResetError:\n                            log.info(\"processor Thread: Connection Was reset, \"\n                                     \"initiating restart\")\n                            self._controller_q.put('restart')\n\n                self._check_heartbeats(ts)\n                self._processor_lock.release()\n            else:\n                time.sleep(0.5)", "response": "Process the client queue and pass the data to the respective methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npass a response message to the corresponding event handler and also takes care of handling errors raised by the _raise_error handler.", "response": "def handle_response(self, ts, resp):\n        \"\"\"\n        Passes a response message to the corresponding event handler, and also\n        takes care of handling errors raised by the _raise_error handler.\n        :param ts: timestamp, declares when data was received by the client\n        :param resp: dict, containing info or error keys, among others\n        :return:\n        \"\"\"\n        log.info(\"handle_response: Handling response %s\", resp)\n        event = resp['event']\n        try:\n            self._event_handlers[event](ts, **resp)\n        # Handle Non-Critical Errors\n        except (InvalidChannelError, InvalidPairError, InvalidBookLengthError,\n                InvalidBookPrecisionError) as e:\n            log.exception(e)\n            print(e)\n        except (NotSubscribedError, AlreadySubscribedError) as e:\n            log.exception(e)\n            print(e)\n        except GenericSubscriptionError as e:\n            log.exception(e)\n            print(e)\n\n        # Handle Critical Errors\n        except InvalidEventError as e:\n            log.critical(\"handle_response(): %s; %s\", e, resp)\n            log.exception(e)\n            raise SystemError(e)\n        except KeyError:\n            # unsupported event!\n            raise UnknownEventError(\"handle_response(): %s\" % resp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_subscribed(self, *args,  chanId=None, channel=None, **kwargs):\n        log.debug(\"_handle_subscribed: %s - %s - %s\", chanId, channel, kwargs)\n        if chanId in self.channels:\n            raise AlreadyRegisteredError()\n\n        self._heartbeats[chanId] = time.time()\n\n        try:\n            channel_key = ('raw_'+channel\n                           if kwargs['prec'].startswith('R') and channel == 'book'\n                           else channel)\n        except KeyError:\n            channel_key = channel\n\n        try:\n            self.channels[chanId] = self._data_handlers[channel_key]\n        except KeyError:\n            raise UnknownChannelError()\n\n        # prep kwargs to be used as secondary value in dict key\n        try:\n            kwargs.pop('event')\n        except KeyError:\n            pass\n\n        try:\n            kwargs.pop('len')\n        except KeyError:\n            pass\n\n        try:\n            kwargs.pop('chanId')\n        except KeyError:\n            pass\n\n        self.channel_labels[chanId] = (channel_key, kwargs)", "response": "Handles responses to subscribe"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles un - subscribed messages from the server.", "response": "def _handle_unsubscribed(self, *args, chanId=None, **kwargs):\n        \"\"\"\n        Handles responses to unsubscribe() commands - removes a channel id from\n        the client.\n        :param chanId: int, represent channel id as assigned by server\n        \"\"\"\n        log.debug(\"_handle_unsubscribed: %s - %s\", chanId, kwargs)\n        try:\n            self.channels.pop(chanId)\n        except KeyError:\n            raise NotRegisteredError()\n\n        try:\n            self._heartbeats.pop(chanId)\n        except KeyError:\n            pass\n\n        try:\n            self._late_heartbeats.pop(chanId)\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises the proper exception for passed error code.", "response": "def _raise_error(self, *args, **kwargs):\n        \"\"\"\n        Raises the proper exception for passed error code. These must then be\n        handled by the layer calling _raise_error()\n        \"\"\"\n        log.debug(\"_raise_error(): %s\" % kwargs)\n        try:\n            error_code = str(kwargs['code'])\n        except KeyError as e:\n            raise FaultyPayloadError('_raise_error(): %s' % kwargs)\n\n        try:\n            raise self._code_handlers[error_code]()\n        except KeyError:\n            raise UnknownWSSError()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles info messages and executed corresponding code", "response": "def _handle_info(self, *args, **kwargs):\n        \"\"\"\n        Handles info messages and executed corresponding code\n        \"\"\"\n        if 'version' in kwargs:\n            # set api version number and exit\n            self.api_version = kwargs['version']\n            print(\"Initialized API with version %s\" % self.api_version)\n            return\n        try:\n            info_code = str(kwargs['code'])\n        except KeyError:\n            raise FaultyPayloadError(\"_handle_info: %s\" % kwargs)\n\n        if not info_code.startswith('2'):\n            raise ValueError(\"Info Code must start with 2! %s\", kwargs)\n\n        output_msg = \"_handle_info(): %s\" % kwargs\n        log.info(output_msg)\n\n        try:\n            self._code_handlers[info_code]()\n        except KeyError:\n            raise UnknownWSSInfo(output_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_pong(self, ts, *args, **kwargs):\n        log.info(\"BitfinexWSS.ping(): Ping received! (%ss)\",\n                 ts - self.ping_timer)\n        self.ping_timer = None", "response": "Handle pong messages ; resets the self. ping_timer variable and logs\n        info message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_data(self, ts, msg):\n        try:\n            chan_id, *data = msg\n        except ValueError as e:\n            # Too many or too few values\n            raise FaultyPayloadError(\"handle_data(): %s - %s\" % (msg, e))\n        self._heartbeats[chan_id] = ts\n        if data[0] == 'hb':\n            self._handle_hearbeat(ts, chan_id)\n            return\n        try:\n            self.channels[chan_id](ts, chan_id, data)\n        except KeyError:\n            raise NotRegisteredError(\"handle_data: %s not registered - \"\n                                     \"Payload: %s\" % (chan_id, msg))", "response": "Passes msg to the data handler determined by its channel id and data dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_ticker(self, ts, chan_id, data):\n        pair = self.channel_labels[chan_id][1]['pair']\n        entry = (*data, ts)\n        self.data_q.put(('ticker', pair, entry))", "response": "Adds received ticker data to self. tickers dict filed under its channel id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_candles(self, ts, chan_id, data):\n        pair = self.channel_labels[chan_id][1]['key'].split(':')[-1][1:]\n        entry = data, ts\n        self.data_q.put(('ohlc', pair, entry))", "response": "Store the data received via wss in self. data_q."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config(self, decimals_as_strings=True, ts_as_dates=False,\n               sequencing=False, **kwargs):\n        \"\"\"\n        Send configuration to websocket server\n        :param decimals_as_strings: bool, turn on/off decimals as strings\n        :param ts_as_dates: bool, decide to request timestamps as dates instead\n        :param sequencing: bool, turn on sequencing\n        :param kwargs:\n        :return:\n        \"\"\"\n        flags = 0\n        if decimals_as_strings:\n            flags += 8\n        if ts_as_dates:\n            flags += 32\n        if sequencing:\n            flags += 65536\n        payload = {'event': 'conf', 'flags': flags}\n        payload.update(kwargs)\n        self.send(payload)", "response": "Send configuration to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsubscribes to the passed pair s raw order book channel.", "response": "def raw_order_book(self, pair, prec=None, **kwargs):\n        \"\"\"\n        Subscribe to the passed pair's raw order book channel.\n        :param pair: str, Pair to request data for.\n        :param kwargs:\n        :return:\n        \"\"\"\n        prec = 'R0' if prec is None else prec\n        self._subscribe('book', pair=pair, prec=prec, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ohlc(self, pair, timeframe=None, **kwargs):\n        valid_tfs = ['1m', '5m', '15m', '30m', '1h', '3h', '6h', '12h', '1D',\n                     '7D', '14D', '1M']\n        if timeframe:\n            if timeframe not in valid_tfs:\n                raise ValueError(\"timeframe must be any of %s\" % valid_tfs)\n        else:\n            timeframe = '1m'\n        pair = 't' + pair if not pair.startswith('t') else pair\n        key = 'trade:' + timeframe + ':' + pair\n        self._subscribe('candles', key=key, **kwargs)", "response": "Subscribe to the passed pair s OHLC data channel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef header(self, text, level, raw=None):\n        return '\\n{0}\\n{1}\\n'.format(text,\n                                     self.hmarks[level] * column_width(text))", "response": "Render a header tag like h1 h2."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a given link with content and title.", "response": "def link(self, link, title, text):\n        \"\"\"Rendering a given link with content and title.\n\n        :param link: href link for ``<a>`` tag.\n        :param title: title content for `title` attribute.\n        :param text: text content for description.\n        \"\"\"\n        if self.anonymous_references:\n            underscore = '__'\n        else:\n            underscore = '_'\n        if title:\n            return self._raw_html(\n                '<a href=\"{link}\" title=\"{title}\">{text}</a>'.format(\n                    link=link, title=title, text=text\n                )\n            )\n        if not self.parse_relative_links:\n            return '\\ `{text} <{target}>`{underscore}\\ '.format(\n                target=link,\n                text=text,\n                underscore=underscore\n            )\n        else:\n            url_info = urlparse(link)\n            if url_info.scheme:\n                return '\\ `{text} <{target}>`{underscore}\\ '.format(\n                    target=link,\n                    text=text,\n                    underscore=underscore\n                )\n            else:\n                link_type = 'doc'\n                anchor = url_info.fragment\n                if url_info.fragment:\n                    if url_info.path:\n                        # Can't link to anchors via doc directive.\n                        anchor = ''\n                    else:\n                        # Example: [text](#anchor)\n                        link_type = 'ref'\n                doc_link = '{doc_name}{anchor}'.format(\n                    # splittext approach works whether or not path is set. It\n                    # will return an empty string if unset, which leads to\n                    # anchor only ref.\n                    doc_name=os.path.splitext(url_info.path)[0],\n                    anchor=anchor\n                )\n                return '\\ :{link_type}:`{text} <{doc_link}>`\\ '.format(\n                    link_type=link_type,\n                    doc_link=doc_link,\n                    text=text\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all events form the given iCal URL occurring in the given time range.", "response": "def events(url=None, file=None, string_content=None, start=None, end=None, fix_apple=False):\n    \"\"\"\n    Get all events form the given iCal URL occurring in the given time range.\n\n    :param url: iCal URL\n    :param file: iCal file path\n    :param string_content: iCal content as string\n    :param start: start date (see dateutils.date)\n    :param end: end date (see dateutils.date)\n    :param fix_apple: fix known Apple iCal issues\n    :return: events as list of dictionaries\n    \"\"\"\n    found_events = []\n\n    content = None\n\n    if url:\n        content = ICalDownload().data_from_url(url, apple_fix=fix_apple)\n\n    if not content and file:\n        content = ICalDownload().data_from_file(file, apple_fix=fix_apple)\n\n    if not content and string_content:\n        content = ICalDownload().data_from_string(string_content,\n                                                  apple_fix=fix_apple)\n\n    found_events += parse_events(content, start=start, end=end)\n\n    return found_events"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting data from the local data cache.", "response": "def request_data(key, url, file, string_content, start, end, fix_apple):\n    \"\"\"\n    Request data, update local data cache and remove this Thread form queue.\n\n    :param key: key for data source to get result later\n    :param url: iCal URL\n    :param file: iCal file path\n    :param string_content: iCal content as string\n    :param start: start date\n    :param end: end date\n    :param fix_apple: fix known Apple iCal issues\n    \"\"\"\n    data = []\n\n    try:\n        data += events(url=url, file=file, string_content=string_content,\n                       start=start, end=end, fix_apple=fix_apple)\n    finally:\n        update_events(key, data)\n        request_finished(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef events_async(key, url=None, file=None, start=None, string_content=None,\n                 end=None, fix_apple=False):\n    \"\"\"\n    Trigger an asynchronous data request.\n\n    :param key: key for data source to get result later\n    :param url: iCal URL\n    :param file: iCal file path\n    :param string_content: iCal content as string\n    :param start: start date\n    :param end: end date\n    :param fix_apple: fix known Apple iCal issues\n    \"\"\"\n    t = Thread(target=request_data, args=(key, url, file, string_content, start, end, fix_apple))\n\n    with event_lock:\n        if key not in threads:\n            threads[key] = []\n\n        threads[key].append(t)\n\n        if not threads[key][0].is_alive():\n            threads[key][0].start()", "response": "Trigger an asynchronous data request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request_finished(key):\n    with event_lock:\n        threads[key] = threads[key][1:]\n\n        if threads[key]:\n            threads[key][0].run()", "response": "Run the finished Thread in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads iCal data from URL.", "response": "def data_from_url(self, url, apple_fix=False):\n        \"\"\"\n        Download iCal data from URL.\n\n        :param url: URL to download\n        :param apple_fix: fix Apple bugs (protocol type and tzdata in iCal)\n        :return: decoded (and fixed) iCal data\n        \"\"\"\n        if apple_fix:\n            url = apple_url_fix(url)\n\n        _, content = self.http.request(url)\n\n        if not content:\n            raise ConnectionError('Could not get data from %s!' % url)\n\n        return self.decode(content, apple_fix=apple_fix)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread iCal data from file.", "response": "def data_from_file(self, file, apple_fix=False):\n        \"\"\"\n        Read iCal data from file.\n\n        :param file: file to read\n        :param apple_fix: fix wrong Apple tzdata in iCal\n        :return: decoded (and fixed) iCal data\n        \"\"\"\n        with open(file, mode='rb') as f:\n            content = f.read()\n\n        if not content:\n            raise IOError(\"File %f is not readable or is empty!\" % file)\n\n        return self.decode(content, apple_fix=apple_fix)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode content using the set charset.", "response": "def decode(self, content, apple_fix=False):\n        \"\"\"\n        Decode content using the set charset.\n\n        :param content: content do decode\n        :param apple_fix: fix Apple txdata bug\n        :return: decoded (and fixed) content\n        \"\"\"\n        content = content.decode(self.encoding)\n        content = content.replace('\\r', '')\n\n        if apple_fix:\n            content = apple_data_fix(content)\n\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_event(component, tz=UTC):\n\n    event = Event()\n\n    event.start = normalize(component.get('dtstart').dt, tz=tz)\n    \n    if component.get('dtend'):\n        event.end = normalize(component.get('dtend').dt, tz=tz)\n    elif component.get('duration'): # compute implicit end as start + duration\n        event.end = event.start + component.get('duration').dt\n    else: # compute implicit end as start + 0\n        event.end = event.start\n    \n    try:\n        event.summary = str(component.get('summary'))\n    except UnicodeEncodeError as e:\n        event.summary = str(component.get('summary').encode('utf-8'))\n    try:\n        event.description = str(component.get('description'))\n    except UnicodeEncodeError as e:\n        event.description = str(component.get('description').encode('utf-8'))\n    event.all_day = type(component.get('dtstart').dt) is date\n    if component.get('rrule'):\n        event.recurring = True\n    try:\n        event.location = str(component.get('location'))\n    except UnicodeEncodeError as e:\n        event.location = str(component.get('location').encode('utf-8'))\n\n    if component.get('attendee'):\n        event.attendee = component.get('attendee')\n        if type(event.attendee) is list:\n            temp = []\n            for a in event.attendee:\n                temp.append(a.encode('utf-8').decode('ascii'))\n            event.attendee = temp\n        else:\n            event.attendee = event.attendee.encode('utf-8').decode('ascii')\n\n    if component.get('uid'):\n        event.uid = component.get('uid').encode('utf-8').decode('ascii')\n\n    if component.get('organizer'):\n        event.organizer = component.get('organizer').encode('utf-8').decode('ascii')\n\n    return event", "response": "Create an event from its iCal representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting date or datetime to datetime with timezone.", "response": "def normalize(dt, tz=UTC):\n    \"\"\"\n    Convert date or datetime to datetime with timezone.\n\n    :param dt: date to normalize\n    :param tz: the normalized date's timezone\n    :return: date as datetime with timezone\n    \"\"\"\n    if type(dt) is date:\n        dt = dt + relativedelta(hour=0)\n    elif type(dt) is datetime:\n        pass\n    else:\n        raise ValueError(\"unknown type %s\" % type(dt))\n\n    if dt.tzinfo:\n        dt = dt.astimezone(tz)\n    else:\n        dt = dt.replace(tzinfo=tz)\n\n    return dt"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_events(content, start=None, end=None, default_span=timedelta(days=7)):\n    if not start:\n        start = now()\n\n    if not end:\n        end = start + default_span\n\n    if not content:\n        raise ValueError('Content is invalid!')\n\n    calendar = Calendar.from_ical(content)\n    \n    # Find the calendar's timezone info, or use UTC\n    for c in calendar.walk():\n        if c.name == 'VTIMEZONE':\n            cal_tz = gettz(str(c['TZID']))\n            break;\n    else:\n        cal_tz = UTC\n\n    start = normalize(start, cal_tz)\n    end = normalize(end, cal_tz)\n\n    found = []\n\n    for component in calendar.walk():\n        if component.name == \"VEVENT\":\n            e = create_event(component)\n            if e.recurring:\n                # Unfold recurring events according to their rrule\n                rule = parse_rrule(component, cal_tz)\n                dur = e.end - e.start\n                found.extend(e.copy_to(dt) for dt in rule.between(start - dur, end, inc=True))\n            elif e.end >= start and e.start <= end:\n                found.append(e)\n    return found", "response": "Parse the iCal file content and return a list of events occurring in a given time range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a icalendar component and returns a rrule or rruleset instance.", "response": "def parse_rrule(component, tz=UTC):\n    \"\"\"\n    Extract a dateutil.rrule object from an icalendar component. Also includes\n    the component's dtstart and exdate properties. The rdate and exrule\n    properties are not yet supported.\n    \n    :param component: icalendar component\n    :param tz: timezone for DST handling\n    :return: extracted rrule or rruleset\n    \"\"\"\n    if component.get('rrule'):\n        # component['rrule'] can be both a scalar and a list\n        rrules = component['rrule']\n        if not isinstance(rrules, list):\n            rrules = [rrules]\n\n        # Since DTSTART are always made timezone aware, UNTIL with no tzinfo\n        # must be converted to UTC.\n        for rule in rrules:\n            until = rule.get(\"until\")\n            for idx, dt in enumerate(until or []):\n                if not hasattr(dt, 'tzinfo'):\n                    until[idx] = normalize(normalize(dt, tz=tz), tz=UTC)\n\n        # Parse the rrules, might return a rruleset instance, instead of rrule\n        rule = rrulestr('\\n'.join(x.to_ical().decode() for x in rrules), dtstart=normalize(component['dtstart'].dt, tz=tz))\n        \n        if component.get('exdate'):\n            # Make sure, to work with a rruleset\n            if isinstance(rule, rrule):\n                rules = rruleset()\n                rules.rrule(rule)\n                rule = rules\n            \n            # Add exdates to the rruleset\n            for exd in extract_exdates(component):\n                rule.exdate(exd)\n        \n        #TODO: What about rdates and exrules?\n        \n    # You really want an rrule for a component without rrule? Here you are.\n    else:\n        rule = rruleset()\n        rule.rdate(normalize(component['dtstart'].dt, tz=tz))\n    \n    return rule"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile a list of all exception dates stored with a component.", "response": "def extract_exdates(component):\n    \"\"\"\n    Compile a list of all exception dates stored with a component.\n    \n    :param component: icalendar iCal component\n    :return: list of exception dates\n    \"\"\"\n    dates = []\n\n    exd_prop = component.get('exdate')\n    if exd_prop:\n        if isinstance(exd_prop, list): # In case there is more than one exdate property\n            for exd_list in exd_prop:\n                dates.extend(normalize(exd.dt) for exd in exd_list.dts)\n        elif isinstance(exd_prop, vDDDLists):\n            dates.extend(normalize(exd.dt) for exd in exd_prop.dts)\n\n    return dates"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new event equal to this with new start date.", "response": "def copy_to(self, new_start=None, uid=None):\n        \"\"\"\n        Create a new event equal to this with new start date.\n\n        :param new_start: new start date\n        :param uid: UID of new event\n        :return: new event\n        \"\"\"\n        if not new_start:\n            new_start = self.start\n\n        if not uid:\n            uid = \"%s_%d\" % (self.uid, randint(0, 1000000))\n\n        ne = Event()\n        ne.summary = self.summary\n        ne.description = self.description\n        ne.start = new_start\n        \n        if self.end:\n            duration = self.end - self.start\n            ne.end = (new_start + duration)\n\n        ne.all_day = self.all_day\n        ne.recurring = self.recurring\n        ne.location = self.location\n        ne.uid = uid\n\n        return ne"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads RSA public key Travis will use for this repo.", "response": "def fetch_public_key(repo):\n    \"\"\"Download RSA public key Travis will use for this repo.\n\n    Travis API docs: http://docs.travis-ci.com/api/#repository-keys\n    \"\"\"\n    keyurl = 'https://api.travis-ci.org/repos/{0}/key'.format(repo)\n    data = json.loads(urlopen(keyurl).read())\n    if 'key' not in data:\n        errmsg = \"Could not find public key for repo: {}.\\n\".format(repo)\n        errmsg += \"Have you already added your GitHub repo to Travis?\"\n        raise ValueError(errmsg)\n    return data['key']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_empty_branch(self, repo, base_branch, new_branch, prefix):\n        # extra safeguard to make sure we are handling a bot branch here\n        assert new_branch.startswith(prefix)\n        comp = repo.compare(base_branch, new_branch)\n        logger.info(\"Got a total of {} commits in {}\".format(comp.total_commits, new_branch))\n        return comp.total_commits == 0", "response": "Checks if a branch is empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_branch(self, repo, branch, prefix):\n        # extra safeguard to make sure we are handling a bot branch here\n        assert branch.startswith(prefix)\n        ref = repo.get_git_ref(\"/\".join([\"heads\", branch]))\n        ref.delete()", "response": "Deletes a branch.\n        :param repo: github.Repository\n        :param branch: string name of the branch to delete"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the current set of requirements.", "response": "def update(self, **kwargs):\n        \"\"\"\n        Main entrypoint to kick off an update run.\n        :param kwargs:\n        :return: RequirementsBundle\n        \"\"\"\n        self.configure(**kwargs)\n        self.get_all_requirements()\n        self.apply_updates(\n            initial=kwargs.get(\"initial\", False),\n            scheduled=kwargs.get(\"scheduled\", False)\n        )\n\n        return self.req_bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can_pull(self, initial, scheduled):\n        if not initial and self.config.is_valid_schedule():\n            # if the config has a valid schedule, return True if this is a scheduled run\n            return scheduled\n        return True", "response": "Determines if pull requests should be created based on the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close_stale_prs(self, update, pull_request, scheduled):\n        closed = []\n        if self.bot_token and not pull_request.is_initial:\n            for pr in self.pull_requests:\n                close_pr = False\n                same_title = \\\n                    pr.canonical_title(self.config.pr_prefix) == \\\n                    pull_request.canonical_title(self.config.pr_prefix)\n\n                if scheduled and pull_request.is_scheduled:\n                    # check that the PR is open and the title does not match\n                    if pr.is_open and not same_title:\n                        # we want to close the previous scheduled PR if it is not merged yet\n                        # and we want to close all previous updates if the user choose to\n                        # switch to a scheduled update\n                        if pr.is_scheduled or pr.is_update:\n                            close_pr = True\n                elif pull_request.is_update:\n                    # check that, the pr is an update, is open, the titles are not equal and that\n                    # the requirement matches\n                    if pr.is_update and \\\n                        pr.is_open and \\\n                            not same_title and \\\n                            pr.get_requirement(self.config.pr_prefix) == update.requirement.key:\n                        # there's a possible race condition where multiple updates with more than\n                        # one target version conflict with each other (closing each others PRs).\n                        # Check that's not the case here\n                        if not self.has_conflicting_update(update):\n                            close_pr = True\n\n                if close_pr and self.is_bot_the_only_committer(pr=pr):\n                    logger.info(\"Closing stale PR {} for {}\".format(pr.title, pull_request.title))\n                    self.provider.close_pull_request(\n                        bot_repo=self.bot_repo,\n                        user_repo=self.user_repo,\n                        pull_request=pr,\n                        comment=\"Closing this in favor of #{}\".format(\n                            pull_request.number),\n                        prefix=self.config.branch_prefix\n                    )\n                    pr.state = \"closed\"\n                    closed.append(pr)\n        for closed_pr in closed:\n            self.pull_requests.remove(closed_pr)", "response": "Closes stale pull requests for the given update."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_bot_the_only_committer(self, pr):\n        committer = self.provider.get_pull_request_committer(\n            self.user_repo,\n            pr)\n        # flatten the list and remove duplicates\n        committer_set = set([c.login for c in committer])\n\n        # it's impossible to get the bots login if this is an integration, just check that\n        # there's only one commit in the commit history.\n        if self.integration or getattr(self.provider, 'name', '') == 'gitlab':\n            return len(committer_set) == 1\n\n        # check that there's exactly one committer in this PRs commit history and\n        # that the committer is the bot\n        return len(committer_set) == 1 and self.provider.is_same_user(self.bot, committer[0])", "response": "Checks if the bot is the only committer for the given pull request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_conflicting_update(self, update):\n        # we explicitly want a flat list of updates here, that's why we call iter_updates\n        # with both `initial` and `scheduled` == False\n        for _, _, _, updates in self.iter_updates(initial=False, scheduled=False):\n            for _update in updates:\n                if (\n                        update.requirement.key == _update.requirement.key and\n                        (\n                                update.commit_message != _update.commit_message or\n                                update.requirement.latest_version_within_specs !=\n                                _update.requirement.latest_version_within_specs\n                        )\n                ):\n                    logger.info(\"{} conflicting with {}/{}\".format(\n                        update.requirement.key,\n                        update.requirement.latest_version_within_specs,\n                        _update.requirement.latest_version_within_specs)\n                    )\n                    return True\n        return False", "response": "Checks if there are conflicting updates."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new branch.", "response": "def create_branch(self, new_branch, delete_empty=False):\n        \"\"\"\n        Creates a new branch.\n        :param new_branch: string name of the new branch\n        :param delete_empty: bool -- delete the branch if it is empty\n        :return: bool -- True if successfull\n        \"\"\"\n        logger.info(\"Preparing to create branch {} from {}\".format(new_branch, self.config.branch))\n        try:\n            # create new branch\n            self.provider.create_branch(\n                base_branch=self.config.branch,\n                new_branch=new_branch,\n                repo=self.user_repo\n            )\n            logger.info(\"Created branch {} from {}\".format(new_branch, self.config.branch))\n            return True\n        except BranchExistsError:\n            logger.info(\"Branch {} exists.\".format(new_branch))\n            # if the branch exists, is empty and delete_empty is set, delete it and call\n            # this function again\n            if delete_empty:\n                if self.provider.is_empty_branch(self.user_repo, self.config.branch, new_branch,\n                                                 self.config.branch_prefix):\n                    self.provider.delete_branch(self.user_repo, new_branch,\n                                                self.config.branch_prefix)\n                    logger.info(\"Branch {} was empty and has been deleted\".format(new_branch))\n                    return self.create_branch(new_branch, delete_empty=False)\n                logger.info(\"Branch {} is not empty\".format(new_branch))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a branch is empty.", "response": "def is_empty_branch(self, repo, base_branch, new_branch, prefix):\n        \"\"\"\n        Compares the top commits of two branches.\n        Please note: This function isn't checking if `base_branch` is a direct\n        parent of `new_branch`, see\n        http://stackoverflow.com/questions/3161204/find-the-parent-branch-of-a-git-branch\n        :param repo: github.Repository\n        :param base_branch: string name of the base branch\n        :param new_branch: string name of the new branch\n        :param prefix: string branch prefix, default 'pyup-'\n        :return: bool -- True if empty\n        \"\"\"\n        # extra safeguard to make sure we are handling a bot branch here\n        assert new_branch.startswith(prefix)\n        comp = repo.repository_compare(base_branch, new_branch)\n        n = len(comp.commits)\n        logger.info(\"Got a total of {} commits in {}\".format(n, new_branch))\n        return n == 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a branch. :param repo: github.Repository :param branch: string name of the branch to delete", "response": "def delete_branch(self, repo, branch, prefix):\n        \"\"\"\n        Deletes a branch.\n        :param repo: github.Repository\n        :param branch: string name of the branch to delete\n        \"\"\"\n        # make sure that the name of the branch begins with pyup.\n        assert branch.startswith(prefix)\n        obj = repo.branches.get(branch)\n        obj.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_config(self, d):\n        for key, value in d.items():\n            if hasattr(self, key):\n                if key == \"requirements\":\n                    items, value = value, []\n                    for item in items:\n                        if isinstance(item, basestring):\n                            req = RequirementConfig(path=item)\n                        elif isinstance(item, dict):\n                            path, item = item.popitem()\n                            req = RequirementConfig(\n                                path=path,\n                                pin=item.get(\"pin\", None),\n                                compile=item.get(\"compile\", False),\n                                update=item.get(\"update\", Config.UPDATE_ALL)\n                            )\n                        value.append(req)\n                        # add constraint requirement files to config\n                        if req.compile:\n                            for spec in req.compile.specs:\n                                value.append(RequirementConfig(path=spec, pin=False))\n                elif key == \"assignees\":\n                    # assignees can be a string or a list. If it's a string, convert it to a list\n                    # to make things consistent\n                    if isinstance(value, basestring):\n                        value = [value, ]\n                elif key == 'gitlab':\n                    value = GitlabConfig(**value)\n                elif key == 'pr_prefix':\n                    # make sure that pr prefixes don't contain a PIPE\n                    if \"|\" in value:\n                        continue\n                # cast ints and floats to str\n                if isinstance(value, (int, float)) and not isinstance(value, bool):\n                    value = str(value)\n\n                setattr(self, key, value)", "response": "Updates the config object with the contents of the dictionary d."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the attribute for a given requirement file in path", "response": "def _get_requirement_attr(self, attr, path):\n        \"\"\"\n        Gets the attribute for a given requirement file in path\n        :param attr: string, attribute\n        :param path: string, path\n        :return: The attribute for the requirement, or the global default\n        \"\"\"\n        for req_file in self.requirements:\n            if path.strip(\"/\") == req_file.path.strip(\"/\"):\n                return getattr(req_file, attr)\n        return getattr(self, attr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef can_update_insecure(self, path):\n        return self._get_requirement_attr(\"update\", path=path) in (Config.UPDATE_ALL,\n                                                                   Config.UPDATE_INSECURE,\n                                                                   Config.UPDATE_INSECURE_TYPO)", "response": "Checks if the given path can be updated if insecure."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if a requirement can be updated.", "response": "def should_update(self, requirement, requirement_file):\n        \"\"\"\n        Determines if a requirement can be updated\n        :param requirement: Requirement\n        :param requirement_file: RequirementFile\n        :return: bool\n        \"\"\"\n        path = requirement_file.path\n        if self.config.can_update_all(path) or \\\n                (self.config.can_update_insecure(path) and requirement.is_insecure):\n            # handle unpinned requirements only if pin is set\n            if not requirement.is_pinned:\n                return self.config.can_pin(path)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kill_the_system(self, warning: str):\n        log.critical('Kill reason: ' + warning)\n        if self.DEBUG:\n            return\n\n        try:\n            self.mail_this(warning)\n        except socket.gaierror:\n            current_time = time.localtime()\n            formatted_time = time.strftime('%Y-%m-%d %I:%M:%S%p', current_time)\n            with open(self.config['global']['killer_file'], 'a', encoding='utf-8') as killer_file:\n                killer_file.write('Time: {0}\\nInternet is out.\\n'\n                                  'Failure: {1}\\n\\n'.format(formatted_time, warning))", "response": "Send an e - mail and then the system down quickly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a KillerBase instance subclassed based on the OS.", "response": "def get_killer(args):\n    \"\"\"Returns a KillerBase instance subclassed based on the OS.\"\"\"\n    if POSIX:\n        log.debug('Platform: POSIX')\n        from killer.killer_posix import KillerPosix\n        return KillerPosix(config_path=args.config, debug=args.debug)\n    elif WINDOWS:\n        log.debug('Platform: Windows')\n        from killer.killer_windows import KillerWindows\n        return KillerWindows(config_path=args.config, debug=args.debug)\n    else:\n        # TODO: WSL\n        # TODO: OSX\n        # TODO: BSD\n        raise NotImplementedError(\"Your platform is not currently supported.\"\n                                  \"If you would like support to be added, or \"\n                                  \"if your platform is supported and this is \"\n                                  \"a bug, please open an issue on GitHub!\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the names of power devices of the specified type.", "response": "def get_devices(device_type: DeviceType) -> Iterator[str]:\n    \"\"\"Gets names of power devices of the specified type.\n\n    :param str device_type: the type of the devices to retrieve\n    :return: the device names\n    :rtype: Iterator[str]\n    \"\"\"\n    for device in BASE_PATH.iterdir():\n        with open(str(Path(device, 'type'))) as type_file:\n            if type_file.readline().strip() == device_type.value:\n                yield device.name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the given property for a device.", "response": "def _get_property(device_path: Union[Path, str], property_name: str) -> str:\n    \"\"\"Gets the given property for a device.\"\"\"\n    with open(str(Path(device_path, property_name))) as file:\n        return file.readline().strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the power status of the system.", "response": "def get_power_status() -> SystemPowerStatus:\n    \"\"\"Retrieves the power status of the system.\n\n    The status indicates whether the system is running on AC or DC power,\n    whether the battery is currently charging, how much battery life remains,\n    and if battery saver is on or off.\n\n    :raises OSError: if the call to GetSystemPowerStatus fails\n    :return: the power status\n    :rtype: SystemPowerStatus\n    \"\"\"\n    get_system_power_status = ctypes.windll.kernel32.GetSystemPowerStatus\n    get_system_power_status.argtypes = [ctypes.POINTER(SystemPowerStatus)]\n    get_system_power_status.restype = wintypes.BOOL\n    status = SystemPowerStatus()\n\n    if not get_system_power_status(ctypes.pointer(status)):\n        raise ctypes.WinError()\n    else:\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef abilities(api_key=None, add_headers=None):\n    client = ClientMixin(api_key=api_key)\n    result = client.request('GET', endpoint='abilities',\n                            add_headers=add_headers,)\n    return result['abilities']", "response": "Fetch a list of permission - like strings for this account."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef can(ability, add_headers=None):\n    client = ClientMixin(api_key=None)\n    try:\n        client.request('GET', endpoint='abilities/%s' % ability,\n                       add_headers=add_headers)\n        return True\n    except Exception:\n        pass\n    return False", "response": "Test whether an ability is allowed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the global api_key from a file path.", "response": "def set_api_key_from_file(path, set_global=True):\n    \"\"\"Set the global api_key from a file path.\"\"\"\n    with open(path, 'r+b') as f:\n        global api_key\n        api_key = f.read().strip()\n    return api_key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve(self, from_email, resolution=None):\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        endpoint = '/'.join((self.endpoint, self.id,))\n        add_headers = {'from': from_email, }\n        data = {\n            'incident': {\n                'type': 'incident',\n                'status': 'resolved',\n            }\n        }\n\n        if resolution is not None:\n            data['resolution'] = resolution\n\n        result = self.request('PUT',\n                              endpoint=endpoint,\n                              add_headers=add_headers,\n                              data=data,)\n        return result", "response": "Resolve an incident using a valid email address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reassign(self, from_email, user_ids):\n        endpoint = '/'.join((self.endpoint, self.id,))\n\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        if user_ids is None or not isinstance(user_ids, list):\n            raise InvalidArguments(user_ids)\n        if not all([isinstance(i, six.string_types) for i in user_ids]):\n            raise InvalidArguments(user_ids)\n\n        assignees = [\n            {\n                'assignee': {\n                    'id': user_id,\n                    'type': 'user_reference',\n                }\n            }\n            for user_id in user_ids\n        ]\n\n        add_headers = {'from': from_email, }\n        data = {\n            'incident': {\n                'type': 'incident',\n                'assignments': assignees,\n            }\n        }\n\n        result = self.request('PUT',\n                              endpoint=endpoint,\n                              add_headers=add_headers,\n                              data=data,)\n        return result", "response": "Reassign an incident to other users using a valid email address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log_entries(self, time_zone='UTC', is_overview=False,\n                    include=None, fetch_all=True):\n        \"\"\"Query for log entries on an incident instance.\"\"\"\n        endpoint = '/'.join((self.endpoint, self.id, 'log_entries'))\n\n        query_params = {\n            'time_zone': time_zone,\n            'is_overview': json.dumps(is_overview),\n        }\n\n        if include:\n            query_params['include'] = include\n\n        result = self.logEntryFactory.find(\n            endpoint=endpoint,\n            api_key=self.api_key,\n            fetch_all=fetch_all,\n            **query_params\n        )\n\n        return result", "response": "Query for log entries on an incident instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notes(self):\n        endpoint = '/'.join((self.endpoint, self.id, 'notes'))\n        return self.noteFactory.find(\n            endpoint=endpoint,\n            api_key=self.api_key,\n        )", "response": "Query for notes attached to this incident."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a note for this incident.", "response": "def create_note(self, from_email, content):\n        \"\"\"Create a note for this incident.\"\"\"\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        endpoint = '/'.join((self.endpoint, self.id, 'notes'))\n        add_headers = {'from': from_email, }\n\n        return self.noteFactory.create(\n            endpoint=endpoint,\n            api_key=self.api_key,\n            add_headers=add_headers,\n            data={'content': content},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef snooze(self, from_email, duration):\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        endpoint = '/'.join((self.endpoint, self.id, 'snooze'))\n        add_headers = {'from': from_email, }\n\n        return self.__class__.create(\n            endpoint=endpoint,\n            api_key=self.api_key,\n            add_headers=add_headers,\n            data_key='duration',\n            data=duration,\n        )", "response": "Snooze this incident for duration seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging other incidents into this incident.", "response": "def merge(self, from_email, source_incidents):\n        \"\"\"Merge other incidents into this incident.\"\"\"\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        add_headers = {'from': from_email, }\n        endpoint = '/'.join((self.endpoint, self.id, 'merge'))\n        incident_ids = [entity['id'] if isinstance(entity, Entity) else entity\n                        for entity in source_incidents]\n        incident_references = [{'type': 'incident_reference', 'id': id_}\n                               for id_ in incident_ids]\n\n        return self.__class__.create(\n            endpoint=endpoint,\n            api_key=self.api_key,\n            add_headers=add_headers,\n            data_key='source_incidents',\n            data=incident_references,\n            method='PUT',\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying for alerts attached to this incident.", "response": "def alerts(self):\n        \"\"\"Query for alerts attached to this incident.\"\"\"\n        endpoint = '/'.join((self.endpoint, self.id, 'alerts'))\n        return self.alertFactory.find(\n            endpoint=endpoint,\n            api_key=self.api_key,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(cls, *args, **kwargs):\n        seconds = 60 * 60 * 24 * 30  # seconds in 30 days\n        until = kwargs.pop('until', None)\n        since = kwargs.pop('since', None)\n\n        if until is None:\n            until = datetime.datetime.now()\n\n        if since is None:\n            since = until - datetime.timedelta(seconds=seconds)\n\n        dt = until - since\n        if dt > datetime.timedelta(seconds=seconds):\n            raise InvalidArguments(until, since)\n\n        kwargs['since'] = since.isoformat()\n        kwargs['until'] = until.isoformat()\n\n        return getattr(Entity, 'find').__func__(cls, *args, **kwargs)", "response": "Find notifications.\n\n        Optional kwargs are:\n            since:\n                datetime instance\n            until:\n                datetime instance\n\n        If not specified, until will default to now(), and since will default\n        to 30 days prior to until.\n\n        As per PD spec, date range must not exceed 1 month."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all instances of services for this EP.", "response": "def services(self):\n        \"\"\"Fetch all instances of services for this EP.\"\"\"\n        ids = [ref['id'] for ref in self['services']]\n        return [Service.fetch(id) for id in ids]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch(cls, id, incident=None, endpoint=None, *args, **kwargs):\n        if incident is None and endpoint is None:\n            raise InvalidArguments(incident, endpoint)\n\n        if endpoint is None:\n            iid = incident['id'] if isinstance(incident, Entity) else incident\n            endpoint = 'incidents/{0}/alerts'.format(iid)\n\n        return getattr(Entity, 'fetch').__func__(cls, id, endpoint=endpoint,\n                                                 *args, **kwargs)", "response": "Customize fetch because this is a nested resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving an alert using a valid email address.", "response": "def resolve(self, from_email):\n        \"\"\"Resolve an alert using a valid email address.\"\"\"\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        parent_incident_id = self['incident']['id']\n        endpoint_format = 'incidents/{0}/alerts/{1}'\n        endpoint = endpoint_format.format(parent_incident_id, self['id'])\n\n        add_headers = {'from': from_email, }\n        data = {\n            'alert': {\n                'id': self['id'],\n                'type': 'alert',\n                'status': 'resolved',\n            }\n        }\n\n        result = self.request('PUT',\n                              endpoint=endpoint,\n                              add_headers=add_headers,\n                              data=data,)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef associate(self, from_email, new_parent_incident=None):\n        if from_email is None or not isinstance(from_email, six.string_types):\n            raise MissingFromEmail(from_email)\n\n        if new_parent_incident is None:\n            raise InvalidArguments(new_parent_incident)\n\n        parent_incident_id = self['incident']['id']\n        endpoint_format = 'incidents/{0}/alerts/{1}'\n        endpoint = endpoint_format.format(parent_incident_id, self['id'])\n\n        if isinstance(new_parent_incident, Entity):\n            new_parent_incident_id = new_parent_incident['id']\n        else:\n            new_parent_incident_id = new_parent_incident\n\n        add_headers = {'from': from_email, }\n        data = {\n            'alert': {\n                'id': self['id'],\n                'type': 'alert',\n                'incident': {\n                    'type': 'incident',\n                    'id': new_parent_incident_id,\n                }\n            }\n        }\n\n        result = self.request('PUT',\n                              endpoint=endpoint,\n                              add_headers=add_headers,\n                              data=data,)\n        return result", "response": "Associate an alert with an incident using a valid email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(cls, id, service=None, endpoint=None, *args, **kwargs):\n        if service is None and endpoint is None:\n            raise InvalidArguments(service, endpoint)\n\n        if endpoint is None:\n            sid = service['id'] if isinstance(service, Entity) else service\n            endpoint = 'services/{0}/integrations'.format(sid)\n\n        return getattr(Entity, 'fetch').__func__(cls, id, endpoint=endpoint,\n                                                 *args, **kwargs)", "response": "Customize fetch because it lives on a special endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, service=None, endpoint=None, data=None, *args, **kwargs):\n        cls.validate(data)\n\n        if service is None and endpoint is None:\n            raise InvalidArguments(service, endpoint)\n        if endpoint is None:\n            sid = service['id'] if isinstance(service, Entity) else service\n            endpoint = 'services/{0}/integrations'.format(sid)\n\n        # otherwise endpoint should contain the service path too\n        return getattr(Entity, 'create').__func__(cls, endpoint=endpoint,\n                                                  data=data, *args, **kwargs)", "response": "Create an integration within the scope of a service or endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_oncall(self, **kwargs):\n\n        endpoint = '/'.join((self.endpoint, self.id, 'users'))\n\n        return self.request('GET', endpoint=endpoint, query_params=kwargs)", "response": "Retrieve this schedule s on call users."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sanitize_ep(endpoint, plural=False):\n        # if we need a plural endpoint (acessing lists)\n        if plural:\n            if endpoint.endswith('y'):\n                endpoint = endpoint[:-1] + 'ies'\n            elif not endpoint.endswith('s'):\n                endpoint += 's'\n        else:\n            # otherwise make sure it's singular form\n            if endpoint.endswith('ies'):\n                endpoint = endpoint[:-3] + 'y'\n            elif endpoint.endswith('s'):\n                endpoint = endpoint[:-1]\n\n        return endpoint", "response": "Sanitize an endpoint to a singular or plural form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the endpoint name of the current class.", "response": "def get_endpoint(cls):\n        \"\"\"\n        Accessor method to enable omition of endpoint name.\n\n        In general we want the class name to be translated to endpoint name,\n        this way unless otherwise specified will translate class name to\n        endpoint name.\n        \"\"\"\n        if cls.endpoint is not None:\n            return cls.endpoint\n        s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', cls.__name__)\n        return cls.sanitize_ep(\n            re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower(),\n            plural=True\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches all the related items from the API.", "response": "def _fetch_all(cls, api_key, endpoint=None, offset=0, limit=25, **kwargs):\n        \"\"\"\n        Call `self._fetch_page` for as many pages as exist.\n\n        TODO: should be extended to do async page fetches if API allows it via\n        exposing total value.\n\n        Returns a list of `cls` instances.\n        \"\"\"\n        output = []\n        qp = kwargs.copy()\n        limit = max(1, min(100, limit))\n        maximum = kwargs.get('maximum')\n        qp['limit'] = min(limit, maximum) if maximum is not None else limit\n        qp['offset'] = offset\n        more, total = None, None\n\n        while True:\n            entities, options = cls._fetch_page(\n                api_key=api_key, endpoint=endpoint, **qp\n            )\n            output += entities\n            more = options.get('more')\n            limit = options.get('limit')\n            offset = options.get('offset')\n            total = options.get('total')\n\n            if more is None:\n                if total is None or offset is None:\n                    break\n                more = (limit + offset) < total\n\n            if not more or (maximum is not None and len(output) >= maximum):\n                break\n\n            qp['limit'] = limit\n            qp['offset'] = offset + limit\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches a single page of items from the API.", "response": "def _fetch_page(cls, api_key, endpoint=None, page_index=0, offset=None,\n                    limit=25, **kwargs):\n        \"\"\"\n        Fetch a single page of `limit` number of results.\n\n        Optionally provide `page_index` an integer (0-based) index for the\n        page to return. Calculated based on `limit` and `offset`.\n\n        Optionally provide `offset` which will override `page_index` if both\n        are passed, will be used to calculate the integer offset of items.\n\n        Optionally provide `limit` integer describing how many items pages\n        ought to have.\n\n        Returns a tuple containing a list of `cls` instances and response\n        options.\n        \"\"\"\n        # if offset is provided have it overwrite the page_index provided\n        if offset is not None:\n            page_index = int(offset / limit)\n\n        # limit can be maximum MAX_LIMIT_VALUE for most PD queries\n        limit = max(1, min(cls.MAX_LIMIT_VALUE, limit))\n\n        # make an tmp instance to do query work\n        inst = cls(api_key=api_key)\n\n        kwargs['offset'] = int(page_index * limit)\n        maximum = kwargs.pop('maximum', None)\n\n        # if maximum is valid, make the limit <= maximum\n        kwargs['limit'] = min(limit, maximum) if maximum is not None else limit\n        ep = parse_key = cls.sanitize_ep(cls.get_endpoint(), plural=True)\n\n        # if an override to the endpoint is provided use that instead\n        # this is useful for nested value searches ie. for\n        # `incident_log_entries` but instead of /log_entries querying with\n        # context of /incident/INCIDENTID/log_entries.\n        # XXX: could be cleaner\n        if endpoint is not None:\n            ep = endpoint\n\n        response = inst.request('GET', endpoint=ep, query_params=kwargs)\n        # XXX: this is a little gross right now. Seems like the best way\n        # to do the parsing out of something and then return everything else\n        datas = cls._parse(response, key=parse_key)\n        response.pop(parse_key, None)\n        entities = [cls(api_key=api_key, _data=d) for d in datas]\n        # return a tuple\n        return entities, response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch(cls, id, api_key=None, endpoint=None, add_headers=None,\n              **kwargs):\n        \"\"\"\n        Fetch a single entity from the API endpoint.\n\n        Used when you know the exact ID that must be queried.\n        \"\"\"\n        if endpoint is None:\n            endpoint = cls.get_endpoint()\n\n        inst = cls(api_key=api_key)\n        parse_key = cls.sanitize_ep(endpoint).split(\"/\")[-1]\n        endpoint = '/'.join((endpoint, id))\n        data = cls._parse(inst.request('GET',\n                                       endpoint=endpoint,\n                                       add_headers=add_headers,\n                                       query_params=kwargs),\n                          key=parse_key)\n        inst._set(data)\n        return inst", "response": "Fetch a single entity from the API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_query_params(cls, **kwargs):\n        values = []\n        output = kwargs.copy()\n        query = kwargs.pop('query', None)\n\n        # remove any of the TRANSLATE_QUERY_PARAMs in output\n        for param in (cls.TRANSLATE_QUERY_PARAM or []):\n            popped = output.pop(param, None)\n            if popped is not None:\n                values.append(popped)\n\n        # if query is provided, just use it\n        if query is not None:\n            output['query'] = query\n            return output\n\n        # if query is not provided, use the first parameter we removed from\n        # the kwargs\n        try:\n            output['query'] = next(iter(values))\n        except StopIteration:\n            pass\n\n        return output", "response": "Translate an arbirtary keyword argument to the expected query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(cls, api_key=None, fetch_all=True, endpoint=None, maximum=None,\n             **kwargs):\n        \"\"\"\n        Find some entities from the API endpoint.\n\n        If no api_key is provided, the global api key will be used.\n        If fetch_all is True, page through all the data and find every record\n        that exists.\n        If add_headers is provided (as a dict) use it to add headers to the\n        HTTP request, eg.\n\n            {'host': 'some.hidden.host'}\n\n        Capitalizing header keys does not matter.\n\n        Remaining keyword arguments will be passed as `query_params` to the\n        instant method `request` (ClientMixin).\n        \"\"\"\n        exclude = kwargs.pop('exclude', None)\n\n        # if exclude param was passed a a string, list-ify it\n        if isinstance(exclude, six.string_types):\n            exclude = [exclude, ]\n\n        query_params = cls.translate_query_params(**kwargs)\n\n        # unless otherwise specified use the class variable for the endpoint\n        if endpoint is None:\n            endpoint = cls.get_endpoint()\n\n        if fetch_all:\n            result = cls._fetch_all(api_key=api_key, endpoint=endpoint,\n                                    maximum=maximum,\n                                    **query_params)\n        else:\n            result = cls._fetch_page(api_key=api_key, endpoint=endpoint,\n                                     maximum=maximum,\n                                     **query_params)\n\n        # for each result run it through an exlcusion filter\n        collection = [r for r in result\n                      if not cls._find_exclude_filter(exclude, r)]\n        return collection", "response": "Find some entities from the API endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_one(cls, *args, **kwargs):\n        # ensure that maximum is supplied so that a big query is not happening\n        # behind the scenes\n        if 'maximum' not in kwargs:\n            kwargs['maximum'] = 1\n\n        try:\n            # call find and extract the first iterated value from the result\n            iterable = iter(cls.find(*args, **kwargs))\n            return next(iterable)\n        except StopIteration:\n            # no result was found\n            return None", "response": "Like find except that only one result is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an instance of the class by calling the API endpoint.", "response": "def create(cls, data=None, api_key=None, endpoint=None, add_headers=None,\n               data_key=None, response_data_key=None, method='POST', **kwargs):\n        \"\"\"\n        Create an instance of the Entity model by calling to the API endpoint.\n\n        This ensures that server knows about the creation before returning\n        the class instance.\n\n        NOTE: The server must return a response with the schema containing\n        the entire entity value. A True or False response is no bueno.\n        \"\"\"\n        inst = cls(api_key=api_key)\n\n        if data_key is None:\n            data_key = cls.sanitize_ep(cls.get_endpoint())\n\n        if response_data_key is None:\n            response_data_key = cls.sanitize_ep(cls.get_endpoint())\n\n        body = {}\n        body[data_key] = data\n\n        if endpoint is None:\n            endpoint = cls.get_endpoint()\n\n        inst._set(cls._parse(inst.request(method,\n                                          endpoint=endpoint,\n                                          data=body,\n                                          query_params=kwargs,\n                                          add_headers=add_headers,\n                                          ),\n                             key=response_data_key))\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(cls, id, api_key=None, **kwargs):\n        inst = cls(api_key=api_key)\n        endpoint = '/'.join((cls.get_endpoint(), id))\n        inst.request('DELETE', endpoint=endpoint, query_params=kwargs)\n        inst._is_deleted = True\n        return True", "response": "Delete an entity from the server by ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(cls, id, api_key=None, **kwargs):\n        inst = cls(api_key=api_key)\n        endpoint = '/'.join((cls.get_endpoint(), id))\n        return inst.request('PUT', endpoint=endpoint, query_params=kwargs)", "response": "Delete an entity from the server by ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse(cls, data, key=None):\n        parse = cls.parse if cls.parse is not None else cls.get_endpoint()\n\n        if callable(parse):\n            data = parse(data)\n        elif isinstance(parse, str):\n            data = data[key]\n        else:\n            raise Exception('\"parse\" should be a callable or string got, {0}'\n                            .format(parse))\n        return data", "response": "Parse a set of data to extract entity - only data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging things with the global logger.", "response": "def log(*args, **kwargs):\n    \"\"\"Log things with the global logger.\"\"\"\n    level = kwargs.pop('level', logging.INFO)\n    logger.log(level, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(cls, event_info):\n        assert 'service_key' in event_info\n        assert isinstance(event_info['service_key'], six.string_types)\n        assert 'event_type' in event_info\n        assert event_info['event_type'] in cls.EVENT_TYPES\n        if event_info['event_type'] != cls.EVENT_TYPES[0]:\n            assert 'incident_key' in event_info\n            assert isinstance(event_info['incident_key'], six.string_types)\n        else:\n            assert 'description' in event_info\n\n        if 'details' in event_info:\n            assert isinstance(event_info['details'], dict)\n\n        if 'contexts' in event_info:\n            assert isinstance(event_info['contexts'], (list, tuple,))", "response": "Validate that provided event information is valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an event on your PagerDuty account.", "response": "def create(cls, data=None, api_key=None, endpoint=None, add_headers=None,\n               **kwargs):\n        \"\"\"Create an event on your PagerDuty account.\"\"\"\n        cls.validate(data)\n        inst = cls(api_key=api_key)\n        endpoint = ''\n        return inst.request('POST',\n                            endpoint=endpoint,\n                            data=data,\n                            query_params=kwargs,\n                            add_headers=add_headers,\n                            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(cls, event_info):\n        assert 'routing_key' in event_info\n        assert isinstance(event_info['routing_key'], six.string_types)\n        assert 'event_action' in event_info\n        assert event_info['event_action'] in cls.EVENT_TYPES\n        assert 'payload' in event_info\n        payload = event_info['payload']\n        assert payload['summary']\n        assert payload['source']\n        assert payload['severity'] in cls.SEVERITY_TYPES", "response": "Validate that provided event information is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_escalation_policy(self, escalation_policy, **kwargs):\n        if isinstance(escalation_policy, Entity):\n            escalation_policy = escalation_policy['id']\n\n        assert isinstance(escalation_policy, six.string_types)\n\n        endpoint = '{0}/{1}/escalation_policies/{2}'.format(\n            self.endpoint,\n            self['id'],\n            escalation_policy,\n        )\n\n        return self.request('DELETE', endpoint=endpoint, query_params=kwargs)", "response": "Remove an escalation policy from this team."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a user from this team.", "response": "def remove_user(self, user, **kwargs):\n        \"\"\"Remove a user from this team.\"\"\"\n        if isinstance(user, Entity):\n            user = user['id']\n\n        assert isinstance(user, six.string_types)\n\n        endpoint = '{0}/{1}/users/{2}'.format(\n            self.endpoint,\n            self['id'],\n            user,\n        )\n        return self.request('DELETE', endpoint=endpoint, query_params=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_user(self, user, **kwargs):\n        if isinstance(user, User):\n            user = user['id']\n\n        assert isinstance(user, six.string_types)\n\n        endpoint = '{0}/{1}/users/{2}'.format(\n            self.endpoint,\n            self['id'],\n            user,\n        )\n        result = self.request('PUT', endpoint=endpoint, query_params=kwargs)\n        return result", "response": "Add a user to this team."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an integration for this service.", "response": "def create_integration(self, integration_info, **kwargs):\n        \"\"\"\n        Create an integration for this service.\n\n        See: https://v2.developer.pagerduty.com/v2/page/api-reference#!/\n              Services/post_services_id_integrations\n        \"\"\"\n        service_info = integration_info.get('service')\n        vendor_info = integration_info.get('vendor')\n\n        if service_info is not None:\n            self.__class__.validate(service_info)\n\n        if vendor_info is not None:\n            self.vendorFactory.validate(vendor_info)\n\n        endpoint = '{0}/{1}/integrations'.format(\n            self.endpoint,\n            self['id'],\n        )\n        return self.integrationFactory.create(\n            endpoint=endpoint,\n            api_key=self.api_key,\n            data=integration_info,\n            query_params=kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef integrations(self, **kwargs):\n        ids = [ref['id'] for ref in self['integrations']]\n        return [Integration.fetch(id, service=self, query_params=kwargs) for id in ids]", "response": "Retrieve all this services integrations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a single integration by id.", "response": "def get_integration(self, id, **kwargs):\n        \"\"\"Retrieve a single integration by id.\"\"\"\n        return Integration.fetch(id, service=self, query_params=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all contact methods for this user.", "response": "def contact_methods(self, **kwargs):\n        \"\"\"Get all contact methods for this user.\"\"\"\n        endpoint = '{0}/{1}/contact_methods'.format(\n            self.endpoint,\n            self['id'],\n        )\n        result = self.request('GET', endpoint=endpoint, query_params=kwargs)\n        return result['contact_methods']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a contact method for this user.", "response": "def delete_contact_method(self, id, **kwargs):\n        \"\"\"Delete a contact method for this user.\"\"\"\n        endpoint = '{0}/{1}/contact_methods/{2}'.format(\n            self.endpoint,\n            self['id'],\n            id,\n        )\n        return self.request('DELETE', endpoint=endpoint, query_params=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_contact_method(self, id, **kwargs):\n        endpoint = '{0}/{1}/contact_methods/{2}'.format(\n            self.endpoint,\n            self['id'],\n            id,\n        )\n        result = self.request('GET', endpoint=endpoint, query_params=kwargs)\n        return result['contact_method']", "response": "Get a contact method for this user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all notification rules for this user.", "response": "def notification_rules(self, **kwargs):\n        \"\"\"Get all notification rules for this user.\"\"\"\n        endpoint = '{0}/{1}/notification_rules'.format(\n            self.endpoint,\n            self['id'],\n        )\n        result = self.request('GET', endpoint=endpoint, query_params=kwargs)\n        return result['notification_rules']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_notification_rule(self, data, **kwargs):\n        data = {'notification_rule': data, }\n        endpoint = '{0}/{1}/notification_rules'.format(\n            self.endpoint,\n            self['id'],\n        )\n        result = self.request('POST', endpoint=endpoint, data=data,\n                              query_params=kwargs)\n        self._data['notification_rules'].append(result['notification_rule'])\n        return result", "response": "Create a notification rule for this user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a notification rule for this user.", "response": "def delete_notification_rule(self, id, **kwargs):\n        \"\"\"Get a notification rule for this user.\"\"\"\n        endpoint = '{0}/{1}/notification_rules/{2}'.format(\n            self.endpoint,\n            self['id'],\n            id,\n        )\n        return self.request('DELETE', endpoint=endpoint, query_params=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall an add - on to this account.", "response": "def install(cls, type_, name, src, *args, **kwargs):\n        \"\"\"Install an add-on to this account.\"\"\"\n        data = kwargs.pop('data', None)\n        if data is None:\n            data = {\n                'addon': {\n                    'type': type_,\n                    'name': name,\n                    'src': src,\n                }\n            }\n        cls.create(data=data, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate and then create a Vendor entity.", "response": "def create(cls, data=None, *args, **kwargs):\n        \"\"\"Validate and then create a Vendor entity.\"\"\"\n        cls.validate(data)\n        # otherwise endpoint should contain the service path too\n        getattr(Entity, 'create').__func__(cls, data=data, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a specialized dict unstructuring function for a class.", "response": "def make_dict_unstructure_fn(cl, converter, **kwargs):\n    # type: (Type[T], Converter) -> Callable[[T], Dict[str, Any]]\n    \"\"\"Generate a specialized dict unstructuring function for a class.\"\"\"\n    cl_name = cl.__name__\n    fn_name = \"unstructure_\" + cl_name\n    globs = {\"__c_u\": converter.unstructure}\n    lines = []\n    post_lines = []\n\n    attrs = cl.__attrs_attrs__\n\n    lines.append(\"def {}(i):\".format(fn_name))\n    lines.append(\"    res = {\")\n    for a in attrs:\n        attr_name = a.name\n        override = kwargs.pop(attr_name, _neutral)\n        d = a.default\n        if a.type is None:\n            # No type annotation, doing runtime dispatch.\n            if d is not attr.NOTHING and override.omit_if_default:\n                def_name = \"__cattr_def_{}\".format(attr_name)\n\n                if isinstance(d, attr.Factory):\n                    globs[def_name] = d.factory\n                    if d.takes_self:\n                        post_lines.append(\n                            \"    if i.{name} != {def_name}(i):\".format(\n                                name=attr_name, def_name=def_name\n                            )\n                        )\n                    else:\n                        post_lines.append(\n                            \"    if i.{name} != {def_name}():\".format(\n                                name=attr_name, def_name=def_name\n                            )\n                        )\n                    post_lines.append(\n                        \"        res['{name}'] = i.{name}\".format(\n                            name=attr_name\n                        )\n                    )\n                else:\n                    globs[def_name] = d\n                    post_lines.append(\n                        \"    if i.{name} != {def_name}:\".format(\n                            name=attr_name, def_name=def_name\n                        )\n                    )\n                    post_lines.append(\n                        \"        res['{name}'] = __c_u(i.{name})\".format(\n                            name=attr_name\n                        )\n                    )\n\n            else:\n                # No default or no override.\n                lines.append(\n                    \"        '{name}': __c_u(i.{name}),\".format(name=attr_name)\n                )\n        else:\n            # Do the dispatch here and now.\n            type = a.type\n            conv_function = converter._unstructure_func.dispatch(type)\n            if d is not attr.NOTHING and override.omit_if_default:\n                def_name = \"__cattr_def_{}\".format(attr_name)\n\n                if isinstance(d, attr.Factory):\n                    # The default is computed every time.\n                    globs[def_name] = d.factory\n                    if d.takes_self:\n                        post_lines.append(\n                            \"    if i.{name} != {def_name}(i):\".format(\n                                name=attr_name, def_name=def_name\n                            )\n                        )\n                    else:\n                        post_lines.append(\n                            \"    if i.{name} != {def_name}():\".format(\n                                name=attr_name, def_name=def_name\n                            )\n                        )\n                    if conv_function == converter._unstructure_identity:\n                        # Special case this, avoid a function call.\n                        post_lines.append(\n                            \"        res['{name}'] = i.{name}\".format(\n                                name=attr_name\n                            )\n                        )\n                    else:\n                        unstruct_fn_name = \"__cattr_unstruct_{}\".format(\n                            attr_name\n                        )\n                        globs[unstruct_fn_name] = conv_function\n                        post_lines.append(\n                            \"        res['{name}'] = {fn}(i.{name}),\".format(\n                                name=attr_name, fn=unstruct_fn_name\n                            )\n                        )\n                else:\n                    # Default is not a factory, but a constant.\n                    globs[def_name] = d\n                    post_lines.append(\n                        \"    if i.{name} != {def_name}:\".format(\n                            name=attr_name, def_name=def_name\n                        )\n                    )\n                    if conv_function == converter._unstructure_identity:\n                        post_lines.append(\n                            \"        res['{name}'] = i.{name}\".format(\n                                name=attr_name\n                            )\n                        )\n                    else:\n                        unstruct_fn_name = \"__cattr_unstruct_{}\".format(\n                            attr_name\n                        )\n                        globs[unstruct_fn_name] = conv_function\n                        post_lines.append(\n                            \"        res['{name}'] = {fn}(i.{name})\".format(\n                                name=attr_name, fn=unstruct_fn_name\n                            )\n                        )\n            else:\n                # No omitting of defaults.\n                if conv_function == converter._unstructure_identity:\n                    # Special case this, avoid a function call.\n                    lines.append(\n                        \"    '{name}': i.{name},\".format(name=attr_name)\n                    )\n                else:\n                    unstruct_fn_name = \"__cattr_unstruct_{}\".format(attr_name)\n                    globs[unstruct_fn_name] = conv_function\n                    lines.append(\n                        \"    '{name}': {fn}(i.{name}),\".format(\n                            name=attr_name, fn=unstruct_fn_name\n                        )\n                    )\n    lines.append(\"    }\")\n\n    total_lines = lines + post_lines + [\"    return res\"]\n\n    eval(compile(\"\\n\".join(total_lines), \"\", \"exec\"), globs)\n\n    fn = globs[fn_name]\n\n    return fn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_structure_hook(self, cl, func):\n        if is_union_type(cl):\n            self._union_registry[cl] = func\n        else:\n            self._structure_func.register_cls_list([(cl, func)])", "response": "Register a primitive - to - class converter function for a type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef structure(self, obj, cl):\n        # type: (Any, Type[T]) -> T\n        \"\"\"Convert unstructured Python data structures to structured data.\"\"\"\n\n        return self._structure_func.dispatch(cl)(obj, cl)", "response": "Convert unstructured Python data structures to structured data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unstructure_attrs_asdict(self, obj):\n        # type: (Any) -> Dict[str, Any]\n        \"\"\"Our version of `attrs.asdict`, so we can call back to us.\"\"\"\n        attrs = obj.__class__.__attrs_attrs__\n        dispatch = self._unstructure_func.dispatch\n        rv = self._dict_factory()\n        for a in attrs:\n            name = a.name\n            v = getattr(obj, name)\n            rv[name] = dispatch(v.__class__)(v)\n        return rv", "response": "Our version of attrs. asdict so we can call back to us."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _unstructure_seq(self, seq):\n        # We can reuse the sequence class, so tuples stay tuples.\n        dispatch = self._unstructure_func.dispatch\n        return seq.__class__(dispatch(e.__class__)(e) for e in seq)", "response": "Convert a sequence to primitive equivalents."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unstructure_mapping(self, mapping):\n\n        # We can reuse the mapping class, so dicts stay dicts and OrderedDicts\n        # stay OrderedDicts.\n        dispatch = self._unstructure_func.dispatch\n        return mapping.__class__(\n            (dispatch(k.__class__)(k), dispatch(v.__class__)(v))\n            for k, v in mapping.items()\n        )", "response": "Convert a mapping of attr classes to primitive equivalents."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads an attrs class from a sequence of tuples.", "response": "def structure_attrs_fromtuple(self, obj, cl):\n        # type: (Tuple, Type[T]) -> T\n        \"\"\"Load an attrs class from a sequence (tuple).\"\"\"\n        conv_obj = []  # A list of converter parameters.\n        for a, value in zip(cl.__attrs_attrs__, obj):  # type: ignore\n            # We detect the type by the metadata.\n            converted = self._structure_attr_from_tuple(a, a.name, value)\n            conv_obj.append(converted)\n\n        return cl(*conv_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _structure_attr_from_tuple(self, a, name, value):\n        type_ = a.type\n        if type_ is None:\n            # No type metadata.\n            return value\n        return self._structure_func.dispatch(type_)(value, type_)", "response": "Handle an individual attrs attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _structure_list(self, obj, cl):\n        if is_bare(cl) or cl.__args__[0] is Any:\n            return [e for e in obj]\n        else:\n            elem_type = cl.__args__[0]\n            return [\n                self._structure_func.dispatch(elem_type)(e, elem_type)\n                for e in obj\n            ]", "response": "Convert an iterable to a potentially generic list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _structure_set(self, obj, cl):\n        if is_bare(cl) or cl.__args__[0] is Any:\n            return set(obj)\n        else:\n            elem_type = cl.__args__[0]\n            return {\n                self._structure_func.dispatch(elem_type)(e, elem_type)\n                for e in obj\n            }", "response": "Convert an iterable into a potentially generic set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _structure_frozenset(self, obj, cl):\n        if is_bare(cl) or cl.__args__[0] is Any:\n            return frozenset(obj)\n        else:\n            elem_type = cl.__args__[0]\n            dispatch = self._structure_func.dispatch\n            return frozenset(dispatch(elem_type)(e, elem_type) for e in obj)", "response": "Convert an iterable into a potentially generic frozenset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a mapping into a potentially generic dict.", "response": "def _structure_dict(self, obj, cl):\n        \"\"\"Convert a mapping into a potentially generic dict.\"\"\"\n        if is_bare(cl) or cl.__args__ == (Any, Any):\n            return dict(obj)\n        else:\n            key_type, val_type = cl.__args__\n            if key_type is Any:\n                val_conv = self._structure_func.dispatch(val_type)\n                return {k: val_conv(v, val_type) for k, v in obj.items()}\n            elif val_type is Any:\n                key_conv = self._structure_func.dispatch(key_type)\n                return {key_conv(k, key_type): v for k, v in obj.items()}\n            else:\n                key_conv = self._structure_func.dispatch(key_type)\n                val_conv = self._structure_func.dispatch(val_type)\n                return {\n                    key_conv(k, key_type): val_conv(v, val_type)\n                    for k, v in obj.items()\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeals with converting a union.", "response": "def _structure_union(self, obj, union):\n        \"\"\"Deal with converting a union.\"\"\"\n        # Unions with NoneType in them are basically optionals.\n        # We check for NoneType early and handle the case of obj being None,\n        # so disambiguation functions don't need to handle NoneType.\n        union_params = union.__args__\n        if NoneType in union_params:  # type: ignore\n            if obj is None:\n                return None\n            if len(union_params) == 2:\n                # This is just a NoneType and something else.\n                other = (\n                    union_params[0]\n                    if union_params[1] is NoneType  # type: ignore\n                    else union_params[1]\n                )\n                # We can't actually have a Union of a Union, so this is safe.\n                return self._structure_func.dispatch(other)(obj, other)\n\n        # Check the union registry first.\n        handler = self._union_registry.get(union)\n        if handler is not None:\n            return handler(obj, union)\n\n        # Getting here means either this is not an optional, or it's an\n        # optional with more than one parameter.\n        # Let's support only unions of attr classes for now.\n        cl = self._dis_func_cache(union)(obj)\n        return self._structure_func.dispatch(cl)(obj, cl)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _structure_tuple(self, obj, tup):\n        tup_params = tup.__args__\n        has_ellipsis = tup_params and tup_params[-1] is Ellipsis\n        if tup_params is None or (has_ellipsis and tup_params[0] is Any):\n            # Just a Tuple. (No generic information.)\n            return tuple(obj)\n        if has_ellipsis:\n            # We're dealing with a homogenous tuple, Tuple[int, ...]\n            tup_type = tup_params[0]\n            conv = self._structure_func.dispatch(tup_type)\n            return tuple(conv(e, tup_type) for e in obj)\n        else:\n            # We're dealing with a heterogenous tuple.\n            return tuple(\n                self._structure_func.dispatch(t)(e, t)\n                for t, e in zip(tup_params, obj)\n            )", "response": "Deal with converting to a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_dis_func(self, union):\n        # type: (Type) -> Callable[..., Type]\n        \"\"\"Fetch or try creating a disambiguation function for a union.\"\"\"\n        union_types = union.__args__\n        if NoneType in union_types:  # type: ignore\n            # We support unions of attrs classes and NoneType higher in the\n            # logic.\n            union_types = tuple(\n                e for e in union_types if e is not NoneType  # type: ignore\n            )\n\n        if not all(hasattr(e, \"__attrs_attrs__\") for e in union_types):\n            raise ValueError(\n                \"Only unions of attr classes supported \"\n                \"currently. Register a loads hook manually.\"\n            )\n        return create_uniq_field_dis_func(*union_types)", "response": "Fetch or create a disambiguation function for a union."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_uniq_field_dis_func(*classes):\n    # type: (*Type) -> Callable\n    \"\"\"Given attr classes, generate a disambiguation function.\n\n    The function is based on unique fields.\"\"\"\n    if len(classes) < 2:\n        raise ValueError(\"At least two classes required.\")\n    cls_and_attrs = [(cl, set(at.name for at in fields(cl))) for cl in classes]\n    if len([attrs for _, attrs in cls_and_attrs if len(attrs) == 0]) > 1:\n        raise ValueError(\"At least two classes have no attributes.\")\n    # TODO: Deal with a single class having no required attrs.\n    # For each class, attempt to generate a single unique required field.\n    uniq_attrs_dict = OrderedDict()  # type: Dict[str, Type]\n    cls_and_attrs.sort(key=lambda c_a: -len(c_a[1]))\n\n    fallback = None  # If none match, try this.\n\n    for i, (cl, cl_reqs) in enumerate(cls_and_attrs):\n        other_classes = cls_and_attrs[i + 1 :]\n        if other_classes:\n            other_reqs = reduce(or_, (c_a[1] for c_a in other_classes))\n            uniq = cl_reqs - other_reqs\n            if not uniq:\n                m = \"{} has no usable unique attributes.\".format(cl)\n                raise ValueError(m)\n            uniq_attrs_dict[next(iter(uniq))] = cl\n        else:\n            fallback = cl\n\n    def dis_func(data):\n        # type: (Mapping) -> Optional[Type]\n        if not isinstance(data, Mapping):\n            raise ValueError(\"Only input mappings are supported.\")\n        for k, v in uniq_attrs_dict.items():\n            if k in data:\n                return v\n        return fallback\n\n    return dis_func", "response": "Generates a disambiguation function that returns the value of the unique field in the given attr classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the appropriate handler for the passed object.", "response": "def _dispatch(self, typ):\n        \"\"\"\n        returns the appropriate handler, for the object passed.\n        \"\"\"\n        for can_handle, handler in self._handler_pairs:\n            # can handle could raise an exception here\n            # such as issubclass being called on an instance.\n            # it's easier to just ignore that case.\n            try:\n                if can_handle(typ):\n                    return handler\n            except Exception:\n                pass\n        raise KeyError(\"unable to find handler for {0}\".format(typ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_cls_list(self, cls_and_handler):\n        for cls, handler in cls_and_handler:\n            self._single_dispatch.register(cls, handler)\n        self.dispatch.cache_clear()", "response": "register a class to singledispatch"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_func_list(self, func_and_handler):\n        for func, handler in func_and_handler:\n            self._function_dispatch.register(func, handler)\n        self.dispatch.cache_clear()", "response": "register a function to determine if the handle\n            should be used for the type\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef endpoint(cls):\n        endpoint = ''\n        if cls.__endpoint__ is not None:\n            return cls.__endpoint__\n        elif cls.__from_class__ is not None:\n            endpoint = cls.__from_class__.__name__.lower()\n        else:\n            endpoint = cls.__tablename__.lower()\n        if not endpoint.endswith('s'):\n            endpoint += 's'\n        return endpoint", "response": "Return the name of the sandman. model. Model s endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resource_uri(self):\n        primary_key_value = getattr(self, self.primary_key(), None)\n        return '/{}/{}'.format(self.endpoint(), primary_key_value)", "response": "Return the URI at which the resource can be found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name of the table s primary key", "response": "def primary_key(cls):\n        \"\"\"Return the name of the table's primary key\n\n        :rtype: string\n\n        \"\"\"\n\n        if cls.__from_class__:\n            cls = cls.__from_class__\n        return cls.__table__.primary_key.columns.values()[0].name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef links(self):\n\n        links = []\n        for foreign_key in self.__table__.foreign_keys:\n            column = foreign_key.column.name\n            column_value = getattr(self, column, None)\n            if column_value:\n                table = foreign_key.column.table.name\n                with app.app_context():\n                    endpoint = current_app.class_references[table]\n                links.append({'rel': 'related', 'uri': '/{}/{}'.format(\n                    endpoint.__name__, column_value)})\n        links.append({'rel': 'self', 'uri': self.resource_uri()})\n        return links", "response": "Return a list of links for endpoints related to the resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary containing only the attributes which map to an instance s database columns.", "response": "def as_dict(self, depth=0):\n        \"\"\"Return a dictionary containing only the attributes which map to\n        an instance's database columns.\n\n        :param int depth: Maximum depth to recurse subobjects\n        :rtype: dict\n\n        \"\"\"\n        result_dict = {}\n        for column in self.__table__.columns.keys():\n            result_dict[column] = getattr(self, column, None)\n            if isinstance(result_dict[column], Decimal):\n                result_dict[column] = str(result_dict[column])\n        result_dict['links'] = self.links()\n        for foreign_key in self.__table__.foreign_keys:\n            column_name = foreign_key.column.name\n            column_value = getattr(self, column_name, None)\n            if column_value:\n                table = foreign_key.column.table.name\n                with app.app_context():\n                    endpoint = current_app.class_references[table]\n                    session = db.session()\n                    resource = session.query(endpoint).get(column_value)\n                if depth > 0:\n                    result_dict.update({\n                        'rel': endpoint.__name__,\n                        endpoint.__name__.lower(): resource.as_dict(depth - 1)\n                        })\n                else:\n                    result_dict[\n                        endpoint.__name__.lower() + '_url'] = '/{}/{}'.format(\n                        endpoint.__name__, column_value)\n\n        result_dict['self'] = self.resource_uri()\n        return result_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a set of attributes which correspond to the column names of the base class.", "response": "def from_dict(self, dictionary):\n        \"\"\"Set a set of attributes which correspond to the\n        :class:`sandman.model.Model`'s columns.\n\n        :param dict dictionary: A dictionary of attributes to set on the\n            instance whose keys are the column names of\n            the :class:`sandman.model.Model`'s underlying database table.\n\n        \"\"\"\n        for column in self.__table__.columns.keys():\n            value = dictionary.get(column, None)\n            if value:\n                setattr(self, column, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets all attributes which correspond to the given dictionary to the values in the database table.", "response": "def replace(self, dictionary):\n        \"\"\"Set all attributes which correspond to the\n        :class:`sandman.model.Model`'s columns to the values in *dictionary*,\n        inserting None if an attribute's value is not specified.\n\n        :param dict dictionary: A dictionary of attributes to set on the\n            instance whose keys are the column names of the\n            :class:`sandman.model.Model`'s underlying database table.\n\n        \"\"\"\n        for column in self.__table__.columns.keys():\n            setattr(self, column, None)\n        self.from_dict(dictionary)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary containing meta - information about the given resource.", "response": "def meta(cls):\n        \"\"\"Return a dictionary containing meta-information about the given\n        resource.\"\"\"\n        if getattr(cls, '__from_class__', None) is not None:\n            cls = cls.__from_class__\n        attribute_info = {}\n        for name, value in cls.__table__.columns.items():\n            attribute_info[name] = str(value.type).lower()\n\n        return {cls.__name__: attribute_info}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_version(ctx, value):\n    if not value:\n        return\n    import pkg_resources\n    version = None\n    try:\n        version = pkg_resources.get_distribution('sandman').version\n    finally:\n        del pkg_resources\n    click.echo(version)\n    ctx.exit()", "response": "Print the current version of sandman and exit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(generate_pks, show_pks, host, port, uri):\n    app.config['SQLALCHEMY_DATABASE_URI'] = uri\n    app.config['SANDMAN_GENERATE_PKS'] = generate_pks\n    app.config['SANDMAN_SHOW_PKS'] = show_pks\n    app.config['SERVER_HOST'] = host\n    app.config['SERVER_PORT'] = port\n    activate(name='sandmanctl')\n    app.run(host=host, port=int(port), debug=True)", "response": "Connect to the URI and start the API server administering the administering interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _perform_database_action(action, *args):\n    session = _get_session()\n    getattr(session, action)(*args)\n    session.commit()", "response": "Call session. action with the given args."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_acceptable_response_type():\n    if ('Accept' not in request.headers or request.headers['Accept'] in\n            ALL_CONTENT_TYPES):\n        return JSON\n    acceptable_content_types = set(\n        request.headers['ACCEPT'].strip().split(','))\n    if acceptable_content_types & HTML_CONTENT_TYPES:\n        return HTML\n    elif acceptable_content_types & JSON_CONTENT_TYPES:\n        return JSON\n    else:\n        # HTTP 406 Not Acceptable\n        raise InvalidAPIUsage(406)", "response": "Return the mimetype for this request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_exception(error):\n    try:\n        if _get_acceptable_response_type() == JSON:\n            response = jsonify(error.to_dict())\n            response.status_code = error.code\n            return response\n        else:\n            return error.abort()\n    except InvalidAPIUsage:\n        # In addition to the original exception, we don't support the content\n        # type in the request's 'Accept' header, which is a more important\n        # error, so return that instead of what was originally raised.\n        response = jsonify(error.to_dict())\n        response.status_code = 415\n        return response", "response": "Return a response with the appropriate status code message and content\nAttributeNames type when an InvalidAPIUsage exception is raised."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the JSON representation of a single resource.", "response": "def _single_resource_json_response(resource, depth=0):\n    \"\"\"Return the JSON representation of *resource*.\n\n    :param resource: :class:`sandman.model.Model` to render\n    :type resource: :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    links = resource.links()\n    response = jsonify(**resource.as_dict(depth))\n    response.headers['Link'] = ''\n    for link in links:\n        response.headers['Link'] += '<{}>; rel=\"{}\",'.format(\n            link['uri'], link['rel'])\n    response.headers['Link'] = response.headers['Link'][:-1]\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _single_attribute_html_response(resource, name, value):\n    return make_response(render_template(\n        'attribute.html',\n        resource=resource,\n        name=name, value=value))", "response": "Return the json representation of a single attribute of a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the HTML representation of a single resource.", "response": "def _single_resource_html_response(resource):\n    \"\"\"Return the HTML representation of *resource*.\n\n    :param resource: :class:`sandman.model.Model` to render\n    :type resource: :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    tablename = resource.__tablename__\n    resource.pk = getattr(resource, resource.primary_key())\n    resource.attributes = resource.as_dict()\n    return make_response(render_template(\n        'resource.html',\n        resource=resource,\n        tablename=tablename))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _collection_json_response(cls, resources, start, stop, depth=0):\n\n    top_level_json_name = None\n    if cls.__top_level_json_name__ is not None:\n        top_level_json_name = cls.__top_level_json_name__\n    else:\n        top_level_json_name = 'resources'\n\n    result_list = []\n    for resource in resources:\n        result_list.append(resource.as_dict(depth))\n\n    payload = {}\n    if start is not None:\n        payload[top_level_json_name] = result_list[start:stop]\n    else:\n        payload[top_level_json_name] = result_list\n\n    return jsonify(payload)", "response": "Return the JSON representation of the collection resources."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _collection_html_response(resources, start=0, stop=20):\n    return make_response(render_template(\n        'collection.html',\n        resources=resources[start:stop]))", "response": "Return the HTML representation of the collection * resources*."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the given class supports the HTTP method found on the incoming HTTP request.", "response": "def _validate(cls, method, resource=None):\n    \"\"\"Return ``True`` if the the given *cls* supports the HTTP *method* found\n    on the incoming HTTP request.\n\n    :param cls: class associated with the request's endpoint\n    :type cls: :class:`sandman.model.Model` instance\n    :param string method: HTTP method of incoming request\n    :param resource: *cls* instance associated with the request\n    :type resource: :class:`sandman.model.Model` or list of\n                    :class:`sandman.model.Model` or None\n    :rtype: bool\n\n    \"\"\"\n    if method not in cls.__methods__:\n        raise InvalidAPIUsage(403, FORBIDDEN_EXCEPTION_MESSAGE.format(\n            method,\n            cls.endpoint(), cls.__methods__))\n\n    class_validator_name = 'validate_' + method\n\n    if hasattr(cls, class_validator_name):\n        class_validator = getattr(cls, class_validator_name)\n        if not class_validator(resource):\n            raise InvalidAPIUsage(403)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_resource_data(incoming_request):\n    content_type = incoming_request.headers['Content-type'].split(';')[0]\n    if ('Content-type' not in incoming_request.headers or\n            content_type in JSON_CONTENT_TYPES):\n        return incoming_request.json\n    elif content_type in HTML_CONTENT_TYPES:\n        if not incoming_request.form:\n            raise InvalidAPIUsage(400)\n        return incoming_request.form\n    else:\n        # HTTP 415: Unsupported Media Type\n        raise InvalidAPIUsage(\n            415,\n            UNSUPPORTED_CONTENT_TYPE_MESSAGE.format(\n                types=incoming_request.headers['Content-type']))", "response": "Return the data from the incoming request based on the content - type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the class associated with the endpoint *collection*.", "response": "def endpoint_class(collection):\n    \"\"\"Return the :class:`sandman.model.Model` associated with the endpoint\n    *collection*.\n\n    :param string collection: a :class:`sandman.model.Model` endpoint\n    :rtype: :class:`sandman.model.Model`\n\n    \"\"\"\n    with app.app_context():\n        try:\n            cls = current_app.class_references[collection]\n        except KeyError:\n            raise InvalidAPIUsage(404)\n        return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retrieve_collection(collection, query_arguments=None):\n    session = _get_session()\n    cls = endpoint_class(collection)\n    if query_arguments:\n        filters = []\n        order = []\n        limit = None\n        for key, value in query_arguments.items():\n            if key == 'page':\n                continue\n            if value.startswith('%'):\n                filters.append(getattr(cls, key).like(str(value), escape='/'))\n            elif key == 'sort':\n                order.append(getattr(cls, value))\n            elif key == 'limit':\n                limit = value\n            elif key:\n                filters.append(getattr(cls, key) == value)\n        resources = session.query(cls).filter(*filters).order_by(\n            *order).limit(limit)\n    else:\n        resources = session.query(cls).all()\n    return resources", "response": "Retrieve the resources in a collection possibly filtered by a series of\n            values to use in a where clause search."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the resource in a collection identified by key *key*.", "response": "def retrieve_resource(collection, key):\n    \"\"\"Return the resource in *collection* identified by key *key*.\n\n    :param string collection: a :class:`sandman.model.Model` endpoint\n    :param string key: primary key of resource\n    :rtype: class:`sandman.model.Model`\n\n    \"\"\"\n    session = _get_session()\n    cls = endpoint_class(collection)\n    resource = session.query(cls).get(key)\n    if resource is None:\n        raise InvalidAPIUsage(404)\n    return resource"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn HTTP response with status code 201 and location header", "response": "def resource_created_response(resource):\n    \"\"\"Return HTTP response with status code *201*, signaling a created\n    *resource*\n\n    :param resource: resource created as a result of current request\n    :type resource: :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    if _get_acceptable_response_type() == JSON:\n        response = _single_resource_json_response(resource)\n    else:\n        response = _single_resource_html_response(resource)\n    response.status_code = 201\n    response.headers['Location'] = 'http://localhost:5000/{}'.format(\n        resource.resource_uri())\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a response for the resources of the appropriate content type.", "response": "def collection_response(cls, resources, start=None, stop=None):\n    \"\"\"Return a response for the *resources* of the appropriate content type.\n\n    :param resources: resources to be returned in request\n    :type resource: list of :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    if _get_acceptable_response_type() == JSON:\n        return _collection_json_response(cls, resources, start, stop)\n    else:\n        return _collection_html_response(resources, start, stop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resource_response(resource, depth=0):\n    if _get_acceptable_response_type() == JSON:\n        depth = 0\n        if 'expand' in request.args:\n            depth = 1\n        return _single_resource_json_response(resource, depth)\n    else:\n        return _single_resource_html_response(resource)", "response": "Return a response for the resource of the appropriate content type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a response for the resource of the appropriate content type.", "response": "def attribute_response(resource, name, value):\n    \"\"\"Return a response for the *resource* of the appropriate content type.\n\n    :param resource: resource to be returned in request\n    :type resource: :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    if _get_acceptable_response_type() == JSON:\n        return _single_attribute_json_response(name, value)\n    else:\n        return _single_attribute_html_response(resource, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing the contents of a resource with data and return an appropriate *Response*.", "response": "def update_resource(resource, incoming_request):\n    \"\"\"Replace the contents of a resource with *data* and return an appropriate\n    *Response*.\n\n    :param resource: :class:`sandman.model.Model` to be updated\n    :param data: New values for the fields in *resource*\n\n    \"\"\"\n    resource.from_dict(get_resource_data(incoming_request))\n    _perform_database_action('merge', resource)\n    return no_content_response()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces the resource identified by the given key and return the appropriate response.", "response": "def put_resource(collection, key):\n    \"\"\"Replace the resource identified by the given key and return the\n    appropriate response.\n\n    :param string collection: a :class:`sandman.model.Model` endpoint\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    resource = retrieve_resource(collection, key)\n\n    _validate(endpoint_class(collection), request.method, resource)\n\n    resource.replace(get_resource_data(request))\n    try:\n        _perform_database_action('add', resource)\n    except IntegrityError as exception:\n        raise InvalidAPIUsage(422, FORWARDED_EXCEPTION_MESSAGE.format(\n            exception))\n    return no_content_response()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_resource(collection):\n    cls = endpoint_class(collection)\n    resource = cls()\n    resource.from_dict(get_resource_data(request))\n\n    _validate(cls, request.method, resource)\n\n    _perform_database_action('add', resource)\n    return resource_created_response(resource)", "response": "Returns the appropriate *Response* based on adding a new resource to\n    *collection*."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_resource(collection, key):\n    cls = endpoint_class(collection)\n    resource = cls()\n    resource = retrieve_resource(collection, key)\n\n    _validate(cls, request.method, resource)\n\n    try:\n        _perform_database_action('delete', resource)\n    except IntegrityError as exception:\n        raise InvalidAPIUsage(422, FORWARDED_EXCEPTION_MESSAGE.format(\n            exception))\n    return no_content_response()", "response": "Returns the appropriate * Response* for deleting an existing resource in\n    *collection*."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the appropriate * Response* for retrieving a single resource.", "response": "def get_resource(collection, key):\n    \"\"\"Return the appropriate *Response* for retrieving a single resource.\n\n    :param string collection: a :class:`sandman.model.Model` endpoint\n    :param string key: the primary key for the :class:`sandman.model.Model`\n    :rtype: :class:`flask.Response`\n\n    \"\"\"\n    resource = retrieve_resource(collection, key)\n    _validate(endpoint_class(collection), request.method, resource)\n\n    return resource_response(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_resource_attribute(collection, key, attribute):\n    resource = retrieve_resource(collection, key)\n    _validate(endpoint_class(collection), request.method, resource)\n    value = getattr(resource, attribute)\n    if isinstance(value, Model):\n        return resource_response(value)\n    else:\n        return attribute_response(resource, attribute, value)", "response": "Returns the appropriate *Response* for retrieving an attribute of\n    a single resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_collection(collection):\n    cls = endpoint_class(collection)\n\n    resources = retrieve_collection(collection, request.args)\n\n    _validate(cls, request.method, resources)\n\n    start = stop = None\n\n    if request.args and 'page' in request.args:\n        page = int(request.args['page'])\n        results_per_page = app.config.get('RESULTS_PER_PAGE', 20)\n        start, stop = page * results_per_page, (page + 1) * results_per_page\n    return collection_response(cls, resources, start, stop)", "response": "Returns the appropriate *Response* for retrieving a collection of resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index():\n    classes = []\n    with app.app_context():\n        classes = set(current_app.class_references.values())\n    if _get_acceptable_response_type() == JSON:\n        meta_data = {}\n        for cls in classes:\n            meta_data[cls.endpoint()] = {\n                'link': '/' + cls.endpoint(),\n                'meta': '/' + cls.endpoint() + '/meta'\n                }\n        return jsonify(meta_data)\n    else:\n        return render_template('index.html', classes=classes)", "response": "Return information about each type of resource and how it can be accessed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the meta - info of a given resource.", "response": "def get_meta(collection):\n    \"\"\"Return the meta-description of a given resource.\n\n    :param collection: The collection to get meta-info for\n\n    \"\"\"\n\n    cls = endpoint_class(collection)\n    description = cls.meta()\n    return jsonify(description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an HTML Response representation of the exception.", "response": "def abort(self):\n        \"\"\"Return an HTML Response representation of the exception.\"\"\"\n        resp = make_response(render_template('error.html', error=self.code, message=self.message), self.code)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_session():\n    session = getattr(g, '_session', None)\n    if session is None:\n        session = g._session = db.session()\n    return session", "response": "Return a database session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_endpoint_classes(db, generate_pks=False):\n    seen_classes = set()\n    for cls in current_app.class_references.values():\n        seen_classes.add(cls.__tablename__)\n    with app.app_context():\n        db.metadata.reflect(bind=db.engine)\n        for name, table in db.metadata.tables.items():\n            if not name in seen_classes:\n                seen_classes.add(name)\n                if not table.primary_key and generate_pks:\n                    cls = add_pk_if_required(db, table, name)\n                else:\n                    cls = type(\n                        str(name),\n                        (sandman_model, db.Model),\n                        {'__tablename__': name})\n                register(cls)", "response": "Return a list of model classes generated for each reflected database\nWorkItem table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_pk_if_required(db, table, name):\n    db.metadata.reflect(bind=db.engine)\n    cls_dict = {'__tablename__': name}\n    if not table.primary_key:\n        for column in table.columns:\n            column.primary_key = True\n        Table(name, db.metadata, *table.columns, extend_existing=True)\n        cls_dict['__table__'] = table\n        db.metadata.create_all(bind=db.engine)\n\n    return type(str(name), (sandman_model, db.Model), cls_dict)", "response": "Return a class deriving from our SQLAlchemy\n    model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_relationships(db, known_tables):\n    inspector = reflection.Inspector.from_engine(db.engine)\n    for cls in set(known_tables.values()):\n        for foreign_key in inspector.get_foreign_keys(cls.__tablename__):\n            if foreign_key['referred_table'] in known_tables:\n                other = known_tables[foreign_key['referred_table']]\n                constrained_column = foreign_key['constrained_columns']\n                if other not in cls.__related_tables__ and cls not in (\n                        other.__related_tables__) and other != cls:\n                    cls.__related_tables__.add(other)\n                    # Add a SQLAlchemy relationship as an attribute\n                    # on the class\n                    setattr(cls, other.__table__.name, relationship(\n                            other.__name__, backref=db.backref(\n                                cls.__name__.lower()),\n                            foreign_keys=str(cls.__name__) + '.' +\n                            ''.join(constrained_column)))", "response": "Enrich the registered Models with SQLAlchemy relationships."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(cls, use_admin=True):\n    with app.app_context():\n        if getattr(current_app, 'class_references', None) is None:\n            current_app.class_references = {}\n        if isinstance(cls, (list, tuple)):\n            for entry in cls:\n                register_internal_data(entry)\n                entry.use_admin = use_admin\n        else:\n            register_internal_data(cls)\n            cls.use_admin = use_admin", "response": "Register with the API a user - defined class and a tuple of to\n articles."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a new class with various internal data structures.", "response": "def register_internal_data(cls):\n    \"\"\"Register a new class, *cls*, with various internal data structures.\n\n    :params `sandman.model.Model` cls: class to register\n\n    \"\"\"\n    with app.app_context():\n        if getattr(cls, 'endpoint', None) is None:\n            orig_class = cls\n            cls = type('Sandman' + cls.__name__, (cls, Model), {})\n            cls.__from_class__ = orig_class\n        current_app.class_references[cls.__tablename__] = cls\n        current_app.class_references[cls.__name__] = cls\n        current_app.class_references[cls.endpoint()] = cls\n        if not getattr(cls, '__related_tables__', None):\n            cls.__related_tables__ = set()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_classes_for_admin(db_session, show_pks=True, name='admin'):\n\n    with app.app_context():\n        admin_view = Admin(current_app, name=name)\n        for cls in set(\n            cls for cls in current_app.class_references.values() if\n                cls.use_admin):\n            column_list = [column.name for column in\n                           cls.__table__.columns.values()]\n            if hasattr(cls, '__view__'):\n                # allow ability for model classes to specify model views\n                admin_view_class = type(\n                    'AdminView',\n                    (cls.__view__,),\n                    {'form_columns': column_list})\n            elif show_pks:\n                # the default of Flask-SQLAlchemy is to not show primary\n                # classes, which obviously isn't acceptable in some cases\n                admin_view_class = type(\n                    'AdminView',\n                    (AdminModelViewWithPK,),\n                    {'form_columns': column_list})\n            else:\n                admin_view_class = ModelView\n            admin_view.add_view(admin_view_class(cls, db_session))", "response": "Registers classes for the admin view that ultimately creates the admin"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef activate(admin=True, browser=True, name='admin', reflect_all=False):\n    with app.app_context():\n        generate_pks = app.config.get('SANDMAN_GENERATE_PKS', None) or False\n        if getattr(app, 'class_references', None) is None or reflect_all:\n            app.class_references = collections.OrderedDict()\n            generate_endpoint_classes(db, generate_pks)\n        else:\n            Model.prepare(db.engine)\n        prepare_relationships(db, current_app.class_references)\n        if admin:\n            try:\n                show_pks = current_app.config['SANDMAN_SHOW_PKS']\n            except KeyError:\n                show_pks = False\n            register_classes_for_admin(db.session, show_pks, name)\n    if browser:\n        port = app.config.get('SERVER_PORT', None) or 5000\n        webbrowser.open('http://localhost:{}/admin'.format(port))", "response": "Activate each pre - registered model or generate the model classes and register them for the admin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a path and parsed xml_document provides class nodes and source nodes and the relevant lines return the class nodes and the relevant lines.", "response": "def _get_classes(self, xml_document, src_path):\n        \"\"\"\n        Given a path and parsed xml_document provides class nodes\n        with the relevant lines\n\n        First, we look to see if xml_document contains a source\n        node providing paths to search for\n\n        If we don't have that we check each nodes filename attribute\n        matches an absolute path\n\n        Finally, if we found no nodes, we check the filename attribute\n        for the relative path\n        \"\"\"\n        # Remove git_root from src_path for searching the correct filename\n        # If cwd is `/home/user/work/diff-cover/diff_cover`\n        # and src_path is `diff_cover/violations_reporter.py`\n        # search for `violations_reporter.py`\n        src_rel_path = self._to_unix_path(GitPathTool.relative_path(src_path))\n\n        # If cwd is `/home/user/work/diff-cover/diff_cover`\n        # and src_path is `other_package/some_file.py`\n        # search for `/home/user/work/diff-cover/other_package/some_file.py`\n        src_abs_path = self._to_unix_path(GitPathTool.absolute_path(src_path))\n\n        # cobertura sometimes provides the sources for the measurements\n        # within it. If we have that we outta use it\n        sources = xml_document.findall('sources/source')\n        sources = [source.text for source in sources if source.text]\n        classes = [class_tree\n                   for class_tree in xml_document.findall(\".//class\")\n                   or []]\n\n        classes = (\n            [clazz for clazz in classes if\n             src_abs_path in [\n                 self._to_unix_path(\n                     os.path.join(\n                         source.strip(),\n                         clazz.get('filename')\n                     )\n                 ) for source in sources]]\n            or\n            [clazz for clazz in classes if\n             self._to_unix_path(clazz.get('filename')) == src_abs_path]\n            or\n            [clazz for clazz in classes if\n             self._to_unix_path(clazz.get('filename')) == src_rel_path]\n        )\n        return classes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of nodes containing line information for src_path in xml_document.", "response": "def _get_src_path_line_nodes_clover(self, xml_document, src_path):\n        \"\"\"\n        Return a list of nodes containing line information for `src_path`\n        in `xml_document`.\n\n        If file is not present in `xml_document`, return None\n        \"\"\"\n\n        files = [file_tree\n                 for file_tree in xml_document.findall(\".//file\")\n                 if GitPathTool.relative_path(file_tree.get('path')) == src_path\n                 or []]\n        if not files:\n            return None\n        lines = [file_tree.findall('./line[@type=\"stmt\"]')\n                 for file_tree in files]\n        return [elem for elem in itertools.chain(*lines)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_src_path_line_nodes_jacoco(self, xml_document, src_path):\n\n        files = []\n        packages = [pkg for pkg in xml_document.findall(\".//package\")]\n        for pkg in packages:\n            _files = [_file\n                      for _file in pkg.findall('sourcefile')\n                      if self._measured_source_path_matches(pkg.get('name'), _file.get('name'), src_path)\n                      or []\n                      ]\n            files.extend(_files)\n\n        if not files:\n            return None\n        lines = [file_tree.findall('./line')\n                 for file_tree in files]\n        return [elem for elem in itertools.chain(*lines)]", "response": "Return a list of nodes containing line information for src_path in xml_document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _cache_file(self, src_path):\n        # If we have not yet loaded this source file\n        if src_path not in self._info_cache:\n            # We only want to keep violations that show up in each xml source.\n            # Thus, each time, we take the intersection.  However, to do this\n            # we must treat the first time as a special case and just add all\n            # the violations from the first xml report.\n            violations = None\n\n            # A line is measured if it is measured in any of the reports, so\n            # we take set union each time and can just start with the empty set\n            measured = set()\n\n            # Loop through the files that contain the xml roots\n            for xml_document in self._xml_roots:\n                if xml_document.findall('.[@clover]'):\n                    # see etc/schema/clover.xsd at  https://bitbucket.org/atlassian/clover/src\n                    line_nodes = self._get_src_path_line_nodes_clover(xml_document, src_path)\n                    _number = 'num'\n                    _hits = 'count'\n                elif xml_document.findall('.[@name]'):\n                    # https://github.com/jacoco/jacoco/blob/master/org.jacoco.report/src/org/jacoco/report/xml/report.dtd\n                    line_nodes = self._get_src_path_line_nodes_jacoco(xml_document, src_path)\n                    _number = 'nr'\n                    _hits = 'ci'\n                else:\n                    # https://github.com/cobertura/web/blob/master/htdocs/xml/coverage-04.dtd\n                    line_nodes = self._get_src_path_line_nodes_cobertura(xml_document, src_path)\n                    _number = 'number'\n                    _hits = 'hits'\n                if line_nodes is None:\n                    continue\n\n                # First case, need to define violations initially\n                if violations is None:\n                    violations = set(\n                        Violation(int(line.get(_number)), None)\n                        for line in line_nodes\n                        if int(line.get(_hits, 0)) == 0)\n\n                # If we already have a violations set,\n                # take the intersection of the new\n                # violations set and its old self\n                else:\n                    violations = violations & set(\n                        Violation(int(line.get(_number)), None)\n                        for line in line_nodes\n                        if int(line.get(_hits, 0)) == 0\n                    )\n\n                # Measured is the union of itself and the new measured\n                measured = measured | set(\n                    int(line.get(_number)) for line in line_nodes\n                )\n\n            # If we don't have any information about the source file,\n            # don't report any violations\n            if violations is None:\n                violations = set()\n\n            self._info_cache[src_path] = (violations, measured)", "response": "Load the data from the xml roots and add it to the internal cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_reports(self, reports):\n        violations_dict = defaultdict(list)\n        for report in reports:\n            output_lines = report.split('\\n')\n\n            for output_line_number, line in enumerate(output_lines):\n                match = self.pylint_expression.match(line)\n\n                # Ignore any line that isn't matched\n                # (for example, snippets from the source code)\n                if match is not None:\n\n                    (pylint_src_path,\n                     line_number,\n                     pylint_code,\n                     function_name,\n                     message) = match.groups()\n                    if pylint_code == self.dupe_code_violation:\n                        files_involved = self._process_dupe_code_violation(\n                            output_lines,\n                            output_line_number,\n                            message\n                        )\n                    else:\n                        files_involved = [(pylint_src_path, line_number)]\n\n                    for violation in files_involved:\n                        pylint_src_path, line_number = violation\n                        # If we're looking for a particular source file,\n                        # ignore any other source files.\n                        if function_name:\n                            error_str = \"{}: {}: {}\".format(pylint_code, function_name, message)\n                        else:\n                            error_str = \"{}: {}\".format(pylint_code, message)\n\n                        violation = Violation(int(line_number), error_str)\n                        violations_dict[pylint_src_path].append(violation)\n\n        return violations_dict", "response": "Parse the output of the report and return a dictionary of Violation objects"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing command line arguments returning a dict of valid options and their values.", "response": "def parse_quality_args(argv):\n    \"\"\"\n    Parse command line arguments, returning a dict of\n    valid options:\n\n        {\n            'violations': pycodestyle| pyflakes | flake8 | pylint | ...,\n            'html_report': None | HTML_REPORT,\n            'external_css_file': None | CSS_FILE,\n        }\n\n    where `HTML_REPORT` and `CSS_FILE` are paths.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=diff_cover.QUALITY_DESCRIPTION\n    )\n\n    parser.add_argument(\n        '--violations',\n        metavar='TOOL',\n        type=str,\n        help=VIOLATION_CMD_HELP,\n        required=True\n    )\n\n    parser.add_argument(\n        '--html-report',\n        metavar='FILENAME',\n        type=str,\n        default=None,\n        help=HTML_REPORT_HELP\n    )\n\n    parser.add_argument(\n        '--external-css-file',\n        metavar='FILENAME',\n        type=str,\n        default=None,\n        help=CSS_FILE_HELP,\n    )\n\n    parser.add_argument(\n        '--compare-branch',\n        metavar='BRANCH',\n        type=str,\n        default='origin/master',\n        help=COMPARE_BRANCH_HELP\n    )\n\n    parser.add_argument(\n        'input_reports',\n        type=str,\n        nargs=\"*\",\n        default=[],\n        help=INPUT_REPORTS_HELP\n    )\n\n    parser.add_argument(\n        '--options',\n        type=str,\n        nargs='?',\n        default=None,\n        help=OPTIONS_HELP\n    )\n\n    parser.add_argument(\n        '--fail-under',\n        metavar='SCORE',\n        type=float,\n        default='0',\n        help=FAIL_UNDER_HELP\n    )\n\n    parser.add_argument(\n        '--ignore-staged',\n        action='store_true',\n        default=False,\n        help=IGNORE_STAGED_HELP\n    )\n\n    parser.add_argument(\n        '--ignore-unstaged',\n        action='store_true',\n        default=False,\n        help=IGNORE_UNSTAGED_HELP\n    )\n\n    parser.add_argument(\n        '--exclude',\n        metavar='EXCLUDE',\n        type=str,\n        nargs='+',\n        help=EXCLUDE_HELP\n    )\n\n    return vars(parser.parse_args(argv))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_quality_report(tool, compare_branch,\n                            html_report=None, css_file=None,\n                            ignore_staged=False, ignore_unstaged=False,\n                            exclude=None):\n    \"\"\"\n    Generate the quality report, using kwargs from `parse_args()`.\n    \"\"\"\n    diff = GitDiffReporter(\n        compare_branch, git_diff=GitDiffTool(),\n        ignore_staged=ignore_staged, ignore_unstaged=ignore_unstaged,\n        supported_extensions=tool.driver.supported_extensions,\n        exclude=exclude)\n\n    if html_report is not None:\n        css_url = css_file\n        if css_url is not None:\n            css_url = os.path.relpath(css_file, os.path.dirname(html_report))\n        reporter = HtmlQualityReportGenerator(tool, diff, css_url=css_url)\n        with open(html_report, \"wb\") as output_file:\n            reporter.generate_report(output_file)\n        if css_file is not None:\n            with open(css_file, \"wb\") as output_file:\n                reporter.generate_css(output_file)\n\n    # Generate the report for stdout\n    reporter = StringQualityReportGenerator(tool, diff)\n    output_file = sys.stdout if six.PY2 else sys.stdout.buffer\n\n    reporter.generate_report(output_file)\n    return reporter.total_percent_covered()", "response": "Generate the quality report for the given compare branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(argv=None, directory=None):\n    logging.basicConfig(format='%(message)s')\n\n    argv = argv or sys.argv\n    arg_dict = parse_quality_args(argv[1:])\n    GitPathTool.set_cwd(directory)\n    fail_under = arg_dict.get('fail_under')\n    tool = arg_dict['violations']\n    user_options = arg_dict.get('options')\n    if user_options:\n        # strip quotes if present\n        first_char = user_options[0]\n        last_char = user_options[-1]\n        if first_char == last_char and first_char in ('\"', \"'\"):\n            user_options = user_options[1:-1]\n    driver = QUALITY_DRIVERS.get(tool)\n\n    if driver is not None:\n        # If we've been given pre-generated reports,\n        # try to open the files\n        input_reports = []\n\n        for path in arg_dict['input_reports']:\n            try:\n                input_reports.append(open(path, 'rb'))\n            except IOError:\n                LOGGER.warning(\"Could not load '{}'\".format(path))\n        try:\n            reporter = QualityReporter(driver, input_reports, user_options)\n            percent_passing = generate_quality_report(\n                reporter,\n                arg_dict['compare_branch'],\n                html_report=arg_dict['html_report'],\n                css_file=arg_dict['external_css_file'],\n                ignore_staged=arg_dict['ignore_staged'],\n                ignore_unstaged=arg_dict['ignore_unstaged'],\n                exclude=arg_dict['exclude'],\n            )\n            if percent_passing >= fail_under:\n                return 0\n            else:\n                LOGGER.error(\"Failure. Quality is below {}%.\".format(fail_under))\n                return 1\n\n        except (ImportError, EnvironmentError):\n            LOGGER.error(\n                \"Quality tool not installed: '{}'\".format(tool)\n            )\n            return 1\n        # Close any reports we opened\n        finally:\n            for file_handle in input_reports:\n                file_handle.close()\n\n    else:\n        LOGGER.error(\"Quality tool not recognized: '{}'\".format(tool))\n        return 1", "response": "Entry point for the tool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_cwd(cls, cwd):\n        if not cwd:\n            try:\n                cwd = os.getcwdu()\n            except AttributeError:\n                cwd = os.getcwd()\n        if isinstance(cwd, six.binary_type):\n            cwd = cwd.decode(sys.getdefaultencoding())\n        cls._cwd = cwd\n        cls._root = cls._git_root()", "response": "Set the cwd that is used to manipulate paths."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relative_path(cls, git_diff_path):\n        # Remove git_root from src_path for searching the correct filename\n        # If cwd is `/home/user/work/diff-cover/diff_cover`\n        # and src_path is `diff_cover/violations_reporter.py`\n        # search for `violations_reporter.py`\n        root_rel_path = os.path.relpath(cls._cwd, cls._root)\n        rel_path = os.path.relpath(git_diff_path, root_rel_path)\n\n        return rel_path", "response": "Returns git_diff_path relative to cwd."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fnmatch(self, filename, patterns, default=True):\n        if not patterns:\n            return default\n        return any(fnmatch.fnmatch(filename, pattern) for pattern in patterns)", "response": "Wrap fnmatch. fnmatch to add some functionality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_path_excluded(self, path):\n        exclude = self._exclude\n        if not exclude:\n            return False\n        basename = os.path.basename(path)\n        if self._fnmatch(basename, exclude):\n            return True\n\n        absolute_path = os.path.abspath(path)\n        match = self._fnmatch(absolute_path, exclude)\n        return match", "response": "Check if a path is excluded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of file paths that have changed since the last commit.", "response": "def src_paths_changed(self):\n        \"\"\"\n        See base class docstring.\n        \"\"\"\n\n        # Get the diff dictionary\n        diff_dict = self._git_diff()\n\n        # Return the changed file paths (dict keys)\n        # in alphabetical order\n        return sorted(diff_dict.keys(), key=lambda x: x.lower())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_included_diff_results(self):\n        included = [self._git_diff_tool.diff_committed(self._compare_branch)]\n        if not self._ignore_staged:\n            included.append(self._git_diff_tool.diff_staged())\n        if not self._ignore_unstaged:\n            included.append(self._git_diff_tool.diff_unstaged())\n\n        return included", "response": "Return a list of stages to be included in the diff results."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _git_diff(self):\n\n        # If we do not have a cached result, execute `git diff`\n        if self._diff_dict is None:\n\n            result_dict = dict()\n\n            for diff_str in self._get_included_diff_results():\n                # Parse the output of the diff string\n                diff_dict = self._parse_diff_str(diff_str)\n\n                for src_path in diff_dict.keys():\n                    if self._is_path_excluded(src_path):\n                        continue\n                    # If no _supported_extensions provided, or extension present: process\n                    root, extension = os.path.splitext(src_path)\n                    extension = extension[1:].lower()\n                    # 'not self._supported_extensions' tests for both None and empty list []\n                    if not self._supported_extensions or extension in self._supported_extensions:\n                        added_lines, deleted_lines = diff_dict[src_path]\n\n                        # Remove any lines from the dict that have been deleted\n                        # Include any lines that have been added\n                        result_dict[src_path] = [\n                            line for line in result_dict.get(src_path, [])\n                            if not line in deleted_lines\n                        ] + added_lines\n\n            # Eliminate repeats and order line numbers\n            for (src_path, lines) in result_dict.items():\n                result_dict[src_path] = self._unique_ordered_lines(lines)\n\n            # Store the resulting dict\n            self._diff_dict = result_dict\n\n        # Return the diff cache\n        return self._diff_dict", "response": "Runs git diff and returns a dict in which the keys are changed file paths and the values are lists of line numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_source_sections(self, diff_str):\n\n        # Create a dict to map source files to lines in the diff output\n        source_dict = dict()\n\n        # Keep track of the current source file\n        src_path = None\n\n        # Signal that we've found a hunk (after starting a source file)\n        found_hunk = False\n\n        # Parse the diff string into sections by source file\n        for line in diff_str.split('\\n'):\n\n            # If the line starts with \"diff --git\"\n            # or \"diff --cc\" (in the case of a merge conflict)\n            # then it is the start of a new source file\n            if line.startswith('diff --git') or line.startswith('diff --cc'):\n\n                # Retrieve the name of the source file\n                src_path = self._parse_source_line(line)\n\n                # Create an entry for the source file, if we don't\n                # already have one.\n                if src_path not in source_dict:\n                    source_dict[src_path] = []\n\n                # Signal that we're waiting for a hunk for this source file\n                found_hunk = False\n\n            # Every other line is stored in the dictionary for this source file\n            # once we find a hunk section\n            else:\n\n                # Only add lines if we're in a hunk section\n                # (ignore index and files changed lines)\n                if found_hunk or line.startswith('@@'):\n\n                    # Remember that we found a hunk\n                    found_hunk = True\n\n                    if src_path is not None:\n                        source_dict[src_path].append(line)\n\n                    else:\n                        # We tolerate other information before we have\n                        # a source file defined, unless it's a hunk line\n                        if line.startswith(\"@@\"):\n                            msg = \"Hunk has no source file: '{}'\".format(line)\n                            raise GitDiffError(msg)\n\n        return source_dict", "response": "Parse the output of git diff into a dictionary of source file paths and lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving the diff lines output from git diff return a tuple of ( added deleted lines ) and ( changed lines ).", "response": "def _parse_lines(self, diff_lines):\n        \"\"\"\n        Given the diff lines output from `git diff` for a particular\n        source file, return a tuple of `(ADDED_LINES, DELETED_LINES)`\n\n        where `ADDED_LINES` and `DELETED_LINES` are lists of line\n        numbers added/deleted respectively.\n\n        Raises a `GitDiffError` if the diff lines are in an invalid format.\n        \"\"\"\n\n        added_lines = []\n        deleted_lines = []\n\n        current_line_new = None\n        current_line_old = None\n\n        for line in diff_lines:\n\n            # If this is the start of the hunk definition, retrieve\n            # the starting line number\n            if line.startswith('@@'):\n                line_num = self._parse_hunk_line(line)\n                current_line_new, current_line_old = line_num, line_num\n\n            # This is an added/modified line, so store the line number\n            elif line.startswith('+'):\n\n                # Since we parse for source file sections before\n                # calling this method, we're guaranteed to have a source\n                # file specified.  We check anyway just to be safe.\n                if current_line_new is not None:\n\n                    # Store the added line\n                    added_lines.append(current_line_new)\n\n                    # Increment the line number in the file\n                    current_line_new += 1\n\n            # This is a deleted line that does not exist in the final\n            # version, so skip it\n            elif line.startswith('-'):\n\n                # Since we parse for source file sections before\n                # calling this method, we're guaranteed to have a source\n                # file specified.  We check anyway just to be safe.\n                if current_line_old is not None:\n\n                    # Store the deleted line\n                    deleted_lines.append(current_line_old)\n\n                    # Increment the line number in the file\n                    current_line_old += 1\n\n            # This is a line in the final version that was not modified.\n            # Increment the line number, but do not store this as a changed\n            # line.\n            else:\n                if current_line_old is not None:\n                    current_line_old += 1\n\n                if current_line_new is not None:\n                    current_line_new += 1\n\n                # If we are not in a hunk, then ignore the line\n                else:\n                    pass\n\n        return added_lines, deleted_lines"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_source_line(self, line):\n        if '--git' in line:\n            regex = self.SRC_FILE_RE\n        elif '--cc' in line:\n            regex = self.MERGE_CONFLICT_RE\n        else:\n            msg = \"Do not recognize format of source in line '{}'\".format(line)\n            raise GitDiffError(msg)\n\n        # Parse for the source file path\n        groups = regex.findall(line)\n\n        if len(groups) == 1:\n            return groups[0]\n\n        else:\n            msg = \"Could not parse source path in line '{}'\".format(line)\n            raise GitDiffError(msg)", "response": "Parse a source line in git diff output and return the path to the source file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_hunk_line(self, line):\n        # Split the line at the @@ terminators (start and end of the line)\n        components = line.split('@@')\n\n        # The first component should be an empty string, because\n        # the line starts with '@@'.  The second component should\n        # be the hunk information, and any additional components\n        # are excerpts from the code.\n        if len(components) >= 2:\n\n            hunk_info = components[1]\n            groups = self.HUNK_LINE_RE.findall(hunk_info)\n\n            if len(groups) == 1:\n\n                try:\n                    return int(groups[0])\n\n                except ValueError:\n                    msg = \"Could not parse '{}' as a line number\".format(groups[0])\n                    raise GitDiffError(msg)\n\n            else:\n                msg = \"Could not find start of hunk in line '{}'\".format(line)\n                raise GitDiffError(msg)\n\n        else:\n            msg = \"Could not parse hunk in line '{}'\".format(line)\n            raise GitDiffError(msg)", "response": "Given a line in git diff output return the line number that represents the start of the hunk."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _unique_ordered_lines(line_numbers):\n\n        if len(line_numbers) == 0:\n            return []\n\n        # Ensure lines are unique by putting them in a set\n        line_set = set(line_numbers)\n\n        # Retrieve the list from the set, sort it, and return\n        return sorted([line for line in line_set])", "response": "Given a list of line numbers return a list of unique line numbers ordered sequentially."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef src_paths(self):\n        return {src for src, summary in self._diff_violations().items()\n                   if len(summary.measured_lines) > 0}", "response": "Return a list of source files in the diff\n        which we have coverage information."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a float percent of lines covered for the source in src_path.", "response": "def percent_covered(self, src_path):\n        \"\"\"\n        Return a float percent of lines covered for the source\n        in `src_path`.\n\n        If we have no coverage information for `src_path`, returns None\n        \"\"\"\n        diff_violations = self._diff_violations().get(src_path)\n\n        if diff_violations is None:\n            return None\n\n        # Protect against a divide by zero\n        num_measured = len(diff_violations.measured_lines)\n        if num_measured > 0:\n            num_uncovered = len(diff_violations.lines)\n            return 100 - float(num_uncovered) / num_measured * 100\n\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef violation_lines(self, src_path):\n\n        diff_violations = self._diff_violations().get(src_path)\n\n        if diff_violations is None:\n            return []\n\n        return sorted(diff_violations.lines)", "response": "Return a list of lines in violation ( integers )\n        in src_path that were changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the total number of lines in the diff for which we have coverage info.", "response": "def total_num_lines(self):\n        \"\"\"\n        Return the total number of lines in the diff for\n        which we have coverage info.\n        \"\"\"\n\n        return sum([len(summary.measured_lines) for summary\n                    in self._diff_violations().values()])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the total number of lines in the diff that are in violation.", "response": "def total_num_violations(self):\n        \"\"\"\n        Returns the total number of lines in the diff\n        that are in violation.\n        \"\"\"\n\n        return sum(\n            len(summary.lines)\n            for summary\n            in self._diff_violations().values()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef total_percent_covered(self):\n        total_lines = self.total_num_lines()\n\n        if total_lines > 0:\n            num_covered = total_lines - self.total_num_violations()\n            return int(float(num_covered) / total_lines * 100)\n\n        else:\n            return 100", "response": "Returns the total percent of lines covered by the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _diff_violations(self):\n        if not self._diff_violations_dict:\n            self._diff_violations_dict = {\n                    src_path: DiffViolations(\n                        self._violations.violations(src_path),\n                        self._violations.measured_lines(src_path),\n                        self._diff.lines_changed(src_path),\n                    )\n                 for src_path in self._diff.src_paths_changed()\n            }\n        return self._diff_violations_dict", "response": "Returns a dictionary of the form SRC_PATH - > DiffViolations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_report(self, output_file):\n\n        if self.TEMPLATE_NAME is not None:\n            template = TEMPLATE_ENV.get_template(self.TEMPLATE_NAME)\n            report = template.render(self._context())\n\n            if isinstance(report, six.string_types):\n                report = report.encode('utf-8')\n\n            output_file.write(report)", "response": "Generate a report from the template and write it to output_file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_css(self, output_file):\n        if self.CSS_TEMPLATE_NAME is not None:\n            template = TEMPLATE_ENV.get_template(self.CSS_TEMPLATE_NAME)\n            style = template.render(self._context())\n\n        if isinstance(style, six.string_types):\n            style = style.encode('utf-8')\n\n        output_file.write(style)", "response": "Generate an external style sheet file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _context(self):\n\n        # Calculate the information to pass to the template\n        src_stats = {\n            src: self._src_path_stats(src) for src in self.src_paths()\n        }\n\n        # Include snippet style info if we're displaying\n        # source code snippets\n        if self.INCLUDE_SNIPPETS:\n            snippet_style = Snippet.style_defs()\n        else:\n            snippet_style = None\n\n        return {\n            'css_url': self.css_url,\n            'report_name': self.coverage_report_name(),\n            'diff_name': self.diff_report_name(),\n            'src_stats': src_stats,\n            'total_num_lines': self.total_num_lines(),\n            'total_num_violations': self.total_num_violations(),\n            'total_percent_covered': self.total_percent_covered(),\n            'snippet_style': snippet_style\n        }", "response": "Return the context of the template."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef combine_adjacent_lines(line_numbers):\n        combine_template = \"{0}-{1}\"\n        combined_list = []\n\n        # Add a terminating value of `None` to list\n        line_numbers.append(None)\n        start = line_numbers[0]\n        end = None\n\n        for line_number in line_numbers[1:]:\n            # If the current number is adjacent to the previous number\n            if (end if end else start) + 1 == line_number:\n                end = line_number\n            else:\n                if end:\n                    combined_list.append(combine_template.format(start, end))\n                else:\n                    combined_list.append(str(start))\n                start = line_number\n                end = None\n        return combined_list", "response": "Given a sorted collection of line numbers this will\n        turn them to strings and combine adjacent values"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict of statistics for the source file at src_path.", "response": "def _src_path_stats(self, src_path):\n        \"\"\"\n        Return a dict of statistics for the source file at `src_path`.\n        \"\"\"\n\n        # Find violation lines\n        violation_lines = self.violation_lines(src_path)\n        violations = sorted(self._diff_violations()[src_path].violations)\n\n        # Load source snippets (if the report will display them)\n        # If we cannot load the file, then fail gracefully\n        if self.INCLUDE_SNIPPETS:\n            try:\n                snippets = Snippet.load_snippets_html(src_path, violation_lines)\n            except IOError:\n                snippets = []\n        else:\n            snippets = []\n\n        return {\n            'percent_covered': self.percent_covered(src_path),\n            'violation_lines': TemplateReportGenerator.combine_adjacent_lines(violation_lines),\n            'violations': violations,\n            'snippets_html': snippets\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses command line arguments and return a dict of valid options.", "response": "def parse_coverage_args(argv):\n    \"\"\"\n    Parse command line arguments, returning a dict of\n    valid options:\n\n        {\n            'coverage_xml': COVERAGE_XML,\n            'html_report': None | HTML_REPORT,\n            'external_css_file': None | CSS_FILE,\n        }\n\n    where `COVERAGE_XML`, `HTML_REPORT`, and `CSS_FILE` are paths.\n\n    The path strings may or may not exist.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=DESCRIPTION)\n\n    parser.add_argument(\n        'coverage_xml',\n        type=str,\n        help=COVERAGE_XML_HELP,\n        nargs='+'\n    )\n\n    parser.add_argument(\n        '--html-report',\n        metavar='FILENAME',\n        type=str,\n        default=None,\n        help=HTML_REPORT_HELP\n    )\n\n    parser.add_argument(\n        '--external-css-file',\n        metavar='FILENAME',\n        type=str,\n        default=None,\n        help=CSS_FILE_HELP,\n    )\n\n    parser.add_argument(\n        '--compare-branch',\n        metavar='BRANCH',\n        type=str,\n        default='origin/master',\n        help=COMPARE_BRANCH_HELP\n    )\n\n    parser.add_argument(\n        '--fail-under',\n        metavar='SCORE',\n        type=float,\n        default='0',\n        help=FAIL_UNDER_HELP\n    )\n\n    parser.add_argument(\n        '--ignore-staged',\n        action='store_true',\n        default=False,\n        help=IGNORE_STAGED_HELP\n    )\n\n    parser.add_argument(\n        '--ignore-unstaged',\n        action='store_true',\n        default=False,\n        help=IGNORE_UNSTAGED_HELP\n    )\n\n    parser.add_argument(\n        '--exclude',\n        metavar='EXCLUDE',\n        type=str,\n        nargs='+',\n        help=EXCLUDE_HELP\n    )\n\n    parser.add_argument(\n        '--src-roots',\n        metavar='DIRECTORY',\n        type=str,\n        nargs='+',\n        default=['src/main/java', 'src/test/java'],\n        help=SRC_ROOTS_HELP\n    )\n\n    return vars(parser.parse_args(argv))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the diff coverage report using kwargs from parse_args.", "response": "def generate_coverage_report(coverage_xml, compare_branch,\n                             html_report=None, css_file=None,\n                             ignore_staged=False, ignore_unstaged=False,\n                             exclude=None, src_roots=None):\n    \"\"\"\n    Generate the diff coverage report, using kwargs from `parse_args()`.\n    \"\"\"\n    diff = GitDiffReporter(\n        compare_branch, git_diff=GitDiffTool(), ignore_staged=ignore_staged,\n        ignore_unstaged=ignore_unstaged, exclude=exclude)\n\n    xml_roots = [cElementTree.parse(xml_root) for xml_root in coverage_xml]\n    coverage = XmlCoverageReporter(xml_roots, src_roots)\n\n    # Build a report generator\n    if html_report is not None:\n        css_url = css_file\n        if css_url is not None:\n            css_url = os.path.relpath(css_file, os.path.dirname(html_report))\n        reporter = HtmlReportGenerator(coverage, diff, css_url=css_url)\n        with open(html_report, \"wb\") as output_file:\n            reporter.generate_report(output_file)\n        if css_file is not None:\n            with open(css_file, \"wb\") as output_file:\n                reporter.generate_css(output_file)\n\n    reporter = StringReportGenerator(coverage, diff)\n    output_file = sys.stdout if six.PY2 else sys.stdout.buffer\n\n    # Generate the report\n    reporter.generate_report(output_file)\n    return reporter.total_percent_covered()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(argv=None, directory=None):\n    logging.basicConfig(format='%(message)s')\n\n    argv = argv or sys.argv\n    arg_dict = parse_coverage_args(argv[1:])\n    GitPathTool.set_cwd(directory)\n    fail_under = arg_dict.get('fail_under')\n    percent_covered = generate_coverage_report(\n        arg_dict['coverage_xml'],\n        arg_dict['compare_branch'],\n        html_report=arg_dict['html_report'],\n        css_file=arg_dict['external_css_file'],\n        ignore_staged=arg_dict['ignore_staged'],\n        ignore_unstaged=arg_dict['ignore_unstaged'],\n        exclude=arg_dict['exclude'],\n        src_roots=arg_dict['src_roots'],\n    )\n\n    if percent_covered >= fail_under:\n        return 0\n    else:\n        LOGGER.error(\"Failure. Coverage is below {}%.\".format(fail_under))\n        return 1", "response": "Entry point for the tool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a command and returns the stdout of the command.", "response": "def execute(command, exit_codes=[0]):\n    \"\"\"Execute provided command returning the stdout\n    Args:\n        command (list[str]): list of tokens to execute as your command.\n        exit_codes (list[int]): exit codes which do not indicate error.\n        subprocess_mod (module): Defaults to pythons subprocess module but you can optionally pass in\n        another. This is mostly for testing purposes\n    Returns:\n        str - Stdout of the command passed in. This will be Unicode for python < 3. Str for python 3\n    Raises:\n        ValueError if there is a error running the command\n    \"\"\"\n    stdout_pipe = subprocess.PIPE\n    process = subprocess.Popen(\n        command, stdout=stdout_pipe,\n        stderr=stdout_pipe\n    )\n    try:\n        stdout, stderr = process.communicate()\n    except OSError:\n        sys.stderr.write(\" \".join(\n                [cmd.decode(sys.getfilesystemencoding())\n                 if isinstance(cmd, bytes) else cmd\n                 for cmd in command])\n        )\n        raise\n\n    stderr = _ensure_unicode(stderr)\n    if process.returncode not in exit_codes:\n        raise CommandError(stderr)\n\n    return _ensure_unicode(stdout), stderr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command_for_code(command):\n    process = subprocess.Popen(\n        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n    )\n    process.communicate()\n    exit_code = process.returncode\n    return exit_code", "response": "Runs command and returns exit code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ensure_unicode(text):\n    if isinstance(text, six.binary_type):\n        return text.decode(sys.getfilesystemencoding(), 'replace')\n    else:\n        return text", "response": "Ensures that the text passed in becomes unicode"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_reports(self, reports):\n        violations_dict = defaultdict(list)\n        for report in reports:\n            xml_document = cElementTree.fromstring(\"\".join(report))\n            files = xml_document.findall(\".//file\")\n            for file_tree in files:\n                for error in file_tree.findall('error'):\n                    line_number = error.get('line')\n                    error_str = \"{}: {}\".format(error.get('severity'),\n                                                   error.get('message'))\n                    violation = Violation(int(line_number), error_str)\n                    filename = GitPathTool.relative_path(file_tree.get('name'))\n                    violations_dict[filename].append(violation)\n        return violations_dict", "response": "Parse the reports and return a dictionary of violations"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the XML reports and return a dictionary of violations", "response": "def parse_reports(self, reports):\n        \"\"\"\n        Args:\n            reports: list[str] - output from the report\n        Return:\n            A dict[Str:Violation]\n            Violation is a simple named tuple Defined above\n        \"\"\"\n        violations_dict = defaultdict(list)\n        for report in reports:\n            xml_document = cElementTree.fromstring(\"\".join(report))\n            bugs = xml_document.findall(\".//BugInstance\")\n            for bug in bugs:\n                category = bug.get('category')\n                short_message = bug.find('ShortMessage').text\n                line = bug.find('SourceLine')\n                if line.get('start') is None or line.get('end') is None:\n                    continue\n                start = int(line.get('start'))\n                end = int(line.get('end'))\n                for line_number in range(start, end+1):\n                    error_str = \"{}: {}\".format(category, short_message)\n                    violation = Violation(line_number, error_str)\n                    filename = GitPathTool.relative_path(\n                        line.get('sourcepath'))\n                    violations_dict[filename].append(violation)\n\n        return violations_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the CSS style definitions required by the formatted snippet.", "response": "def style_defs(cls):\n        \"\"\"\n        Return the CSS style definitions required\n        by the formatted snippet.\n        \"\"\"\n        formatter = HtmlFormatter()\n        formatter.style.highlight_color = cls.VIOLATION_COLOR\n        return formatter.get_style_defs()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an HTML representation of the snippet.", "response": "def html(self):\n        \"\"\"\n        Return an HTML representation of the snippet.\n        \"\"\"\n        formatter = HtmlFormatter(\n            cssclass=self.DIV_CSS_CLASS,\n            linenos=True,\n            linenostart=self._start_line,\n            hl_lines=self._shift_lines(\n                self._violation_lines,\n                self._start_line\n            ),\n            lineanchors=self._src_filename\n        )\n\n        return pygments.format(self.src_tokens(), formatter)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple of the form start_line end_line indicating the start and end line number of the snippet.", "response": "def line_range(self):\n        \"\"\"\n        Return a tuple of the form `(start_line, end_line)`\n        indicating the start and end line number of the snippet.\n        \"\"\"\n        num_lines = len(self.text().split('\\n'))\n        end_line = self._start_line + num_lines - 1\n        return (self._start_line, end_line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_snippets_html(cls, src_path, violation_lines):\n        snippet_list = cls.load_snippets(src_path, violation_lines)\n        return [snippet.html() for snippet in snippet_list]", "response": "Load snippets from the file at src_path and format them as HTML."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the snippets from the file at src_path to show the lines in the list violation_lines.", "response": "def load_snippets(cls, src_path, violation_lines):\n        \"\"\"\n        Load snippets from the file at `src_path` to show\n        violations on lines in the list `violation_lines`\n        (list of line numbers, starting at index 0).\n\n        The file at `src_path` should be a text file (not binary).\n\n        Returns a list of `Snippet` instances.\n\n        Raises an `IOError` if the file could not be loaded.\n        \"\"\"\n        # Load the contents of the file\n        with openpy(GitPathTool.relative_path(src_path)) as src_file:\n            contents = src_file.read()\n\n        # Convert the source file to unicode (Python < 3)\n        if isinstance(contents, six.binary_type):\n            contents = contents.decode('utf-8', 'replace')\n\n        # Construct a list of snippet ranges\n        src_lines = contents.split('\\n')\n        snippet_ranges = cls._snippet_ranges(len(src_lines), violation_lines)\n\n        # Parse the source into tokens\n        token_stream = cls._parse_src(contents, src_path)\n\n        # Group the tokens by snippet\n        token_groups = cls._group_tokens(token_stream, snippet_ranges)\n\n        return [\n            Snippet(tokens, src_path, start, violation_lines)\n            for (start, _), tokens in sorted(token_groups.items())\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_src(cls, src_contents, src_filename):\n\n        # Parse the source into tokens\n        try:\n            lexer = guess_lexer_for_filename(src_filename, src_contents)\n        except ClassNotFound:\n            lexer = TextLexer()\n\n        # Ensure that we don't strip newlines from\n        # the source file when lexing.\n        lexer.stripnl = False\n\n        return pygments.lex(src_contents, lexer)", "response": "Parse the source file into a stream of tuples containing the token type and value of the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngrouping tokens into snippet ranges.", "response": "def _group_tokens(cls, token_stream, range_list):\n        \"\"\"\n        Group tokens into snippet ranges.\n\n        `token_stream` is a generator that produces\n        `(token_type, value)` tuples,\n\n        `range_list` is a list of `(start, end)` tuples representing\n        the (inclusive) range of line numbers for each snippet.\n\n        Assumes that `range_list` is an ascending order by start value.\n\n        Returns a dict mapping ranges to lists of tokens:\n        {\n            (4, 10): [(ttype_1, val_1), (ttype_2, val_2), ...],\n            (29, 39): [(ttype_3, val_3), ...],\n            ...\n        }\n\n        The algorithm is slightly complicated because a single token\n        can contain multiple line breaks.\n        \"\"\"\n\n        # Create a map from ranges (start/end tuples) to tokens\n        token_map = {rng: [] for rng in range_list}\n\n        # Keep track of the current line number; we will\n        # increment this as we encounter newlines in token values\n        line_num = 1\n\n        for ttype, val in token_stream:\n\n            # If there are newlines in this token,\n            # we need to split it up and check whether\n            # each line within the token is within one\n            # of our ranges.\n            if '\\n' in val:\n                val_lines = val.split('\\n')\n\n                # Check if the tokens match each range\n                for (start, end), filtered_tokens in six.iteritems(token_map):\n\n                    # Filter out lines that are not in this range\n                    include_vals = [\n                        val_lines[i] for i in\n                        range(0, len(val_lines))\n                        if i + line_num in range(start, end + 1)\n                    ]\n\n                    # If we found any lines, store the tokens\n                    if len(include_vals) > 0:\n                        token = (ttype, '\\n'.join(include_vals))\n                        filtered_tokens.append(token)\n\n                # Increment the line number\n                # by the number of lines we found\n                line_num += len(val_lines) - 1\n\n            # No newline in this token\n            # If we're in the line range, add it\n            else:\n                # Check if the tokens match each range\n                for (start, end), filtered_tokens in six.iteritems(token_map):\n\n                    # If we got a match, store the token\n                    if line_num in range(start, end + 1):\n                        filtered_tokens.append((ttype, val))\n\n                    # Otherwise, ignore the token\n\n        return token_map"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _snippet_ranges(cls, num_src_lines, violation_lines):\n        current_range = (None, None)\n        lines_since_last_violation = 0\n        snippet_ranges = []\n        for line_num in range(1, num_src_lines + 1):\n\n            # If we have not yet started a snippet,\n            # check if we can (is this line a violation?)\n            if current_range[0] is None:\n                if line_num in violation_lines:\n\n                    # Expand to include extra context, but not before line 1\n                    snippet_start = max(1, line_num - cls.NUM_CONTEXT_LINES)\n                    current_range = (snippet_start, None)\n                    lines_since_last_violation = 0\n\n            # If we are within a snippet, check if we\n            # can end the snippet (have we gone enough\n            # lines without hitting a violation?)\n            elif current_range[1] is None:\n                if line_num in violation_lines:\n                    lines_since_last_violation = 0\n\n                elif lines_since_last_violation > cls.MAX_GAP_IN_SNIPPET:\n\n                    # Expand to include extra context, but not after last line\n                    snippet_end = line_num - lines_since_last_violation\n                    snippet_end = min(\n                        num_src_lines,\n                        snippet_end + cls.NUM_CONTEXT_LINES\n                    )\n                    current_range = (current_range[0], snippet_end)\n\n                    # Store the snippet and start looking for the next one\n                    snippet_ranges.append(current_range)\n                    current_range = (None, None)\n\n            # Another line since the last violation\n            lines_since_last_violation += 1\n\n        # If we started a snippet but didn't finish it, do so now\n        if current_range[0] is not None and current_range[1] is None:\n            snippet_ranges.append((current_range[0], num_src_lines))\n\n        return snippet_ranges", "response": "Given the number of source file lines and a list of line numbers return a list of snippet_ranges that are grouped by context_COOKIE."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the reports from a list of files.", "response": "def _load_reports(self, report_files):\n        \"\"\"\n        Args:\n            report_files: list[file] reports to read in\n        \"\"\"\n        contents = []\n        for file_handle in report_files:\n            # Convert to unicode, replacing unreadable chars\n            contents.append(\n                file_handle.read().decode(\n                    'utf-8',\n                    'replace'\n                )\n            )\n        return contents"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef violations(self, src_path):\n        if not any(src_path.endswith(ext) for ext in self.driver.supported_extensions):\n            return []\n        if src_path not in self.violations_dict:\n            if self.reports:\n                self.violations_dict = self.driver.parse_reports(self.reports)\n            else:\n                if self.driver_tool_installed is None:\n                    self.driver_tool_installed = self.driver.installed()\n                if not self.driver_tool_installed:\n                    raise EnvironmentError(\"{} is not installed\".format(self.driver.name))\n                command = copy.deepcopy(self.driver.command)\n                if self.options:\n                    command.append(self.options)\n                if os.path.exists(src_path):\n                    command.append(src_path.encode(sys.getfilesystemencoding()))\n                    output, _ = execute(command, self.driver.exit_codes)\n                    self.violations_dict.update(self.driver.parse_reports([output]))\n\n        return self.violations_dict[src_path]", "response": "Return a list of Violations recorded in src_path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the report and return a dictionary of violations", "response": "def parse_reports(self, reports):\n        \"\"\"\n        Args:\n            reports: list[str] - output from the report\n        Return:\n            A dict[Str:Violation]\n            Violation is a simple named tuple Defined above\n        \"\"\"\n        violations_dict = defaultdict(list)\n        for report in reports:\n            if self.expression.flags & re.MULTILINE:\n                matches = (match for match in\n                           re.finditer(self.expression, report))\n            else:\n                matches = (self.expression.match(line) for line in\n                           report.split('\\n'))\n            for match in matches:\n                if match is not None:\n                    src, line_number, message = match.groups()\n                    # Transform src to a relative path, if it isn't already\n                    src = os.path.relpath(src)\n                    violation = Violation(int(line_number), message)\n                    violations_dict[src].append(violation)\n        return violations_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version(module):\n    init_py = open('{0}.py'.format(module)).read()\n    return re.search(\"__version__ = ['\\\"]([^'\\\"]+)['\\\"]\", init_py).group(1)", "response": "Get package version as listed in __version__."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_dotenv(dotenv=None, override=False):\n    if dotenv is None:\n        frame_filename = sys._getframe().f_back.f_code.co_filename\n        dotenv = os.path.join(os.path.dirname(frame_filename), '.env')\n\n    if os.path.isdir(dotenv) and os.path.isfile(os.path.join(dotenv, '.env')):\n        dotenv = os.path.join(dotenv, '.env')\n\n    if os.path.exists(dotenv):\n        with open(dotenv) as f:\n            for k, v in parse_dotenv(f.read()).items():\n                if override:\n                    os.environ[k] = v\n                else:\n                    os.environ.setdefault(k, v)\n    else:\n        warnings.warn(\"Not reading {0} - it doesn't exist.\".format(dotenv),\n                      stacklevel=2)", "response": "Reads a. env file into the system variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configure(self, transport, auth, address, port):\n\n        self.transport = transport\n        self.username = auth.username\n        self.address = address\n        self.port = port", "response": "Configure the object with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting ssh tunnel type: local_port: int param: local_port: local tunnel endpoint ip binding type: remote_address: str param: remote_address: Remote tunnel endpoing ip binding type: remote_port: int param: remote_port: Remote tunnel endpoint port binding", "response": "def start(self, local_port, remote_address, remote_port):\n        \"\"\"\n        Start ssh tunnel\n\n        type: local_port: int\n        param: local_port: local tunnel endpoint ip binding\n        type: remote_address: str\n        param: remote_address: Remote tunnel endpoing ip binding\n        type: remote_port: int\n        param: remote_port: Remote tunnel endpoint port binding\n        \"\"\"\n        self.local_port = local_port\n        self.remote_address = remote_address\n        self.remote_port = remote_port\n\n        logger.debug((\"Starting ssh tunnel {0}:{1}:{2} for \"\n                      \"{3}@{4}\".format(local_port, remote_address, remote_port,\n                                       self.username, self.address)))\n        self.forward = Forward(local_port,\n                               remote_address,\n                               remote_port,\n                               self.transport)\n        self.forward.start()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a stream handler for the provided name and level to the logging module.", "response": "def set_stream_logger(name='margaritashotgun', level=logging.INFO,\n                      format_string=None):\n    \"\"\"\n    Add a stream handler for the provided name and level to the logging module.\n\n        >>> import margaritashotgun\n        >>> margaritashotgun.set_stream_logger('marsho', logging.DEBUG)\n\n    :type name: string\n    :param name: Log name\n    :type level: int\n    :param level: Logging level\n    :type format_string: str\n    :param format_string: Log message format\n    \"\"\"\n\n    if format_string is None:\n        format_string = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    time_format = \"%Y-%m-%dT%H:%M:%S\"\n\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n    handler = logging.StreamHandler()\n    handler.setLevel(level)\n    formatter = logging.Formatter(format_string, time_format)\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    paramiko_log_level = logging.CRITICAL\n    paramiko_log = logging.getLogger('paramiko')\n    paramiko_log.setLevel(paramiko_log_level)\n    paramiko_handler = logging.StreamHandler()\n    paramiko_handler.setLevel(paramiko_log_level)\n    paramiko_handler.setFormatter(formatter)\n    paramiko_log.addHandler(paramiko_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to remote host and configure ssh tunnel and shell executor", "response": "def connect(self, username, password, key, address, port, jump_host):\n        \"\"\"\n        Connect ssh tunnel and shell executor to remote host\n\n        :type username: str\n        :param username: username for authentication\n        :type password: str\n        :param password: password for authentication, may be used to unlock rsa key\n        :type key: str\n        :param key: path to rsa key for authentication\n        :type address: str\n        :param address: address for remote host\n        :type port: int\n        :param port: ssh port for remote host\n        \"\"\"\n        if port is None:\n            self.remote_port = 22\n        else:\n            self.remote_port = int(port)\n\n        auth = Auth(username=username, password=password, key=key)\n        if jump_host is not None:\n            jump_auth = Auth(username=jump_host['username'],\n                             password=jump_host['password'],\n                             key=jump_host['key'])\n            if jump_host['port'] is None:\n                jump_host['port'] = 22\n        else:\n            jump_auth = None\n        self.shell.connect(auth, address, self.remote_port, jump_host, jump_auth)\n        transport = self.shell.transport()\n        self.tunnel.configure(transport, auth, address, self.remote_port)\n        self.remote_addr = address"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_tunnel(self, local_port, remote_address, remote_port):\n        self.tunnel.start(local_port, remote_address, remote_port)\n        self.tunnel_port = local_port", "response": "Start ssh forward tunnel for the current node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the memory size in bytes of the remote host", "response": "def mem_size(self):\n        \"\"\"\n        Returns the memory size in bytes of the remote host\n        \"\"\"\n        result = self.shell.execute(self.commands.mem_size.value)\n        stdout = self.shell.decode(result['stdout'])\n        stderr = self.shell.decode(result['stderr'])\n        return int(stdout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kernel_version(self):\n        result = self.shell.execute(self.commands.kernel_version.value)\n        stdout = self.shell.decode(result['stdout'])\n        stderr = self.shell.decode(result['stderr'])\n        return stdout", "response": "Returns the kernel version of the remote host"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait until LiME has loaded a LiME entry.", "response": "def wait_for_lime(self, listen_port, listen_address=\"0.0.0.0\",\n                      max_tries=20, wait=1):\n        \"\"\"\n        Wait for lime to load unless max_retries is exceeded\n\n        :type listen_port: int\n        :param listen_port: port LiME is listening for connections on\n        :type listen_address: str\n        :param listen_address: address LiME is listening for connections on\n        :type max_tries: int\n        :param max_tries: maximum number of checks that LiME has loaded\n        :type wait: int\n        :param wait: time to wait between checks\n        \"\"\"\n        tries = 0\n        pattern = self.commands.lime_pattern.value.format(listen_address,\n                                                          listen_port)\n        lime_loaded = False\n        while tries < max_tries and lime_loaded is False:\n            lime_loaded = self.check_for_lime(pattern)\n            tries = tries + 1\n            time.sleep(wait)\n        return lime_loaded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck to see if LiME has loaded on the remote system", "response": "def check_for_lime(self, pattern):\n        \"\"\"\n        Check to see if LiME has loaded on the remote system\n\n        :type pattern: str\n        :param pattern: pattern to check output against\n        :type listen_port: int\n        :param listen_port: port LiME is listening for connections on\n        \"\"\"\n        check = self.commands.lime_check.value\n        lime_loaded = False\n        result = self.shell.execute(check)\n        stdout = self.shell.decode(result['stdout'])\n        connections = self.net_parser.parse(stdout)\n\n        for conn in connections:\n            local_addr, remote_addr = conn\n            if local_addr == pattern:\n                lime_loaded = True\n                break\n\n        return lime_loaded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading LiME kernel module to remote host", "response": "def upload_module(self, local_path=None, remote_path=\"/tmp/lime.ko\"):\n        \"\"\"\n        Upload LiME kernel module to remote host\n\n        :type local_path: str\n        :param local_path: local path to lime kernel module\n        :type remote_path: str\n        :param remote_path: remote path to upload lime kernel module\n        \"\"\"\n        if local_path is None:\n            raise FileNotFoundFoundError(local_path)\n        self.shell.upload_file(local_path, remote_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_lime(self, remote_path, listen_port, dump_format='lime'):\n        load_command = self.commands.load_lime.value.format(remote_path,\n                                                            listen_port,\n                                                            dump_format)\n        self.shell.execute_async(load_command)", "response": "Load LiME kernel module from remote filesystem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning up resources used by supporting classes.", "response": "def cleanup(self):\n        \"\"\"\n        Release resources used by supporting classes\n        \"\"\"\n        try:\n            self.unload_lime()\n        except AttributeError as ex:\n            pass\n        self.tunnel.cleanup()\n        self.shell.cleanup()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to a remote host and returns a SSHSession object.", "response": "def connect(self, auth, address, port, jump_host, jump_auth):\n        \"\"\"\n        Creates an ssh session to a remote host\n\n        :type auth: :py:class:`margaritashotgun.auth.AuthMethods`\n        :param auth: Authentication object\n        :type address: str\n        :param address: remote server address\n        :type port: int\n        :param port: remote server port\n        \"\"\"\n\n        try:\n            self.target_address = address\n            sock = None\n            if jump_host is not None:\n                self.jump_host_ssh = paramiko.SSHClient()\n                self.jump_host_ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n                self.connect_with_auth(self.jump_host_ssh, jump_auth,\n                                       jump_host['addr'], jump_host['port'], sock)\n                transport = self.jump_host_ssh.get_transport()\n                dest_addr = (address, port)\n                jump_addr = (jump_host['addr'], jump_host['port'])\n                channel = transport.open_channel('direct-tcpip', dest_addr,\n                                                 jump_addr)\n                self.connect_with_auth(self.ssh, auth, address, port, channel)\n            else:\n                self.connect_with_auth(self.ssh, auth, address, port, sock)\n        except (AuthenticationException, SSHException,\n                ChannelException, SocketError) as ex:\n            raise SSHConnectionError(\"{0}:{1}\".format(address, port), ex)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to a remote host with a username and password.", "response": "def connect_with_password(self, ssh, username, password, address, port, sock,\n                              timeout=20):\n        \"\"\"\n        Create an ssh session to a remote host with a username and password\n\n        :type username: str\n        :param username: username used for ssh authentication\n        :type password: str\n        :param password: password used for ssh authentication\n        :type address: str\n        :param address: remote server address\n        :type port: int\n        :param port: remote server port\n        \"\"\"\n        ssh.connect(username=username,\n                    password=password,\n                    hostname=address,\n                    port=port,\n                    sock=sock,\n                    timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_with_key(self, ssh, username, key, address, port, sock,\n                         timeout=20):\n        \"\"\"\n        Create an ssh session to a remote host with a username and rsa key\n\n        :type username: str\n        :param username: username used for ssh authentication\n        :type key: :py:class:`paramiko.key.RSAKey`\n        :param key: paramiko rsa key used for ssh authentication\n        :type address: str\n        :param address: remote server address\n        :type port: int\n        :param port: remote server port\n        \"\"\"\n        ssh.connect(hostname=address,\n                    port=port,\n                    username=username,\n                    pkey=key,\n                    sock=sock,\n                    timeout=timeout)", "response": "Connect to a remote host with a username and rsa key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes command on remote hosts and returns a dictionary of stdout and stderr", "response": "def execute(self, command):\n        \"\"\"\n        Executes command on remote hosts\n\n        :type command: str\n        :param command: command to be run on remote host\n        \"\"\"\n        try:\n            if self.ssh.get_transport() is not None:\n                logger.debug('{0}: executing \"{1}\"'.format(self.target_address,\n                                                           command))\n                stdin, stdout, stderr = self.ssh.exec_command(command)\n                return dict(zip(['stdin', 'stdout', 'stderr'],\n                                [stdin, stdout, stderr]))\n            else:\n                raise SSHConnectionError(self.target_address,\n                                         \"ssh transport is closed\")\n        except (AuthenticationException, SSHException,\n                ChannelException, SocketError) as ex:\n            logger.critical((\"{0} execution failed on {1} with exception:\"\n                             \"{2}\".format(command, self.target_address,\n                                               ex)))\n            raise SSHCommandError(self.target_address, command, ex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes command on remote hosts without blocking", "response": "def execute_async(self, command, callback=None):\n        \"\"\"\n        Executes command on remote hosts without blocking\n\n        :type command: str\n        :param command: command to be run on remote host\n        :type callback: function\n        :param callback: function to call when execution completes\n        \"\"\"\n        try:\n            logger.debug(('{0}: execute async \"{1}\"'\n                          'with callback {2}'.format(self.target_address,\n                                                     command,\n                                                     callback)))\n            future = self.executor.submit(self.execute, command)\n            if callback is not None:\n                future.add_done_callback(callback)\n            return future\n        except (AuthenticationException, SSHException,\n                ChannelException, SocketError) as ex:\n            logger.critical((\"{0} execution failed on {1} with exception:\"\n                             \"{2}\".format(command, self.target_address,\n                                               ex)))\n            raise SSHCommandError(self.target_address, command, ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(self, stream, encoding='utf-8'):\n        data = stream.read().decode(encoding).strip(\"\\n\")\n        if data != \"\":\n            logger.debug(('{0}: decoded \"{1}\" with encoding '\n                          '{2}'.format(self.target_address, data, encoding)))\n        return data", "response": "Decode the string from the paramiko stream into a string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload a file from the local filesystem to the remote host", "response": "def upload_file(self, local_path, remote_path):\n        \"\"\"\n        Upload a file from the local filesystem to the remote host\n\n        :type local_path: str\n        :param local_path: path of local file to upload\n        :type remote_path: str\n        :param remote_path: destination path of upload on remote host\n        \"\"\"\n        logger.debug(\"{0}: uploading {1} to {0}:{2}\".format(self.target_address,\n                                                            local_path,\n                                                            remote_path))\n        try:\n            sftp = paramiko.SFTPClient.from_transport(self.transport())\n            sftp.put(local_path, remote_path)\n            sftp.close()\n        except SSHException as ex:\n            logger.warn((\"{0}: LiME module upload failed with exception:\"\n                         \"{1}\".format(self.target_address, ex)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cleanup(self):\n        for future in self.futures:\n            future.cancel()\n        self.executor.shutdown(wait=10)\n        if self.ssh.get_transport() != None:\n            self.ssh.close()", "response": "Clean up resources used during shell execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses command line arguments and return a list of arguments object", "response": "def parse_args(self, args):\n        \"\"\"\n        Parse arguments and return an arguments object\n\n            >>> from margaritashotgun.cli import Cli\n            >>> cli = CLi()\n            >>> cli.parse_args(sys.argv[1:])\n\n        :type args: list\n        :param args: list of arguments\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description='Remote memory aquisition wrapper for LiME')\n\n        root = parser.add_mutually_exclusive_group(required=True)\n        root.add_argument('-c', '--config', help='path to config.yml')\n        root.add_argument('--server',\n                          help='hostname or ip of target server')\n        root.add_argument('--version', action='version',\n                          version=\"%(prog)s {ver}\".format(ver=__version__))\n\n        opts = parser.add_argument_group()\n        opts.add_argument('--port', help='ssh port on remote server')\n        opts.add_argument('--username',\n                          help='username for ssh connection to target server')\n        opts.add_argument('--module',\n                          help='path to kernel lime kernel module')\n        opts.add_argument('--password',\n                          help='password for user or encrypted keyfile')\n        opts.add_argument('--key',\n                          help='path to rsa key for ssh connection')\n        opts.add_argument('--jump-server',\n                          help='hostname or ip of jump server')\n        opts.add_argument('--jump-port',\n                          help='ssh port on jump server')\n        opts.add_argument('--jump-username',\n                          help='username for ssh connection to jump server')\n        opts.add_argument('--jump-password',\n                          help='password for jump-user or encrypted keyfile')\n        opts.add_argument('--jump-key',\n                          help='path to rsa key for ssh connection to jump server')\n        opts.add_argument('--filename',\n                          help='memory dump filename')\n        opts.add_argument('--repository', action='store_true',\n                          help='enable automatic kernel module downloads')\n        opts.add_argument('--repository-url',\n                          help='kernel module repository url')\n        opts.add_argument('--repository-manifest',\n                          help='specify alternate repository manifest')\n        opts.add_argument('--gpg-no-verify', dest='gpg_verify',\n                          action='store_false',\n                          help='skip lime module gpg signature check')\n        opts.add_argument('--workers', default=1,\n                          help=('number of workers to run in parallel,'\n                                'default: auto acceptable values are'\n                                '(INTEGER | \"auto\")'))\n        opts.add_argument('--verbose', action='store_true',\n                          help='log debug messages')\n        opts.set_defaults(repository_manifest='primary')\n        opts.set_defaults(gpg_verify=True)\n\n        output = parser.add_mutually_exclusive_group(required=False)\n        output.add_argument('--bucket',\n                            help='memory dump output bucket')\n        output.add_argument('--output-dir',\n                            help='memory dump output directory')\n\n        log = parser.add_argument_group()\n        log.add_argument('--log-dir',\n                         help='log directory')\n        log.add_argument('--log-prefix',\n                         help='log file prefix')\n        return parser.parse_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure(self, arguments=None, config=None):\n\n        if arguments is not None:\n            args_config = self.configure_args(arguments)\n            base_config = copy.deepcopy(default_config)\n            working_config = self.merge_config(base_config, args_config)\n        if config is not None:\n            self.validate_config(config)\n            base_config = copy.deepcopy(default_config)\n            working_config = self.merge_config(base_config, config)\n\n        # override configuration with environment variables\n        repo = self.get_env_default('LIME_REPOSITORY', 'disabled')\n        repo_url = self.get_env_default('LIME_REPOSITORY_URL',\n                                    working_config['repository']['url'])\n        if repo.lower() == 'enabled':\n            working_config['repository']['enabled'] = True\n\n        working_config['repository']['url'] = repo_url\n\n        return working_config", "response": "Merge command line arguments config files and default configs and validate the configuration"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches environment variables returning a default if not found", "response": "def get_env_default(self, variable, default):\n        \"\"\"\n        Fetch environment variables, returning a default if not found\n        \"\"\"\n        if variable in os.environ:\n            env_var = os.environ[variable]\n        else:\n            env_var = default\n        return env_var"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure_args(self, arguments):\n\n        module, key, config_path = self.check_file_paths(arguments.module,\n                                                         arguments.key,\n                                                         arguments.config)\n        log_dir = self.check_directory_paths(arguments.log_dir)\n\n        if arguments.repository_url is None:\n            url = default_config['repository']['url']\n        else:\n            url = arguments.repository_url\n\n        args_config = dict(aws=dict(bucket=arguments.bucket),\n                           logging=dict(dir=arguments.log_dir,\n                                        prefix=arguments.log_prefix),\n                           workers=arguments.workers,\n                           repository=dict(enabled=arguments.repository,\n                                           url=url,\n                                           manifest=arguments.repository_manifest,\n                                           gpg_verify=arguments.gpg_verify))\n\n        if arguments.server is not None:\n\n            jump_host = None\n            if arguments.jump_server is not None:\n                if arguments.jump_port is not None:\n                    jump_port = int(arguments.jump_port)\n                else:\n                    jump_port = None\n                jump_host = dict(zip(jump_host_allowed_keys,\n                                     [arguments.jump_server,\n                                      jump_port,\n                                      arguments.jump_username,\n                                      arguments.jump_password,\n                                      arguments.jump_key]))\n\n            if arguments.port is not None:\n                port = int(arguments.port)\n            else:\n                port = None\n            host = dict(zip(host_allowed_keys,\n                            [arguments.server, port, arguments.username,\n                             arguments.password, module, key,\n                             arguments.filename, jump_host]))\n            args_config['hosts'] = []\n            args_config['hosts'].append(host)\n\n        if config_path is not None:\n            try:\n                config = self.load_config(config_path)\n                self.validate_config(config)\n                args_config.update(config)\n            except YAMLError as ex:\n                logger.warn('Invalid yaml Format: {0}'.format(ex))\n                raise\n            except InvalidConfigurationError as ex:\n                logger.warn(ex)\n                raise\n\n        return args_config", "response": "Configure the configuration of a new instance of a new instance of a new class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_file_paths(self, *args):\n        for path in enumerate(args):\n            path = path[1]\n            if path is not None:\n                try:\n                    self.check_file_path(path)\n                except OSError as ex:\n                    logger.warn(ex)\n                    raise\n        return args", "response": "Checks that all arguments correspond to a file in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that the file exists at the provided path.", "response": "def check_file_path(self, path):\n        \"\"\"\n        Ensure file exists at the provided path\n\n        :type path: string\n        :param path: path to directory to check\n        \"\"\"\n        if os.path.exists(path) is not True:\n            msg = \"File Not Found {}\".format(path)\n            raise OSError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that all arguments correspond to directories", "response": "def check_directory_paths(self, *args):\n        \"\"\"\n        Ensure all arguments correspond to directories\n        \"\"\"\n        for path in enumerate(args):\n            path = path[1]\n            if path is not None:\n                try:\n                    self.check_directory_path(path)\n                except OSError as ex:\n                    logger.warn(ex)\n                    raise\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the directory exists at the provided path.", "response": "def check_directory_path(self, path):\n        \"\"\"\n        Ensure directory exists at the provided path\n\n        :type path: string\n        :param path: path to directory to check\n        \"\"\"\n        if os.path.isdir(path) is not True:\n            msg = \"Directory Does Not Exist {}\".format(path)\n            raise OSError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_config(self, config):\n\n        try:\n            hosts = config['hosts']\n        except KeyError:\n            raise InvalidConfigurationError('hosts', \"\",\n                                            reason=('hosts configuration '\n                                                    'section is required'))\n\n        for key in config.keys():\n            if key not in default_allowed_keys:\n                raise InvalidConfigurationError(key, config[key])\n\n        bucket = False\n        # optional configuration\n        try:\n            for key in config['aws'].keys():\n                if key == 'bucket' and config['aws'][key] is not None:\n                    bucket = True\n                if key not in aws_allowed_keys:\n                    raise InvalidConfigurationError(key, config['aws'][key])\n        except KeyError:\n            pass\n\n        # optional configuration\n        try:\n            for key in config['logging'].keys():\n                if key not in logging_allowed_keys:\n                    raise InvalidConfigurationError(key, config['logging'][key])\n        except KeyError:\n            pass\n\n        # optional configuration\n        try:\n            for key in config['repository'].keys():\n                if key not in repository_allowed_keys:\n                    raise InvalidConfigurationError(key, config['repository'][key])\n        except KeyError:\n            pass\n\n        # required configuration\n        if type(config['hosts']) is not list:\n            raise InvalidConfigurationError('hosts', config['hosts'],\n                                            reason=\"hosts must be a list\")\n        filename = False\n        for host in config['hosts']:\n            for key in host.keys():\n                if key == 'filename' and host['filename'] is not None:\n                    filename = True\n                if key == 'jump_host' and host['jump_host'] is not None:\n                    for jump_key in host['jump_host'].keys():\n                        if jump_key not in jump_host_allowed_keys:\n                            raise InvalidConfigurationError(key, host['jump_host'])\n                if key not in host_allowed_keys:\n                    raise InvalidConfigurationError(key, host[key])\n\n        if bucket and filename:\n            raise InvalidConfigurationError('bucket', config['aws']['bucket'],\n                                            reason=('bucket configuration is'\n                                                    'incompatible with filename'\n                                                    'configuration in hosts'))", "response": "Validate configuration dict keys are supported\n\n        :type config: dict\n        :param config: configuration dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_key(self, key_path, password):\n\n        try:\n            return paramiko.RSAKey.from_private_key_file(key_path)\n        except PasswordRequiredException as ex:\n            return paramiko.RSAKey.from_private_key_file(key_path,\n                                                         password=password)", "response": "Loads the key from the file specified by key_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        logger = logging.getLogger(__name__)\n        try:\n            # Check repository GPG settings before starting workers\n            # Handling this here prevents subprocesses from needing stdin access\n            repo_conf = self.config['repository']\n            repo = None\n            if repo_conf['enabled'] and repo_conf['gpg_verify']:\n                try:\n                    repo = Repository(repo_conf['url'],\n                                      repo_conf['gpg_verify'])\n                    repo.init_gpg()\n                except Exception as ex:\n                    # Do not prompt to install gpg keys unless running interactively\n                    if repo is not None and self.library is False:\n                        if isinstance(ex, RepositoryUntrustedSigningKeyError):\n                            installed = repo.prompt_for_install()\n                            if installed is False:\n                                logger.critical((\"repository signature not \"\n                                                 \"installed, install the \"\n                                                 \"signature manually or use \"\n                                                 \"the --gpg-no-verify flag \"\n                                                 \"to bypass this check\"))\n                                quit(1)\n                    else:\n                        logger.critical(ex)\n                        quit(1)\n\n            conf = self.map_config()\n            workers = Workers(conf, self.config['workers'], name=self.name, library=self.library)\n            description = 'memory capture action'\n            results = workers.spawn(description)\n\n            self.statistics(results)\n            if self.library is True:\n                return dict([('total', self.total),\n                             ('completed', self.completed_addresses),\n                             ('failed', self.failed_addresses)])\n            else:\n                logger.info((\"{0} hosts processed. completed: {1} \"\n                             \"failed {2}\".format(self.total, self.completed,\n                                                 self.failed)))\n                logger.info(\"completed_hosts: {0}\".format(self.completed_addresses))\n                logger.info(\"failed_hosts: {0}\".format(self.failed_addresses))\n                quit()\n        except KeyboardInterrupt:\n            workers.cleanup(terminate=True)\n            if self.library:\n                raise\n            else:\n                quit(1)", "response": "Runs memory capture action."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef capture(self, tunnel_addr, tunnel_port, filename=None,\n                bucket=None, destination=None):\n        \"\"\"\n        Captures memory based on the provided OutputDestination\n\n        :type tunnel_addr: str\n        :param tunnel_port: ssh tunnel hostname or ip\n        :type tunnel_port: int\n        :param tunnel_port: ssh tunnel port\n        :type filename: str\n        :param filename: memory dump output filename\n        :type bucket: str\n        :param bucket: output s3 bucket\n        :type destination: :py:class:`margaritashotgun.memory.OutputDestinations`\n        :param destination: OutputDestinations member\n        \"\"\"\n        if filename is None:\n            raise MemoryCaptureAttributeMissingError('filename')\n        if destination == OutputDestinations.local:\n            logger.info(\"{0}: dumping to file://{1}\".format(self.remote_addr,\n                                                            filename))\n            result = self.to_file(filename, tunnel_addr, tunnel_port)\n        elif destination == OutputDestinations.s3:\n            if bucket is None:\n                raise MemoryCaptureAttributeMissingError('bucket')\n            logger.info((\"{0}: dumping memory to s3://{1}/\"\n                         \"{2}\".format(self.remote_addr, bucket, filename)))\n            result = self.to_s3(bucket, filename, tunnel_addr, tunnel_port)\n        else:\n            raise MemoryCaptureOutputMissingError(self.remote_addr)\n\n        return result", "response": "Captures memory based on the provided OutputDestination."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites memory dump to a local file.", "response": "def to_file(self, filename, tunnel_addr, tunnel_port):\n        \"\"\"\n        Writes memory dump to a local file\n\n        :type filename: str\n        :param filename: memory dump output filename\n        :type tunnel_addr: str\n        :param tunnel_port: ssh tunnel hostname or ip\n        :type tunnel_port: int\n        :param tunnel_port: ssh tunnel port\n        \"\"\"\n        if self.progressbar:\n            self.bar = ProgressBar(widgets=self.widgets,\n                                   maxval=self.max_size).start()\n            self.bar.start()\n\n        with open(filename, 'wb') as self.outfile:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.sock.connect((tunnel_addr, tunnel_port))\n            self.sock.settimeout(self.sock_timeout)\n            bytes_since_update = 0\n            while True:\n                try:\n                    data = self.sock.recv(self.recv_size)\n                    data_length = len(data)\n                    if not data:\n                        break\n                    self.outfile.write(data)\n                    self.transfered = self.transfered + data_length\n                    bytes_since_update +=  data_length\n                    data = None\n                    data_length = 0\n                    if bytes_since_update > self.update_threshold:\n                        self.update_progress()\n                        bytes_since_update = 0\n\n                except (socket.timeout, socket.error) as ex:\n                    if isinstance(ex, socket.timeout):\n                        break\n                    elif isinstance(ex, socket.error):\n                        if ex.errno == errno.EINTR:\n                            pass\n                        else:\n                            self.cleanup()\n                            raise\n                    else:\n                        self.cleanup()\n                        raise\n\n        self.cleanup()\n        logger.info('{0}: capture complete: {1}'.format(self.remote_addr,\n                                                        filename))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_progress(self, complete=False):\n        if self.progressbar:\n            try:\n                self.bar.update(self.transfered)\n            except Exception as e:\n                logger.debug(\"{0}: {1}, {2} exceeds memsize {3}\".format(\n                                 self.remote_addr,\n                                 e,\n                                 self.transfered,\n                                 self.max_size))\n            if complete:\n                self.bar.update(self.max_size)\n                self.bar.finish()\n        else:\n            percent = int(100 * float(self.transfered) / float(self.max_size))\n            # printe a message at 10%, 20%, etc...\n            if percent % 10 == 0:\n                if self.progress != percent:\n                    logger.info(\"{0}: capture {1}% complete\".format(\n                                self.remote_addr, percent))\n                    self.progress = percent", "response": "Update the progress of the ncurses capture."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup(self):\n        if self.sock is not None:\n            self.sock.close()\n        if self.outfile is not None:\n            self.outfile.close()\n        if self.bar is not None:\n            self.update_progress(complete=True)", "response": "Cleans up resources used during memory capture."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the GPG object and check if the repository signing key is trusted", "response": "def init_gpg(self):\n        \"\"\"\n        Initialize gpg object and check if repository signing key is trusted\n        \"\"\"\n        if self.gpg_verify:\n            logger.debug(\"gpg verification enabled, initializing gpg\")\n            gpg_home = os.path.expanduser('~/.gnupg')\n            self.gpg = gnupg.GPG(gnupghome=gpg_home)\n            self.key_path, self.key_info = self.get_signing_key()\n            logger.debug(\"{0} {1}\".format(self.key_path, self.key_info))\n            self.check_signing_key()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_signing_key(self):\n\n        \"\"\"\n        Download a local copy of repo signing key key metadata.\n        Fixes #17 Scan Keys no available in all GPG versions.\n        \"\"\"\n        tmp_key_path = \"/tmp/{0}\".format(self.repo_signing_key)\n        tmp_metadata_path = \"/tmp/{0}\".format(self.key_metadata)\n\n        repo_key_path = \"{0}/{1}\".format(self.url, self.repo_signing_key)\n        repo_metadata_path = \"{0}/{1}\".format(self.url, self.key_metadata)\n\n\n        req_key = requests.get(repo_key_path)\n        req_metadata = requests.get(repo_metadata_path)\n\n        # Fetch the key to disk\n        if req_key.status_code is 200:\n            logger.debug((\"found repository signing key at \"\n                          \"{0}\".format(repo_key_path)))\n            self.raw_key = req_key.content\n            with open(tmp_key_path, 'wb') as f:\n                f.write(self.raw_key)\n        else:\n            raise RepositoryMissingSigningKeyError(repo_key_path)\n\n        # Fetch the fingerprint from the metadata\n        if req_metadata.status_code is 200:\n            logger.debug((\"found key metadata at \"\n                          \"{0}\".format(repo_metadata_path)))\n            print(req_metadata.content)\n            key_info = json.loads(req_metadata.content.decode('utf-8'))\n        else:\n            RepositoryMissingKeyMetadataError\n\n        return (tmp_key_path, key_info)", "response": "Download a local copy of repo signing key for installation and return the path and the key info."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_signing_key(self):\n        user_keys = self.gpg.list_keys()\n        if len(user_keys) > 0:\n            trusted = False\n            for key in user_keys:\n                if key['fingerprint'] == self.key_info['fingerprint']:\n                    trusted = True\n                    logger.debug((\"repo signing key trusted in user keyring, \"\n                                  \"fingerprint {0}\".format(key['fingerprint'])))\n        else:\n            trusted = False\n        if trusted is False:\n            repo_key_url = \"{0}/{1}\".format(self.url, self.repo_signing_key)\n            raise RepositoryUntrustedSigningKeyError(repo_key_url,\n                                                     self.key_info['fingerprint'])", "response": "Check that repo signing key is trusted by gpg keychain"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prompt_for_install(self):\n        print(self.key_info)\n        repo_key_url = \"{0}/{1}\".format(self.url, self.repo_signing_key)\n        print((\"warning: Repository key untrusted \\n\"\n               \"Importing GPG key 0x{0}:\\n\"\n               \"  Userid: \\\"{1}\\\"\\n\"\n               \"  From  : {2}\".format(self.key_info['fingerprint'],\n                                      self.key_info['uids'][0],\n                                      repo_key_url)))\n        response = prompt(u'Is this ok: [y/N] ')\n        if response == 'y':\n            self.install_key(self.raw_key)\n            return True\n        else:\n            return False", "response": "Prompt user to install untrusted GPG key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_key(self, key_data):\n        logger.info((\"importing repository signing key {0} \"\n                     \"{1}\".format(self.key_info['fingerprint'],\n                                  self.key_info['uids'][0])))\n        import_result = self.gpg.import_keys(key_data)\n        logger.debug(\"import results: {0}\".format(import_result.results))", "response": "Install untrusted repo signing key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching repository for kernel module matching kernel_version", "response": "def fetch(self, kernel_version, manifest_type):\n        \"\"\"\n        Search repository for kernel module matching kernel_version\n\n        :type kernel_version: str\n        :param kernel_version: kernel version to search repository on\n        :type manifest_type: str\n        :param manifest_type: kernel module manifest to search on\n        \"\"\"\n        metadata = self.get_metadata()\n        logger.debug(\"parsed metadata: {0}\".format(metadata))\n        manifest = self.get_manifest(metadata['manifests'][manifest_type])\n\n        try:\n            module = manifest[kernel_version]\n            logger.debug(\"found module {0}\".format(module))\n        except KeyError:\n            raise KernelModuleNotFoundError(kernel_version, self.url)\n        path = self.fetch_module(module)\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_metadata(self):\n        metadata_path = \"{}/{}/{}\".format(self.url,\n                                          self.metadata_dir,\n                                          self.metadata_file)\n        metadata_sig_path = \"{}/{}/{}.sig\".format(self.url.rstrip('/'),\n                                                  self.metadata_dir,\n                                                  self.metadata_file)\n        # load metadata\n        req = requests.get(metadata_path)\n        if req.status_code is 200:\n            raw_metadata = req.content\n        else:\n            raise RepositoryError(metadata_path, (\"status code not 200: \"\n                                                  \"{}\".format(req.status_code)))\n\n        if self.gpg_verify:\n            self.verify_data_signature(metadata_sig_path, metadata_path,\n                                       raw_metadata)\n\n        return self.parse_metadata(raw_metadata)", "response": "Fetch repository repomd. xml file and parse it into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_metadata(self, metadata_xml):\n        try:\n            metadata = dict()\n            mdata = xmltodict.parse(metadata_xml)['metadata']\n            metadata['revision'] = mdata['revision']\n            metadata['manifests'] = dict()\n\n            # check if multiple manifests are present\n            if type(mdata['data']) is list:\n                manifests = mdata['data']\n            else:\n                manifests = [mdata['data']]\n\n            for manifest in manifests:\n                manifest_dict = dict()\n                manifest_dict['type'] = manifest['@type']\n                manifest_dict['checksum'] = manifest['checksum']\n                manifest_dict['open_checksum'] = manifest['open_checksum']\n                manifest_dict['location'] = manifest['location']['@href']\n                manifest_dict['timestamp'] = datetime.fromtimestamp(\n                                                 int(manifest['timestamp']))\n                manifest_dict['size'] = int(manifest['size'])\n                manifest_dict['open_size'] = int(manifest['open_size'])\n                metadata['manifests'][manifest['@type']] = manifest_dict\n\n        except Exception as e:\n            raise RepositoryError(\"{0}/{1}\".format(self.url,self.metadata_dir,\n                                                   self.metadata_file), e)\n\n        return metadata", "response": "Parse repomd. xml file and return dict of metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets latest manifest as specified in repomd. xml", "response": "def get_manifest(self, metadata):\n        \"\"\"\n        Get latest manifest as specified in repomd.xml\n\n        :type metadata: dict\n        :param metadata: dictionary representation of repomd.xml\n        \"\"\"\n        manifest_path = \"{0}/{1}\".format(self.url, metadata['location'])\n        req = requests.get(manifest_path, stream=True)\n        if req.status_code is 200:\n            gz_manifest = req.raw.read()\n\n        self.verify_checksum(gz_manifest, metadata['checksum'],\n                             metadata['location'])\n        manifest = self.unzip_manifest(gz_manifest)\n        self.verify_checksum(manifest, metadata['open_checksum'],\n                             metadata['location'].rstrip('.gz'))\n\n        return self.parse_manifest(manifest)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecompress gzip encoded manifest", "response": "def unzip_manifest(self, raw_manifest):\n        \"\"\"\n        Decompress gzip encoded manifest\n\n        :type raw_manifest: str\n        :param raw_manifest: compressed gzip manifest file content\n        \"\"\"\n        buf = BytesIO(raw_manifest)\n        f = gzip.GzipFile(fileobj=buf)\n        manifest = f.read()\n\n        return manifest"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse manifest xml file and return dict of all the modules", "response": "def parse_manifest(self, manifest_xml):\n        \"\"\"\n        Parse manifest xml file\n\n        :type manifest_xml: str\n        :param manifest_xml: raw xml content of manifest file\n        \"\"\"\n\n        manifest = dict()\n        try:\n            mdata = xmltodict.parse(manifest_xml)['modules']['module']\n            for module in mdata:\n                mod = dict()\n                mod['type'] = module['@type']\n                mod['name'] = module['name']\n                mod['arch'] = module['arch']\n                mod['checksum'] = module['checksum']\n                mod['version'] = module['version']\n                mod['packager'] = module['packager']\n                mod['location'] = module['location']['@href']\n                mod['signature'] = module['signature']['@href']\n                mod['platform'] = module['platform']\n                manifest[mod['version']] = mod\n\n        except Exception as e:\n            raise\n\n        return manifest"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads and verify kernel module", "response": "def fetch_module(self, module):\n        \"\"\"\n        Download and verify kernel module\n\n        :type module: str\n        :param module: kernel module path\n        \"\"\"\n        tm = int(time.time())\n        datestamp = datetime.utcfromtimestamp(tm).isoformat()\n        filename = \"lime-{0}-{1}.ko\".format(datestamp, module['version'])\n        url = \"{0}/{1}\".format(self.url, module['location'])\n        logger.info(\"downloading {0} as {1}\".format(url, filename))\n        req = requests.get(url, stream=True)\n\n        with open(filename, 'wb') as f:\n            f.write(req.raw.read())\n\n        self.verify_module(filename, module, self.gpg_verify)\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_module(self, filename, module, verify_signature):\n        with open(filename, 'rb') as f:\n            module_data = f.read()\n        self.verify_checksum(module_data, module['checksum'],\n                             module['location'])\n\n        if self.gpg_verify:\n            signature_url = \"{0}/{1}\".format(self.url, module['signature'])\n            file_url = \"{0}/{1}\".format(self.url, module['location'])\n            self.verify_file_signature(signature_url, file_url, filename)", "response": "Verify the checksum and signature of a kernel module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies sha256 checksum vs calculated checksum of data and filename", "response": "def verify_checksum(self, data, checksum, filename):\n        \"\"\"\n        Verify sha256 checksum vs calculated checksum\n\n        :type data: str\n        :param data: data used to calculate checksum\n        :type checksum: str\n        :param checksum: expected checksum of data\n        :type filename: str\n        :param checksum: original filename\n        \"\"\"\n        calculated_checksum = hashlib.sha256(data).hexdigest()\n        logger.debug(\"calculated checksum {0} for {1}\".format(calculated_checksum,\n                                                              filename))\n        if calculated_checksum != checksum:\n            raise RepositoryError(\"{0}/{1}\".format(self.url, filename),\n                                  (\"checksum verification failed, expected \"\n                                   \"{0} got {1}\".format(checksum,\n                                                        calculated_checksum)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_data_signature(self, signature_url, data_url, data):\n\n        req = requests.get(signature_url)\n        if req.status_code is 200:\n            tm = int(time.time())\n            datestamp = datetime.utcfromtimestamp(tm).isoformat()\n            sigfile = \"repo-{0}-tmp.sig\".format(datestamp)\n            logger.debug(\"writing {0} to {1}\".format(signature_url, sigfile))\n            with open(sigfile, 'wb') as f:\n                f.write(req.content)\n        else:\n            raise RepositoryMissingSignatureError(signature_url)\n\n        verified = self.gpg.verify_data(sigfile, data)\n        try:\n            os.remove(sigfile)\n        except OSError:\n            pass\n\n        if verified.valid is True:\n            logger.debug(\"verified {0} against {1}\".format(data_url,\n                                                           signature_url))\n        else:\n            raise RepositorySignatureError(data_url, signature_url)", "response": "Verify data against a remote signature"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_file_signature(self, signature_url, file_url, filename):\n\n        req = requests.get(signature_url, stream=True)\n        if req.status_code is 200:\n            sigfile = req.raw\n        else:\n            raise RepositoryMissingSignatureError(signature_url)\n\n        verified = self.gpg.verify_file(sigfile, filename)\n\n        if verified.valid is True:\n            logger.debug(\"verified {0} against {1}\".format(filename, signature_url))\n        else:\n            raise RepositorySignatureError(file_url, signature_url)", "response": "Verify a local file against its remote signature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnotify about a new tick event.", "response": "def _notify_new_tick_event(self, tick):\n        \"\"\"tick\u63a8\u9001\"\"\"\n        if tick.time is '':\n            return\n        event = Event(type_=EVENT_TINY_TICK)\n        event.dict_['data'] = tick\n        self._event_engine.put(event)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _notify_quote_change_event(self, tiny_quote):\n        if not self._market_opened:\n            return\n\n        event = Event(type_=EVENT_QUOTE_CHANGE)\n        event.dict_['data'] = tiny_quote\n        self._rt_tiny_quote[tiny_quote.symbol] = tiny_quote\n        self._event_engine.put(event)", "response": "Notify the event engine of a change of the quote"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unpack_rsp(cls, rsp_pb):\n        ret_type = rsp_pb.retType\n        ret_msg = rsp_pb.retMsg\n\n        if ret_type != RET_OK:\n            return RET_ERROR, ret_msg, None\n\n        res = {}\n        if rsp_pb.HasField('s2c'):\n            res['server_version'] = rsp_pb.s2c.serverVer\n            res['login_user_id'] = rsp_pb.s2c.loginUserID\n            res['conn_id'] = rsp_pb.s2c.connID\n            res['conn_key'] = rsp_pb.s2c.connAESKey\n            res['keep_alive_interval'] = rsp_pb.s2c.keepAliveInterval\n        else:\n            return RET_ERROR, \"rsp_pb error\", None\n\n        return RET_OK, \"\", res", "response": "Unpack the init connect response from a server response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        ret_type = rsp_pb.retType\n        ret_msg = rsp_pb.retMsg\n\n        if ret_type != RET_OK:\n            return RET_ERROR, ret_msg, None\n\n        raw_snapshot_list = rsp_pb.s2c.snapshotList\n\n        snapshot_list = []\n        for record in raw_snapshot_list:\n            snapshot_tmp = {}\n            snapshot_tmp['code'] = merge_qot_mkt_stock_str(\n                int(record.basic.security.market), record.basic.security.code)\n            snapshot_tmp['update_time'] = record.basic.updateTime\n            snapshot_tmp['last_price'] = record.basic.curPrice\n            snapshot_tmp['open_price'] = record.basic.openPrice\n            snapshot_tmp['high_price'] = record.basic.highPrice\n            snapshot_tmp['low_price'] = record.basic.lowPrice\n            snapshot_tmp['prev_close_price'] = record.basic.lastClosePrice\n            snapshot_tmp['volume'] = record.basic.volume\n            snapshot_tmp['turnover'] = record.basic.turnover\n            snapshot_tmp['turnover_rate'] = record.basic.turnoverRate\n            snapshot_tmp['suspension'] = record.basic.isSuspend\n            snapshot_tmp['listing_date'] = \"N/A\" if record.HasField('optionExData') else record.basic.listTime\n            snapshot_tmp['price_spread'] = record.basic.priceSpread\n            snapshot_tmp['lot_size'] = record.basic.lotSize\n\n            snapshot_tmp['equity_valid'] = False\n            # equityExData\n            if record.HasField('equityExData'):\n                snapshot_tmp['equity_valid'] = True\n                snapshot_tmp[\n                    'issued_shares'] = record.equityExData.issuedShares\n                snapshot_tmp[\n                    'total_market_val'] = record.equityExData.issuedMarketVal\n                snapshot_tmp['net_asset'] = record.equityExData.netAsset\n                snapshot_tmp['net_profit'] = record.equityExData.netProfit\n                snapshot_tmp[\n                    'earning_per_share'] = record.equityExData.earningsPershare\n                snapshot_tmp[\n                    'outstanding_shares'] = record.equityExData.outstandingShares\n                snapshot_tmp[\n                    'circular_market_val'] = record.equityExData.outstandingMarketVal\n                snapshot_tmp[\n                    'net_asset_per_share'] = record.equityExData.netAssetPershare\n                snapshot_tmp['ey_ratio'] = record.equityExData.eyRate\n                snapshot_tmp['pe_ratio'] = record.equityExData.peRate\n                snapshot_tmp['pb_ratio'] = record.equityExData.pbRate\n                snapshot_tmp['pe_ttm_ratio'] = record.equityExData.peTTMRate\n\n            snapshot_tmp['wrt_valid'] = False\n            if record.basic.type == SEC_TYPE_MAP[SecurityType.WARRANT]:\n                snapshot_tmp['wrt_valid'] = True\n                snapshot_tmp[\n                    'wrt_conversion_ratio'] = record.warrantExData.conversionRate\n                snapshot_tmp['wrt_type'] = QUOTE.REV_WRT_TYPE_MAP[\n                    record.warrantExData.warrantType]\n                snapshot_tmp[\n                    'wrt_strike_price'] = record.warrantExData.strikePrice\n                snapshot_tmp[\n                    'wrt_maturity_date'] = record.warrantExData.maturityTime\n                snapshot_tmp[\n                    'wrt_end_trade'] = record.warrantExData.endTradeTime\n                snapshot_tmp['stock_owner'] = merge_qot_mkt_stock_str(\n                    record.warrantExData.owner.market,\n                    record.warrantExData.owner.code)\n                snapshot_tmp[\n                    'wrt_recovery_price'] = record.warrantExData.recoveryPrice\n                snapshot_tmp[\n                    'wrt_street_vol'] = record.warrantExData.streetVolumn\n                snapshot_tmp[\n                    'wrt_issue_vol'] = record.warrantExData.issueVolumn\n                snapshot_tmp[\n                    'wrt_street_ratio'] = record.warrantExData.streetRate\n                snapshot_tmp['wrt_delta'] = record.warrantExData.delta\n                snapshot_tmp[\n                    'wrt_implied_volatility'] = record.warrantExData.impliedVolatility\n                snapshot_tmp['wrt_premium'] = record.warrantExData.premium\n\n            snapshot_tmp['option_valid'] = False\n            if record.basic.type == SEC_TYPE_MAP[SecurityType.DRVT]:\n                snapshot_tmp['option_valid'] = True\n                snapshot_tmp[\n                    'option_type'] = QUOTE.REV_OPTION_TYPE_CLASS_MAP[record.optionExData.type]\n                snapshot_tmp['stock_owner'] = merge_qot_mkt_stock_str(\n                    record.optionExData.owner.market, record.optionExData.owner.code)\n                snapshot_tmp[\n                    'strike_time'] = record.optionExData.strikeTime\n                snapshot_tmp[\n                    'option_strike_price'] = record.optionExData.strikePrice\n                snapshot_tmp[\n                    'option_contract_size'] = record.optionExData.contractSize\n                snapshot_tmp[\n                    'option_open_interest'] = record.optionExData.openInterest\n                snapshot_tmp['option_implied_volatility'] = record.optionExData.impliedVolatility\n                snapshot_tmp[\n                    'option_premium'] = record.optionExData.premium\n                snapshot_tmp[\n                    'option_delta'] = record.optionExData.delta\n                snapshot_tmp[\n                    'option_gamma'] = record.optionExData.gamma\n                snapshot_tmp[\n                    'option_vega'] = record.optionExData.vega\n                snapshot_tmp['option_theta'] = record.optionExData.theta\n                snapshot_tmp['option_rho'] = record.optionExData.rho\n            else:\n                pass\n            snapshot_list.append(snapshot_tmp)\n\n        return RET_OK, \"\", snapshot_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nunpacks the un - subscribed response", "response": "def unpack_unsubscribe_rsp(cls, rsp_pb):\n        \"\"\"Unpack the un-subscribed response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        return RET_OK, \"\", None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getJsonPath(name, moduleFile):\n    currentFolder = os.getcwd()\n    currentJsonPath = os.path.join(currentFolder, name)\n    if os.path.isfile(currentJsonPath):\n        return currentJsonPath\n    else:\n        moduleFolder = os.path.abspath(os.path.dirname(moduleFile))\n        moduleJsonPath = os.path.join(moduleFolder, '.', name)\n        return moduleJsonPath", "response": "getJsonPath - Get the path to the JSON file for the given name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplace a buy order", "response": "def buy(self, price, volume, symbol, order_type=ft.OrderType.NORMAL, adjust_limit=0, acc_id=0):\n        \"\"\"\u4e70\u5165\"\"\"\n        ret, data = self._trade_ctx.place_order(price=price, qty=volume, code=symbol, trd_side=ft.TrdSide.BUY,\n                                                order_type=order_type, adjust_limit=adjust_limit,\n                                                trd_env=self._env_type, acc_id=acc_id)\n        if ret != ft.RET_OK:\n            return ret, data\n\n        order_id = 0\n        for ix, row in data.iterrows():\n            order_id = str(row['order_id'])\n\n        return ret, order_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tiny_trade_order(self, order_id, acc_id=0):\n        ret, data = self._trade_ctx.order_list_query(order_id=order_id, status_filter_list=[], code='', start='',\n                                                     end='', trd_env=self._env_type, acc_id=acc_id)\n        if ret != ft.RET_OK:\n            return ret, data\n\n        order = TinyTradeOrder()\n        for ix, row in data.iterrows():\n            if order_id != str(row['order_id']):\n                continue\n            order.symbol = row['code']\n            order.order_id = order_id\n            order.direction = row['trd_side']\n\n            order.price = float(row['price'])\n            order.total_volume = int(row['qty'])\n            order.trade_volume = int(row['dealt_qty'])\n            order.create_time = row['create_time']\n            order.updated_time = row['updated_time']\n            order.trade_avg_price = float(row['dealt_avg_price']) if row['dealt_avg_price'] else 0\n            order.order_status = row['order_status']\n            break\n        return ret, order", "response": "Get a TinyTrade Order object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting TinyPosition object for a symbol.", "response": "def get_tiny_position(self, symbol, acc_id=0):\n        \"\"\"\u5f97\u5230\u80a1\u7968\u6301\u4ed3\"\"\"\n        ret, data = self._trade_ctx.position_list_query(code=symbol, trd_env=self._env_type, acc_id=acc_id)\n        if 0 != ret:\n            return None\n\n        for _, row in data.iterrows():\n            if row['code'] != symbol:\n                continue\n            pos = TinyPosition()\n            pos.symbol = symbol\n            pos.position = row['qty']\n            pos.frozen = pos.position - row['can_sell_qty']\n            pos.price = row['cost_price']\n            pos.market_value = row['market_val']\n            return pos\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __loadSetting(self):\n        with open(self.settingfilePath, 'rb') as f:\n            df = f.read()\n            f.close()\n            if type(df) is not str:\n                df = ft.str_utf8(df)\n            self._global_settings = json.loads(df)\n            if self._global_settings is None or 'frame' not in self._global_settings:\n                raise Exception(\"setting.json - no frame config!'\")\n\n            # \u8bbe\u7f6eframe\u53c2\u6570\n            frame_setting = self._global_settings['frame']\n            d = self.__dict__\n            for key in d.keys():\n                if key in frame_setting.keys():\n                    d[key] = frame_setting[key]\n\n            # check paramlist\n            # for key in d.keys():\n            #     if d[key] is None:\n            #         str_error = \"setting.json - 'frame' config no key:'%s'\" % key\n            #         raise Exception(str_error)\n\n            # check _env_type / market\n            env_list = [ft.TrdEnv.REAL, ft.TrdEnv.SIMULATE]\n            if self._env_type not in env_list:\n                str_error = \"setting.json - 'frame' config '_env_type' can only is '{}'\".format(','.join(env_list))\n                raise Exception(str_error)\n\n            market_list = [ft.Market.HK, ft.Market.US]\n            if self._market not in market_list:\n                str_error = \"setting.json - 'frame' config '_market' can only is '{}'\".format(','.join(market_list))\n                raise Exception(str_error)\n\n        return True", "response": "load the settings from file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_client_info(cls, client_id, client_ver):\n\n        SysConfig.CLINET_ID = client_id\n        SysConfig.CLIENT_VER = client_ver", "response": "set_client_info - Set the client info for the current FutuQuant API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_api_socket_reconnected(self):\n        # auto subscriber\n        resub_count = 0\n        subtype_list = []\n        code_list = []\n\n        resub_dict = copy(self._ctx_subscribe)\n        subtype_all_cnt = len(resub_dict.keys())\n        subtype_cur_cnt = 0\n\n        ret_code = RET_OK\n        ret_msg = ''\n\n        for subtype in resub_dict.keys():\n            subtype_cur_cnt += 1\n            code_set = resub_dict[subtype]\n            code_list_new = [code for code in code_set]\n            if len(code_list_new) == 0:\n                continue\n\n            if len(code_list) == 0:\n                code_list = code_list_new\n                subtype_list = [subtype]\n\n            is_need_sub = False\n            if code_list == code_list_new:\n                if subtype not in subtype_list:\n                    subtype_list.append(subtype)   # \u5408\u5e76subtype\u8bf7\u6c42\n            else:\n                ret_code, ret_msg = self._reconnect_subscribe(code_list, subtype_list)\n                logger.debug(\"reconnect subscribe code_count={} ret_code={} ret_msg={} subtype_list={} code_list={}\".format(\n                    len(code_list), ret_code, ret_msg, subtype_list, code_list))\n                if ret_code != RET_OK:\n                    break\n\n                resub_count += len(code_list)\n                code_list = code_list_new\n                subtype_list = [subtype]\n\n            # \u5faa\u73af\u5373\u5c06\u7ed3\u675f\n            if subtype_cur_cnt == subtype_all_cnt and len(code_list):\n                ret_code, ret_msg = self._reconnect_subscribe(code_list, subtype_list)\n                logger.debug(\"reconnect subscribe code_count={} ret_code={} ret_msg={} subtype_list={} code_list={}\".format(len(code_list), ret_code, ret_msg, subtype_list, code_list))\n                if ret_code != RET_OK:\n                    break\n                resub_count += len(code_list)\n                code_list = []\n                subtype_list = []\n\n        logger.debug(\"reconnect subscribe all code_count={} ret_code={} ret_msg={}\".format(resub_count, ret_code, ret_msg))\n\n        # \u91cd\u5b9a\u9605\u5931\u8d25\uff0c\u91cd\u8fde\n        if ret_code != RET_OK:\n            logger.error(\"reconnect subscribe error, close connect and retry!!\")\n            self._status = ContextStatus.Start\n            self._wait_reconnect()\n        return ret_code, ret_msg", "response": "re - subscribe for new API socket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_stock_basicinfo(self, market, stock_type=SecurityType.STOCK, code_list=None):\n        param_table = {'market': market, 'stock_type': stock_type}\n        for x in param_table:\n            param = param_table[x]\n            if param is None or is_str(param) is False:\n                error_str = ERROR_STR_PREFIX + \"the type of %s param is wrong\" % x\n                return RET_ERROR, error_str\n\n        if code_list is not None:\n            if is_str(code_list):\n                code_list = code_list.split(',')\n            elif isinstance(code_list, list):\n                pass\n            else:\n                return RET_ERROR, \"code list must be like ['HK.00001', 'HK.00700'] or 'HK.00001,HK.00700'\"\n\n        query_processor = self._get_sync_query_processor(\n            StockBasicInfoQuery.pack_req, StockBasicInfoQuery.unpack_rsp)\n        kargs = {\n            \"market\": market,\n            'stock_type': stock_type,\n            'code_list': code_list,\n            'conn_id': self.get_sync_conn_id()\n        }\n\n        ret_code, msg, basic_info_list = query_processor(**kargs)\n        if ret_code != RET_OK:\n            return ret_code, msg\n\n        col_list = [\n            'code', 'name', 'lot_size', 'stock_type', 'stock_child_type', 'stock_owner',\n            'option_type', 'strike_time', 'strike_price', 'suspension',\n            'listing_date', 'stock_id', 'delisting'\n        ]\n\n        basic_info_table = pd.DataFrame(basic_info_list, columns=col_list)\n\n        return RET_OK, basic_info_table", "response": "get_stock_basicinfo - Returns basic info of a given stock"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_history_kline(self,\n                      code,\n                      start=None,\n                      end=None,\n                      ktype=KLType.K_DAY,\n                      autype=AuType.QFQ,\n                      fields=[KL_FIELD.ALL]):\n        \"\"\"\n            \u5f97\u5230\u672c\u5730\u5386\u53f2k\u7ebf\uff0c\u9700\u5148\u53c2\u7167\u5e2e\u52a9\u6587\u6863\u4e0b\u8f7dk\u7ebf\n\n            :param code: \u80a1\u7968\u4ee3\u7801\n            :param start: \u5f00\u59cb\u65f6\u95f4\uff0c\u4f8b\u5982'2017-06-20'\n            :param end:  \u7ed3\u675f\u65f6\u95f4\uff0c\u4f8b\u5982'2017-06-30'\n                    start\u548cend\u7684\u7ec4\u5408\u5982\u4e0b\uff1a\n                    ==========    ==========    ========================================\n                     start\u7c7b\u578b      end\u7c7b\u578b       \u8bf4\u660e\n                    ==========    ==========    ========================================\n                     str            str           start\u548cend\u5206\u522b\u4e3a\u6307\u5b9a\u7684\u65e5\u671f\n                     None           str           start\u4e3aend\u5f80\u524d365\u5929\n                     str            None          end\u4e3astart\u5f80\u540e365\u5929\n                     None           None          end\u4e3a\u5f53\u524d\u65e5\u671f\uff0cstart\u4e3aend\u5f80\u524d365\u5929\n                    ==========    ==========    ========================================\n            :param ktype: k\u7ebf\u7c7b\u578b\uff0c \u53c2\u89c1 KLType \u5b9a\u4e49\n            :param autype: \u590d\u6743\u7c7b\u578b, \u53c2\u89c1 AuType \u5b9a\u4e49\n            :param fields: \u9700\u8fd4\u56de\u7684\u5b57\u6bb5\u5217\u8868\uff0c\u53c2\u89c1 KL_FIELD \u5b9a\u4e49 KL_FIELD.ALL  KL_FIELD.OPEN ....\n            :return: (ret, data)\n\n                    ret == RET_OK \u8fd4\u56depd dataframe\u6570\u636e\uff0cdata.DataFrame\u6570\u636e, \u6570\u636e\u5217\u683c\u5f0f\u5982\u4e0b\n\n                    ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n                =================   ===========   ==============================================================================\n                \u53c2\u6570                  \u7c7b\u578b                        \u8bf4\u660e\n                =================   ===========   ==============================================================================\n                code                str            \u80a1\u7968\u4ee3\u7801\n                time_key            str            k\u7ebf\u65f6\u95f4\n                open                float          \u5f00\u76d8\u4ef7\n                close               float          \u6536\u76d8\u4ef7\n                high                float          \u6700\u9ad8\u4ef7\n                low                 float          \u6700\u4f4e\u4ef7\n                pe_ratio            float          \u5e02\u76c8\u7387\uff08\u8be5\u5b57\u6bb5\u4e3a\u6bd4\u4f8b\u5b57\u6bb5\uff0c\u9ed8\u8ba4\u4e0d\u5c55\u793a%\uff09\n                turnover_rate       float          \u6362\u624b\u7387\n                volume              int            \u6210\u4ea4\u91cf\n                turnover            float          \u6210\u4ea4\u989d\n                change_rate         float          \u6da8\u8dcc\u5e45\n                last_close          float          \u6628\u6536\u4ef7\n                =================   ===========   ==============================================================================\n\n            :example:\n\n            .. code:: python\n\n                from futuquant import *\n                quote_ctx = OpenQuoteContext(host='127.0.0.1', port=11111)\n                print(quote_ctx.get_history_kline('HK.00700', start='2017-06-20', end='2017-06-22'))\n                quote_ctx.close()\n        \"\"\"\n        return self._get_history_kline_impl(GetHistoryKlineQuery, code, start=start, end=end,\n                                            ktype=ktype, autype=autype, fields=fields)", "response": "get_history_kline - Returns a kline object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_market_snapshot(self, code_list):\n        code_list = unique_and_normalize_list(code_list)\n        if not code_list:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            MarketSnapshotQuery.pack_req, MarketSnapshotQuery.unpack_rsp)\n        kargs = {\n            \"stock_list\": code_list,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        ret_code, msg, snapshot_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        equity_col_list = ['issued_shares',\n                           'total_market_val',\n                           'net_asset',\n                           'net_profit',\n                           'earning_per_share',\n                           'outstanding_shares',\n                           'circular_market_val',\n                           'net_asset_per_share',\n                           'ey_ratio',\n                           'pe_ratio',\n                           'pb_ratio',\n                           'pe_ttm_ratio'\n                           ]\n        wrt_col_list = ['wrt_conversion_ratio',\n                        'wrt_type',\n                        'wrt_strike_price',\n                        'wrt_maturity_date',\n                        'wrt_end_trade',\n                        'wrt_recovery_price',\n                        'wrt_street_vol',\n                        'wrt_issue_vol',\n                        'wrt_street_ratio',\n                        'wrt_delta',\n                        'wrt_implied_volatility',\n                        'wrt_premium'\n                        ]\n        option_col_list = ['option_type',\n                           'strike_time',\n                           'option_strike_price',\n                           'option_contract_size',\n                           'option_open_interest',\n                           'option_implied_volatility',\n                           'option_premium',\n                           'option_delta',\n                           'option_gamma',\n                           'option_vega',\n                           'option_theta',\n                           'option_rho'\n                           ]\n        col_list = [\n            'code',\n            'update_time',\n            'last_price',\n            'open_price',\n            'high_price',\n            'low_price',\n            'prev_close_price',\n            'volume',\n            'turnover',\n            'turnover_rate',\n            'suspension',\n            'listing_date',\n            'lot_size',\n            'price_spread',\n            'stock_owner'\n        ]\n\n        col_list.append('equity_valid')\n        col_list.extend(equity_col_list)\n        col_list.append('wrt_valid')\n        col_list.extend(wrt_col_list)\n        col_list.append('option_valid')\n        col_list.extend(option_col_list)\n\n        snapshot_frame_table = pd.DataFrame(snapshot_list, columns=col_list)\n\n        return RET_OK, snapshot_frame_table", "response": "Get market snapshot from code_list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_plate_list(self, market, plate_class):\n        param_table = {'market': market, 'plate_class': plate_class}\n        for x in param_table:\n            param = param_table[x]\n            if param is None or is_str(market) is False:\n                error_str = ERROR_STR_PREFIX + \"the type of market param is wrong\"\n                return RET_ERROR, error_str\n\n        if market not in MKT_MAP:\n            error_str = ERROR_STR_PREFIX + \"the value of market param is wrong \"\n            return RET_ERROR, error_str\n\n        if plate_class not in PLATE_CLASS_MAP:\n            error_str = ERROR_STR_PREFIX + \"the class of plate is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            SubplateQuery.pack_req, SubplateQuery.unpack_rsp)\n        kargs = {\n            'market': market,\n            'plate_class': plate_class,\n            'conn_id': self.get_sync_conn_id()\n        }\n\n        ret_code, msg, subplate_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = ['code', 'plate_name', 'plate_id']\n\n        subplate_frame_table = pd.DataFrame(subplate_list, columns=col_list)\n\n        return RET_OK, subplate_frame_table", "response": "get_plate_list - Returns a pandas dataframe of all the plate_namefacts and plate_idfacts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a single stock from a single plate.", "response": "def get_plate_stock(self, plate_code):\n        \"\"\"\n        \u83b7\u53d6\u7279\u5b9a\u677f\u5757\u4e0b\u7684\u80a1\u7968\u5217\u8868\n\n        :param plate_code: \u677f\u5757\u4ee3\u7801, string, \u4f8b\u5982\uff0c\u201dSH.BK0001\u201d\uff0c\u201dSH.BK0002\u201d\uff0c\u5148\u5229\u7528\u83b7\u53d6\u5b50\u7248\u5757\u5217\u8868\u51fd\u6570\u83b7\u53d6\u5b50\u7248\u5757\u4ee3\u7801\n        :return: (ret, data)\n\n                ret == RET_OK \u8fd4\u56depd dataframe\u6570\u636e\uff0cdata.DataFrame\u6570\u636e, \u6570\u636e\u5217\u683c\u5f0f\u5982\u4e0b\n\n                ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n                =====================   ===========   ==============================================================\n                \u53c2\u6570                      \u7c7b\u578b                        \u8bf4\u660e\n                =====================   ===========   ==============================================================\n                code                    str            \u80a1\u7968\u4ee3\u7801\n                lot_size                int            \u6bcf\u624b\u80a1\u6570\n                stock_name              str            \u80a1\u7968\u540d\u79f0\n                stock_owner             str            \u6240\u5c5e\u6b63\u80a1\u7684\u4ee3\u7801\n                stock_child_type        str            \u80a1\u7968\u5b50\u7c7b\u578b\uff0c\u53c2\u89c1WrtType\n                stock_type              str            \u80a1\u7968\u7c7b\u578b\uff0c\u53c2\u89c1SecurityType\n                list_time               str            \u4e0a\u5e02\u65f6\u95f4\uff08\u7f8e\u80a1\u9ed8\u8ba4\u662f\u7f8e\u4e1c\u65f6\u95f4\uff0c\u6e2f\u80a1A\u80a1\u9ed8\u8ba4\u662f\u5317\u4eac\u65f6\u95f4\uff09\n                stock_id                int            \u80a1\u7968id\n                =====================   ===========   ==============================================================\n        \"\"\"\n        if plate_code is None or is_str(plate_code) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of code is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            PlateStockQuery.pack_req, PlateStockQuery.unpack_rsp)\n        kargs = {\n            \"plate_code\": plate_code,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        ret_code, msg, plate_stock_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = [\n            'code', 'lot_size', 'stock_name', 'stock_owner',\n            'stock_child_type', 'stock_type', 'list_time', 'stock_id',\n        ]\n        plate_stock_table = pd.DataFrame(plate_stock_list, columns=col_list)\n\n        return RET_OK, plate_stock_table"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subscribe(self, code_list, subtype_list, is_first_push=True):\n        return self._subscribe_impl(code_list, subtype_list, is_first_push)", "response": "subscribe to a list of codes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unsubscribe(self, code_list, subtype_list):\n\n        ret, msg, code_list, subtype_list = self._check_subscribe_param(code_list, subtype_list)\n        if ret != RET_OK:\n            return ret, msg\n\n        query_processor = self._get_sync_query_processor(SubscriptionQuery.pack_unsubscribe_req,\n                                                         SubscriptionQuery.unpack_unsubscribe_rsp)\n\n        kargs = {\n            'code_list': code_list,\n            'subtype_list': subtype_list,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        for subtype in subtype_list:\n            if subtype not in self._ctx_subscribe:\n                continue\n            code_set = self._ctx_subscribe[subtype]\n            for code in code_list:\n                if code not in code_set:\n                    continue\n                code_set.remove(code)\n\n        ret_code, msg, _ = query_processor(**kargs)\n\n        if ret_code != RET_OK:\n            return RET_ERROR, msg\n\n        ret_code, msg, unpush_req_str = SubscriptionQuery.pack_unpush_req(code_list, subtype_list, self.get_async_conn_id())\n        if ret_code != RET_OK:\n            return RET_ERROR, msg\n\n        ret_code, msg = self._send_async_req(unpush_req_str)\n        if ret_code != RET_OK:\n            return RET_ERROR, msg\n\n        return RET_OK, None", "response": "unsubscribe from a list of code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_subscription(self, is_all_conn=True):\n        is_all_conn = bool(is_all_conn)\n        query_processor = self._get_sync_query_processor(\n            SubscriptionQuery.pack_subscription_query_req,\n            SubscriptionQuery.unpack_subscription_query_rsp)\n        kargs = {\n            \"is_all_conn\": is_all_conn,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        ret_code, msg, sub_table = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        ret_dict = {}\n        ret_dict['total_used'] = sub_table['total_used']\n        ret_dict['remain'] = sub_table['remain']\n        ret_dict['own_used'] = 0\n        ret_dict['sub_list'] = {}\n        for conn_sub in sub_table['conn_sub_list']:\n\n            is_own_conn = conn_sub['is_own_conn']\n            if is_own_conn:\n                ret_dict['own_used'] = conn_sub['used']\n            if not is_all_conn and not is_own_conn:\n                continue\n\n            for sub_info in conn_sub['sub_list']:\n                subtype = sub_info['subtype']\n\n                if subtype not in ret_dict['sub_list']:\n                    ret_dict['sub_list'][subtype] = []\n                code_list = ret_dict['sub_list'][subtype]\n\n                for code in sub_info['code_list']:\n                    if code not in code_list:\n                        code_list.append(code)\n\n        return RET_OK, ret_dict", "response": "Query the subscription list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_stock_quote(self, code_list):\n        code_list = unique_and_normalize_list(code_list)\n        if not code_list:\n            error_str = ERROR_STR_PREFIX + \"the type of code_list param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            StockQuoteQuery.pack_req,\n            StockQuoteQuery.unpack_rsp,\n        )\n        kargs = {\n            \"stock_list\": code_list,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        ret_code, msg, quote_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = [\n            'code', 'data_date', 'data_time', 'last_price', 'open_price',\n            'high_price', 'low_price', 'prev_close_price', 'volume',\n            'turnover', 'turnover_rate', 'amplitude', 'suspension',\n            'listing_date', 'price_spread', 'dark_status', 'strike_price',\n            'contract_size', 'open_interest', 'implied_volatility',\n            'premium', 'delta', 'gamma', 'vega', 'theta', 'rho'\n        ]\n\n        quote_frame_table = pd.DataFrame(quote_list, columns=col_list)\n\n        return RET_OK, quote_frame_table", "response": "get_stock_quote - \u83b7\u53d6stock_quote \ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_rt_ticker(self, code, num=500):\n\n        if code is None or is_str(code) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        if num is None or isinstance(num, int) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of num param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            TickerQuery.pack_req,\n            TickerQuery.unpack_rsp,\n        )\n        kargs = {\n            \"code\": code,\n            \"num\": num,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n        ret_code, msg, ticker_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = [\n            'code', 'time', 'price', 'volume', 'turnover', \"ticker_direction\",\n            'sequence', 'type'\n        ]\n        ticker_frame_table = pd.DataFrame(ticker_list, columns=col_list)\n\n        return RET_OK, ticker_frame_table", "response": "\u83b7\u53d6\u6307\u5b9a\u80a1\u7968\u7684\u5b9e\u65f6\u9010\u7b14\u3002\u53d6\u6700\u8fd1num\u4e2a\u9010\u7b14\n\n        :param code: \u80a1\u7968\u4ee3\u7801\n        :param num: \u6700\u8fd1ticker\u4e2a\u6570(\u6709\u6700\u5927\u4e2a\u6570\u9650\u5236\uff0c\u6700\u8fd11000\u4e2a\uff09\n        :return: (ret, data)\n\n                ret == RET_OK \u8fd4\u56depd dataframe\u6570\u636e\uff0c\u6570\u636e\u5217\u683c\u5f0f\u5982\u4e0b\n\n                ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n                =====================   ===========   ==============================================================\n                \u53c2\u6570                      \u7c7b\u578b                        \u8bf4\u660e\n                =====================   ===========   ==============================================================\n                stock_code               str            \u80a1\u7968\u4ee3\u7801\n                sequence                 int            \u9010\u7b14\u5e8f\u53f7\n                time                     str            \u6210\u4ea4\u65f6\u95f4\uff08\u7f8e\u80a1\u9ed8\u8ba4\u662f\u7f8e\u4e1c\u65f6\u95f4\uff0c\u6e2f\u80a1A\u80a1\u9ed8\u8ba4\u662f\u5317\u4eac\u65f6\u95f4\uff09\n                price                    float          \u6210\u4ea4\u4ef7\u683c\n                volume                   int            \u6210\u4ea4\u6570\u91cf\uff08\u80a1\u6570\uff09\n                turnover                 float          \u6210\u4ea4\u91d1\u989d\n                ticker_direction         str            \u9010\u7b14\u65b9\u5411\n                type                    str             \u9010\u7b14\u7c7b\u578b\uff0c\u53c2\u89c1TickerType\n                =====================   ===========   =============================================================="}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_order_book(self, code):\n        if code is None or is_str(code) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            OrderBookQuery.pack_req,\n            OrderBookQuery.unpack_rsp,\n        )\n\n        kargs = {\n            \"code\": code,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n        ret_code, msg, orderbook = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        return RET_OK, orderbook", "response": "\u83b7\u53d6\u5b9e\u65f6\u6446\u76d8\u6570\u636e\n\n        :param code: \u80a1\u7968\u4ee3\u7801\n        :return: (ret, data)\n\n                ret == RET_OK \u8fd4\u56de\u5b57\u5178\uff0c\u6570\u636e\u683c\u5f0f\u5982\u4e0b\n\n                ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n                {\u2018code\u2019: \u80a1\u7968\u4ee3\u7801\n                \u2018Ask\u2019:[ (ask_price1, ask_volume1\uff0corder_num), (ask_price2, ask_volume2, order_num),\u2026]\n                \u2018Bid\u2019: [ (bid_price1, bid_volume1, order_num), (bid_price2, bid_volume2, order_num),\u2026]\n                }\n\n                'Ask'\uff1a\u5356\u76d8\uff0c 'Bid'\u4e70\u76d8\u3002\u6bcf\u4e2a\u5143\u7ec4\u7684\u542b\u4e49\u662f(\u59d4\u6258\u4ef7\u683c\uff0c\u59d4\u6258\u6570\u91cf\uff0c\u59d4\u6258\u8ba2\u5355\u6570)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_multi_points_history_kline(self,\n                                       code_list,\n                                       dates,\n                                       fields,\n                                       ktype=KLType.K_DAY,\n                                       autype=AuType.QFQ,\n                                       no_data_mode=KLNoDataMode.FORWARD):\n        '''\n        \u4ece\u672c\u5730\u5386\u53f2K\u7ebf\u4e2d\u83b7\u53d6\u591a\u652f\u80a1\u7968\u591a\u4e2a\u65f6\u95f4\u70b9\u7684\u6307\u5b9a\u6570\u636e\u5217\n\n        :param code_list: \u5355\u4e2a\u6216\u591a\u4e2a\u80a1\u7968 'HK.00700'  or  ['HK.00700', 'HK.00001']\n        :param dates: \u5355\u4e2a\u6216\u591a\u4e2a\u65e5\u671f '2017-01-01' or ['2017-01-01', '2017-01-02']\n        :param fields: \u5355\u4e2a\u6216\u591a\u4e2a\u6570\u636e\u5217 KL_FIELD.ALL or [KL_FIELD.DATE_TIME, KL_FIELD.OPEN]\n        :param ktype: K\u7ebf\u7c7b\u578b\n        :param autype: \u590d\u6743\u7c7b\u578b\n        :param no_data_mode: \u6307\u5b9a\u65f6\u95f4\u4e3a\u975e\u4ea4\u6613\u65e5\u65f6\uff0c\u5bf9\u5e94\u7684k\u7ebf\u6570\u636e\u53d6\u503c\u6a21\u5f0f\uff0c\u53c2\u89c1KLNoDataMode\n        :return: (ret, data)\n\n                ret == RET_OK \u8fd4\u56depd dataframe\u6570\u636e\uff0c\u56fa\u5b9a\u8868\u5934\u5305\u62ec'code'(\u4ee3\u7801) 'time_point'(\u6307\u5b9a\u7684\u65e5\u671f) 'data_status' (KLDataStatus)\u3002\u6570\u636e\u5217\u683c\u5f0f\u5982\u4e0b\n\n                ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n            =================   ===========   ==============================================================================\n            \u53c2\u6570                  \u7c7b\u578b                        \u8bf4\u660e\n            =================   ===========   ==============================================================================\n            code                str            \u80a1\u7968\u4ee3\u7801\n            time_point          str            \u8bf7\u6c42\u7684\u65f6\u95f4\n            data_status         str            \u6570\u636e\u70b9\u662f\u5426\u6709\u6548\uff0c\u53c2\u89c1KLDataStatus\n            time_key            str            k\u7ebf\u65f6\u95f4\uff08\u7f8e\u80a1\u9ed8\u8ba4\u662f\u7f8e\u4e1c\u65f6\u95f4\uff0c\u6e2f\u80a1A\u80a1\u9ed8\u8ba4\u662f\u5317\u4eac\u65f6\u95f4\uff09\n            open                float          \u5f00\u76d8\u4ef7\n            close               float          \u6536\u76d8\u4ef7\n            high                float          \u6700\u9ad8\u4ef7\n            low                 float          \u6700\u4f4e\u4ef7\n            pe_ratio            float          \u5e02\u76c8\u7387\uff08\u8be5\u5b57\u6bb5\u4e3a\u6bd4\u4f8b\u5b57\u6bb5\uff0c\u9ed8\u8ba4\u4e0d\u5c55\u793a%\uff09\n            turnover_rate       float          \u6362\u624b\u7387\n            volume              int            \u6210\u4ea4\u91cf\n            turnover            float          \u6210\u4ea4\u989d\n            change_rate         float          \u6da8\u8dcc\u5e45\n            last_close          float          \u6628\u6536\u4ef7\n            =================   ===========   ==============================================================================\n        '''\n        req_codes = unique_and_normalize_list(code_list)\n        if not code_list:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        req_dates = unique_and_normalize_list(dates)\n        if not dates:\n            error_str = ERROR_STR_PREFIX + \"the type of dates param is wrong\"\n            return RET_ERROR, error_str\n\n        req_fields = unique_and_normalize_list(fields)\n        if not fields:\n            req_fields = copy(KL_FIELD.ALL_REAL)\n        req_fields = KL_FIELD.normalize_field_list(req_fields)\n        if not req_fields:\n            error_str = ERROR_STR_PREFIX + \"the type of fields param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            MultiPointsHisKLine.pack_req, MultiPointsHisKLine.unpack_rsp)\n\n        # \u4e00\u6b21\u6027\u6700\u591a\u53d6100\u652f\u80a1\u7968\u7684\u6570\u636e\n        max_req_code_num = 50\n\n        data_finish = False\n        list_ret = []\n        # \u5faa\u73af\u8bf7\u6c42\u6570\u636e\uff0c\u907f\u514d\u4e00\u6b21\u6027\u53d6\u592a\u591a\u8d85\u65f6\n        while not data_finish:\n            logger.debug('get_multi_points_history_kline - wait ... %s' % datetime.now())\n            kargs = {\n                \"code_list\": req_codes,\n                \"dates\": req_dates,\n                \"fields\": copy(req_fields),\n                \"ktype\": ktype,\n                \"autype\": autype,\n                \"max_req\": max_req_code_num,\n                \"no_data_mode\": int(no_data_mode),\n                \"conn_id\": self.get_sync_conn_id()\n            }\n            ret_code, msg, content = query_processor(**kargs)\n            if ret_code == RET_ERROR:\n                return ret_code, msg\n\n            list_kline, has_next = content\n            data_finish = (not has_next)\n\n            for dict_item in list_kline:\n                item_code = dict_item['code']\n                list_ret.append(dict_item)\n                if item_code in req_codes:\n                    req_codes.remove(item_code)\n\n            if 0 == len(req_codes):\n                data_finish = True\n\n        # \u8868\u5934\u5217\n        col_list = ['code', 'time_point', 'data_status']\n        for field in req_fields:\n            str_field = KL_FIELD.DICT_KL_FIELD_STR[field]\n            if str_field not in col_list:\n                col_list.append(str_field)\n\n        pd_frame = pd.DataFrame(list_ret, columns=col_list)\n\n        return RET_OK, pd_frame", "response": "\u4ece\u672c\u5730\u5386\u53f2K\u7ebf\u4e2d\u83b7\u53d6\u591a\u652f\u80a1\u7968\u591a\u4e2a\u65f6\u95f4\u70b9\u7684\u6307\u5b9a\u6570\u636e\u5217\n\n        :param code_list: \u5355\u4e2a\u6216\u591a\u4e2a\u80a1\u7968 'HK.00700'  or  ['HK.00700', 'HK.00001']\n        :param dates: \u5355\u4e2a\u6216\u591a\u4e2a\u65e5\u671f '2017-01-01' or ['2017-01-01', '2017-01-02']\n        :param fields: \u5355\u4e2a\u6216\u591a\u4e2a\u6570\u636e\u5217 KL_FIELD.ALL or [KL_FIELD.DATE_TIME, KL_FIELD.OPEN]\n        :param ktype: K\u7ebf\u7c7b\u578b\n        :param autype: \u590d\u6743\u7c7b\u578b\n        :param no_data_mode: \u6307\u5b9a\u65f6\u95f4\u4e3a\u975e\u4ea4\u6613\u65e5\u65f6\uff0c\u5bf9\u5e94\u7684k\u7ebf\u6570\u636e\u53d6\u503c\u6a21\u5f0f\uff0c\u53c2\u89c1KLNoDataMode\n        :return: (ret, data)\n\n                ret == RET_OK \u8fd4\u56depd dataframe\u6570\u636e\uff0c\u56fa\u5b9a\u8868\u5934\u5305\u62ec'code'(\u4ee3\u7801) 'time_point'(\u6307\u5b9a\u7684\u65e5\u671f) 'data_status' (KLDataStatus)\u3002\u6570\u636e\u5217\u683c\u5f0f\u5982\u4e0b\n\n                ret != RET_OK \u8fd4\u56de\u9519\u8bef\u5b57\u7b26\u4e32\n\n            =================   ===========   ==============================================================================\n            \u53c2\u6570                  \u7c7b\u578b                        \u8bf4\u660e\n            =================   ===========   ==============================================================================\n            code                str            \u80a1\u7968\u4ee3\u7801\n            time_point          str            \u8bf7\u6c42\u7684\u65f6\u95f4\n            data_status         str            \u6570\u636e\u70b9\u662f\u5426\u6709\u6548\uff0c\u53c2\u89c1KLDataStatus\n            time_key            str            k\u7ebf\u65f6\u95f4\uff08\u7f8e\u80a1\u9ed8\u8ba4\u662f\u7f8e\u4e1c\u65f6\u95f4\uff0c\u6e2f\u80a1A\u80a1\u9ed8\u8ba4\u662f\u5317\u4eac\u65f6\u95f4\uff09\n            open                float          \u5f00\u76d8\u4ef7\n            close               float          \u6536\u76d8\u4ef7\n            high                float          \u6700\u9ad8\u4ef7\n            low                 float          \u6700\u4f4e\u4ef7\n            pe_ratio            float          \u5e02\u76c8\u7387\uff08\u8be5\u5b57\u6bb5\u4e3a\u6bd4\u4f8b\u5b57\u6bb5\uff0c\u9ed8\u8ba4\u4e0d\u5c55\u793a%\uff09\n            turnover_rate       float          \u6362\u624b\u7387\n            volume              int            \u6210\u4ea4\u91cf\n            turnover            float          \u6210\u4ea4\u989d\n            change_rate         float          \u6da8\u8dcc\u5e45\n            last_close          float          \u6628\u6536\u4ef7\n            =================   ===========   =============================================================================="}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_referencestock_list(self, code, reference_type):\n        if code is None or is_str(code) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            StockReferenceList.pack_req,\n            StockReferenceList.unpack_rsp,\n        )\n\n        kargs = {\n            \"code\": code,\n            'ref_type': reference_type,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n        ret_code, msg, data_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = [\n            'code', 'lot_size', 'stock_type', 'stock_name', 'list_time', 'wrt_valid', 'wrt_type', 'wrt_code'\n        ]\n\n        pd_frame = pd.DataFrame(data_list, columns=col_list)\n        return RET_OK, pd_frame", "response": "Get a list of all the related resources for a given code and reference type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_holding_change_list(self, code, holder_type, start=None, end=None):\n        holder_type = STOCK_HOLDER_CLASS_MAP[holder_type]\n        if code is None or is_str(code) is False:\n            msg = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, msg\n\n        if holder_type < 1 or holder_type > len(STOCK_HOLDER_CLASS_MAP):\n            msg = ERROR_STR_PREFIX + \"the type {0} is wrong, total number of types is {1}\".format(holder_type, len(STOCK_HOLDER_CLASS_MAP))\n            return RET_ERROR, msg\n\n        ret_code, msg, start, end = normalize_start_end_date(start, end, delta_days=365)\n        if ret_code != RET_OK:\n            return  ret_code, msg\n\n        query_processor = self._get_sync_query_processor(\n            HoldingChangeList.pack_req, HoldingChangeList.unpack_rsp)\n        kargs = {\n            \"code\": code,\n            \"holder_type\": holder_type,\n            \"conn_id\": self.get_sync_conn_id(),\n            \"start_date\": start,\n            \"end_date\": end\n        }\n\n        ret_code, msg, owner_plate_list = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        col_list = [\n            'holder_name', 'holding_qty', 'holding_ratio', 'change_qty', 'change_ratio', 'time'\n        ]\n\n        holding_change_list = pd.DataFrame(owner_plate_list, columns=col_list)\n\n        return RET_OK, holding_change_list", "response": "get holding change list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_order_detail(self, code):\n\n        if code is None or is_str(code) is False:\n            error_str = ERROR_STR_PREFIX + \"the type of code param is wrong\"\n            return RET_ERROR, error_str\n\n        query_processor = self._get_sync_query_processor(\n            OrderDetail.pack_req, OrderDetail.unpack_rsp)\n        kargs = {\n            \"code\": code,\n            \"conn_id\": self.get_sync_conn_id()\n        }\n\n        ret_code, msg, order_detail = query_processor(**kargs)\n        if ret_code == RET_ERROR:\n            return ret_code, msg\n\n        return RET_OK, order_detail", "response": "\u67e5\u8be2A\u80a1Level 2\u6743\u9650\u4e0b\u63d0\u4f9b\u7684\u59d4\u6258\u660e\u7ec6\n\n        :param code: \u80a1\u7968\u4ee3\u7801,\u4f8b\u5982\uff1a'HK.02318'\n        :return: (ret, data)\n\n                ret == RET_OK data\u4e3a1\u4e2adict\uff0c\u5305\u542b\u4ee5\u4e0b\u6570\u636e\n\n                ret != RET_OK data\u4e3a\u9519\u8bef\u5b57\u7b26\u4e32\n\n                {\u2018code\u2019: \u80a1\u7968\u4ee3\u7801\n                \u2018Ask\u2019:[ order_num, [order_volume1, order_volume2] ]\n                \u2018Bid\u2019: [ order_num, [order_volume1, order_volume2] ]\n                }\n\n                'Ask'\uff1a\u5356\u76d8\uff0c 'Bid'\u4e70\u76d8\u3002order_num\u6307\u59d4\u6258\u8ba2\u5355\u6570\u91cf\uff0corder_volume\u662f\u6bcf\u7b14\u59d4\u6258\u7684\u59d4\u6258\u91cf\uff0c\u5f53\u524d\u6700\u591a\u8fd4\u56de\u524d50\u7b14\u59d4\u6258\u7684\u59d4\u6258\u6570\u91cf\u3002\u5373order_num\u6709\u53ef\u80fd\u591a\u4e8e\u540e\u9762\u7684order_volume"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef aStockQoutation(self,code):\n        '''\n        \u8ba2\u9605\u4e00\u53ea\u80a1\u7968\u7684\u5b9e\u65f6\u884c\u60c5\u6570\u636e\uff0c\u63a5\u6536\u63a8\u9001\n        :param code: \u80a1\u7968\u4ee3\u7801\n        :return:\n        '''\n\n        #\u8bbe\u7f6e\u76d1\u542c-->\u8ba2\u9605-->\u8c03\u7528\u63a5\u53e3\n\n        # \u5206\u65f6\n        self.quote_ctx.set_handler(RTDataTest())\n        self.quote_ctx.subscribe(code, SubType.RT_DATA)\n        ret_code_rt_data, ret_data_rt_data = self.quote_ctx.get_rt_data(code)\n        # \u9010\u7b14\n        self.quote_ctx.set_handler(TickerTest())\n        self.quote_ctx.subscribe(code, SubType.TICKER)\n        ret_code_rt_ticker, ret_data_rt_ticker = self.quote_ctx.get_rt_ticker(code)\n        # \u62a5\u4ef7\n        self.quote_ctx.set_handler(StockQuoteTest())\n        self.quote_ctx.subscribe(code, SubType.QUOTE)\n        ret_code_stock_quote, ret_data_stock_quote = self.quote_ctx.get_stock_quote([code])\n        # \u5b9e\u65f6K\u7ebf\n        self.quote_ctx.set_handler(CurKlineTest())\n        kTypes = [SubType.K_1M, SubType.K_5M, SubType.K_15M, SubType.K_30M, SubType.K_60M, SubType.K_DAY,\n                  SubType.K_WEEK, SubType.K_MON]\n        auTypes = [AuType.NONE, AuType.QFQ, AuType.HFQ]\n        num = 10\n        ret_code_cur_kline = RET_OK\n        for kType in kTypes:\n            self.quote_ctx.subscribe(code, kType)\n            for auType in auTypes:\n                ret_code_cur_kline_temp, ret_data_cur_kline = self.quote_ctx.get_cur_kline(code, num, kType, auType)\n                if ret_code_cur_kline_temp is RET_ERROR:\n                    ret_code_cur_kline = RET_ERROR\n        # \u6446\u76d8\n        self.quote_ctx.set_handler(OrderBookTest())\n        self.quote_ctx.subscribe(code, SubType.ORDER_BOOK)\n        ret_code_order_book, ret_data_order_book = self.quote_ctx.get_order_book(code)\n        # \u7ecf\u7eaa\u961f\u5217\n        self.quote_ctx.set_handler(BrokerTest())\n        self.quote_ctx.subscribe(code, SubType.BROKER)\n        ret_code_broker_queue, bid_frame_table, ask_frame_table = self.quote_ctx.get_broker_queue(code)\n\n        return ret_code_rt_data+ret_code_rt_ticker+ret_code_stock_quote+ret_code_cur_kline+ret_code_order_book+ret_code_broker_queue", "response": "\u8ba2\u9605\u4e00\u53ea\u80a1\u7968\u7684\u5b9e\u65f6\u884c\u60c5\u6570\u636e\uff0c\u63a5\u6536\u63a8\u9001\n        :param code: \u80a1\u7968\u4ee3\u7801\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef track(self, symbol):\n        quote_ctx = OpenQuoteContext(host='127.0.0.1', port=11111)\n        now = datetime.datetime.now()\n        end_str = now.strftime('%Y-%m-%d')\n        start = now - datetime.timedelta(days=365)\n        start_str = start.strftime('%Y-%m-%d')\n        _, temp = quote_ctx.get_history_kline(symbol, start=start_str, end=end_str)\n        #print(temp)\n        high = temp['high'].values\n        low = temp['low'].values\n        open = temp['open'].values\n        \"\"\"\u786e\u5b9a\u4e0a\u4e0b\u8f68\"\"\"\n        '''\n        y_amplitude = []\n        for i in range(len(high)):\n            temp = high[i] - low[i]\n            y_amplitude.append(temp)\n        '''\n        y_amplitude = high - low\n        print(y_amplitude)\n        y_a_r = y_amplitude[-1] / open[-2]\n        if y_a_r > 0.05:\n            up_ = open[-1] + 0.5 * y_amplitude[-1]\n            down_ = open[-1] - 0.5 * y_amplitude[-1]\n        else:\n            up_ = open[-1] + 2 / 3 * y_amplitude[-1]\n            down_ = open[-1] - 2 / 3 * y_amplitude[-1]\n        #print(up_, down_)\n        return up_, down_", "response": "Get the current state of a symbol from the quote."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the thread that will be called by the main thread.", "response": "def start(self):\n        \"\"\"\n        Should be called from main thread\n        :return:\n        \"\"\"\n        with self._mgr_lock:\n            with self._lock:\n                self._use_count += 1\n\n            if self._thread is None:\n                self._create_all()\n                self._thread = threading.Thread(target=self._thread_func)\n                self._thread.setDaemon(SysConfig.get_all_thread_daemon())\n                self._thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict2pb(cls, adict, strict=False):\n    obj = cls()\n    for field in obj.DESCRIPTOR.fields:\n        if not field.label == field.LABEL_REQUIRED:\n            continue\n        if not field.has_default_value:\n            continue\n        if not field.name in adict:\n            raise ConvertException('Field \"%s\" missing from descriptor dictionary.'\n                                   % field.name)\n    field_names = set([field.name for field in obj.DESCRIPTOR.fields])\n    if strict:\n        for key in adict.keys():\n            if key not in field_names:\n                raise ConvertException(\n                    'Key \"%s\" can not be mapped to field in %s class.'\n                    % (key, type(obj)))\n    for field in obj.DESCRIPTOR.fields:\n        if not field.name in adict:\n            continue\n        msg_type = field.message_type\n        if field.label == FD.LABEL_REPEATED:\n            if field.type == FD.TYPE_MESSAGE:\n                for sub_dict in adict[field.name]:\n                    item = getattr(obj, field.name).add()\n                    item.CopyFrom(dict2pb(msg_type._concrete_class, sub_dict))\n            else:\n                # fix python3 map\u7528\u6cd5\u53d8\u66f4\n                list(map(getattr(obj, field.name).append, adict[field.name]))\n        else:\n            if field.type == FD.TYPE_MESSAGE:\n                value = dict2pb(msg_type._concrete_class, adict[field.name])\n                getattr(obj, field.name).CopyFrom(value)\n            elif field.type in [FD.TYPE_UINT64, FD.TYPE_INT64, FD.TYPE_SINT64]:\n                setattr(obj, field.name, int(adict[field.name]))\n            else:\n                setattr(obj, field.name, adict[field.name])\n    return obj", "response": "Takes a ProtoBuf Message and fills it with data from the dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a ProtoBuf Message obj and convertes it to a dict.", "response": "def pb2dict(obj):\n    \"\"\"\n    Takes a ProtoBuf Message obj and convertes it to a dict.\n    \"\"\"\n    adict = {}\n    if not obj.IsInitialized():\n        return None\n    for field in obj.DESCRIPTOR.fields:\n        if not getattr(obj, field.name):\n            continue\n        if not field.label == FD.LABEL_REPEATED:\n            if not field.type == FD.TYPE_MESSAGE:\n                adict[field.name] = getattr(obj, field.name)\n            else:\n                value = pb2dict(getattr(obj, field.name))\n                if value:\n                    adict[field.name] = value\n        else:\n            if field.type == FD.TYPE_MESSAGE:\n                adict[field.name] = \\\n                    [pb2dict(v) for v in getattr(obj, field.name)]\n            else:\n                adict[field.name] = [v for v in getattr(obj, field.name)]\n    return adict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json2pb(cls, json, strict=False):\n    return dict2pb(cls, simplejson.loads(json), strict)", "response": "Takes a class representing the Protobuf Message and fills it with data from the json string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_pre_handler(self, handler):\n        '''pre handler push\n        return: ret_error or ret_ok\n        '''\n        set_flag = False\n        for protoc in self._pre_handler_table:\n            if isinstance(handler, self._pre_handler_table[protoc][\"type\"]):\n                self._pre_handler_table[protoc][\"obj\"] = handler\n                return RET_OK\n\n        if set_flag is False:\n            return RET_ERROR", "response": "pre handler push\n        return: ret_error or ret_ok"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_handler(self, handler):\n        set_flag = False\n        for protoc in self._handler_table:\n            if isinstance(handler, self._handler_table[protoc][\"type\"]):\n                self._handler_table[protoc][\"obj\"] = handler\n                return RET_OK\n\n        if set_flag is False:\n            return RET_ERROR", "response": "set the callback processing object for the base object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving response callback function", "response": "def recv_func(self, rsp_pb, proto_id):\n        \"\"\"receive response callback function\"\"\"\n\n        if self.cb_check_recv is not None and not self.cb_check_recv() and ProtoId.is_proto_id_push(proto_id):\n            return\n\n        handler = self._default_handler\n        pre_handler = None\n\n        if proto_id in self._handler_table:\n            handler = self._handler_table[proto_id]['obj']\n\n        if proto_id in self._pre_handler_table:\n            pre_handler = self._pre_handler_table[proto_id]['obj']\n\n        if pre_handler is not None:\n            pre_handler.on_recv_rsp(rsp_pb)\n\n        handler.on_recv_rsp(rsp_pb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        raw_acc_list = rsp_pb.s2c.accList\n        acc_list = [{\n            'acc_id': record.accID,\n            'trd_env': TRADE.REV_TRD_ENV_MAP[record.trdEnv] if record.trdEnv in TRADE.REV_TRD_ENV_MAP else \"\",\n            'trdMarket_list': [(TRADE.REV_TRD_MKT_MAP[trdMkt] if trdMkt in TRADE.REV_TRD_MKT_MAP else TrdMarket.NONE) for trdMkt in record.trdMarketAuthList]\n        } for record in raw_acc_list]\n\n        return RET_OK, \"\", acc_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pack_req(cls, is_unlock, password_md5, conn_id):\n        from futuquant.common.pb.Trd_UnlockTrade_pb2 import Request\n        req = Request()\n        req.c2s.unlock = is_unlock\n        req.c2s.pwdMD5 = password_md5\n\n        return pack_pb_req(req, ProtoId.Trd_UnlockTrade, conn_id)", "response": "Packs a TrdUnlockTrade_pb2 request into a protobuf."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpack_rsp(cls, rsp_pb):\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        if rsp_pb.HasField('retMsg'):\n            return RET_OK, rsp_pb.retMsg, None\n        return RET_OK, \"\", None", "response": "Convert from PLS response to user response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpack_rsp(cls, rsp_pb):\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        return RET_OK, \"\", None", "response": "Convert from PLS response to user response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        raw_funds = rsp_pb.s2c.funds\n        accinfo_list = [{\n            'power': raw_funds.power,\n            'total_assets': raw_funds.totalAssets,\n            'cash': raw_funds.cash,\n            'market_val': raw_funds.marketVal,\n            'frozen_cash': raw_funds.frozenCash,\n            'avl_withdrawal_cash': raw_funds.avlWithdrawalCash,\n        }]\n        return RET_OK, \"\", accinfo_list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pack_req(cls, code, pl_ratio_min,\n                 pl_ratio_max, trd_env, acc_id, trd_mkt, conn_id):\n        \"\"\"Convert from user request for trading days to PLS request\"\"\"\n        from futuquant.common.pb.Trd_GetPositionList_pb2 import Request\n        req = Request()\n        req.c2s.header.trdEnv = TRD_ENV_MAP[trd_env]\n        req.c2s.header.accID = acc_id\n        req.c2s.header.trdMarket = TRD_MKT_MAP[trd_mkt]\n        if code:\n            req.c2s.filterConditions.codeList.append(code)\n        if pl_ratio_min is not None:\n            req.c2s.filterPLRatioMin = float(pl_ratio_min) / 100.0\n        if pl_ratio_max is not None:\n            req.c2s.filterPLRatioMax = float(pl_ratio_max) / 100.0\n\n        return pack_pb_req(req, ProtoId.Trd_GetPositionList, conn_id)", "response": "Packs a Trd_GetPositionList_pb2 request into a ProtoBuf message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        raw_position_list = rsp_pb.s2c.positionList\n\n        position_list = [{\n                             \"code\": merge_trd_mkt_stock_str(rsp_pb.s2c.header.trdMarket, position.code),\n                             \"stock_name\": position.name,\n                             \"qty\": position.qty,\n                             \"can_sell_qty\": position.canSellQty,\n                             \"cost_price\": position.costPrice if position.HasField('costPrice') else 0,\n                             \"cost_price_valid\": 1 if position.HasField('costPrice') else 0,\n                             \"market_val\": position.val,\n                             \"nominal_price\": position.price,\n                             \"pl_ratio\": 100 * position.plRatio if position.HasField('plRatio') else 0,\n                             \"pl_ratio_valid\": 1 if position.HasField('plRatio') else 0,\n                             \"pl_val\": position.plVal if position.HasField('plVal') else 0,\n                             \"pl_val_valid\": 1 if position.HasField('plVal') else 0,\n                             \"today_buy_qty\": position.td_buyQty if position.HasField('td_buyQty') else 0,\n                             \"today_buy_val\": position.td_buyVal if position.HasField('td_buyVal') else 0,\n                             \"today_pl_val\": position.td_plVal if position.HasField('td_plVal') else 0,\n                             \"today_sell_qty\": position.td_sellQty if position.HasField('td_sellQty') else 0,\n                             \"today_sell_val\": position.td_sellVal if position.HasField('td_sellVal') else 0,\n                             \"position_side\": TRADE.REV_POSITION_SIDE_MAP[position.positionSide]\n                                if position.positionSide in TRADE.REV_POSITION_SIDE_MAP else PositionSide.NONE,\n                         } for position in raw_position_list]\n        return RET_OK, \"\", position_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pack_req(cls, order_id, status_filter_list, code, start, end,\n                 trd_env, acc_id, trd_mkt, conn_id):\n        \"\"\"Convert from user request for trading days to PLS request\"\"\"\n        from futuquant.common.pb.Trd_GetOrderList_pb2 import Request\n        req = Request()\n        req.c2s.header.trdEnv = TRD_ENV_MAP[trd_env]\n        req.c2s.header.accID = acc_id\n        req.c2s.header.trdMarket = TRD_MKT_MAP[trd_mkt]\n\n        if code:\n            req.c2s.filterConditions.codeList.append(code)\n        if order_id:\n            req.c2s.filterConditions.idList.append(int(order_id))\n\n        if start:\n            req.c2s.filterConditions.beginTime = start\n        if end:\n            req.c2s.filterConditions.endTime = end\n\n        if len(status_filter_list):\n            for order_status in status_filter_list:\n                req.c2s.filterStatusList.append(ORDER_STATUS_MAP[order_status])\n\n        return pack_pb_req(req, ProtoId.Trd_GetOrderList, conn_id)", "response": "Packs a Trd_GetOrderList_pb2 request into a PLS request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_rsp(cls, rsp_pb):\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        raw_order_list = rsp_pb.s2c.orderList\n        order_list = [OrderListQuery.parse_order(rsp_pb, order) for order in raw_order_list]\n        return RET_OK, \"\", order_list", "response": "Convert from PLS response to user response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pack_req(cls, trd_side, order_type, price, qty,\n                 code, adjust_limit, trd_env, sec_mkt_str, acc_id, trd_mkt, conn_id):\n        \"\"\"Convert from user request for place order to PLS request\"\"\"\n        from futuquant.common.pb.Trd_PlaceOrder_pb2 import Request\n        req = Request()\n        serial_no = get_unique_id32()\n        req.c2s.packetID.serialNo = serial_no\n        req.c2s.packetID.connID = conn_id\n\n        req.c2s.header.trdEnv = TRD_ENV_MAP[trd_env]\n        req.c2s.header.accID = acc_id\n        req.c2s.header.trdMarket = TRD_MKT_MAP[trd_mkt]\n\n        req.c2s.trdSide = TRD_SIDE_MAP[trd_side]\n        req.c2s.orderType = ORDER_TYPE_MAP[order_type]\n        req.c2s.code = code\n        req.c2s.qty = qty\n        req.c2s.price = price\n        req.c2s.adjustPrice = adjust_limit != 0\n        req.c2s.adjustSideAndLimit = adjust_limit\n        proto_qot_mkt = MKT_MAP.get(sec_mkt_str, Qot_Common_pb2.QotMarket_Unknown)\n        proto_trd_sec_mkt = QOT_MARKET_TO_TRD_SEC_MARKET_MAP.get(proto_qot_mkt,\n                                                                 Trd_Common_pb2.TrdSecMarket_Unknown)\n        req.c2s.secMarket = proto_trd_sec_mkt\n\n        return pack_pb_req(req, ProtoId.Trd_PlaceOrder, conn_id, serial_no)", "response": "Convert from user request to PLS request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unpack_rsp(cls, rsp_pb):\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        order_id = str(rsp_pb.s2c.orderID)\n\n        return RET_OK, \"\", order_id", "response": "Convert from PLS response to user response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pack_req(cls, modify_order_op, order_id, price, qty,\n                 adjust_limit, trd_env, acc_id, trd_mkt, conn_id):\n        \"\"\"Convert from user request for place order to PLS request\"\"\"\n        from futuquant.common.pb.Trd_ModifyOrder_pb2 import Request\n        req = Request()\n        serial_no = get_unique_id32()\n        req.c2s.packetID.serialNo = serial_no\n        req.c2s.packetID.connID = conn_id\n\n        req.c2s.header.trdEnv = TRD_ENV_MAP[trd_env]\n        req.c2s.header.accID = acc_id\n        req.c2s.header.trdMarket = TRD_MKT_MAP[trd_mkt]\n\n        req.c2s.orderID = int(order_id)\n        req.c2s.modifyOrderOp = MODIFY_ORDER_OP_MAP[modify_order_op]\n        req.c2s.forAll = False\n\n        if modify_order_op == ModifyOrderOp.NORMAL:\n            req.c2s.qty = qty\n            req.c2s.price = price\n            req.c2s.adjustPrice = adjust_limit != 0\n            req.c2s.adjustSideAndLimit = adjust_limit\n\n        return pack_pb_req(req, ProtoId.Trd_ModifyOrder, conn_id, serial_no)", "response": "Packs a TrdModifyOrder_pb2 request into a PLS request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        order_id = str(rsp_pb.s2c.orderID)\n        modify_order_list = [{\n            'trd_env': TRADE.REV_TRD_ENV_MAP[rsp_pb.s2c.header.trdEnv],\n            'order_id': order_id\n        }]\n\n        return RET_OK, \"\", modify_order_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pack_req(cls, code, trd_env, acc_id, trd_mkt, conn_id):\n        from futuquant.common.pb.Trd_GetOrderFillList_pb2 import Request\n        req = Request()\n        req.c2s.header.trdEnv = TRD_ENV_MAP[trd_env]\n        req.c2s.header.accID = acc_id\n        req.c2s.header.trdMarket = TRD_MKT_MAP[trd_mkt]\n\n        if code:\n            req.c2s.filterConditions.codeList.append(code)\n\n        return pack_pb_req(req, ProtoId.Trd_GetOrderFillList, conn_id)", "response": "Packs a Trd_GetOrderFillList_pb2 request into a PLS message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting from PLS response to user response", "response": "def unpack_rsp(cls, rsp_pb):\n        \"\"\"Convert from PLS response to user response\"\"\"\n        if rsp_pb.retType != RET_OK:\n            return RET_ERROR, rsp_pb.retMsg, None\n\n        raw_deal_list = rsp_pb.s2c.orderFillList\n        deal_list = [DealListQuery.parse_deal(rsp_pb, deal) for deal in raw_deal_list]\n\n        return RET_OK, \"\", deal_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_recv_rsp(self, rsp_pb):\n        ret_code, content = self.parse_rsp_pb(rsp_pb)\n\n        return ret_code, content", "response": "parse the response from the server"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the response from the server and return a DataFrame", "response": "def on_recv_rsp(self, rsp_pb):\n        \"\"\"\n        \u5728\u6536\u5230\u5b9e\u65f6\u9010\u7b14\u6570\u636e\u63a8\u9001\u540e\u4f1a\u56de\u8c03\u5230\u8be5\u51fd\u6570\uff0c\u4f7f\u7528\u8005\u9700\u8981\u5728\u6d3e\u751f\u7c7b\u4e2d\u8986\u76d6\u6b64\u65b9\u6cd5\n\n        \u6ce8\u610f\u8be5\u56de\u8c03\u662f\u5728\u72ec\u7acb\u5b50\u7ebf\u7a0b\u4e2d\n\n        :param rsp_pb: \u6d3e\u751f\u7c7b\u4e2d\u4e0d\u9700\u8981\u76f4\u63a5\u5904\u7406\u8be5\u53c2\u6570\n        :return: \u53c2\u89c1get_rt_ticker\u7684\u8fd4\u56de\u503c\n        \"\"\"\n        ret_code, content = self.parse_rsp_pb(rsp_pb)\n        if ret_code != RET_OK:\n            return ret_code, content\n        else:\n\n            col_list = [\n                'code', 'time', 'price', 'volume', 'turnover',\n                \"ticker_direction\", 'sequence', 'type', 'push_data_type',\n            ]\n            ticker_frame_table = pd.DataFrame(content, columns=col_list)\n\n            return RET_OK, ticker_frame_table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse response from broker", "response": "def on_recv_rsp(self, rsp_pb):\n        \"\"\"\n        \u5728\u6536\u5230\u5b9e\u65f6\u7ecf\u7eaa\u6570\u636e\u63a8\u9001\u540e\u4f1a\u56de\u8c03\u5230\u8be5\u51fd\u6570\uff0c\u4f7f\u7528\u8005\u9700\u8981\u5728\u6d3e\u751f\u7c7b\u4e2d\u8986\u76d6\u6b64\u65b9\u6cd5\n\n        \u6ce8\u610f\u8be5\u56de\u8c03\u662f\u5728\u72ec\u7acb\u5b50\u7ebf\u7a0b\u4e2d\n\n        :param rsp_pb: \u6d3e\u751f\u7c7b\u4e2d\u4e0d\u9700\u8981\u76f4\u63a5\u5904\u7406\u8be5\u53c2\u6570\n        :return: \u6210\u529f\u65f6\u8fd4\u56de(RET_OK, stock_code, [bid_frame_table, ask_frame_table]), \u76f8\u5173frame table\u542b\u4e49\u89c1 get_broker_queue_ \u7684\u8fd4\u56de\u503c\u8bf4\u660e\n\n                 \u5931\u8d25\u65f6\u8fd4\u56de(RET_ERROR, ERR_MSG, None)\n        \"\"\"\n        ret_code, content = self.parse_rsp_pb(rsp_pb)\n        if ret_code != RET_OK:\n            return ret_code, content, None\n        else:\n            stock_code, bid_content, ask_content = content\n            bid_list = [\n                'code', 'bid_broker_id', 'bid_broker_name', 'bid_broker_pos'\n            ]\n            ask_list = [\n                'code', 'ask_broker_id', 'ask_broker_name', 'ask_broker_pos'\n            ]\n            bid_frame_table = pd.DataFrame(bid_content, columns=bid_list)\n            ask_frame_table = pd.DataFrame(ask_content, columns=ask_list)\n\n            return RET_OK, stock_code, [bid_frame_table, ask_frame_table]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreceive response callback function", "response": "def on_recv_rsp(self, rsp_pb):\n        \"\"\"receive response callback function\"\"\"\n        ret_code, msg, conn_info_map = InitConnect.unpack_rsp(rsp_pb)\n\n        if self._notify_obj is not None:\n            self._notify_obj.on_async_init_connect(ret_code, msg, conn_info_map)\n\n        return ret_code, msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_recv_rsp(self, rsp_pb):\n        ret_code, msg, data = OrderDetail.unpack_rsp(rsp_pb)\n\n        if ret_code != RET_OK:\n            return ret_code, msg\n        else:\n            return RET_OK, data", "response": "receive response callback function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_history_change_stocks(quote_context=None, markets=[Market.HK], start='2017-01-05', end='2017-1-10', change_min=5.0,\n                            change_max=None, stock_type=SecurityType.STOCK, ascend=True):\n    '''\n    :param quote_context: api \u884c\u60c5\u5bf9\u8c61\n    :param markets: \u8981\u67e5\u8be2\u7684\u5e02\u573a\u5217\u8868, \u53ef\u4ee5\u53ea\u4f20\u5355\u4e2a\u5e02\u573a\u5982'HK'\u5b57\u7b26\u4e32\n    :param start: \u5f00\u59cb\u65f6\u95f4\n    :param end: \u622a\u6b62\u65f6\u95f4\n    :param change_min: \u6da8\u8dcc\u5e45\u6700\u5c0f\u503c eg: 1.0% \u4f20\u503c 1.0, None\u8868\u793a\u5ffd\u7565\n    :param change_max: \u6da8\u8dcc\u5e45\u6700\u5927\u503c\n    :param stock_type: \u8981\u67e5\u8be2\u7684\u80a1\u7968\u7c7b\u578b, \u89c1 SEC_TYPE_MAP - 'STOCK','IDX','ETF','WARRANT','BOND'\n    :param ascend: \u7ed3\u679c\u662f\u5426\u5347\u5e8f\u6392\u5217\n    :return: (ret, data), ret == 0\u8fd4\u56depd dataframe, \u8868\u5934\u4e3a 'code'(\u80a1\u7968\u4ee3\u7801), 'change_rate'(\u6da8\u8dcc\u7387*100), 'real_times'(\u8d77\u6b62\u771f\u5b9e\u4ea4\u6613\u65f6\u95f4\u5b57\u7b26\u4e32)\n                          ret != 0 data \u4e3a\u9519\u8bef\u5b57\u7b26\u4e32\n    '''\n    if not markets or (not is_str(markets) and not isinstance(markets, list)):\n        error_str = \"the type of markets param is wrong\"\n        return RET_ERROR, error_str\n    req_markets = markets if isinstance(markets, list) else [markets]\n\n    if change_min is None and change_max is None:\n        return RET_ERROR, \"param change is wrong\"\n\n    # float \u6bd4\u8f83\u6709\u504f\u5dee \u6bd4\u5982 a = 1.0 , b = 1.1, c = (b-a)/a * 100, d = 10 ,  c<=d \u7ed3\u679c\u4e3aFalse\n    if change_min is not None:\n        change_min = int(float(change_min) * 1000)\n    if change_max is not None:\n        change_max = int(float(change_max) * 1000)\n\n    # \u6c47\u603b\u5f97\u5230\u9700\u8981\u67e5\u8be2\u7684\u6240\u6709\u80a1\u7968code\n    list_stocks = []\n    for mk in req_markets:\n        ret, data = quote_context.get_stock_basicinfo(mk, stock_type)\n        if 0 != ret:\n            return ret, data\n        for ix, row in data.iterrows():\n            list_stocks.append(row['code'])\n\n    # \u591a\u70b9k\u7ebf\u6570\u636e\u67e5\u8be2\n    dt_last = datetime.now()\n    ret_list = []\n    ret, data_start = quote_context.get_multi_points_history_kline(list_stocks, [start],\n                                                             [KL_FIELD.DATE_TIME, KL_FIELD.CLOSE], KLType.K_DAY, AuType.QFQ,\n                                                                   KLNoDataMode.FORWARD)\n    if ret != 0:\n        return ret, data_start\n    ret, data_end = quote_context.get_multi_points_history_kline(list_stocks, [end],\n                                                             [KL_FIELD.DATE_TIME, KL_FIELD.CLOSE], KLType.K_DAY, AuType.QFQ,\n                                                                 KLNoDataMode.FORWARD)\n    if ret != 0:\n        return ret, data_end\n\n    # \u5408\u5e76\u6570\u636e\n    data = data_start.append(data_end)\n\n    dt = datetime.now() - dt_last\n    print('get_multi_points_history_kline - run time = %s\u79d2' % dt.seconds)\n\n    # \u8fd4\u56de\u8ba1\u7b97\u6da8\u8dcc\u5e45\uff0c\u7edf\u8ba1\u7b26\u5408\u6761\u4ef6\u7684\u80a1\u7968\n    for stock in list_stocks:\n        pd_find = data[data.code == stock]\n        close_start = 0\n        close_end = 0\n        real_times = []\n        for _, row in pd_find.iterrows():\n            if KLDataStatus.NONE == row['data_status']:\n                break\n            if row['time_point'] == start:\n                close_start = row['close']\n                real_times.append(row['time_key'])\n            elif row['time_point'] == end:\n                close_end = row['close']\n                real_times.append(row['time_key'])\n        if close_start and close_end:\n            change_rate = (close_end - close_start) / float(close_start) * 100000.0\n            data_ok = True\n            if change_min is not None:\n                data_ok = change_rate >= change_min\n            if data_ok and change_max is not None:\n                data_ok = change_rate <= change_max\n            if data_ok:\n                ret_list.append({'code': stock, 'change_rate':  float(change_rate / 1000.0), 'real_times': ','.join(real_times)})\n\n    # \u6570\u636e\u6392\u5e8f\n    ret_list = sorted(ret_list, key=lambda x: x['change_rate'], reverse=(not ascend))\n\n    # \u7ec4\u88c5\u8fd4\u56depdframe\u6570\u636e\n    col_list = ['code', 'change_rate', 'real_times']\n    pd_frame = pd.DataFrame(ret_list, columns=col_list)\n\n    return RET_OK, pd_frame", "response": "Query history of change stocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef buy(self, price, volume, symbol, order_type=ft.OrderType.NORMAL, adjust_limit=0, acc_id=0):\n        return self._quant_frame.buy(price, volume, symbol, order_type, adjust_limit, acc_id)", "response": "\u4e70\u5165\n        :param price: \u62a5\u4ef7\uff0c\u6d6e\u70b9\u6570 \u7cbe\u5ea60.001\n        :param volume: \u6570\u91cf\uff08\u80a1\uff09\n        :param symbol: \u80a1\u7968 eg: 'HK.00700'\n        :param order_type: \u8ba2\u5355\u7c7b\u578b\n        :param adjust_limit: \u5f53\u975e0\u65f6\uff0c\u4f1a\u81ea\u52a8\u8c03\u6574\u62a5\u4ef7\uff0c\u4ee5\u7b26\u5408\u4ef7\u4f4d\u8868\u8981\u6c42\uff0c \u4f46\u4e0d\u4f1a\u8d85\u8fc7\u6307\u5b9a\u7684\u5e45\u5ea6, \u4e3a0\u65f6\u4e0d\u8c03\u6574\u62a5\u4ef7\n        :param acc_id: int, \u4ea4\u6613\u8d26\u6237id, \u4e3a0\u65f6\u53d6\u7b2c1\u4e2a\u53ef\u4ea4\u6613\u8d26\u6237\n        :return: (ret, data)\n        ret == 0 , data = order_id\n        ret != 0 , data = \u9519\u8bef\u5b57\u7b26\u4e32"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_strate(self, global_setting, quant_frame, event_engine):\n\n        if type(self._quant_frame) is not int:\n            return True\n\n        self._quant_frame = quant_frame\n        self._event_engine = event_engine\n        init_ret = self.__loadSetting(global_setting)\n\n        # \u6ce8\u518c\u4e8b\u4ef6\n        self._event_engine.register(EVENT_BEFORE_TRADING, self.__event_before_trading)\n        self._event_engine.register(EVENT_AFTER_TRADING, self.__event_after_trading)\n        self._event_engine.register(EVENT_QUOTE_CHANGE, self.__event_quote_change)\n        self._event_engine.register(EVENT_CUR_KLINE_BAR, self.__event_cur_kline_bar)\n\n        self.log(\"init_strate '%s' ret = %s\" % (self.name, init_ret))\n\n        # \u5bf9\u5916\u901a\u77e5\u521d\u59cb\u5316\u4e8b\u4ef6\n        self.on_init_strate()\n\n        return init_ret", "response": "init_strate - init the internal state of the TinyQuantFrame"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_init_strate(self):\n\n        # \u6dfb\u52a0\u5fc5\u8981\u7684\u80a1\u7968\uff0c\u4ee5\u4fbf\u80fd\u5f97\u5230\u76f8\u5e94\u7684\u80a1\u7968\u884c\u60c5\u6570\u636e\n        self.symbol_pools.append(self.symbol_ref)\n        if self.cta_call[\"enable\"]:\n            self.symbol_pools.append(self.cta_call[\"symbol\"])\n\n        if self.cta_put[\"enable\"]:\n            self.symbol_pools.append(self.cta_put[\"symbol\"])\n\n        # call put \u7684\u6301\u4ed3\u91cf\u4ee5\u53ca\u6301\u4ed3\u5929\u6570\n        self.cta_call['pos'] = 0\n        self.cta_call['days'] = 0\n        self.cta_put['pos'] = 0\n        self.cta_put['days'] = 0\n\n        # call put \u4e00\u5929\u53ea\u64cd\u4f5c\u4e00\u6b21\uff0c\u8bb0\u5f55\u5f53\u5929\u662f\u5426\u5df2\u7ecf\u64cd\u4f5c\u8fc7\n        self.cta_call['done'] = False\n        self.cta_put['done'] = False\n\n        # \u8bb0\u5f55\u5f53\u5929\u64cd\u4f5c\u7684\u8ba2\u5355id\n        self.cta_call['order_id'] = ''\n        self.cta_put['order_id'] = ''\n\n        # \u68c0\u67e5\u53c2\u6570: \u4e0b\u5355\u7684\u6ed1\u70b9 / \u4e0b\u5355\u7684\u6570\u91cf\n        if self.trade_price_idx < 1 or self.trade_price_idx > 5:\n            raise Exception(\"conifg trade_price_idx error!\")\n        if self.trade_qty < 0:\n            raise Exception(\"conifg trade_qty error!\")", "response": "Initialize the internal state of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_quote_changed(self, tiny_quote):\n\n        # TinyQuoteData\n        if tiny_quote.symbol != self.symbol_ref:\n            return\n\n        # \u51cf\u5c11\u8ba1\u7b97\u9891\u7387\uff0c\u6bcfx\u79d2\u4e00\u6b21\n        dt_now = time.time()\n        if dt_now - self._last_dt_process < 2:\n            return\n        self._last_dt_process = dt_now\n\n        # \u6267\u884c\u7b56\u7565\n        self._process_cta(self.cta_call)\n        self._process_cta(self.cta_put)", "response": "Process the CTA call and put events."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_before_trading(self, date_time):\n\n        if self.cta_call['pos'] > 0:\n            self.cta_call['days'] += 1\n        if self.cta_put['pos'] > 0:\n            self.cta_put['days'] += 1\n\n        self.cta_call['done'] = False\n        self.cta_put['done'] = False", "response": "Called by the agent when the time is before trading."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating cta_call and cta_put", "response": "def on_after_trading(self, date_time):\n        \"\"\"\u6536\u76d8\u7684\u65f6\u5019\u66f4\u65b0\u6301\u4ed3\u4fe1\u606f\"\"\"\n\n        self._update_cta_pos(self.cta_call)\n        self._update_cta_pos(self.cta_put)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the API socket is reconnected", "response": "def on_api_socket_reconnected(self):\n        \"\"\"for API socket reconnected\"\"\"\n        self.__is_acc_sub_push = False\n        self.__last_acc_list = []\n\n        ret, msg = RET_OK, ''\n        # auto unlock trade\n        if self._ctx_unlock is not None:\n            password, password_md5 = self._ctx_unlock\n            ret, data = self.unlock_trade(password, password_md5)\n            logger.debug('auto unlock trade ret={},data={}'.format(ret, data))\n            if ret != RET_OK:\n                msg = data\n\n        # \u5b9a\u9605\u4ea4\u6613\u5e10\u53f7\u63a8\u9001\n        if ret == RET_OK:\n            self.__check_acc_sub_push()\n\n        return ret, msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the list of all accounts", "response": "def get_acc_list(self):\n        \"\"\"\n        :return: (ret, data)\n        \"\"\"\n        query_processor = self._get_sync_query_processor(\n            GetAccountList.pack_req, GetAccountList.unpack_rsp)\n\n        kargs = {\n            'user_id': self.get_login_user_id(),\n            'conn_id': self.get_sync_conn_id()\n        }\n\n        ret_code, msg, acc_list = query_processor(**kargs)\n        if ret_code != RET_OK:\n            return RET_ERROR, msg\n\n        # \u8bb0\u5f55\u5f53\u524d\u5e02\u573a\u7684\u5e10\u53f7\u5217\u8868\n        self.__last_acc_list = []\n\n        for record in acc_list:\n            trdMkt_list = record[\"trdMarket_list\"]\n            if self.__trd_mkt in trdMkt_list:\n                self.__last_acc_list.append({\n                    \"trd_env\": record[\"trd_env\"],\n                    \"acc_id\": record[\"acc_id\"]})\n\n        col_list = [\"acc_id\", \"trd_env\"]\n\n        acc_table = pd.DataFrame(copy(self.__last_acc_list), columns=col_list)\n\n        return RET_OK, acc_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _split_stock_code(self, code):\n        stock_str = str(code)\n\n        split_loc = stock_str.find(\".\")\n        '''do not use the built-in split function in python.\n        The built-in function cannot handle some stock strings correctly.\n        for instance, US..DJI, where the dot . itself is a part of original code'''\n        if 0 <= split_loc < len(\n                stock_str) - 1 and stock_str[0:split_loc] in MKT_MAP:\n            market_str = stock_str[0:split_loc]\n            partial_stock_str = stock_str[split_loc + 1:]\n            return RET_OK, (market_str, partial_stock_str)\n\n        else:\n            error_str = ERROR_STR_PREFIX + \"format of %s is wrong. (US.AAPL, HK.00700, SZ.000001)\" % stock_str\n            return RET_ERROR, error_str", "response": "split the stock code into market and partial stock strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef place_order(self, price, qty, code, trd_side, order_type=OrderType.NORMAL,\n                    adjust_limit=0, trd_env=TrdEnv.REAL, acc_id=0, acc_index=0):\n        \"\"\"\n        place order\n        use  set_handle(HKTradeOrderHandlerBase) to recv order push !\n        \"\"\"\n        # ret, msg = self._check_trd_env(trd_env)\n        # if ret != RET_OK:\n        #     return ret, msg\n\n        ret, msg, acc_id = self._check_acc_id_and_acc_index(trd_env, acc_id, acc_index)\n        if ret != RET_OK:\n            return ret, msg\n\n        ret, content = self._split_stock_code(code)\n        if ret != RET_OK:\n            return ret, content\n\n        market_str, stock_code = content\n\n        query_processor = self._get_sync_query_processor(\n            PlaceOrder.pack_req, PlaceOrder.unpack_rsp)\n\n        # the keys of kargs should be corresponding to the actual function arguments\n        kargs = {\n            'trd_side': trd_side,\n            'order_type': order_type,\n            'price': float(price),\n            'qty': float(qty),\n            'code': stock_code,\n            'adjust_limit': float(adjust_limit),\n            'trd_mkt': self.__trd_mkt,\n            'sec_mkt_str': market_str,\n            'trd_env': trd_env,\n            'acc_id': acc_id,\n            'conn_id': self.get_sync_conn_id()\n        }\n\n        ret_code, msg, order_id = query_processor(**kargs)\n        if ret_code != RET_OK:\n            return RET_ERROR, msg\n\n        order_item = {'trd_env': trd_env, 'order_id': order_id}\n\n        # \u4fdd\u6301\u8ddfv2.0\u517c\u5bb9\uff0c \u589e\u52a0\u5fc5\u8981\u7684\u8ba2\u5355\u5b57\u6bb5\n        for x in range(3):\n            ret_code, ret_data = self._order_list_query_impl(order_id=order_id,status_filter_list=[],\n                                            code=\"\", start=\"\", end=\"\", trd_env=trd_env, acc_id=acc_id)\n            if ret_code == RET_OK and len(ret_data) > 0:\n                order_item = ret_data[0]\n                order_item['trd_env'] = trd_env\n                break\n\n        col_list = [\n            \"code\", \"stock_name\", \"trd_side\", \"order_type\", \"order_status\",\n            \"order_id\", \"qty\", \"price\", \"create_time\", \"updated_time\",\n            \"dealt_qty\", \"dealt_avg_price\", \"last_err_msg\"\n        ]\n        order_list = [order_item]\n        order_table = pd.DataFrame(order_list, columns=col_list)\n\n        return RET_OK, order_table", "response": "place order in HKTrade"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order_list_query(self, order_id=\"\", status_filter_list=[], code='', start='', end='',\n                         trd_env=TrdEnv.REAL, acc_id=0, acc_index=0):\n        \"\"\"\n        :param order_id:\n        :param status_filter_list:\n        :param code:\n        :param start:\n        :param end:\n        :param trd_env:\n        :param acc_id:\n        :return: \u8fd4\u56de\u503c\u89c1\u57fa\u7c7b\u53ca\u63a5\u53e3\u6587\u6863\uff0c\u4f46order_type\u4ec5\u6709OrderType.NORMAL, order_status\u6ca1\u6709OrderStatus.DISABLED\n        \"\"\"\n        return super(OpenHKCCTradeContext, self).order_list_query(order_id, status_filter_list, code, start, end, trd_env, acc_id, acc_index)", "response": "Query the order list for a given order_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modify_order(self, modify_order_op, order_id, qty, price, adjust_limit=0, trd_env=TrdEnv.REAL, acc_id=0, acc_index=0):\n        return super(OpenHKCCTradeContext, self).modify_order(modify_order_op=modify_order_op,\n                                    order_id=order_id,\n                                    qty=qty,\n                                    price=price,\n                                    adjust_limit=adjust_limit,\n                                    trd_env=trd_env,\n                                    acc_id=acc_id,\n                                    acc_index=acc_index)", "response": "Modify an order in OpenHKCCTrade"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the event loop", "response": "def __run(self):\n        \"\"\"\u5f15\u64ce\u8fd0\u884c\"\"\"\n        while self.__active == True:\n            try:\n                event = self.__queue.get(block = True, timeout = 1)  # \u83b7\u53d6\u4e8b\u4ef6\u7684\u963b\u585e\u65f6\u95f4\u8bbe\u4e3a1\u79d2\n                self.__process(event)\n            except Empty:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting thread and timer", "response": "def start(self, timer=True):\n        \"\"\"\n        \u5f15\u64ce\u542f\u52a8\n        timer\uff1a\u662f\u5426\u8981\u542f\u52a8\u8ba1\u65f6\u5668\n        \"\"\"\n        # \u5c06\u5f15\u64ce\u8bbe\u4e3a\u542f\u52a8\n        self.__active = True\n        \n        # \u542f\u52a8\u4e8b\u4ef6\u5904\u7406\u7ebf\u7a0b\n        self.__thread.start()\n        \n        # \u542f\u52a8\u8ba1\u65f6\u5668\uff0c\u8ba1\u65f6\u5668\u4e8b\u4ef6\u95f4\u9694\u9ed8\u8ba4\u8bbe\u5b9a\u4e3a1\u79d2\n        if timer:\n            self.__timer.start(1000)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registerGeneralHandler(self, handler):\n        if handler not in self.__generalHandlers:\n            self.__generalHandlers.append(handler)", "response": "register a general handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _example_get_market_snapshot(quote_ctx):\n    ret_status, ret_data = quote_ctx.get_market_snapshot([\"US.AAPL\", \"HK.00700\"])\n    if ret_status != ft.RET_OK:\n        print(ret_data)\n        exit()\n    print(\"market_snapshot\")\n    print(ret_data)", "response": "Example for getting market snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_sock_ok(self, timeout_select):\n        self._socket_lock.acquire()\n        try:\n            ret = self._is_socket_ok(timeout_select)\n        finally:\n            self._socket_lock.release()\n        return ret", "response": "check if socket is OK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef network_query(self, req_str, is_create_socket=True):\n        req_proto_id = 0\n        try:\n            is_socket_lock = False\n            ret, msg = self._create_session(is_create_socket)\n            if ret != RET_OK:\n                return ret, msg, None\n\n            self._socket_lock.acquire()\n            if not self.s:\n                self._socket_lock.release()\n                return RET_ERROR, \"socket is closed\"\n            is_socket_lock = True\n\n            head_len = get_message_head_len()\n            req_head_dict = parse_head(req_str[:head_len])\n            req_proto_id = req_head_dict['proto_id']\n            req_serial_no = req_head_dict['serial_no']\n            s_cnt = self.s.send(req_str)\n\n            is_rsp_body = False\n            left_buf = b''\n            rsp_body = b''\n            head_dict = []\n            while not is_rsp_body:\n                if len(left_buf) < head_len:\n                    recv_buf = self.s.recv(5 * 1024 * 1024)\n                    if recv_buf == b'':\n                        raise Exception(\"_SyncNetworkQueryCtx : head recv error, remote server close\")\n                    left_buf += recv_buf\n\n                head_dict = parse_head(left_buf[:head_len])\n                rsp_body = left_buf[head_len:]\n\n                while head_dict['body_len'] > len(rsp_body):\n                    try:\n                        recv_buf = self.s.recv(5 * 1024 * 1024)\n                        rsp_body += recv_buf\n                        if recv_buf == b'':\n                            raise Exception(\"_SyncNetworkQueryCtx : body recv error, remote server close\")\n                    except Exception as e:\n                        traceback.print_exc()\n                        err = sys.exc_info()[1]\n                        error_str = ERROR_STR_PREFIX + str(\n                            err) + ' when receiving after sending %s bytes.' % s_cnt + \"\"\n                        self._force_close_session()\n                        return RET_ERROR, error_str, None\n                if head_dict[\"proto_id\"] == req_proto_id and head_dict[\"serial_no\"] == req_serial_no:\n                    is_rsp_body = True\n                else:\n                    left_buf = rsp_body[head_dict['body_len']:]\n                    logger.debug(\"recv dirty response: req protoID={} serial={}, recv protoID={} serial={} conn_id={}\".format(\n                            req_proto_id, req_serial_no, head_dict[\"proto_id\"], head_dict[\"serial_no\"], self._conn_id))\n\n            ret_decrypt, msg_decrypt, rsp_body = decrypt_rsp_body(rsp_body, head_dict, self._conn_id)\n\n            if ret_decrypt != RET_OK:\n                return ret_decrypt, msg_decrypt, None\n\n            rsp_pb = binary2pb(rsp_body, head_dict['proto_id'], head_dict['proto_fmt_type'])\n            if rsp_pb is None:\n                return RET_ERROR, \"parse error\", None\n\n            self._close_session()\n\n        except Exception as e:\n            traceback.print_exc()\n            err = sys.exc_info()[1]\n            str_proto = ' when req proto:{} conn_id:{}, host:{} port:{}'.format(req_proto_id, self._conn_id, self.__host, self.__port)\n            error_str = ERROR_STR_PREFIX + str(err) + str_proto\n            logger.error(error_str)\n\n            return RET_ERROR, error_str, None\n        finally:\n            if is_socket_lock:\n                self._socket_lock.release()\n\n        return RET_OK, \"\", rsp_pb", "response": "This function sends a request to FUTU and attempts to get the response from the client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef findCaller(self):\n        f = currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is not None:\n            f = f.f_back\n        rv = \"(unknown file)\", 0, \"(unknown function)\", None\n        while hasattr(f, \"f_code\"):\n            co = f.f_code\n            filename = os.path.normcase(co.co_filename)\n            if filename == _srcfile:\n                f = f.f_back\n                continue\n            rv = (co.co_filename, f.f_lineno, co.co_name)\n            break\n        return rv", "response": "Find the caller so that we can note the source\n            file name line number and function name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the format of date string", "response": "def check_date_str_format(s, default_time=\"00:00:00\"):\n    \"\"\"Check the format of date string\"\"\"\n    try:\n        str_fmt = s\n        if \":\" not in s:\n            str_fmt = '{} {}'.format(s, default_time)\n\n        dt_obj = datetime.strptime(str_fmt, \"%Y-%m-%d %H:%M:%S\")\n\n        return RET_OK, dt_obj\n\n    except ValueError:\n        error_str = ERROR_STR_PREFIX + \"wrong time or time format\"\n        return RET_ERROR, error_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing the format of data", "response": "def normalize_date_format(date_str, default_time=\"00:00:00\"):\n    \"\"\"normalize the format of data\"\"\"\n    ret_code, ret_data = check_date_str_format(date_str, default_time)\n    if ret_code != RET_OK:\n        return ret_code, ret_data\n\n    return RET_OK, ret_data.strftime(\"%Y-%m-%d %H:%M:%S\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the response from PLS", "response": "def extract_pls_rsp(rsp_str):\n    \"\"\"Extract the response of PLS\"\"\"\n    try:\n        rsp = json.loads(rsp_str)\n    except ValueError:\n        traceback.print_exc()\n        err = sys.exc_info()[1]\n        err_str = ERROR_STR_PREFIX + str(err)\n        return RET_ERROR, err_str, None\n\n    error_code = int(rsp['retType'])\n\n    if error_code != 1:\n        error_str = ERROR_STR_PREFIX + rsp['retMsg']\n        return RET_ERROR, error_str, None\n\n    return RET_OK, \"\", rsp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the stock string into a list of items", "response": "def split_stock_str(stock_str_param):\n    \"\"\"split the stock string\"\"\"\n    stock_str = str(stock_str_param)\n\n    split_loc = stock_str.find(\".\")\n    '''do not use the built-in split function in python.\n    The built-in function cannot handle some stock strings correctly.\n    for instance, US..DJI, where the dot . itself is a part of original code'''\n    if 0 <= split_loc < len(\n            stock_str) - 1 and stock_str[0:split_loc] in MKT_MAP:\n        market_str = stock_str[0:split_loc]\n        market_code = MKT_MAP[market_str]\n        partial_stock_str = stock_str[split_loc + 1:]\n        return RET_OK, (market_code, partial_stock_str)\n\n    else:\n        error_str = ERROR_STR_PREFIX + \"format of %s is wrong. (US.AAPL, HK.00700, SZ.000001)\" % stock_str\n        return RET_ERROR, error_str"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_qot_mkt_stock_str(qot_mkt, partial_stock_str):\n    market_str = QUOTE.REV_MKT_MAP[qot_mkt]\n    stock_str = '.'.join([market_str, partial_stock_str])\n    return stock_str", "response": "Merge the string of stocks with the original stock string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_trd_mkt_stock_str(trd_mkt, partial_stock_str):\n    mkt_qot = Market.NONE\n    mkt = TRADE.REV_TRD_MKT_MAP[trd_mkt] if trd_mkt in TRADE.REV_TRD_MKT_MAP else TrdMarket.NONE\n    if mkt == TrdMarket.HK:\n        mkt_qot = Market.HK\n    elif mkt == TrdMarket.US:\n        mkt_qot = Market.US\n    elif mkt == TrdMarket.HKCC or mkt == TrdMarket.CN:\n        if partial_stock_str.startswith('6') or partial_stock_str.startswith('9'):\n            mkt_qot = Market.SH\n        else:\n            mkt_qot = Market.SZ\n    else:\n        raise Exception(\"merge_trd_mkt_stock_str: unknown trd_mkt.\")\n\n    return merge_qot_mkt_stock_str(MKT_MAP[mkt_qot], partial_stock_str)", "response": "Merge the string of stocks into a single market code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransfers binary to string", "response": "def binary2str(b, proto_id, proto_fmt_type):\n    \"\"\"\n    Transfer binary to string\n    :param b: binary content to be transformed to string\n    :return: string\n    \"\"\"\n    if proto_fmt_type == ProtoFMT.Json:\n        return b.decode('utf-8')\n    elif proto_fmt_type == ProtoFMT.Protobuf:\n        rsp = pb_map[proto_id]\n        if IS_PY2:\n            rsp.ParseFromString(str(b))\n        else:\n            rsp.ParseFromString(b)\n        return MessageToJson(rsp)\n    else:\n        raise Exception(\"binary2str: unknown proto format.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef binary2pb(b, proto_id, proto_fmt_type):\n    rsp = pb_map[proto_id]\n    if rsp is None:\n        return None\n    if proto_fmt_type == ProtoFMT.Json:\n        return json2pb(type(rsp), b.decode('utf-8'))\n    elif proto_fmt_type == ProtoFMT.Protobuf:\n        rsp = type(rsp)()\n        # logger.debug((proto_id))\n        if IS_PY2:\n            rsp.ParseFromString(str(b))\n        else:\n            rsp.ParseFromString(b)\n        return rsp\n    else:\n        raise Exception(\"binary2str: unknown proto format.\")", "response": "Transfer binary to protobuf message\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trailing_stop(api_svr_ip='127.0.0.1', api_svr_port=11111, unlock_password=\"\", code='HK.00700',\n                  trade_env=ft.TrdEnv.SIMULATE, method=TrailingMethod.DROP_ABS, drop=1.0, volume=100,\n                  how_to_sell=SellMethod.SMART_SELL, diff=0, rest_time=2,\n                  enable_email_notification=False, receiver=''):\n    \"\"\"\n    \u6b62\u635f\u7b56\u7565\u51fd\u6570\n    :param api_svr_ip: (string)ip\n    :param api_svr_port: (int)port\n    :param unlock_password: (string)\u4ea4\u6613\u89e3\u9501\u5bc6\u7801, \u5fc5\u9700\u4fee\u6539! \u6a21\u62df\u4ea4\u6613\u8bbe\u4e3a\u4e00\u4e2a\u975e\u7a7a\u5b57\u7b26\u4e32\u5373\u53ef\n    :param code: (string)\u80a1\u7968\n    :param trade_env: ft.TrdEnv.REAL: \u771f\u5b9e\u4ea4\u6613 ft.TrdEnv.SIMULATE: \u6a21\u62df\u4ea4\u6613\n    :param method: method == TrailingMethod.DROP_ABS: \u80a1\u7968\u4e0b\u8dccdrop\u4ef7\u683c\u5c31\u4f1a\u6b62\u635f  railingMethod.DROP_PER: \u80a1\u7968\u4e0b\u8dccdrop\u7684\u767e\u5206\u6bd4\u5c31\u4f1a\u6b62\u635f\n    :param drop: method == TrailingMethod.DROP_ABS, \u80a1\u7968\u4e0b\u8dcc\u7684\u4ef7\u683c   method == TrailingMethod.DROP_PER\uff0c\u80a1\u7968\u4e0b\u8dcc\u7684\u767e\u5206\u6bd4\uff0c0.01\u8868\u793a\u4e0b\u8dcc1%\u5219\u6b62\u635f\n    :param volume: \u9700\u8981\u5356\u6389\u7684\u80a1\u7968\u6570\u91cf\n    :param how_to_sell: \u4ee5\u4f55\u79cd\u65b9\u5f0f\u5356\u51fa\u80a1\u7968\uff0c SellMethod \u7c7b\u578b\n    :param diff: \u9ed8\u8ba4\u4e3a0\uff0c\u5f53how_to_sell\u4e3aSellMethod.DROP_ABS\u65f6\uff0c\u4ee5(\u5e02\u4ef7-diff)\u7684\u4ef7\u683c\u5356\u51fa\n    :param rest_time: \u6bcf\u9694REST_TIME\u79d2\uff0c\u4f1a\u68c0\u67e5\u8ba2\u5355\u72b6\u6001, \u9700\u8981>=2\n    :param enable_email_notification: \u6fc0\u6d3bemail\u529f\u80fd\n    :param receiver: \u90ae\u4ef6\u63a5\u6536\u8005\n    \"\"\"\n    EmailNotification.set_enable(enable_email_notification)\n\n    if how_to_sell not in [SellMethod.SIMPLE_SELL, SellMethod.SMART_SELL]:\n        raise Exception('how_to_sell value error')\n\n    if method not in [TrailingMethod.DROP_ABS, TrailingMethod.DROP_PER]:\n        raise Exception('method value error')\n\n    quote_ctx = ft.OpenQuoteContext(host=api_svr_ip, port=api_svr_port)\n    is_hk_trade = 'HK.' in code\n    if is_hk_trade:\n        trade_ctx = ft.OpenHKTradeContext(host=api_svr_ip, port=api_svr_port)\n    else:\n        trade_ctx = ft.OpenUSTradeContext(host=api_svr_ip, port=api_svr_port)\n\n    if unlock_password == \"\":\n        raise Exception('\u8bf7\u5148\u914d\u7f6e\u4ea4\u6613\u5bc6\u7801')\n\n    ret, data = trade_ctx.unlock_trade(unlock_password)\n    if ret != ft.RET_OK:\n        raise Exception('\u89e3\u9501\u4ea4\u6613\u5931\u8d25')\n\n    ret, data = trade_ctx.position_list_query(trd_env=trd_env)\n    if ret != ft.RET_OK:\n        raise Exception(\"\u65e0\u6cd5\u83b7\u53d6\u6301\u4ed3\u5217\u8868\")\n\n    try:\n        qty = data[data['code'] == code].iloc[0]['qty']\n    except:\n        raise Exception('\u4f60\u6ca1\u6709\u6301\u4ed3\uff01\u65e0\u6cd5\u4e70\u5356')\n\n    qty = int(qty)\n    if volume == 0:\n        volume = qty\n    if volume < 0:\n        raise Exception('volume lower than  0')\n    elif qty < volume:\n        raise Exception('\u6301\u4ed3\u4e0d\u8db3')\n\n    ret, data = quote_ctx.get_market_snapshot(code)\n    if ret != ft.RET_OK:\n        raise Exception('\u83b7\u53d6lot size\u5931\u8d25')\n    lot_size = data.iloc[0]['lot_size']\n\n    if volume % lot_size != 0:\n        raise Exception('volume \u5fc5\u987b\u662f{}\u7684\u6574\u6570\u500d'.format(lot_size))\n\n    ret, data = quote_ctx.subscribe(code, ft.SubType.QUOTE)\n    if ret != ft.RET_OK:\n        raise Exception('\u8ba2\u9605QUOTE\u9519\u8bef: error {}:{}'.format(ret, data))\n\n    ret, data = quote_ctx.subscribe(code, ft.SubType.ORDER_BOOK)\n    if ret != ft.RET_OK:\n        print('error {}:{}'.format(ret, data))\n        raise Exception('\u8ba2\u9605order book\u5931\u8d25: error {}:{}'.format(ret, data))\n\n    if diff:\n        if is_hk_trade:\n            ret, data = quote_ctx.get_order_book(code)\n            if ret != ft.RET_OK:\n                raise Exception('\u83b7\u53d6order book\u5931\u8d25: cannot get order book'.format(data))\n\n            min_diff = round(abs(data['Bid'][0][0] - data['Bid'][1][0]), 3)\n            if floor(diff / min_diff) * min_diff != diff:\n                raise Exception('diff \u5e94\u662f{}\u7684\u6574\u6570\u500d'.format(min_diff))\n        else:\n            if round(diff, 2) != diff:\n                raise Exception('\u7f8e\u80a1\u4ef7\u5dee\u4fdd\u75592\u4f4d\u5c0f\u6570{}->{}'.format(diff, round(diff, 2)))\n\n    if method == TrailingMethod.DROP_ABS:\n        if is_hk_trade:\n            if floor(drop / min_diff) * min_diff != drop:\n                raise Exception('drop\u5fc5\u987b\u662f{}\u7684\u6574\u6570\u500d'.format(min_diff))\n        else:\n            if round(drop, 2) != drop:\n                raise Exception('drop\u5fc5\u987b\u4fdd\u75592\u4f4d\u5c0f\u6570{}->{}'.format(drop, round(drop, 2)))\n\n    elif method == TrailingMethod.DROP_PER:\n        if drop < 0 or drop > 1:\n            raise Exception('drop must in [0, 1] if method is DROP_PER')\n\n    trailing_stop_handler = TrailingStopHandler(quote_ctx, is_hk_trade, method, drop)\n    quote_ctx.set_handler(trailing_stop_handler)\n    quote_ctx.start()\n    while True:\n        if trailing_stop_handler.finished:\n            # sell the stock\n            qty = volume\n            sell_price = trailing_stop_handler.stop\n            while qty > 0:\n                if how_to_sell == SellMethod.SIMPLE_SELL:\n                    data = simple_sell(quote_ctx, trade_ctx, code, sell_price - diff, qty, trade_env, ft.OrderType.SPECIAL_LIMIT)\n                else:\n                    data = smart_sell(quote_ctx, trade_ctx, code, qty, trade_env, ft.OrderType.SPECIAL_LIMIT)\n                if data is None:\n                    print('\u4e0b\u5355\u5931\u8d25')\n                    EmailNotification.send_email(receiver, '\u4e0b\u5355\u5931\u8d25', '\u80a1\u7968\u4ee3\u7801{}\uff0c\u6570\u91cf{}'.format(code, volume))\n                    sleep(rest_time)\n                    continue\n\n                order_id = data.iloc[0]['order_id']\n                sleep(rest_time)\n\n                while True:\n                    ret, data = trade_ctx.order_list_query(order_id=order_id, trd_env=trade_env)\n                    if ret != ft.RET_OK:\n                        sleep(rest_time)\n                        continue\n\n                    status = data.iloc[0]['order_status']\n                    dealt_qty = int(data.iloc[0]['dealt_qty'])\n                    order_price = data.iloc[0]['price']\n                    qty -= dealt_qty\n\n                    if status == ft.OrderStatus.FILLED_ALL:\n                        print('\u5168\u90e8\u6210\u4ea4:\u80a1\u7968\u4ee3\u7801{}, \u6210\u4ea4\u603b\u6570{}\uff0c\u4ef7\u683c{}'.format(code, dealt_qty, order_price))\n                        EmailNotification.send_email(receiver, '\u5168\u90e8\u6210\u4ea4', '\u80a1\u7968\u4ee3\u7801{}\uff0c\u6210\u4ea4\u603b\u6570{}\uff0c\u4ef7\u683c{}'\n                                                     .format(code, dealt_qty, order_price))\n                        break\n                    elif status == ft.OrderStatus.FILLED_PART:\n                        print('\u90e8\u5206\u6210\u4ea4:\u80a1\u7968\u4ee3\u7801{}\uff0c\u6210\u4ea4\u603b\u6570{}\uff0c\u4ef7\u683c{}'.format(code, dealt_qty, order_price))\n                        EmailNotification.send_email(receiver, '\u90e8\u5206\u6210\u4ea4', '\u80a1\u7968\u4ee3\u7801{}\uff0c\u6210\u4ea4\u603b\u6570{}\uff0c\u4ef7\u683c{}'\n                                                     .format(code, dealt_qty, order_price))\n                        break\n                    elif status == ft.OrderStatus.FAILED or status == ft.OrderStatus.SUBMIT_FAILED or \\\n                                    status == ft.OrderStatus.CANCELLED_ALL or status == ft.OrderStatus.DELETED:\n                        break\n                    else:\n                        trade_ctx.modify_order(ft.ModifyOrderOp.CANCEL, order_id, 0, 0)\n                        sleep(rest_time)\n                        continue\n\n                if how_to_sell == SellMethod.SIMPLE_SELL:\n                    ret, data = quote_ctx.get_order_book(code)\n                    if ret != ft.RET_OK:\n                        raise Exception('\u83b7\u53d6order_book\u5931\u8d25')\n                    sell_price = data['Bid'][0][0]\n\n            # draw price and stop\n            price_lst = trailing_stop_handler.price_lst\n            plt.plot(np.arange(len(price_lst)), price_lst)\n            stop_list = trailing_stop_handler.stop_lst\n            plt.plot(np.arange(len(stop_list)), stop_list)\n            break\n\n    quote_ctx.close()\n    trade_ctx.close()", "response": "\u6b62\u635f\u7b56\u7565\u51fd\u6570\n    :param api_svr_ip: (string)ip\n    :param api_svr_port: (int)port\n    :param unlock_password: (string)\u4ea4\u6613\u89e3\u9501\u5bc6\u7801, \u5fc5\u9700\u4fee\u6539! \u6a21\u62df\u4ea4\u6613\u8bbe\u4e3a\u4e00\u4e2a\u975e\u7a7a\u5b57\u7b26\u4e32\u5373\u53ef\n    :param code: (string)\u80a1\u7968\n    :param trade_env: ft.TrdEnv.REAL: \u771f\u5b9e\u4ea4\u6613 ft.TrdEnv.SIMULATE: \u6a21\u62df\u4ea4\u6613\n    :param method: method == TrailingMethod.DROP_ABS: \u80a1\u7968\u4e0b\u8dccdrop\u4ef7\u683c\u5c31\u4f1a\u6b62\u635f  railingMethod.DROP_PER: \u80a1\u7968\u4e0b\u8dccdrop\u7684\u767e\u5206\u6bd4\u5c31\u4f1a\u6b62\u635f\n    :param drop: method == TrailingMethod.DROP_ABS, \u80a1\u7968\u4e0b\u8dcc\u7684\u4ef7\u683c   method == TrailingMethod.DROP_PER\uff0c\u80a1\u7968\u4e0b\u8dcc\u7684\u767e\u5206\u6bd4\uff0c0.01\u8868\u793a\u4e0b\u8dcc1%\u5219\u6b62\u635f\n    :param volume: \u9700\u8981\u5356\u6389\u7684\u80a1\u7968\u6570\u91cf\n    :param how_to_sell: \u4ee5\u4f55\u79cd\u65b9\u5f0f\u5356\u51fa\u80a1\u7968\uff0c SellMethod \u7c7b\u578b\n    :param diff: \u9ed8\u8ba4\u4e3a0\uff0c\u5f53how_to_sell\u4e3aSellMethod.DROP_ABS\u65f6\uff0c\u4ee5(\u5e02\u4ef7-diff)\u7684\u4ef7\u683c\u5356\u51fa\n    :param rest_time: \u6bcf\u9694REST_TIME\u79d2\uff0c\u4f1a\u68c0\u67e5\u8ba2\u5355\u72b6\u6001, \u9700\u8981>=2\n    :param enable_email_notification: \u6fc0\u6d3bemail\u529f\u80fd\n    :param receiver: \u90ae\u4ef6\u63a5\u6536\u8005"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_recv_rsp(self, rsp_str):\n        ret, content = super(TrailingStopHandler, self).on_recv_rsp(rsp_str)\n        if ret != ft.RET_OK:\n            print('StockQuote error {}'.format(content))\n            return ret, content\n        if self.finished:\n            return ret, content\n        ret, data = self.quote_ctx.get_global_state()\n        if ret != ft.RET_OK:\n            print('\u83b7\u53d6\u5168\u5c40\u72b6\u6001\u5931\u8d25')\n            trading = False\n        else:\n            hk_trading = (data['market_hk'] == ft.MarketState.MORNING or data['market_hk'] == ft.MarketState.AFTERNOON)\n            us_trading = (data['market_us'] == ft.MarketState.MORNING)\n            trading = hk_trading if self.is_hk_trade else us_trading\n\n        if not trading:\n            print('\u4e0d\u5904\u5728\u4ea4\u6613\u65f6\u95f4\u6bb5')\n            return ft.RET_OK, content\n        last_price = content.iloc[0]['last_price']\n\n        if self.stop is None:\n            self.stop = last_price - self.drop if self.method == TrailingMethod.DROP_ABS else last_price * (1 - self.drop)\n        elif (self.stop + self.drop < last_price) if self.method == TrailingMethod.DROP_ABS else (self.stop < last_price * (1 - self.drop)):\n            self.stop = last_price - self.drop if self.method == TrailingMethod.DROP_ABS else last_price * (1 - self.drop)\n        elif self.stop >= last_price:\n            # \u4ea4\u6613\u5df1\u88ab\u89e6\u53d1\n            self.finished = True\n            print('\u4ea4\u6613\u88ab\u89e6\u53d1')\n\n        self.price_lst.append(last_price)\n        self.stop_lst.append(self.stop)\n        print('last_price is {}, stop is {}'.format(last_price, self.stop))\n\n        return ft.RET_OK, content", "response": "This method is called when the response is received from the stock quote."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef context_setting(self):\n        if self.unlock_password == \"\":\n            raise Exception(\"\u8bf7\u5148\u914d\u7f6e\u4ea4\u6613\u89e3\u9501\u5bc6\u7801! password: {}\".format(\n                self.unlock_password))\n\n        quote_ctx = ft.OpenQuoteContext(\n            host=self.api_svr_ip, port=self.api_svr_port)\n\n        if 'HK.' in self.stock:\n            trade_ctx = ft.OpenHKTradeContext(\n                host=self.api_svr_ip, port=self.api_svr_port)\n\n            if self.trade_env == ft.TrdEnv.REAL:\n                ret_code, ret_data = trade_ctx.unlock_trade(\n                    self.unlock_password)\n                if ret_code == ft.RET_OK:\n                    print('\u89e3\u9501\u4ea4\u6613\u6210\u529f!')\n                else:\n                    raise Exception(\"\u8bf7\u6c42\u4ea4\u6613\u89e3\u9501\u5931\u8d25: {}\".format(ret_data))\n            else:\n                print('\u89e3\u9501\u4ea4\u6613\u6210\u529f!')\n        elif 'US.' in self.stock:\n            if self.trade_env != 0:\n                raise Exception(\"\u7f8e\u80a1\u4ea4\u6613\u63a5\u53e3\u4e0d\u652f\u6301\u4eff\u771f\u73af\u5883 trade_env: {}\".format(\n                    self.trade_env))\n            trade_ctx = ft.OpenUSTradeContext(\n                host=self.api_svr_ip, port=self.api_svr_port)\n        else:\n            raise Exception(\"stock\u8f93\u5165\u9519\u8bef stock: {}\".format(self.stock))\n\n        return quote_ctx, trade_ctx", "response": "API trading and quote context setting"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling stock data for trading signal and make order", "response": "def handle_data(self):\n        \"\"\"\n        handle stock data for trading signal, and make order\n        \"\"\"\n        # \u8bfb\u53d6\u5386\u53f2\u6570\u636e\uff0c\u4f7f\u7528sma\u65b9\u5f0f\u8ba1\u7b97\u5747\u7ebf\u51c6\u786e\u5ea6\u548c\u6570\u636e\u957f\u5ea6\u65e0\u5173\uff0c\u4f46\u662f\u5728\u4f7f\u7528ema\u65b9\u5f0f\u8ba1\u7b97\u5747\u7ebf\u65f6\u5efa\u8bae\u5c06\u5386\u53f2\u6570\u636e\u7a97\u53e3\u9002\u5f53\u653e\u5927\uff0c\u7ed3\u679c\u4f1a\u66f4\u52a0\u51c6\u786e\n        today = datetime.datetime.today()\n        pre_day = (today - datetime.timedelta(days=self.observation)\n                   ).strftime('%Y-%m-%d')\n        end_dt = today.strftime('%Y-%m-%d')\n        ret_code, prices = self.quote_ctx.get_history_kline(self.stock, start=pre_day, end=end_dt, ktype=ft.KLType.K_DAY)\n        if ret_code != ft.RET_OK:\n            print(\"get_history_kline fail: {}\".format(prices))\n            return\n\n        # \u7528talib\u8ba1\u7b97MACD\u53d6\u503c\uff0c\u5f97\u5230\u4e09\u4e2a\u65f6\u95f4\u5e8f\u5217\u6570\u7ec4\uff0c\u5206\u522b\u4e3a macd, signal \u548c hist\n        # macd \u662f\u957f\u77ed\u5747\u7ebf\u7684\u5dee\u503c\uff0csignal \u662f macd \u7684\u5747\u7ebf\n        # \u4f7f\u7528 macd \u7b56\u7565\u6709\u51e0\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u6211\u4eec\u8fd9\u91cc\u91c7\u7528 macd \u7ebf\u7a81\u7834 signal \u7ebf\u7684\u5224\u65ad\u65b9\u6cd5\n        macd, signal, hist = talib.MACD(prices['close'].values,\n                                        self.short_period, self.long_period,\n                                        self.smooth_period)\n\n        # \u5982\u679cmacd\u4ece\u4e0a\u5f80\u4e0b\u8dcc\u7834macd_signal\n        if macd[-1] < signal[-1] and macd[-2] > signal[-2]:\n            # \u8ba1\u7b97\u73b0\u5728portfolio\u4e2d\u80a1\u7968\u7684\u4ed3\u4f4d\n            ret_code, data = self.trade_ctx.position_list_query(\n                trd_env=self.trade_env)\n\n            if ret_code != ft.RET_OK:\n                raise Exception('\u8d26\u6237\u4fe1\u606f\u83b7\u53d6\u5931\u8d25: {}'.format(data))\n            pos_info = data.set_index('code')\n\n            cur_pos = int(pos_info['qty'][self.stock])\n            # \u8fdb\u884c\u6e05\u4ed3\n            if cur_pos > 0:\n                ret_code, data = self.quote_ctx.get_market_snapshot(\n                    [self.stock])\n                if ret_code != 0:\n                    raise Exception('\u5e02\u573a\u5feb\u7167\u6570\u636e\u83b7\u53d6\u5f02\u5e38 {}'.format(data))\n                cur_price = data['last_price'][0]\n                ret_code, ret_data = self.trade_ctx.place_order(\n                    price=cur_price,\n                    qty=cur_pos,\n                    code=self.stock,\n                    trd_side=ft.TrdSide.SELL,\n                    order_type=ft.OrderType.NORMAL,\n                    trd_env=self.trade_env)\n                if ret_code == ft.RET_OK:\n                    print('stop_loss MAKE SELL ORDER\\n\\tcode = {} price = {} quantity = {}'\n                          .format(self.stock, cur_price, cur_pos))\n                else:\n                    print('stop_loss: MAKE SELL ORDER FAILURE: {}'.format(ret_data))\n\n        # \u5982\u679c\u77ed\u5747\u7ebf\u4ece\u4e0b\u5f80\u4e0a\u7a81\u7834\u957f\u5747\u7ebf\uff0c\u4e3a\u5165\u573a\u4fe1\u53f7\n        if macd[-1] > signal[-1] and macd[-2] < signal[-2]:\n            # \u6ee1\u4ed3\u5165\u80a1\n            ret_code, acc_info = self.trade_ctx.accinfo_query(\n                trd_env=self.trade_env)\n            if ret_code != 0:\n                raise Exception('\u8d26\u6237\u4fe1\u606f\u83b7\u53d6\u5931\u8d25! \u8bf7\u91cd\u8bd5: {}'.format(acc_info))\n\n            ret_code, snapshot = self.quote_ctx.get_market_snapshot(\n                [self.stock])\n            if ret_code != 0:\n                raise Exception('\u5e02\u573a\u5feb\u7167\u6570\u636e\u83b7\u53d6\u5f02\u5e38 {}'.format(snapshot))\n            lot_size = snapshot['lot_size'][0]\n            cur_price = snapshot['last_price'][0]\n            cash = acc_info['Power'][0]  # \u8d2d\u4e70\u529b\n            qty = int(math.floor(cash / cur_price))\n            qty = qty // lot_size * lot_size\n\n            ret_code, ret_data = self.trade_ctx.place_order(\n                price=cur_price,\n                qty=qty,\n                code=self.stock,\n                trd_side=ft.TrdSide.BUY,\n                order_type=ft.OrderType.NORMAL,\n                trd_env=self.trade_env)\n            if not ret_code:\n                print(\n                    'stop_loss MAKE BUY ORDER\\n\\tcode = {} price = {} quantity = {}'\n                    .format(self.stock, cur_price, qty))\n            else:\n                print('stop_loss: MAKE BUY ORDER FAILURE: {}'.format(ret_data))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_handler(self, handler):\n        with self._lock:\n            if self._handler_ctx is not None:\n                return self._handler_ctx.set_handler(handler)\n        return RET_ERROR", "response": "set handler to the current instance of the handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsynchronize the query processor :param pack_func: back :param unpack_func: unpack :return: sync_query_processor", "response": "def _get_sync_query_processor(self, pack_func, unpack_func, is_create_socket=True):\n        \"\"\"\n        synchronize the query processor\n        :param pack_func: back\n        :param unpack_func: unpack\n        :return: sync_query_processor\n        \"\"\"\n\n        def sync_query_processor(**kargs):\n            \"\"\"sync query processor\"\"\"\n            while True:\n                with self._lock:\n                    if self._status == ContextStatus.Ready:\n                        net_mgr = self._net_mgr\n                        conn_id = self._conn_id\n                        break\n                sleep(0.01)\n\n            try:\n                ret_code, msg, req_str = pack_func(**kargs)\n                if ret_code != RET_OK:\n                    return ret_code, msg, None\n\n                ret_code, msg, rsp_str = net_mgr.sync_query(conn_id, req_str)\n                if ret_code != RET_OK:\n                    return ret_code, msg, None\n\n                ret_code, msg, content = unpack_func(rsp_str)\n                if ret_code != RET_OK:\n                    return ret_code, msg, None\n            except Exception as e:\n                logger.error(traceback.format_exc())\n                return RET_ERROR, str(e), None\n\n            return RET_OK, msg, content\n\n        return sync_query_processor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _socket_reconnect_and_wait_ready(self):\n        logger.info(\"Start connecting: host={}; port={};\".format(self.__host, self.__port))\n        with self._lock:\n            self._status = ContextStatus.Connecting\n            # logger.info(\"try connecting: host={}; port={};\".format(self.__host, self.__port))\n            ret, msg, conn_id = self._net_mgr.connect((self.__host, self.__port), self, 5)\n            if ret == RET_OK:\n                self._conn_id = conn_id\n            else:\n                logger.warning(msg)\n\n        if ret == RET_OK:\n            while True:\n                with self._lock:\n                    if self._sync_req_ret is not None:\n                        if self._sync_req_ret.ret == RET_OK:\n                            self._status = ContextStatus.Ready\n                        else:\n                            ret, msg = self._sync_req_ret.ret, self._sync_req_ret.msg\n                        self._sync_req_ret = None\n                        break\n                sleep(0.01)\n\n        if ret == RET_OK:\n            ret, msg = self.on_api_socket_reconnected()\n        else:\n            self._wait_reconnect()\n        return RET_OK, ''", "response": "Connect to the server and wait for the connection to be ready."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget global state of a single instance of a class", "response": "def get_global_state(self):\n        \"\"\"\n        \u83b7\u53d6\u5168\u5c40\u72b6\u6001\n\n        :return: (ret, data)\n\n                ret == RET_OK data\u4e3a\u5305\u542b\u5168\u5c40\u72b6\u6001\u7684\u5b57\u5178\uff0c\u542b\u4e49\u5982\u4e0b\n\n                ret != RET_OK data\u4e3a\u9519\u8bef\u63cf\u8ff0\u5b57\u7b26\u4e32\n\n                =====================   ===========   ==============================================================\n                key                      value\u7c7b\u578b                        \u8bf4\u660e\n                =====================   ===========   ==============================================================\n                market_sz               str            \u6df1\u5733\u5e02\u573a\u72b6\u6001\uff0c\u53c2\u89c1MarketState\n                market_us               str            \u7f8e\u56fd\u5e02\u573a\u72b6\u6001\uff0c\u53c2\u89c1MarketState\n                market_sh               str            \u4e0a\u6d77\u5e02\u573a\u72b6\u6001\uff0c\u53c2\u89c1MarketState\n                market_hk               str            \u9999\u6e2f\u5e02\u573a\u72b6\u6001\uff0c\u53c2\u89c1MarketState\n                market_future           str            \u9999\u6e2f\u671f\u8d27\u5e02\u573a\u72b6\u6001\uff0c\u53c2\u89c1MarketState\n                server_ver              str            FutuOpenD\u7248\u672c\u53f7\n                trd_logined             str            '1'\uff1a\u5df2\u767b\u5f55\u4ea4\u6613\u670d\u52a1\u5668\uff0c'0': \u672a\u767b\u5f55\u4ea4\u6613\u670d\u52a1\u5668\n                qot_logined             str            '1'\uff1a\u5df2\u767b\u5f55\u884c\u60c5\u670d\u52a1\u5668\uff0c'0': \u672a\u767b\u5f55\u884c\u60c5\u670d\u52a1\u5668\n                timestamp               str            Futu\u540e\u53f0\u670d\u52a1\u5668\u5f53\u524d\u65f6\u95f4\u6233(\u79d2)\n                local_timestamp         double         FutuOpenD\u8fd0\u884c\u673a\u5668\u5f53\u524d\u65f6\u95f4\u6233(\n                =====================   ===========   ==============================================================\n        :example:\n\n        .. code:: python\n\n        from futuquant import *\n        quote_ctx = OpenQuoteContext(host='127.0.0.1', port=11111)\n        print(quote_ctx.get_global_state())\n        quote_ctx.close()\n        \"\"\"\n        query_processor = self._get_sync_query_processor(\n            GlobalStateQuery.pack_req, GlobalStateQuery.unpack_rsp)\n\n        kargs = {\n            'user_id': self.get_login_user_id(),\n            'conn_id': self.get_sync_conn_id(),\n        }\n        ret_code, msg, state_dict = query_processor(**kargs)\n        if ret_code != RET_OK:\n            return ret_code, msg\n\n        return RET_OK, state_dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_order_and_cancel(api_svr_ip, api_svr_port, unlock_password, test_code, trade_env, acc_id):\n    if unlock_password == \"\":\n        raise Exception(\"\u8bf7\u5148\u914d\u7f6e\u4ea4\u6613\u89e3\u9501\u5bc6\u7801!\")\n\n    quote_ctx = ft.OpenQuoteContext(host=api_svr_ip, port=api_svr_port)  # \u521b\u5efa\u884c\u60c5api\n    quote_ctx.subscribe(test_code, ft.SubType.ORDER_BOOK) # \u5b9a\u9605\u6446\u76d8\n\n    # \u521b\u5efa\u4ea4\u6613api\n    is_hk_trade = 'HK.' in test_code\n    if is_hk_trade:\n        trade_ctx = ft.OpenHKTradeContext(host=api_svr_ip, port=api_svr_port)\n    else:\n        trade_ctx = ft.OpenUSTradeContext(host=api_svr_ip, port=api_svr_port)\n\n    # \u6bcf\u624b\u80a1\u6570\n    lot_size = 0\n    is_unlock_trade = False\n    is_fire_trade = False\n    while not is_fire_trade:\n        sleep(2)\n        # \u89e3\u9501\u4ea4\u6613\n        if not is_unlock_trade and trade_env == ft.TrdEnv.REAL:\n            print(\"unlocking trade...\")\n            ret_code, ret_data = trade_ctx.unlock_trade(unlock_password)\n            is_unlock_trade = (ret_code == ft.RET_OK)\n            if not is_unlock_trade:\n                print(\"\u8bf7\u6c42\u4ea4\u6613\u89e3\u9501\u5931\u8d25\uff1a{}\".format(ret_data))\n                break\n\n        if lot_size == 0:\n            print(\"get lotsize...\")\n            ret, data = quote_ctx.get_market_snapshot(test_code)\n            lot_size = data.iloc[0]['lot_size'] if ret == ft.RET_OK else 0\n            if ret != ft.RET_OK:\n                print(\"\u53d6\u4e0d\u5230\u6bcf\u624b\u4fe1\u606f\uff0c\u91cd\u8bd5\u4e2d: {}\".format(data))\n                continue\n            elif lot_size <= 0:\n                raise BaseException(\"\u8be5\u80a1\u7968\u6bcf\u624b\u4fe1\u606f\u9519\u8bef\uff0c\u53ef\u80fd\u4e0d\u652f\u6301\u4ea4\u6613 code ={}\".format(test_code))\n\n        print(\"get order book...\")\n        ret, data = quote_ctx.get_order_book(test_code)  # \u5f97\u5230\u7b2c\u5341\u6863\u6570\u636e\n        if ret != ft.RET_OK:\n            continue\n\n        # \u8ba1\u7b97\u4ea4\u6613\u4ef7\u683c\n        bid_order_arr = data['Bid']\n        if is_hk_trade:\n            if len(bid_order_arr) != 10:\n                continue\n            # \u6e2f\u80a1\u4e0b\u5355: \u4ef7\u683c\u5b9a\u4e3a\u7b2c\u5341\u6863\n            price, _, _ = bid_order_arr[9]\n        else:\n            if len(bid_order_arr) == 0:\n                continue\n            # \u7f8e\u80a1\u4e0b\u5355\uff1a \u4ef7\u683c\u5b9a\u4e3a\u4e00\u6863\u964d10%\n            price, _, _ = bid_order_arr[0]\n            price = round(price * 0.9, 2)\n\n        qty = lot_size\n\n        # \u4ef7\u683c\u548c\u6570\u91cf\u5224\u65ad\n        if qty == 0 or price == 0.0:\n            continue\n\n        # \u4e0b\u5355\n        order_id = 0\n        print(\"place order : price={} qty={} code={}\".format(price, qty, test_code))\n        ret_code, ret_data = trade_ctx.place_order(price=price, qty=qty, code=test_code, trd_side=ft.TrdSide.BUY,\n                                                   order_type=ft.OrderType.NORMAL, trd_env=trade_env, acc_id=acc_id)\n        is_fire_trade = True\n        print('\u4e0b\u5355ret={} data={}'.format(ret_code, ret_data))\n        if ret_code == ft.RET_OK:\n            row = ret_data.iloc[0]\n            order_id = row['order_id']\n\n        # \u5faa\u73af\u64a4\u5355\n        sleep(2)\n\n\n        if order_id:\n            while True:\n                ret_code, ret_data = trade_ctx.order_list_query(order_id=order_id, status_filter_list=[], code='',\n                                                                start='', end='', trd_env=trade_env, acc_id=acc_id)\n\n                if ret_code != ft.RET_OK:\n                    sleep(2)\n                    continue\n                order_status = ret_data.iloc[0]['order_status']\n                if order_status in [ft.OrderStatus.SUBMIT_FAILED, ft.OrderStatus.TIMEOUT, ft.OrderStatus.FILLED_ALL,\n                                    ft.OrderStatus.FAILED, ft.OrderStatus.DELETED]:\n                    break\n\n                print(\"cancel order...\")\n                ret_code, ret_data = trade_ctx.modify_order(modify_order_op=ft.ModifyOrderOp.CANCEL, order_id=order_id,\n                                price=price, qty=qty, adjust_limit=0, trd_env=trade_env, acc_id=acc_id)\n                print(\"\u64a4\u5355ret={} data={}\".format(ret_code, ret_data))\n                if ret_code == ft.RET_OK:\n                    break\n                else:\n                    sleep(2)\n    # destroy object\n    quote_ctx.close()\n    trade_ctx.close()", "response": "This function creates a new order book and cancels it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the internal array with the contents of the given bar.", "response": "def updateBar(self, bar):\n        \"\"\"\u66f4\u65b0K\u7ebf\"\"\"\n        self.count += 1\n        if not self.inited and self.count >= self.size:\n            self.inited = True\n\n        self.openArray[0:self.size - 1] = self.openArray[1:self.size]\n        self.highArray[0:self.size - 1] = self.highArray[1:self.size]\n        self.lowArray[0:self.size - 1] = self.lowArray[1:self.size]\n        self.closeArray[0:self.size - 1] = self.closeArray[1:self.size]\n        self.volumeArray[0:self.size - 1] = self.volumeArray[1:self.size]\n\n        self.openArray[-1] = bar.open\n        self.highArray[-1] = bar.high\n        self.lowArray[-1] = bar.low\n        self.closeArray[-1] = bar.close\n        self.volumeArray[-1] = bar.volume"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sma(self, n, array=False):\n        result = talib.SMA(self.close, n)\n        if array:\n            return result\n        return result[-1]", "response": "SMA \u5927\u4e8e n \u5355\u5747\u7ebf"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets n standard deviations", "response": "def std(self, n, array=False):\n        \"\"\"\u6807\u51c6\u5dee\"\"\"\n        result = talib.STDDEV(self.close, n)\n        if array:\n            return result\n        return result[-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget n most recent CCI", "response": "def cci(self, n, array=False):\n        \"\"\"CCI\u6307\u6807\"\"\"\n        result = talib.CCI(self.high, self.low, self.close, n)\n        if array:\n            return result\n        return result[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the n most recent ATR", "response": "def atr(self, n, array=False):\n        \"\"\"ATR\u6307\u6807\"\"\"\n        result = talib.ATR(self.high, self.low, self.close, n)\n        if array:\n            return result\n        return result[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef adx(self, n, array=False):\n        result = talib.ADX(self.high, self.low, self.close, n)\n        if array:\n            return result\n        return result[-1]", "response": "ADX \u6307\u6807 n - 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the up and down kelts for a given dev", "response": "def keltner(self, n, dev, array=False):\n        \"\"\"\u80af\u7279\u7eb3\u901a\u9053\"\"\"\n        mid = self.sma(n, array)\n        atr = self.atr(n, array)\n\n        up = mid + atr * dev\n        down = mid - atr * dev\n\n        return up, down"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the donchian and donchian talib.", "response": "def donchian(self, n, array=False):\n        \"\"\"\u5510\u5947\u5b89\u901a\u9053\"\"\"\n        up = talib.MAX(self.high, n)\n        down = talib.MIN(self.low, n)\n\n        if array:\n            return up, down\n        return up[-1], down[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreceives response callback function", "response": "def on_recv_rsp(self, rsp_pb):\n        \"\"\"receive response callback function\"\"\"\n        ret_code, ret_data = UpdateOrderPush.unpack_rsp(rsp_pb)\n\n        if ret_code != RET_OK:\n            return ret_code, ret_data\n        else:\n            order_dict = ret_data\n            col_list = ['trd_env', 'code', 'stock_name', 'dealt_avg_price', 'dealt_qty',\n                        'qty', 'order_id', 'order_type', 'price', 'order_status',\n                        'create_time', 'updated_time', 'trd_side', 'last_err_msg', 'trd_market',\n                        ]\n\n            trade_frame_table = pd.DataFrame([order_dict], columns=col_list)\n            return RET_OK, trade_frame_table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_recv_rsp(self, rsp_pb):\n        ret_code, ret_data = UpdateDealPush.unpack_rsp(rsp_pb)\n\n        if ret_code != RET_OK:\n            return ret_code, ret_data\n        else:\n            deal_dict = ret_data\n            col_list = ['trd_env', 'code', 'stock_name', 'deal_id', 'order_id',\n                        'qty', 'price', 'trd_side', 'create_time', 'counter_broker_id',\n                        'counter_broker_name', 'trd_market',\n                        ]\n\n            trade_frame_table = pd.DataFrame([deal_dict], columns=col_list)\n            return RET_OK, trade_frame_table", "response": "receive response callback function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreceiving response callback function", "response": "def on_recv_rsp(self, rsp_pb):\n        \"\"\"receive response callback function\"\"\"\n        ret_code, msg, _= SubAccPush.unpack_rsp(rsp_pb)\n\n        if self._notify_obj is not None:\n            self._notify_obj.on_async_sub_acc_push(ret_code, msg)\n\n        return ret_code, msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the column of the relation.", "response": "def relation_column(instance, fields):\n    '''\n    such as: user.username\n    such as: replies.content\n    '''\n    relation = getattr(instance.__class__, fields[0]).property\n    _field = getattr(instance, fields[0])\n    if relation.lazy == 'dynamic':\n        _field = _field.first()\n    return getattr(_field, fields[1]) if _field else ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _index(self, model):\n        '''\n        get index\n        '''\n        index_name = self.index_name\n        if hasattr(model, \"__msearch_index__\"):\n            index_name = model.__msearch_index__\n\n        name = model\n        if not isinstance(model, str):\n            name = model.__table__.name\n        if name not in self._indexs:\n            self._indexs[name] = Index(index_name, model, self.analyzer)\n        return self._indexs[name]", "response": "get index from model"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates one index for the given object.", "response": "def create_one_index(self,\n                         instance,\n                         update=False,\n                         delete=False,\n                         commit=True):\n        '''\n        :param instance: sqlalchemy instance object\n        :param update: when update is True,use `update_document`,default `False`\n        :param delete: when delete is True,use `delete_by_term` with id(primary key),default `False`\n        :param commit: when commit is True,writer would use writer.commit()\n        :raise: ValueError:when both update is True and delete is True\n        :return: instance\n        '''\n        if update and delete:\n            raise ValueError(\"update and delete can't work togther\")\n        table = instance.__class__\n        ix = self._index(table)\n        searchable = ix.fields\n        attrs = {DEFAULT_PRIMARY_KEY: str(instance.id)}\n\n        for field in searchable:\n            if '.' in field:\n                attrs[field] = str(relation_column(instance, field.split('.')))\n            else:\n                attrs[field] = str(getattr(instance, field))\n        if delete:\n            logger.debug('deleting index: {}'.format(instance))\n            ix.delete(fieldname=DEFAULT_PRIMARY_KEY, text=str(instance.id))\n        elif update:\n            logger.debug('updating index: {}'.format(instance))\n            ix.update(**attrs)\n        else:\n            logger.debug('creating index: {}'.format(instance))\n            ix.create(**attrs)\n        if commit:\n            ix.commit()\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for a set of fields in a Multifield table", "response": "def msearch(self, m, query, fields=None, limit=None, or_=True):\n        '''\n        set limit make search faster\n        '''\n        ix = self._index(m)\n        if fields is None:\n            fields = ix.fields\n        group = OrGroup if or_ else AndGroup\n        parser = MultifieldParser(fields, ix.schema, group=group)\n        return ix.search(parser.parse(query), limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, **kwargs):\n        \"Update document not update index.\"\n        kw = dict(index=self.name, doc_type=self.doc_type, ignore=[404])\n        kw.update(**kwargs)\n        return self._client.update(**kw)", "response": "Update document not update index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _index(self, model):\n        '''\n        Elasticsearch multi types has been removed\n        Use multi index unless set __msearch_index__.\n        '''\n        doc_type = model\n        if not isinstance(model, str):\n            doc_type = model.__table__.name\n\n        index_name = doc_type\n        if hasattr(model, \"__msearch_index__\"):\n            index_name = model.__msearch_index__\n\n        if doc_type not in self._indexs:\n            self._indexs[doc_type] = Index(self._client, index_name, doc_type)\n        return self._indexs[doc_type]", "response": "Create multi index for the given model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrewrite import xxx and from xxx import for vendored_libs", "response": "def rewrite_file_imports(item, vendored_libs):\n    \"\"\"Rewrite 'import xxx' and 'from xxx import' for vendored_libs\"\"\"\n    text = item.read_text(encoding='utf-8')\n    for lib in vendored_libs:\n        text = re.sub(\n            r'(\\n\\s*)import %s(\\n\\s*)' % lib,\n            r'\\1from pythonfinder._vendor import %s\\2' % lib,\n            text,\n        )\n        text = re.sub(\n            r'(\\n\\s*)from %s' % lib,\n            r'\\1from pythonfinder._vendor.%s' % lib,\n            text,\n        )\n    item.write_text(text, encoding='utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef diagonalize_collision_matrix(collision_matrices,\n                                 i_sigma=None,\n                                 i_temp=None,\n                                 pinv_solver=0,\n                                 log_level=0):\n    \"\"\"Diagonalize collision matrices.\n\n    Note\n    ----\n    collision_matricies is overwritten by eigenvectors.\n\n    Parameters\n    ----------\n    collision_matricies : ndarray, optional\n        Collision matrix. This ndarray has to have the following size and\n        flags.\n        shapes:\n            (sigmas, temperatures, prod(mesh), num_band, prod(mesh), num_band)\n            (sigmas, temperatures, ir_grid_points, num_band, 3,\n                                   ir_grid_points, num_band, 3)\n            (size, size)\n        dtype='double', order='C'\n    i_sigma : int, optional\n        Index of BZ integration methods, tetrahedron method and smearing\n        method with widths. Default is None.\n    i_temp : int, optional\n        Index of temperature. Default is None.\n    pinv_solver : int, optional\n        Diagnalization solver choice.\n    log_level : int, optional\n        Verbosity level. Smaller is more quiet. Default is 0.\n\n    Returns\n    -------\n    w : ndarray, optional\n        Eigenvalues.\n        shape=(size_of_collision_matrix,), dtype='double'\n\n    \"\"\"\n\n    start = time.time()\n\n    # Matrix size of collision matrix to be diagonalized.\n    # The following value is expected:\n    #   ir-colmat:  num_ir_grid_points * num_band * 3\n    #   red-colmat: num_mesh_points * num_band\n\n    shape = collision_matrices.shape\n    if len(shape) == 6:\n        size = shape[2] * shape[3]\n        assert size == shape[4] * shape[5]\n    elif len(shape) == 8:\n        size = np.prod(shape[2:5])\n        assert size == np.prod(shape[5:8])\n    elif len(shape) == 2:\n        size = shape[0]\n        assert size == shape[1]\n\n    solver = _select_solver(pinv_solver)\n\n    # [1] dsyev: safer and slower than dsyevd and smallest memory usage\n    # [2] dsyevd: faster than dsyev and largest memory usage\n    if solver in [1, 2]:\n        if log_level:\n            routine = ['dsyev', 'dsyevd'][solver - 1]\n            sys.stdout.write(\"Diagonalizing by lapacke %s... \" % routine)\n            sys.stdout.flush()\n        import phono3py._phono3py as phono3c\n        w = np.zeros(size, dtype='double')\n        if i_sigma is None:\n            _i_sigma = 0\n        else:\n            _i_sigma = i_sigma\n        if i_temp is None:\n            _i_temp = 0\n        else:\n            _i_temp = i_temp\n        phono3c.diagonalize_collision_matrix(collision_matrices,\n                                             w,\n                                             _i_sigma,\n                                             _i_temp,\n                                             0.0,\n                                             (solver + 1) % 2,\n                                             0)  # only diagonalization\n    elif solver == 3:  # np.linalg.eigh depends on dsyevd.\n        if log_level:\n            sys.stdout.write(\"Diagonalizing by np.linalg.eigh... \")\n            sys.stdout.flush()\n        col_mat = collision_matrices[i_sigma, i_temp].reshape(\n            size, size)\n        w, col_mat[:] = np.linalg.eigh(col_mat)\n\n    elif solver == 4:  # fully scipy dsyev\n        if log_level:\n            sys.stdout.write(\"Diagonalizing by \"\n                             \"scipy.linalg.lapack.dsyev... \")\n            sys.stdout.flush()\n        import scipy.linalg\n        col_mat = collision_matrices[i_sigma, i_temp].reshape(\n            size, size)\n        w, _, info = scipy.linalg.lapack.dsyev(col_mat.T, overwrite_a=1)\n    elif solver == 5:  # fully scipy dsyevd\n        if log_level:\n            sys.stdout.write(\"Diagonalizing by \"\n                             \"scipy.linalg.lapack.dsyevd... \")\n            sys.stdout.flush()\n        import scipy.linalg\n        col_mat = collision_matrices[i_sigma, i_temp].reshape(\n            size, size)\n        w, _, info = scipy.linalg.lapack.dsyevd(col_mat.T, overwrite_a=1)\n\n    if log_level:\n        print(\"[%.3fs]\" % (time.time() - start))\n        sys.stdout.flush()\n\n    return w", "response": "Diagonalize the collision matrices."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the list of weights used for collision matrix and |X > and |f > and |X > and |f >", "response": "def _get_weights(self):\n        \"\"\"Returns weights used for collision matrix and |X> and |f>\n\n        self._rot_grid_points : ndarray\n            shape=(ir_grid_points, point_operations), dtype='uintp'\n\n        r_gps : grid points of arms of k-star with duplicates\n            len(r_gps) == order of crystallographic point group\n            len(unique(r_gps)) == number of arms of the k-star\n\n        Returns\n        -------\n        weights : list\n            sqrt(g_k)/|g|, where g is the crystallographic point group and\n            g_k is the number of arms of k-star.\n\n        \"\"\"\n        weights = []\n        n = float(self._rot_grid_points.shape[1])\n        for r_gps in self._rot_grid_points:\n            weights.append(np.sqrt(len(np.unique(r_gps)) / n))\n        return weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns I matrix in Chaput s PRL paper.", "response": "def _get_I(self, a, b, size, plus_transpose=True):\n        \"\"\"Return I matrix in Chaput's PRL paper.\n\n        None is returned if I is zero matrix.\n\n        \"\"\"\n        r_sum = np.zeros((3, 3), dtype='double', order='C')\n        for r in self._rotations_cartesian:\n            for i in range(3):\n                for j in range(3):\n                    r_sum[i, j] += r[a, i] * r[b, j]\n        if plus_transpose:\n            r_sum += r_sum.T\n\n        # Return None not to consume computer for diagonalization\n        if (np.abs(r_sum) < 1e-10).all():\n            return None\n\n        # Same as np.kron(np.eye(size), r_sum), but writen as below\n        # to be sure the values in memory C-congiguous with 'double'.\n        I_mat = np.zeros((3 * size, 3 * size), dtype='double', order='C')\n        for i in range(size):\n            I_mat[(i * 3):((i + 1) * 3), (i * 3):((i + 1) * 3)] = r_sum\n\n        return I_mat"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_mode_kappa_Chaput(self, i_sigma, i_temp, weights):\n\n        X = self._get_X(i_temp, weights, self._gv).ravel()\n        num_ir_grid_points = len(self._ir_grid_points)\n        num_band = self._primitive.get_number_of_atoms() * 3\n        size = num_ir_grid_points * num_band * 3\n        v = self._collision_matrix[i_sigma, i_temp].reshape(size, size)\n        solver = _select_solver(self._pinv_solver)\n        if solver in [1, 2, 4, 5]:\n            v = v.T\n        e = self._get_eigvals_pinv(i_sigma, i_temp)\n        t = self._temperatures[i_temp]\n\n        omega_inv = np.empty(v.shape, dtype='double', order='C')\n        np.dot(v, (e * v).T, out=omega_inv)\n        Y = np.dot(omega_inv, X)\n        self._set_f_vectors(Y, num_ir_grid_points, weights)\n        elems = ((0, 0), (1, 1), (2, 2), (1, 2), (0, 2), (0, 1))\n        for i, vxf in enumerate(elems):\n            mat = self._get_I(vxf[0], vxf[1], num_ir_grid_points * num_band)\n            self._mode_kappa[i_sigma, i_temp, :, :, i] = 0\n            if mat is not None:\n                np.dot(mat, omega_inv, out=mat)\n                # vals = (X ** 2 * np.diag(mat)).reshape(-1, 3).sum(axis=1)\n                # vals = vals.reshape(num_ir_grid_points, num_band)\n                # self._mode_kappa[i_sigma, i_temp, :, :, i] = vals\n                w = diagonalize_collision_matrix(mat,\n                                                 pinv_solver=self._pinv_solver,\n                                                 log_level=self._log_level)\n                if solver in [1, 2, 4, 5]:\n                    mat = mat.T\n                spectra = np.dot(mat.T, X) ** 2 * w\n                for s, eigvec in zip(spectra, mat.T):\n                    vals = s * (eigvec ** 2).reshape(-1, 3).sum(axis=1)\n                    vals = vals.reshape(num_ir_grid_points, num_band)\n                    self._mode_kappa[i_sigma, i_temp, :, :, i] += vals\n\n        factor = self._conversion_factor * Kb * t ** 2\n        self._mode_kappa[i_sigma, i_temp] *= factor", "response": "Calculate mode kappa by the way in Laurent Chaput s PRL paper."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_third_order_displacements(cell,\n                                  symmetry,\n                                  is_plusminus='auto',\n                                  is_diagonal=False):\n    \"\"\"Create dispalcement dataset\n\n    Note\n    ----\n    Atoms 1, 2, and 3 are defined as follows:\n\n    Atom 1: The first displaced atom. Third order force constant\n            between Atoms 1, 2, and 3 is calculated.\n    Atom 2: The second displaced atom. Second order force constant\n            between Atoms 2 and 3 is calculated.\n    Atom 3: Force is mesuared on this atom.\n\n    Parameters\n    ----------\n    cell : PhonopyAtoms\n        Supercell\n    symmetry : Symmetry\n        Symmetry of supercell\n    is_plusminus : str or bool, optional\n        Type of displacements, plus only (False), always plus and minus (True),\n        and plus and minus depending on site symmetry ('auto').\n    is_diagonal : bool, optional\n        Whether allow diagonal displacements of Atom 2 or not\n\n    Returns\n    -------\n    dict\n        Data structure is like:\n        {'natom': 64,\n         'cutoff_distance': 4.000000,\n         'first_atoms':\n          [{'number': atom1,\n            'displacement': [0.03, 0., 0.],\n            'second_atoms': [ {'number': atom2,\n                               'displacement': [0., -0.03, 0.],\n                               'distance': 2.353},\n                              {'number': ... }, ... ] },\n           {'number': atom1, ... } ]}\n\n    \"\"\"\n\n    positions = cell.get_scaled_positions()\n    lattice = cell.get_cell().T\n\n    # Least displacements of first atoms (Atom 1) are searched by\n    # using respective site symmetries of the original crystal.\n    # 'is_diagonal=False' below is made intentionally to expect\n    # better accuracy.\n    disps_first = get_least_displacements(symmetry,\n                                          is_plusminus=is_plusminus,\n                                          is_diagonal=False)\n\n    symprec = symmetry.get_symmetry_tolerance()\n\n    dds = []\n    for disp in disps_first:\n        atom1 = disp[0]\n        disp1 = disp[1:4]\n        site_sym = symmetry.get_site_symmetry(atom1)\n\n        dds_atom1 = {'number': atom1,\n                     'direction': disp1,\n                     'second_atoms': []}\n\n        # Reduced site symmetry at the first atom with respect to\n        # the displacement of the first atoms.\n        reduced_site_sym = get_reduced_site_symmetry(site_sym, disp1, symprec)\n        # Searching orbits (second atoms) with respect to\n        # the first atom and its reduced site symmetry.\n        second_atoms = get_least_orbits(atom1,\n                                        cell,\n                                        reduced_site_sym,\n                                        symprec)\n\n        for atom2 in second_atoms:\n            dds_atom2 = get_next_displacements(atom1,\n                                               atom2,\n                                               reduced_site_sym,\n                                               lattice,\n                                               positions,\n                                               symprec,\n                                               is_diagonal)\n\n            min_vec = get_equivalent_smallest_vectors(atom1,\n                                                      atom2,\n                                                      cell,\n                                                      symprec)[0]\n            min_distance = np.linalg.norm(np.dot(lattice, min_vec))\n            dds_atom2['distance'] = min_distance\n            dds_atom1['second_atoms'].append(dds_atom2)\n        dds.append(dds_atom1)\n\n    return dds", "response": "Returns a dictionary of displacements for third order atoms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_least_orbits(atom_index, cell, site_symmetry, symprec=1e-5):\n    orbits = _get_orbits(atom_index, cell, site_symmetry, symprec)\n    mapping = np.arange(cell.get_number_of_atoms())\n\n    for i, orb in enumerate(orbits):\n        for num in np.unique(orb):\n            if mapping[num] > mapping[i]:\n                mapping[num] = mapping[i]\n\n    return np.unique(mapping)", "response": "Find the least orbits for a centering atom"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_fc3_to_hdf5(fc3,\n                      filename='fc3.hdf5',\n                      p2s_map=None,\n                      compression=None):\n    \"\"\"Write third-order force constants in hdf5 format.\n\n    Parameters\n    ----------\n    force_constants : ndarray\n        Force constants\n        shape=(n_satom, n_satom, n_satom, 3, 3, 3) or\n        (n_patom, n_satom, n_satom,3,3,3), dtype=double\n    filename : str\n        Filename to be used.\n    p2s_map : ndarray, optional\n        Primitive atom indices in supercell index system\n        shape=(n_patom,), dtype=intc\n    compression : str or int, optional\n        h5py's lossless compression filters (e.g., \"gzip\", \"lzf\").\n        See the detail at docstring of h5py.Group.create_dataset. Default is\n        None.\n\n    \"\"\"\n\n    with h5py.File(filename, 'w') as w:\n        w.create_dataset('fc3', data=fc3, compression=compression)\n        if p2s_map is not None:\n            w.create_dataset('p2s_map', data=p2s_map)", "response": "Write third - order force constants in hdf5 format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_unitary_matrix_to_hdf5(temperature,\n                                 mesh,\n                                 unitary_matrix=None,\n                                 sigma=None,\n                                 sigma_cutoff=None,\n                                 solver=None,\n                                 filename=None,\n                                 verbose=False):\n    \"\"\"Write eigenvectors of collision matrices at temperatures.\n\n    Depending on the choice of the solver, eigenvectors are sotred in\n    either column-wise or row-wise.\n\n    \"\"\"\n\n    suffix = _get_filename_suffix(mesh,\n                                  sigma=sigma,\n                                  sigma_cutoff=sigma_cutoff,\n                                  filename=filename)\n    hdf5_filename = \"unitary\" + suffix + \".hdf5\"\n    with h5py.File(hdf5_filename, 'w') as w:\n        w.create_dataset('temperature', data=temperature)\n        if unitary_matrix is not None:\n            w.create_dataset('unitary_matrix', data=unitary_matrix)\n        if solver is not None:\n            w.create_dataset('solver', data=solver)\n\n        if verbose:\n            if len(temperature) > 1:\n                text = \"Unitary matrices \"\n            else:\n                text = \"Unitary matrix \"\n            if sigma is not None:\n                text += \"at sigma %s \" % _del_zeros(sigma)\n                if sigma_cutoff is not None:\n                    text += \"(%4.2f SD) \" % sigma_cutoff\n            if len(temperature) > 1:\n                text += \"were written into \"\n            else:\n                text += \"was written into \"\n            if sigma is not None:\n                text += \"\\n\"\n            text += \"\\\"%s\\\".\" % hdf5_filename\n            print(text)", "response": "Write unitary matrix to hdf5 file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the primitive cell.", "response": "def _build_primitive_cell(self):\n        \"\"\"\n        primitive_matrix:\n          Relative axes of primitive cell to the input unit cell.\n          Relative axes to the supercell is calculated by:\n             supercell_matrix^-1 * primitive_matrix\n          Therefore primitive cell lattice is finally calculated by:\n             (supercell_lattice * (supercell_matrix)^-1 * primitive_matrix)^T\n        \"\"\"\n        self._primitive = self._get_primitive_cell(\n            self._supercell, self._supercell_matrix, self._primitive_matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_phonon_supercell(self):\n        if self._phonon_supercell_matrix is None:\n            self._phonon_supercell = self._supercell\n        else:\n            self._phonon_supercell = get_supercell(\n                self._unitcell, self._phonon_supercell_matrix, self._symprec)", "response": "Builds the phonon supercell for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_triplets_at_q(grid_point,\n                      mesh,\n                      point_group,  # real space point group of space group\n                      reciprocal_lattice,  # column vectors\n                      is_time_reversal=True,\n                      swappable=True,\n                      stores_triplets_map=False):\n    \"\"\"Parameters\n    ----------\n    grid_point : int\n        A grid point\n    mesh : array_like\n        Mesh numbers\n        dtype='intc'\n        shape=(3,)\n    point_group : array_like\n        Rotation matrices in real space. Note that those in reciprocal space\n        mean these matrices transposed (local terminology).\n        dtype='intc'\n        shape=(n_rot, 3, 3)\n    reciprocal_lattice : array_like\n        Reciprocal primitive basis vectors given as column vectors\n        dtype='double'\n        shape=(3, 3)\n    is_time_reversal : bool\n        Inversion symemtry is added if it doesn't exist.\n    swappable : bool\n        q1 and q2 can be swapped. By this number of triplets decreases.\n\n    Returns\n    -------\n    triplets_at_q : ndarray\n        Symmetry reduced number of triplets are stored as grid point\n        integer numbers.\n        dtype='uintp'\n        shape=(n_triplets, 3)\n    weights : ndarray\n        Weights of triplets in Brillouin zone\n        dtype='intc'\n        shape=(n_triplets,)\n    bz_grid_address : ndarray\n        Integer grid address of the points in Brillouin zone including\n        surface.  The first prod(mesh) numbers of points are\n        independent. But the rest of points are\n        translational-symmetrically equivalent to some other points.\n        dtype='intc'\n        shape=(n_grid_points, 3)\n    bz_map : ndarray\n        Grid point mapping table containing BZ surface. See more\n        detail in spglib docstring.\n        dtype='uintp'\n        shape=(prod(mesh*2),)\n    map_tripelts : ndarray or None\n        Returns when stores_triplets_map=True, otherwise None is\n        returned.  Mapping table of all triplets to symmetrically\n        independent tripelts. More precisely, this gives a list of\n        index mapping from all q-points to independent q' of\n        q+q'+q''=G. Considering q' is enough because q is fixed and\n        q''=G-q-q' where G is automatically determined to choose\n        smallest |G|.\n        dtype='uintp'\n        shape=(prod(mesh),)\n    map_q : ndarray or None\n        Returns when stores_triplets_map=True, otherwise None is\n        returned.  Irreducible q-points stabilized by q-point of\n        specified grid_point.\n        dtype='uintp'\n        shape=(prod(mesh),)\n\n    \"\"\"\n\n    map_triplets, map_q, grid_address = _get_triplets_reciprocal_mesh_at_q(\n        grid_point,\n        mesh,\n        point_group,\n        is_time_reversal=is_time_reversal,\n        swappable=swappable)\n    bz_grid_address, bz_map = spg.relocate_BZ_grid_address(grid_address,\n                                                           mesh,\n                                                           reciprocal_lattice,\n                                                           is_dense=True)\n    triplets_at_q, weights = _get_BZ_triplets_at_q(\n        grid_point,\n        bz_grid_address,\n        bz_map,\n        map_triplets,\n        mesh)\n\n    assert np.prod(mesh) == weights.sum(), \\\n        \"Num grid points %d, sum of weight %d\" % (\n                    np.prod(mesh), weights.sum())\n\n    # These maps are required for collision matrix calculation.\n    if not stores_triplets_map:\n        map_triplets = None\n        map_q = None\n\n    return triplets_at_q, weights, bz_grid_address, bz_map, map_triplets, map_q", "response": "Returns a list of triplets at a given point in a real space point group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_triplets_reciprocal_mesh_at_q(fixed_grid_number,\n                                       mesh,\n                                       rotations,\n                                       is_time_reversal=True,\n                                       swappable=True):\n    \"\"\"Search symmetry reduced triplets fixing one q-point\n\n    Triplets of (q0, q1, q2) are searched.\n\n    Parameters\n    ----------\n    fixed_grid_number : int\n        Grid point of q0\n    mesh : array_like\n        Mesh numbers\n        dtype='intc'\n        shape=(3,)\n    rotations : array_like\n        Rotation matrices in real space. Note that those in reciprocal space\n        mean these matrices transposed (local terminology).\n        dtype='intc'\n        shape=(n_rot, 3, 3)\n    is_time_reversal : bool\n        Inversion symemtry is added if it doesn't exist.\n    swappable : bool\n        q1 and q2 can be swapped. By this number of triplets decreases.\n\n    \"\"\"\n\n    import phono3py._phono3py as phono3c\n\n    map_triplets = np.zeros(np.prod(mesh), dtype='uintp')\n    map_q = np.zeros(np.prod(mesh), dtype='uintp')\n    grid_address = np.zeros((np.prod(mesh), 3), dtype='intc')\n\n    phono3c.triplets_reciprocal_mesh_at_q(\n        map_triplets,\n        map_q,\n        grid_address,\n        fixed_grid_number,\n        np.array(mesh, dtype='intc'),\n        is_time_reversal * 1,\n        np.array(rotations, dtype='intc', order='C'),\n        swappable * 1)\n\n    return map_triplets, map_q, grid_address", "response": "Search symmetry reduced triplets fixing one q - point and return the triplets that are found at the given grid - point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_averaged_interaction(self):\n\n        # v[triplet, band0, band, band]\n        v = self._interaction_strength\n        w = self._weights_at_q\n        v_sum = np.dot(w, v.sum(axis=2).sum(axis=2))\n        return v_sum / np.prod(v.shape[2:])", "response": "Return sum over phonon triplets of interaction strength\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef optimize(lattice,\n             positions,\n             numbers,\n             displacements,\n             forces,\n             alm_options=None,\n             p2s_map=None,\n             p2p_map=None,\n             log_level=0):\n    \"\"\"Calculate force constants\n\n    lattice : array_like\n        Basis vectors. a, b, c are given as column vectors.\n        shape=(3, 3), dtype='double'\n    positions : array_like\n        Fractional coordinates of atomic points.\n        shape=(num_atoms, 3), dtype='double'\n    numbers : array_like\n        Atomic numbers.\n        shape=(num_atoms,), dtype='intc'\n    displacements : array_like\n        Atomic displacement patterns in supercells in Cartesian.\n        dtype='double', shape=(supercells, num_atoms, 3)\n    forces : array_like\n        Forces in supercells.\n        dtype='double', shape=(supercells, num_atoms, 3)\n    alm_options : dict, optional\n        Default is None.\n        List of keys\n            cutoff_distance : float\n            solver : str\n                Either 'SimplicialLDLT' or 'dense'. Default is\n                'SimplicialLDLT'.\n\n    \"\"\"\n\n    from alm import ALM\n    with ALM(lattice, positions, numbers) as alm:\n        natom = len(numbers)\n        alm.set_verbosity(log_level)\n        nkd = len(np.unique(numbers))\n        if 'cutoff_distance' not in alm_options:\n            rcs = -np.ones((2, nkd, nkd), dtype='double')\n        elif type(alm_options['cutoff_distance']) is float:\n            rcs = np.ones((2, nkd, nkd), dtype='double')\n            rcs[0] *= -1\n            rcs[1] *= alm_options['cutoff_distance']\n        alm.define(2, rcs)\n        alm.set_displacement_and_force(displacements, forces)\n\n        if 'solver' in alm_options:\n            solver = alm_options['solver']\n        else:\n            solver = 'SimplicialLDLT'\n        info = alm.optimize(solver=solver)\n        fc2 = extract_fc2_from_alm(alm,\n                                   natom,\n                                   atom_list=p2s_map,\n                                   p2s_map=p2s_map,\n                                   p2p_map=p2p_map)\n        fc3 = _extract_fc3_from_alm(alm,\n                                    natom,\n                                    p2s_map=p2s_map,\n                                    p2p_map=p2p_map)\n        return fc2, fc3", "response": "This function calculates the force constants for a single internal state machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_alm_disp_fc3(disp_dataset):\n\n    natom = disp_dataset['natom']\n    ndisp = len(disp_dataset['first_atoms'])\n    for disp1 in disp_dataset['first_atoms']:\n        ndisp += len(disp1['second_atoms'])\n    disp = np.zeros((ndisp, natom, 3), dtype='double', order='C')\n    indices = []\n    count = 0\n    for disp1 in disp_dataset['first_atoms']:\n        indices.append(count)\n        disp[count, disp1['number']] = disp1['displacement']\n        count += 1\n\n    for disp1 in disp_dataset['first_atoms']:\n        for disp2 in disp1['second_atoms']:\n            if 'included' in disp2:\n                if disp2['included']:\n                    indices.append(count)\n            else:\n                indices.append(count)\n            disp[count, disp1['number']] = disp1['displacement']\n            disp[count, disp2['number']] = disp2['displacement']\n            count += 1\n\n    return disp, indices", "response": "Create displacements of atoms for ALM input and return the corresponding displacements."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_imag_self_energy(interaction,\n                         grid_points,\n                         sigmas,\n                         frequency_step=None,\n                         num_frequency_points=None,\n                         temperatures=None,\n                         scattering_event_class=None,  # class 1 or 2\n                         write_detail=False,\n                         output_filename=None,\n                         log_level=0):\n    \"\"\"Imaginary part of self energy at frequency points\n\n    Band indices to be calculated at are kept in Interaction instance.\n\n    Args:\n        interaction: Ph-ph interaction\n        grid_points: Grid-point indices to be caclculated on\n        sigmas:\n            A set of sigmas. simga=None means to use tetrahedron method,\n            otherwise smearing method with real positive value of sigma.\n        frequency_step: Pitch of frequency to be sampled.\n        num_frequency_points: Number of sampling sampling points to be used\n            instead of frequency_step.\n        temperatures: Temperatures to be calculated at.\n        scattering_event_class:\n            Extract scattering event class 1 or 2.\n        log_level: Log level. 0 or non 0 in this method.\n\n    Returns:\n        Tuple: (Imaginary part of self energy, sampling frequency points)\n\n    \"\"\"\n    if temperatures is None:\n        temperatures = [0.0, 300.0]\n\n    if temperatures is None:\n        print(\"Temperatures have to be set.\")\n        return False\n\n    mesh = interaction.get_mesh_numbers()\n    ise = ImagSelfEnergy(interaction, with_detail=write_detail)\n    imag_self_energy = []\n    frequency_points = []\n    for i, gp in enumerate(grid_points):\n        ise.set_grid_point(gp)\n        if log_level:\n            weights = interaction.get_triplets_at_q()[1]\n            print(\"------------------- Imaginary part of self energy (%d/%d) \"\n                  \"-------------------\" % (i + 1, len(grid_points)))\n            print(\"Grid point: %d\" % gp)\n            print(\"Number of ir-triplets: \"\n                  \"%d / %d\" % (len(weights), weights.sum()))\n        ise.run_interaction()\n        frequencies = interaction.get_phonons()[0]\n        max_phonon_freq = np.amax(frequencies)\n\n        if log_level:\n            adrs = interaction.get_grid_address()[gp]\n            q = adrs.astype('double') / mesh\n            print(\"q-point: %s\" % q)\n            print(\"Phonon frequency:\")\n            text = \"[ \"\n            for i, freq in enumerate(frequencies[gp]):\n                if i % 6 == 0 and i != 0:\n                    text += \"\\n\"\n                text += \"%8.4f \" % freq\n            text += \"]\"\n            print(text)\n            sys.stdout.flush()\n\n        gamma_sigmas = []\n        fp_sigmas = []\n        if write_detail:\n            (triplets,\n             weights,\n             map_triplets, _) = interaction.get_triplets_at_q()\n\n        for j, sigma in enumerate(sigmas):\n            if log_level:\n                if sigma:\n                    print(\"Sigma: %s\" % sigma)\n                else:\n                    print(\"Tetrahedron method\")\n\n            ise.set_sigma(sigma)\n            if sigma:\n                fmax = max_phonon_freq * 2 + sigma * 4\n            else:\n                fmax = max_phonon_freq * 2\n            fmax *= 1.005\n            fmin = 0\n            frequency_points_at_sigma = get_frequency_points(\n                fmin,\n                fmax,\n                frequency_step=frequency_step,\n                num_frequency_points=num_frequency_points)\n            fp_sigmas.append(frequency_points_at_sigma)\n            gamma = np.zeros(\n                (len(temperatures), len(frequency_points_at_sigma),\n                 len(interaction.get_band_indices())), dtype='double')\n\n            if write_detail:\n                num_band0 = len(interaction.get_band_indices())\n                num_band = frequencies.shape[1]\n                detailed_gamma = np.zeros(\n                    (len(temperatures), len(frequency_points_at_sigma),\n                     len(weights), num_band0, num_band, num_band),\n                    dtype='double')\n\n            for k, freq_point in enumerate(frequency_points_at_sigma):\n                ise.set_frequency_points([freq_point])\n                ise.set_integration_weights(\n                    scattering_event_class=scattering_event_class)\n\n                for l, t in enumerate(temperatures):\n                    ise.set_temperature(t)\n                    ise.run()\n                    gamma[l, k] = ise.get_imag_self_energy()[0]\n                    if write_detail:\n                        detailed_gamma[l, k] = (\n                            ise.get_detailed_imag_self_energy()[0])\n\n            gamma_sigmas.append(gamma)\n\n            if write_detail:\n                full_filename = write_gamma_detail_to_hdf5(\n                    temperatures,\n                    mesh,\n                    gamma_detail=detailed_gamma,\n                    grid_point=gp,\n                    triplet=triplets,\n                    weight=weights,\n                    triplet_map=map_triplets,\n                    sigma=sigma,\n                    frequency_points=frequency_points_at_sigma,\n                    filename=output_filename)\n\n                if log_level:\n                    print(\"Contribution of each triplet to imaginary part of \"\n                          \"self energy is written in\\n\\\"%s\\\".\" % full_filename)\n\n        imag_self_energy.append(gamma_sigmas)\n        frequency_points.append(fp_sigmas)\n\n    return imag_self_energy, frequency_points", "response": "This method calculates the imaginary self energy at the given grid - points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndistributing a set of supercell atoms to a set of supercell atoms.", "response": "def distribute_fc3(fc3,\n                   first_disp_atoms,\n                   target_atoms,\n                   lattice,\n                   rotations,\n                   permutations,\n                   s2compact,\n                   verbose=False):\n    \"\"\"Distribute fc3\n\n    fc3[i, :, :, 0:3, 0:3, 0:3] where i=indices done are distributed to\n    symmetrically equivalent fc3 elements by tensor rotations.\n\n    Search symmetry operation (R, t) that performs\n        i_target -> i_done\n    and\n        atom_mapping[i_target] = i_done\n        fc3[i_target, j_target, k_target] = R_inv[i_done, j, k]\n\n    Parameters\n    ----------\n\n    target_atoms: list or ndarray\n        Supercell atom indices to which fc3 are distributed.\n    s2compact: ndarray\n        Maps supercell index to compact index. For full-fc3,\n        s2compact=np.arange(n_satom).\n        shape=(n_satom,)\n        dtype=intc\n\n    \"\"\"\n\n    n_satom = fc3.shape[1]\n    for i_target in target_atoms:\n        for i_done in first_disp_atoms:\n            rot_indices = np.where(permutations[:, i_target] == i_done)[0]\n            if len(rot_indices) > 0:\n                atom_mapping = np.array(permutations[rot_indices[0]],\n                                        dtype='intc')\n                rot = rotations[rot_indices[0]]\n                rot_cart_inv = np.array(\n                    similarity_transformation(lattice, rot).T,\n                    dtype='double', order='C')\n                break\n\n        if len(rot_indices) == 0:\n            print(\"Position or symmetry may be wrong.\")\n            raise RuntimeError\n\n        if verbose > 2:\n            print(\"    [ %d, x, x ] to [ %d, x, x ]\" %\n                  (i_done + 1, i_target + 1))\n            sys.stdout.flush()\n\n        try:\n            import phono3py._phono3py as phono3c\n            phono3c.distribute_fc3(fc3,\n                                   int(s2compact[i_target]),\n                                   int(s2compact[i_done]),\n                                   atom_mapping,\n                                   rot_cart_inv)\n        except ImportError:\n            print(\"Phono3py C-routine is not compiled correctly.\")\n            for j in range(n_satom):\n                j_rot = atom_mapping[j]\n                for k in range(n_satom):\n                    k_rot = atom_mapping[k]\n                    fc3[i_target, j, k] = third_rank_tensor_rotation(\n                        rot_cart_inv, fc3[i_done, j_rot, k_rot])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of constrained fc2 for the second atom atom1.", "response": "def get_constrained_fc2(supercell,\n                        dataset_second_atoms,\n                        atom1,\n                        reduced_site_sym,\n                        symprec):\n    \"\"\"\n    dataset_second_atoms: [{'number': 7,\n                            'displacement': [],\n                            'delta_forces': []}, ...]\n    \"\"\"\n    lattice = supercell.get_cell().T\n    positions = supercell.get_scaled_positions()\n    num_atom = supercell.get_number_of_atoms()\n\n    fc2 = np.zeros((num_atom, num_atom, 3, 3), dtype='double')\n    atom_list = np.unique([x['number'] for x in dataset_second_atoms])\n    for atom2 in atom_list:\n        disps2 = []\n        sets_of_forces = []\n        for disps_second in dataset_second_atoms:\n            if atom2 != disps_second['number']:\n                continue\n            bond_sym = get_bond_symmetry(\n                reduced_site_sym,\n                lattice,\n                positions,\n                atom1,\n                atom2,\n                symprec)\n\n            disps2.append(disps_second['displacement'])\n            sets_of_forces.append(disps_second['delta_forces'])\n\n        solve_force_constants(fc2,\n                              atom2,\n                              disps2,\n                              sets_of_forces,\n                              supercell,\n                              bond_sym,\n                              symprec)\n\n    # Shift positions according to set atom1 is at origin\n    pos_center = positions[atom1].copy()\n    positions -= pos_center\n    rotations = np.array(reduced_site_sym, dtype='intc', order='C')\n    translations = np.zeros((len(reduced_site_sym), 3),\n                            dtype='double', order='C')\n    permutations = compute_all_sg_permutations(positions,\n                                               rotations,\n                                               translations,\n                                               lattice,\n                                               symprec)\n    distribute_force_constants(fc2,\n                               atom_list,\n                               lattice,\n                               rotations,\n                               permutations)\n    return fc2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef capture_dash_in_url_name(self, node):\n        for keyword in node.keywords:\n            if keyword.arg == 'name' and '-' in keyword.value.s:\n                return DJ04(\n                    lineno=node.lineno,\n                    col=node.col_offset,\n                )", "response": "Capture dash in URL name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncapturing missing namespace in url include.", "response": "def capture_url_missing_namespace(self, node):\n        \"\"\"\n        Capture missing namespace in url include.\n        \"\"\"\n        for arg in node.args:\n            if not(isinstance(arg, ast.Call) and isinstance(arg.func, ast.Name)):\n                continue\n            if arg.func.id != 'include':\n                continue\n            for keyword in arg.keywords:\n                if keyword.arg == 'namespace':\n                    return\n\n            return DJ05(\n                lineno=node.lineno,\n                col=node.col_offset,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of DJ03 issues that can be found in the render function.", "response": "def run(self, node):\n        \"\"\"\n        Captures the use of locals() in render function.\n        \"\"\"\n        if self.get_call_name(node) != 'render':\n            return\n        issues = []\n        for arg in node.args:\n            if isinstance(arg, ast.Call) and arg.func.id == 'locals':\n                issues.append(\n                    DJ03(\n                        lineno=node.lineno,\n                        col=node.col_offset,\n                    )\n                )\n        return issues"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_call_name(self, node):\n        if isinstance(node.func, ast.Attribute):\n            return node.func.attr\n        elif isinstance(node.func, ast.Name):\n            return node.func.id", "response": "Return call name for the given node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the element is a string_dunder_all node.", "response": "def is_string_dunder_all(self, element):\n        \"\"\"\n        Return True if element is ast.Str or ast.Bytes and equals \"__all__\"\n        \"\"\"\n        if not isinstance(element.value, (ast.Str, ast.Bytes)):\n            return False\n\n        node_value = element.value.s\n        if isinstance(node_value, bytes):\n            node_value = node_value.decode()\n        return node_value == '__all__'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of issues that can be found in the ModelForm Meta.", "response": "def run(self, node):\n        \"\"\"\n        Captures the use of exclude in ModelForm Meta\n        \"\"\"\n        if not self.checker_applies(node):\n            return\n\n        issues = []\n        for body in node.body:\n            if not isinstance(body, ast.ClassDef):\n                continue\n            for element in body.body:\n                if not isinstance(element, ast.Assign):\n                    continue\n                for target in element.targets:\n                    if target.id == 'fields' and self.is_string_dunder_all(element):\n                        issues.append(\n                            DJ07(\n                                lineno=node.lineno,\n                                col=node.col_offset,\n                            )\n                        )\n                    elif target.id == 'exclude':\n                        issues.append(\n                            DJ06(\n                                lineno=node.lineno,\n                                col=node.col_offset,\n                            )\n                        )\n        return issues"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_model_name_lookup(self, base):\n        return (\n            isinstance(base, ast.Name) and\n            base.id == self.model_name_lookup\n        )", "response": "Return True if class is defined as the respective model name lookup declaration\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_models_name_lookup_attribute(self, base):\n        return (\n            isinstance(base, ast.Attribute) and\n            isinstance(base.value, ast.Name) and\n            base.value.id == 'models' and base.attr == self.model_name_lookup\n        )", "response": "Return True if class is defined as the respective model name lookup declaration\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting scheme and format based on source and return as a tuple.", "response": "def detect_scheme_and_format(source):\n    \"\"\"Detect scheme and format based on source and return as a tuple.\n\n    Scheme is a minimum 2 letters before `://` (will be lower cased).\n    For example `http` from `http://example.com/table.csv`\n\n    \"\"\"\n\n    # Scheme: stream\n    if hasattr(source, 'read'):\n        return ('stream', None)\n\n    # Format: inline\n    if not isinstance(source, six.string_types):\n        return (None, 'inline')\n\n    # Format: gsheet\n    if 'docs.google.com/spreadsheets' in source:\n        if 'export' not in source and 'pub' not in source:\n            return (None, 'gsheet')\n        elif 'csv' in source:\n            return ('https', 'csv')\n\n    # Format: sql\n    for sql_scheme in config.SQL_SCHEMES:\n        if source.startswith('%s://' % sql_scheme):\n            return (None, 'sql')\n\n    # General\n    parsed = urlparse(source)\n    scheme = parsed.scheme.lower()\n    if len(scheme) < 2:\n        scheme = config.DEFAULT_SCHEME\n    format = os.path.splitext(parsed.path or parsed.netloc)[1][1:].lower() or None\n    if format is None:\n        # Test if query string contains a \"format=\" parameter.\n        query_string = parse_qs(parsed.query)\n        query_string_format = query_string.get(\"format\")\n        if query_string_format is not None and len(query_string_format) == 1:\n            format = query_string_format[0]\n\n    # Format: datapackage\n    if parsed.path.endswith('datapackage.json'):\n        return (None, 'datapackage')\n\n    return (scheme, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect encoding of a byte string sample.", "response": "def detect_encoding(sample, encoding=None):\n    \"\"\"Detect encoding of a byte string sample.\n    \"\"\"\n    # To reduce tabulator import time\n    from cchardet import detect\n    if encoding is not None:\n        return normalize_encoding(sample, encoding)\n    result = detect(sample)\n    confidence = result['confidence'] or 0\n    encoding = result['encoding'] or 'ascii'\n    encoding = normalize_encoding(sample, encoding)\n    if confidence < config.ENCODING_CONFIDENCE:\n        encoding = config.DEFAULT_ENCODING\n    if encoding == 'ascii':\n        encoding = config.DEFAULT_ENCODING\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize_encoding(sample, encoding):\n    encoding = codecs.lookup(encoding).name\n    # Work around 'Incorrect detection of utf-8-sig encoding'\n    # <https://github.com/PyYoshi/cChardet/issues/28>\n    if encoding == 'utf-8':\n        if sample.startswith(codecs.BOM_UTF8):\n            encoding = 'utf-8-sig'\n    # Use the BOM stripping name (without byte-order) for UTF-16 encodings\n    elif encoding == 'utf-16-be':\n        if sample.startswith(codecs.BOM_UTF16_BE):\n            encoding = 'utf-16'\n    elif encoding == 'utf-16-le':\n        if sample.startswith(codecs.BOM_UTF16_LE):\n            encoding = 'utf-16'\n    return encoding", "response": "Normalize the encoding including utf - 8 - sig utf - 16 - be and utf - 16 - le tweaks.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect if text is HTML.", "response": "def detect_html(text):\n    \"\"\"Detect if text is HTML.\n    \"\"\"\n    pattern = re.compile('\\\\s*<(!doctype|html)', re.IGNORECASE)\n    return bool(pattern.match(text))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the stream pointer to the first element.", "response": "def reset_stream(stream):\n    \"\"\"Reset stream pointer to the first element.\n\n    If stream is not seekable raise Exception.\n\n    \"\"\"\n    try:\n        position = stream.tell()\n    except Exception:\n        position = True\n    if position != 0:\n        try:\n            stream.seek(0)\n        except Exception:\n            message = 'It\\'s not possible to reset this stream'\n            raise exceptions.TabulatorException(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requote_uri(uri):\n    # To reduce tabulator import time\n    import requests.utils\n    if six.PY2:\n        def url_encode_non_ascii(bytes):\n            pattern = '[\\x80-\\xFF]'\n            replace = lambda c: ('%%%02x' % ord(c.group(0))).upper()\n            return re.sub(pattern, replace, bytes)\n        parts = urlparse(uri)\n        uri = urlunparse(\n            part.encode('idna') if index == 1\n            else url_encode_non_ascii(part.encode('utf-8'))\n            for index, part in enumerate(parts))\n    return requests.utils.requote_uri(uri)", "response": "Requote uri if it contains non - ascii chars spaces etc."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting attribute by path like package. module. attribute", "response": "def import_attribute(path):\n    \"\"\"Import attribute by path like `package.module.attribute`\n    \"\"\"\n    module_name, attribute_name = path.rsplit('.', 1)\n    module = import_module(module_name)\n    attribute = getattr(module, attribute_name)\n    return attribute"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_options(options, names):\n    result = {}\n    for name, value in copy(options).items():\n        if name in names:\n            result[name] = value\n            del options[name]\n    return result", "response": "Return options for names and remove it from given options in - place."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting any value to string.", "response": "def stringify_value(value):\n    \"\"\"Convert any value to string.\n    \"\"\"\n    if value is None:\n        return u''\n    isoformat = getattr(value, 'isoformat', None)\n    if isoformat is not None:\n        value = isoformat()\n    return type(u'')(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen the stream for reading.", "response": "def open(self):\n        '''Opens the stream for reading.'''\n        options = copy(self.__options)\n\n        # Get scheme and format if not already given\n        compression = None\n        if self.__scheme is None or self.__format is None:\n            detected_scheme, detected_format = helpers.detect_scheme_and_format(self.__source)\n            scheme = self.__scheme or detected_scheme\n            format = self.__format or detected_format\n            # Get compression\n            for type in config.SUPPORTED_COMPRESSION:\n                if self.__compression == type or detected_format == type:\n                    compression = type\n        else:\n            scheme = self.__scheme\n            format = self.__format\n\n        # Initiate loader\n        self.__loader = None\n        if scheme is not None:\n            loader_class = self.__custom_loaders.get(scheme)\n            if loader_class is None:\n                if scheme not in config.LOADERS:\n                    message = 'Scheme \"%s\" is not supported' % scheme\n                    raise exceptions.SchemeError(message)\n                loader_path = config.LOADERS[scheme]\n                if loader_path:\n                    loader_class = helpers.import_attribute(loader_path)\n            if loader_class is not None:\n                loader_options = helpers.extract_options(options, loader_class.options)\n                if compression and 'http_stream' in loader_class.options:\n                    loader_options['http_stream'] = False\n                self.__loader = loader_class(\n                    bytes_sample_size=self.__bytes_sample_size,\n                    **loader_options)\n\n        # Zip compression\n        if compression == 'zip' and six.PY3:\n            source = self.__loader.load(self.__source, mode='b')\n            with zipfile.ZipFile(source) as archive:\n                name = archive.namelist()[0]\n                if 'filename' in options.keys():\n                    name = options['filename']\n                    del options['filename']\n                with archive.open(name) as file:\n                    source = tempfile.NamedTemporaryFile(suffix='.' + name)\n                    for line in file:\n                        source.write(line)\n                    source.seek(0)\n            self.__source = source\n            self.__loader = StreamLoader(bytes_sample_size=self.__bytes_sample_size)\n            format = self.__format or helpers.detect_scheme_and_format(source.name)[1]\n            scheme = 'stream'\n\n        # Gzip compression\n        elif compression == 'gz' and six.PY3:\n            name = self.__source.replace('.gz', '')\n            self.__source = gzip.open(self.__loader.load(self.__source, mode='b'))\n            self.__loader = StreamLoader(bytes_sample_size=self.__bytes_sample_size)\n            format = self.__format or helpers.detect_scheme_and_format(name)[1]\n            scheme = 'stream'\n\n        # Not supported compression\n        elif compression:\n            message = 'Compression \"%s\" is not supported for your Python version'\n            raise exceptions.TabulatorException(message % compression)\n\n        # Initiate parser\n        parser_class = self.__custom_parsers.get(format)\n        if parser_class is None:\n            if format not in config.PARSERS:\n                message = 'Format \"%s\" is not supported' % format\n                raise exceptions.FormatError(message)\n            parser_class = helpers.import_attribute(config.PARSERS[format])\n        parser_options = helpers.extract_options(options, parser_class.options)\n        self.__parser = parser_class(self.__loader,\n                force_parse=self.__force_parse,\n                **parser_options)\n\n        # Bad options\n        if options:\n            message = 'Not supported option(s) \"%s\" for scheme \"%s\" and format \"%s\"'\n            message = message % (', '.join(options), scheme, format)\n            warnings.warn(message, UserWarning)\n\n        # Open and setup\n        self.__parser.open(self.__source, encoding=self.__encoding)\n        self.__extract_sample()\n        self.__extract_headers()\n        if not self.__allow_html:\n            self.__detect_html()\n\n        # Set scheme/format/encoding\n        self.__actual_scheme = scheme\n        self.__actual_format = format\n        self.__actual_encoding = self.__parser.encoding\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the stream pointer to the beginning of the file.", "response": "def reset(self):\n        '''Resets the stream pointer to the beginning of the file.'''\n        if self.__row_number > self.__sample_size:\n            self.__parser.reset()\n            self.__extract_sample()\n            self.__extract_headers()\n        self.__row_number = 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the stream s rows used as sample. These rows are used internally to infer characteristics of the the source file.", "response": "def sample(self):\n        '''Returns the stream's rows used as sample.\n\n        These sample rows are used internally to infer characteristics of the\n        source file (e.g. encoding, headers, ...).\n        '''\n        sample = []\n        iterator = iter(self.__sample_extended_rows)\n        iterator = self.__apply_processors(iterator)\n        for row_number, headers, row in iterator:\n            sample.append(row)\n        return sample"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter(self, keyed=False, extended=False):\n        '''Iterate over the rows.\n\n        Each row is returned in a format that depends on the arguments `keyed`\n        and `extended`. By default, each row is returned as list of their\n        values.\n\n        Args:\n            keyed (bool, optional): When True, each returned row will be a\n                `dict` mapping the header name to its value in the current row.\n                For example, `[{'name': 'J Smith', 'value': '10'}]`. Ignored if\n                ``extended`` is True. Defaults to False.\n            extended (bool, optional): When True, returns each row as a tuple\n                with row number (starts at 1), list of headers, and list of row\n                values. For example, `(1, ['name', 'value'], ['J Smith', '10'])`.\n                Defaults to False.\n\n        Returns:\n            Iterator[Union[List[Any], Dict[str, Any], Tuple[int, List[str], List[Any]]]]:\n                The row itself. The format depends on the values of `keyed` and\n                `extended` arguments.\n\n        Raises:\n            exceptions.TabulatorException: If the stream is closed.\n        '''\n\n        # Error if closed\n        if self.closed:\n            message = 'Stream is closed. Please call \"stream.open()\" first.'\n            raise exceptions.TabulatorException(message)\n\n        # Create iterator\n        iterator = chain(\n            self.__sample_extended_rows,\n            self.__parser.extended_rows)\n        iterator = self.__apply_processors(iterator)\n\n        # Yield rows from iterator\n        for row_number, headers, row in iterator:\n            if row_number > self.__row_number:\n                self.__row_number = row_number\n                if extended:\n                    yield (row_number, headers, row)\n                elif keyed:\n                    yield dict(zip(headers, row))\n                else:\n                    yield row", "response": "Iterate over the rows."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, target, format=None,  encoding=None, **options):\n        '''Save stream to the local filesystem.\n\n        Args:\n            target (str): Path where to save the stream.\n            format (str, optional): The format the stream will be saved as. If\n                None, detects from the ``target`` path. Defaults to None.\n            encoding (str, optional): Saved file encoding. Defaults to\n                ``config.DEFAULT_ENCODING``.\n            **options: Extra options passed to the writer.\n        '''\n\n        # Get encoding/format\n        if encoding is None:\n            encoding = config.DEFAULT_ENCODING\n        if format is None:\n            _, format = helpers.detect_scheme_and_format(target)\n\n        # Prepare writer class\n        writer_class = self.__custom_writers.get(format)\n        if writer_class is None:\n            if format not in config.WRITERS:\n                message = 'Format \"%s\" is not supported' % format\n                raise exceptions.FormatError(message)\n            writer_class = helpers.import_attribute(config.WRITERS[format])\n\n        # Prepare writer options\n        writer_options = helpers.extract_options(options, writer_class.options)\n        if options:\n            message = 'Not supported options \"%s\" for format \"%s\"'\n            message = message % (', '.join(options), format)\n            raise exceptions.TabulatorException(message)\n\n        # Write data to target\n        writer = writer_class(**writer_options)\n        writer.write(self.iter(), target, headers=self.headers, encoding=encoding)", "response": "Save the data to the local filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the tabulator is able to load the source file.", "response": "def validate(source, scheme=None, format=None):\n    '''Check if tabulator is able to load the source.\n\n    Args:\n        source (Union[str, IO]): The source path or IO object.\n        scheme (str, optional): The source scheme. Auto-detect by default.\n        format (str, optional): The source file format. Auto-detect by default.\n\n    Returns:\n        bool: Whether tabulator is able to load the source file.\n\n    Raises:\n        `tabulator.exceptions.SchemeError`: The file scheme is not supported.\n        `tabulator.exceptions.FormatError`: The file format is not supported.\n    '''\n\n    # Get scheme and format\n    detected_scheme, detected_format = helpers.detect_scheme_and_format(source)\n    scheme = scheme or detected_scheme\n    format = format or detected_format\n\n    # Validate scheme and format\n    if scheme is not None:\n        if scheme not in config.LOADERS:\n            raise exceptions.SchemeError('Scheme \"%s\" is not supported' % scheme)\n    if format not in config.PARSERS:\n        raise exceptions.FormatError('Format \"%s\" is not supported' % format)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef require_axis(f):\n\n    @wraps(f)\n    def _wrapper(self, *args, **kwargs):\n        if None in (self.axis, self.sel_axis):\n            raise ValueError('%(func_name) requires the node %(node)s '\n                    'to have an axis and a sel_axis function' %\n                    dict(func_name=f.__name__, node=repr(self)))\n\n        return f(self, *args, **kwargs)\n\n    return _wrapper", "response": "Decorator that checks if the object of the function has axis and sel_axis members."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a kd - tree from a list of points.", "response": "def create(point_list=None, dimensions=None, axis=0, sel_axis=None):\n    \"\"\" Creates a kd-tree from a list of points\n\n    All points in the list must be of the same dimensionality.\n\n    If no point_list is given, an empty tree is created. The number of\n    dimensions has to be given instead.\n\n    If both a point_list and dimensions are given, the numbers must agree.\n\n    Axis is the axis on which the root-node should split.\n\n    sel_axis(axis) is used when creating subnodes of a node. It receives the\n    axis of the parent node and returns the axis of the child node. \"\"\"\n\n    if not point_list and not dimensions:\n        raise ValueError('either point_list or dimensions must be provided')\n\n    elif point_list:\n        dimensions = check_dimensionality(point_list, dimensions)\n\n    # by default cycle through the axis\n    sel_axis = sel_axis or (lambda prev_axis: (prev_axis+1) % dimensions)\n\n    if not point_list:\n        return KDNode(sel_axis=sel_axis, axis=axis, dimensions=dimensions)\n\n    # Sort point list and choose median as pivot element\n    point_list = list(point_list)\n    point_list.sort(key=lambda point: point[axis])\n    median = len(point_list) // 2\n\n    loc   = point_list[median]\n    left  = create(point_list[:median], dimensions, sel_axis(axis))\n    right = create(point_list[median + 1:], dimensions, sel_axis(axis))\n    return KDNode(loc, left, right, axis=axis, sel_axis=sel_axis, dimensions=dimensions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator over the tree in level - order.", "response": "def level_order(tree, include_all=False):\n    \"\"\" Returns an iterator over the tree in level-order\n\n    If include_all is set to True, empty parts of the tree are filled\n    with dummy entries and the iterator becomes infinite. \"\"\"\n\n    q = deque()\n    q.append(tree)\n    while q:\n        node = q.popleft()\n        yield node\n\n        if include_all or node.left:\n            q.append(node.left or node.__class__())\n\n        if include_all or node.right:\n            q.append(node.right or node.__class__())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visualize(tree, max_level=100, node_width=10, left_padding=5):\n\n    height = min(max_level, tree.height()-1)\n    max_width = pow(2, height)\n\n    per_level = 1\n    in_level  = 0\n    level     = 0\n\n    for node in level_order(tree, include_all=True):\n\n        if in_level == 0:\n            print()\n            print()\n            print(' '*left_padding, end=' ')\n\n        width = int(max_width*node_width/per_level)\n\n        node_str = (str(node.data) if node else '').center(width)\n        print(node_str, end=' ')\n\n        in_level += 1\n\n        if in_level == per_level:\n            in_level   = 0\n            per_level *= 2\n            level     += 1\n\n        if level > height:\n            break\n\n    print()\n    print()", "response": "Prints the tree to stdout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_leaf(self):\n        return (not self.data) or \\\n               (all(not bool(c) for c, p in self.children))", "response": "Returns True if a Node is leaf False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inorder(self):\n\n        if not self:\n            return\n\n        if self.left:\n            for x in self.left.inorder():\n                yield x\n\n        yield self\n\n        if self.right:\n            for x in self.right.inorder():\n                yield x", "response": "iterator for all the elements in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef postorder(self):\n\n        if not self:\n            return\n\n        if self.left:\n            for x in self.left.postorder():\n                yield x\n\n        if self.right:\n            for x in self.right.postorder():\n                yield x\n\n        yield self", "response": "iterator for nodes in postorder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef children(self):\n\n        if self.left and self.left.data is not None:\n            yield self.left, 0\n        if self.right and self.right.data is not None:\n            yield self.right, 1", "response": "Returns an iterator for the non - empty children of the Node Arc Arc."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets one of the node s children with the given index.", "response": "def set_child(self, index, child):\n        \"\"\" Sets one of the node's children\n\n        index 0 refers to the left, 1 to the right child \"\"\"\n\n        if index == 0:\n            self.left = child\n        else:\n            self.right = child"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the height of the tree without considering empty leaf - nodes", "response": "def height(self):\n        \"\"\"\n        Returns height of the (sub)tree, without considering\n        empty leaf-nodes\n\n        >>> create(dimensions=2).height()\n        0\n\n        >>> create([ (1, 2) ]).height()\n        1\n\n        >>> create([ (1, 2), (2, 3) ]).height()\n        2\n        \"\"\"\n\n        min_height = int(bool(self))\n        return max([min_height] + [c.height()+1 for c, p in self.children])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the position of the given child in the tree.", "response": "def get_child_pos(self, child):\n        \"\"\" Returns the position if the given child\n\n        If the given node is the left child, 0 is returned. If its the right\n        child, 1 is returned. Otherwise None \"\"\"\n\n        for c, pos in self.children:\n            if child == c:\n                return pos"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a point to the current node or iteratively descends to one of its children. Returns the new node or iteratively .", "response": "def add(self, point):\n        \"\"\"\n        Adds a point to the current node or iteratively\n        descends to one of its children.\n\n        Users should call add() only to the topmost tree.\n        \"\"\"\n\n        current = self\n        while True:\n            check_dimensionality([point], dimensions=current.dimensions)\n\n            # Adding has hit an empty leaf-node, add here\n            if current.data is None:\n                current.data = point\n                return current\n\n            # split on self.axis, recurse either left or right\n            if point[current.axis] < current.data[current.axis]:\n                if current.left is None:\n                    current.left = current.create_subnode(point)\n                    return current.left\n                else:\n                    current = current.left\n            else:\n                if current.right is None:\n                    current.right = current.create_subnode(point)\n                    return current.right\n                else:\n                    current = current.right"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a subnode for the current node", "response": "def create_subnode(self, data):\n        \"\"\" Creates a subnode for the current node \"\"\"\n\n        return self.__class__(data,\n                axis=self.sel_axis(self.axis),\n                sel_axis=self.sel_axis,\n                dimensions=self.dimensions)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_replacement(self):\n\n        if self.right:\n            child, parent = self.right.extreme_child(min, self.axis)\n        else:\n            child, parent = self.left.extreme_child(max, self.axis)\n\n        return (child, parent if parent is not None else self)", "response": "Finds a replacement for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef should_remove(self, point, node):\n        if not self.data == point:\n            return False\n\n        return (node is None) or (node is self)", "response": "checks if self s point matches point and node matches"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, point, node=None):\n\n        # Recursion has reached an empty leaf node, nothing here to delete\n        if not self:\n            return\n\n        # Recursion has reached the node to be deleted\n        if self.should_remove(point, node):\n            return self._remove(point)\n\n        # Remove direct subnode\n        if self.left and self.left.should_remove(point, node):\n            self.left = self.left._remove(point)\n\n        elif self.right and self.right.should_remove(point, node):\n            self.right = self.right._remove(point)\n\n        # Recurse to subtrees\n        if point[self.axis] <= self.data[self.axis]:\n            if self.left:\n                self.left = self.left.remove(point, node)\n\n        if point[self.axis] >= self.data[self.axis]:\n            if self.right:\n                self.right = self.right.remove(point, node)\n\n        return self", "response": "Removes the node with the given point from the tree. Returns the new root node of the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_balanced(self):\n\n        left_height = self.left.height() if self.left else 0\n        right_height = self.right.height() if self.right else 0\n\n        if abs(left_height - right_height) > 1:\n            return False\n\n        return all(c.is_balanced for c, _ in self.children)", "response": "Returns True if the tree is balanced"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the squared distance at the given axis between the current Node and the given point", "response": "def axis_dist(self, point, axis):\n        \"\"\"\n        Squared distance at the given axis between\n        the current Node and the given point\n        \"\"\"\n        return math.pow(self.data[axis] - point[axis], 2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dist(self, point):\n        r = range(self.dimensions)\n        return sum([self.axis_dist(point, i) for i in r])", "response": "Squared distance between the current Node\n        and the given point"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_knn(self, point, k, dist=None):\n\n        if k < 1:\n            raise ValueError(\"k must be greater than 0.\")\n\n        if dist is None:\n            get_dist = lambda n: n.dist(point)\n        else:\n            get_dist = lambda n: dist(n.data, point)\n\n        results = []\n\n        self._search_node(point, k, results, get_dist, itertools.count())\n\n        # We sort the final result by the distance in the tuple\n        # (<KdNode>, distance).\n        return [(node, -d) for d, _, node in sorted(results, reverse=True)]", "response": "Search the k nearest neighbors of point and their distances."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_nn(self, point, dist=None):\n\n        return next(iter(self.search_knn(point, 1, dist)), None)", "response": "Search the nearest node to the given point."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching the nearest nodes of the given point within the given distance.", "response": "def search_nn_dist(self, point, distance, best=None):\n        \"\"\"\n        Search the n nearest nodes of the given point which are within given\n        distance\n\n        point must be a location, not a node. A list containing the n nearest\n        nodes to the point within the distance will be returned.\n        \"\"\"\n\n        results = []\n        get_dist = lambda n: n.dist(point)\n\n        self._search_nn_dist(point, distance, results, get_dist)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking recursively if the tree is valid", "response": "def is_valid(self):\n        \"\"\" Checks recursively if the tree is valid\n\n        It is valid if each node splits correctly \"\"\"\n\n        if not self:\n            return True\n\n        if self.left and self.data[self.axis] < self.left.data[self.axis]:\n            return False\n\n        if self.right and self.data[self.axis] > self.right.data[self.axis]:\n            return False\n\n        return all(c.is_valid() for c, _ in self.children) or self.is_leaf"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a child of the subtree and its parent", "response": "def extreme_child(self, sel_func, axis):\n        \"\"\" Returns a child of the subtree and its parent\n\n        The child is selected by sel_func which is either min or max\n        (or a different function with similar semantics). \"\"\"\n\n        max_key = lambda child_parent: child_parent[0].data[axis]\n\n\n        # we don't know our parent, so we include None\n        me = [(self, None)] if self else []\n\n        child_max = [c.extreme_child(sel_func, axis) for c, _ in self.children]\n        # insert self for unknown parents\n        child_max = [(c, p if p is not None else self) for c, p in child_max]\n\n        candidates =  me + child_max\n\n        if not candidates:\n            return None, None\n\n        return sel_func(candidates, key=max_key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencrypting raw data and write to stream.", "response": "def dump_raw(self, text, stream=None):\n        \"\"\"Encrypt raw data and write to stream.\"\"\"\n        encrypted = self.vault.encrypt(text)\n        if stream:\n            stream.write(encrypted)\n        else:\n            return encrypted"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencrypts data and print stdout or write to stream.", "response": "def dump(self, data, stream=None):\n        \"\"\"Encrypt data and print stdout or write to stream.\"\"\"\n        yaml_text = yaml.dump(\n            data,\n            default_flow_style=False,\n            allow_unicode=True)\n        return self.dump_raw(yaml_text, stream=stream)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_item(c, name, item):\n        if isinstance(item, MenuItem):\n            if name not in c.items:\n                c.items[name] = []\n            c.items[name].append(item)\n            c.sorted[name] = False", "response": "Adds a MenuItem to the menu identified by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_menus(c):\n\n        # we don't need to do this more than once\n        if c.loaded:\n            return\n\n        # Fetch all installed app names\n        app_names = settings.INSTALLED_APPS\n        if apps:\n            app_names = [\n                app_config.name\n                for app_config in apps.get_app_configs()\n            ]\n\n        # loop through our INSTALLED_APPS\n        for app in app_names:\n            # skip any django apps\n            if app.startswith(\"django.\"):\n                continue\n\n            menu_module = '%s.menus' % app\n            try:\n                __import__(menu_module, fromlist=[\"menu\", ])\n            except ImportError:\n                pass\n\n        c.loaded = True", "response": "Load all menus from INSTALLED_APPS and loads the menu. py\n        files from them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_menus(c):\n        for name in c.items:\n            if not c.sorted[name]:\n                c.items[name].sort(key=lambda x: x.weight)\n                c.sorted[name] = True", "response": "sort_menus goes through the items and sorts them based on their weight"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process(c, request, name=None):\n        # make sure we're loaded & sorted\n        c.load_menus()\n        c.sort_menus()\n\n        if name is None:\n            # special case, process all menus\n            items = {}\n            for name in c.items:\n                items[name] = c.process(request, name)\n            return items\n\n        if name not in c.items:\n            return []\n\n        items = copy.deepcopy(c.items[name])\n        curitem = None\n        for item in items:\n            item.process(request)\n            if item.visible:\n                item.selected = False\n                if item.match_url(request):\n                    if curitem is None or len(curitem.url) < len(item.url):\n                        curitem = item\n\n        if curitem is not None:\n            curitem.selected = True\n\n        # return only visible items\n        visible = [\n            item\n            for item in items\n            if item.visible\n        ]\n\n        # determine if we should apply 'selected' to parents when one of their\n        # children is the 'selected' menu\n        if getattr(settings, 'MENU_SELECT_PARENTS', False):\n            def is_child_selected(item):\n                for child in item.children:\n                    if child.selected or is_child_selected(child):\n                        return True\n\n            for item in visible:\n                if is_child_selected(item):\n                    item.selected = True\n\n        return visible", "response": "process uses the current request to determine which menus\n            should be visible which are selected etc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(self, request):\n        if callable(self.check_func):\n            self.visible = self.check_func(request)", "response": "Evaluate if we should be visible for this request"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess determines if this item should be visible if its selected etc...", "response": "def process(self, request):\n        \"\"\"\n        process determines if this item should visible, if its selected, etc...\n        \"\"\"\n        # if we're not visible we return since we don't need to do anymore processing\n        self.check(request)\n        if not self.visible:\n            return\n\n        # evaluate our title\n        if callable(self.title):\n            self.title = self.title(request)\n\n        # if no title is set turn it into a slug\n        if self.slug is None:\n            # in python3 we don't need to convert to unicode, in python2 slugify\n            # requires a unicode string\n            if sys.version_info > (3, 0):\n                self.slug = slugify(self.title)\n            else:\n                self.slug = slugify(unicode(self.title))\n\n        # evaluate children\n        if callable(self.children):\n            children = list(self.children(request))\n        else:\n            children = list(self.children)\n\n        for child in children:\n            child.parent = self\n            child.process(request)\n\n        self.children = [\n            child\n            for child in children\n            if child.visible\n        ]\n        self.children.sort(key=lambda child: child.weight)\n\n        # if we have no children and MENU_HIDE_EMPTY then we are not visible and should return\n        hide_empty = getattr(settings, 'MENU_HIDE_EMPTY', False)\n        if hide_empty and len(self.children) == 0:\n            self.visible = False\n            return\n\n        # find out if one of our children is selected, and mark it as such\n        curitem = None\n        for item in self.children:\n            item.selected = False\n\n            if item.match_url(request):\n                if curitem is None or len(curitem.url) < len(item.url):\n                    curitem = item\n\n        if curitem is not None:\n            curitem.selected = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmatching url determines if this is selected", "response": "def match_url(self, request):\n        \"\"\"\n        match url determines if this is selected\n        \"\"\"\n        matched = False\n        if self.exact_url:\n            if re.match(\"%s$\" % (self.url,), request.path):\n                matched = True\n        elif re.match(\"%s\" % self.url, request.path):\n            matched = True\n        return matched"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the protocol using the information gathered from the remote Mongo instance.", "response": "def configure(self, proto):\n        \"\"\"\n            Configures the protocol using the information gathered from the\n            remote Mongo instance. Such information may contain the max\n            BSON document size, replica set configuration, and the master\n            status of the instance.\n            \"\"\"\n\n        if not proto:\n            defer.returnValue(None)\n\n        reply = yield self.__send_ismaster(proto, timeout=self.initialDelay)\n\n        # Handle the reply from the \"ismaster\" query. The reply contains\n        # configuration information about the peer.\n\n        # Make sure we got a result document.\n        if len(reply.documents) != 1:\n            raise OperationFailure(\"TxMongo: invalid document length.\")\n\n        # Get the configuration document from the reply.\n        config = reply.documents[0].decode()\n\n        # Make sure the command was successful.\n        if not config.get(\"ok\"):\n            code = config.get(\"code\")\n            msg = \"TxMongo: \" + config.get(\"err\", \"Unknown error\")\n            raise OperationFailure(msg, code)\n\n        # Check that the replicaSet matches.\n        set_name = config.get(\"setName\")\n        expected_set_name = self.uri[\"options\"].get(\"replicaset\")\n        if expected_set_name and (expected_set_name != set_name):\n            # Log the invalid replica set failure.\n            msg = \"TxMongo: Mongo instance does not match requested replicaSet.\"\n            raise ConfigurationError(msg)\n\n        # Track max bson object size limit.\n        proto.max_bson_size = config.get(\"maxBsonObjectSize\", DEFAULT_MAX_BSON_SIZE)\n        proto.max_write_batch_size = config.get(\"maxWriteBatchSize\", DEFAULT_MAX_WRITE_BATCH_SIZE)\n\n        proto.set_wire_versions(config.get(\"minWireVersion\", 0),\n                                config.get(\"maxWireVersion\", 0))\n\n        # Track the other hosts in the replica set.\n        hosts = config.get(\"hosts\")\n        if isinstance(hosts, list) and hosts:\n            for host in hosts:\n                if ':' not in host:\n                    host = (host, 27017)\n                else:\n                    host = host.split(':', 1)\n                    host[1] = int(host[1])\n                    host = tuple(host)\n                if host not in self.__allnodes:\n                    self.__allnodes.append(host)\n\n        # Check if this node is the master.\n        ismaster = config.get(\"ismaster\")\n        if not ismaster:\n            msg = \"TxMongo: MongoDB host `%s` is not master.\" % config.get('me')\n            raise AutoReconnect(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a deferred that will fire when the master has created a protocol that can be used to communicate with a Mongo server.", "response": "def notifyReady(self):\n        \"\"\"\n            Returns a deferred that will fire when the factory has created a\n            protocol that can be used to communicate with a Mongo server.\n\n            Note that this will not fire until we have connected to a Mongo\n            master, unless slaveOk was specified in the Mongo URI connection\n            options.\n            \"\"\"\n        if self.instance:\n            return defer.succeed(self.instance)\n\n        def on_cancel(d):\n            self.__notify_ready.remove(d)\n\n        df = defer.Deferred(on_cancel)\n        self.__notify_ready.append(df)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retryNextHost(self, connector=None):\n        if not self.continueTrying:\n            msg = \"TxMongo: Abandoning {0} on explicit request.\".format(connector)\n            log.msg(msg)\n            return\n\n        if connector is None:\n            if self.connector is None:\n                raise ValueError(\"TxMongo: No additional connector to retry.\")\n            else:\n                connector = self.connector\n\n        delay = False\n        self.__index += 1\n\n        if self.__index >= len(self.__allnodes):\n            self.__index = 0\n            delay = True\n\n        connector.host, connector.port = self.__allnodes[self.__index]\n\n        if delay:\n            self.retry(connector)\n        else:\n            connector.connect()", "response": "Retry next host in the list of hosts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a defer on the creation of this GridFS instance s indexes", "response": "def indexes_created(self):\n        \"\"\"Returns a defer on the creation of this GridFS instance's indexes\n        \"\"\"\n        d = defer.Deferred()\n        self.__indexes_created_defer.chainDeferred(d)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, data, **kwargs):\n        grid_file = GridIn(self.__collection, **kwargs)\n\n        def _finally(result):\n            return grid_file.close().addCallback(lambda _: result)\n\n        return grid_file.write(data)\\\n            .addBoth(_finally)\\\n            .addCallback(lambda _: grid_file._id)", "response": "Put data in GridFS as a new file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, file_id):\n        def ok(doc):\n            if doc is None:\n                raise NoFile(\"TxMongo: no file in gridfs with _id {0}\".format(repr(file_id)))\n\n            return GridOut(self.__collection, doc)\n        return self.__collection.files.find_one({\"_id\": file_id}).addCallback(ok)", "response": "Get a file from GridFS by _id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a file from GridFS by filename and optionally version.", "response": "def get_version(self, filename=None, version=-1):\n        \"\"\"Get a file from GridFS by ``\"filename\"``.\n        Returns a version of the file in GridFS whose filename matches\n        `filename` and whose metadata fields match the supplied keyword\n        arguments, as an instance of :class:`~gridfs.grid_file.GridOut`.\n        Version numbering is a convenience atop the GridFS API provided\n        by MongoDB. If more than one file matches the query (either by\n        `filename` alone, by metadata fields, or by a combination of\n        both), then version ``-1`` will be the most recently uploaded\n        matching file, ``-2`` the second most recently\n        uploaded, etc. Version ``0`` will be the first version\n        uploaded, ``1`` the second version, etc. So if three versions\n        have been uploaded, then version ``0`` is the same as version\n        ``-3``, version ``1`` is the same as version ``-2``, and\n        version ``2`` is the same as version ``-1``. Note that searching by\n        random (unindexed) meta data is not supported here.\n        Raises :class:`~gridfs.errors.NoFile` if no such version of\n        that file exists.\n        :Parameters:\n          - `filename`: ``\"filename\"`` of the file to get, or `None`\n          - `version` (optional): version of the file to get (defaults\n            to -1, the most recent version uploaded)\n        \"\"\"        \n        query = {\"filename\": filename}\n        skip = abs(version)\n        if version < 0:\n            skip -= 1\n            myorder = DESCENDING(\"uploadDate\")\n        else:\n            myorder = ASCENDING(\"uploadDate\")\n\n        def ok(cursor):\n            if cursor:\n                return GridOut(self.__collection, cursor[0])\n\n            raise NoFile(\"no version %d for filename %r\" % (version, filename))\n\n        return self.__files.find(query, filter=filter.sort(myorder), limit=1, skip=skip)\\\n            .addCallback(ok)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a file from GridFS by filename.", "response": "def get_last_version(self, filename):\n        \"\"\"Get a file from GridFS by ``\"filename\"``.\n\n        Returns the most recently uploaded file in GridFS with the\n        name `filename` as an instance of\n        :class:`~gridfs.grid_file.GridOut`. Raises\n        :class:`~gridfs.errors.NoFile` if no such file exists.\n\n        An index on ``{filename: 1, uploadDate: -1}`` will\n        automatically be created when this method is called the first\n        time.\n\n        :Parameters:\n          - `filename`: ``\"filename\"`` of the file to get\n\n        .. versionadded:: 1.6\n        \"\"\"\n        def ok(doc):\n            if doc is None:\n                raise NoFile(\"TxMongo: no file in gridfs with filename {0}\".format(repr(filename)))\n\n            return GridOut(self.__collection, doc)\n\n        return self.__files.find_one({\"filename\": filename},\n                                     filter = filter.sort(DESCENDING(\"uploadDate\"))).addCallback(ok)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, file_id):\n        return defer.DeferredList([\n            self.__files.remove({\"_id\": file_id}, safe=True),\n            self.__chunks.remove({\"files_id\": file_id})\n        ])", "response": "Delete a file from GridFS by file_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a command on the cluster and return the result.", "response": "def command(self, command, value=1, check=True, allowable_errors=None,\n                codec_options=DEFAULT_CODEC_OPTIONS, _deadline=None, **kwargs):\n        \"\"\"command(command, value=1, check=True, allowable_errors=None, codec_options=DEFAULT_CODEC_OPTIONS)\"\"\"\n        if isinstance(command, (bytes, unicode)):\n            command = SON([(command, value)])\n        options = kwargs.copy()\n        command.update(options)\n\n        def on_ok(response):\n            if check:\n                msg = \"TxMongo: command {0} on namespace {1} failed with '%s'\".format(repr(command), ns)\n                _check_command_response(response, msg, allowable_errors)\n\n            return response\n\n        ns = self[\"$cmd\"].with_options(codec_options=codec_options)\n        return ns.find_one(command, _deadline=_deadline).addCallback(on_ok)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndrops a collection from the database.", "response": "def drop_collection(self, name_or_collection, _deadline=None):\n        \"\"\"drop_collection(name_or_collection)\"\"\"\n        if isinstance(name_or_collection, Collection):\n            name = name_or_collection._collection_name\n        elif isinstance(name_or_collection, (bytes, unicode)):\n            name = name_or_collection\n        else:\n            raise TypeError(\"TxMongo: name must be an instance of basestring or txmongo.Collection\")\n\n        return self.command(\"drop\", unicode(name), allowable_errors=[\"ns not found\"],\n                            _deadline=_deadline)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all the names of the current user s system. namespaces.", "response": "def collection_names(self, _deadline=None):\n        \"\"\"collection_names()\"\"\"\n        def ok(results):\n            names = [r[\"name\"] for r in results]\n            names = [n[len(str(self)) + 1:] for n in names\n                     if n.startswith(str(self) + \".\")]\n            names = [n for n in names if \"$\" not in n]\n            return names\n        return self[\"system.namespaces\"].find(_deadline=_deadline).addCallback(ok)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nauthenticating with the database.", "response": "def authenticate(self, name, password, mechanism=\"DEFAULT\"):\n        \"\"\"\n        Send an authentication command for this database.\n        mostly stolen from pymongo\n        \"\"\"\n        if not isinstance(name, (bytes, unicode)):\n            raise TypeError(\"TxMongo: name must be an instance of basestring.\")\n        if not isinstance(password, (bytes, unicode)):\n            raise TypeError(\"TxMongo: password must be an instance of basestring.\")\n\n        \"\"\"\n        Authenticating\n        \"\"\"\n        return self.connection.authenticate(self, name, password, mechanism)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeout(func):\n\n    @wraps(func)\n    def _timeout(*args, **kwargs):\n        now = time()\n        deadline = kwargs.pop(\"deadline\", None)\n        seconds = kwargs.pop(\"timeout\", None)\n\n        if deadline is None and seconds is not None:\n            deadline = now + seconds\n\n        if deadline is not None and deadline < now:\n            raise TimeExceeded(\"TxMongo: run time exceeded by {0}s.\".format(now-deadline))\n\n        kwargs['_deadline'] = deadline\n        raw_d = func(*args, **kwargs)\n\n        if deadline is None:\n            return raw_d\n\n        if seconds is None and deadline is not None and deadline - now > 0:\n            seconds = deadline - now\n\n        timeout_d = defer.Deferred()\n        times_up = reactor.callLater(seconds, timeout_d.callback, None)\n\n        def on_ok(result):\n            if timeout_d.called:\n                raw_d.cancel()\n                raise TimeExceeded(\"TxMongo: run time of {0}s exceeded.\".format(seconds))\n            else:\n                times_up.cancel()\n                return result[0]\n\n        def on_fail(failure):\n            failure.trap(defer.FirstError)\n            assert failure.value.index == 0\n            times_up.cancel()\n            failure.value.subFailure.raiseException()\n\n\n        return defer.DeferredList([raw_d, timeout_d], fireOnOneCallback=True,\n                                  fireOnOneErrback=True, consumeErrors=True).addCallbacks(on_ok, on_fail)\n\n    return _timeout", "response": "Decorator to add timeout to Deferred calls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_property(field_name, docstring,\n                     read_only=False, closed_only=False):\n    \"\"\"Helper for creating properties to read/write to files.\n    \"\"\"\n\n    def getter(self):\n        if closed_only and not self._closed:\n            raise AttributeError(\n                \"TxMongo: can only get {0} on a closed file.\".format(repr(field_name)))\n        return self._file.get(field_name, None)\n\n    def setter(self, value):\n        if self._closed:\n            raise AttributeError(\n                \"TxMongo: cannot set {0} on a closed file.\".format(repr(field_name)))\n        self._file[field_name] = value\n\n    if read_only:\n        docstring += \"\\n\\nThis attribute is read-only.\"\n    elif not closed_only:\n        docstring = \"%s\\n\\n%s\" % (docstring, \"This attribute can only be \"\n                                             \"set before :meth:`close` has been called.\")\n    else:\n        docstring = \"%s\\n\\n%s\" % (docstring, \"This attribute is read-only and \"\n                                             \"can only be read after :meth:`close` \"\n                                             \"has been called.\")\n\n    if not read_only and not closed_only:\n        return property(getter, setter, doc=docstring)\n    return property(getter, doc=docstring)", "response": "Helper for creating properties to read or write to files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflush the data to a chunk.", "response": "def __flush_data(self, data):\n        \"\"\"Flush `data` to a chunk.\n        \"\"\"\n        if not data:\n            return defer.succeed(None)\n\n        assert (len(data) <= self.chunk_size)\n        chunk = {\"files_id\": self._file[\"_id\"],\n                 \"n\": self._chunk_number,\n                 \"data\": Binary(data)}\n\n        def ok(_):\n            self._chunk_number += 1\n            self._position += len(data)\n\n        # Continue writing after the insert completes (non-blocking)\n        return self._chunks.insert(chunk).addCallback(ok)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __flush_buffer(self):\n        def ok(_):\n            self._buffer.close()\n            self._buffer = StringIO()\n        return self.__flush_data(self._buffer.getvalue()).addCallback(ok)", "response": "Flush the buffer contents out to a chunk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nflush the file to the database.", "response": "def __flush(self):\n        \"\"\"Flush the file to the database.\n        \"\"\"\n        def on_md5(md5):\n            self._file[\"md5\"] = md5\n            self._file[\"length\"] = self._position\n            self._file[\"uploadDate\"] = datetime.datetime.utcnow()\n            return self._coll.files.insert(self._file)\n\n        return self.__flush_buffer()\\\n            .addCallback(lambda _: self._coll.filemd5(self._id))\\\n            .addCallback(on_md5)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self):\n        if self._closed:\n            return defer.succeed(None)\n\n        def ok(_):\n            self._closed = True\n        return self.__flush().addCallback(ok)", "response": "Flush the file and close it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, data):\n        if self._closed:\n            raise ValueError(\"TxMongo: cannot write to a closed file.\")\n\n        try:\n            # file-like\n            read = data.read\n        except AttributeError:\n            # string\n            if not isinstance(data, (bytes, unicode)):\n                raise TypeError(\"TxMongo: can only write strings or file-like objects.\")\n            if isinstance(data, unicode):\n                try:\n                    data = data.encode(self.encoding)\n                except AttributeError:\n                    raise TypeError(\"TxMongo: must specify an encoding for file in \"\n                                    \"order to write {0}\".format(data))\n            read = StringIO(data).read\n\n        def do_write(_=None):\n            to_write = read(self.chunk_size)\n            if to_write and len(to_write) == self.chunk_size:\n                return self.__flush_data(to_write).addCallback(do_write)\n            else:\n                self._buffer.write(to_write)\n\n        if self._buffer.tell() > 0:\n            # Make sure to flush only when _buffer is complete\n            space = self.chunk_size - self._buffer.tell()\n            if space:\n                to_write = read(space)\n                self._buffer.write(to_write)\n                if len(to_write) < space:\n                    return defer.succeed(None)  # EOF or incomplete\n            return self.__flush_buffer().addCallback(do_write)\n        else:\n            return defer.maybeDeferred(do_write)", "response": "Writes data to the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a sequence of strings to the file. Does not add separators.", "response": "def writelines(self, sequence):\n        \"\"\"Write a sequence of strings to the file.\n\n        Does not add separators.\n        \"\"\"\n        iterator = iter(sequence)\n\n        def iterate(_=None):\n            try:\n                return self.write(next(iterator)).addCallback(iterate)\n            except StopIteration:\n                return\n        return defer.maybeDeferred(iterate)"}
